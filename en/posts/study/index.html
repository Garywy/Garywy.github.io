<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Study | Gary's House</title>
<meta name=keywords content><meta name=description content="Study - Gary's House"><meta name=author content="Gary"><link rel=canonical href=https://garyforreal.me/en/posts/study/><meta name=google-site-verification content="XYZabc"><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><meta name=referrer content="no-referrer-when-downgrade"><link crossorigin=anonymous href=/assets/css/stylesheet.7e5251d8716d933fafcf3df70d7ecd02729661d6d232fc5dd0b8a85ef75e3409.css integrity="sha256-flJR2HFtkz+vzz33DX7NAnKWYdbSMvxd0LioXvdeNAk=" rel="preload stylesheet" as=style><link rel=icon href=https://garyforreal.me/img/Q.jpg><link rel=icon type=image/png sizes=16x16 href=https://garyforreal.me/img/Q.jpg><link rel=icon type=image/png sizes=32x32 href=https://garyforreal.me/img/Q.jpg><link rel=apple-touch-icon href=https://garyforreal.me/Q.jpg><link rel=mask-icon href=https://garyforreal.me/Q.jpg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://garyforreal.me/en/posts/study/index.xml><link rel=alternate hreflang=en href=https://garyforreal.me/en/posts/study/><link rel=alternate hreflang=zh href=https://garyforreal.me/zh/posts/study/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@200..900&display=swap" rel=stylesheet><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous referrerpolicy=no-referrer></script><meta property="og:title" content="Study"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://garyforreal.me/en/posts/study/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Study"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://garyforreal.me/en/posts/"},{"@type":"ListItem","position":2,"name":"Study","item":"https://garyforreal.me/en/posts/study/"}]}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css><script src=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><script src=https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js></script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://garyforreal.me/en/ accesskey=h title="Gary's Blog (Alt + H)"><img src=https://garyforreal.me/img/me.jpg alt aria-label=logo height=35>Gary's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://garyforreal.me/zh/ title=‰∏≠Êñá aria-label=‰∏≠Êñá>‰∏≠Êñá</a></li></ul></div></div><ul id=menu><li><a href=https://garyforreal.me/en/search title="üîçSearch (Alt + /)" accesskey=/><span>üîçSearch</span></a></li><li><a href=https://garyforreal.me/en/ title=üè†Homepage><span>üè†Homepage</span></a></li><li><a href=https://garyforreal.me/en/posts title=üìöArticle><span>üìöArticle</span></a></li><li><a href=https://garyforreal.me/en/archives/ title=‚è±Archives><span>‚è±Archives</span></a></li><li><a href=https://garyforreal.me/en/music/ title=üéµmusic><span>üéµmusic</span></a></li><li><a href=https://garyforreal.me/en/about title=üôãüèª‚Äç‚ôÇÔ∏èAbout><span>üôãüèª‚Äç‚ôÇÔ∏èAbout</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://garyforreal.me/en/>Home</a>&nbsp;¬ª&nbsp;<a href=https://garyforreal.me/en/posts/>Posts</a></div><h1>Study</h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Weekly Paper Notes - 2025-12-09</h2></header><div class=entry-content><p>Weekly Paper Notes üîç multilingual M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG Authors: David Anugraha, Patrick Amadeus Irawan, Anshul Singh, En-Shiun Annie Lee, Genta Indra Winata Venue: arXiv (2025)
Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.
...</p></div><footer class=entry-footer><span title='2025-12-09 00:32:16.811643 +0000 UTC'>2025-12-09</span>&nbsp;¬∑&nbsp;44 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Weekly Paper Notes - 2025-12-09" href=https://garyforreal.me/en/posts/study/paper-2025-12-09-weekly/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Weekly Paper Notes - 2025-12-08</h2></header><div class=entry-content><p>Weekly Paper Notes üîç multilingual M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG Authors: David Anugraha, Patrick Amadeus Irawan, Anshul Singh, En-Shiun Annie Lee, Genta Indra Winata Venue: arXiv (2025)
Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.
...</p></div><footer class=entry-footer><span title='2025-12-08 04:07:26.185792 +0000 UTC'>2025-12-08</span>&nbsp;¬∑&nbsp;44 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Weekly Paper Notes - 2025-12-08" href=https://garyforreal.me/en/posts/study/paper-2025-12-08-weekly/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Weekly Paper Notes - 2025-12-07</h2></header><div class=entry-content><p>Weekly Paper Notes üîç cross-lingual KDA: Knowledge Distillation Adapter for Cross-Lingual Transfer Authors: Venue: (Tue,)
Ta-Bao Nguyen, Nguyen-Phuong Phan, Tung Le and Huy Tien Nguyen in Proceedings of the 18th International Natural Language Generation Conference
üì• Save to Zotero üìÑ Download PDF
Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent? Authors: Venue: (Fri,)
Xi Ai, Mahardika Krisna Ihsani and Min-Yen Kan in Findings of the Association for Computational Linguistics: EMNLP 2025
...</p></div><footer class=entry-footer><span title='2025-12-07 07:18:42.705067 +0000 UTC'>2025-12-07</span>&nbsp;¬∑&nbsp;10 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Weekly Paper Notes - 2025-12-07" href=https://garyforreal.me/en/posts/study/paper-2025-12-07-weekly/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Weekly Paper Notes - 2025-12-06</h2></header><div class=entry-content><p>Weekly Paper Notes üîç multilingual LLMs Know More Than Words: A Genre Study with Syntax, Metaphor & Phonetics Authors: Weiye Shi, Zhaowei Zhang, Shaoheng Yan, Yaodong Yang Venue: arXiv (2025)
Large language models (LLMs) demonstrate remarkable potential across diverse language related tasks, yet whether they capture deeper linguistic properties, such as syntactic structure, phonetic cues, and metrical patterns from raw text remains unclear. To analysis whether LLMs can learn these features effectively and apply them to important nature language related tasks, we introduce a novel multilingual genre classification dataset derived from Project Gutenberg, a large-scale digital library offering free access to thousands of public domain literary works, comprising thousands of sentences per binary task (poetry vs. novel;drama vs. poetry;drama vs. novel) in six languages (English, French, German, Italian, Spanish, and Portuguese). We augment each with three explicit linguistic feature sets (syntactic tree structures, metaphor counts, and phonetic metrics) to evaluate their impact on classification performance. Experiments demonstrate that although LLM classifiers can learn latent linguistic structures either from raw text or from explicitly provided features, different features contribute unevenly across tasks, which underscores the importance of incorporating more complex linguistic signals during model training.
...</p></div><footer class=entry-footer><span title='2025-12-06 11:29:05.001617 +0000 UTC'>2025-12-06</span>&nbsp;¬∑&nbsp;53 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Weekly Paper Notes - 2025-12-06" href=https://garyforreal.me/en/posts/study/paper-2025-12-06-weekly/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Weekly Paper Notes - 2025-12-05</h2></header><div class=entry-content><p>Weekly Paper Notes üîç multilingual LLMs Know More Than Words: A Genre Study with Syntax, Metaphor & Phonetics Authors: Weiye Shi, Zhaowei Zhang, Shaoheng Yan, Yaodong Yang Venue: arXiv (2025)
Large language models (LLMs) demonstrate remarkable potential across diverse language related tasks, yet whether they capture deeper linguistic properties, such as syntactic structure, phonetic cues, and metrical patterns from raw text remains unclear. To analysis whether LLMs can learn these features effectively and apply them to important nature language related tasks, we introduce a novel multilingual genre classification dataset derived from Project Gutenberg, a large-scale digital library offering free access to thousands of public domain literary works, comprising thousands of sentences per binary task (poetry vs. novel;drama vs. poetry;drama vs. novel) in six languages (English, French, German, Italian, Spanish, and Portuguese). We augment each with three explicit linguistic feature sets (syntactic tree structures, metaphor counts, and phonetic metrics) to evaluate their impact on classification performance. Experiments demonstrate that although LLM classifiers can learn latent linguistic structures either from raw text or from explicitly provided features, different features contribute unevenly across tasks, which underscores the importance of incorporating more complex linguistic signals during model training.
...</p></div><footer class=entry-footer><span title='2025-12-05 15:29:10.166264 +0000 UTC'>2025-12-05</span>&nbsp;¬∑&nbsp;853 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Weekly Paper Notes - 2025-12-05" href=https://garyforreal.me/en/posts/study/paper-2025-12-05-weekly/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Weekly Paper Notes - 2025-12-04</h2></header><div class=entry-content><p>Weekly Paper Notes üîç cross-lingual KDA: Knowledge Distillation Adapter for Cross-Lingual Transfer Authors: Venue: (Tue,)
Ta-Bao Nguyen, Nguyen-Phuong Phan, Tung Le and Huy Tien Nguyen in Proceedings of the 18th International Natural Language Generation Conference
üîç code-switching Can Code-Switched Texts Activate a Knowledge Switch in LLMs? A Case Study on English-Korean Code-Switching Authors: Venue: (Fri,)
Seoyeon Kim, Huiseo Kim, Chanjun Park, Jinyoung Yeo and Dongha Lee in Findings of the Association for Computational Linguistics: EMNLP 2025
...</p></div><footer class=entry-footer><span title='2025-12-04 08:53:15.015296 +0000 UTC'>2025-12-04</span>&nbsp;¬∑&nbsp;3 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Weekly Paper Notes - 2025-12-04" href=https://garyforreal.me/en/posts/study/paper-2025-12-04-weekly/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>DP_Question</h2></header><div class=entry-content><p>Preface Because I always hit a wall with Dynamic Programming problems, I would like to summarize the solution to Dynamic Programming problems(DP).
Basic solution to DP problemsÔºö
Initial State State Transition Equation 1. Linear DP 1. 1 ExampleÔºöLeetcode 300. Longest Increasing Subsequence Given an integer array nums, return the length of the longest strictly increasing subsequence.
Example 1:
Input: nums = [10, 9, 2, 5, 3, 7, 101, 18]
Output: 4
Explanation: The longest increasing subsequence is [2, 3, 7, 101], therefore the length is 4.
...</p></div><footer class=entry-footer><span title='2024-09-29 18:20:59 +0900 JST'>2024-09-29</span>&nbsp;¬∑&nbsp;13 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to DP_Question" href=https://garyforreal.me/en/posts/study/dp_question/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Markdown Study Notes</h2></header><div class=entry-content><p>Preface This article mainly summarizes the common syntax of Markdown, so that you can write Markdown files better by yourself.
1. Basic Grammer 1.1 Title Use# to create a title. The number of # you use indicates the number of heading levels.
Markdown Display # title1 title1 # title2 title2 # title3 title3 1.2 Line break Add 2 or more spaces after the text, or add a blank line (press enter twice).
...</p></div><footer class=entry-footer><span title='2024-09-26 17:31:12 +0900 JST'>2024-09-26</span>&nbsp;¬∑&nbsp;2 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Markdown Study Notes" href=https://garyforreal.me/en/posts/study/markdown_study_notes/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Hugo_githubpages</h2></header><div class=entry-content><p>1. Preface Originally, I was required to create a web service for a research project, but I accidentally discovered Hugo. So I took this opportunity to use Hugo to make my blog. This article mainly covers the process of setting up a personal blog, some of the problems I encountered and the solutions, I hope it will be helpful to you.
Since I am using mac os, there may be some differences from the Windows system.
...</p></div><footer class=entry-footer><span title='2024-09-26 11:09:46 +0900 JST'>2024-09-26</span>&nbsp;¬∑&nbsp;5 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Hugo_githubpages" href=https://garyforreal.me/en/posts/study/hugo_githubpages/></a></article></main><footer class=footer><span>&copy; 2025 <a href=https://garyforreal.me/en/>Gary's House</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span><div class=busuanzi-footer><span id=busuanzi_container_site_pv>Views: <span id=busuanzi_value_site_pv></span>
</span><span id=busuanzi_container_site_uv>Visitors: <span id=busuanzi_value_site_uv></span></span></div></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>