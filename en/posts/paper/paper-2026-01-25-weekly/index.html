<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Weekly Paper Notes - 2026-01-25 | Gary's House</title>
<meta name=keywords content><meta name=description content="Weekly Paper Notes
üîç multilingual
Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging
Authors: Alphaeus Dmonte, Vidhi Gupta, Daniel J Perry, Mark Arehart
Venue: arXiv (2026)
Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work."><meta name=author content="Gary"><link rel=canonical href=https://garyforreal.me/en/posts/paper/paper-2026-01-25-weekly/><meta name=google-site-verification content="XYZabc"><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><meta name=referrer content="no-referrer-when-downgrade"><link crossorigin=anonymous href=/assets/css/stylesheet.7e5251d8716d933fafcf3df70d7ecd02729661d6d232fc5dd0b8a85ef75e3409.css integrity="sha256-flJR2HFtkz+vzz33DX7NAnKWYdbSMvxd0LioXvdeNAk=" rel="preload stylesheet" as=style><link rel=icon href=https://garyforreal.me/img/Q.jpg><link rel=icon type=image/png sizes=16x16 href=https://garyforreal.me/img/Q.jpg><link rel=icon type=image/png sizes=32x32 href=https://garyforreal.me/img/Q.jpg><link rel=apple-touch-icon href=https://garyforreal.me/Q.jpg><link rel=mask-icon href=https://garyforreal.me/Q.jpg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://garyforreal.me/zh/posts/paper/paper-2026-01-25-weekly/><link rel=alternate hreflang=en href=https://garyforreal.me/en/posts/paper/paper-2026-01-25-weekly/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@200..900&display=swap" rel=stylesheet><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous referrerpolicy=no-referrer></script><meta property="og:title" content="Weekly Paper Notes - 2026-01-25"><meta property="og:description" content="Weekly Paper Notes
üîç multilingual
Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging
Authors: Alphaeus Dmonte, Vidhi Gupta, Daniel J Perry, Mark Arehart
Venue: arXiv (2026)
Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work."><meta property="og:type" content="article"><meta property="og:url" content="https://garyforreal.me/en/posts/paper/paper-2026-01-25-weekly/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-01-25T15:25:20+00:00"><meta property="article:modified_time" content="2026-01-25T15:25:20+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Weekly Paper Notes - 2026-01-25"><meta name=twitter:description content="Weekly Paper Notes
üîç multilingual
Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging
Authors: Alphaeus Dmonte, Vidhi Gupta, Daniel J Perry, Mark Arehart
Venue: arXiv (2026)
Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://garyforreal.me/en/posts/"},{"@type":"ListItem","position":2,"name":"Paper","item":"https://garyforreal.me/en/posts/paper/"},{"@type":"ListItem","position":3,"name":"Weekly Paper Notes - 2026-01-25","item":"https://garyforreal.me/en/posts/paper/paper-2026-01-25-weekly/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Weekly Paper Notes - 2026-01-25","name":"Weekly Paper Notes - 2026-01-25","description":"Weekly Paper Notes üîç multilingual Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging Authors: Alphaeus Dmonte, Vidhi Gupta, Daniel J Perry, Mark Arehart Venue: arXiv (2026)\nFine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work.\n","keywords":[],"articleBody":"Weekly Paper Notes üîç multilingual Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging Authors: Alphaeus Dmonte, Vidhi Gupta, Daniel J Perry, Mark Arehart Venue: arXiv (2026)\nFine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work.\nüìÑ Download PDF\nAdapter Fusion for Multilingual Text2Cypher with Linear and Learned Gating Authors: Makbule Gulcin Ozsoy Venue: arXiv (2026)\nLarge Language Models enable users to access database using natural language interfaces using tools like Text2SQL, Text2SPARQL, and Text2Cypher, which translate user questions into structured database queries. While these systems improve database accessibility, most research focuses on English with limited multilingual support. This work investigates a scalable multilingual Text2Cypher, aiming to support new languages without re-running full fine-tuning, avoiding manual hyper-parameter tuning, and maintaining performance close to joint multilingual fine-tuning. We train language-specific LoRA adapters for English, Spanish, and Turkish and combined them via uniform linear merging or learned fusion MLP with dynamic gating. Experimental results show that the fusion MLP recovers around 75% of the accuracy gains from joint multilingual fine-tuning while requiring only a smaller subset of the data, outperforming linear merging across all three languages. This approach enables incremental language expansion to new languages by requiring only one LoRA adapter and a lightweight MLP retraining. Learned adapter fusion offers a practical alternative to expensive joint fine-tuning, balancing performance, data efficiency, and scalability for multilingual Text2Cypher task.\nüìÑ Download PDF\nTimbre-Aware LLM-based Direct Speech-to-Speech Translation Extendable to Multiple Language Pairs Authors: Lalaram Arya, Mrinmoy Bhattacharjee, Adarsh C. R., S. R. Mahadeva Prasanna Venue: arXiv (2026)\nDirect Speech-to-Speech Translation (S2ST) has gained increasing attention for its ability to translate speech from one language to another, while reducing error propagation and latency inherent in traditional cascaded pipelines. However, existing direct S2ST systems continue to face notable challenges, including instability in semantic-acoustic alignment when parallel speech data is scarce, difficulty in preserving speaker identity, and limited multilingual scalability. In this work, we introduce DS2ST-LM, a scalable, single-stage direct S2ST framework leveraging a multilingual Large Language Model (LLM). The architecture integrates a Whisper speech encoder, a learnable projection module, a Qwen2-0.5B LLM, and a timbre-controlled vocoder. We construct GigaS2S-1000, a 1000-hour bilingual corpus by extending the GigaST dataset with high-fidelity synthetic target speech, and show that this synthetic data alleviates data scarcity to some extent. We investigate two semantic token generation strategies: speech-derived S3 tokens and text-derived tokens generated by a pre-trained LLM, and analyze their impact on training stability and semantic consistency. We further evaluate three projection architectures (Linear, Conv1D-Linear, and Q-Former) and observe that while higher-capacity projectors converge faster, the simple Linear projector achieves higher performance. Extensive experiments demonstrate that DS2ST-LM outperforms traditional cascaded and ST (Qwen-Audio) + TTS baselines across both lexical (BLEU, METEOR) and semantic (BLEURT, COMET) metrics, while extending to multiple language pairs, including French, Spanish, German, Hindi, Bengali, and Urdu. Furthermore, we incorporate timbre-aware speech synthesis to preserve speaker information, enabling DS2ST-LM to surpass prior direct S2ST systems in both speaker similarity and perceptual naturalness.\nüìÑ Download PDF\nDeterminants of Training Corpus Size for Clinical Text Classification Authors: Jaya Chaturvedi, Saniya Deshpande, Chenkai Ma, Robert Cobb, Angus Roberts, Robert Stewart, Daniel Stahl, Diana Shamsutdinova Venue: arXiv (2026)\nIntroduction: Clinical text classification using natural language processing (NLP) models requires adequate training data to achieve optimal performance. For that, 200-500 documents are typically annotated. The number is constrained by time and costs and lacks justification of the sample size requirements and their relationship to text vocabulary properties. Methods: Using the publicly available MIMIC-III dataset containing hospital discharge notes with ICD-9 diagnoses as labels, we employed pre-trained BERT embeddings followed by Random Forest classifiers to identify 10 randomly selected diagnoses, varying training corpus sizes from 100 to 10,000 documents, and analyzed vocabulary properties by identifying strong and noisy predictive words through Lasso logistic regression on bag-of-words embeddings. Results: Learning curves varied significantly across the 10 classification tasks despite identical preprocessing and algorithms, with 600 documents sufficient to achieve 95% of the performance attainable with 10,000 documents for all tasks. Vocabulary analysis revealed that more strong predictors and fewer noisy predictors were associated with steeper learning curves, where every 100 additional noisy words decreased accuracy by approximately 0.02 while 100 additional strong predictors increased maximum accuracy by approximately 0.04.\nüìÑ Download PDF\nSteerEval: Inference-time Interventions Strengthen Multilingual Generalization in Neural Summarization Metrics Authors: Silvia Casola, Ryan Soh-Eun Shim, Felicia K√∂rner, Yuchen Mao, Barbara Plank Venue: arXiv (2026)\nAn increasing body of work has leveraged multilingual language models for Natural Language Generation tasks such as summarization. A major empirical bottleneck in this area is the shortage of accurate and robust evaluation metrics for many languages, which hinders progress. Recent studies suggest that multilingual language models often use English as an internal pivot language, and that misalignment with this pivot can lead to degraded downstream performance. Motivated by the hypothesis that this mismatch could also apply to multilingual neural metrics, we ask whether steering their activations toward an English pivot can improve correlation with human judgments. We experiment with encoder- and decoder-based metrics and find that test-time intervention methods are effective across the board, increasing metric effectiveness for diverse languages.\nüìÑ Download PDF\nImproving Methodologies for LLM Evaluations Across Global Languages Authors: Akriti Vij, Benjamin Chua, Darshini Ramiah, En Qi Ng, Mahran Morsidi, Naga Nikshith Gangarapu, Sharmini Johnson, Vanessa Wilfred, Vikneswaran Kumaran, Wan Sie Lee, Wenzhuo Yang, Yongsen Zheng, Bill Black, Boming Xia, Frank Sun, Hao Zhang, Qinghua Lu, Suyu Ma, Yue Liu, Chi-kiu Lo, Fatemeh Azadi, Isar Nejadgholi, Sowmya Vajjala, Agnes Delaborde, Nicolas Rolin, Tom Seimandi, Akiko Murakami, Haruto Ishi, Satoshi Sekine, Takayuki Semitsu, Tasuku Sasaki, Angela Kinuthia, Jean Wangari, Michael Michie, Stephanie Kasaon, Hankyul Baek, Jaewon Noh, Kihyuk Nam, Sang Seo, Sungpil Shin, Taewhi Lee, Yongsu Kim, Daisy Newbold-Harrop, Jessica Wang, Mahmoud Ghanem, Vy Hong Venue: arXiv (2026)\nAs frontier AI models are deployed globally, it is essential that their behaviour remains safe and reliable across diverse linguistic and cultural contexts. To examine how current model safeguards hold up in such settings, participants from the International Network for Advanced AI Measurement, Evaluation and Science, including representatives from Singapore, Japan, Australia, Canada, the EU, France, Kenya, South Korea and the UK conducted a joint multilingual evaluation exercise. Led by Singapore AISI, two open-weight models were tested across ten languages spanning high and low resourced groups: Cantonese English, Farsi, French, Japanese, Korean, Kiswahili, Malay, Mandarin Chinese and Telugu. Over 6,000 newly translated prompts were evaluated across five harm categories (privacy, non-violent crime, violent crime, intellectual property and jailbreak robustness), using both LLM-as-a-judge and human annotation. The exercise shows how safety behaviours can vary across languages. These include differences in safeguard robustness across languages and harm types and variation in evaluator reliability (LLM-as-judge vs. human review). Further, it also generated methodological insights for improving multilingual safety evaluations, such as the need for culturally contextualised translations, stress-tested evaluator prompts and clearer human annotation guidelines. This work represents an initial step toward a shared framework for multilingual safety testing of advanced AI systems and calls for continued collaboration with the wider research community and industry.\nüìÑ Download PDF\nObscuring Data Contamination Through Translation: Evidence from Arabic Corpora Authors: Chaymaa Abbas, Nour Shamaa, Mariette Awad Venue: arXiv (2026)\nData contamination undermines the validity of Large Language Model evaluation by enabling models to rely on memorized benchmark content rather than true generalization. While prior work has proposed contamination detection methods, these approaches are largely limited to English benchmarks, leaving multilingual contamination poorly understood. In this work, we investigate contamination dynamics in multilingual settings by fine-tuning several open-weight LLMs on varying proportions of Arabic datasets and evaluating them on original English benchmarks. To detect memorization, we extend the Tested Slot Guessing method with a choice-reordering strategy and incorporate Min-K% probability analysis, capturing both behavioral and distributional contamination signals. Our results show that translation into Arabic suppresses conventional contamination indicators, yet models still benefit from exposure to contaminated data, particularly those with stronger Arabic capabilities. This effect is consistently reflected in rising Mink% scores and increased cross-lingual answer consistency as contamination levels grow. To address this blind spot, we propose Translation-Aware Contamination Detection, which identifies contamination by comparing signals across multiple translated benchmark variants rather than English alone. The Translation-Aware Contamination Detection reliably exposes contamination even when English-only methods fail. Together, our findings highlight the need for multilingual, translation-aware evaluation pipelines to ensure fair, transparent, and reproducible assessment of LLMs.\nüìÑ Download PDF\nPRiSM: Benchmarking Phone Realization in Speech Models Authors: Shikhar Bharadwaj, Chin-Jou Li, Yoonjae Kim, Kwanghee Choi, Eunjung Yeo, Ryan Soh-Eun Shim, Hanyu Zhou, Brendon Boldt, Karen Rosero Jacome, Kalvin Chang, Darsh Agrawal, Keer Xu, Chao-Han Huck Yang, Jian Zhu, Shinji Watanabe, David R. Mortensen Venue: arXiv (2026)\nPhone recognition (PR) serves as the atomic interface for language-agnostic modeling for cross-lingual speech processing and phonetic analysis. Despite prolonged efforts in developing PR systems, current evaluations only measure surface-level transcription accuracy. We introduce PRiSM, the first open-source benchmark designed to expose blind spots in phonetic perception through intrinsic and extrinsic evaluation of PR systems. PRiSM standardizes transcription-based evaluation and assesses downstream utility in clinical, educational, and multilingual settings with transcription and representation probes. We find that diverse language exposure during training is key to PR performance, encoder-CTC models are the most stable, and specialized PR models still outperform Large Audio Language Models. PRiSM releases code, recipes, and datasets to move the field toward multilingual speech models with robust phonetic ability: https://github.com/changelinglab/prism.\nüìÑ Download PDF\nA Shared Geometry of Difficulty in Multilingual Language Models Authors: Stefano Civelli, Pietro Bernardelle, Nicol√≤ Brunello, Gianluca Demartini Venue: arXiv (2026)\nPredicting problem-difficulty in large language models (LLMs) refers to estimating how difficult a task is according to the model itself, typically by training linear probes on its internal representations. In this work, we study the multilingual geometry of problem-difficulty in LLMs by training linear probes using the AMC subset of the Easy2Hard benchmark, translated into 21 languages. We found that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow (early-layers) and deep (later-layers) internal representations, that exhibit functionally different behaviors. Probes trained on deep representations achieve high accuracy when evaluated on the same language but exhibit poor cross-lingual generalization. In contrast, probes trained on shallow representations generalize substantially better across languages, despite achieving lower within-language performance. Together, these results suggest that LLMs first form a language-agnostic representation of problem difficulty, which subsequently becomes language-specific. This closely aligns with existing findings in LLM interpretability showing that models tend to operate in an abstract conceptual space before producing language-specific outputs. We demonstrate that this two-stage representational process extends beyond semantic content to high-level meta-cognitive properties such as problem-difficulty estimation.\nüìÑ Download PDF\nUbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages Authors: Tassallah Abdullahi, Macton Mgonzo, Mardiyyah Oduwole, Paul Okewunmi, Abraham Owodunni, Ritambhara Singh, Carsten Eickhoff Venue: arXiv (2026)\nCurrent guardian models are predominantly Western-centric and optimized for high-resource languages, leaving low-resource African languages vulnerable to evolving harms, cross-lingual safety failures, and cultural misalignment. Moreover, most guardian models rely on rigid, predefined safety categories that fail to generalize across diverse linguistic and sociocultural contexts. Robust safety, therefore, requires flexible, runtime-enforceable policies and benchmarks that reflect local norms, harm scenarios, and cultural expectations. We introduce UbuntuGuard, the first African policy-based safety benchmark built from adversarial queries authored by 155 domain experts across sensitive fields, including healthcare. From these expert-crafted queries, we derive context-specific safety policies and reference responses that capture culturally grounded risk signals, enabling policy-aligned evaluation of guardian models. We evaluate 13 models, comprising six general-purpose LLMs and seven guardian models across three distinct variants: static, dynamic, and multilingual. Our findings reveal that existing English-centric benchmarks overestimate real-world multilingual safety, cross-lingual transfer provides partial but insufficient coverage, and dynamic models, while better equipped to leverage policies at inference time, still struggle to fully localize African-language contexts. These findings highlight the urgent need for multilingual, culturally grounded safety benchmarks to enable the development of reliable and equitable guardian models for low-resource languages. Our code can be found online.\\footnote{Code repository available at https://github.com/hemhemoh/UbuntuGuard.\nüìÑ Download PDF\nBenchmarking Concept-Spilling Across Languages in LLMs Authors: Ilia Badanin, Daniil Dzenhaliou, Imanol Schlag Venue: arXiv (2026)\nMultilingual Large Language Models (LLMs) exhibit remarkable cross-lingual abilities, yet often exhibit a systematic bias toward the representations from other languages, resulting in semantic interference when generating content in non-English languages$-$a phenomenon we define as language spilling. This paper presents a novel comparative framework for evaluating multilingual semantic robustness by systematically measuring how models handle polysemous words across languages. Our methodology provides a relative measure of model performance: when required to generate exactly five meanings, both strong and weak models may resort to meanings from dominant languages, but semantically stronger models do so later in the generation sequence, producing more true meanings from the target language before failing, while weaker models resort to dominant-language meanings earlier in the sequence. We evaluate a diverse set of open and closed multilingual LLMs using a structured meaning generation task across nine languages, employing a carefully curated benchmark of 100 high-polysemy English words. Our findings reveal significant variation in semantic robustness across both models and languages, providing a principled ranking system for model comparison without requiring definitive causal attribution of error sources. We contribute both a scalable comparative benchmark for multilingual semantic evaluation and a rigorous validation pipeline$-$critical tools for developing more linguistically balanced AI systems.\nüìÑ Download PDF\nCogToM: A Comprehensive Theory of Mind Benchmark inspired by Human Cognition for Large Language Models Authors: Haibo Tong, Zeyang Yue, Feifei Zhao, Erliang Lin, Lu Jia, Ruolin Chen, Yinqian Sun, Qian Zhang, Yi Zeng Venue: arXiv (2026)\nWhether Large Language Models (LLMs) truly possess human-like Theory of Mind (ToM) capabilities has garnered increasing attention. However, existing benchmarks remain largely restricted to narrow paradigms like false belief tasks, failing to capture the full spectrum of human cognitive mechanisms. We introduce CogToM, a comprehensive, theoretically grounded benchmark comprising over 8000 bilingual instances across 46 paradigms, validated by 49 human annotator.A systematic evaluation of 22 representative models, including frontier models like GPT-5.1 and Qwen3-Max, reveals significant performance heterogeneities and highlights persistent bottlenecks in specific dimensions. Further analysis based on human cognitive patterns suggests potential divergences between LLM and human cognitive structures. CogToM offers a robust instrument and perspective for investigating the evolving cognitive boundaries of LLMs.\nüìÑ Download PDF\nThe Dark Side of AI Transformers: Sentiment Polarization \u0026 the Loss of Business Neutrality by NLP Transformers Authors: Prasanna Kumar Venue: arXiv (2026)\nThe use of Transfer Learning \u0026 Transformers has steadily improved accuracy and has significantly contributed in solving complex computation problems. However, this transformer led accuracy improvement in Applied AI Analytics specifically in sentiment analytics comes with the dark side. It is observed during experiments that a lot of these improvements in transformer led accuracy of one class of sentiment has been at the cost of polarization of another class of sentiment and the failing of neutrality. This lack of neutrality poses an acute problem in the Applied NLP space, which relies heavily on the computational outputs of sentiment analytics for reliable industry ready tasks.\nüìÑ Download PDF\nThe GDN-CC Dataset: Automatic Corpus Clarification for AI-enhanced Democratic Citizen Consultations Authors: Pierre-Antoine Lequeu, L√©o Labat, Laur√®ne Cave, Ga√´l Lejeune, Fran√ßois Yvon, Benjamin Piwowarski Venue: arXiv (2026)\nLLMs are ubiquitous in modern NLP, and while their applicability extends to texts produced for democratic activities such as online deliberations or large-scale citizen consultations, ethical questions have been raised for their usage as analysis tools. We continue this line of research with two main goals: (a) to develop resources that can help standardize citizen contributions in public forums at the pragmatic level, and make them easier to use in topic modeling and political analysis; (b) to study how well this standardization can reliably be performed by small, open-weights LLMs, i.e. models that can be run locally and transparently with limited resources. Accordingly, we introduce Corpus Clarification as a preprocessing framework for large-scale consultation data that transforms noisy, multi-topic contributions into structured, self-contained argumentative units ready for downstream analysis. We present GDN-CC, a manually-curated dataset of 1,231 contributions to the French Grand D√©bat National, comprising 2,285 argumentative units annotated for argumentative structure and manually clarified. We then show that finetuned Small Language Models match or outperform LLMs on reproducing these annotations, and measure their usability for an opinion clustering task. We finally release GDN-CC-large, an automatically annotated corpus of 240k contributions, the largest annotated democratic consultation dataset to date.\nüìÑ Download PDF\nRECAP: Resistance Capture in Text-based Mental Health Counseling with Large Language Models Authors: Anqi Li, Yuqian Chen, Yu Lu, Zhaoming Chen, Yuan Xie, Zhenzhong Lan Venue: arXiv (2026)\nRecognizing and navigating client resistance is critical for effective mental health counseling, yet detecting such behaviors is particularly challenging in text-based interactions. Existing NLP approaches oversimplify resistance categories, ignore the sequential dynamics of therapeutic interventions, and offer limited interpretability. To address these limitations, we propose PsyFIRE, a theoretically grounded framework capturing 13 fine-grained resistance behaviors alongside collaborative interactions. Based on PsyFIRE, we construct the ClientResistance corpus with 23,930 annotated utterances from real-world Chinese text-based counseling, each supported by context-specific rationales. Leveraging this dataset, we develop RECAP, a two-stage framework that detects resistance and fine-grained resistance types with explanations. RECAP achieves 91.25% F1 for distinguishing collaboration and resistance and 66.58% macro-F1 for fine-grained resistance categories classification, outperforming leading prompt-based LLM baselines by over 20 points. Applied to a separate counseling dataset and a pilot study with 62 counselors, RECAP reveals the prevalence of resistance, its negative impact on therapeutic relationships and demonstrates its potential to improve counselors‚Äô understanding and intervention strategies.\nüìÑ Download PDF\nCURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning Authors: Eric Onyame, Akash Ghosh, Subhadip Baidya, Sriparna Saha, Xiuying Chen, Chirag Agarwal Venue: arXiv (2026)\nWhile large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/\nüìÑ Download PDF\nThink3D: Thinking with Space for Spatial Reasoning Authors: Zaibin Zhang, Yuhan Wu, Lianjie Jia, Yifan Wang, Zhongbo Zhang, Yijiang Li, Binghao Ran, Fuxi Zhang, Zhuohan Sun, Zhenfei Yin, Lijun Wang, Huchuan Lu Venue: arXiv (2026)\nUnderstanding and reasoning about the physical world requires spatial intelligence: the ability to interpret geometry, perspective, and spatial relations beyond 2D perception. While recent vision large models (VLMs) excel at visual understanding, they remain fundamentally 2D perceivers and struggle with genuine 3D reasoning. We introduce Think3D, a framework that enables VLM agents to think with 3D space. By leveraging 3D reconstruction models that recover point clouds and camera poses from images or videos, Think3D allows the agent to actively manipulate space through camera-based operations and ego/global-view switching, transforming spatial reasoning into an interactive 3D chain-of-thought process. Without additional training, Think3D significantly improves the spatial reasoning performance of advanced models such as GPT-4.1 and Gemini 2.5 Pro, yielding average gains of +7.8% on BLINK Multi-view and MindCube, and +4.7% on VSI-Bench. We further show that smaller models, which struggle with spatial exploration, benefit significantly from a reinforcement learning policy that enables the model to select informative viewpoints and operations. With RL, the benefit from tool usage increases from +0.7% to +6.8%. Our findings demonstrate that training-free, tool-augmented spatial exploration is a viable path toward more flexible and human-like 3D reasoning in multimodal agents, establishing a new dimension of multimodal intelligence. Code and weights are released at https://github.com/zhangzaibin/spagent.\nüìÑ Download PDF\nStatic Detection of Core Structures in Tigress Virtualization-Based Obfuscation Using an LLVM Pass Authors: Sangjun An, Seoksu Lee, Eun-Sun Cho Venue: arXiv (2026)\nMalware often uses obfuscation to hinder security analysis. Among these techniques, virtualization-based obfuscation is particularly strong because it protects programs by translating original instructions into attacker-defined virtual machine (VM) bytecode, producing long and complex code that is difficult to analyze and deobfuscate. This paper aims to identify the structural components of virtualization-based obfuscation through static analysis. By examining the execution model of obfuscated code, we define and detect the key elements required for deobfuscation-namely the dispatch routine, handler blocks, and the VM region-using LLVM IR. Experimental results show that, in the absence of compiler optimizations, the proposed LLVM Pass successfully detects all core structures across major virtualization options, including switch, direct, and indirect modes.\nüìÑ Download PDF\nTowards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach Authors: Shiqi Wang, Mahdi Khosravy, Neeraj Gupta, Olaf Witkowski Venue: arXiv (2026)\nUniversal adversarial perturbations (UAPs) have garnered significant attention due to their ability to undermine deep neural networks across multiple inputs using a single noise pattern. Evolutionary algorithms offer a promising approach to generating such perturbations due to their ability to navigate non-convex, gradient-free landscapes. In this work, we introduce a float-coded, penalty-driven single-objective evolutionary framework for UAP generation that achieves lower visibility perturbations while enhancing attack success rates. Our approach leverages continuous gene representations aligned with contemporary deep learning scales, incorporates dynamic evolutionary operators with adaptive scheduling, and utilizes a modular PyTorch implementation for seamless integration with modern architectures. Additionally, we ensure the universality of the generated perturbations by testing across diverse models and by periodically switching batches to prevent overfitting. Experimental results on the ImageNet dataset demonstrate that our framework consistently produces perturbations with smaller norms, higher misclassification effectiveness, and faster convergence compared to existing evolutionary-based methods. These findings highlight the robustness and scalability of our approach for universal adversarial attacks across various deep learning architectures.\nüìÑ Download PDF\nNLP-Based Review for Toxic Comment Detection Tailored to the Chinese Cyberspace Authors: Ruixing Ren, Junhui Zhao, Xiaoke Sun, Qiuping Li Venue: arXiv (2026)\nWith the in-depth integration of mobile Internet and widespread adoption of social platforms, user-generated content in the Chinese cyberspace has witnessed explosive growth. Among this content, the proliferation of toxic comments poses severe challenges to individual mental health, community atmosphere and social trust. Owing to the strong context dependence, cultural specificity and rapid evolution of Chinese cyber language, toxic expressions are often conveyed through complex forms such as homophones and metaphors, imposing notable limitations on traditional detection methods. To address this issue, this review focuses on the core topic of natural language processing based toxic comment detection in the Chinese cyberspace, systematically collating and critically analyzing the research progress and key challenges in this field. This review first defines the connotation and characteristics of Chinese toxic comments, and analyzes the platform ecology and transmission mechanisms they rely on. It then comprehensively reviews the construction methods and limitations of existing public datasets, and proposes a novel fine-grained and scalable framework for toxic comment definition and classification, along with corresponding data annotation and quality assessment strategies. We systematically summarize the evolutionary path of detection models from traditional methods to deep learning, with special emphasis on the importance of interpretability in model design. Finally, we thoroughly discuss the open challenges faced by current research and provide forward-looking suggestions for future research directions.\nüìÑ Download PDF\nVariance-Adaptive Muon: Accelerating LLM Pretraining with NSR-Modulated and Variance-Scaled Momentum Authors: Jingru Li, Yibo Fan, Huan Li Venue: arXiv (2026)\nLarge Language Models (LLMs) achieve competitive performance across diverse natural language processing (NLP) tasks, yet pretraining is computationally demanding, making optimizer efficiency an important practical consideration. Muon accelerates LLM pretraining via orthogonal momentum updates that serve as a matrix analogue of the element-wise sign operator. Motivated by the recent perspective that Adam is a variance-adaptive sign update algorithm, we propose two variants of Muon, Muon-NSR and Muon-VS, which apply variance-adaptive normalization to momentum before orthogonalization. Muon-NSR applies noise-to-signal ratio (NSR) modulation, while Muon-VS performs variance-based scaling without introducing additional hyperparameters. Experiments on GPT-2 and LLaMA pretraining demonstrate that our proposed methods accelerate convergence and consistently achieve lower validation loss than both competitive, well-tuned AdamW and Muon baselines. For example, on the LLaMA-1.2B model, Muon-NSR and Muon-VS reduce the iterations required to reach the target validation loss by $1.36\\times$ relative to the well-tuned Muon following the recent benchmark.\nüìÑ Download PDF\nPoint Bridge: 3D Representations for Cross Domain Policy Learning Authors: Siddhant Haldar, Lars Johannsmeier, Lerrel Pinto, Abhishek Gupta, Dieter Fox, Yashraj Narang, Ajay Mandlekar Venue: arXiv (2026)\nRobot foundation models are beginning to deliver on the promise of generalist robotic agents, yet progress remains constrained by the scarcity of large-scale real-world manipulation datasets. Simulation and synthetic data generation offer a scalable alternative, but their usefulness is limited by the visual domain gap between simulation and reality. In this work, we present Point Bridge, a framework that leverages unified, domain-agnostic point-based representations to unlock synthetic datasets for zero-shot sim-to-real policy transfer, without explicit visual or object-level alignment. Point Bridge combines automated point-based representation extraction via Vision-Language Models (VLMs), transformer-based policy learning, and efficient inference-time pipelines to train capable real-world manipulation agents using only synthetic data. With additional co-training on small sets of real demonstrations, Point Bridge further improves performance, substantially outperforming prior vision-based sim-and-real co-training methods. It achieves up to 44% gains in zero-shot sim-to-real transfer and up to 66% with limited real data across both single-task and multitask settings. Videos of the robot are best viewed at: https://pointbridge3d.github.io/\nüìÑ Download PDF\nPyraTok: Language-Aligned Pyramidal Tokenizer for Video Understanding and Generation Authors: Onkar Susladkar, Tushar Prakash, Adheesh Juvekar, Kiet A. Nguyen, Dong-Hwan Jang, Inderjit S Dhillon, Ismini Lourentzou Venue: arXiv (2026)\nDiscrete video VAEs underpin modern text-to-video generation and video understanding systems, yet existing tokenizers typically learn visual codebooks at a single scale with limited vocabularies and shallow language supervision, leading to poor cross-modal alignment and zero-shot transfer. We introduce PyraTok, a language-aligned pyramidal tokenizer that learns semantically structured discrete latents across multiple spatiotemporal resolutions. PyraTok builds on a pretrained video VAE and a novel Language aligned Pyramidal Quantization (LaPQ) module that discretizes encoder features at several depths using a shared large binary codebook, yielding compact yet expressive video token sequences. To tightly couple visual tokens with language, PyraTok jointly optimizes multi-scale text-guided quantization and a global autoregressive objective over the token hierarchy. Across ten benchmarks, PyraTok delivers state-of-the-art (SOTA) video reconstruction, consistently improves text-to-video quality, and sets new SOTA zero-shot performance on video segmentation, temporal action localization, and video understanding, scaling robustly to up to 4K/8K resolutions.\nüìÑ Download PDF\nIVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance Authors: Jongwoo Park, Kanchana Ranasinghe, Jinhyeok Jang, Cristina Mata, Yoo Sung Jang, Michael S Ryoo Venue: arXiv (2026)\nMany Vision-Language-Action (VLA) models flatten image patches into a 1D token sequence, weakening the 2D spatial cues needed for precise manipulation. We introduce IVRA, a lightweight, training-free method that improves spatial understanding by exploiting affinity hints already available in the model‚Äôs built-in vision encoder, without requiring any external encoder or retraining. IVRA selectively injects these affinity signals into a language-model layer in which instance-level features reside. This inference-time intervention realigns visual-token interactions and better preserves geometric structure while keeping all model parameters fixed. We demonstrate the generality of IVRA by applying it to diverse VLA architectures (LLaRA, OpenVLA, and FLOWER) across simulated benchmarks spanning both 2D and 3D manipulation (VIMA and LIBERO) and on various real-robot tasks. On 2D VIMA, IVRA improves average success by +4.2% over the baseline LLaRA in a low-data regime. On 3D LIBERO, it yields consistent gains over the OpenVLA and FLOWER baselines, including improvements when baseline accuracy is near saturation (96.3% to 97.1%). All code and models will be released publicly. Visualizations are available at: jongwoopark7978.github.io/IVRA\nüìÑ Download PDF\nLLM-in-Sandbox Elicits General Agentic Intelligence Authors: Daixuan Cheng, Shaohan Huang, Yuxian Gu, Huatong Song, Guoxin Chen, Li Dong, Wayne Xin Zhao, Ji-Rong Wen, Furu Wei Venue: arXiv (2026)\nWe introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverage the file system to handle long contexts, and execute scripts to satisfy formatting requirements. We further show that these agentic capabilities can be enhanced through LLM-in-Sandbox Reinforcement Learning (LLM-in-Sandbox-RL), which uses only non-agentic data to train models for sandbox exploration. Experiments demonstrate that LLM-in-Sandbox, in both training-free and post-trained settings, achieves robust generalization spanning mathematics, physics, chemistry, biomedicine, long-context understanding, and instruction following. Finally, we analyze LLM-in-Sandbox‚Äôs efficiency from computational and system perspectives, and open-source it as a Python package to facilitate real-world deployment.\nüìÑ Download PDF\nProvable Robustness in Multimodal Large Language Models via Feature Space Smoothing Authors: Song Xia, Meiwen Ding, Chenqi Kong, Wenhan Yang, Xudong Jiang Venue: arXiv (2026)\nMultimodal large language models (MLLMs) exhibit strong capabilities across diverse applications, yet remain vulnerable to adversarial perturbations that distort their feature representations and induce erroneous predictions. To address this vulnerability, we propose the Feature-space Smoothing (FS) and theoretically prove that FS offers certified robustness on the feature representations of MLLMs. Specifically, FS transforms any feature encoder into a smoothed variant that is guaranteed to maintain a certified lower bound on the feature cosine similarity between clean and adversarial representations under $\\ell_2$-bounded attacks. Moreover, we indicate that the value of this Feature Cosine Similarity Bound (FCSB) derived from FS can be improved by enlarging the defined Gaussian robustness score on the vanilla encoder. Building upon this, we introduce the Purifier and Smoothness Mapper (PSM), a plug-and-play module that improves the Gaussian robustness score of MLLMs and thus enhances their certified robustness under FS, without requiring any retraining on MLLMs. We demonstrate that the FS with PSM not only provides a strong theoretical robustness guarantee but also exhibits superior empirical performance compared to adversarial training. Extensive experiments across diverse MLLMs and downstream tasks indicate the effectiveness of the FS-PSM, reducing the Attack Success Rate (ASR) of various white-box attacks from nearly 90% to about 1%.\nüìÑ Download PDF\nPAL*M: Property Attestation for Large Generative Models Authors: Prach Chantasantitam, Adam Ilyas Caulfield, Vasisht Duddu, Lachlan J. Gunn, N. Asokan Venue: arXiv (2026)\nMachine learning property attestations allow provers (e.g., model providers or owners) to attest properties of their models/datasets to verifiers (e.g., regulators, customers), enabling accountability towards regulations and policies. But, current approaches do not support generative models or large datasets. We present PALM, a property attestation framework for large generative models, illustrated using large language models. PALM defines properties across training and inference, leverages confidential virtual machines with security-aware GPUs for coverage of CPU-GPU operations, and proposes using incremental multiset hashing over memory-mapped datasets to efficiently track their integrity. We implement PAL*M on Intel TDX and NVIDIA H100, showing it is efficient, scalable, versatile, and secure.\nüìÑ Download PDF\nElectron Transfer, Diabatic Couplings and Vibronic Energy Gaps in a Phase Space Framework Authors: Zain Zaidi, Xuezhi Bian, Joseph E. Subotnik Venue: arXiv (2026)\nWe investigate the well-known Shin-Metiu model for an electronic crossing, using both a standard Born-Huang (BH) framework and a novel phase space (PS) electronic Hamiltonian framework. We show that as long as we are not in the strongly nonadiabatic region, a phase space framework can obtain a relative error in vibrational energy gap which is consistently one order of magnitude smaller than what is found within a BH framework. In line with recent results showing that dynamics on one phase space surface can outperform dynamics on one Born-Oppenheimer surface, our results indicate that the same advantages should largely hold for curve crossings and dynamics on two or a handful of electronic surfaces, from which several implications can be surmised as far as the possibility of spin-dependent electron transfer dynamics.\nüìÑ Download PDF\nBeat-ssl: Capturing Local ECG Morphology through Heartbeat-level Contrastive Learning with Soft Targets Authors: Muhammad Ilham Rizqyawan, Peter Macfarlane, Stathis Hadjidemetriou, Fani Deligianni Venue: arXiv (2026)\nObtaining labelled ECG data for developing supervised models is challenging. Contrastive learning (CL) has emerged as a promising pretraining approach that enables effective transfer learning with limited labelled data. However, existing CL frameworks either focus solely on global context or fail to exploit ECG-specific characteristics. Furthermore, these methods rely on hard contrastive targets, which may not adequately capture the continuous nature of feature similarity in ECG signals. In this paper, we propose Beat-SSL, a contrastive learning framework that performs dual-context learning through both rhythm-level and heartbeat-level contrasting with soft targets. We evaluated our pretrained model on two downstream tasks: 1) multilabel classification for global rhythm assessment, and 2) ECG segmentation to assess its capacity to learn representations across both contexts. We conducted an ablation study and compared the best configuration with three other methods, including one ECG foundation model. Despite the foundation model‚Äôs broader pretraining, Beat-SSL reached 93% of its performance in multilabel classification task and surpassed all other methods in the segmentation task by 4%.\nüìÑ Download PDF\nEfficiently Learning Robust Torque-based Locomotion Through Reinforcement with Model-Based Supervision Authors: Yashuai Yan, Tobias Egle, Christian Ott, Dongheui Lee Venue: arXiv (2026)\nWe propose a control framework that integrates model-based bipedal locomotion with residual reinforcement learning (RL) to achieve robust and adaptive walking in the presence of real-world uncertainties. Our approach leverages a model-based controller, comprising a Divergent Component of Motion (DCM) trajectory planner and a whole-body controller, as a reliable base policy. To address the uncertainties of inaccurate dynamics modeling and sensor noise, we introduce a residual policy trained through RL with domain randomization. Crucially, we employ a model-based oracle policy, which has privileged access to ground-truth dynamics during training, to supervise the residual policy via a novel supervised loss. This supervision enables the policy to efficiently learn corrective behaviors that compensate for unmodeled effects without extensive reward shaping. Our method demonstrates improved robustness and generalization across a range of randomized conditions, offering a scalable solution for sim-to-real transfer in bipedal locomotion.\nüìÑ Download PDF\nDSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models Authors: Hanwen Zhang, Qiaojin Shen, Yuxi Liu, Yuesheng Zhu, Guibo Luo Venue: arXiv (2026)\nFoundation Models (FMs) have demonstrated strong generalization across diverse vision tasks. However, their deployment in federated settings is hindered by high computational demands, substantial communication overhead, and significant inference costs. We propose DSFedMed, a dual-scale federated framework that enables mutual knowledge distillation between a centralized foundation model and lightweight client models for medical image segmentation. To support knowledge distillation, a set of high-quality medical images is generated to replace real public datasets, and a learnability-guided sample selection strategy is proposed to enhance efficiency and effectiveness in dual-scale distillation. This mutual distillation enables the foundation model to transfer general knowledge to lightweight clients, while also incorporating client-specific insights to refine the foundation model. Evaluations on five medical imaging segmentation datasets show that DSFedMed achieves an average 2 percent improvement in Dice score while reducing communication costs and inference time by nearly 90 percent compared to existing federated foundation model baselines. These results demonstrate significant efficiency gains and scalability for resource-limited federated deployments.\nüìÑ Download PDF\nCamPilot: Improving Camera Control in Video Diffusion Model with Efficient Camera Reward Feedback Authors: Wenhang Ge, Guibao Shen, Jiawei Feng, Luozhou Wang, Hao Lu, Xingye Tian, Xin Tao, Ying-Cong Chen Venue: arXiv (2026)\nRecent advances in camera-controlled video diffusion models have significantly improved video-camera alignment. However, the camera controllability still remains limited. In this work, we build upon Reward Feedback Learning and aim to further improve camera controllability. However, directly borrowing existing ReFL approaches faces several challenges. First, current reward models lack the capacity to assess video-camera alignment. Second, decoding latent into RGB videos for reward computation introduces substantial computational overhead. Third, 3D geometric information is typically neglected during video decoding. To address these limitations, we introduce an efficient camera-aware 3D decoder that decodes video latent into 3D representations for reward quantization. Specifically, video latent along with the camera pose are decoded into 3D Gaussians. In this process, the camera pose not only acts as input, but also serves as a projection parameter. Misalignment between the video latent and camera pose will cause geometric distortions in the 3D structure, resulting in blurry renderings. Based on this property, we explicitly optimize pixel-level consistency between the rendered novel views and ground-truth ones as reward. To accommodate the stochastic nature, we further introduce a visibility term that selectively supervises only deterministic regions derived via geometric warping. Extensive experiments conducted on RealEstate10K and WorldScore benchmarks demonstrate the effectiveness of our proposed method. Project page: \\href{https://a-bigbao.github.io/CamPilot/}{CamPilot Page}.\nüìÑ Download PDF\nA multiwavelength ALMA view of gas and dust in binary protoplanetary system AS 205: Evidence of dust asymmetric distribution Authors: Nguyen Thi Phuong, Nguyen Tat Thang Venue: arXiv (2026)\nWe present Atacama Large Millimeter/Submillimeter Array observations of multi-wavelength dust emissions at 3.1,mm and 1.3,mm; along with molecular line emissions of CO(2‚Äì1), CO(3‚Äì2), \\mbox{$^{13}$CO(3‚Äì2)}, and C$^{18}$O(3‚Äì2) at spatial resolutions of 7‚Äì45 AU towards the protoplanetary system AS 205. The dust emissions exhibit two distinct components of AS 205 N and AS 205 S, separated by 1.3 arcsec. While gas kinematics within the dust disk regions are dominated by Keplerian rotation, the more extended gas emission displays complex morphology and kinematics strongly affected by the binary gravitational interaction in the outer regions. The stellar masses of AS 205 N and AS 205 S are estimated at $0.78\\pm0.19$,M$\\odot$ and $1.93\\pm0.86$,M$\\odot$, respectively. Azimuthal variation is observed in the spectral index distribution of both disks. In AS 205 N, the spectral index minimum in the southwest is coincident with the peaks of CO($2-1$), CO($3-2$), and $^{13}$CO($3-2$) integrated intensity and the relative position of its southern counterpart. On the other hand, the spectral index distribution in \\ass~exhibits two prominent maxima, with the one in the northeast aligning with the peak of $^{13}$CO($3-2$), and the peak in the south coinciding with local maxima in CO($2-1$) and CO($3-2$) azimuthal profiles. These results suggest a correlation between dust grain size and/or optical depth with the gas distributions. Dust-trapping along the spiral arms possibly contributes to the spectral index minima in AS 205 N; however, the observed asymmetry across both disks suggests the involvement of additional mechanisms.\nüìÑ Download PDF\n360Anything: Geometry-Free Lifting of Images and Videos to 360¬∞ Authors: Ziyi Wu, Daniel Watson, Andrea Tagliasacchi, David J. Fleet, Marcus A. Brubaker, Saurabh Saxena Venue: arXiv (2026)\nLifting perspective images and videos to 360¬∞ panoramas enables immersive 3D world generation. Existing approaches often rely on explicit geometric alignment between the perspective and the equirectangular projection (ERP) space. Yet, this requires known camera metadata, obscuring the application to in-the-wild data where such calibration is typically absent or noisy. We propose 360Anything, a geometry-free framework built upon pre-trained diffusion transformers. By treating the perspective input and the panorama target simply as token sequences, 360Anything learns the perspective-to-equirectangular mapping in a purely data-driven way, eliminating the need for camera information. Our approach achieves state-of-the-art performance on both image and video perspective-to-360¬∞ generation, outperforming prior works that use ground-truth camera information. We also trace the root cause of the seam artifacts at ERP boundaries to zero-padding in the VAE encoder, and introduce Circular Latent Encoding to facilitate seamless generation. Finally, we show competitive results in zero-shot camera FoV and orientation estimation benchmarks, demonstrating 360Anything‚Äôs deep geometric understanding and broader utility in computer vision tasks. Additional results are available at https://360anything.github.io/.\nüìÑ Download PDF\nA general spectral solver for the axisymmetric Jeans equations: fast galaxy modelling with arbitrary anisotropy Authors: Michele Cappellari Venue: arXiv (2026)\nDynamical modelling is a fundamental tool for measuring galaxy masses and density profiles in the era of large integral-field spectroscopic surveys and Bayesian inference. Solutions based on the Jeans equations are popular due to their robustness and computational efficiency. However, traditional semi-analytic Jeans solvers often require restrictive assumptions about the velocity anisotropy to remain computationally tractable. This paper presents a new spectral solver for the axisymmetric Jeans equations designed to overcome these limitations. I first illustrate, using orbit integrations in realistic potentials, that spherical alignment of the velocity ellipsoid is a physically well-motivated approximation for galaxy modelling. The new method employs a spectral technique to solve the Jeans partial differential equations directly. Two design choices are critical for accuracy and speed: (i) solving for the slowly-varying velocity dispersion rather than the rapidly varying pressure, and (ii) imposing a Robin boundary condition to enforce the asymptotic decay on a finite domain. This formulation supports arbitrary anisotropy distributions beta(r, theta) while simultaneously increasing computational speed by orders of magnitude compared to standard high-accuracy quadratures. Validated against exact analytic benchmarks, the solver recovers intrinsic moments with sub-percent accuracy. The implementation will be included in the public JamPy package and is structured to be optimally suited for massive parallelization on specialized hardware such as GPUs, enabling the rigorous exploration of complex parameter spaces.\nüìÑ Download PDF\nHVD: Human Vision-Driven Video Representation Learning for Text-Video Retrieval Authors: Zequn Xie, Xin Liu, Boyun Zhang, Yuxiao Lin, Sihang Cai, Tao Jin Venue: arXiv (2026)\nThe success of CLIP has driven substantial progress in text-video retrieval. However, current methods often suffer from ‚Äúblind‚Äù feature interaction, where the model struggles to discern key visual information from background noise due to the sparsity of textual queries. To bridge this gap, we draw inspiration from human cognitive behavior and propose the Human Vision-Driven (HVD) model. Our framework establishes a coarse-to-fine alignment mechanism comprising two key components: the Frame Features Selection Module (FFSM) and the Patch Features Compression Module (PFCM). FFSM mimics the human macro-perception ability by selecting key frames to eliminate temporal redundancy. Subsequently, PFCM simulates micro-perception by aggregating patch features into salient visual entities through an advanced attention mechanism, enabling precise entity-level matching. Extensive experiments on five benchmarks demonstrate that HVD not only captures human-like visual focus but also achieves state-of-the-art performance.\nüìÑ Download PDF\nRethinking Composed Image Retrieval Evaluation: A Fine-Grained Benchmark from Image Editing Authors: Tingyu Song, Yanzhao Zhang, Mingxin Li, Zhuoning Guo, Dingkun Long, Pengjun Xie, Siyue Zhang, Yilun Zhao, Shu Wu Venue: arXiv (2026)\nComposed Image Retrieval (CIR) is a pivotal and complex task in multimodal understanding. Current CIR benchmarks typically feature limited query categories and fail to capture the diverse requirements of real-world scenarios. To bridge this evaluation gap, we leverage image editing to achieve precise control over modification types and content, enabling a pipeline for synthesizing queries across a broad spectrum of categories. Using this pipeline, we construct EDIR, a novel fine-grained CIR benchmark. EDIR encompasses 5,000 high-quality queries structured across five main categories and fifteen subcategories. Our comprehensive evaluation of 13 multimodal embedding models reveals a significant capability gap; even state-of-the-art models (e.g., RzenEmbed and GME) struggle to perform consistently across all subcategories, highlighting the rigorous nature of our benchmark. Through comparative analysis, we further uncover inherent limitations in existing benchmarks, such as modality biases and insufficient categorical coverage. Furthermore, an in-domain training experiment demonstrates the feasibility of our benchmark. This experiment clarifies the task challenges by distinguishing between categories that are solvable with targeted data and those that expose intrinsic limitations of current model architectures.\nüìÑ Download PDF\nMultimodal Climate Disinformation Detection: Integrating Vision-Language Models with External Knowledge Sources Authors: Marzieh Adeli Shamsabad, Hamed Ghodrati Venue: arXiv (2026)\nClimate disinformation has become a major challenge in today digital world, especially with the rise of misleading images and videos shared widely on social media. These false claims are often convincing and difficult to detect, which can delay actions on climate change. While vision-language models (VLMs) have been used to identify visual disinformation, they rely only on the knowledge available at the time of training. This limits their ability to reason about recent events or updates. The main goal of this paper is to overcome that limitation by combining VLMs with external knowledge. By retrieving up-to-date information such as reverse image results, online fact-checks, and trusted expert content, the system can better assess whether an image and its claim are accurate, misleading, false, or unverifiable. This approach improves the model ability to handle real-world climate disinformation and supports efforts to protect public understanding of science in a rapidly changing information landscape.\nüìÑ Download PDF\nGrounding Large Language Models in Reaction Knowledge Graphs for Synthesis Retrieval Authors: Olga Bunkova, Lorenzo Di Fruscia, Sophia Rupprecht, Artur M. Schweidtmann, Marcel J. T. Reinders, Jana M. Weber Venue: arXiv (2026)\nLarge Language Models (LLMs) can aid synthesis planning in chemistry, but standard prompting methods often yield hallucinated or outdated suggestions. We study LLM interactions with a reaction knowledge graph by casting reaction path retrieval as a Text2Cypher (natural language to graph query) generation problem, and define single- and multi-step retrieval tasks. We compare zero-shot prompting to one-shot variants using static, random, and embedding-based exemplar selection, and assess a checklist-driven validator/corrector loop. To evaluate our framework, we consider query validity and retrieval accuracy. We find that one-shot prompting with aligned exemplars consistently performs best. Our checklist-style self-correction loop mainly improves executability in zero-shot settings and offers limited additional retrieval gains once a good exemplar is present. We provide a reproducible Text2Cypher evaluation setup to facilitate further work on KG-grounded LLMs for synthesis planning. Code is available at https://github.com/Intelligent-molecular-systems/KG-LLM-Synthesis-Retrieval.\nüìÑ Download PDF\nDeja Vu in Plots: Leveraging Cross-Session Evidence with Retrieval-Augmented LLMs for Live Streaming Risk Assessment Authors: Yiran Qiao, Xiang Ao, Jing Chen, Yang Liu, Qiwei Zhong, Qing He Venue: arXiv (2026)\nThe rise of live streaming has transformed online interaction, enabling massive real-time engagement but also exposing platforms to complex risks such as scams and coordinated malicious behaviors. Detecting these risks is challenging because harmful actions often accumulate gradually and recur across seemingly unrelated streams. To address this, we propose CS-VAR (Cross-Session Evidence-Aware Retrieval-Augmented Detector) for live streaming risk assessment. In CS-VAR, a lightweight, domain-specific model performs fast session-level risk inference, guided during training by a Large Language Model (LLM) that reasons over retrieved cross-session behavioral evidence and transfers its local-to-global insights to the small model. This design enables the small model to recognize recurring patterns across streams, perform structured risk assessment, and maintain efficiency for real-time deployment. Extensive offline experiments on large-scale industrial datasets, combined with online validation, demonstrate the state-of-the-art performance of CS-VAR. Furthermore, CS-VAR provides interpretable, localized signals that effectively empower real-world moderation for live streaming.\nüìÑ Download PDF\nMecellem Models: Turkish Models Trained from Scratch and Continually Pre-trained for the Legal Domain Authors: √ñzg√ºr Uƒüur, Mahmut G√∂ksu, Mahmut √áimen, Musa Yƒ±lmaz, Esra ≈ûavirdi, Alp Talha Demir, Rumeysa G√ºll√ºce, ƒ∞clal √áetin, √ñmer Can Saƒüba≈ü Venue: arXiv (2026)\nThis paper presents Mecellem models, a framework for developing specialized language models for the Turkish legal domain through domain adaptation strategies. We make two contributions: (1)Encoder Model Pre-trained from Scratch: ModernBERT-based bidirectional encoders pre-trained on a Turkish-dominant corpus of 112.7 billion tokens. We implement a checkpoint selection strategy that evaluates downstream retrieval performance throughout training, revealing that optimal checkpoints achieve best retrieval scores before pre-training loss reaches its minimum. Our encoder models achieve top-3 rankings on the Turkish retrieval leaderboard, with smaller models (155M parameters) achieving comparable performance to larger reference models (307M-567M parameters). Our approach achieves 92.36% production efficiency compared to state-of-the-art models (embeddinggemma-300m: 100.00%, BAAI/bge-m3: 99.54%, newmindai/bge-m3-stsb: 94.38%), ranking fourth overall despite requiring less computational resources. SOTA models rely on multi-stage, computationally intensive training pipelines, making our single-stage pre-training followed by efficient post-training approach a cost-effective alternative; (2)Decoder Model with Continual Pre-training (CPT): Qwen3-1.7B and Qwen3-4B models adapted to Turkish legal domain through controlled curriculum learning. Four-phase CPT with optimal sample ratios enables gradual transition from general language knowledge to specialized legal terminology and long-context reasoning. This approach achieves 36.2% perplexity reduction on Turkish legal text, demonstrating domain adaptation gains.\nüìÑ Download PDF\nüîç linguistics Gauge Theory and Skein Modules Authors: Du Pei Venue: arXiv (2026)\nWe study skein modules of 3-manifolds by embedding them into the Hilbert spaces of 4d ${\\cal N}=4$ super-Yang-Mills theories. When the 3-manifold has reduced holonomy, we present an algorithm to determine the dimension and the list of generators of the skein module with a general gauge group. The analysis uses a deformation preserving ${\\cal N}=1$ supersymmetry to express the dimension as a sum over nilpotent orbits. We find that the dimensions often differ between Langlands-dual pairs beyond the A-series, for which we provide a physical explanation involving chiral symmetry breaking and ‚Äôt Hooft operators. We also relate our results to the structure of $\\mathbb{C}^*$-fixed loci in the moduli space of Higgs bundles. This approach helps to clarify the relation between the gauge-theoretic framework of Kapustin and Witten with other versions of the geometric Langlands program, explains why the dimensions of skein modules do not exhibit a TQFT-like behavior, and provides a physical interpretation of the skein-valued curve counting of Ekholm and Shende.\nüìÑ Download PDF\nWhy Can‚Äôt I Open My Drawer? Mitigating Object-Driven Shortcuts in Zero-Shot Compositional Action Recognition Authors: Geo Ahn, Inwoong Lee, Taeoh Kim, Minho Shim, Dongyoon Wee, Jinwoo Choi Venue: arXiv (2026)\nWe study Compositional Video Understanding (CVU), where models must recognize verbs and objects and compose them to generalize to unseen combinations. We find that existing Zero-Shot Compositional Action Recognition (ZS-CAR) models fail primarily due to an overlooked failure mode: object-driven verb shortcuts. Through systematic analysis, we show that this behavior arises from two intertwined factors: severe sparsity and skewness of compositional supervision, and the asymmetric learning difficulty between verbs and objects. As training progresses, the existing ZS-CAR model increasingly ignores visual evidence and overfits to co-occurrence statistics. Consequently, the existing model does not gain the benefit of compositional recognition in unseen verb-object compositions. To address this, we propose RCORE, a simple and effective framework that enforces temporally grounded verb learning. RCORE introduces (i) a composition-aware augmentation that diversifies verb-object combinations without corrupting motion cues, and (ii) a temporal order regularization loss that penalizes shortcut behaviors by explicitly modeling temporal structure. Across two benchmarks, Sth-com and our newly constructed EK100-com, RCORE significantly improves unseen composition accuracy, reduces reliance on co-occurrence bias, and achieves consistently positive compositional gaps. Our findings reveal object-driven shortcuts as a critical limiting factor in ZS-CAR and demonstrate that addressing them is essential for robust compositional video understanding.\nüìÑ Download PDF\nScaling Text-to-Image Diffusion Transformers with Representation Autoencoders Authors: Shengbang Tong, Boyang Zheng, Ziteng Wang, Bingda Tang, Nanye Ma, Ellis Brown, Jihan Yang, Rob Fergus, Yann LeCun, Saining Xie Venue: arXiv (2026)\nRepresentation Autoencoders (RAEs) have shown distinct advantages in diffusion modeling on ImageNet by training in high-dimensional semantic latent spaces. In this work, we investigate whether this framework can scale to large-scale, freeform text-to-image (T2I) generation. We first scale RAE decoders on the frozen representation encoder (SigLIP-2) beyond ImageNet by training on web, synthetic, and text-rendering data, finding that while scale improves general fidelity, targeted data composition is essential for specific domains like text. We then rigorously stress-test the RAE design choices originally proposed for ImageNet. Our analysis reveals that scaling simplifies the framework: while dimension-dependent noise scheduling remains critical, architectural complexities such as wide diffusion heads and noise-augmented decoding offer negligible benefits at scale Building on this simplified framework, we conduct a controlled comparison of RAE against the state-of-the-art FLUX VAE across diffusion transformer scales from 0.5B to 9.8B parameters. RAEs consistently outperform VAEs during pretraining across all model scales. Further, during finetuning on high-quality datasets, VAE-based models catastrophically overfit after 64 epochs, while RAE models remain stable through 256 epochs and achieve consistently better performance. Across all experiments, RAE-based diffusion models demonstrate faster convergence and better generation quality, establishing RAEs as a simpler and stronger foundation than VAEs for large-scale T2I generation. Additionally, because both visual understanding and generation can operate in a shared representation space, the multimodal model can directly reason over generated latents, opening new possibilities for unified models.\nüìÑ Download PDF\nHigh-resolution neutron diffraction determination of noncollinear antiferromagnetic order in the honeycomb magnetoelectric Fe${4}$Nb${2}$O$_{9}$ Authors: Raktim Datta, Kapil Kumar, Dong Gun Oh, Dongwook Kim, Rahul Goel, Nara Lee, Ara Go, Young Jai Choi, Valery Kiryukhin, Sungkyun Choi Venue: arXiv (2026)\nMagnetoelectric systems offer potential for device applications exploiting coupled states between electric and magnetic properties. Among magnetoelectric materials, \\FNO has attracted special attention because of its pronounced dielectric signal at high magnetic transition temperatures. However, the magnetic ground state, which is essential information for understanding its unusual magnetoelectricity, remains unclarified. Here, we report a noncollinear magnetic ground state of Fe${4}$Nb${2}$O$_{9}$. To examine the magnetoelectric effect associated with sequential magnetic and structural transitions upon cooling, we conducted combined x-ray diffraction, magnetic susceptibility, magnetization, dielectric constant, and magnetodielectric experiments. Powder neutron diffraction experiments revealed a series of magnetic Bragg peaks and clear splitting of peaks via structural transition. Magnetic Rietveld refinements, combined with group theory analysis, determined a noncollinear antiferromagnetic structure including a significant $c$-axis moment component at 1.5 K. This study provides insights into the understanding of its magnetoelectric properties.\nüìÑ Download PDF\nOn the Missing Red Giants near the Galactic Center Authors: Taeho Kim, Jeremy Goodman Venue: arXiv (2026)\nThere is a long-acknowledged deficiency of bright red giants relative to fainter old stars within a few arc seconds of Sgr A*. We explore whether this could be due to tidal stripping by the central black hole. This requires putting the stars onto highly eccentric orbits, for which we evaluate diffusion by both scalar resonant and non-resonant relaxation of the orbital angular momentum. We conclude that tidal stripping does not discriminate sufficiently between main-sequence and red giant stars. While the tidal loss cone increases with stellar radius, the rate of diffusion into the loss cone increases only logarithmically, whereas the lifetime on the red giant branch decreases more rapidly than $R_*^{-1}$. In agreement with previous studies, we find that stellar collisions are a more likely explanation for the deficiency of bright red giants relative to fainter ones.\nüìÑ Download PDF\nPhysical and Dielectric Properties of Polycrystalline LaV${0.5}$Nb${0.5}$O$_4$ Authors: Ashok Kumar, Simranjot K. Sapra, Ramcharan Meena, Vinod Singh, Anita Dhaka, Rajendra S. Dhaka Venue: arXiv (2026)\nWe report a detailed investigation of the structural, electronic, vibrational, and dielectric properties of polycrystalline LaV${0.5}$Nb${0.5}$O$4$ samples, prepared at two sintering temperatures (1000\\degree C and 1250\\degree C). The introduction of Nb$^{5+}$ at the V$^{5+}$ site leads to notable structural and vibrational changes, which can be attributed to their isoelectronic nature and the comparatively larger ionic radius of Nb$^{5+}$. The Rietveld refinement of the X-ray diffraction patterns confirms a coexistence of monoclinic ($P$2${1}$/$n$) and scheelite-type tetragonal ($I$4${1}$/$a$) phases; for example, with a fraction of 4% and 96% for the sample annealed at 1250\\degree C. The particle morphology has altered from spherical (1000\\degree C) to irregular-shaped (1250\\degree C) as a result of increase in annealing temperature. The Raman spectroscopy, Fourier Transform Infrared spectroscopy and X-ray Photoemission Spectroscopy have been used to understand the vibrational and electronic properties. An optical band gap of 2.7~eV for the sample sintered at 1250\\degree C is calculated using Ultraviolet-vis diffuse reflectance spectroscopy measurements. The dielectric studies shows the higher dielectric permittivity ($Œµ$${r}$) and lower dielectric loss for the sample annealed at 1250\\degree C.\nüìÑ Download PDF\nUnveiling the Spectral Morphological Division of Fast Radio Bursts with CHIME/FRB Catalog 2 Authors: Wan-Peng Sun, Yin-Long Cao, Yong-Kun Zhang, Ji-Guo Zhang, Xiaohui Liu, Yichao Li, Fu-Wen Zhang, Wan-Ting Hou, Jing-Fei Zhang, Xin Zhang Venue: arXiv (2026)\nFast radio bursts (FRBs) are commonly divided into repeating and apparently non-repeating sources, but whether these represent distinct physical populations remains uncertain. In this work, we apply an unsupervised machine learning methods combining Uniform Manifold Approximation and Projection (UMAP) with density-based clustering to analyze CHIME/FRB Catalog 2. We find that FRBs remain primarily separated into two clusters in the multi-dimensional parameter space, with a recall of 0.94 for known repeaters, indicating strong robustness. Consistent with Catalog 1 analyses, we confirm that the spectral morphology parameter, specifically spectral running remains the key discriminator between the two populations, indicating that narrowband emission is an intrinsic and persistent property of repeating FRBs. With the enlarged Catalog 2 sample, we further identify a stable subclass of atypical repeaters (about $6%$ of repeating bursts) that are broadband, shorter in duration, and more luminous, resembling non-repeating bursts. The Nonrepeater-like cluster also shows higher inferred energies and dispersion measures, consistent with a scenario in which apparently non-repeating FRBs may result from observational incompleteness, with low-energy repeating bursts remaining undetected. Our results provide new statistical evidence for a physical connection between repeating and non-repeating FRBs.\nüìÑ Download PDF\nPAINT: Pathology-Aware Integrated Next-Scale Transformation for Virtual Immunohistochemistry Authors: Rongze Ma, Mengkang Lu, Zhenyu Xiang, Yongsheng Pan, Yicheng Wu, Qingjie Zeng, Yong Xia Venue: arXiv (2026)\nVirtual immunohistochemistry (IHC) aims to computationally synthesize molecular staining patterns from routine Hematoxylin and Eosin (H\u0026E) images, offering a cost-effective and tissue-efficient alternative to traditional physical staining. However, this task is particularly challenging: H\u0026E morphology provides ambiguous cues about protein expression, and similar tissue structures may correspond to distinct molecular states. Most existing methods focus on direct appearance synthesis to implicitly achieve cross-modal generation, often resulting in semantic inconsistencies due to insufficient structural priors. In this paper, we propose Pathology-Aware Integrated Next-Scale Transformation (PAINT), a visual autoregressive framework that reformulates the synthesis process as a structure-first conditional generation task. Unlike direct image translation, PAINT enforces a causal order by resolving molecular details conditioned on a global structural layout. Central to this approach is the introduction of a Spatial Structural Start Map (3S-Map), which grounds the autoregressive initialization in observed morphology, ensuring deterministic, spatially aligned synthesis. Experiments on the IHC4BC and MIST datasets demonstrate that PAINT outperforms state-of-the-art methods in structural fidelity and clinical downstream tasks, validating the potential of structure-guided autoregressive modeling.\nüìÑ Download PDF\nCounterfactual Training: Teaching Models Plausible and Actionable Explanations Authors: Patrick Altmeyer, Aleksander Buszydlik, Arie van Deursen, Cynthia C. S. Liem Venue: arXiv (2026)\nWe propose a novel training regime termed counterfactual training that leverages counterfactual explanations to increase the explanatory capacity of models. Counterfactual explanations have emerged as a popular post-hoc explanation method for opaque machine learning models: they inform how factual inputs would need to change in order for a model to produce some desired output. To be useful in real-world decision-making systems, counterfactuals should be plausible with respect to the underlying data and actionable with respect to the feature mutability constraints. Much existing research has therefore focused on developing post-hoc methods to generate counterfactuals that meet these desiderata. In this work, we instead hold models directly accountable for the desired end goal: counterfactual training employs counterfactuals during the training phase to minimize the divergence between learned representations and plausible, actionable explanations. We demonstrate empirically and theoretically that our proposed method facilitates training models that deliver inherently desirable counterfactual explanations and additionally exhibit improved adversarial robustness.\nüìÑ Download PDF\nA Rolling-Space Branch-and-Price Algorithm for the Multi-Compartment Vehicle Routing Problem with Multiple Time Windows Authors: El Mehdi Er Raqabi, Kevin Dalmeijer, Pascal Van Hentenryck Venue: arXiv (2026)\nThis paper investigates the multi-compartment vehicle routing problem with multiple time windows (MCVRPMTW), an extension of the classical vehicle routing problem with time windows that considers vehicles equipped with multiple compartments and customers requiring service across several delivery time windows. The problem incorporates three key compartment-related features: (i) compartment flexibility in the number of compartments, (ii) item-to-compartment compatibility, and (iii) item-to-item compatibility. The problem also accommodates practical operational requirements such as driver breaks. To solve the MCVRPMTW, we develop an exact branch-and-price (B\u0026P) algorithm in which the pricing problem is solved using a labeling algorithm. Several acceleration strategies are introduced to limit symmetry during label extensions, improve the stability of dual solutions in column generation, and enhance the branching process. To handle large-scale instances, we propose a rolling-space B\u0026P algorithm that integrates clustering techniques into the solution framework. Extensive computational experiments on instances inspired by a real-world industrial application demonstrate the effectiveness of the proposed approach and provide useful managerial insights for practical implementation.\nüìÑ Download PDF\nMagnon equilibrium spin current in collinear antiferromagnets Authors: Vladimir A. Zyuzin Venue: arXiv (2026)\nWe theoretically predict that Dzyaloshinskii-Moriya interaction can induce magnon equilibrium spin current in collinear antiferromagnets. Such a current, being a response to the effective magnon vector potential, can be considered as magnon analog of the superconducting supercurrent or the persistent current. Large amplitude of the predicted effect may compensate for the smallness of the Dzyaloshinskii-Moriya interaction, making the equilibrium spin currents to be experimentally observed. We suggest that external electric field can play the role of effective flux magnons interact with and propose an experiment based on the interference of magnons in the ring geometry as a verification of the concept.\nüìÑ Download PDF\nOn the structural properties of Lie algebras via associated labeled directed graphs Authors: Tim Heib, David Edward Bruschi Venue: arXiv (2026)\nWe present a method for associating labeled directed graphs to finite-dimensional Lie algebras, thereby enabling rapid identification of key structural algebraic features. To formalize this approach, we introduce the concept of graph-admissible Lie algebras and analyze properties of valid graphs given the antisymmetry property of the Lie bracket as well as the Jacobi identity. Based on these foundations, we develop graph-theoretic criteria for solvability, nilpotency, presence of ideals, simplicity, semisimplicity, and reductiveness of an algebra. Practical algorithms are provided for constructing such graphs and those associated with the lower central series and derived series via an iterative pruning procedure. This visual framework allows for an intuitive understanding of Lie algebraic structures that goes beyond purely visual advantages, since it enables a simpler and swifter grasping of the algebras of interest beyond computational-heavy approaches. Examples, which include the Schr√∂dinger and Lorentz algebra, illustrate the applicability of these tools to physically relevant cases. We further explore applications in physics, where the method facilitates computation of similtude relations essential for determining quantum mechanical time evolution via the Lie algebraic factorization method. Extensions to graded Lie algebras and related conjectures are discussed. Our approach bridges algebraic and combinatorial perspectives, offering both theoretical insights and computational tools into this area of mathematical physics.\nüìÑ Download PDF\nDomain-Incremental Continual Learning for Robust and Efficient Keyword Spotting in Resource Constrained Systems Authors: Prakash Dhungana, Sayed Ahmad Salehi Venue: arXiv (2026)\nKeyword Spotting (KWS) systems with small footprint models deployed on edge devices face significant accuracy and robustness challenges due to domain shifts caused by varying noise and recording conditions. To address this, we propose a comprehensive framework for continual learning designed to adapt to new domains while maintaining computational efficiency. The proposed pipeline integrates a dual-input Convolutional Neural Network, utilizing both Mel Frequency Cepstral Coefficients (MFCC) and Mel-spectrogram features, supported by a multi-stage denoising process, involving discrete wavelet transform and spectral subtraction techniques, plus model and prototype update blocks. Unlike prior methods that restrict updates to specific layers, our approach updates the complete quantized model, made possible due to compact model architecture. A subset of input samples are selected during runtime using class prototypes and confidence-driven filtering, which are then pseudo-labeled and combined with rehearsal buffer for incremental model retraining. Experimental results on noisy test dataset demonstrate the framework‚Äôs effectiveness, achieving 99.63% accuracy on clean data and maintaining robust performance (exceeding 94% accuracy) across diverse noisy environments, even at -10 dB Signal-to-Noise Ratio. The proposed framework work confirms that integrating efficient denoising with prototype-based continual learning enables KWS models to operate autonomously and robustly in resource-constrained, dynamic environments.\nüìÑ Download PDF\nSAMTok: Representing Any Mask with Two Words Authors: Yikang Zhou, Tao Zhang, Dengxian Gong, Yuanzheng Wu, Ye Tian, Haochen Wang, Haobo Yuan, Jiacong Wang, Lu Qi, Hao Fei, Anran Wang, Zhuochen Wang, Yujing Wang, Cheng Chen, Shunping Ji, Xiangtai Li Venue: arXiv (2026)\nPixel-wise capabilities are essential for building interactive intelligent systems. However, pixel-wise multi-modal LLMs (MLLMs) remain difficult to scale due to complex region-level encoders, specialized segmentation decoders, and incompatible training objectives. To address these challenges, we present SAMTok, a discrete mask tokenizer that converts any region mask into two special tokens and reconstructs the mask using these tokens with high fidelity. By treating masks as new language tokens, SAMTok enables base MLLMs (such as the QwenVL series) to learn pixel-wise capabilities through standard next-token prediction and simple reinforcement learning, without architectural modifications and specialized loss design. SAMTok builds on SAM2 and is trained on 209M diverse masks using a mask encoder and residual vector quantizer to produce discrete, compact, and information-rich tokens. With 5M SAMTok-formatted mask understanding and generation data samples, QwenVL-SAMTok attains state-of-the-art or comparable results on region captioning, region VQA, grounded conversation, referring segmentation, scene graph parsing, and multi-round interactive segmentation. We further introduce a textual answer-matching reward that enables efficient reinforcement learning for mask generation, delivering substantial improvements on GRES and GCG benchmarks. Our results demonstrate a scalable and straightforward paradigm for equipping MLLMs with strong pixel-wise capabilities. Our code and models are available.\nüìÑ Download PDF\nMolecularIQ: Characterizing Chemical Reasoning Capabilities Through Symbolic Verification on Molecular Graphs Authors: Christoph Bartmann, Johannes Schimunek, Mykyta Ielanskyi, Philipp Seidl, G√ºnter Klambauer, Sohvi Luukkonen Venue: arXiv (2026)\nA molecule‚Äôs properties are fundamentally determined by its composition and structure encoded in its molecular graph. Thus, reasoning about molecular properties requires the ability to parse and understand the molecular graph. Large Language Models (LLMs) are increasingly applied to chemistry, tackling tasks such as molecular name conversion, captioning, text-guided generation, and property or reaction prediction. Most existing benchmarks emphasize general chemical knowledge, rely on literature or surrogate labels that risk leakage or bias, or reduce evaluation to multiple-choice questions. We introduce MolecularIQ, a molecular structure reasoning benchmark focused exclusively on symbolically verifiable tasks. MolecularIQ enables fine-grained evaluation of reasoning over molecular graphs and reveals capability patterns that localize model failures to specific tasks and molecular structures. This provides actionable insights into the strengths and limitations of current chemistry LLMs and guides the development of models that reason faithfully over molecular structure.\nüìÑ Download PDF\nInterpreting Multimodal Communication at Scale in Short-Form Video: Visual, Audio, and Textual Mental Health Discourse on TikTok Authors: Mingyue Zha, Ho-Chun Herbert Chang Venue: arXiv (2026)\nShort-form video platforms integrate text, visuals, and audio into complex communicative acts, yet existing research analyzes these modalities in isolation, lacking scalable frameworks to interpret their joint contributions. This study introduces a pipeline combining automated multimodal feature extraction with Shapley value-based interpretability to analyze how text, visuals, and audio jointly influence engagement. Applying this framework to 162,965 TikTok videos and 814,825 images about social anxiety disorder (SAD), we find that facial expressions outperform textual sentiment in predicting viewership, informational content drives more attention than emotional support, and cross-modal synergies exhibit threshold-dependent effects. These findings demonstrate how multimodal analysis reveals interaction patterns invisible to single-modality approaches. Methodologically, we contribute a reproducible framework for interpretable multimodal research applicable across domains; substantively, we advance understanding of mental health communication in algorithmically mediated environments.\nüìÑ Download PDF\nLarge-Scale Multidimensional Knowledge Profiling of Scientific Literature Authors: Zhucun Xue, Jiangning Zhang, Juntao Jiang, Jinzhuo Liu, Haoyang He, Teng Hu, Xiaobin Hu, Guangming Yao, Yi Yuan, Yong Liu Venue: arXiv (2026)\nThe rapid expansion of research across machine learning, vision, and language has produced a volume of publications that is increasingly difficult to synthesize. Traditional bibliometric tools rely mainly on metadata and offer limited visibility into the semantic content of papers, making it hard to track how research themes evolve over time or how different areas influence one another. To obtain a clearer picture of recent developments, we compile a unified corpus of more than 100,000 papers from 22 major conferences between 2020 and 2025 and construct a multidimensional profiling pipeline to organize and analyze their textual content. By combining topic clustering, LLM-assisted parsing, and structured retrieval, we derive a comprehensive representation of research activity that supports the study of topic lifecycles, methodological transitions, dataset and model usage patterns, and institutional research directions. Our analysis highlights several notable shifts, including the growth of safety, multimodal reasoning, and agent-oriented studies, as well as the gradual stabilization of areas such as neural machine translation and graph-based methods. These findings provide an evidence-based view of how AI research is evolving and offer a resource for understanding broader trends and identifying emerging directions. Code and dataset: https://github.com/xzc-zju/Profiling_Scientific_Literature\nüìÑ Download PDF\nDeLog: An Efficient Log Compression Framework with Pattern Signature Synthesis Authors: Siyu Yu, Yifan Wu, Junjielong Xu, Ying Fu, Ning Wang, Maoyin Liu, Pancheng Jiang, Xiang Zhang, Tong Jia, Pinjia He, Ying Li Venue: arXiv (2026)\nParser-based log compression, which separates static templates from dynamic variables, is a promising approach to exploit the unique structure of log data. However, its performance on complex production logs is often unsatisfactory. This performance gap coincides with a known degradation in the accuracy of its core log parsing component on such data, motivating our investigation into a foundational yet unverified question: does higher parsing accuracy necessarily lead to better compression ratio? To answer this, we conduct the first empirical study quantifying this relationship and find that a higher parsing accuracy does not guarantee a better compression ratio. Instead, our findings reveal that compression ratio is dictated by achieving effective pattern-based grouping and encoding, i.e., the partitioning of tokens into low entropy, highly compressible groups. Guided by this insight, we design DeLog, a novel log compressor that implements a Pattern Signature Synthesis mechanism to achieve efficient pattern-based grouping. On 16 public and 10 production datasets, DeLog achieves state-of-the-art compression ratio and speed.\nüìÑ Download PDF\nJust aware enough: Evaluating awareness across artificial systems Authors: Nadine Meertens, Suet Lee, Ophelia Deroy Venue: arXiv (2026)\nRecent debates on artificial intelligence increasingly emphasise questions of AI consciousness and moral status, yet there remains little agreement on how such properties should be evaluated. In this paper, we argue that awareness offers a more productive and methodologically tractable alternative. We introduce a practical method for evaluating awareness across diverse systems, where awareness is understood as encompassing a system‚Äôs abilities to process, store and use information in the service of goal-directed action. Central to this approach is the claim that any evaluation aiming to capture the diversity of artificial systems must be domain-sensitive, deployable at any scale, multidimensional, and enable the prediction of task performance, while generalising to the level of abilities for the sake of comparison. Given these four desiderata, we outline a structured approach to evaluating and comparing awareness profiles across artificial systems with differing architectures, scales, and operational domains. By shifting the focus from artificial consciousness to being just aware enough, this approach aims to facilitate principled assessment, support design and oversight, and enable more constructive scientific and public discourse.\nüìÑ Download PDF\nUniversal non-Gaussian order parameter statistics in 2D superfluids Authors: Abel Beregi, En Chang, Erik Rydow, Christopher J. Foot, Shinichi Sunami Venue: arXiv (2026)\nFluctuations are an intrinsic feature of many-body systems, and their full statistical distributions reveal a wealth of information about the underlying physics. Of particular interest are non-Gaussian, extreme-value statistics that arise when nontrivial correlations and criticality dominate over the central limit theorem. Strikingly, in two-dimensional (2D) quantum fluids, such effects have been predicted to manifest in the order parameter distribution in the Berezinskii-Kosterlitz-Thouless (BKT) superfluid phase, which approaches a universal extreme-value form in the low-temperature limit. Here, we measure the order parameter statistics of 2D Bose gases across the BKT critical point using matter-wave interferometry. This allows us to confirm the predicted convergence of the observed statistics to a universal Gumbel distribution at low temperatures, to the 0.1% level of the probability density. Furthermore, the intrinsic precision of the atom interferometer allows the robust extraction of higher-moment observables such as skewness and kurtosis; in particular, we report direct measurements of the Binder cumulant which allows us to precisely identify the onset of the phase transition. Extending this approach to the investigation of non-equilibrium systems, we probe vortex unbinding dynamics following a quench across the BKT critical point and identify parameter-independent scaling behaviour of higher moments.\nüìÑ Download PDF\nStudying energy-resolved transport with wavepacket dynamics on quantum computers Authors: Melody Lee, Roland C. Farrell Venue: arXiv (2026)\nProbing energy-dependent transport in quantum simulators requires preparing states with tunable energy and small energy variance. Existing approaches often study quench dynamics of simple initial states, such as computational basis states, which are far from energy eigenstates and therefore limit the achievable energy resolution. In this work, we propose using wavepackets to probe transport properties with improved energy resolution. To demonstrate the utility of this approach, we prepare and evolve wavepackets on Quantinuum‚Äôs H2-2 quantum computer and identify an energy-dependent localization transition in the Anderson model on an 8x7 lattice‚Äìa finite-size mobility edge. We observe that a wavepacket initialized at low energy remains spatially localized under time evolution, while a high-energy wavepacket delocalizes, consistent with the presence of a mobility edge. Crucial to our experiments is an error mitigation strategy that infers the noiseless output bit string distribution using maximum-likelihood estimation. Compared to post-selection, this method removes systematic errors and reduces statistical uncertainty by up to a factor of 5. We extend our methods to the many-particle regime by developing a quantum algorithm for preparing quasiparticle wavepackets in a one-dimensional model of interacting fermions. This technique has modest quantum resource requirements, making wavepacket-based studies of transport in many-body systems a promising application for near-term quantum computers.\nüìÑ Download PDF\nThe FarView Low Frequency Radio Array on the Moon‚Äôs Far Side: Science and Array Architecture Authors: Jack O. Burns, Judd Bowman, Tzu-Ching Chang, Gregg Hallinan, Alex Hegedus, Nivedita Mahesh, Bang Nhan, Jonathan Pober, Ronald Polidan, Willow Smith, Nithyanandan Thyagarajan Venue: arXiv (2026)\nFarView is a proposed low frequency radio interferometer for deployment on the lunar far side, enabled by the Moon‚Äôs radio quiet environment. Operating over 1-50 MHz inaccessible from Earth, FarView will open a new observational window and promote discovery class science in cosmology, heliophysics, Galactic and exoplanet astrophysics. The primary science is measurement of the redshifted 21 cm signal from the Cosmic Dark Ages (z=30-100), identified by the Astro2020 Decadal Survey as a priority cosmology discovery area. FarView will deliver 3D tomographic measurements and precision power spectra of neutral hydrogen in a largely linear regime, enabling tests of inflationary initial conditions, primordial non Gaussianity, dark matter properties, neutrino masses, and early dark energy. The reference design consists of 100000 crossed dipole antennas in a dense core-halo configuration spanning 200 sq km. A compact 4 km core with 83000 dipoles maximizes sensitivity to large scale cosmological modes, while 20000 halo elements extending to 14 km provide angular resolution and calibration for foreground characterization. Sensitivity forecasts indicate a 10-sigma detection of the Dark Ages 21 cm power spectrum at z=30 over five years of half duty cycle lunar night observations. An FFT-based EPIC beamformer is identified as an efficient signal processing architecture. Beyond cosmology, FarView will enable interferometric imaging of low frequency solar radio bursts, advancing space weather studies. Additional capabilities include stellar space weather observations, Galactic cosmic ray tomography via free-free absorption, and searches for auroral radio emission from exoplanet magnetospheres, a probe of exoplanet habitability. FarView represents a flagship class opportunity to establish the Moon as a platform for foundational astrophysics while delivering unique observational capabilities.\nüìÑ Download PDF\nReanalyzing DESI DR1: 4. Percent-Level Cosmological Constraints from Combined Probes and Robust Evidence for the Normal Neutrino Mass Hierarchy Authors: Mikhail M. Ivanov, James M. Sullivan, Shi-Fan Chen, Anton Chudaykin, Mark Maus, Oliver H. E. Philcox Venue: arXiv (2026)\nWe present cosmological parameters measurements from the full combination of DESI DR1 galaxy clustering data described with large-scale structure effective field theory. By incorporating additional datasets (photometric galaxies and CMB lensing cross-correlations) and extending the bispectrum likelihood to smaller scales using a consistent one-loop theory computation, we achieve substantial gains in constraining power relative to previous analyses. Combining with the latest DESI baryon acoustic oscillation data and using cosmic microwave background (CMB) priors on the power spectrum tilt and baryon density, we obtain tight constraints on the $Œõ$CDM model, finding the Hubble constant $H_0=69.08\\pm 0.37~\\mathrm{km},\\mathrm{s}^{-1}\\mathrm{Mpc}^{-1}$, the matter density fraction $Œ©_m=0.2973\\pm 0.0050$, and the mass fluctuation amplitude $œÉ_8 = 0.815\\pm 0.016$ (or the lensing parameter $S_8\\equivœÉ_8\\sqrt{Œ©_m/0.3}=0.811\\pm 0.016$), corresponding to $0.6%$, $1.7%$, and $2%$ precision respectively. Adding the Pantheon+ supernova sample (SNe), we find a preference of $2.6œÉ$ for the $w_0w_a$ dynamical dark energy model from low-redshift data alone, which increases to $2.8œÉ$ when exchanging the SNe with Planck CMB data. Combining full-shape data with BAO, CMB, and SNe likelihoods, we improve the dark energy figure-of-merit by $18%$ and bound the sum of the neutrino masses to $M_ŒΩ\u003c0.057$ eV in $Œõ$CDM and $M_ŒΩ\u003c0.095$ eV in the $w_0w_a$ dynamical dark energy model (both at 95% CL). This represents an improvement of $25%$ over the background expansion constraints and the strongest bound on neutrino masses in $w_0w_a$CDM to date. Our results suggest that the preference for the normal ordering of neutrino mass states holds regardless of the cosmological background model, and is robust in light of tensions between cosmological datasets.\nüìÑ Download PDF\nAutomatic Classification of Arabic Literature into Historical Eras Authors: Zainab Alhathloul, Irfan Ahmad Venue: arXiv (2026)\nThe Arabic language has undergone notable transformations over time, including the emergence of new vocabulary, the obsolescence of others, and shifts in word usage. This evolution is evident in the distinction between the classical and modern Arabic eras. Although historians and linguists have partitioned Arabic literature into multiple eras, relatively little research has explored the automatic classification of Arabic texts by time period, particularly beyond the domain of poetry. This paper addresses this gap by employing neural networks and deep learning techniques to automatically classify Arabic texts into distinct eras and periods. The proposed models are evaluated using two datasets derived from two publicly available corpora, covering texts from the pre-Islamic to the modern era. The study examines class setups ranging from binary to 15-class classification and considers both predefined historical eras and custom periodizations. Results range from F1-scores of 0.83 and 0.79 on the binary-era classification task using the OpenITI and APCD datasets, respectively, to 0.20 on the 15-era classification task using OpenITI and 0.18 on the 12-era classification task using APCD.\nüìÑ Download PDF\nBiexcitons in Ruddlesden-Popper Metal Halides Probed by Nonlinear Coherent Spectroscopy Authors: Katherine A. Koch, Carlos Silva-Acu√±a, Ajay Ram Srimath Kandada Venue: arXiv (2026)\nExcitons and their correlated complexes underpin the rich photophysics of quantum-confined semiconductors. Among these, biexcitons ‚Äì bound states of two electrons and two holes ‚Äì provide a sensitive probe of Coulomb correlations, exciton-exciton interactions, and the role of the dielectric environment. In Ruddlesden-Popper metal halide materials (RPMHs), strong quantum and dielectric confinement stabilize excitons with binding energies of hundreds of meV, creating an ideal platform for multi-exciton phenomena. Conventional linear spectroscopies, such as photoluminescence and transient absorption, reveal biexciton signatures but suffer from spectral congestion and reabsorption artifacts. Two-dimensional coherent spectroscopies, particularly two-quantum (2Q) multidimensional techniques, uniquely access multi-exciton coherences and provide unambiguous estimates of biexciton binding energies. This minireview surveys the spectroscopic evidence for biexcitons in RPMHs, highlights the advantages of nonlinear multidimensional approaches, and situates biexciton physics within the broader context of excitonic materials, including GaAs quantum wells, quantum dots, and transition-metal dichalcogenides. By emphasizing the interplay of exciton-exciton annihilation, excitation-induced dephasing, and biexciton formation, we argue that multidimensional coherent spectroscopy offers the most reliable pathway to disentangle many-body interactions in quantum-well derivatives of metal-halide perovskites.\nüìÑ Download PDF\nThe Pohozaev identity for the Spectral Fractional Laplacian Authors: Itahisa Barrios-Cubas, Matteo Bonforte, Mar√≠a del Mar Gonz√°lez, Clara Torres-Latorre Venue: arXiv (2026)\nIn this paper, we prove a Pohozaev identity for the Spectral Fractional Laplacian (SFL). This identity allows us to establish non-existence results for the semilinear Dirichlet problem $(-Œî|_Œ©)^su = f(u)$ in star-shaped domains. The first such identity for non-local operators was established by Ros-Oton and Serra in 2014 for the Restricted Fractional Laplacian (RFL). However, the SFL differs fundamentally from the RFL, and the integration by parts strategy of Ros-Oton and Serra cannot be applied. Instead, we develop a novel spectral approach that exploits the underlying quadratic structure. Our main result expresses the identity as a Schur product of the classical Pohozaev quadratic form and a transition matrix that depends on the eigenvalues of the Laplacian and the fractional exponent.\nüìÑ Download PDF\nMild Solutions for Path-Dependent Parabolic PDEs with Neumann Boundary Conditions via Generalized BSDEs Authors: Luca Di Persio, Matteo Garbelli, Adrian Zalinescu Venue: arXiv (2026)\nWe study a system of Forward-Backward Stochastic Differential Equations (FBSDEs) with time-delayed generators. The forward process includes a reflection component expressed via a Stieltjes integral, while the backward process takes the form of a Generalized BSDE. We establish the connection between this FBSDE system and non-linear path-dependent PDEs with Neumann boundary conditions by deriving a representation formula.\nüìÑ Download PDF\nBeyond Predictive Uncertainty: Reliable Representation Learning with Structural Constraints Authors: Yiyao Yang Venue: arXiv (2026)\nUncertainty estimation in machine learning has traditionally focused on the prediction stage, aiming to quantify confidence in model outputs while treating learned representations as deterministic and reliable by default. In this work, we challenge this implicit assumption and argue that reliability should be regarded as a first-class property of learned representations themselves. We propose a principled framework for reliable representation learning that explicitly models representation-level uncertainty and leverages structural constraints as inductive biases to regularize the space of feasible representations. Our approach introduces uncertainty-aware regularization directly in the representation space, encouraging representations that are not only predictive but also stable, well-calibrated, and robust to noise and structural perturbations. Structural constraints, such as sparsity, relational structure, or feature-group dependencies, are incorporated to define meaningful geometry and reduce spurious variability in learned representations, without assuming fully correct or noise-free structure. Importantly, the proposed framework is independent of specific model architectures and can be integrated with a wide range of representation learning methods.\nüìÑ Download PDF\nCTL* Model Checking on Infinite Families of Finite-State Labeled Transition Systems (Technical Report) Authors: Roberto Pettinau, Christoph Matheja Venue: arXiv (2026)\nWe study model checking algorithms for infinite families of finite-state labeled transition systems against temporal properties written in CTL*. Such families arise, for example, as models of highly configurable systems or software product lines. We model families using context-free graph grammars. We then develop a state labeling algorithm that works compositionally on the grammar‚Äôs production rules with limited information about the context in which the rule is applied. The result is a graph grammar modeling the same family but with extended labels. We leverage this grammar to decide whether all, some, or (in)finitely many members of a family satisfy a given temporal property. We have implemented our algorithms and present early experiments.\nüìÑ Download PDF\nBeyond Visual Safety: Jailbreaking Multimodal Large Language Models for Harmful Image Generation via Semantic-Agnostic Inputs Authors: Mingyu Yu, Lana Liu, Zhehao Zhao, Wei Wang, Sujuan Qin Venue: arXiv (2026)\nThe rapid advancement of Multimodal Large Language Models (MLLMs) has introduced complex security challenges, particularly at the intersection of textual and visual safety. While existing schemes have explored the security vulnerabilities of MLLMs, the investigation into their visual safety boundaries remains insufficient. In this paper, we propose Beyond Visual Safety (BVS), a novel image-text pair jailbreaking framework specifically designed to probe the visual safety boundaries of MLLMs. BVS employs a ‚Äúreconstruction-then-generation‚Äù strategy, leveraging neutralized visual splicing and inductive recomposition to decouple malicious intent from raw inputs, thereby leading MLLMs to be induced into generating harmful images. Experimental results demonstrate that BVS achieves a remarkable jailbreak success rate of 98.21% against GPT-5 (12 January 2026 release). Our findings expose critical vulnerabilities in the visual safety alignment of current MLLMs.\nüìÑ Download PDF\nPRISM: Deriving the Transformer as a Signal-Denoising Operator via Maximum Coding Rate Reduction Authors: Dongchen Huang Venue: arXiv (2026)\nDeep learning models, particularly Transformers, are often criticized as ‚Äúblack boxes‚Äù and lack interpretability. We propose Prism, a white-box attention-based architecture derived from the principles of Maximizing Coding Rate Reduction ($\\text{MCR}^2$). By modeling the attention mechanism as a gradient ascent process on a distinct signal-noise manifold, we introduce two physical constraints: an overcomplete dictionary to expand the representational phase space, and an irrational frequency separation ($œÄ$-RoPE) to enforce incoherence between signal and noise subspaces. We demonstrate that these geometric inductive biases can be viewed as a physical constraint and they are sufficient to induce unsupervised functional disentanglement alone. Using TinyStories as a controlled testbed for verifying spectral dynamics, we observe that Prism spontaneously specializes its attention heads into spectrally distinct regimes: low-frequency heads capturing long-range causal dependencies (signal) and high-frequency heads handling local syntactic constraints (noise). Our results suggest that interpretability and performance are not a trade-off, but can be unified through principled geometric construction.\nüìÑ Download PDF\nTesting Deep Learning Libraries via Neurosymbolic Constraint Learning Authors: M M Abid Naziri, Shinhae Kim, Feiran Qin, Marcelo d‚ÄôAmorim, Saikat Dutta Venue: arXiv (2026)\nDeep Learning (DL) libraries (e.g., PyTorch) are popular in AI development. These libraries are complex and contain bugs. Researchers have proposed various bug-finding techniques for such libraries. Yet, there is much room for improvement. A key challenge in testing DL libraries is the lack of API specifications. Prior testing approaches often inaccurately model the input specifications of DL APIs, resulting in missed valid inputs that could reveal bugs or false alarms due to invalid inputs. To address this challenge, we develop Centaur ‚Äì the first neurosymbolic technique to test DL library APIs using dynamically learned input constraints. Centaur leverages the key idea that formal API constraints can be learned from a small number of automatically generated seed inputs, and that the learned constraints can be solved using SMT solvers to generate valid and diverse test inputs. We develop a novel grammar that represents first-order logic formulae over API parameters and expresses tensor-related properties (e.g., shape, data types) as well as relational properties between parameters. We use the grammar to guide a Large Language Model (LLM) to enumerate syntactically correct candidate rules, validated using seed inputs. Further, we develop a custom refinement strategy to prune the set of learned rules to eliminate spurious or redundant rules. We use the learned constraints to systematically generate valid and diverse inputs by integrating SMT-based solving with randomized sampling. We evaluate Centaur for testing PyTorch and TensorFlow. Our results show that Centaur‚Äôs constraints have a recall of 94.0% and a precision of 94.0% on average. In terms of coverage, Centaur covers 203, 150, and 9,608 more branches than TitanFuzz, ACETest and Pathfinder, respectively. Using Centaur, we also detect 26 new bugs in PyTorch and TensorFlow, 18 of which are confirmed.\nüìÑ Download PDF\nOn the diagonal of low bidegree hypersurfaces Authors: Morten L√ºders, Elia Fiammengo Venue: arXiv (2026)\nWe study the existence of a decomposition of the diagonal for bidegree hypersurfaces in a product of projective spaces. Using a cycle theoretic degeneration technique due to Lange, Pavic and Schreieder, we develop an inductive procedure that allows one to raise the degree and dimension starting from the quadric surface bundle of Hassett, Pirutka and Tschinkel. Furthermore, we are able to raise the dimension without raising the degree in a special case, showing that a very general $(3,2)$ complete intersection in $\\mathbb P^4\\times \\mathbb P^3$ does not admit a decomposition of the diagonal. As a corollary of these theorems, we show that in a certain range, bidegree hypersurfaces which were previously only known to be stably irrational over fields of characteristic zero by results of Moe, Nicaise and Ottem, are not retract rational over fields of characteristic different from two.\nüìÑ Download PDF\nüîç psycholinguistics Stochastic Control Barrier Functions under State Estimation: From Euclidean Space to Lie Groups Authors: Ruoyu Lin, Magnus Egerstedt Venue: arXiv (2026)\nEnsuring safety for autonomous systems under uncertainty remains challenging, particularly when safety of the true state is required despite the true state not being fully known. Control barrier functions (CBFs) have become widely adopted as safety filters. However, standard CBF formulations do not explicitly account for state estimation uncertainty and its propagation, especially for stochastic systems evolving on manifolds. In this paper, we propose a safety-critical control framework with a provable bound on the finite-time safety probability for stochastic systems under noisy state information. The proposed framework explicitly incorporates the uncertainty arising from both process and measurement noise, and synthesizes controllers that adapt to the level of uncertainty. The framework admits closed-form solutions in linear settings, and experimental results demonstrate its effectiveness on systems whose state spaces range from Euclidean space to Lie groups.\nüìÑ Download PDF\nScaling Sample-Based Quantum Diagonalization on GPU-Accelerated Systems using OpenMP Offload Authors: Robert Walkup, Juha J√§ykk√§, Igor Pasichnyk, Zachary Streeter, Kasia ≈öwirydowicz, Mikko Tukiainen, Yasuko Eckert, Luke Bertels, Daniel Claudino, Peter Groszkowski, Travis S. Humble, Constantinos Evangelinos, Javier Robledo-Moreno, William Kirby, Antonio Mezzacapo, Antonio C√≥rcoles, Seetharami Seelam Venue: arXiv (2026)\nHybrid quantum-HPC algorithms advance research by delegating complex tasks to quantum processors and using HPC systems to orchestrate workflows and complementary computations. Sample-based quantum diagonalization (SQD) is a hybrid quantum-HPC method in which information from a molecular Hamiltonian is encoded into a quantum circuit for evaluation on a quantum computer. A set of measurements on the quantum computer yields electronic configurations that are filtered on the classical computer, which also performs diagonalization on the selected subspace and identifies configurations to be carried over to the next step in an iterative process. Diagonalization is the most demanding task for the classical computer. Previous studies used the Fugaku supercomputer and a highly scalable diagonalization code designed for CPUs. In this work, we describe our efforts to enable efficient scalable and portable diagonalization on heterogeneous systems using GPUs as the main compute engines based on the previous work. GPUs provide massive on-device thread-level parallelism that is well aligned with the algorithms used for diagonalization. We focus on the computation of ground-state energies and wavefunctions using the Davidson algorithm with a selected set of electron configurations. We describe the offload strategy, code transformations, and data-movement, with examples of measurements on the Frontier supercomputer and five other GPU accelerated systems. Our measurements show that GPUs provide an outstanding performance boost of order 100x on a per-node basis. This dramatically expedites the diagonalization step-essential for extracting ground and excited state energies-bringing the classical processing time down from hours to minutes.\nüìÑ Download PDF\nEven GPT-5.2 Can‚Äôt Count to Five: The Case for Zero-Error Horizons in Trustworthy LLMs Authors: Ryoma Sato Venue: arXiv (2026)\nWe propose Zero-Error Horizon (ZEH) for trustworthy LLMs, which represents the maximum range that a model can solve without any errors. While ZEH itself is simple, we demonstrate that evaluating the ZEH of state-of-the-art LLMs yields abundant insights. For example, by evaluating the ZEH of GPT-5.2, we found that GPT-5.2 cannot even compute the parity of a short string like 11000, and GPT-5.2 cannot determine whether the parentheses in ((((()))))) are balanced. This is surprising given the excellent capabilities of GPT-5.2. The fact that LLMs make mistakes on such simple problems serves as an important lesson when applying LLMs to safety-critical domains. By applying ZEH to Qwen2.5 and conducting detailed analysis, we found that while ZEH correlates with accuracy, the detailed behaviors differ, and ZEH provides clues about the emergence of algorithmic capabilities. Finally, while computing ZEH incurs significant computational cost, we discuss how to mitigate this cost by achieving up to one order of magnitude speedup using tree structures and online softmax.\nüìÑ Download PDF\nPredictive Coding and Information Bottleneck for Hallucination Detection in Large Language Models Authors: Manish Bhatt Venue: arXiv (2026)\nHallucinations in Large Language Models (LLMs) ‚Äì generations that are plausible but factually unfaithful ‚Äì remain a critical barrier to high-stakes deployment. Current detection methods typically rely on computationally expensive external retrieval loops or opaque black-box LLM judges requiring 70B+ parameters. In this work, we introduce [Model Name], a hybrid detection framework that combines neuroscience-inspired signal design with supervised machine learning. We extract interpretable signals grounded in Predictive Coding (quantifying surprise against internal priors) and the Information Bottleneck (measuring signal retention under perturbation). Through systematic ablation, we demonstrate three key enhancements: Entity-Focused Uptake (concentrating on high-value tokens), Context Adherence (measuring grounding strength), and Falsifiability Score (detecting confident but contradictory claims). Evaluating on HaluBench (n=200, perfectly balanced), our theory-guided baseline achieves 0.8017 AUROC. BASE supervised models reach 0.8274 AUROC, while IMPROVED features boost performance to 0.8669 AUROC (4.95% gain), demonstrating consistent improvements across architectures. This competitive performance is achieved while using 75x less training data than Lynx (200 vs 15,000 samples), 1000x faster inference (5ms vs 5s), and remaining fully interpretable. Crucially, we report a negative result: the Rationalization signal fails to distinguish hallucinations, suggesting that LLMs generate coherent reasoning for false premises (‚ÄúSycophancy‚Äù). This work demonstrates that domain knowledge encoded in signal architecture provides superior data efficiency compared to scaling LLM judges, achieving strong performance with lightweight (less than 1M parameter), explainable models suitable for production deployment.\nüìÑ Download PDF\nColoring small locally sparse degenerate graphs and related problems Authors: Domagoj Bradaƒç, Jacob Fox, Raphael Steiner, Benny Sudakov, Shengtong Zhang Venue: arXiv (2026)\nThe classic upper bound on the chromatic number of $d$-degenerate graphs is $d+1$, shown to be tight by complete graphs. A natural question is whether this bound remains tight if one forbids large cliques. Classic constructions of Tutte and Zykov from the early 50s show that there exist $d$-degenerate $(d+1)$-chromatic graphs that are triangle-free, however these constructions grow rapidly with $d$. Motivated by this and addressing a problem posed by the second author at the Oberwolfach Graph Theory workshop, we prove that the minimum order $f(d)$ of a $d$-degenerate triangle-free graph of chromatic number $d+1$ satisfies $e^{Œ©(d)}\\le f(d)\\le e^{O(d^2\\log d)}.$ The lower bound follows from a novel upper bound on the chromatic number of triangle-free graphs: Every triangle-free $d$-degenerate graph $G$ on $n \\le e^{O(d)}$ vertices satisfies $$œá(G)\\le O\\left(\\frac{d}{\\log\\left(d/\\log n\\right)}\\right).$$ We extend this to a more general result about degenerate graphs with sparse neighborhoods, which has applications to many graph coloring problems: For example, we prove that every counterexample to Hadwiger‚Äôs conjecture with parameter $t$ must have a complete bipartite subgraph with one exponentially large side ($K_{a,b}$ where $a=(\\log t)^{1/2-o(1)}$ and $b=e^{t^{1-o(1)}}$) or a small and very dense subgraph (of order $\\le t$ with $t^{2-o(1)}$ edges) in some neighborhood. For the upper bound on $f(d)$ we establish a surprising connection between $f(d)$ and the on-line-chromatic number $g(n)$ of $n$-vertex triangle-free graphs. We also give an asymptotic improvement of the previous best upper bound for $g(n)$ due to Lov√°sz, Saks and Trotter from 1989. Along the way we disprove a generalization of Harris‚Äô fractional coloring conjecture to graphs of bounded clique number and raise numerous problems which open up interesting directions to explore for future research.\nüìÑ Download PDF\nInformation mechanics: conservation and exchange Authors: Takuya Isomura Venue: arXiv (2026)\nInference and learning are commonly cast in terms of optimisation, yet the fundamental constraints governing uncertainty reduction remain unclear. This work presents a first-principles framework inherent to Bayesian updating, termed information mechanics (infomechanics). Any pointwise reduction in posterior surprisal is exactly balanced by information gained from data, independently of algorithms, dynamics, or implementation. Imposing additivity, symmetry, and robustness collapses the freedom of this identity to only two independent conservation relations. One governs the global redistribution of uncertainty and recovers Shannon entropy. The other captures a complementary local geometric component, formalised as Fisher information. Together, these conserved quantities motivate a non-additive state function, the information potential $Œ¶$, which isolates structural degrees of freedom beyond entropy while remaining invariant under reparametrisation. $Œ¶$ quantifies local sharpness and ruggedness in posterior beliefs and vanishes uniquely for isotropic Gaussian distributions. In a low-temperature regime, $Œ¶$ scales logarithmically with the effective number of local optima, linking information geometry to computational complexity. This formalises an information-computation exchange, whereby information acquisition reshapes the inference landscape and reduces computational demands. By separating invariant informational constraints from inference mechanisms, this framework provides a unified, algorithm-independent foundation for inference, learning, and computation across biological and artificial systems.\nüìÑ Download PDF\nResonant Excitation Induced Vibronic Mollow Triplets Authors: Devashish Pandey, Corne Koks, Martijn Wubs, Nicolas Stenger, Jake Iles-Smith Venue: arXiv (2026)\nThe Mollow triplet is the definitive spectral signature of an optically dressed quantum emitter. We predict that for emitters coupled to localized phonons, this signature is not confined to the zero-phonon line. Under a strong resonant drive, we show that Mollow triplets are strikingly replicated on the associated phonon sidebands -a surprising result, given that phonon sidebands are typically viewed as incoherent, inelastic scattering pathways. These vibronic Mollow triplets are a direct fingerprint of dynamically generated dressed states that hybridize the emitter‚Äôs electronic, photonic, and vibrational degrees of freedom. We develop a scalable analytical formalism to model this effect in complex, multi-mode molecular systems, such as dibenzoterrylene. Our work provides the precise driving conditions for observing these novel spectral features, establishing a new signature of coherence in vibronically coupled systems.\nüìÑ Download PDF\nWhich Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment Authors: Yuming Yang, Mingyoung Lai, Wanxu Zhao, Xiaoran Fan, Zhiheng Xi, Mingqi Wu, Chiyue Huang, Jun Zhao, Haijun Lv, Jian Tong, Yunhua Zhou, Yicheng Zou, Qipeng Guo, Tao Gui, Qi Zhang, Xuanjing Huang Venue: arXiv (2026)\nLong chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model‚Äôs current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory‚Äôs average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection.\nüìÑ Download PDF\nCyclic sunspot activity during the first millennium CE as reconstructed from radiocarbon Authors: Ilya Usoskin, Sami K. Solanki, Natalie A. Krivova, Theodosis Chatzistergos Venue: arXiv (2026)\nContext. Solar activity, dominated by the 11-year cyclic evolution, has been observed directly since 1610. Before that, indirect cosmogenic proxy data are used to reconstruct it over millennia. Recently, the precision of radiocarbon measurements has improved sufficiently to allow reconstructing solar activity over millennia. Aims. The first detailed reconstruction of solar activity, represented by annual sunspot numbers, is presented for 1-969 CE. Methods. The reconstruction of sunspot numbers from D14C was performed using a physics-based method involving several steps: using a carbon-cycle box model, the 14C production rate, corrected for the geomagnetic shielding, was computed from the measured data; The open solar magnetic flux was computed using a model of the heliospheric cosmic-ray modulation; Sunspot numbers were calculated using a model of the evolution of the Sun‚Äôs magnetic field. The Markov Chain Monte Carlo approach was used to account for different sources of uncertainty. Results. Annual sunspot numbers were reconstructed for the first millennium CE. This period includes one extreme solar event of 774 CE and one Grand solar minimum of 650-730 CE. We could identify 91 solar cycles, of which 26 were well-defined, while 24 and 41 were reasonably and poorly defined, respectively. The mean cycle length was 10.6 years, but the lengths of individual cycles vary between 8 and 15 years. The existence of empirical Waldmeier‚Äôs relations remains inconclusive. No significant periodicities were found beyond the 11-year cycle. Conclusions. This work fills the gap in the solar cycle statistics between the previously reconstructed first millennium BCE and the second millennium CE, providing vital constraints for the solar dynamo and irradiance models. A consistent 3-millennium-long reconstruction of sunspot numbers, based on a composite multi-proxy cosmogenic record, is pending.\nüìÑ Download PDF\nA forward-only scheme for online learning of proposal distributions in particle filters Authors: Sylvain Procope-Mamert, Nicolas Chopin, Maud Delattre, Guillaume Kon Kam King Venue: arXiv (2026)\nWe introduce a new online approach for constructing proposal distributions in particle filters using a forward scheme. Our method progressively incorporates future observations to refine proposals. This is in contrast to backward-scheme algorithms that require access to the entire dataset, such as the iterated auxiliary particle filters (Guarniero et al., 2017, arXiv:1511.06286) and controlled sequential Monte Carlo (Heng et al., 2020, arXiv:1708.08396) which leverage all future observations through backward recursion. In comparison, our forward scheme achieves a gradual improvement of proposals that converges toward the proposal targeted by these backward methods. We show that backward approaches can be numerically unstable even in simple settings. Our forward method, however, offers significantly greater robustness with only a minor trade-off in performance, measured by the variance of the marginal likelihood estimator. Numerical experiments on both simulated and real data illustrate the enhanced stability of our forward approach.\nüìÑ Download PDF\nThe Role of Cognitive Abilities in Requirements Inspection: Comparing UML and Textual Representations Authors: Giovanna Broccia, Sira Vegas, Alessio Ferrari Venue: arXiv (2026)\nThe representation of requirements plays a critical role in the accuracy of requirements inspection. While visual representations, such as UML diagrams, are widely used alongside text-based requirements, their effectiveness in supporting inspection is still debated. Cognitive abilities, such as working memory and mental rotation skills, may also influence inspection accuracy. This study aims to evaluate whether the use of UML sequence diagrams alongside text-based requirements improves the accuracy of requirements inspection compared to text-based requirements alone and to explore whether cognitive abilities are associated with differences in performance across the two treatments (text vs text with UML support). We conducted a crossover experiment with 38 participants to assess the accuracy of requirements inspection under the two treatments in terms of issues found and justifications provided. Linear mixed-effects and generalized linear models were used to analyse the effects of treatment, period, sequence, and cognitive abilities. The results indicate a significant three-way interaction between representation type, working memory capacity, and mental rotation ability. This finding suggests that the effectiveness of UML support is not uniform across individuals: participants with high scores in both cognitive abilities experienced reduced performance when using UML for violation detection. Conversely, the same cognitive profile was associated with improved justification accuracy under UML-aided inspection, indicating that higher cognitive abilities may support deeper reasoning processes when dealing with multi-modal information, i.e., diagrams and text.\nüìÑ Download PDF\nHumanLLM: Towards Personalized Understanding and Simulation of Human Nature Authors: Yuxuan Lei, Tianfu Wang, Jianxun Lian, Zhengyu Hu, Defu Lian, Xing Xie Venue: arXiv (2026)\nMotivated by the remarkable progress of large language models (LLMs) in objective tasks like mathematics and coding, there is growing interest in their potential to simulate human behavior‚Äìa capability with profound implications for transforming social science research and customer-centric business insights. However, LLMs often lack a nuanced understanding of human cognition and behavior, limiting their effectiveness in social simulation and personalized applications. We posit that this limitation stems from a fundamental misalignment: standard LLM pretraining on vast, uncontextualized web data does not capture the continuous, situated context of an individual‚Äôs decisions, thoughts, and behaviors over time. To bridge this gap, we introduce HumanLLM, a foundation model designed for personalized understanding and simulation of individuals. We first construct the Cognitive Genome Dataset, a large-scale corpus curated from real-world user data on platforms like Reddit, Twitter, Blogger, and Amazon. Through a rigorous, multi-stage pipeline involving data filtering, synthesis, and quality control, we automatically extract over 5.5 million user logs to distill rich profiles, behaviors, and thinking patterns. We then formulate diverse learning tasks and perform supervised fine-tuning to empower the model to predict a wide range of individualized human behaviors, thoughts, and experiences. Comprehensive evaluations demonstrate that HumanLLM achieves superior performance in predicting user actions and inner thoughts, more accurately mimics user writing styles and preferences, and generates more authentic user profiles compared to base models. Furthermore, HumanLLM shows significant gains on out-of-domain social intelligence benchmarks, indicating enhanced generalization.\nüìÑ Download PDF\nResting-State Functional Connectivity Correlates of Emotional Memory Control under Cognitive load in Subclinical Anxiety Authors: Shruti Kinger, Mrinmoy Chakrabarty Venue: arXiv (2026)\nVolitional memory control supports adaptive cognition by enabling intentional Recall of goal-relevant information and Suppression of unwanted memories. While neural mechanisms underlying Recall and Suppression have been studied largely in isolation, less is known about the large-scale brain networks supporting these processes under competing cognitive demands, particularly as a function of subclinical anxiety. Here, we examined control of emotionally valenced memories during directed Recall and Suppression while 47 participants concurrently performed an independent visual working memory task. Cognitive control efficiency was quantified using the Balanced Integration Score (BIS), and seed-to-voxel resting-state functional connectivity (rsFC) was used to characterize intrinsic network organization. Dissociable rsFC profiles were associated with memory control efficiency across emotional valences and were selectively moderated by anxiety. More efficient Suppression of positive memories was linked to reduced connectivity between the anterior cingulate cortex and posterior perceptual-midline regions, as well as diminished hippocampal-frontal pole coupling. In contrast, efficient Suppression of negative memories was associated with increased connectivity between posterior parietal and lateral occipital regions. Anxiety moderated relationships between cognitive efficiency and prefrontal connectivity during Suppression of positive memories and Recall of positive and neutral memories. Direct comparisons further revealed stronger hippocampal-thalamic rsFC during Suppression relative to Recall of positive memories. Together, these findings delineate the functional brain architecture supporting volitional control of emotional memories under cognitive load and demonstrate that anxiety severity selectively shapes these network-level mechanisms across the anxiety continuum.\nüìÑ Download PDF\nAverage Unfairness in Routing Games Authors: Pan-Yang Su, Arwa Alanqary, Bryce L. Ferguson, Manxi Wu, Alexandre M. Bayen, Shankar Sastry Venue: arXiv (2026)\nWe propose average unfairness as a new measure of fairness in routing games, defined as the ratio between the average latency and the minimum latency experienced by users. This measure is a natural complement to two existing unfairness notions: loaded unfairness, which compares maximum and minimum latencies of routes with positive flow, and user equilibrium (UE) unfairness, which compares maximum latency with the latency of a Nash equilibrium. We show that the worst-case values of all three unfairness measures coincide and are characterized by a steepness parameter intrinsic to the latency function class. We show that average unfairness is always no greater than loaded unfairness, and the two measures are equal only when the flow is fully fair. Besides that, we offer a complete comparison of the three unfairness measures, which, to the best of our knowledge, is the first theoretical analysis in this direction. Finally, we study the constrained system optimum (CSO) problem, where one seeks to minimize total latency subject to an upper bound on unfairness. We prove that, for the same tolerance level, the optimal flow under an average unfairness constraint achieves lower total latency than any flow satisfying a loaded unfairness constraint. We show that such improvement is always strict in parallel-link networks and establish sufficient conditions for general networks. We further illustrate the latter with numerical examples. Our results provide theoretical guarantees and valuable insights for evaluating fairness-efficiency tradeoffs in network routing.\nüìÑ Download PDF\nEAIFD: A Fast and Scalable Algorithm for Incremental Functional Dependency Discovery Authors: Yajuan Xu, Xixian Han, Xiaolong Wan Venue: arXiv (2026)\nFunctional dependencies (FDs) are fundamental integrity constraints in relational databases, but discovering them under incremental updates remains challenging. While static algorithms are inefficient due to full re-execution, incremental algorithms suffer from severe performance and memory bottlenecks. To address these challenges, this paper proposes EAIFD, a novel algorithm for incremental FD discovery. EAIFD maintains the partial hypergraph of difference sets and reframes the incremental FD discovery problem into minimal hitting set enumeration on hypergraph, avoiding full re-runs. EAIFD introduces two key innovations. First, a multi-attribute hash table ($MHT$) is devised for high-frequency key-value mappings of valid FDs, whose memory consumption is proven to be independent of the dataset size. Second, two-step validation strategy is developed to efficiently validate the enumerated candidates, which leverages $MHT$ to effectively reduce the validation space and then selectively loads data blocks for batch validation of remaining candidates, effectively avoiding repeated I/O operations. Experimental results on real-world datasets demonstrate the significant advantages of EAIFD. Compared to existing algorithms, EAIFD achieves up to an order-of-magnitude speedup in runtime while reducing memory usage by over two orders-of-magnitude, establishing it as a highly efficient and scalable solution for incremental FD discovery.\nüìÑ Download PDF\nStability Analysis of Power-Electronics-Dominated Grids Using Scaled Relative Graphs Authors: Eder Baron-Prada, Adolfo Anta, Florian D√∂rfler Venue: arXiv (2026)\nThis paper presents a novel approach to stability analysis for grid-connected converters utilizing Scaled Relative Graphs (SRG). Our method effectively decouples grid and converter dynamics, thereby establishing a comprehensive and efficient framework for evaluating closed-loop stability. Our analysis accommodates both linear and non-linear loads, enhancing its practical applicability. Furthermore, we demonstrate that our stability assessment remains unaffected by angular variations resulting from dq-frame transformations, significantly increasing the method‚Äôs robustness and versatility. The effectiveness of our approach is validated in several simulation case studies, which illustrate its broad applicability in modern power systems.\nüìÑ Download PDF\nEfficient Cloud-edge Collaborative Approaches to SPARQL Queries over Large RDF graphs Authors: Shidan Ma, Peng Peng, Xu Zhou, M. Tamer √ñzsu, Lei Zou, Guo Chen Venue: arXiv (2026)\nWith the increasing use of RDF graphs, storing and querying such data using SPARQL remains a critical problem. Current mainstream solutions rely on cloud-based data management architectures, but often suffer from performance bottle- necks in environments with limited bandwidth or high system load. To address this issue, this paper explores for the first time the integration of edge computing to move graph data storage and processing to edge environments, thereby improving query performance. This approach requires offloading query processing to edge servers, which involves addressing two challenges: data localization and network scheduling. First, the data localization challenge lies in computing the subgraphs maintained on edge servers to quickly identify the servers that can handle specific queries. To address this challenge, we introduce a new concept of pattern-induced subgraphs. Second, the network scheduling challenge involves efficiently assigning queries to edge and cloud servers to optimize overall system performance. We tackle this by constructing a overall system model that jointly captures data distribution, query characteristics, network communication, and computational resources. Accordingly, we further propose a joint formulation of query assignment and computational resource allocation, modeling it as a Mixed Integer Nonlinear Programming (MINLP) problem and solve this problem using a modified branch-and-bound algorithm. Experimental results on real datasets under a real cloud platform demonstrate that our proposed method outperforms the state-of-the-art baseline methods in terms of efficiency. The codes are available on GitHub\nüìÑ Download PDF\nüîç llm Ergodic averages for commutative transformations along return times Authors: Sebasti√°n Donoso, Sovanlal Mondal, Vicente Saavedra-Araya Venue: arXiv (2026)\nIn this paper, we extend recent results on the convergence of ergodic averages along sequences generated by return times to shrinking targets in rapidly mixing systems, partially answering questions posed by the first author, Maass and the third author in [6]. In particular, for a fixed parameter $a\\in (0,1)$ and for generic $y\\in [0,1]$, we establish both $L^2$ and pointwise convergence for single averages and multiple averages for commuting transformations along the sequences $(a_n(y))_{n\\in \\mathbb{N}}$, obtained by arranging the set $$\\Big{n\\in\\mathbb{N}: 0\u003c2^ny \\mod{1}","wordCount":"26079","inLanguage":"en","datePublished":"2026-01-25T15:25:20.581591Z","dateModified":"2026-01-25T15:25:20.581591Z","author":{"@type":"Person","name":"Gary"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://garyforreal.me/en/posts/paper/paper-2026-01-25-weekly/"},"publisher":{"@type":"Organization","name":"Gary's House","logo":{"@type":"ImageObject","url":"https://garyforreal.me/img/Q.jpg"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css><script src=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><script src=https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js></script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://garyforreal.me/en/ accesskey=h title="Gary's Blog (Alt + H)"><img src=https://garyforreal.me/img/me.jpg alt aria-label=logo height=35>Gary's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://garyforreal.me/zh/ title=‰∏≠Êñá aria-label=‰∏≠Êñá>‰∏≠Êñá</a></li></ul></div></div><ul id=menu><li><a href=https://garyforreal.me/en/search title="üîçSearch (Alt + /)" accesskey=/><span>üîçSearch</span></a></li><li><a href=https://garyforreal.me/en/ title=üè†Homepage><span>üè†Homepage</span></a></li><li><a href=https://garyforreal.me/en/posts title=üìöArticle><span>üìöArticle</span></a></li><li><a href=https://garyforreal.me/en/archives/ title=‚è±Archives><span>‚è±Archives</span></a></li><li><a href=https://garyforreal.me/en/music/ title=üéµmusic><span>üéµmusic</span></a></li><li><a href=https://garyforreal.me/en/about title=üôãüèª‚Äç‚ôÇÔ∏èAbout><span>üôãüèª‚Äç‚ôÇÔ∏èAbout</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://garyforreal.me/en/>Home</a>&nbsp;¬ª&nbsp;<a href=https://garyforreal.me/en/posts/>Posts</a>&nbsp;¬ª&nbsp;<a href=https://garyforreal.me/en/posts/paper/>Paper</a></div><h1 class="post-title entry-hint-parent">Weekly Paper Notes - 2026-01-25</h1><div class=post-meta><span title='2026-01-25 15:25:20.581591 +0000 UTC'>2026-01-25</span>&nbsp;¬∑&nbsp;123 min&nbsp;¬∑&nbsp;123 min&nbsp;¬∑&nbsp;Gary&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://garyforreal.me/zh/posts/paper/paper-2026-01-25-weekly/>‰∏≠Êñá</a></li></ul><div class=meta-item>&nbsp¬∑&nbsp
        <span id=busuanzi_container_page_pv>Êú¨ÊñáÈòÖËØªÈáè<span id=busuanzi_value_page_pv></span>Ê¨°</span></div></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#weekly-paper-notes aria-label="Weekly Paper Notes">Weekly Paper Notes</a><ul><li><a href=#-multilingual aria-label="üîç multilingual">üîç multilingual</a><ul><li><a href=#improving-training-efficiency-and-reducing-maintenance-costs-via-language-specific-model-merginghttpsarxivorgabs260116127v1 aria-label="Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging"><a href=https://arxiv.org/abs/2601.16127v1>Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging</a></a></li><li><a href=#adapter-fusion-for-multilingual-text2cypher-with-linear-and-learned-gatinghttpsarxivorgabs260116097v1 aria-label="Adapter Fusion for Multilingual Text2Cypher with Linear and Learned Gating"><a href=https://arxiv.org/abs/2601.16097v1>Adapter Fusion for Multilingual Text2Cypher with Linear and Learned Gating</a></a></li><li><a href=#timbre-aware-llm-based-direct-speech-to-speech-translation-extendable-to-multiple-language-pairshttpsarxivorgabs260116023v1 aria-label="Timbre-Aware LLM-based Direct Speech-to-Speech Translation Extendable to Multiple Language Pairs"><a href=https://arxiv.org/abs/2601.16023v1>Timbre-Aware LLM-based Direct Speech-to-Speech Translation Extendable to Multiple Language Pairs</a></a></li><li><a href=#determinants-of-training-corpus-size-for-clinical-text-classificationhttpsarxivorgabs260115846v1 aria-label="Determinants of Training Corpus Size for Clinical Text Classification"><a href=https://arxiv.org/abs/2601.15846v1>Determinants of Training Corpus Size for Clinical Text Classification</a></a></li><li><a href=#steereval-inference-time-interventions-strengthen-multilingual-generalization-in-neural-summarization-metricshttpsarxivorgabs260115809v1 aria-label="SteerEval: Inference-time Interventions Strengthen Multilingual Generalization in Neural Summarization Metrics"><a href=https://arxiv.org/abs/2601.15809v1>SteerEval: Inference-time Interventions Strengthen Multilingual Generalization in Neural Summarization Metrics</a></a></li><li><a href=#improving-methodologies-for-llm-evaluations-across-global-languageshttpsarxivorgabs260115706v1 aria-label="Improving Methodologies for LLM Evaluations Across Global Languages"><a href=https://arxiv.org/abs/2601.15706v1>Improving Methodologies for LLM Evaluations Across Global Languages</a></a></li><li><a href=#obscuring-data-contamination-through-translation-evidence-from-arabic-corporahttpsarxivorgabs260114994v1 aria-label="Obscuring Data Contamination Through Translation: Evidence from Arabic Corpora"><a href=https://arxiv.org/abs/2601.14994v1>Obscuring Data Contamination Through Translation: Evidence from Arabic Corpora</a></a></li><li><a href=#prism-benchmarking-phone-realization-in-speech-modelshttpsarxivorgabs260114046v1 aria-label="PRiSM: Benchmarking Phone Realization in Speech Models"><a href=https://arxiv.org/abs/2601.14046v1>PRiSM: Benchmarking Phone Realization in Speech Models</a></a></li><li><a href=#a-shared-geometry-of-difficulty-in-multilingual-language-modelshttpsarxivorgabs260112731v1 aria-label="A Shared Geometry of Difficulty in Multilingual Language Models"><a href=https://arxiv.org/abs/2601.12731v1>A Shared Geometry of Difficulty in Multilingual Language Models</a></a></li><li><a href=#ubuntuguard-a-culturally-grounded-policy-benchmark-for-equitable-ai-safety-in-african-languageshttpsarxivorgabs260112696v1 aria-label="UbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages"><a href=https://arxiv.org/abs/2601.12696v1>UbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages</a></a></li><li><a href=#benchmarking-concept-spilling-across-languages-in-llmshttpsarxivorgabs260112549v1 aria-label="Benchmarking Concept-Spilling Across Languages in LLMs"><a href=https://arxiv.org/abs/2601.12549v1>Benchmarking Concept-Spilling Across Languages in LLMs</a></a></li><li><a href=#cogtom-a-comprehensive-theory-of-mind-benchmark-inspired-by-human-cognition-for-large-language-modelshttpsarxivorgabs260115628v1 aria-label="CogToM: A Comprehensive Theory of Mind Benchmark inspired by Human Cognition for Large Language Models"><a href=https://arxiv.org/abs/2601.15628v1>CogToM: A Comprehensive Theory of Mind Benchmark inspired by Human Cognition for Large Language Models</a></a></li><li><a href=#the-dark-side-of-ai-transformers-sentiment-polarization--the-loss-of-business-neutrality-by-nlp-transformershttpsarxivorgabs260115509v1 aria-label="The Dark Side of AI Transformers: Sentiment Polarization & the Loss of Business Neutrality by NLP Transformers"><a href=https://arxiv.org/abs/2601.15509v1>The Dark Side of AI Transformers: Sentiment Polarization & the Loss of Business Neutrality by NLP Transformers</a></a></li><li><a href=#the-gdn-cc-dataset-automatic-corpus-clarification-for-ai-enhanced-democratic-citizen-consultationshttpsarxivorgabs260114944v2 aria-label="The GDN-CC Dataset: Automatic Corpus Clarification for AI-enhanced Democratic Citizen Consultations"><a href=https://arxiv.org/abs/2601.14944v2>The GDN-CC Dataset: Automatic Corpus Clarification for AI-enhanced Democratic Citizen Consultations</a></a></li><li><a href=#recap-resistance-capture-in-text-based-mental-health-counseling-with-large-language-modelshttpsarxivorgabs260114780v1 aria-label="RECAP: Resistance Capture in Text-based Mental Health Counseling with Large Language Models"><a href=https://arxiv.org/abs/2601.14780v1>RECAP: Resistance Capture in Text-based Mental Health Counseling with Large Language Models</a></a></li><li><a href=#cure-med-curriculum-informed-reinforcement-learning-for-multilingual-medical-reasoninghttpsarxivorgabs260113262v1 aria-label="CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning"><a href=https://arxiv.org/abs/2601.13262v1>CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning</a></a></li><li><a href=#think3d-thinking-with-space-for-spatial-reasoninghttpsarxivorgabs260113029v1 aria-label="Think3D: Thinking with Space for Spatial Reasoning"><a href=https://arxiv.org/abs/2601.13029v1>Think3D: Thinking with Space for Spatial Reasoning</a></a></li><li><a href=#static-detection-of-core-structures-in-tigress-virtualization-based-obfuscation-using-an-llvm-passhttpsarxivorgabs260112916v1 aria-label="Static Detection of Core Structures in Tigress Virtualization-Based Obfuscation Using an LLVM Pass"><a href=https://arxiv.org/abs/2601.12916v1>Static Detection of Core Structures in Tigress Virtualization-Based Obfuscation Using an LLVM Pass</a></a></li><li><a href=#towards-robust-universal-perturbation-attacks-a-float-coded-penalty-driven-evolutionary-approachhttpsarxivorgabs260112624v1 aria-label="Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach"><a href=https://arxiv.org/abs/2601.12624v1>Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach</a></a></li><li><a href=#nlp-based-review-for-toxic-comment-detection-tailored-to-the-chinese-cyberspacehttpsarxivorgabs260114721v1 aria-label="NLP-Based Review for Toxic Comment Detection Tailored to the Chinese Cyberspace"><a href=https://arxiv.org/abs/2601.14721v1>NLP-Based Review for Toxic Comment Detection Tailored to the Chinese Cyberspace</a></a></li><li><a href=#variance-adaptive-muon-accelerating-llm-pretraining-with-nsr-modulated-and-variance-scaled-momentumhttpsarxivorgabs260114603v1 aria-label="Variance-Adaptive Muon: Accelerating LLM Pretraining with NSR-Modulated and Variance-Scaled Momentum"><a href=https://arxiv.org/abs/2601.14603v1>Variance-Adaptive Muon: Accelerating LLM Pretraining with NSR-Modulated and Variance-Scaled Momentum</a></a></li><li><a href=#point-bridge-3d-representations-for-cross-domain-policy-learninghttpsarxivorgabs260116212v1 aria-label="Point Bridge: 3D Representations for Cross Domain Policy Learning"><a href=https://arxiv.org/abs/2601.16212v1>Point Bridge: 3D Representations for Cross Domain Policy Learning</a></a></li><li><a href=#pyratok-language-aligned-pyramidal-tokenizer-for-video-understanding-and-generationhttpsarxivorgabs260116210v1 aria-label="PyraTok: Language-Aligned Pyramidal Tokenizer for Video Understanding and Generation"><a href=https://arxiv.org/abs/2601.16210v1>PyraTok: Language-Aligned Pyramidal Tokenizer for Video Understanding and Generation</a></a></li><li><a href=#ivra-improving-visual-token-relations-for-robot-action-policy-with-training-free-hint-based-guidancehttpsarxivorgabs260116207v1 aria-label="IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance"><a href=https://arxiv.org/abs/2601.16207v1>IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance</a></a></li><li><a href=#llm-in-sandbox-elicits-general-agentic-intelligencehttpsarxivorgabs260116206v1 aria-label="LLM-in-Sandbox Elicits General Agentic Intelligence"><a href=https://arxiv.org/abs/2601.16206v1>LLM-in-Sandbox Elicits General Agentic Intelligence</a></a></li><li><a href=#provable-robustness-in-multimodal-large-language-models-via-feature-space-smoothinghttpsarxivorgabs260116200v1 aria-label="Provable Robustness in Multimodal Large Language Models via Feature Space Smoothing"><a href=https://arxiv.org/abs/2601.16200v1>Provable Robustness in Multimodal Large Language Models via Feature Space Smoothing</a></a></li><li><a href=#palm-property-attestation-for-large-generative-modelshttpsarxivorgabs260116199v1 aria-label="PAL*M: Property Attestation for Large Generative Models"><a href=https://arxiv.org/abs/2601.16199v1>PAL*M: Property Attestation for Large Generative Models</a></a></li><li><a href=#electron-transfer-diabatic-couplings-and-vibronic-energy-gaps-in-a-phase-space-frameworkhttpsarxivorgabs260116209v1 aria-label="Electron Transfer, Diabatic Couplings and Vibronic Energy Gaps in a Phase Space Framework"><a href=https://arxiv.org/abs/2601.16209v1>Electron Transfer, Diabatic Couplings and Vibronic Energy Gaps in a Phase Space Framework</a></a></li><li><a href=#beat-ssl-capturing-local-ecg-morphology-through-heartbeat-level-contrastive-learning-with-soft-targetshttpsarxivorgabs260116147v1 aria-label="Beat-ssl: Capturing Local ECG Morphology through Heartbeat-level Contrastive Learning with Soft Targets"><a href=https://arxiv.org/abs/2601.16147v1>Beat-ssl: Capturing Local ECG Morphology through Heartbeat-level Contrastive Learning with Soft Targets</a></a></li><li><a href=#efficiently-learning-robust-torque-based-locomotion-through-reinforcement-with-model-based-supervisionhttpsarxivorgabs260116109v1 aria-label="Efficiently Learning Robust Torque-based Locomotion Through Reinforcement with Model-Based Supervision"><a href=https://arxiv.org/abs/2601.16109v1>Efficiently Learning Robust Torque-based Locomotion Through Reinforcement with Model-Based Supervision</a></a></li><li><a href=#dsfedmed-dual-scale-federated-medical-image-segmentation-via-mutual-distillation-between-foundation-and-lightweight-modelshttpsarxivorgabs260116073v1 aria-label="DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models"><a href=https://arxiv.org/abs/2601.16073v1>DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models</a></a></li><li><a href=#campilot-improving-camera-control-in-video-diffusion-model-with-efficient-camera-reward-feedbackhttpsarxivorgabs260116214v1 aria-label="CamPilot: Improving Camera Control in Video Diffusion Model with Efficient Camera Reward Feedback"><a href=https://arxiv.org/abs/2601.16214v1>CamPilot: Improving Camera Control in Video Diffusion Model with Efficient Camera Reward Feedback</a></a></li><li><a href=#a-multiwavelength-alma-view-of-gas-and-dust-in-binary-protoplanetary-system-as-205-evidence-of-dust-asymmetric-distributionhttpsarxivorgabs260116202v1 aria-label="A multiwavelength ALMA view of gas and dust in binary protoplanetary system AS 205: Evidence of dust asymmetric distribution"><a href=https://arxiv.org/abs/2601.16202v1>A multiwavelength ALMA view of gas and dust in binary protoplanetary system AS 205: Evidence of dust asymmetric distribution</a></a></li><li><a href=#360anything-geometry-free-lifting-of-images-and-videos-to-360httpsarxivorgabs260116192v1 aria-label="360Anything: Geometry-Free Lifting of Images and Videos to 360¬∞"><a href=https://arxiv.org/abs/2601.16192v1>360Anything: Geometry-Free Lifting of Images and Videos to 360¬∞</a></a></li><li><a href=#a-general-spectral-solver-for-the-axisymmetric-jeans-equations-fast-galaxy-modelling-with-arbitrary-anisotropyhttpsarxivorgabs260116179v1 aria-label="A general spectral solver for the axisymmetric Jeans equations: fast galaxy modelling with arbitrary anisotropy"><a href=https://arxiv.org/abs/2601.16179v1>A general spectral solver for the axisymmetric Jeans equations: fast galaxy modelling with arbitrary anisotropy</a></a></li><li><a href=#hvd-human-vision-driven-video-representation-learning-for-text-video-retrievalhttpsarxivorgabs260116155v1 aria-label="HVD: Human Vision-Driven Video Representation Learning for Text-Video Retrieval"><a href=https://arxiv.org/abs/2601.16155v1>HVD: Human Vision-Driven Video Representation Learning for Text-Video Retrieval</a></a></li><li><a href=#rethinking-composed-image-retrieval-evaluation-a-fine-grained-benchmark-from-image-editinghttpsarxivorgabs260116125v1 aria-label="Rethinking Composed Image Retrieval Evaluation: A Fine-Grained Benchmark from Image Editing"><a href=https://arxiv.org/abs/2601.16125v1>Rethinking Composed Image Retrieval Evaluation: A Fine-Grained Benchmark from Image Editing</a></a></li><li><a href=#multimodal-climate-disinformation-detection-integrating-vision-language-models-with-external-knowledge-sourceshttpsarxivorgabs260116108v1 aria-label="Multimodal Climate Disinformation Detection: Integrating Vision-Language Models with External Knowledge Sources"><a href=https://arxiv.org/abs/2601.16108v1>Multimodal Climate Disinformation Detection: Integrating Vision-Language Models with External Knowledge Sources</a></a></li><li><a href=#grounding-large-language-models-in-reaction-knowledge-graphs-for-synthesis-retrievalhttpsarxivorgabs260116038v1 aria-label="Grounding Large Language Models in Reaction Knowledge Graphs for Synthesis Retrieval"><a href=https://arxiv.org/abs/2601.16038v1>Grounding Large Language Models in Reaction Knowledge Graphs for Synthesis Retrieval</a></a></li><li><a href=#deja-vu-in-plots-leveraging-cross-session-evidence-with-retrieval-augmented-llms-for-live-streaming-risk-assessmenthttpsarxivorgabs260116027v1 aria-label="Deja Vu in Plots: Leveraging Cross-Session Evidence with Retrieval-Augmented LLMs for Live Streaming Risk Assessment"><a href=https://arxiv.org/abs/2601.16027v1>Deja Vu in Plots: Leveraging Cross-Session Evidence with Retrieval-Augmented LLMs for Live Streaming Risk Assessment</a></a></li><li><a href=#mecellem-models-turkish-models-trained-from-scratch-and-continually-pre-trained-for-the-legal-domainhttpsarxivorgabs260116018v1 aria-label="Mecellem Models: Turkish Models Trained from Scratch and Continually Pre-trained for the Legal Domain"><a href=https://arxiv.org/abs/2601.16018v1>Mecellem Models: Turkish Models Trained from Scratch and Continually Pre-trained for the Legal Domain</a></a></li></ul></li><li><a href=#-linguistics aria-label="üîç linguistics">üîç linguistics</a><ul><li><a href=#gauge-theory-and-skein-moduleshttpsarxivorgabs260116213v1 aria-label="Gauge Theory and Skein Modules"><a href=https://arxiv.org/abs/2601.16213v1>Gauge Theory and Skein Modules</a></a></li><li><a href=#why-cant-i-open-my-drawer-mitigating-object-driven-shortcuts-in-zero-shot-compositional-action-recognitionhttpsarxivorgabs260116211v1 aria-label="Why Can&rsquo;t I Open My Drawer? Mitigating Object-Driven Shortcuts in Zero-Shot Compositional Action Recognition"><a href=https://arxiv.org/abs/2601.16211v1>Why Can&rsquo;t I Open My Drawer? Mitigating Object-Driven Shortcuts in Zero-Shot Compositional Action Recognition</a></a></li><li><a href=#scaling-text-to-image-diffusion-transformers-with-representation-autoencodershttpsarxivorgabs260116208v1 aria-label="Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders"><a href=https://arxiv.org/abs/2601.16208v1>Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders</a></a></li><li><a href=#high-resolution-neutron-diffraction-determination-of-noncollinear-antiferromagnetic-order-in-the-honeycomb-magnetoelectric-fe_4nb_2o_9httpsarxivorgabs260116215v1 aria-label="High-resolution neutron diffraction determination of noncollinear antiferromagnetic order in the honeycomb magnetoelectric Fe${4}$Nb${2}$O$_{9}$"><a href=https://arxiv.org/abs/2601.16215v1>High-resolution neutron diffraction determination of noncollinear antiferromagnetic order in the honeycomb magnetoelectric Fe$<em>{4}$Nb$</em>{2}$O$_{9}$</a></a></li><li><a href=#on-the-missing-red-giants-near-the-galactic-centerhttpsarxivorgabs260116191v1 aria-label="On the Missing Red Giants near the Galactic Center"><a href=https://arxiv.org/abs/2601.16191v1>On the Missing Red Giants near the Galactic Center</a></a></li><li><a href=#physical-and-dielectric-properties-of-polycrystalline-lav_05nb_05o_4httpsarxivorgabs260116067v1 aria-label="Physical and Dielectric Properties of Polycrystalline LaV${0.5}$Nb${0.5}$O$_4$"><a href=https://arxiv.org/abs/2601.16067v1>Physical and Dielectric Properties of Polycrystalline LaV$<em>{0.5}$Nb$</em>{0.5}$O$_4$</a></a></li><li><a href=#unveiling-the-spectral-morphological-division-of-fast-radio-bursts-with-chimefrb-catalog-2httpsarxivorgabs260116048v1 aria-label="Unveiling the Spectral Morphological Division of Fast Radio Bursts with CHIME/FRB Catalog 2"><a href=https://arxiv.org/abs/2601.16048v1>Unveiling the Spectral Morphological Division of Fast Radio Bursts with CHIME/FRB Catalog 2</a></a></li><li><a href=#paint-pathology-aware-integrated-next-scale-transformation-for-virtual-immunohistochemistryhttpsarxivorgabs260116024v1 aria-label="PAINT: Pathology-Aware Integrated Next-Scale Transformation for Virtual Immunohistochemistry"><a href=https://arxiv.org/abs/2601.16024v1>PAINT: Pathology-Aware Integrated Next-Scale Transformation for Virtual Immunohistochemistry</a></a></li><li><a href=#counterfactual-training-teaching-models-plausible-and-actionable-explanationshttpsarxivorgabs260116205v1 aria-label="Counterfactual Training: Teaching Models Plausible and Actionable Explanations"><a href=https://arxiv.org/abs/2601.16205v1>Counterfactual Training: Teaching Models Plausible and Actionable Explanations</a></a></li><li><a href=#a-rolling-space-branch-and-price-algorithm-for-the-multi-compartment-vehicle-routing-problem-with-multiple-time-windowshttpsarxivorgabs260116194v1 aria-label="A Rolling-Space Branch-and-Price Algorithm for the Multi-Compartment Vehicle Routing Problem with Multiple Time Windows"><a href=https://arxiv.org/abs/2601.16194v1>A Rolling-Space Branch-and-Price Algorithm for the Multi-Compartment Vehicle Routing Problem with Multiple Time Windows</a></a></li><li><a href=#magnon-equilibrium-spin-current-in-collinear-antiferromagnetshttpsarxivorgabs260116184v1 aria-label="Magnon equilibrium spin current in collinear antiferromagnets"><a href=https://arxiv.org/abs/2601.16184v1>Magnon equilibrium spin current in collinear antiferromagnets</a></a></li><li><a href=#on-the-structural-properties-of-lie-algebras-via-associated-labeled-directed-graphshttpsarxivorgabs260116161v1 aria-label="On the structural properties of Lie algebras via associated labeled directed graphs"><a href=https://arxiv.org/abs/2601.16161v1>On the structural properties of Lie algebras via associated labeled directed graphs</a></a></li><li><a href=#domain-incremental-continual-learning-for-robust-and-efficient-keyword-spotting-in-resource-constrained-systemshttpsarxivorgabs260116158v1 aria-label="Domain-Incremental Continual Learning for Robust and Efficient Keyword Spotting in Resource Constrained Systems"><a href=https://arxiv.org/abs/2601.16158v1>Domain-Incremental Continual Learning for Robust and Efficient Keyword Spotting in Resource Constrained Systems</a></a></li><li><a href=#samtok-representing-any-mask-with-two-wordshttpsarxivorgabs260116093v1 aria-label="SAMTok: Representing Any Mask with Two Words"><a href=https://arxiv.org/abs/2601.16093v1>SAMTok: Representing Any Mask with Two Words</a></a></li><li><a href=#moleculariq-characterizing-chemical-reasoning-capabilities-through-symbolic-verification-on-molecular-graphshttpsarxivorgabs260115279v1 aria-label="MolecularIQ: Characterizing Chemical Reasoning Capabilities Through Symbolic Verification on Molecular Graphs"><a href=https://arxiv.org/abs/2601.15279v1>MolecularIQ: Characterizing Chemical Reasoning Capabilities Through Symbolic Verification on Molecular Graphs</a></a></li><li><a href=#interpreting-multimodal-communication-at-scale-in-short-form-video-visual-audio-and-textual-mental-health-discourse-on-tiktokhttpsarxivorgabs260115278v1 aria-label="Interpreting Multimodal Communication at Scale in Short-Form Video: Visual, Audio, and Textual Mental Health Discourse on TikTok"><a href=https://arxiv.org/abs/2601.15278v1>Interpreting Multimodal Communication at Scale in Short-Form Video: Visual, Audio, and Textual Mental Health Discourse on TikTok</a></a></li><li><a href=#large-scale-multidimensional-knowledge-profiling-of-scientific-literaturehttpsarxivorgabs260115170v1 aria-label="Large-Scale Multidimensional Knowledge Profiling of Scientific Literature"><a href=https://arxiv.org/abs/2601.15170v1>Large-Scale Multidimensional Knowledge Profiling of Scientific Literature</a></a></li><li><a href=#delog-an-efficient-log-compression-framework-with-pattern-signature-synthesishttpsarxivorgabs260115084v2 aria-label="DeLog: An Efficient Log Compression Framework with Pattern Signature Synthesis"><a href=https://arxiv.org/abs/2601.15084v2>DeLog: An Efficient Log Compression Framework with Pattern Signature Synthesis</a></a></li><li><a href=#just-aware-enough-evaluating-awareness-across-artificial-systemshttpsarxivorgabs260114901v1 aria-label="Just aware enough: Evaluating awareness across artificial systems"><a href=https://arxiv.org/abs/2601.14901v1>Just aware enough: Evaluating awareness across artificial systems</a></a></li><li><a href=#universal-non-gaussian-order-parameter-statistics-in-2d-superfluidshttpsarxivorgabs260116204v1 aria-label="Universal non-Gaussian order parameter statistics in 2D superfluids"><a href=https://arxiv.org/abs/2601.16204v1>Universal non-Gaussian order parameter statistics in 2D superfluids</a></a></li><li><a href=#studying-energy-resolved-transport-with-wavepacket-dynamics-on-quantum-computershttpsarxivorgabs260116180v1 aria-label="Studying energy-resolved transport with wavepacket dynamics on quantum computers"><a href=https://arxiv.org/abs/2601.16180v1>Studying energy-resolved transport with wavepacket dynamics on quantum computers</a></a></li><li><a href=#the-farview-low-frequency-radio-array-on-the-moons-far-side-science-and-array-architecturehttpsarxivorgabs260116170v1 aria-label="The FarView Low Frequency Radio Array on the Moon&rsquo;s Far Side: Science and Array Architecture"><a href=https://arxiv.org/abs/2601.16170v1>The FarView Low Frequency Radio Array on the Moon&rsquo;s Far Side: Science and Array Architecture</a></a></li><li><a href=#reanalyzing-desi-dr1-4-percent-level-cosmological-constraints-from-combined-probes-and-robust-evidence-for-the-normal-neutrino-mass-hierarchyhttpsarxivorgabs260116165v1 aria-label="Reanalyzing DESI DR1: 4. Percent-Level Cosmological Constraints from Combined Probes and Robust Evidence for the Normal Neutrino Mass Hierarchy"><a href=https://arxiv.org/abs/2601.16165v1>Reanalyzing DESI DR1: 4. Percent-Level Cosmological Constraints from Combined Probes and Robust Evidence for the Normal Neutrino Mass Hierarchy</a></a></li><li><a href=#automatic-classification-of-arabic-literature-into-historical-erashttpsarxivorgabs260116138v1 aria-label="Automatic Classification of Arabic Literature into Historical Eras"><a href=https://arxiv.org/abs/2601.16138v1>Automatic Classification of Arabic Literature into Historical Eras</a></a></li><li><a href=#biexcitons-in-ruddlesden-popper-metal-halides-probed-by-nonlinear-coherent-spectroscopyhttpsarxivorgabs260116101v1 aria-label="Biexcitons in Ruddlesden-Popper Metal Halides Probed by Nonlinear Coherent Spectroscopy"><a href=https://arxiv.org/abs/2601.16101v1>Biexcitons in Ruddlesden-Popper Metal Halides Probed by Nonlinear Coherent Spectroscopy</a></a></li><li><a href=#the-pohozaev-identity-for-the-spectral-fractional-laplacianhttpsarxivorgabs260116185v1 aria-label="The Pohozaev identity for the Spectral Fractional Laplacian"><a href=https://arxiv.org/abs/2601.16185v1>The Pohozaev identity for the Spectral Fractional Laplacian</a></a></li><li><a href=#mild-solutions-for-path-dependent-parabolic-pdes-with-neumann-boundary-conditions-via-generalized-bsdeshttpsarxivorgabs260116178v1 aria-label="Mild Solutions for Path-Dependent Parabolic PDEs with Neumann Boundary Conditions via Generalized BSDEs"><a href=https://arxiv.org/abs/2601.16178v1>Mild Solutions for Path-Dependent Parabolic PDEs with Neumann Boundary Conditions via Generalized BSDEs</a></a></li><li><a href=#beyond-predictive-uncertainty-reliable-representation-learning-with-structural-constraintshttpsarxivorgabs260116174v1 aria-label="Beyond Predictive Uncertainty: Reliable Representation Learning with Structural Constraints"><a href=https://arxiv.org/abs/2601.16174v1>Beyond Predictive Uncertainty: Reliable Representation Learning with Structural Constraints</a></a></li><li><a href=#ctl-model-checking-on-infinite-families-of-finite-state-labeled-transition-systems-technical-reporthttpsarxivorgabs260115756v1 aria-label="CTL* Model Checking on Infinite Families of Finite-State Labeled Transition Systems (Technical Report)"><a href=https://arxiv.org/abs/2601.15756v1>CTL* Model Checking on Infinite Families of Finite-State Labeled Transition Systems (Technical Report)</a></a></li><li><a href=#beyond-visual-safety-jailbreaking-multimodal-large-language-models-for-harmful-image-generation-via-semantic-agnostic-inputshttpsarxivorgabs260115698v1 aria-label="Beyond Visual Safety: Jailbreaking Multimodal Large Language Models for Harmful Image Generation via Semantic-Agnostic Inputs"><a href=https://arxiv.org/abs/2601.15698v1>Beyond Visual Safety: Jailbreaking Multimodal Large Language Models for Harmful Image Generation via Semantic-Agnostic Inputs</a></a></li><li><a href=#prism-deriving-the-transformer-as-a-signal-denoising-operator-via-maximum-coding-rate-reductionhttpsarxivorgabs260115540v1 aria-label="PRISM: Deriving the Transformer as a Signal-Denoising Operator via Maximum Coding Rate Reduction"><a href=https://arxiv.org/abs/2601.15540v1>PRISM: Deriving the Transformer as a Signal-Denoising Operator via Maximum Coding Rate Reduction</a></a></li><li><a href=#testing-deep-learning-libraries-via-neurosymbolic-constraint-learninghttpsarxivorgabs260115493v1 aria-label="Testing Deep Learning Libraries via Neurosymbolic Constraint Learning"><a href=https://arxiv.org/abs/2601.15493v1>Testing Deep Learning Libraries via Neurosymbolic Constraint Learning</a></a></li><li><a href=#on-the-diagonal-of-low-bidegree-hypersurfaceshttpsarxivorgabs260115409v1 aria-label="On the diagonal of low bidegree hypersurfaces"><a href=https://arxiv.org/abs/2601.15409v1>On the diagonal of low bidegree hypersurfaces</a></a></li></ul></li><li><a href=#-psycholinguistics aria-label="üîç psycholinguistics">üîç psycholinguistics</a><ul><li><a href=#stochastic-control-barrier-functions-under-state-estimation-from-euclidean-space-to-lie-groupshttpsarxivorgabs260116198v1 aria-label="Stochastic Control Barrier Functions under State Estimation: From Euclidean Space to Lie Groups"><a href=https://arxiv.org/abs/2601.16198v1>Stochastic Control Barrier Functions under State Estimation: From Euclidean Space to Lie Groups</a></a></li><li><a href=#scaling-sample-based-quantum-diagonalization-on-gpu-accelerated-systems-using-openmp-offloadhttpsarxivorgabs260116169v1 aria-label="Scaling Sample-Based Quantum Diagonalization on GPU-Accelerated Systems using OpenMP Offload"><a href=https://arxiv.org/abs/2601.16169v1>Scaling Sample-Based Quantum Diagonalization on GPU-Accelerated Systems using OpenMP Offload</a></a></li><li><a href=#even-gpt-52-cant-count-to-five-the-case-for-zero-error-horizons-in-trustworthy-llmshttpsarxivorgabs260115714v1 aria-label="Even GPT-5.2 Can&rsquo;t Count to Five: The Case for Zero-Error Horizons in Trustworthy LLMs"><a href=https://arxiv.org/abs/2601.15714v1>Even GPT-5.2 Can&rsquo;t Count to Five: The Case for Zero-Error Horizons in Trustworthy LLMs</a></a></li><li><a href=#predictive-coding-and-information-bottleneck-for-hallucination-detection-in-large-language-modelshttpsarxivorgabs260115652v1 aria-label="Predictive Coding and Information Bottleneck for Hallucination Detection in Large Language Models"><a href=https://arxiv.org/abs/2601.15652v1>Predictive Coding and Information Bottleneck for Hallucination Detection in Large Language Models</a></a></li><li><a href=#coloring-small-locally-sparse-degenerate-graphs-and-related-problemshttpsarxivorgabs260115245v1 aria-label="Coloring small locally sparse degenerate graphs and related problems"><a href=https://arxiv.org/abs/2601.15245v1>Coloring small locally sparse degenerate graphs and related problems</a></a></li><li><a href=#information-mechanics-conservation-and-exchangehttpsarxivorgabs260115028v1 aria-label="Information mechanics: conservation and exchange"><a href=https://arxiv.org/abs/2601.15028v1>Information mechanics: conservation and exchange</a></a></li><li><a href=#resonant-excitation-induced-vibronic-mollow-tripletshttpsarxivorgabs260114963v1 aria-label="Resonant Excitation Induced Vibronic Mollow Triplets"><a href=https://arxiv.org/abs/2601.14963v1>Resonant Excitation Induced Vibronic Mollow Triplets</a></a></li><li><a href=#which-reasoning-trajectories-teach-students-to-reason-better-a-simple-metric-of-informative-alignmenthttpsarxivorgabs260114249v1 aria-label="Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment"><a href=https://arxiv.org/abs/2601.14249v1>Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment</a></a></li><li><a href=#cyclic-sunspot-activity-during-the-first-millennium-ce-as-reconstructed-from-radiocarbonhttpsarxivorgabs260116203v1 aria-label="Cyclic sunspot activity during the first millennium CE as reconstructed from radiocarbon"><a href=https://arxiv.org/abs/2601.16203v1>Cyclic sunspot activity during the first millennium CE as reconstructed from radiocarbon</a></a></li><li><a href=#a-forward-only-scheme-for-online-learning-of-proposal-distributions-in-particle-filtershttpsarxivorgabs260116089v1 aria-label="A forward-only scheme for online learning of proposal distributions in particle filters"><a href=https://arxiv.org/abs/2601.16089v1>A forward-only scheme for online learning of proposal distributions in particle filters</a></a></li><li><a href=#the-role-of-cognitive-abilities-in-requirements-inspection-comparing-uml-and-textual-representationshttpsarxivorgabs260116009v1 aria-label="The Role of Cognitive Abilities in Requirements Inspection: Comparing UML and Textual Representations"><a href=https://arxiv.org/abs/2601.16009v1>The Role of Cognitive Abilities in Requirements Inspection: Comparing UML and Textual Representations</a></a></li><li><a href=#humanllm-towards-personalized-understanding-and-simulation-of-human-naturehttpsarxivorgabs260115793v1 aria-label="HumanLLM: Towards Personalized Understanding and Simulation of Human Nature"><a href=https://arxiv.org/abs/2601.15793v1>HumanLLM: Towards Personalized Understanding and Simulation of Human Nature</a></a></li><li><a href=#resting-state-functional-connectivity-correlates-of-emotional-memory-control-under-cognitive-load-in-subclinical-anxietyhttpsarxivorgabs260115689v1 aria-label="Resting-State Functional Connectivity Correlates of Emotional Memory Control under Cognitive load in Subclinical Anxiety"><a href=https://arxiv.org/abs/2601.15689v1>Resting-State Functional Connectivity Correlates of Emotional Memory Control under Cognitive load in Subclinical Anxiety</a></a></li><li><a href=#average-unfairness-in-routing-gameshttpsarxivorgabs260116187v1 aria-label="Average Unfairness in Routing Games"><a href=https://arxiv.org/abs/2601.16187v1>Average Unfairness in Routing Games</a></a></li><li><a href=#eaifd-a-fast-and-scalable-algorithm-for-incremental-functional-dependency-discoveryhttpsarxivorgabs260116025v1 aria-label="EAIFD: A Fast and Scalable Algorithm for Incremental Functional Dependency Discovery"><a href=https://arxiv.org/abs/2601.16025v1>EAIFD: A Fast and Scalable Algorithm for Incremental Functional Dependency Discovery</a></a></li><li><a href=#stability-analysis-of-power-electronics-dominated-grids-using-scaled-relative-graphshttpsarxivorgabs260116014v1 aria-label="Stability Analysis of Power-Electronics-Dominated Grids Using Scaled Relative Graphs"><a href=https://arxiv.org/abs/2601.16014v1>Stability Analysis of Power-Electronics-Dominated Grids Using Scaled Relative Graphs</a></a></li><li><a href=#efficient-cloud-edge-collaborative-approaches-to-sparql-queries-over-large-rdf-graphshttpsarxivorgabs260115992v1 aria-label="Efficient Cloud-edge Collaborative Approaches to SPARQL Queries over Large RDF graphs"><a href=https://arxiv.org/abs/2601.15992v1>Efficient Cloud-edge Collaborative Approaches to SPARQL Queries over Large RDF graphs</a></a></li></ul></li><li><a href=#-llm aria-label="üîç llm">üîç llm</a><ul><li><a href=#ergodic-averages-for-commutative-transformations-along-return-timeshttpsarxivorgabs260116188v1 aria-label="Ergodic averages for commutative transformations along return times"><a href=https://arxiv.org/abs/2601.16188v1>Ergodic averages for commutative transformations along return times</a></a></li><li><a href=#contex-t-contextual-privacy-exploitation-via-transformer-spectral-analysis-for-iot-device-fingerprintinghttpsarxivorgabs260116160v1 aria-label="CONTEX-T: Contextual Privacy Exploitation via Transformer Spectral Analysis for IoT Device Fingerprinting"><a href=https://arxiv.org/abs/2601.16160v1>CONTEX-T: Contextual Privacy Exploitation via Transformer Spectral Analysis for IoT Device Fingerprinting</a></a></li><li><a href=#substrate-stability-under-persistent-disagreement-structural-constraints-for-neutral-ontological-substrateshttpsarxivorgabs260116152v1 aria-label="Substrate Stability Under Persistent Disagreement: Structural Constraints for Neutral Ontological Substrates"><a href=https://arxiv.org/abs/2601.16152v1>Substrate Stability Under Persistent Disagreement: Structural Constraints for Neutral Ontological Substrates</a></a></li><li><a href=#cis--trans-rotational-isomerism-of-seleno--thio--and-formic-acids-and-their-dimers-chemical-kinetics-under-interstellar-conditionshttpsarxivorgabs260116115v1 aria-label="Cis&ndash;Trans Rotational Isomerism of Seleno-, Thio-, and Formic Acids and Their Dimers: Chemical Kinetics under Interstellar Conditions"><a href=https://arxiv.org/abs/2601.16115v1>Cis&ndash;Trans Rotational Isomerism of Seleno-, Thio-, and Formic Acids and Their Dimers: Chemical Kinetics under Interstellar Conditions</a></a></li><li><a href=#robust-quantum-algorithmic-binary-decision-making-on-displacement-signalshttpsarxivorgabs260116081v1 aria-label="Robust Quantum Algorithmic Binary Decision-Making on Displacement Signals"><a href=https://arxiv.org/abs/2601.16081v1>Robust Quantum Algorithmic Binary Decision-Making on Displacement Signals</a></a></li><li><a href=#pushing-the-limits-of-unconstrained-machine-learned-interatomic-potentialshttpsarxivorgabs260116195v1 aria-label="Pushing the limits of unconstrained machine-learned interatomic potentials"><a href=https://arxiv.org/abs/2601.16195v1>Pushing the limits of unconstrained machine-learned interatomic potentials</a></a></li><li><a href=#inference-on-the-significance-of-modalities-in-multimodal-generalized-linear-modelshttpsarxivorgabs260116196v1 aria-label="Inference on the Significance of Modalities in Multimodal Generalized Linear Models"><a href=https://arxiv.org/abs/2601.16196v1>Inference on the Significance of Modalities in Multimodal Generalized Linear Models</a></a></li><li><a href=#learning-to-discover-at-test-timehttpsarxivorgabs260116175v1 aria-label="Learning to Discover at Test Time"><a href=https://arxiv.org/abs/2601.16175v1>Learning to Discover at Test Time</a></a></li><li><a href=#structured-hints-for-sample-efficient-lean-theorem-provinghttpsarxivorgabs260116172v1 aria-label="Structured Hints for Sample-Efficient Lean Theorem Proving"><a href=https://arxiv.org/abs/2601.16172v1>Structured Hints for Sample-Efficient Lean Theorem Proving</a></a></li></ul></li><li><a href=#-neuroscience aria-label="üîç neuroscience">üîç neuroscience</a><ul><li><a href=#interface-spin-orbit-coupling-induced-room-temperature-ferromagnetic-insulatorhttpsarxivorgabs260116069v1 aria-label="Interface Spin-orbit Coupling Induced Room-temperature Ferromagnetic Insulator"><a href=https://arxiv.org/abs/2601.16069v1>Interface Spin-orbit Coupling Induced Room-temperature Ferromagnetic Insulator</a></a></li><li><a href=#can-platform-design-encourage-curiosity-evidence-from-an-independent-social-media-experimenthttpsarxivorgabs260116040v1 aria-label="Can Platform Design Encourage Curiosity? Evidence from an Independent Social Media Experiment"><a href=https://arxiv.org/abs/2601.16040v1>Can Platform Design Encourage Curiosity? Evidence from an Independent Social Media Experiment</a></a></li><li><a href=#jwst-advanced-deep-extragalactic-survey-jades-data-release-5-photometric-cataloghttpsarxivorgabs260115956v1 aria-label="JWST Advanced Deep Extragalactic Survey (JADES) Data Release 5: Photometric Catalog"><a href=https://arxiv.org/abs/2601.15956v1>JWST Advanced Deep Extragalactic Survey (JADES) Data Release 5: Photometric Catalog</a></a></li><li><a href=#natural-language-driven-global-mapping-of-martian-landformshttpsarxivorgabs260115949v1 aria-label="Natural Language-Driven Global Mapping of Martian Landforms"><a href=https://arxiv.org/abs/2601.15949v1>Natural Language-Driven Global Mapping of Martian Landforms</a></a></li><li><a href=#tenet-text-to-network-for-compact-policy-synthesishttpsarxivorgabs260115912v1 aria-label="TeNet: Text-to-Network for Compact Policy Synthesis"><a href=https://arxiv.org/abs/2601.15912v1>TeNet: Text-to-Network for Compact Policy Synthesis</a></a></li></ul></li><li><a href=#-data_resources aria-label="üîç data_resources">üîç data_resources</a><ul><li><a href=#cgpt-cluster-guided-partial-tables-with-llm-generated-supervision-for-table-retrievalhttpsarxivorgabs260115849v1 aria-label="CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval"><a href=https://arxiv.org/abs/2601.15849v1>CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval</a></a></li><li><a href=#synthocr-gen-a-synthetic-ocr-dataset-generator-for-low-resource-languages--breaking-the-data-barrierhttpsarxivorgabs260116113v1 aria-label="synthocr-gen: A synthetic ocr dataset generator for low-resource languages- breaking the data barrier"><a href=https://arxiv.org/abs/2601.16113v1>synthocr-gen: A synthetic ocr dataset generator for low-resource languages- breaking the data barrier</a></a></li><li><a href=#a-multi-view-pipeline-and-benchmark-dataset-for-3d-hand-pose-estimation-in-surgeryhttpsarxivorgabs260115918v1 aria-label="A Multi-View Pipeline and Benchmark Dataset for 3D Hand Pose Estimation in Surgery"><a href=https://arxiv.org/abs/2601.15918v1>A Multi-View Pipeline and Benchmark Dataset for 3D Hand Pose Estimation in Surgery</a></a></li><li><a href=#a-lightweight-brain-inspired-machine-learning-framework-for-coronary-angiography-hybrid-neural-representation-and-robust-learning-strategieshttpsarxivorgabs260115865v1 aria-label="A Lightweight Brain-Inspired Machine Learning Framework for Coronary Angiography: Hybrid Neural Representation and Robust Learning Strategies"><a href=https://arxiv.org/abs/2601.15865v1>A Lightweight Brain-Inspired Machine Learning Framework for Coronary Angiography: Hybrid Neural Representation and Robust Learning Strategies</a></a></li></ul></li><li><a href=#-emotion_language aria-label="üîç emotion_language">üîç emotion_language</a><ul><li><a href=#synthetic-augmentation-in-imbalanced-learning-when-it-helps-when-it-hurts-and-how-much-to-addhttpsarxivorgabs260116120v1 aria-label="Synthetic Augmentation in Imbalanced Learning: When It Helps, When It Hurts, and How Much to Add"><a href=https://arxiv.org/abs/2601.16120v1>Synthetic Augmentation in Imbalanced Learning: When It Helps, When It Hurts, and How Much to Add</a></a></li><li><a href=#benchmarking-deep-learning-models-for-raman-spectroscopy-across-open-source-datasetshttpsarxivorgabs260116107v1 aria-label="Benchmarking Deep Learning Models for Raman Spectroscopy Across Open-Source Datasets"><a href=https://arxiv.org/abs/2601.16107v1>Benchmarking Deep Learning Models for Raman Spectroscopy Across Open-Source Datasets</a></a></li><li><a href=#clustering-guided-spatial-spectral-mamba-for-hyperspectral-image-classificationhttpsarxivorgabs260116098v1 aria-label="Clustering-Guided Spatial-Spectral Mamba for Hyperspectral Image Classification"><a href=https://arxiv.org/abs/2601.16098v1>Clustering-Guided Spatial-Spectral Mamba for Hyperspectral Image Classification</a></a></li><li><a href=#constraining-dark-energy-models-using-jackknife-and-bootstrap-resamplinghttpsarxivorgabs260116197v1 aria-label="Constraining dark energy models using Jackknife and Bootstrap resampling"><a href=https://arxiv.org/abs/2601.16197v1>Constraining dark energy models using Jackknife and Bootstrap resampling</a></a></li><li><a href=#evolution-of-the-recent-high-accretion-state-of-the-recurrent-nova-t-crb-hst-swift-nustar-and-xmm-newton-observationshttpsarxivorgabs260116190v1 aria-label="Evolution of the recent high-accretion state of the recurrent nova T CrB: HST, Swift, NuSTAR, and XMM-Newton observations"><a href=https://arxiv.org/abs/2601.16190v1>Evolution of the recent high-accretion state of the recurrent nova T CrB: HST, Swift, NuSTAR, and XMM-Newton observations</a></a></li><li><a href=#string-breaking-and-glueball-dynamics-in-21d-quantum-link-electrodynamicshttpsarxivorgabs260116166v1 aria-label="String Breaking and Glueball Dynamics in $2+1$D Quantum Link Electrodynamics"><a href=https://arxiv.org/abs/2601.16166v1>String Breaking and Glueball Dynamics in $2+1$D Quantum Link Electrodynamics</a></a></li><li><a href=#a-saturation-bound-for-cumulative-responses-under-local-linear-relaxationhttpsarxivorgabs260116157v1 aria-label="A saturation bound for cumulative responses under local linear relaxation"><a href=https://arxiv.org/abs/2601.16157v1>A saturation bound for cumulative responses under local linear relaxation</a></a></li><li><a href=#interconnection-based-model-reduction-for-linear-hybrid-systemshttpsarxivorgabs260116149v1 aria-label="Interconnection-based Model Reduction for Linear Hybrid Systems"><a href=https://arxiv.org/abs/2601.16149v1>Interconnection-based Model Reduction for Linear Hybrid Systems</a></a></li><li><a href=#calibration-conditioned-film-decoders-for-low-latency-decoding-of-quantum-error-correction-evaluated-on-ibm-repetition-code-experimentshttpsarxivorgabs260116123v1 aria-label="Calibration-Conditioned FiLM Decoders for Low-Latency Decoding of Quantum Error Correction Evaluated on IBM Repetition-Code Experiments"><a href=https://arxiv.org/abs/2601.16123v1>Calibration-Conditioned FiLM Decoders for Low-Latency Decoding of Quantum Error Correction Evaluated on IBM Repetition-Code Experiments</a></a></li><li><a href=#controlling-long-horizon-behavior-in-language-model-agents-with-explicit-state-dynamicshttpsarxivorgabs260116087v1 aria-label="Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics"><a href=https://arxiv.org/abs/2601.16087v1>Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics</a></a></li><li><a href=#robust-bell-nonlocality-from-gottesman-kitaev-preskill-stateshttpsarxivorgabs260116189v1 aria-label="Robust Bell Nonlocality from Gottesman-Kitaev-Preskill States"><a href=https://arxiv.org/abs/2601.16189v1>Robust Bell Nonlocality from Gottesman-Kitaev-Preskill States</a></a></li><li><a href=#magnetar-fraction-in-core-collapse-supernovaehttpsarxivorgabs260116159v1 aria-label="Magnetar fraction in Core-Collapse Supernovae"><a href=https://arxiv.org/abs/2601.16159v1>Magnetar fraction in Core-Collapse Supernovae</a></a></li><li><a href=#charge-and-spin-orders-in-the-t-u-v-j-model-a-slave-spin-1-approachhttpsarxivorgabs260116153v1 aria-label="Charge and spin orders in the t-U-V-J model: a slave-spin-1 approach"><a href=https://arxiv.org/abs/2601.16153v1>Charge and spin orders in the t-U-V-J model: a slave-spin-1 approach</a></a></li><li><a href=#transition-in-splitting-probabilities-of-quantum-walkshttpsarxivorgabs260116111v1 aria-label="Transition in Splitting Probabilities of Quantum Walks"><a href=https://arxiv.org/abs/2601.16111v1>Transition in Splitting Probabilities of Quantum Walks</a></a></li><li><a href=#engineering-polarization-how-contradictory-stimulation-systematically-undermines-political-moderationhttpsarxivorgabs260116181v1 aria-label="Engineering polarization: How contradictory stimulation systematically undermines political moderation"><a href=https://arxiv.org/abs/2601.16181v1>Engineering polarization: How contradictory stimulation systematically undermines political moderation</a></a></li><li><a href=#from-harm-to-healing-understanding-individual-resilience-after-cybercrimeshttpsarxivorgabs260116050v1 aria-label="From Harm to Healing: Understanding Individual Resilience after Cybercrimes"><a href=https://arxiv.org/abs/2601.16050v1>From Harm to Healing: Understanding Individual Resilience after Cybercrimes</a></a></li><li><a href=#predicting-healthcare-system-visitation-flow-by-integrating-hospital-attributes-and-population-socioeconomics-with-human-mobility-datahttpsarxivorgabs260115977v1 aria-label="Predicting Healthcare System Visitation Flow by Integrating Hospital Attributes and Population Socioeconomics with Human Mobility Data"><a href=https://arxiv.org/abs/2601.15977v1>Predicting Healthcare System Visitation Flow by Integrating Hospital Attributes and Population Socioeconomics with Human Mobility Data</a></a></li><li><a href=#unveiling-and-simulating-short-video-addiction-behaviors-via-economic-addiction-theoryhttpsarxivorgabs260115975v1 aria-label="Unveiling and Simulating Short-Video Addiction Behaviors via Economic Addiction Theory"><a href=https://arxiv.org/abs/2601.15975v1>Unveiling and Simulating Short-Video Addiction Behaviors via Economic Addiction Theory</a></a></li></ul></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=weekly-paper-notes>Weekly Paper Notes<a hidden class=anchor aria-hidden=true href=#weekly-paper-notes>#</a></h1><h2 id=-multilingual>üîç multilingual<a hidden class=anchor aria-hidden=true href=#-multilingual>#</a></h2><h3 id=improving-training-efficiency-and-reducing-maintenance-costs-via-language-specific-model-merginghttpsarxivorgabs260116127v1><a href=https://arxiv.org/abs/2601.16127v1>Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging</a><a hidden class=anchor aria-hidden=true href=#improving-training-efficiency-and-reducing-maintenance-costs-via-language-specific-model-merginghttpsarxivorgabs260116127v1>#</a></h3><p><strong>Authors:</strong> Alphaeus Dmonte, Vidhi Gupta, Daniel J Perry, Mark Arehart
<strong>Venue:</strong> arXiv (2026)</p><p>Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16127v1">üìÑ Download PDF</a></p><hr><h3 id=adapter-fusion-for-multilingual-text2cypher-with-linear-and-learned-gatinghttpsarxivorgabs260116097v1><a href=https://arxiv.org/abs/2601.16097v1>Adapter Fusion for Multilingual Text2Cypher with Linear and Learned Gating</a><a hidden class=anchor aria-hidden=true href=#adapter-fusion-for-multilingual-text2cypher-with-linear-and-learned-gatinghttpsarxivorgabs260116097v1>#</a></h3><p><strong>Authors:</strong> Makbule Gulcin Ozsoy
<strong>Venue:</strong> arXiv (2026)</p><p>Large Language Models enable users to access database using natural language interfaces using tools like Text2SQL, Text2SPARQL, and Text2Cypher, which translate user questions into structured database queries. While these systems improve database accessibility, most research focuses on English with limited multilingual support. This work investigates a scalable multilingual Text2Cypher, aiming to support new languages without re-running full fine-tuning, avoiding manual hyper-parameter tuning, and maintaining performance close to joint multilingual fine-tuning. We train language-specific LoRA adapters for English, Spanish, and Turkish and combined them via uniform linear merging or learned fusion MLP with dynamic gating. Experimental results show that the fusion MLP recovers around 75% of the accuracy gains from joint multilingual fine-tuning while requiring only a smaller subset of the data, outperforming linear merging across all three languages. This approach enables incremental language expansion to new languages by requiring only one LoRA adapter and a lightweight MLP retraining. Learned adapter fusion offers a practical alternative to expensive joint fine-tuning, balancing performance, data efficiency, and scalability for multilingual Text2Cypher task.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16097v1">üìÑ Download PDF</a></p><hr><h3 id=timbre-aware-llm-based-direct-speech-to-speech-translation-extendable-to-multiple-language-pairshttpsarxivorgabs260116023v1><a href=https://arxiv.org/abs/2601.16023v1>Timbre-Aware LLM-based Direct Speech-to-Speech Translation Extendable to Multiple Language Pairs</a><a hidden class=anchor aria-hidden=true href=#timbre-aware-llm-based-direct-speech-to-speech-translation-extendable-to-multiple-language-pairshttpsarxivorgabs260116023v1>#</a></h3><p><strong>Authors:</strong> Lalaram Arya, Mrinmoy Bhattacharjee, Adarsh C. R., S. R. Mahadeva Prasanna
<strong>Venue:</strong> arXiv (2026)</p><p>Direct Speech-to-Speech Translation (S2ST) has gained increasing attention for its ability to translate speech from one language to another, while reducing error propagation and latency inherent in traditional cascaded pipelines. However, existing direct S2ST systems continue to face notable challenges, including instability in semantic-acoustic alignment when parallel speech data is scarce, difficulty in preserving speaker identity, and limited multilingual scalability. In this work, we introduce DS2ST-LM, a scalable, single-stage direct S2ST framework leveraging a multilingual Large Language Model (LLM). The architecture integrates a Whisper speech encoder, a learnable projection module, a Qwen2-0.5B LLM, and a timbre-controlled vocoder. We construct GigaS2S-1000, a 1000-hour bilingual corpus by extending the GigaST dataset with high-fidelity synthetic target speech, and show that this synthetic data alleviates data scarcity to some extent. We investigate two semantic token generation strategies: speech-derived S3 tokens and text-derived tokens generated by a pre-trained LLM, and analyze their impact on training stability and semantic consistency. We further evaluate three projection architectures (Linear, Conv1D-Linear, and Q-Former) and observe that while higher-capacity projectors converge faster, the simple Linear projector achieves higher performance. Extensive experiments demonstrate that DS2ST-LM outperforms traditional cascaded and ST (Qwen-Audio) + TTS baselines across both lexical (BLEU, METEOR) and semantic (BLEURT, COMET) metrics, while extending to multiple language pairs, including French, Spanish, German, Hindi, Bengali, and Urdu. Furthermore, we incorporate timbre-aware speech synthesis to preserve speaker information, enabling DS2ST-LM to surpass prior direct S2ST systems in both speaker similarity and perceptual naturalness.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16023v1">üìÑ Download PDF</a></p><hr><h3 id=determinants-of-training-corpus-size-for-clinical-text-classificationhttpsarxivorgabs260115846v1><a href=https://arxiv.org/abs/2601.15846v1>Determinants of Training Corpus Size for Clinical Text Classification</a><a hidden class=anchor aria-hidden=true href=#determinants-of-training-corpus-size-for-clinical-text-classificationhttpsarxivorgabs260115846v1>#</a></h3><p><strong>Authors:</strong> Jaya Chaturvedi, Saniya Deshpande, Chenkai Ma, Robert Cobb, Angus Roberts, Robert Stewart, Daniel Stahl, Diana Shamsutdinova
<strong>Venue:</strong> arXiv (2026)</p><p>Introduction: Clinical text classification using natural language processing (NLP) models requires adequate training data to achieve optimal performance. For that, 200-500 documents are typically annotated. The number is constrained by time and costs and lacks justification of the sample size requirements and their relationship to text vocabulary properties.
Methods: Using the publicly available MIMIC-III dataset containing hospital discharge notes with ICD-9 diagnoses as labels, we employed pre-trained BERT embeddings followed by Random Forest classifiers to identify 10 randomly selected diagnoses, varying training corpus sizes from 100 to 10,000 documents, and analyzed vocabulary properties by identifying strong and noisy predictive words through Lasso logistic regression on bag-of-words embeddings.
Results: Learning curves varied significantly across the 10 classification tasks despite identical preprocessing and algorithms, with 600 documents sufficient to achieve 95% of the performance attainable with 10,000 documents for all tasks. Vocabulary analysis revealed that more strong predictors and fewer noisy predictors were associated with steeper learning curves, where every 100 additional noisy words decreased accuracy by approximately 0.02 while 100 additional strong predictors increased maximum accuracy by approximately 0.04.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15846v1">üìÑ Download PDF</a></p><hr><h3 id=steereval-inference-time-interventions-strengthen-multilingual-generalization-in-neural-summarization-metricshttpsarxivorgabs260115809v1><a href=https://arxiv.org/abs/2601.15809v1>SteerEval: Inference-time Interventions Strengthen Multilingual Generalization in Neural Summarization Metrics</a><a hidden class=anchor aria-hidden=true href=#steereval-inference-time-interventions-strengthen-multilingual-generalization-in-neural-summarization-metricshttpsarxivorgabs260115809v1>#</a></h3><p><strong>Authors:</strong> Silvia Casola, Ryan Soh-Eun Shim, Felicia K√∂rner, Yuchen Mao, Barbara Plank
<strong>Venue:</strong> arXiv (2026)</p><p>An increasing body of work has leveraged multilingual language models for Natural Language Generation tasks such as summarization. A major empirical bottleneck in this area is the shortage of accurate and robust evaluation metrics for many languages, which hinders progress. Recent studies suggest that multilingual language models often use English as an internal pivot language, and that misalignment with this pivot can lead to degraded downstream performance. Motivated by the hypothesis that this mismatch could also apply to multilingual neural metrics, we ask whether steering their activations toward an English pivot can improve correlation with human judgments. We experiment with encoder- and decoder-based metrics and find that test-time intervention methods are effective across the board, increasing metric effectiveness for diverse languages.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15809v1">üìÑ Download PDF</a></p><hr><h3 id=improving-methodologies-for-llm-evaluations-across-global-languageshttpsarxivorgabs260115706v1><a href=https://arxiv.org/abs/2601.15706v1>Improving Methodologies for LLM Evaluations Across Global Languages</a><a hidden class=anchor aria-hidden=true href=#improving-methodologies-for-llm-evaluations-across-global-languageshttpsarxivorgabs260115706v1>#</a></h3><p><strong>Authors:</strong> Akriti Vij, Benjamin Chua, Darshini Ramiah, En Qi Ng, Mahran Morsidi, Naga Nikshith Gangarapu, Sharmini Johnson, Vanessa Wilfred, Vikneswaran Kumaran, Wan Sie Lee, Wenzhuo Yang, Yongsen Zheng, Bill Black, Boming Xia, Frank Sun, Hao Zhang, Qinghua Lu, Suyu Ma, Yue Liu, Chi-kiu Lo, Fatemeh Azadi, Isar Nejadgholi, Sowmya Vajjala, Agnes Delaborde, Nicolas Rolin, Tom Seimandi, Akiko Murakami, Haruto Ishi, Satoshi Sekine, Takayuki Semitsu, Tasuku Sasaki, Angela Kinuthia, Jean Wangari, Michael Michie, Stephanie Kasaon, Hankyul Baek, Jaewon Noh, Kihyuk Nam, Sang Seo, Sungpil Shin, Taewhi Lee, Yongsu Kim, Daisy Newbold-Harrop, Jessica Wang, Mahmoud Ghanem, Vy Hong
<strong>Venue:</strong> arXiv (2026)</p><p>As frontier AI models are deployed globally, it is essential that their behaviour remains safe and reliable across diverse linguistic and cultural contexts. To examine how current model safeguards hold up in such settings, participants from the International Network for Advanced AI Measurement, Evaluation and Science, including representatives from Singapore, Japan, Australia, Canada, the EU, France, Kenya, South Korea and the UK conducted a joint multilingual evaluation exercise. Led by Singapore AISI, two open-weight models were tested across ten languages spanning high and low resourced groups: Cantonese English, Farsi, French, Japanese, Korean, Kiswahili, Malay, Mandarin Chinese and Telugu. Over 6,000 newly translated prompts were evaluated across five harm categories (privacy, non-violent crime, violent crime, intellectual property and jailbreak robustness), using both LLM-as-a-judge and human annotation.
The exercise shows how safety behaviours can vary across languages. These include differences in safeguard robustness across languages and harm types and variation in evaluator reliability (LLM-as-judge vs. human review). Further, it also generated methodological insights for improving multilingual safety evaluations, such as the need for culturally contextualised translations, stress-tested evaluator prompts and clearer human annotation guidelines. This work represents an initial step toward a shared framework for multilingual safety testing of advanced AI systems and calls for continued collaboration with the wider research community and industry.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15706v1">üìÑ Download PDF</a></p><hr><h3 id=obscuring-data-contamination-through-translation-evidence-from-arabic-corporahttpsarxivorgabs260114994v1><a href=https://arxiv.org/abs/2601.14994v1>Obscuring Data Contamination Through Translation: Evidence from Arabic Corpora</a><a hidden class=anchor aria-hidden=true href=#obscuring-data-contamination-through-translation-evidence-from-arabic-corporahttpsarxivorgabs260114994v1>#</a></h3><p><strong>Authors:</strong> Chaymaa Abbas, Nour Shamaa, Mariette Awad
<strong>Venue:</strong> arXiv (2026)</p><p>Data contamination undermines the validity of Large Language Model evaluation by enabling models to rely on memorized benchmark content rather than true generalization. While prior work has proposed contamination detection methods, these approaches are largely limited to English benchmarks, leaving multilingual contamination poorly understood. In this work, we investigate contamination dynamics in multilingual settings by fine-tuning several open-weight LLMs on varying proportions of Arabic datasets and evaluating them on original English benchmarks. To detect memorization, we extend the Tested Slot Guessing method with a choice-reordering strategy and incorporate Min-K% probability analysis, capturing both behavioral and distributional contamination signals.
Our results show that translation into Arabic suppresses conventional contamination indicators, yet models still benefit from exposure to contaminated data, particularly those with stronger Arabic capabilities. This effect is consistently reflected in rising Mink% scores and increased cross-lingual answer consistency as contamination levels grow. To address this blind spot, we propose Translation-Aware Contamination Detection, which identifies contamination by comparing signals across multiple translated benchmark variants rather than English alone. The Translation-Aware Contamination Detection reliably exposes contamination even when English-only methods fail. Together, our findings highlight the need for multilingual, translation-aware evaluation pipelines to ensure fair, transparent, and reproducible assessment of LLMs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.14994v1">üìÑ Download PDF</a></p><hr><h3 id=prism-benchmarking-phone-realization-in-speech-modelshttpsarxivorgabs260114046v1><a href=https://arxiv.org/abs/2601.14046v1>PRiSM: Benchmarking Phone Realization in Speech Models</a><a hidden class=anchor aria-hidden=true href=#prism-benchmarking-phone-realization-in-speech-modelshttpsarxivorgabs260114046v1>#</a></h3><p><strong>Authors:</strong> Shikhar Bharadwaj, Chin-Jou Li, Yoonjae Kim, Kwanghee Choi, Eunjung Yeo, Ryan Soh-Eun Shim, Hanyu Zhou, Brendon Boldt, Karen Rosero Jacome, Kalvin Chang, Darsh Agrawal, Keer Xu, Chao-Han Huck Yang, Jian Zhu, Shinji Watanabe, David R. Mortensen
<strong>Venue:</strong> arXiv (2026)</p><p>Phone recognition (PR) serves as the atomic interface for language-agnostic modeling for cross-lingual speech processing and phonetic analysis. Despite prolonged efforts in developing PR systems, current evaluations only measure surface-level transcription accuracy. We introduce PRiSM, the first open-source benchmark designed to expose blind spots in phonetic perception through intrinsic and extrinsic evaluation of PR systems. PRiSM standardizes transcription-based evaluation and assesses downstream utility in clinical, educational, and multilingual settings with transcription and representation probes. We find that diverse language exposure during training is key to PR performance, encoder-CTC models are the most stable, and specialized PR models still outperform Large Audio Language Models. PRiSM releases code, recipes, and datasets to move the field toward multilingual speech models with robust phonetic ability: <a href=https://github.com/changelinglab/prism>https://github.com/changelinglab/prism</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.14046v1">üìÑ Download PDF</a></p><hr><h3 id=a-shared-geometry-of-difficulty-in-multilingual-language-modelshttpsarxivorgabs260112731v1><a href=https://arxiv.org/abs/2601.12731v1>A Shared Geometry of Difficulty in Multilingual Language Models</a><a hidden class=anchor aria-hidden=true href=#a-shared-geometry-of-difficulty-in-multilingual-language-modelshttpsarxivorgabs260112731v1>#</a></h3><p><strong>Authors:</strong> Stefano Civelli, Pietro Bernardelle, Nicol√≤ Brunello, Gianluca Demartini
<strong>Venue:</strong> arXiv (2026)</p><p>Predicting problem-difficulty in large language models (LLMs) refers to estimating how difficult a task is according to the model itself, typically by training linear probes on its internal representations. In this work, we study the multilingual geometry of problem-difficulty in LLMs by training linear probes using the AMC subset of the Easy2Hard benchmark, translated into 21 languages. We found that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow (early-layers) and deep (later-layers) internal representations, that exhibit functionally different behaviors. Probes trained on deep representations achieve high accuracy when evaluated on the same language but exhibit poor cross-lingual generalization. In contrast, probes trained on shallow representations generalize substantially better across languages, despite achieving lower within-language performance. Together, these results suggest that LLMs first form a language-agnostic representation of problem difficulty, which subsequently becomes language-specific. This closely aligns with existing findings in LLM interpretability showing that models tend to operate in an abstract conceptual space before producing language-specific outputs. We demonstrate that this two-stage representational process extends beyond semantic content to high-level meta-cognitive properties such as problem-difficulty estimation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.12731v1">üìÑ Download PDF</a></p><hr><h3 id=ubuntuguard-a-culturally-grounded-policy-benchmark-for-equitable-ai-safety-in-african-languageshttpsarxivorgabs260112696v1><a href=https://arxiv.org/abs/2601.12696v1>UbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages</a><a hidden class=anchor aria-hidden=true href=#ubuntuguard-a-culturally-grounded-policy-benchmark-for-equitable-ai-safety-in-african-languageshttpsarxivorgabs260112696v1>#</a></h3><p><strong>Authors:</strong> Tassallah Abdullahi, Macton Mgonzo, Mardiyyah Oduwole, Paul Okewunmi, Abraham Owodunni, Ritambhara Singh, Carsten Eickhoff
<strong>Venue:</strong> arXiv (2026)</p><p>Current guardian models are predominantly Western-centric and optimized for high-resource languages, leaving low-resource African languages vulnerable to evolving harms, cross-lingual safety failures, and cultural misalignment. Moreover, most guardian models rely on rigid, predefined safety categories that fail to generalize across diverse linguistic and sociocultural contexts. Robust safety, therefore, requires flexible, runtime-enforceable policies and benchmarks that reflect local norms, harm scenarios, and cultural expectations. We introduce UbuntuGuard, the first African policy-based safety benchmark built from adversarial queries authored by 155 domain experts across sensitive fields, including healthcare. From these expert-crafted queries, we derive context-specific safety policies and reference responses that capture culturally grounded risk signals, enabling policy-aligned evaluation of guardian models. We evaluate 13 models, comprising six general-purpose LLMs and seven guardian models across three distinct variants: static, dynamic, and multilingual. Our findings reveal that existing English-centric benchmarks overestimate real-world multilingual safety, cross-lingual transfer provides partial but insufficient coverage, and dynamic models, while better equipped to leverage policies at inference time, still struggle to fully localize African-language contexts. These findings highlight the urgent need for multilingual, culturally grounded safety benchmarks to enable the development of reliable and equitable guardian models for low-resource languages. Our code can be found online.\footnote{Code repository available at <a href=https://github.com/hemhemoh/UbuntuGuard>https://github.com/hemhemoh/UbuntuGuard</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.12696v1">üìÑ Download PDF</a></p><hr><h3 id=benchmarking-concept-spilling-across-languages-in-llmshttpsarxivorgabs260112549v1><a href=https://arxiv.org/abs/2601.12549v1>Benchmarking Concept-Spilling Across Languages in LLMs</a><a hidden class=anchor aria-hidden=true href=#benchmarking-concept-spilling-across-languages-in-llmshttpsarxivorgabs260112549v1>#</a></h3><p><strong>Authors:</strong> Ilia Badanin, Daniil Dzenhaliou, Imanol Schlag
<strong>Venue:</strong> arXiv (2026)</p><p>Multilingual Large Language Models (LLMs) exhibit remarkable cross-lingual abilities, yet often exhibit a systematic bias toward the representations from other languages, resulting in semantic interference when generating content in non-English languages$-$a phenomenon we define as language spilling. This paper presents a novel comparative framework for evaluating multilingual semantic robustness by systematically measuring how models handle polysemous words across languages. Our methodology provides a relative measure of model performance: when required to generate exactly five meanings, both strong and weak models may resort to meanings from dominant languages, but semantically stronger models do so later in the generation sequence, producing more true meanings from the target language before failing, while weaker models resort to dominant-language meanings earlier in the sequence. We evaluate a diverse set of open and closed multilingual LLMs using a structured meaning generation task across nine languages, employing a carefully curated benchmark of 100 high-polysemy English words. Our findings reveal significant variation in semantic robustness across both models and languages, providing a principled ranking system for model comparison without requiring definitive causal attribution of error sources. We contribute both a scalable comparative benchmark for multilingual semantic evaluation and a rigorous validation pipeline$-$critical tools for developing more linguistically balanced AI systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.12549v1">üìÑ Download PDF</a></p><hr><h3 id=cogtom-a-comprehensive-theory-of-mind-benchmark-inspired-by-human-cognition-for-large-language-modelshttpsarxivorgabs260115628v1><a href=https://arxiv.org/abs/2601.15628v1>CogToM: A Comprehensive Theory of Mind Benchmark inspired by Human Cognition for Large Language Models</a><a hidden class=anchor aria-hidden=true href=#cogtom-a-comprehensive-theory-of-mind-benchmark-inspired-by-human-cognition-for-large-language-modelshttpsarxivorgabs260115628v1>#</a></h3><p><strong>Authors:</strong> Haibo Tong, Zeyang Yue, Feifei Zhao, Erliang Lin, Lu Jia, Ruolin Chen, Yinqian Sun, Qian Zhang, Yi Zeng
<strong>Venue:</strong> arXiv (2026)</p><p>Whether Large Language Models (LLMs) truly possess human-like Theory of Mind (ToM) capabilities has garnered increasing attention. However, existing benchmarks remain largely restricted to narrow paradigms like false belief tasks, failing to capture the full spectrum of human cognitive mechanisms. We introduce CogToM, a comprehensive, theoretically grounded benchmark comprising over 8000 bilingual instances across 46 paradigms, validated by 49 human annotator.A systematic evaluation of 22 representative models, including frontier models like GPT-5.1 and Qwen3-Max, reveals significant performance heterogeneities and highlights persistent bottlenecks in specific dimensions. Further analysis based on human cognitive patterns suggests potential divergences between LLM and human cognitive structures. CogToM offers a robust instrument and perspective for investigating the evolving cognitive boundaries of LLMs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15628v1">üìÑ Download PDF</a></p><hr><h3 id=the-dark-side-of-ai-transformers-sentiment-polarization--the-loss-of-business-neutrality-by-nlp-transformershttpsarxivorgabs260115509v1><a href=https://arxiv.org/abs/2601.15509v1>The Dark Side of AI Transformers: Sentiment Polarization & the Loss of Business Neutrality by NLP Transformers</a><a hidden class=anchor aria-hidden=true href=#the-dark-side-of-ai-transformers-sentiment-polarization--the-loss-of-business-neutrality-by-nlp-transformershttpsarxivorgabs260115509v1>#</a></h3><p><strong>Authors:</strong> Prasanna Kumar
<strong>Venue:</strong> arXiv (2026)</p><p>The use of Transfer Learning & Transformers has steadily improved accuracy and has significantly contributed in solving complex computation problems. However, this transformer led accuracy improvement in Applied AI Analytics specifically in sentiment analytics comes with the dark side. It is observed during experiments that a lot of these improvements in transformer led accuracy of one class of sentiment has been at the cost of polarization of another class of sentiment and the failing of neutrality. This lack of neutrality poses an acute problem in the Applied NLP space, which relies heavily on the computational outputs of sentiment analytics for reliable industry ready tasks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15509v1">üìÑ Download PDF</a></p><hr><h3 id=the-gdn-cc-dataset-automatic-corpus-clarification-for-ai-enhanced-democratic-citizen-consultationshttpsarxivorgabs260114944v2><a href=https://arxiv.org/abs/2601.14944v2>The GDN-CC Dataset: Automatic Corpus Clarification for AI-enhanced Democratic Citizen Consultations</a><a hidden class=anchor aria-hidden=true href=#the-gdn-cc-dataset-automatic-corpus-clarification-for-ai-enhanced-democratic-citizen-consultationshttpsarxivorgabs260114944v2>#</a></h3><p><strong>Authors:</strong> Pierre-Antoine Lequeu, L√©o Labat, Laur√®ne Cave, Ga√´l Lejeune, Fran√ßois Yvon, Benjamin Piwowarski
<strong>Venue:</strong> arXiv (2026)</p><p>LLMs are ubiquitous in modern NLP, and while their applicability extends to texts produced for democratic activities such as online deliberations or large-scale citizen consultations, ethical questions have been raised for their usage as analysis tools. We continue this line of research with two main goals: (a) to develop resources that can help standardize citizen contributions in public forums at the pragmatic level, and make them easier to use in topic modeling and political analysis; (b) to study how well this standardization can reliably be performed by small, open-weights LLMs, i.e. models that can be run locally and transparently with limited resources. Accordingly, we introduce Corpus Clarification as a preprocessing framework for large-scale consultation data that transforms noisy, multi-topic contributions into structured, self-contained argumentative units ready for downstream analysis. We present GDN-CC, a manually-curated dataset of 1,231 contributions to the French Grand D√©bat National, comprising 2,285 argumentative units annotated for argumentative structure and manually clarified. We then show that finetuned Small Language Models match or outperform LLMs on reproducing these annotations, and measure their usability for an opinion clustering task. We finally release GDN-CC-large, an automatically annotated corpus of 240k contributions, the largest annotated democratic consultation dataset to date.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.14944v2">üìÑ Download PDF</a></p><hr><h3 id=recap-resistance-capture-in-text-based-mental-health-counseling-with-large-language-modelshttpsarxivorgabs260114780v1><a href=https://arxiv.org/abs/2601.14780v1>RECAP: Resistance Capture in Text-based Mental Health Counseling with Large Language Models</a><a hidden class=anchor aria-hidden=true href=#recap-resistance-capture-in-text-based-mental-health-counseling-with-large-language-modelshttpsarxivorgabs260114780v1>#</a></h3><p><strong>Authors:</strong> Anqi Li, Yuqian Chen, Yu Lu, Zhaoming Chen, Yuan Xie, Zhenzhong Lan
<strong>Venue:</strong> arXiv (2026)</p><p>Recognizing and navigating client resistance is critical for effective mental health counseling, yet detecting such behaviors is particularly challenging in text-based interactions. Existing NLP approaches oversimplify resistance categories, ignore the sequential dynamics of therapeutic interventions, and offer limited interpretability.
To address these limitations, we propose PsyFIRE, a theoretically grounded framework capturing 13 fine-grained resistance behaviors alongside collaborative interactions. Based on PsyFIRE, we construct the ClientResistance corpus with 23,930 annotated utterances from real-world Chinese text-based counseling, each supported by context-specific rationales. Leveraging this dataset, we develop RECAP, a two-stage framework that detects resistance and fine-grained resistance types with explanations.
RECAP achieves 91.25% F1 for distinguishing collaboration and resistance and 66.58% macro-F1 for fine-grained resistance categories classification, outperforming leading prompt-based LLM baselines by over 20 points. Applied to a separate counseling dataset and a pilot study with 62 counselors, RECAP reveals the prevalence of resistance, its negative impact on therapeutic relationships and demonstrates its potential to improve counselors&rsquo; understanding and intervention strategies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.14780v1">üìÑ Download PDF</a></p><hr><h3 id=cure-med-curriculum-informed-reinforcement-learning-for-multilingual-medical-reasoninghttpsarxivorgabs260113262v1><a href=https://arxiv.org/abs/2601.13262v1>CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning</a><a hidden class=anchor aria-hidden=true href=#cure-med-curriculum-informed-reinforcement-learning-for-multilingual-medical-reasoninghttpsarxivorgabs260113262v1>#</a></h3><p><strong>Authors:</strong> Eric Onyame, Akash Ghosh, Subhadip Baidya, Sriparna Saha, Xiuying Chen, Chirag Agarwal
<strong>Venue:</strong> arXiv (2026)</p><p>While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at <a href=https://cure-med.github.io/>https://cure-med.github.io/</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.13262v1">üìÑ Download PDF</a></p><hr><h3 id=think3d-thinking-with-space-for-spatial-reasoninghttpsarxivorgabs260113029v1><a href=https://arxiv.org/abs/2601.13029v1>Think3D: Thinking with Space for Spatial Reasoning</a><a hidden class=anchor aria-hidden=true href=#think3d-thinking-with-space-for-spatial-reasoninghttpsarxivorgabs260113029v1>#</a></h3><p><strong>Authors:</strong> Zaibin Zhang, Yuhan Wu, Lianjie Jia, Yifan Wang, Zhongbo Zhang, Yijiang Li, Binghao Ran, Fuxi Zhang, Zhuohan Sun, Zhenfei Yin, Lijun Wang, Huchuan Lu
<strong>Venue:</strong> arXiv (2026)</p><p>Understanding and reasoning about the physical world requires spatial intelligence: the ability to interpret geometry, perspective, and spatial relations beyond 2D perception. While recent vision large models (VLMs) excel at visual understanding, they remain fundamentally 2D perceivers and struggle with genuine 3D reasoning. We introduce Think3D, a framework that enables VLM agents to think with 3D space. By leveraging 3D reconstruction models that recover point clouds and camera poses from images or videos, Think3D allows the agent to actively manipulate space through camera-based operations and ego/global-view switching, transforming spatial reasoning into an interactive 3D chain-of-thought process. Without additional training, Think3D significantly improves the spatial reasoning performance of advanced models such as GPT-4.1 and Gemini 2.5 Pro, yielding average gains of +7.8% on BLINK Multi-view and MindCube, and +4.7% on VSI-Bench. We further show that smaller models, which struggle with spatial exploration, benefit significantly from a reinforcement learning policy that enables the model to select informative viewpoints and operations. With RL, the benefit from tool usage increases from +0.7% to +6.8%. Our findings demonstrate that training-free, tool-augmented spatial exploration is a viable path toward more flexible and human-like 3D reasoning in multimodal agents, establishing a new dimension of multimodal intelligence. Code and weights are released at <a href=https://github.com/zhangzaibin/spagent>https://github.com/zhangzaibin/spagent</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.13029v1">üìÑ Download PDF</a></p><hr><h3 id=static-detection-of-core-structures-in-tigress-virtualization-based-obfuscation-using-an-llvm-passhttpsarxivorgabs260112916v1><a href=https://arxiv.org/abs/2601.12916v1>Static Detection of Core Structures in Tigress Virtualization-Based Obfuscation Using an LLVM Pass</a><a hidden class=anchor aria-hidden=true href=#static-detection-of-core-structures-in-tigress-virtualization-based-obfuscation-using-an-llvm-passhttpsarxivorgabs260112916v1>#</a></h3><p><strong>Authors:</strong> Sangjun An, Seoksu Lee, Eun-Sun Cho
<strong>Venue:</strong> arXiv (2026)</p><p>Malware often uses obfuscation to hinder security analysis. Among these techniques, virtualization-based obfuscation is particularly strong because it protects programs by translating original instructions into attacker-defined virtual machine (VM) bytecode, producing long and complex code that is difficult to analyze and deobfuscate. This paper aims to identify the structural components of virtualization-based obfuscation through static analysis. By examining the execution model of obfuscated code, we define and detect the key elements required for deobfuscation-namely the dispatch routine, handler blocks, and the VM region-using LLVM IR. Experimental results show that, in the absence of compiler optimizations, the proposed LLVM Pass successfully detects all core structures across major virtualization options, including switch, direct, and indirect modes.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.12916v1">üìÑ Download PDF</a></p><hr><h3 id=towards-robust-universal-perturbation-attacks-a-float-coded-penalty-driven-evolutionary-approachhttpsarxivorgabs260112624v1><a href=https://arxiv.org/abs/2601.12624v1>Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach</a><a hidden class=anchor aria-hidden=true href=#towards-robust-universal-perturbation-attacks-a-float-coded-penalty-driven-evolutionary-approachhttpsarxivorgabs260112624v1>#</a></h3><p><strong>Authors:</strong> Shiqi Wang, Mahdi Khosravy, Neeraj Gupta, Olaf Witkowski
<strong>Venue:</strong> arXiv (2026)</p><p>Universal adversarial perturbations (UAPs) have garnered significant attention due to their ability to undermine deep neural networks across multiple inputs using a single noise pattern. Evolutionary algorithms offer a promising approach to generating such perturbations due to their ability to navigate non-convex, gradient-free landscapes. In this work, we introduce a float-coded, penalty-driven single-objective evolutionary framework for UAP generation that achieves lower visibility perturbations while enhancing attack success rates. Our approach leverages continuous gene representations aligned with contemporary deep learning scales, incorporates dynamic evolutionary operators with adaptive scheduling, and utilizes a modular PyTorch implementation for seamless integration with modern architectures. Additionally, we ensure the universality of the generated perturbations by testing across diverse models and by periodically switching batches to prevent overfitting. Experimental results on the ImageNet dataset demonstrate that our framework consistently produces perturbations with smaller norms, higher misclassification effectiveness, and faster convergence compared to existing evolutionary-based methods. These findings highlight the robustness and scalability of our approach for universal adversarial attacks across various deep learning architectures.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.12624v1">üìÑ Download PDF</a></p><hr><h3 id=nlp-based-review-for-toxic-comment-detection-tailored-to-the-chinese-cyberspacehttpsarxivorgabs260114721v1><a href=https://arxiv.org/abs/2601.14721v1>NLP-Based Review for Toxic Comment Detection Tailored to the Chinese Cyberspace</a><a hidden class=anchor aria-hidden=true href=#nlp-based-review-for-toxic-comment-detection-tailored-to-the-chinese-cyberspacehttpsarxivorgabs260114721v1>#</a></h3><p><strong>Authors:</strong> Ruixing Ren, Junhui Zhao, Xiaoke Sun, Qiuping Li
<strong>Venue:</strong> arXiv (2026)</p><p>With the in-depth integration of mobile Internet and widespread adoption of social platforms, user-generated content in the Chinese cyberspace has witnessed explosive growth. Among this content, the proliferation of toxic comments poses severe challenges to individual mental health, community atmosphere and social trust. Owing to the strong context dependence, cultural specificity and rapid evolution of Chinese cyber language, toxic expressions are often conveyed through complex forms such as homophones and metaphors, imposing notable limitations on traditional detection methods. To address this issue, this review focuses on the core topic of natural language processing based toxic comment detection in the Chinese cyberspace, systematically collating and critically analyzing the research progress and key challenges in this field. This review first defines the connotation and characteristics of Chinese toxic comments, and analyzes the platform ecology and transmission mechanisms they rely on. It then comprehensively reviews the construction methods and limitations of existing public datasets, and proposes a novel fine-grained and scalable framework for toxic comment definition and classification, along with corresponding data annotation and quality assessment strategies. We systematically summarize the evolutionary path of detection models from traditional methods to deep learning, with special emphasis on the importance of interpretability in model design. Finally, we thoroughly discuss the open challenges faced by current research and provide forward-looking suggestions for future research directions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.14721v1">üìÑ Download PDF</a></p><hr><h3 id=variance-adaptive-muon-accelerating-llm-pretraining-with-nsr-modulated-and-variance-scaled-momentumhttpsarxivorgabs260114603v1><a href=https://arxiv.org/abs/2601.14603v1>Variance-Adaptive Muon: Accelerating LLM Pretraining with NSR-Modulated and Variance-Scaled Momentum</a><a hidden class=anchor aria-hidden=true href=#variance-adaptive-muon-accelerating-llm-pretraining-with-nsr-modulated-and-variance-scaled-momentumhttpsarxivorgabs260114603v1>#</a></h3><p><strong>Authors:</strong> Jingru Li, Yibo Fan, Huan Li
<strong>Venue:</strong> arXiv (2026)</p><p>Large Language Models (LLMs) achieve competitive performance across diverse natural language processing (NLP) tasks, yet pretraining is computationally demanding, making optimizer efficiency an important practical consideration. Muon accelerates LLM pretraining via orthogonal momentum updates that serve as a matrix analogue of the element-wise sign operator. Motivated by the recent perspective that Adam is a variance-adaptive sign update algorithm, we propose two variants of Muon, Muon-NSR and Muon-VS, which apply variance-adaptive normalization to momentum before orthogonalization. Muon-NSR applies noise-to-signal ratio (NSR) modulation, while Muon-VS performs variance-based scaling without introducing additional hyperparameters. Experiments on GPT-2 and LLaMA pretraining demonstrate that our proposed methods accelerate convergence and consistently achieve lower validation loss than both competitive, well-tuned AdamW and Muon baselines. For example, on the LLaMA-1.2B model, Muon-NSR and Muon-VS reduce the iterations required to reach the target validation loss by $1.36\times$ relative to the well-tuned Muon following the recent benchmark.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.14603v1">üìÑ Download PDF</a></p><hr><h3 id=point-bridge-3d-representations-for-cross-domain-policy-learninghttpsarxivorgabs260116212v1><a href=https://arxiv.org/abs/2601.16212v1>Point Bridge: 3D Representations for Cross Domain Policy Learning</a><a hidden class=anchor aria-hidden=true href=#point-bridge-3d-representations-for-cross-domain-policy-learninghttpsarxivorgabs260116212v1>#</a></h3><p><strong>Authors:</strong> Siddhant Haldar, Lars Johannsmeier, Lerrel Pinto, Abhishek Gupta, Dieter Fox, Yashraj Narang, Ajay Mandlekar
<strong>Venue:</strong> arXiv (2026)</p><p>Robot foundation models are beginning to deliver on the promise of generalist robotic agents, yet progress remains constrained by the scarcity of large-scale real-world manipulation datasets. Simulation and synthetic data generation offer a scalable alternative, but their usefulness is limited by the visual domain gap between simulation and reality. In this work, we present Point Bridge, a framework that leverages unified, domain-agnostic point-based representations to unlock synthetic datasets for zero-shot sim-to-real policy transfer, without explicit visual or object-level alignment. Point Bridge combines automated point-based representation extraction via Vision-Language Models (VLMs), transformer-based policy learning, and efficient inference-time pipelines to train capable real-world manipulation agents using only synthetic data. With additional co-training on small sets of real demonstrations, Point Bridge further improves performance, substantially outperforming prior vision-based sim-and-real co-training methods. It achieves up to 44% gains in zero-shot sim-to-real transfer and up to 66% with limited real data across both single-task and multitask settings. Videos of the robot are best viewed at: <a href=https://pointbridge3d.github.io/>https://pointbridge3d.github.io/</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16212v1">üìÑ Download PDF</a></p><hr><h3 id=pyratok-language-aligned-pyramidal-tokenizer-for-video-understanding-and-generationhttpsarxivorgabs260116210v1><a href=https://arxiv.org/abs/2601.16210v1>PyraTok: Language-Aligned Pyramidal Tokenizer for Video Understanding and Generation</a><a hidden class=anchor aria-hidden=true href=#pyratok-language-aligned-pyramidal-tokenizer-for-video-understanding-and-generationhttpsarxivorgabs260116210v1>#</a></h3><p><strong>Authors:</strong> Onkar Susladkar, Tushar Prakash, Adheesh Juvekar, Kiet A. Nguyen, Dong-Hwan Jang, Inderjit S Dhillon, Ismini Lourentzou
<strong>Venue:</strong> arXiv (2026)</p><p>Discrete video VAEs underpin modern text-to-video generation and video understanding systems, yet existing tokenizers typically learn visual codebooks at a single scale with limited vocabularies and shallow language supervision, leading to poor cross-modal alignment and zero-shot transfer. We introduce PyraTok, a language-aligned pyramidal tokenizer that learns semantically structured discrete latents across multiple spatiotemporal resolutions. PyraTok builds on a pretrained video VAE and a novel Language aligned Pyramidal Quantization (LaPQ) module that discretizes encoder features at several depths using a shared large binary codebook, yielding compact yet expressive video token sequences. To tightly couple visual tokens with language, PyraTok jointly optimizes multi-scale text-guided quantization and a global autoregressive objective over the token hierarchy. Across ten benchmarks, PyraTok delivers state-of-the-art (SOTA) video reconstruction, consistently improves text-to-video quality, and sets new SOTA zero-shot performance on video segmentation, temporal action localization, and video understanding, scaling robustly to up to 4K/8K resolutions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16210v1">üìÑ Download PDF</a></p><hr><h3 id=ivra-improving-visual-token-relations-for-robot-action-policy-with-training-free-hint-based-guidancehttpsarxivorgabs260116207v1><a href=https://arxiv.org/abs/2601.16207v1>IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance</a><a hidden class=anchor aria-hidden=true href=#ivra-improving-visual-token-relations-for-robot-action-policy-with-training-free-hint-based-guidancehttpsarxivorgabs260116207v1>#</a></h3><p><strong>Authors:</strong> Jongwoo Park, Kanchana Ranasinghe, Jinhyeok Jang, Cristina Mata, Yoo Sung Jang, Michael S Ryoo
<strong>Venue:</strong> arXiv (2026)</p><p>Many Vision-Language-Action (VLA) models flatten image patches into a 1D token sequence, weakening the 2D spatial cues needed for precise manipulation. We introduce IVRA, a lightweight, training-free method that improves spatial understanding by exploiting affinity hints already available in the model&rsquo;s built-in vision encoder, without requiring any external encoder or retraining. IVRA selectively injects these affinity signals into a language-model layer in which instance-level features reside. This inference-time intervention realigns visual-token interactions and better preserves geometric structure while keeping all model parameters fixed. We demonstrate the generality of IVRA by applying it to diverse VLA architectures (LLaRA, OpenVLA, and FLOWER) across simulated benchmarks spanning both 2D and 3D manipulation (VIMA and LIBERO) and on various real-robot tasks. On 2D VIMA, IVRA improves average success by +4.2% over the baseline LLaRA in a low-data regime. On 3D LIBERO, it yields consistent gains over the OpenVLA and FLOWER baselines, including improvements when baseline accuracy is near saturation (96.3% to 97.1%). All code and models will be released publicly. Visualizations are available at: jongwoopark7978.github.io/IVRA</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16207v1">üìÑ Download PDF</a></p><hr><h3 id=llm-in-sandbox-elicits-general-agentic-intelligencehttpsarxivorgabs260116206v1><a href=https://arxiv.org/abs/2601.16206v1>LLM-in-Sandbox Elicits General Agentic Intelligence</a><a hidden class=anchor aria-hidden=true href=#llm-in-sandbox-elicits-general-agentic-intelligencehttpsarxivorgabs260116206v1>#</a></h3><p><strong>Authors:</strong> Daixuan Cheng, Shaohan Huang, Yuxian Gu, Huatong Song, Guoxin Chen, Li Dong, Wayne Xin Zhao, Ji-Rong Wen, Furu Wei
<strong>Venue:</strong> arXiv (2026)</p><p>We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverage the file system to handle long contexts, and execute scripts to satisfy formatting requirements. We further show that these agentic capabilities can be enhanced through LLM-in-Sandbox Reinforcement Learning (LLM-in-Sandbox-RL), which uses only non-agentic data to train models for sandbox exploration. Experiments demonstrate that LLM-in-Sandbox, in both training-free and post-trained settings, achieves robust generalization spanning mathematics, physics, chemistry, biomedicine, long-context understanding, and instruction following. Finally, we analyze LLM-in-Sandbox&rsquo;s efficiency from computational and system perspectives, and open-source it as a Python package to facilitate real-world deployment.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16206v1">üìÑ Download PDF</a></p><hr><h3 id=provable-robustness-in-multimodal-large-language-models-via-feature-space-smoothinghttpsarxivorgabs260116200v1><a href=https://arxiv.org/abs/2601.16200v1>Provable Robustness in Multimodal Large Language Models via Feature Space Smoothing</a><a hidden class=anchor aria-hidden=true href=#provable-robustness-in-multimodal-large-language-models-via-feature-space-smoothinghttpsarxivorgabs260116200v1>#</a></h3><p><strong>Authors:</strong> Song Xia, Meiwen Ding, Chenqi Kong, Wenhan Yang, Xudong Jiang
<strong>Venue:</strong> arXiv (2026)</p><p>Multimodal large language models (MLLMs) exhibit strong capabilities across diverse applications, yet remain vulnerable to adversarial perturbations that distort their feature representations and induce erroneous predictions. To address this vulnerability, we propose the Feature-space Smoothing (FS) and theoretically prove that FS offers certified robustness on the feature representations of MLLMs. Specifically, FS transforms any feature encoder into a smoothed variant that is guaranteed to maintain a certified lower bound on the feature cosine similarity between clean and adversarial representations under $\ell_2$-bounded attacks. Moreover, we indicate that the value of this Feature Cosine Similarity Bound (FCSB) derived from FS can be improved by enlarging the defined Gaussian robustness score on the vanilla encoder. Building upon this, we introduce the Purifier and Smoothness Mapper (PSM), a plug-and-play module that improves the Gaussian robustness score of MLLMs and thus enhances their certified robustness under FS, without requiring any retraining on MLLMs. We demonstrate that the FS with PSM not only provides a strong theoretical robustness guarantee but also exhibits superior empirical performance compared to adversarial training. Extensive experiments across diverse MLLMs and downstream tasks indicate the effectiveness of the FS-PSM, reducing the Attack Success Rate (ASR) of various white-box attacks from nearly 90% to about 1%.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16200v1">üìÑ Download PDF</a></p><hr><h3 id=palm-property-attestation-for-large-generative-modelshttpsarxivorgabs260116199v1><a href=https://arxiv.org/abs/2601.16199v1>PAL*M: Property Attestation for Large Generative Models</a><a hidden class=anchor aria-hidden=true href=#palm-property-attestation-for-large-generative-modelshttpsarxivorgabs260116199v1>#</a></h3><p><strong>Authors:</strong> Prach Chantasantitam, Adam Ilyas Caulfield, Vasisht Duddu, Lachlan J. Gunn, N. Asokan
<strong>Venue:</strong> arXiv (2026)</p><p>Machine learning property attestations allow provers (e.g., model providers or owners) to attest properties of their models/datasets to verifiers (e.g., regulators, customers), enabling accountability towards regulations and policies. But, current approaches do not support generative models or large datasets. We present PAL<em>M, a property attestation framework for large generative models, illustrated using large language models. PAL</em>M defines properties across training and inference, leverages confidential virtual machines with security-aware GPUs for coverage of CPU-GPU operations, and proposes using incremental multiset hashing over memory-mapped datasets to efficiently track their integrity. We implement PAL*M on Intel TDX and NVIDIA H100, showing it is efficient, scalable, versatile, and secure.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16199v1">üìÑ Download PDF</a></p><hr><h3 id=electron-transfer-diabatic-couplings-and-vibronic-energy-gaps-in-a-phase-space-frameworkhttpsarxivorgabs260116209v1><a href=https://arxiv.org/abs/2601.16209v1>Electron Transfer, Diabatic Couplings and Vibronic Energy Gaps in a Phase Space Framework</a><a hidden class=anchor aria-hidden=true href=#electron-transfer-diabatic-couplings-and-vibronic-energy-gaps-in-a-phase-space-frameworkhttpsarxivorgabs260116209v1>#</a></h3><p><strong>Authors:</strong> Zain Zaidi, Xuezhi Bian, Joseph E. Subotnik
<strong>Venue:</strong> arXiv (2026)</p><p>We investigate the well-known Shin-Metiu model for an electronic crossing, using both a standard Born-Huang (BH) framework and a novel phase space (PS) electronic Hamiltonian framework. We show that as long as we are not in the strongly nonadiabatic region, a phase space framework can obtain a relative error in vibrational energy gap which is consistently one order of magnitude smaller than what is found within a BH framework. In line with recent results showing that dynamics on one phase space surface can outperform dynamics on one Born-Oppenheimer surface, our results indicate that the same advantages should largely hold for curve crossings and dynamics on two or a handful of electronic surfaces, from which several implications can be surmised as far as the possibility of spin-dependent electron transfer dynamics.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16209v1">üìÑ Download PDF</a></p><hr><h3 id=beat-ssl-capturing-local-ecg-morphology-through-heartbeat-level-contrastive-learning-with-soft-targetshttpsarxivorgabs260116147v1><a href=https://arxiv.org/abs/2601.16147v1>Beat-ssl: Capturing Local ECG Morphology through Heartbeat-level Contrastive Learning with Soft Targets</a><a hidden class=anchor aria-hidden=true href=#beat-ssl-capturing-local-ecg-morphology-through-heartbeat-level-contrastive-learning-with-soft-targetshttpsarxivorgabs260116147v1>#</a></h3><p><strong>Authors:</strong> Muhammad Ilham Rizqyawan, Peter Macfarlane, Stathis Hadjidemetriou, Fani Deligianni
<strong>Venue:</strong> arXiv (2026)</p><p>Obtaining labelled ECG data for developing supervised models is challenging. Contrastive learning (CL) has emerged as a promising pretraining approach that enables effective transfer learning with limited labelled data. However, existing CL frameworks either focus solely on global context or fail to exploit ECG-specific characteristics. Furthermore, these methods rely on hard contrastive targets, which may not adequately capture the continuous nature of feature similarity in ECG signals. In this paper, we propose Beat-SSL, a contrastive learning framework that performs dual-context learning through both rhythm-level and heartbeat-level contrasting with soft targets. We evaluated our pretrained model on two downstream tasks: 1) multilabel classification for global rhythm assessment, and 2) ECG segmentation to assess its capacity to learn representations across both contexts. We conducted an ablation study and compared the best configuration with three other methods, including one ECG foundation model. Despite the foundation model&rsquo;s broader pretraining, Beat-SSL reached 93% of its performance in multilabel classification task and surpassed all other methods in the segmentation task by 4%.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16147v1">üìÑ Download PDF</a></p><hr><h3 id=efficiently-learning-robust-torque-based-locomotion-through-reinforcement-with-model-based-supervisionhttpsarxivorgabs260116109v1><a href=https://arxiv.org/abs/2601.16109v1>Efficiently Learning Robust Torque-based Locomotion Through Reinforcement with Model-Based Supervision</a><a hidden class=anchor aria-hidden=true href=#efficiently-learning-robust-torque-based-locomotion-through-reinforcement-with-model-based-supervisionhttpsarxivorgabs260116109v1>#</a></h3><p><strong>Authors:</strong> Yashuai Yan, Tobias Egle, Christian Ott, Dongheui Lee
<strong>Venue:</strong> arXiv (2026)</p><p>We propose a control framework that integrates model-based bipedal locomotion with residual reinforcement learning (RL) to achieve robust and adaptive walking in the presence of real-world uncertainties. Our approach leverages a model-based controller, comprising a Divergent Component of Motion (DCM) trajectory planner and a whole-body controller, as a reliable base policy. To address the uncertainties of inaccurate dynamics modeling and sensor noise, we introduce a residual policy trained through RL with domain randomization. Crucially, we employ a model-based oracle policy, which has privileged access to ground-truth dynamics during training, to supervise the residual policy via a novel supervised loss. This supervision enables the policy to efficiently learn corrective behaviors that compensate for unmodeled effects without extensive reward shaping. Our method demonstrates improved robustness and generalization across a range of randomized conditions, offering a scalable solution for sim-to-real transfer in bipedal locomotion.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16109v1">üìÑ Download PDF</a></p><hr><h3 id=dsfedmed-dual-scale-federated-medical-image-segmentation-via-mutual-distillation-between-foundation-and-lightweight-modelshttpsarxivorgabs260116073v1><a href=https://arxiv.org/abs/2601.16073v1>DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models</a><a hidden class=anchor aria-hidden=true href=#dsfedmed-dual-scale-federated-medical-image-segmentation-via-mutual-distillation-between-foundation-and-lightweight-modelshttpsarxivorgabs260116073v1>#</a></h3><p><strong>Authors:</strong> Hanwen Zhang, Qiaojin Shen, Yuxi Liu, Yuesheng Zhu, Guibo Luo
<strong>Venue:</strong> arXiv (2026)</p><p>Foundation Models (FMs) have demonstrated strong generalization across diverse vision tasks. However, their deployment in federated settings is hindered by high computational demands, substantial communication overhead, and significant inference costs. We propose DSFedMed, a dual-scale federated framework that enables mutual knowledge distillation between a centralized foundation model and lightweight client models for medical image segmentation. To support knowledge distillation, a set of high-quality medical images is generated to replace real public datasets, and a learnability-guided sample selection strategy is proposed to enhance efficiency and effectiveness in dual-scale distillation. This mutual distillation enables the foundation model to transfer general knowledge to lightweight clients, while also incorporating client-specific insights to refine the foundation model. Evaluations on five medical imaging segmentation datasets show that DSFedMed achieves an average 2 percent improvement in Dice score while reducing communication costs and inference time by nearly 90 percent compared to existing federated foundation model baselines. These results demonstrate significant efficiency gains and scalability for resource-limited federated deployments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16073v1">üìÑ Download PDF</a></p><hr><h3 id=campilot-improving-camera-control-in-video-diffusion-model-with-efficient-camera-reward-feedbackhttpsarxivorgabs260116214v1><a href=https://arxiv.org/abs/2601.16214v1>CamPilot: Improving Camera Control in Video Diffusion Model with Efficient Camera Reward Feedback</a><a hidden class=anchor aria-hidden=true href=#campilot-improving-camera-control-in-video-diffusion-model-with-efficient-camera-reward-feedbackhttpsarxivorgabs260116214v1>#</a></h3><p><strong>Authors:</strong> Wenhang Ge, Guibao Shen, Jiawei Feng, Luozhou Wang, Hao Lu, Xingye Tian, Xin Tao, Ying-Cong Chen
<strong>Venue:</strong> arXiv (2026)</p><p>Recent advances in camera-controlled video diffusion models have significantly improved video-camera alignment. However, the camera controllability still remains limited. In this work, we build upon Reward Feedback Learning and aim to further improve camera controllability. However, directly borrowing existing ReFL approaches faces several challenges. First, current reward models lack the capacity to assess video-camera alignment. Second, decoding latent into RGB videos for reward computation introduces substantial computational overhead. Third, 3D geometric information is typically neglected during video decoding. To address these limitations, we introduce an efficient camera-aware 3D decoder that decodes video latent into 3D representations for reward quantization. Specifically, video latent along with the camera pose are decoded into 3D Gaussians. In this process, the camera pose not only acts as input, but also serves as a projection parameter. Misalignment between the video latent and camera pose will cause geometric distortions in the 3D structure, resulting in blurry renderings. Based on this property, we explicitly optimize pixel-level consistency between the rendered novel views and ground-truth ones as reward. To accommodate the stochastic nature, we further introduce a visibility term that selectively supervises only deterministic regions derived via geometric warping. Extensive experiments conducted on RealEstate10K and WorldScore benchmarks demonstrate the effectiveness of our proposed method. Project page: \href{https://a-bigbao.github.io/CamPilot/}{CamPilot Page}.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16214v1">üìÑ Download PDF</a></p><hr><h3 id=a-multiwavelength-alma-view-of-gas-and-dust-in-binary-protoplanetary-system-as-205-evidence-of-dust-asymmetric-distributionhttpsarxivorgabs260116202v1><a href=https://arxiv.org/abs/2601.16202v1>A multiwavelength ALMA view of gas and dust in binary protoplanetary system AS 205: Evidence of dust asymmetric distribution</a><a hidden class=anchor aria-hidden=true href=#a-multiwavelength-alma-view-of-gas-and-dust-in-binary-protoplanetary-system-as-205-evidence-of-dust-asymmetric-distributionhttpsarxivorgabs260116202v1>#</a></h3><p><strong>Authors:</strong> Nguyen Thi Phuong, Nguyen Tat Thang
<strong>Venue:</strong> arXiv (2026)</p><p>We present Atacama Large Millimeter/Submillimeter Array observations of multi-wavelength dust emissions at 3.1,mm and 1.3,mm; along with molecular line emissions of CO(2&ndash;1), CO(3&ndash;2), \mbox{$^{13}$CO(3&ndash;2)}, and C$^{18}$O(3&ndash;2) at spatial resolutions of 7&ndash;45 AU towards the protoplanetary system AS 205. The dust emissions exhibit two distinct components of AS 205 N and AS 205 S, separated by 1.3 arcsec. While gas kinematics within the dust disk regions are dominated by Keplerian rotation, the more extended gas emission displays complex morphology and kinematics strongly affected by the binary gravitational interaction in the outer regions. The stellar masses of AS 205 N and AS 205 S are estimated at $0.78\pm0.19$,M$<em>\odot$ and $1.93\pm0.86$,M$</em>\odot$, respectively. Azimuthal variation is observed in the spectral index distribution of both disks. In AS 205 N, the spectral index minimum in the southwest is coincident with the peaks of CO($2-1$), CO($3-2$), and $^{13}$CO($3-2$) integrated intensity and the relative position of its southern counterpart. On the other hand, the spectral index distribution in \ass~exhibits two prominent maxima, with the one in the northeast aligning with the peak of $^{13}$CO($3-2$), and the peak in the south coinciding with local maxima in CO($2-1$) and CO($3-2$) azimuthal profiles. These results suggest a correlation between dust grain size and/or optical depth with the gas distributions. Dust-trapping along the spiral arms possibly contributes to the spectral index minima in AS 205 N; however, the observed asymmetry across both disks suggests the involvement of additional mechanisms.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16202v1">üìÑ Download PDF</a></p><hr><h3 id=360anything-geometry-free-lifting-of-images-and-videos-to-360httpsarxivorgabs260116192v1><a href=https://arxiv.org/abs/2601.16192v1>360Anything: Geometry-Free Lifting of Images and Videos to 360¬∞</a><a hidden class=anchor aria-hidden=true href=#360anything-geometry-free-lifting-of-images-and-videos-to-360httpsarxivorgabs260116192v1>#</a></h3><p><strong>Authors:</strong> Ziyi Wu, Daniel Watson, Andrea Tagliasacchi, David J. Fleet, Marcus A. Brubaker, Saurabh Saxena
<strong>Venue:</strong> arXiv (2026)</p><p>Lifting perspective images and videos to 360¬∞ panoramas enables immersive 3D world generation. Existing approaches often rely on explicit geometric alignment between the perspective and the equirectangular projection (ERP) space. Yet, this requires known camera metadata, obscuring the application to in-the-wild data where such calibration is typically absent or noisy. We propose 360Anything, a geometry-free framework built upon pre-trained diffusion transformers. By treating the perspective input and the panorama target simply as token sequences, 360Anything learns the perspective-to-equirectangular mapping in a purely data-driven way, eliminating the need for camera information. Our approach achieves state-of-the-art performance on both image and video perspective-to-360¬∞ generation, outperforming prior works that use ground-truth camera information. We also trace the root cause of the seam artifacts at ERP boundaries to zero-padding in the VAE encoder, and introduce Circular Latent Encoding to facilitate seamless generation. Finally, we show competitive results in zero-shot camera FoV and orientation estimation benchmarks, demonstrating 360Anything&rsquo;s deep geometric understanding and broader utility in computer vision tasks. Additional results are available at <a href=https://360anything.github.io/>https://360anything.github.io/</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16192v1">üìÑ Download PDF</a></p><hr><h3 id=a-general-spectral-solver-for-the-axisymmetric-jeans-equations-fast-galaxy-modelling-with-arbitrary-anisotropyhttpsarxivorgabs260116179v1><a href=https://arxiv.org/abs/2601.16179v1>A general spectral solver for the axisymmetric Jeans equations: fast galaxy modelling with arbitrary anisotropy</a><a hidden class=anchor aria-hidden=true href=#a-general-spectral-solver-for-the-axisymmetric-jeans-equations-fast-galaxy-modelling-with-arbitrary-anisotropyhttpsarxivorgabs260116179v1>#</a></h3><p><strong>Authors:</strong> Michele Cappellari
<strong>Venue:</strong> arXiv (2026)</p><p>Dynamical modelling is a fundamental tool for measuring galaxy masses and density profiles in the era of large integral-field spectroscopic surveys and Bayesian inference. Solutions based on the Jeans equations are popular due to their robustness and computational efficiency. However, traditional semi-analytic Jeans solvers often require restrictive assumptions about the velocity anisotropy to remain computationally tractable. This paper presents a new spectral solver for the axisymmetric Jeans equations designed to overcome these limitations. I first illustrate, using orbit integrations in realistic potentials, that spherical alignment of the velocity ellipsoid is a physically well-motivated approximation for galaxy modelling. The new method employs a spectral technique to solve the Jeans partial differential equations directly. Two design choices are critical for accuracy and speed: (i) solving for the slowly-varying velocity dispersion rather than the rapidly varying pressure, and (ii) imposing a Robin boundary condition to enforce the asymptotic decay on a finite domain. This formulation supports arbitrary anisotropy distributions beta(r, theta) while simultaneously increasing computational speed by orders of magnitude compared to standard high-accuracy quadratures. Validated against exact analytic benchmarks, the solver recovers intrinsic moments with sub-percent accuracy. The implementation will be included in the public JamPy package and is structured to be optimally suited for massive parallelization on specialized hardware such as GPUs, enabling the rigorous exploration of complex parameter spaces.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16179v1">üìÑ Download PDF</a></p><hr><h3 id=hvd-human-vision-driven-video-representation-learning-for-text-video-retrievalhttpsarxivorgabs260116155v1><a href=https://arxiv.org/abs/2601.16155v1>HVD: Human Vision-Driven Video Representation Learning for Text-Video Retrieval</a><a hidden class=anchor aria-hidden=true href=#hvd-human-vision-driven-video-representation-learning-for-text-video-retrievalhttpsarxivorgabs260116155v1>#</a></h3><p><strong>Authors:</strong> Zequn Xie, Xin Liu, Boyun Zhang, Yuxiao Lin, Sihang Cai, Tao Jin
<strong>Venue:</strong> arXiv (2026)</p><p>The success of CLIP has driven substantial progress in text-video retrieval. However, current methods often suffer from &ldquo;blind&rdquo; feature interaction, where the model struggles to discern key visual information from background noise due to the sparsity of textual queries. To bridge this gap, we draw inspiration from human cognitive behavior and propose the Human Vision-Driven (HVD) model. Our framework establishes a coarse-to-fine alignment mechanism comprising two key components: the Frame Features Selection Module (FFSM) and the Patch Features Compression Module (PFCM). FFSM mimics the human macro-perception ability by selecting key frames to eliminate temporal redundancy. Subsequently, PFCM simulates micro-perception by aggregating patch features into salient visual entities through an advanced attention mechanism, enabling precise entity-level matching. Extensive experiments on five benchmarks demonstrate that HVD not only captures human-like visual focus but also achieves state-of-the-art performance.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16155v1">üìÑ Download PDF</a></p><hr><h3 id=rethinking-composed-image-retrieval-evaluation-a-fine-grained-benchmark-from-image-editinghttpsarxivorgabs260116125v1><a href=https://arxiv.org/abs/2601.16125v1>Rethinking Composed Image Retrieval Evaluation: A Fine-Grained Benchmark from Image Editing</a><a hidden class=anchor aria-hidden=true href=#rethinking-composed-image-retrieval-evaluation-a-fine-grained-benchmark-from-image-editinghttpsarxivorgabs260116125v1>#</a></h3><p><strong>Authors:</strong> Tingyu Song, Yanzhao Zhang, Mingxin Li, Zhuoning Guo, Dingkun Long, Pengjun Xie, Siyue Zhang, Yilun Zhao, Shu Wu
<strong>Venue:</strong> arXiv (2026)</p><p>Composed Image Retrieval (CIR) is a pivotal and complex task in multimodal understanding. Current CIR benchmarks typically feature limited query categories and fail to capture the diverse requirements of real-world scenarios. To bridge this evaluation gap, we leverage image editing to achieve precise control over modification types and content, enabling a pipeline for synthesizing queries across a broad spectrum of categories. Using this pipeline, we construct EDIR, a novel fine-grained CIR benchmark. EDIR encompasses 5,000 high-quality queries structured across five main categories and fifteen subcategories. Our comprehensive evaluation of 13 multimodal embedding models reveals a significant capability gap; even state-of-the-art models (e.g., RzenEmbed and GME) struggle to perform consistently across all subcategories, highlighting the rigorous nature of our benchmark. Through comparative analysis, we further uncover inherent limitations in existing benchmarks, such as modality biases and insufficient categorical coverage. Furthermore, an in-domain training experiment demonstrates the feasibility of our benchmark. This experiment clarifies the task challenges by distinguishing between categories that are solvable with targeted data and those that expose intrinsic limitations of current model architectures.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16125v1">üìÑ Download PDF</a></p><hr><h3 id=multimodal-climate-disinformation-detection-integrating-vision-language-models-with-external-knowledge-sourceshttpsarxivorgabs260116108v1><a href=https://arxiv.org/abs/2601.16108v1>Multimodal Climate Disinformation Detection: Integrating Vision-Language Models with External Knowledge Sources</a><a hidden class=anchor aria-hidden=true href=#multimodal-climate-disinformation-detection-integrating-vision-language-models-with-external-knowledge-sourceshttpsarxivorgabs260116108v1>#</a></h3><p><strong>Authors:</strong> Marzieh Adeli Shamsabad, Hamed Ghodrati
<strong>Venue:</strong> arXiv (2026)</p><p>Climate disinformation has become a major challenge in today digital world, especially with the rise of misleading images and videos shared widely on social media. These false claims are often convincing and difficult to detect, which can delay actions on climate change. While vision-language models (VLMs) have been used to identify visual disinformation, they rely only on the knowledge available at the time of training. This limits their ability to reason about recent events or updates. The main goal of this paper is to overcome that limitation by combining VLMs with external knowledge. By retrieving up-to-date information such as reverse image results, online fact-checks, and trusted expert content, the system can better assess whether an image and its claim are accurate, misleading, false, or unverifiable. This approach improves the model ability to handle real-world climate disinformation and supports efforts to protect public understanding of science in a rapidly changing information landscape.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16108v1">üìÑ Download PDF</a></p><hr><h3 id=grounding-large-language-models-in-reaction-knowledge-graphs-for-synthesis-retrievalhttpsarxivorgabs260116038v1><a href=https://arxiv.org/abs/2601.16038v1>Grounding Large Language Models in Reaction Knowledge Graphs for Synthesis Retrieval</a><a hidden class=anchor aria-hidden=true href=#grounding-large-language-models-in-reaction-knowledge-graphs-for-synthesis-retrievalhttpsarxivorgabs260116038v1>#</a></h3><p><strong>Authors:</strong> Olga Bunkova, Lorenzo Di Fruscia, Sophia Rupprecht, Artur M. Schweidtmann, Marcel J. T. Reinders, Jana M. Weber
<strong>Venue:</strong> arXiv (2026)</p><p>Large Language Models (LLMs) can aid synthesis planning in chemistry, but standard prompting methods often yield hallucinated or outdated suggestions. We study LLM interactions with a reaction knowledge graph by casting reaction path retrieval as a Text2Cypher (natural language to graph query) generation problem, and define single- and multi-step retrieval tasks. We compare zero-shot prompting to one-shot variants using static, random, and embedding-based exemplar selection, and assess a checklist-driven validator/corrector loop. To evaluate our framework, we consider query validity and retrieval accuracy. We find that one-shot prompting with aligned exemplars consistently performs best. Our checklist-style self-correction loop mainly improves executability in zero-shot settings and offers limited additional retrieval gains once a good exemplar is present. We provide a reproducible Text2Cypher evaluation setup to facilitate further work on KG-grounded LLMs for synthesis planning. Code is available at <a href=https://github.com/Intelligent-molecular-systems/KG-LLM-Synthesis-Retrieval>https://github.com/Intelligent-molecular-systems/KG-LLM-Synthesis-Retrieval</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16038v1">üìÑ Download PDF</a></p><hr><h3 id=deja-vu-in-plots-leveraging-cross-session-evidence-with-retrieval-augmented-llms-for-live-streaming-risk-assessmenthttpsarxivorgabs260116027v1><a href=https://arxiv.org/abs/2601.16027v1>Deja Vu in Plots: Leveraging Cross-Session Evidence with Retrieval-Augmented LLMs for Live Streaming Risk Assessment</a><a hidden class=anchor aria-hidden=true href=#deja-vu-in-plots-leveraging-cross-session-evidence-with-retrieval-augmented-llms-for-live-streaming-risk-assessmenthttpsarxivorgabs260116027v1>#</a></h3><p><strong>Authors:</strong> Yiran Qiao, Xiang Ao, Jing Chen, Yang Liu, Qiwei Zhong, Qing He
<strong>Venue:</strong> arXiv (2026)</p><p>The rise of live streaming has transformed online interaction, enabling massive real-time engagement but also exposing platforms to complex risks such as scams and coordinated malicious behaviors. Detecting these risks is challenging because harmful actions often accumulate gradually and recur across seemingly unrelated streams. To address this, we propose CS-VAR (Cross-Session Evidence-Aware Retrieval-Augmented Detector) for live streaming risk assessment. In CS-VAR, a lightweight, domain-specific model performs fast session-level risk inference, guided during training by a Large Language Model (LLM) that reasons over retrieved cross-session behavioral evidence and transfers its local-to-global insights to the small model. This design enables the small model to recognize recurring patterns across streams, perform structured risk assessment, and maintain efficiency for real-time deployment. Extensive offline experiments on large-scale industrial datasets, combined with online validation, demonstrate the state-of-the-art performance of CS-VAR. Furthermore, CS-VAR provides interpretable, localized signals that effectively empower real-world moderation for live streaming.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16027v1">üìÑ Download PDF</a></p><hr><h3 id=mecellem-models-turkish-models-trained-from-scratch-and-continually-pre-trained-for-the-legal-domainhttpsarxivorgabs260116018v1><a href=https://arxiv.org/abs/2601.16018v1>Mecellem Models: Turkish Models Trained from Scratch and Continually Pre-trained for the Legal Domain</a><a hidden class=anchor aria-hidden=true href=#mecellem-models-turkish-models-trained-from-scratch-and-continually-pre-trained-for-the-legal-domainhttpsarxivorgabs260116018v1>#</a></h3><p><strong>Authors:</strong> √ñzg√ºr Uƒüur, Mahmut G√∂ksu, Mahmut √áimen, Musa Yƒ±lmaz, Esra ≈ûavirdi, Alp Talha Demir, Rumeysa G√ºll√ºce, ƒ∞clal √áetin, √ñmer Can Saƒüba≈ü
<strong>Venue:</strong> arXiv (2026)</p><p>This paper presents Mecellem models, a framework for developing specialized language models for the Turkish legal domain through domain adaptation strategies. We make two contributions: (1)Encoder Model Pre-trained from Scratch: ModernBERT-based bidirectional encoders pre-trained on a Turkish-dominant corpus of 112.7 billion tokens. We implement a checkpoint selection strategy that evaluates downstream retrieval performance throughout training, revealing that optimal checkpoints achieve best retrieval scores before pre-training loss reaches its minimum. Our encoder models achieve top-3 rankings on the Turkish retrieval leaderboard, with smaller models (155M parameters) achieving comparable performance to larger reference models (307M-567M parameters). Our approach achieves 92.36% production efficiency compared to state-of-the-art models (embeddinggemma-300m: 100.00%, BAAI/bge-m3: 99.54%, newmindai/bge-m3-stsb: 94.38%), ranking fourth overall despite requiring less computational resources. SOTA models rely on multi-stage, computationally intensive training pipelines, making our single-stage pre-training followed by efficient post-training approach a cost-effective alternative; (2)Decoder Model with Continual Pre-training (CPT): Qwen3-1.7B and Qwen3-4B models adapted to Turkish legal domain through controlled curriculum learning. Four-phase CPT with optimal sample ratios enables gradual transition from general language knowledge to specialized legal terminology and long-context reasoning. This approach achieves 36.2% perplexity reduction on Turkish legal text, demonstrating domain adaptation gains.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16018v1">üìÑ Download PDF</a></p><hr><h2 id=-linguistics>üîç linguistics<a hidden class=anchor aria-hidden=true href=#-linguistics>#</a></h2><h3 id=gauge-theory-and-skein-moduleshttpsarxivorgabs260116213v1><a href=https://arxiv.org/abs/2601.16213v1>Gauge Theory and Skein Modules</a><a hidden class=anchor aria-hidden=true href=#gauge-theory-and-skein-moduleshttpsarxivorgabs260116213v1>#</a></h3><p><strong>Authors:</strong> Du Pei
<strong>Venue:</strong> arXiv (2026)</p><p>We study skein modules of 3-manifolds by embedding them into the Hilbert spaces of 4d ${\cal N}=4$ super-Yang-Mills theories. When the 3-manifold has reduced holonomy, we present an algorithm to determine the dimension and the list of generators of the skein module with a general gauge group. The analysis uses a deformation preserving ${\cal N}=1$ supersymmetry to express the dimension as a sum over nilpotent orbits. We find that the dimensions often differ between Langlands-dual pairs beyond the A-series, for which we provide a physical explanation involving chiral symmetry breaking and &rsquo;t Hooft operators. We also relate our results to the structure of $\mathbb{C}^*$-fixed loci in the moduli space of Higgs bundles. This approach helps to clarify the relation between the gauge-theoretic framework of Kapustin and Witten with other versions of the geometric Langlands program, explains why the dimensions of skein modules do not exhibit a TQFT-like behavior, and provides a physical interpretation of the skein-valued curve counting of Ekholm and Shende.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16213v1">üìÑ Download PDF</a></p><hr><h3 id=why-cant-i-open-my-drawer-mitigating-object-driven-shortcuts-in-zero-shot-compositional-action-recognitionhttpsarxivorgabs260116211v1><a href=https://arxiv.org/abs/2601.16211v1>Why Can&rsquo;t I Open My Drawer? Mitigating Object-Driven Shortcuts in Zero-Shot Compositional Action Recognition</a><a hidden class=anchor aria-hidden=true href=#why-cant-i-open-my-drawer-mitigating-object-driven-shortcuts-in-zero-shot-compositional-action-recognitionhttpsarxivorgabs260116211v1>#</a></h3><p><strong>Authors:</strong> Geo Ahn, Inwoong Lee, Taeoh Kim, Minho Shim, Dongyoon Wee, Jinwoo Choi
<strong>Venue:</strong> arXiv (2026)</p><p>We study Compositional Video Understanding (CVU), where models must recognize verbs and objects and compose them to generalize to unseen combinations. We find that existing Zero-Shot Compositional Action Recognition (ZS-CAR) models fail primarily due to an overlooked failure mode: object-driven verb shortcuts. Through systematic analysis, we show that this behavior arises from two intertwined factors: severe sparsity and skewness of compositional supervision, and the asymmetric learning difficulty between verbs and objects. As training progresses, the existing ZS-CAR model increasingly ignores visual evidence and overfits to co-occurrence statistics. Consequently, the existing model does not gain the benefit of compositional recognition in unseen verb-object compositions. To address this, we propose RCORE, a simple and effective framework that enforces temporally grounded verb learning. RCORE introduces (i) a composition-aware augmentation that diversifies verb-object combinations without corrupting motion cues, and (ii) a temporal order regularization loss that penalizes shortcut behaviors by explicitly modeling temporal structure. Across two benchmarks, Sth-com and our newly constructed EK100-com, RCORE significantly improves unseen composition accuracy, reduces reliance on co-occurrence bias, and achieves consistently positive compositional gaps. Our findings reveal object-driven shortcuts as a critical limiting factor in ZS-CAR and demonstrate that addressing them is essential for robust compositional video understanding.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16211v1">üìÑ Download PDF</a></p><hr><h3 id=scaling-text-to-image-diffusion-transformers-with-representation-autoencodershttpsarxivorgabs260116208v1><a href=https://arxiv.org/abs/2601.16208v1>Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders</a><a hidden class=anchor aria-hidden=true href=#scaling-text-to-image-diffusion-transformers-with-representation-autoencodershttpsarxivorgabs260116208v1>#</a></h3><p><strong>Authors:</strong> Shengbang Tong, Boyang Zheng, Ziteng Wang, Bingda Tang, Nanye Ma, Ellis Brown, Jihan Yang, Rob Fergus, Yann LeCun, Saining Xie
<strong>Venue:</strong> arXiv (2026)</p><p>Representation Autoencoders (RAEs) have shown distinct advantages in diffusion modeling on ImageNet by training in high-dimensional semantic latent spaces. In this work, we investigate whether this framework can scale to large-scale, freeform text-to-image (T2I) generation. We first scale RAE decoders on the frozen representation encoder (SigLIP-2) beyond ImageNet by training on web, synthetic, and text-rendering data, finding that while scale improves general fidelity, targeted data composition is essential for specific domains like text. We then rigorously stress-test the RAE design choices originally proposed for ImageNet. Our analysis reveals that scaling simplifies the framework: while dimension-dependent noise scheduling remains critical, architectural complexities such as wide diffusion heads and noise-augmented decoding offer negligible benefits at scale Building on this simplified framework, we conduct a controlled comparison of RAE against the state-of-the-art FLUX VAE across diffusion transformer scales from 0.5B to 9.8B parameters. RAEs consistently outperform VAEs during pretraining across all model scales. Further, during finetuning on high-quality datasets, VAE-based models catastrophically overfit after 64 epochs, while RAE models remain stable through 256 epochs and achieve consistently better performance. Across all experiments, RAE-based diffusion models demonstrate faster convergence and better generation quality, establishing RAEs as a simpler and stronger foundation than VAEs for large-scale T2I generation. Additionally, because both visual understanding and generation can operate in a shared representation space, the multimodal model can directly reason over generated latents, opening new possibilities for unified models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16208v1">üìÑ Download PDF</a></p><hr><h3 id=high-resolution-neutron-diffraction-determination-of-noncollinear-antiferromagnetic-order-in-the-honeycomb-magnetoelectric-fe_4nb_2o_9httpsarxivorgabs260116215v1><a href=https://arxiv.org/abs/2601.16215v1>High-resolution neutron diffraction determination of noncollinear antiferromagnetic order in the honeycomb magnetoelectric Fe$<em>{4}$Nb$</em>{2}$O$_{9}$</a><a hidden class=anchor aria-hidden=true href=#high-resolution-neutron-diffraction-determination-of-noncollinear-antiferromagnetic-order-in-the-honeycomb-magnetoelectric-fe_4nb_2o_9httpsarxivorgabs260116215v1>#</a></h3><p><strong>Authors:</strong> Raktim Datta, Kapil Kumar, Dong Gun Oh, Dongwook Kim, Rahul Goel, Nara Lee, Ara Go, Young Jai Choi, Valery Kiryukhin, Sungkyun Choi
<strong>Venue:</strong> arXiv (2026)</p><p>Magnetoelectric systems offer potential for device applications exploiting coupled states between electric and magnetic properties. Among magnetoelectric materials, \FNO has attracted special attention because of its pronounced dielectric signal at high magnetic transition temperatures. However, the magnetic ground state, which is essential information for understanding its unusual magnetoelectricity, remains unclarified. Here, we report a noncollinear magnetic ground state of Fe$<em>{4}$Nb$</em>{2}$O$_{9}$. To examine the magnetoelectric effect associated with sequential magnetic and structural transitions upon cooling, we conducted combined x-ray diffraction, magnetic susceptibility, magnetization, dielectric constant, and magnetodielectric experiments. Powder neutron diffraction experiments revealed a series of magnetic Bragg peaks and clear splitting of peaks via structural transition. Magnetic Rietveld refinements, combined with group theory analysis, determined a noncollinear antiferromagnetic structure including a significant $c$-axis moment component at 1.5 K. This study provides insights into the understanding of its magnetoelectric properties.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16215v1">üìÑ Download PDF</a></p><hr><h3 id=on-the-missing-red-giants-near-the-galactic-centerhttpsarxivorgabs260116191v1><a href=https://arxiv.org/abs/2601.16191v1>On the Missing Red Giants near the Galactic Center</a><a hidden class=anchor aria-hidden=true href=#on-the-missing-red-giants-near-the-galactic-centerhttpsarxivorgabs260116191v1>#</a></h3><p><strong>Authors:</strong> Taeho Kim, Jeremy Goodman
<strong>Venue:</strong> arXiv (2026)</p><p>There is a long-acknowledged deficiency of bright red giants relative to fainter old stars within a few arc seconds of Sgr A*. We explore whether this could be due to tidal stripping by the central black hole. This requires putting the stars onto highly eccentric orbits, for which we evaluate diffusion by both scalar resonant and non-resonant relaxation of the orbital angular momentum. We conclude that tidal stripping does not discriminate sufficiently between main-sequence and red giant stars. While the tidal loss cone increases with stellar radius, the rate of diffusion into the loss cone increases only logarithmically, whereas the lifetime on the red giant branch decreases more rapidly than $R_*^{-1}$. In agreement with previous studies, we find that stellar collisions are a more likely explanation for the deficiency of bright red giants relative to fainter ones.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16191v1">üìÑ Download PDF</a></p><hr><h3 id=physical-and-dielectric-properties-of-polycrystalline-lav_05nb_05o_4httpsarxivorgabs260116067v1><a href=https://arxiv.org/abs/2601.16067v1>Physical and Dielectric Properties of Polycrystalline LaV$<em>{0.5}$Nb$</em>{0.5}$O$_4$</a><a hidden class=anchor aria-hidden=true href=#physical-and-dielectric-properties-of-polycrystalline-lav_05nb_05o_4httpsarxivorgabs260116067v1>#</a></h3><p><strong>Authors:</strong> Ashok Kumar, Simranjot K. Sapra, Ramcharan Meena, Vinod Singh, Anita Dhaka, Rajendra S. Dhaka
<strong>Venue:</strong> arXiv (2026)</p><p>We report a detailed investigation of the structural, electronic, vibrational, and dielectric properties of polycrystalline LaV$<em>{0.5}$Nb$</em>{0.5}$O$<em>4$ samples, prepared at two sintering temperatures (1000\degree C and 1250\degree C). The introduction of Nb$^{5+}$ at the V$^{5+}$ site leads to notable structural and vibrational changes, which can be attributed to their isoelectronic nature and the comparatively larger ionic radius of Nb$^{5+}$. The Rietveld refinement of the X-ray diffraction patterns confirms a coexistence of monoclinic ($P$2$</em>{1}$/$n$) and scheelite-type tetragonal ($I$4$<em>{1}$/$a$) phases; for example, with a fraction of 4% and 96% for the sample annealed at 1250\degree C. The particle morphology has altered from spherical (1000\degree C) to irregular-shaped (1250\degree C) as a result of increase in annealing temperature. The Raman spectroscopy, Fourier Transform Infrared spectroscopy and X-ray Photoemission Spectroscopy have been used to understand the vibrational and electronic properties. An optical band gap of 2.7~eV for the sample sintered at 1250\degree C is calculated using Ultraviolet-vis diffuse reflectance spectroscopy measurements. The dielectric studies shows the higher dielectric permittivity ($Œµ$$</em>{r}$) and lower dielectric loss for the sample annealed at 1250\degree C.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16067v1">üìÑ Download PDF</a></p><hr><h3 id=unveiling-the-spectral-morphological-division-of-fast-radio-bursts-with-chimefrb-catalog-2httpsarxivorgabs260116048v1><a href=https://arxiv.org/abs/2601.16048v1>Unveiling the Spectral Morphological Division of Fast Radio Bursts with CHIME/FRB Catalog 2</a><a hidden class=anchor aria-hidden=true href=#unveiling-the-spectral-morphological-division-of-fast-radio-bursts-with-chimefrb-catalog-2httpsarxivorgabs260116048v1>#</a></h3><p><strong>Authors:</strong> Wan-Peng Sun, Yin-Long Cao, Yong-Kun Zhang, Ji-Guo Zhang, Xiaohui Liu, Yichao Li, Fu-Wen Zhang, Wan-Ting Hou, Jing-Fei Zhang, Xin Zhang
<strong>Venue:</strong> arXiv (2026)</p><p>Fast radio bursts (FRBs) are commonly divided into repeating and apparently non-repeating sources, but whether these represent distinct physical populations remains uncertain. In this work, we apply an unsupervised machine learning methods combining Uniform Manifold Approximation and Projection (UMAP) with density-based clustering to analyze CHIME/FRB Catalog 2. We find that FRBs remain primarily separated into two clusters in the multi-dimensional parameter space, with a recall of 0.94 for known repeaters, indicating strong robustness. Consistent with Catalog 1 analyses, we confirm that the spectral morphology parameter, specifically spectral running remains the key discriminator between the two populations, indicating that narrowband emission is an intrinsic and persistent property of repeating FRBs. With the enlarged Catalog 2 sample, we further identify a stable subclass of atypical repeaters (about $6%$ of repeating bursts) that are broadband, shorter in duration, and more luminous, resembling non-repeating bursts. The Nonrepeater-like cluster also shows higher inferred energies and dispersion measures, consistent with a scenario in which apparently non-repeating FRBs may result from observational incompleteness, with low-energy repeating bursts remaining undetected. Our results provide new statistical evidence for a physical connection between repeating and non-repeating FRBs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16048v1">üìÑ Download PDF</a></p><hr><h3 id=paint-pathology-aware-integrated-next-scale-transformation-for-virtual-immunohistochemistryhttpsarxivorgabs260116024v1><a href=https://arxiv.org/abs/2601.16024v1>PAINT: Pathology-Aware Integrated Next-Scale Transformation for Virtual Immunohistochemistry</a><a hidden class=anchor aria-hidden=true href=#paint-pathology-aware-integrated-next-scale-transformation-for-virtual-immunohistochemistryhttpsarxivorgabs260116024v1>#</a></h3><p><strong>Authors:</strong> Rongze Ma, Mengkang Lu, Zhenyu Xiang, Yongsheng Pan, Yicheng Wu, Qingjie Zeng, Yong Xia
<strong>Venue:</strong> arXiv (2026)</p><p>Virtual immunohistochemistry (IHC) aims to computationally synthesize molecular staining patterns from routine Hematoxylin and Eosin (H&amp;E) images, offering a cost-effective and tissue-efficient alternative to traditional physical staining. However, this task is particularly challenging: H&amp;E morphology provides ambiguous cues about protein expression, and similar tissue structures may correspond to distinct molecular states. Most existing methods focus on direct appearance synthesis to implicitly achieve cross-modal generation, often resulting in semantic inconsistencies due to insufficient structural priors. In this paper, we propose Pathology-Aware Integrated Next-Scale Transformation (PAINT), a visual autoregressive framework that reformulates the synthesis process as a structure-first conditional generation task. Unlike direct image translation, PAINT enforces a causal order by resolving molecular details conditioned on a global structural layout. Central to this approach is the introduction of a Spatial Structural Start Map (3S-Map), which grounds the autoregressive initialization in observed morphology, ensuring deterministic, spatially aligned synthesis. Experiments on the IHC4BC and MIST datasets demonstrate that PAINT outperforms state-of-the-art methods in structural fidelity and clinical downstream tasks, validating the potential of structure-guided autoregressive modeling.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16024v1">üìÑ Download PDF</a></p><hr><h3 id=counterfactual-training-teaching-models-plausible-and-actionable-explanationshttpsarxivorgabs260116205v1><a href=https://arxiv.org/abs/2601.16205v1>Counterfactual Training: Teaching Models Plausible and Actionable Explanations</a><a hidden class=anchor aria-hidden=true href=#counterfactual-training-teaching-models-plausible-and-actionable-explanationshttpsarxivorgabs260116205v1>#</a></h3><p><strong>Authors:</strong> Patrick Altmeyer, Aleksander Buszydlik, Arie van Deursen, Cynthia C. S. Liem
<strong>Venue:</strong> arXiv (2026)</p><p>We propose a novel training regime termed counterfactual training that leverages counterfactual explanations to increase the explanatory capacity of models. Counterfactual explanations have emerged as a popular post-hoc explanation method for opaque machine learning models: they inform how factual inputs would need to change in order for a model to produce some desired output. To be useful in real-world decision-making systems, counterfactuals should be plausible with respect to the underlying data and actionable with respect to the feature mutability constraints. Much existing research has therefore focused on developing post-hoc methods to generate counterfactuals that meet these desiderata. In this work, we instead hold models directly accountable for the desired end goal: counterfactual training employs counterfactuals during the training phase to minimize the divergence between learned representations and plausible, actionable explanations. We demonstrate empirically and theoretically that our proposed method facilitates training models that deliver inherently desirable counterfactual explanations and additionally exhibit improved adversarial robustness.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16205v1">üìÑ Download PDF</a></p><hr><h3 id=a-rolling-space-branch-and-price-algorithm-for-the-multi-compartment-vehicle-routing-problem-with-multiple-time-windowshttpsarxivorgabs260116194v1><a href=https://arxiv.org/abs/2601.16194v1>A Rolling-Space Branch-and-Price Algorithm for the Multi-Compartment Vehicle Routing Problem with Multiple Time Windows</a><a hidden class=anchor aria-hidden=true href=#a-rolling-space-branch-and-price-algorithm-for-the-multi-compartment-vehicle-routing-problem-with-multiple-time-windowshttpsarxivorgabs260116194v1>#</a></h3><p><strong>Authors:</strong> El Mehdi Er Raqabi, Kevin Dalmeijer, Pascal Van Hentenryck
<strong>Venue:</strong> arXiv (2026)</p><p>This paper investigates the multi-compartment vehicle routing problem with multiple time windows (MCVRPMTW), an extension of the classical vehicle routing problem with time windows that considers vehicles equipped with multiple compartments and customers requiring service across several delivery time windows. The problem incorporates three key compartment-related features: (i) compartment flexibility in the number of compartments, (ii) item-to-compartment compatibility, and (iii) item-to-item compatibility. The problem also accommodates practical operational requirements such as driver breaks. To solve the MCVRPMTW, we develop an exact branch-and-price (B&amp;P) algorithm in which the pricing problem is solved using a labeling algorithm. Several acceleration strategies are introduced to limit symmetry during label extensions, improve the stability of dual solutions in column generation, and enhance the branching process. To handle large-scale instances, we propose a rolling-space B&amp;P algorithm that integrates clustering techniques into the solution framework. Extensive computational experiments on instances inspired by a real-world industrial application demonstrate the effectiveness of the proposed approach and provide useful managerial insights for practical implementation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16194v1">üìÑ Download PDF</a></p><hr><h3 id=magnon-equilibrium-spin-current-in-collinear-antiferromagnetshttpsarxivorgabs260116184v1><a href=https://arxiv.org/abs/2601.16184v1>Magnon equilibrium spin current in collinear antiferromagnets</a><a hidden class=anchor aria-hidden=true href=#magnon-equilibrium-spin-current-in-collinear-antiferromagnetshttpsarxivorgabs260116184v1>#</a></h3><p><strong>Authors:</strong> Vladimir A. Zyuzin
<strong>Venue:</strong> arXiv (2026)</p><p>We theoretically predict that Dzyaloshinskii-Moriya interaction can induce magnon equilibrium spin current in collinear antiferromagnets. Such a current, being a response to the effective magnon vector potential, can be considered as magnon analog of the superconducting supercurrent or the persistent current. Large amplitude of the predicted effect may compensate for the smallness of the Dzyaloshinskii-Moriya interaction, making the equilibrium spin currents to be experimentally observed. We suggest that external electric field can play the role of effective flux magnons interact with and propose an experiment based on the interference of magnons in the ring geometry as a verification of the concept.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16184v1">üìÑ Download PDF</a></p><hr><h3 id=on-the-structural-properties-of-lie-algebras-via-associated-labeled-directed-graphshttpsarxivorgabs260116161v1><a href=https://arxiv.org/abs/2601.16161v1>On the structural properties of Lie algebras via associated labeled directed graphs</a><a hidden class=anchor aria-hidden=true href=#on-the-structural-properties-of-lie-algebras-via-associated-labeled-directed-graphshttpsarxivorgabs260116161v1>#</a></h3><p><strong>Authors:</strong> Tim Heib, David Edward Bruschi
<strong>Venue:</strong> arXiv (2026)</p><p>We present a method for associating labeled directed graphs to finite-dimensional Lie algebras, thereby enabling rapid identification of key structural algebraic features. To formalize this approach, we introduce the concept of graph-admissible Lie algebras and analyze properties of valid graphs given the antisymmetry property of the Lie bracket as well as the Jacobi identity. Based on these foundations, we develop graph-theoretic criteria for solvability, nilpotency, presence of ideals, simplicity, semisimplicity, and reductiveness of an algebra. Practical algorithms are provided for constructing such graphs and those associated with the lower central series and derived series via an iterative pruning procedure. This visual framework allows for an intuitive understanding of Lie algebraic structures that goes beyond purely visual advantages, since it enables a simpler and swifter grasping of the algebras of interest beyond computational-heavy approaches. Examples, which include the Schr√∂dinger and Lorentz algebra, illustrate the applicability of these tools to physically relevant cases. We further explore applications in physics, where the method facilitates computation of similtude relations essential for determining quantum mechanical time evolution via the Lie algebraic factorization method. Extensions to graded Lie algebras and related conjectures are discussed. Our approach bridges algebraic and combinatorial perspectives, offering both theoretical insights and computational tools into this area of mathematical physics.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16161v1">üìÑ Download PDF</a></p><hr><h3 id=domain-incremental-continual-learning-for-robust-and-efficient-keyword-spotting-in-resource-constrained-systemshttpsarxivorgabs260116158v1><a href=https://arxiv.org/abs/2601.16158v1>Domain-Incremental Continual Learning for Robust and Efficient Keyword Spotting in Resource Constrained Systems</a><a hidden class=anchor aria-hidden=true href=#domain-incremental-continual-learning-for-robust-and-efficient-keyword-spotting-in-resource-constrained-systemshttpsarxivorgabs260116158v1>#</a></h3><p><strong>Authors:</strong> Prakash Dhungana, Sayed Ahmad Salehi
<strong>Venue:</strong> arXiv (2026)</p><p>Keyword Spotting (KWS) systems with small footprint models deployed on edge devices face significant accuracy and robustness challenges due to domain shifts caused by varying noise and recording conditions. To address this, we propose a comprehensive framework for continual learning designed to adapt to new domains while maintaining computational efficiency. The proposed pipeline integrates a dual-input Convolutional Neural Network, utilizing both Mel Frequency Cepstral Coefficients (MFCC) and Mel-spectrogram features, supported by a multi-stage denoising process, involving discrete wavelet transform and spectral subtraction techniques, plus model and prototype update blocks. Unlike prior methods that restrict updates to specific layers, our approach updates the complete quantized model, made possible due to compact model architecture. A subset of input samples are selected during runtime using class prototypes and confidence-driven filtering, which are then pseudo-labeled and combined with rehearsal buffer for incremental model retraining. Experimental results on noisy test dataset demonstrate the framework&rsquo;s effectiveness, achieving 99.63% accuracy on clean data and maintaining robust performance (exceeding 94% accuracy) across diverse noisy environments, even at -10 dB Signal-to-Noise Ratio. The proposed framework work confirms that integrating efficient denoising with prototype-based continual learning enables KWS models to operate autonomously and robustly in resource-constrained, dynamic environments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16158v1">üìÑ Download PDF</a></p><hr><h3 id=samtok-representing-any-mask-with-two-wordshttpsarxivorgabs260116093v1><a href=https://arxiv.org/abs/2601.16093v1>SAMTok: Representing Any Mask with Two Words</a><a hidden class=anchor aria-hidden=true href=#samtok-representing-any-mask-with-two-wordshttpsarxivorgabs260116093v1>#</a></h3><p><strong>Authors:</strong> Yikang Zhou, Tao Zhang, Dengxian Gong, Yuanzheng Wu, Ye Tian, Haochen Wang, Haobo Yuan, Jiacong Wang, Lu Qi, Hao Fei, Anran Wang, Zhuochen Wang, Yujing Wang, Cheng Chen, Shunping Ji, Xiangtai Li
<strong>Venue:</strong> arXiv (2026)</p><p>Pixel-wise capabilities are essential for building interactive intelligent systems. However, pixel-wise multi-modal LLMs (MLLMs) remain difficult to scale due to complex region-level encoders, specialized segmentation decoders, and incompatible training objectives. To address these challenges, we present SAMTok, a discrete mask tokenizer that converts any region mask into two special tokens and reconstructs the mask using these tokens with high fidelity. By treating masks as new language tokens, SAMTok enables base MLLMs (such as the QwenVL series) to learn pixel-wise capabilities through standard next-token prediction and simple reinforcement learning, without architectural modifications and specialized loss design. SAMTok builds on SAM2 and is trained on 209M diverse masks using a mask encoder and residual vector quantizer to produce discrete, compact, and information-rich tokens. With 5M SAMTok-formatted mask understanding and generation data samples, QwenVL-SAMTok attains state-of-the-art or comparable results on region captioning, region VQA, grounded conversation, referring segmentation, scene graph parsing, and multi-round interactive segmentation. We further introduce a textual answer-matching reward that enables efficient reinforcement learning for mask generation, delivering substantial improvements on GRES and GCG benchmarks. Our results demonstrate a scalable and straightforward paradigm for equipping MLLMs with strong pixel-wise capabilities. Our code and models are available.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16093v1">üìÑ Download PDF</a></p><hr><h3 id=moleculariq-characterizing-chemical-reasoning-capabilities-through-symbolic-verification-on-molecular-graphshttpsarxivorgabs260115279v1><a href=https://arxiv.org/abs/2601.15279v1>MolecularIQ: Characterizing Chemical Reasoning Capabilities Through Symbolic Verification on Molecular Graphs</a><a hidden class=anchor aria-hidden=true href=#moleculariq-characterizing-chemical-reasoning-capabilities-through-symbolic-verification-on-molecular-graphshttpsarxivorgabs260115279v1>#</a></h3><p><strong>Authors:</strong> Christoph Bartmann, Johannes Schimunek, Mykyta Ielanskyi, Philipp Seidl, G√ºnter Klambauer, Sohvi Luukkonen
<strong>Venue:</strong> arXiv (2026)</p><p>A molecule&rsquo;s properties are fundamentally determined by its composition and structure encoded in its molecular graph. Thus, reasoning about molecular properties requires the ability to parse and understand the molecular graph. Large Language Models (LLMs) are increasingly applied to chemistry, tackling tasks such as molecular name conversion, captioning, text-guided generation, and property or reaction prediction. Most existing benchmarks emphasize general chemical knowledge, rely on literature or surrogate labels that risk leakage or bias, or reduce evaluation to multiple-choice questions. We introduce MolecularIQ, a molecular structure reasoning benchmark focused exclusively on symbolically verifiable tasks. MolecularIQ enables fine-grained evaluation of reasoning over molecular graphs and reveals capability patterns that localize model failures to specific tasks and molecular structures. This provides actionable insights into the strengths and limitations of current chemistry LLMs and guides the development of models that reason faithfully over molecular structure.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15279v1">üìÑ Download PDF</a></p><hr><h3 id=interpreting-multimodal-communication-at-scale-in-short-form-video-visual-audio-and-textual-mental-health-discourse-on-tiktokhttpsarxivorgabs260115278v1><a href=https://arxiv.org/abs/2601.15278v1>Interpreting Multimodal Communication at Scale in Short-Form Video: Visual, Audio, and Textual Mental Health Discourse on TikTok</a><a hidden class=anchor aria-hidden=true href=#interpreting-multimodal-communication-at-scale-in-short-form-video-visual-audio-and-textual-mental-health-discourse-on-tiktokhttpsarxivorgabs260115278v1>#</a></h3><p><strong>Authors:</strong> Mingyue Zha, Ho-Chun Herbert Chang
<strong>Venue:</strong> arXiv (2026)</p><p>Short-form video platforms integrate text, visuals, and audio into complex communicative acts, yet existing research analyzes these modalities in isolation, lacking scalable frameworks to interpret their joint contributions. This study introduces a pipeline combining automated multimodal feature extraction with Shapley value-based interpretability to analyze how text, visuals, and audio jointly influence engagement. Applying this framework to 162,965 TikTok videos and 814,825 images about social anxiety disorder (SAD), we find that facial expressions outperform textual sentiment in predicting viewership, informational content drives more attention than emotional support, and cross-modal synergies exhibit threshold-dependent effects. These findings demonstrate how multimodal analysis reveals interaction patterns invisible to single-modality approaches. Methodologically, we contribute a reproducible framework for interpretable multimodal research applicable across domains; substantively, we advance understanding of mental health communication in algorithmically mediated environments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15278v1">üìÑ Download PDF</a></p><hr><h3 id=large-scale-multidimensional-knowledge-profiling-of-scientific-literaturehttpsarxivorgabs260115170v1><a href=https://arxiv.org/abs/2601.15170v1>Large-Scale Multidimensional Knowledge Profiling of Scientific Literature</a><a hidden class=anchor aria-hidden=true href=#large-scale-multidimensional-knowledge-profiling-of-scientific-literaturehttpsarxivorgabs260115170v1>#</a></h3><p><strong>Authors:</strong> Zhucun Xue, Jiangning Zhang, Juntao Jiang, Jinzhuo Liu, Haoyang He, Teng Hu, Xiaobin Hu, Guangming Yao, Yi Yuan, Yong Liu
<strong>Venue:</strong> arXiv (2026)</p><p>The rapid expansion of research across machine learning, vision, and language has produced a volume of publications that is increasingly difficult to synthesize. Traditional bibliometric tools rely mainly on metadata and offer limited visibility into the semantic content of papers, making it hard to track how research themes evolve over time or how different areas influence one another. To obtain a clearer picture of recent developments, we compile a unified corpus of more than 100,000 papers from 22 major conferences between 2020 and 2025 and construct a multidimensional profiling pipeline to organize and analyze their textual content. By combining topic clustering, LLM-assisted parsing, and structured retrieval, we derive a comprehensive representation of research activity that supports the study of topic lifecycles, methodological transitions, dataset and model usage patterns, and institutional research directions. Our analysis highlights several notable shifts, including the growth of safety, multimodal reasoning, and agent-oriented studies, as well as the gradual stabilization of areas such as neural machine translation and graph-based methods. These findings provide an evidence-based view of how AI research is evolving and offer a resource for understanding broader trends and identifying emerging directions. Code and dataset: <a href=https://github.com/xzc-zju/Profiling_Scientific_Literature>https://github.com/xzc-zju/Profiling_Scientific_Literature</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15170v1">üìÑ Download PDF</a></p><hr><h3 id=delog-an-efficient-log-compression-framework-with-pattern-signature-synthesishttpsarxivorgabs260115084v2><a href=https://arxiv.org/abs/2601.15084v2>DeLog: An Efficient Log Compression Framework with Pattern Signature Synthesis</a><a hidden class=anchor aria-hidden=true href=#delog-an-efficient-log-compression-framework-with-pattern-signature-synthesishttpsarxivorgabs260115084v2>#</a></h3><p><strong>Authors:</strong> Siyu Yu, Yifan Wu, Junjielong Xu, Ying Fu, Ning Wang, Maoyin Liu, Pancheng Jiang, Xiang Zhang, Tong Jia, Pinjia He, Ying Li
<strong>Venue:</strong> arXiv (2026)</p><p>Parser-based log compression, which separates static templates from dynamic variables, is a promising approach to exploit the unique structure of log data. However, its performance on complex production logs is often unsatisfactory. This performance gap coincides with a known degradation in the accuracy of its core log parsing component on such data, motivating our investigation into a foundational yet unverified question: does higher parsing accuracy necessarily lead to better compression ratio?
To answer this, we conduct the first empirical study quantifying this relationship and find that a higher parsing accuracy does not guarantee a better compression ratio. Instead, our findings reveal that compression ratio is dictated by achieving effective pattern-based grouping and encoding, i.e., the partitioning of tokens into low entropy, highly compressible groups.
Guided by this insight, we design DeLog, a novel log compressor that implements a Pattern Signature Synthesis mechanism to achieve efficient pattern-based grouping. On 16 public and 10 production datasets, DeLog achieves state-of-the-art compression ratio and speed.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15084v2">üìÑ Download PDF</a></p><hr><h3 id=just-aware-enough-evaluating-awareness-across-artificial-systemshttpsarxivorgabs260114901v1><a href=https://arxiv.org/abs/2601.14901v1>Just aware enough: Evaluating awareness across artificial systems</a><a hidden class=anchor aria-hidden=true href=#just-aware-enough-evaluating-awareness-across-artificial-systemshttpsarxivorgabs260114901v1>#</a></h3><p><strong>Authors:</strong> Nadine Meertens, Suet Lee, Ophelia Deroy
<strong>Venue:</strong> arXiv (2026)</p><p>Recent debates on artificial intelligence increasingly emphasise questions of AI consciousness and moral status, yet there remains little agreement on how such properties should be evaluated. In this paper, we argue that awareness offers a more productive and methodologically tractable alternative. We introduce a practical method for evaluating awareness across diverse systems, where awareness is understood as encompassing a system&rsquo;s abilities to process, store and use information in the service of goal-directed action. Central to this approach is the claim that any evaluation aiming to capture the diversity of artificial systems must be domain-sensitive, deployable at any scale, multidimensional, and enable the prediction of task performance, while generalising to the level of abilities for the sake of comparison. Given these four desiderata, we outline a structured approach to evaluating and comparing awareness profiles across artificial systems with differing architectures, scales, and operational domains. By shifting the focus from artificial consciousness to being just aware enough, this approach aims to facilitate principled assessment, support design and oversight, and enable more constructive scientific and public discourse.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.14901v1">üìÑ Download PDF</a></p><hr><h3 id=universal-non-gaussian-order-parameter-statistics-in-2d-superfluidshttpsarxivorgabs260116204v1><a href=https://arxiv.org/abs/2601.16204v1>Universal non-Gaussian order parameter statistics in 2D superfluids</a><a hidden class=anchor aria-hidden=true href=#universal-non-gaussian-order-parameter-statistics-in-2d-superfluidshttpsarxivorgabs260116204v1>#</a></h3><p><strong>Authors:</strong> Abel Beregi, En Chang, Erik Rydow, Christopher J. Foot, Shinichi Sunami
<strong>Venue:</strong> arXiv (2026)</p><p>Fluctuations are an intrinsic feature of many-body systems, and their full statistical distributions reveal a wealth of information about the underlying physics. Of particular interest are non-Gaussian, extreme-value statistics that arise when nontrivial correlations and criticality dominate over the central limit theorem. Strikingly, in two-dimensional (2D) quantum fluids, such effects have been predicted to manifest in the order parameter distribution in the Berezinskii-Kosterlitz-Thouless (BKT) superfluid phase, which approaches a universal extreme-value form in the low-temperature limit. Here, we measure the order parameter statistics of 2D Bose gases across the BKT critical point using matter-wave interferometry. This allows us to confirm the predicted convergence of the observed statistics to a universal Gumbel distribution at low temperatures, to the 0.1% level of the probability density. Furthermore, the intrinsic precision of the atom interferometer allows the robust extraction of higher-moment observables such as skewness and kurtosis; in particular, we report direct measurements of the Binder cumulant which allows us to precisely identify the onset of the phase transition. Extending this approach to the investigation of non-equilibrium systems, we probe vortex unbinding dynamics following a quench across the BKT critical point and identify parameter-independent scaling behaviour of higher moments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16204v1">üìÑ Download PDF</a></p><hr><h3 id=studying-energy-resolved-transport-with-wavepacket-dynamics-on-quantum-computershttpsarxivorgabs260116180v1><a href=https://arxiv.org/abs/2601.16180v1>Studying energy-resolved transport with wavepacket dynamics on quantum computers</a><a hidden class=anchor aria-hidden=true href=#studying-energy-resolved-transport-with-wavepacket-dynamics-on-quantum-computershttpsarxivorgabs260116180v1>#</a></h3><p><strong>Authors:</strong> Melody Lee, Roland C. Farrell
<strong>Venue:</strong> arXiv (2026)</p><p>Probing energy-dependent transport in quantum simulators requires preparing states with tunable energy and small energy variance. Existing approaches often study quench dynamics of simple initial states, such as computational basis states, which are far from energy eigenstates and therefore limit the achievable energy resolution. In this work, we propose using wavepackets to probe transport properties with improved energy resolution. To demonstrate the utility of this approach, we prepare and evolve wavepackets on Quantinuum&rsquo;s H2-2 quantum computer and identify an energy-dependent localization transition in the Anderson model on an 8x7 lattice&ndash;a finite-size mobility edge. We observe that a wavepacket initialized at low energy remains spatially localized under time evolution, while a high-energy wavepacket delocalizes, consistent with the presence of a mobility edge. Crucial to our experiments is an error mitigation strategy that infers the noiseless output bit string distribution using maximum-likelihood estimation. Compared to post-selection, this method removes systematic errors and reduces statistical uncertainty by up to a factor of 5. We extend our methods to the many-particle regime by developing a quantum algorithm for preparing quasiparticle wavepackets in a one-dimensional model of interacting fermions. This technique has modest quantum resource requirements, making wavepacket-based studies of transport in many-body systems a promising application for near-term quantum computers.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16180v1">üìÑ Download PDF</a></p><hr><h3 id=the-farview-low-frequency-radio-array-on-the-moons-far-side-science-and-array-architecturehttpsarxivorgabs260116170v1><a href=https://arxiv.org/abs/2601.16170v1>The FarView Low Frequency Radio Array on the Moon&rsquo;s Far Side: Science and Array Architecture</a><a hidden class=anchor aria-hidden=true href=#the-farview-low-frequency-radio-array-on-the-moons-far-side-science-and-array-architecturehttpsarxivorgabs260116170v1>#</a></h3><p><strong>Authors:</strong> Jack O. Burns, Judd Bowman, Tzu-Ching Chang, Gregg Hallinan, Alex Hegedus, Nivedita Mahesh, Bang Nhan, Jonathan Pober, Ronald Polidan, Willow Smith, Nithyanandan Thyagarajan
<strong>Venue:</strong> arXiv (2026)</p><p>FarView is a proposed low frequency radio interferometer for deployment on the lunar far side, enabled by the Moon&rsquo;s radio quiet environment. Operating over 1-50 MHz inaccessible from Earth, FarView will open a new observational window and promote discovery class science in cosmology, heliophysics, Galactic and exoplanet astrophysics. The primary science is measurement of the redshifted 21 cm signal from the Cosmic Dark Ages (z=30-100), identified by the Astro2020 Decadal Survey as a priority cosmology discovery area. FarView will deliver 3D tomographic measurements and precision power spectra of neutral hydrogen in a largely linear regime, enabling tests of inflationary initial conditions, primordial non Gaussianity, dark matter properties, neutrino masses, and early dark energy. The reference design consists of 100000 crossed dipole antennas in a dense core-halo configuration spanning 200 sq km. A compact 4 km core with 83000 dipoles maximizes sensitivity to large scale cosmological modes, while 20000 halo elements extending to 14 km provide angular resolution and calibration for foreground characterization. Sensitivity forecasts indicate a 10-sigma detection of the Dark Ages 21 cm power spectrum at z=30 over five years of half duty cycle lunar night observations. An FFT-based EPIC beamformer is identified as an efficient signal processing architecture. Beyond cosmology, FarView will enable interferometric imaging of low frequency solar radio bursts, advancing space weather studies. Additional capabilities include stellar space weather observations, Galactic cosmic ray tomography via free-free absorption, and searches for auroral radio emission from exoplanet magnetospheres, a probe of exoplanet habitability. FarView represents a flagship class opportunity to establish the Moon as a platform for foundational astrophysics while delivering unique observational capabilities.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16170v1">üìÑ Download PDF</a></p><hr><h3 id=reanalyzing-desi-dr1-4-percent-level-cosmological-constraints-from-combined-probes-and-robust-evidence-for-the-normal-neutrino-mass-hierarchyhttpsarxivorgabs260116165v1><a href=https://arxiv.org/abs/2601.16165v1>Reanalyzing DESI DR1: 4. Percent-Level Cosmological Constraints from Combined Probes and Robust Evidence for the Normal Neutrino Mass Hierarchy</a><a hidden class=anchor aria-hidden=true href=#reanalyzing-desi-dr1-4-percent-level-cosmological-constraints-from-combined-probes-and-robust-evidence-for-the-normal-neutrino-mass-hierarchyhttpsarxivorgabs260116165v1>#</a></h3><p><strong>Authors:</strong> Mikhail M. Ivanov, James M. Sullivan, Shi-Fan Chen, Anton Chudaykin, Mark Maus, Oliver H. E. Philcox
<strong>Venue:</strong> arXiv (2026)</p><p>We present cosmological parameters measurements from the full combination of DESI DR1 galaxy clustering data described with large-scale structure effective field theory. By incorporating additional datasets (photometric galaxies and CMB lensing cross-correlations) and extending the bispectrum likelihood to smaller scales using a consistent one-loop theory computation, we achieve substantial gains in constraining power relative to previous analyses. Combining with the latest DESI baryon acoustic oscillation data and using cosmic microwave background (CMB) priors on the power spectrum tilt and baryon density, we obtain tight constraints on the $Œõ$CDM model, finding the Hubble constant $H_0=69.08\pm 0.37~\mathrm{km},\mathrm{s}^{-1}\mathrm{Mpc}^{-1}$, the matter density fraction $Œ©_m=0.2973\pm 0.0050$, and the mass fluctuation amplitude $œÉ_8 = 0.815\pm 0.016$ (or the lensing parameter $S_8\equivœÉ_8\sqrt{Œ©_m/0.3}=0.811\pm 0.016$), corresponding to $0.6%$, $1.7%$, and $2%$ precision respectively. Adding the Pantheon+ supernova sample (SNe), we find a preference of $2.6œÉ$ for the $w_0w_a$ dynamical dark energy model from low-redshift data alone, which increases to $2.8œÉ$ when exchanging the SNe with Planck CMB data. Combining full-shape data with BAO, CMB, and SNe likelihoods, we improve the dark energy figure-of-merit by $18%$ and bound the sum of the neutrino masses to $M_ŒΩ&lt;0.057$ eV in $Œõ$CDM and $M_ŒΩ&lt;0.095$ eV in the $w_0w_a$ dynamical dark energy model (both at 95% CL). This represents an improvement of $25%$ over the background expansion constraints and the strongest bound on neutrino masses in $w_0w_a$CDM to date. Our results suggest that the preference for the normal ordering of neutrino mass states holds regardless of the cosmological background model, and is robust in light of tensions between cosmological datasets.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16165v1">üìÑ Download PDF</a></p><hr><h3 id=automatic-classification-of-arabic-literature-into-historical-erashttpsarxivorgabs260116138v1><a href=https://arxiv.org/abs/2601.16138v1>Automatic Classification of Arabic Literature into Historical Eras</a><a hidden class=anchor aria-hidden=true href=#automatic-classification-of-arabic-literature-into-historical-erashttpsarxivorgabs260116138v1>#</a></h3><p><strong>Authors:</strong> Zainab Alhathloul, Irfan Ahmad
<strong>Venue:</strong> arXiv (2026)</p><p>The Arabic language has undergone notable transformations over time, including the emergence of new vocabulary, the obsolescence of others, and shifts in word usage. This evolution is evident in the distinction between the classical and modern Arabic eras. Although historians and linguists have partitioned Arabic literature into multiple eras, relatively little research has explored the automatic classification of Arabic texts by time period, particularly beyond the domain of poetry. This paper addresses this gap by employing neural networks and deep learning techniques to automatically classify Arabic texts into distinct eras and periods. The proposed models are evaluated using two datasets derived from two publicly available corpora, covering texts from the pre-Islamic to the modern era. The study examines class setups ranging from binary to 15-class classification and considers both predefined historical eras and custom periodizations. Results range from F1-scores of 0.83 and 0.79 on the binary-era classification task using the OpenITI and APCD datasets, respectively, to 0.20 on the 15-era classification task using OpenITI and 0.18 on the 12-era classification task using APCD.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16138v1">üìÑ Download PDF</a></p><hr><h3 id=biexcitons-in-ruddlesden-popper-metal-halides-probed-by-nonlinear-coherent-spectroscopyhttpsarxivorgabs260116101v1><a href=https://arxiv.org/abs/2601.16101v1>Biexcitons in Ruddlesden-Popper Metal Halides Probed by Nonlinear Coherent Spectroscopy</a><a hidden class=anchor aria-hidden=true href=#biexcitons-in-ruddlesden-popper-metal-halides-probed-by-nonlinear-coherent-spectroscopyhttpsarxivorgabs260116101v1>#</a></h3><p><strong>Authors:</strong> Katherine A. Koch, Carlos Silva-Acu√±a, Ajay Ram Srimath Kandada
<strong>Venue:</strong> arXiv (2026)</p><p>Excitons and their correlated complexes underpin the rich photophysics of quantum-confined semiconductors. Among these, biexcitons &ndash; bound states of two electrons and two holes &ndash; provide a sensitive probe of Coulomb correlations, exciton-exciton interactions, and the role of the dielectric environment. In Ruddlesden-Popper metal halide materials (RPMHs), strong quantum and dielectric confinement stabilize excitons with binding energies of hundreds of meV, creating an ideal platform for multi-exciton phenomena. Conventional linear spectroscopies, such as photoluminescence and transient absorption, reveal biexciton signatures but suffer from spectral congestion and reabsorption artifacts. Two-dimensional coherent spectroscopies, particularly two-quantum (2Q) multidimensional techniques, uniquely access multi-exciton coherences and provide unambiguous estimates of biexciton binding energies. This minireview surveys the spectroscopic evidence for biexcitons in RPMHs, highlights the advantages of nonlinear multidimensional approaches, and situates biexciton physics within the broader context of excitonic materials, including GaAs quantum wells, quantum dots, and transition-metal dichalcogenides. By emphasizing the interplay of exciton-exciton annihilation, excitation-induced dephasing, and biexciton formation, we argue that multidimensional coherent spectroscopy offers the most reliable pathway to disentangle many-body interactions in quantum-well derivatives of metal-halide perovskites.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16101v1">üìÑ Download PDF</a></p><hr><h3 id=the-pohozaev-identity-for-the-spectral-fractional-laplacianhttpsarxivorgabs260116185v1><a href=https://arxiv.org/abs/2601.16185v1>The Pohozaev identity for the Spectral Fractional Laplacian</a><a hidden class=anchor aria-hidden=true href=#the-pohozaev-identity-for-the-spectral-fractional-laplacianhttpsarxivorgabs260116185v1>#</a></h3><p><strong>Authors:</strong> Itahisa Barrios-Cubas, Matteo Bonforte, Mar√≠a del Mar Gonz√°lez, Clara Torres-Latorre
<strong>Venue:</strong> arXiv (2026)</p><p>In this paper, we prove a Pohozaev identity for the Spectral Fractional Laplacian (SFL). This identity allows us to establish non-existence results for the semilinear Dirichlet problem $(-Œî|_Œ©)^su = f(u)$ in star-shaped domains. The first such identity for non-local operators was established by Ros-Oton and Serra in 2014 for the Restricted Fractional Laplacian (RFL). However, the SFL differs fundamentally from the RFL, and the integration by parts strategy of Ros-Oton and Serra cannot be applied. Instead, we develop a novel spectral approach that exploits the underlying quadratic structure. Our main result expresses the identity as a Schur product of the classical Pohozaev quadratic form and a transition matrix that depends on the eigenvalues of the Laplacian and the fractional exponent.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16185v1">üìÑ Download PDF</a></p><hr><h3 id=mild-solutions-for-path-dependent-parabolic-pdes-with-neumann-boundary-conditions-via-generalized-bsdeshttpsarxivorgabs260116178v1><a href=https://arxiv.org/abs/2601.16178v1>Mild Solutions for Path-Dependent Parabolic PDEs with Neumann Boundary Conditions via Generalized BSDEs</a><a hidden class=anchor aria-hidden=true href=#mild-solutions-for-path-dependent-parabolic-pdes-with-neumann-boundary-conditions-via-generalized-bsdeshttpsarxivorgabs260116178v1>#</a></h3><p><strong>Authors:</strong> Luca Di Persio, Matteo Garbelli, Adrian Zalinescu
<strong>Venue:</strong> arXiv (2026)</p><p>We study a system of Forward-Backward Stochastic Differential Equations (FBSDEs) with time-delayed generators. The forward process includes a reflection component expressed via a Stieltjes integral, while the backward process takes the form of a Generalized BSDE. We establish the connection between this FBSDE system and non-linear path-dependent PDEs with Neumann boundary conditions by deriving a representation formula.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16178v1">üìÑ Download PDF</a></p><hr><h3 id=beyond-predictive-uncertainty-reliable-representation-learning-with-structural-constraintshttpsarxivorgabs260116174v1><a href=https://arxiv.org/abs/2601.16174v1>Beyond Predictive Uncertainty: Reliable Representation Learning with Structural Constraints</a><a hidden class=anchor aria-hidden=true href=#beyond-predictive-uncertainty-reliable-representation-learning-with-structural-constraintshttpsarxivorgabs260116174v1>#</a></h3><p><strong>Authors:</strong> Yiyao Yang
<strong>Venue:</strong> arXiv (2026)</p><p>Uncertainty estimation in machine learning has traditionally focused on the prediction stage, aiming to quantify confidence in model outputs while treating learned representations as deterministic and reliable by default. In this work, we challenge this implicit assumption and argue that reliability should be regarded as a first-class property of learned representations themselves. We propose a principled framework for reliable representation learning that explicitly models representation-level uncertainty and leverages structural constraints as inductive biases to regularize the space of feasible representations. Our approach introduces uncertainty-aware regularization directly in the representation space, encouraging representations that are not only predictive but also stable, well-calibrated, and robust to noise and structural perturbations. Structural constraints, such as sparsity, relational structure, or feature-group dependencies, are incorporated to define meaningful geometry and reduce spurious variability in learned representations, without assuming fully correct or noise-free structure. Importantly, the proposed framework is independent of specific model architectures and can be integrated with a wide range of representation learning methods.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16174v1">üìÑ Download PDF</a></p><hr><h3 id=ctl-model-checking-on-infinite-families-of-finite-state-labeled-transition-systems-technical-reporthttpsarxivorgabs260115756v1><a href=https://arxiv.org/abs/2601.15756v1>CTL* Model Checking on Infinite Families of Finite-State Labeled Transition Systems (Technical Report)</a><a hidden class=anchor aria-hidden=true href=#ctl-model-checking-on-infinite-families-of-finite-state-labeled-transition-systems-technical-reporthttpsarxivorgabs260115756v1>#</a></h3><p><strong>Authors:</strong> Roberto Pettinau, Christoph Matheja
<strong>Venue:</strong> arXiv (2026)</p><p>We study model checking algorithms for infinite families of finite-state labeled transition systems against temporal properties written in CTL*. Such families arise, for example, as models of highly configurable systems or software product lines.
We model families using context-free graph grammars. We then develop a state labeling algorithm that works compositionally on the grammar&rsquo;s production rules with limited information about the context in which the rule is applied. The result is a graph grammar modeling the same family but with extended labels. We leverage this grammar to decide whether all, some, or (in)finitely many members of a family satisfy a given temporal property. We have implemented our algorithms and present early experiments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15756v1">üìÑ Download PDF</a></p><hr><h3 id=beyond-visual-safety-jailbreaking-multimodal-large-language-models-for-harmful-image-generation-via-semantic-agnostic-inputshttpsarxivorgabs260115698v1><a href=https://arxiv.org/abs/2601.15698v1>Beyond Visual Safety: Jailbreaking Multimodal Large Language Models for Harmful Image Generation via Semantic-Agnostic Inputs</a><a hidden class=anchor aria-hidden=true href=#beyond-visual-safety-jailbreaking-multimodal-large-language-models-for-harmful-image-generation-via-semantic-agnostic-inputshttpsarxivorgabs260115698v1>#</a></h3><p><strong>Authors:</strong> Mingyu Yu, Lana Liu, Zhehao Zhao, Wei Wang, Sujuan Qin
<strong>Venue:</strong> arXiv (2026)</p><p>The rapid advancement of Multimodal Large Language Models (MLLMs) has introduced complex security challenges, particularly at the intersection of textual and visual safety. While existing schemes have explored the security vulnerabilities of MLLMs, the investigation into their visual safety boundaries remains insufficient. In this paper, we propose Beyond Visual Safety (BVS), a novel image-text pair jailbreaking framework specifically designed to probe the visual safety boundaries of MLLMs. BVS employs a &ldquo;reconstruction-then-generation&rdquo; strategy, leveraging neutralized visual splicing and inductive recomposition to decouple malicious intent from raw inputs, thereby leading MLLMs to be induced into generating harmful images. Experimental results demonstrate that BVS achieves a remarkable jailbreak success rate of 98.21% against GPT-5 (12 January 2026 release). Our findings expose critical vulnerabilities in the visual safety alignment of current MLLMs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15698v1">üìÑ Download PDF</a></p><hr><h3 id=prism-deriving-the-transformer-as-a-signal-denoising-operator-via-maximum-coding-rate-reductionhttpsarxivorgabs260115540v1><a href=https://arxiv.org/abs/2601.15540v1>PRISM: Deriving the Transformer as a Signal-Denoising Operator via Maximum Coding Rate Reduction</a><a hidden class=anchor aria-hidden=true href=#prism-deriving-the-transformer-as-a-signal-denoising-operator-via-maximum-coding-rate-reductionhttpsarxivorgabs260115540v1>#</a></h3><p><strong>Authors:</strong> Dongchen Huang
<strong>Venue:</strong> arXiv (2026)</p><p>Deep learning models, particularly Transformers, are often criticized as &ldquo;black boxes&rdquo; and lack interpretability. We propose Prism, a white-box attention-based architecture derived from the principles of Maximizing Coding Rate Reduction ($\text{MCR}^2$). By modeling the attention mechanism as a gradient ascent process on a distinct signal-noise manifold, we introduce two physical constraints: an overcomplete dictionary to expand the representational phase space, and an irrational frequency separation ($œÄ$-RoPE) to enforce incoherence between signal and noise subspaces. We demonstrate that these geometric inductive biases can be viewed as a physical constraint and they are sufficient to induce unsupervised functional disentanglement alone. Using TinyStories as a controlled testbed for verifying spectral dynamics, we observe that Prism spontaneously specializes its attention heads into spectrally distinct regimes: low-frequency heads capturing long-range causal dependencies (signal) and high-frequency heads handling local syntactic constraints (noise). Our results suggest that interpretability and performance are not a trade-off, but can be unified through principled geometric construction.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15540v1">üìÑ Download PDF</a></p><hr><h3 id=testing-deep-learning-libraries-via-neurosymbolic-constraint-learninghttpsarxivorgabs260115493v1><a href=https://arxiv.org/abs/2601.15493v1>Testing Deep Learning Libraries via Neurosymbolic Constraint Learning</a><a hidden class=anchor aria-hidden=true href=#testing-deep-learning-libraries-via-neurosymbolic-constraint-learninghttpsarxivorgabs260115493v1>#</a></h3><p><strong>Authors:</strong> M M Abid Naziri, Shinhae Kim, Feiran Qin, Marcelo d&rsquo;Amorim, Saikat Dutta
<strong>Venue:</strong> arXiv (2026)</p><p>Deep Learning (DL) libraries (e.g., PyTorch) are popular in AI development. These libraries are complex and contain bugs. Researchers have proposed various bug-finding techniques for such libraries. Yet, there is much room for improvement. A key challenge in testing DL libraries is the lack of API specifications. Prior testing approaches often inaccurately model the input specifications of DL APIs, resulting in missed valid inputs that could reveal bugs or false alarms due to invalid inputs.
To address this challenge, we develop Centaur &ndash; the first neurosymbolic technique to test DL library APIs using dynamically learned input constraints. Centaur leverages the key idea that formal API constraints can be learned from a small number of automatically generated seed inputs, and that the learned constraints can be solved using SMT solvers to generate valid and diverse test inputs.
We develop a novel grammar that represents first-order logic formulae over API parameters and expresses tensor-related properties (e.g., shape, data types) as well as relational properties between parameters. We use the grammar to guide a Large Language Model (LLM) to enumerate syntactically correct candidate rules, validated using seed inputs. Further, we develop a custom refinement strategy to prune the set of learned rules to eliminate spurious or redundant rules. We use the learned constraints to systematically generate valid and diverse inputs by integrating SMT-based solving with randomized sampling.
We evaluate Centaur for testing PyTorch and TensorFlow. Our results show that Centaur&rsquo;s constraints have a recall of 94.0% and a precision of 94.0% on average. In terms of coverage, Centaur covers 203, 150, and 9,608 more branches than TitanFuzz, ACETest and Pathfinder, respectively. Using Centaur, we also detect 26 new bugs in PyTorch and TensorFlow, 18 of which are confirmed.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15493v1">üìÑ Download PDF</a></p><hr><h3 id=on-the-diagonal-of-low-bidegree-hypersurfaceshttpsarxivorgabs260115409v1><a href=https://arxiv.org/abs/2601.15409v1>On the diagonal of low bidegree hypersurfaces</a><a hidden class=anchor aria-hidden=true href=#on-the-diagonal-of-low-bidegree-hypersurfaceshttpsarxivorgabs260115409v1>#</a></h3><p><strong>Authors:</strong> Morten L√ºders, Elia Fiammengo
<strong>Venue:</strong> arXiv (2026)</p><p>We study the existence of a decomposition of the diagonal for bidegree hypersurfaces in a product of projective spaces. Using a cycle theoretic degeneration technique due to Lange, Pavic and Schreieder, we develop an inductive procedure that allows one to raise the degree and dimension starting from the quadric surface bundle of Hassett, Pirutka and Tschinkel. Furthermore, we are able to raise the dimension without raising the degree in a special case, showing that a very general $(3,2)$ complete intersection in $\mathbb P^4\times \mathbb P^3$ does not admit a decomposition of the diagonal. As a corollary of these theorems, we show that in a certain range, bidegree hypersurfaces which were previously only known to be stably irrational over fields of characteristic zero by results of Moe, Nicaise and Ottem, are not retract rational over fields of characteristic different from two.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15409v1">üìÑ Download PDF</a></p><hr><h2 id=-psycholinguistics>üîç psycholinguistics<a hidden class=anchor aria-hidden=true href=#-psycholinguistics>#</a></h2><h3 id=stochastic-control-barrier-functions-under-state-estimation-from-euclidean-space-to-lie-groupshttpsarxivorgabs260116198v1><a href=https://arxiv.org/abs/2601.16198v1>Stochastic Control Barrier Functions under State Estimation: From Euclidean Space to Lie Groups</a><a hidden class=anchor aria-hidden=true href=#stochastic-control-barrier-functions-under-state-estimation-from-euclidean-space-to-lie-groupshttpsarxivorgabs260116198v1>#</a></h3><p><strong>Authors:</strong> Ruoyu Lin, Magnus Egerstedt
<strong>Venue:</strong> arXiv (2026)</p><p>Ensuring safety for autonomous systems under uncertainty remains challenging, particularly when safety of the true state is required despite the true state not being fully known. Control barrier functions (CBFs) have become widely adopted as safety filters. However, standard CBF formulations do not explicitly account for state estimation uncertainty and its propagation, especially for stochastic systems evolving on manifolds. In this paper, we propose a safety-critical control framework with a provable bound on the finite-time safety probability for stochastic systems under noisy state information. The proposed framework explicitly incorporates the uncertainty arising from both process and measurement noise, and synthesizes controllers that adapt to the level of uncertainty. The framework admits closed-form solutions in linear settings, and experimental results demonstrate its effectiveness on systems whose state spaces range from Euclidean space to Lie groups.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16198v1">üìÑ Download PDF</a></p><hr><h3 id=scaling-sample-based-quantum-diagonalization-on-gpu-accelerated-systems-using-openmp-offloadhttpsarxivorgabs260116169v1><a href=https://arxiv.org/abs/2601.16169v1>Scaling Sample-Based Quantum Diagonalization on GPU-Accelerated Systems using OpenMP Offload</a><a hidden class=anchor aria-hidden=true href=#scaling-sample-based-quantum-diagonalization-on-gpu-accelerated-systems-using-openmp-offloadhttpsarxivorgabs260116169v1>#</a></h3><p><strong>Authors:</strong> Robert Walkup, Juha J√§ykk√§, Igor Pasichnyk, Zachary Streeter, Kasia ≈öwirydowicz, Mikko Tukiainen, Yasuko Eckert, Luke Bertels, Daniel Claudino, Peter Groszkowski, Travis S. Humble, Constantinos Evangelinos, Javier Robledo-Moreno, William Kirby, Antonio Mezzacapo, Antonio C√≥rcoles, Seetharami Seelam
<strong>Venue:</strong> arXiv (2026)</p><p>Hybrid quantum-HPC algorithms advance research by delegating complex tasks to quantum processors and using HPC systems to orchestrate workflows and complementary computations. Sample-based quantum diagonalization (SQD) is a hybrid quantum-HPC method in which information from a molecular Hamiltonian is encoded into a quantum circuit for evaluation on a quantum computer. A set of measurements on the quantum computer yields electronic configurations that are filtered on the classical computer, which also performs diagonalization on the selected subspace and identifies configurations to be carried over to the next step in an iterative process. Diagonalization is the most demanding task for the classical computer. Previous studies used the Fugaku supercomputer and a highly scalable diagonalization code designed for CPUs. In this work, we describe our efforts to enable efficient scalable and portable diagonalization on heterogeneous systems using GPUs as the main compute engines based on the previous work.
GPUs provide massive on-device thread-level parallelism that is well aligned with the algorithms used for diagonalization. We focus on the computation of ground-state energies and wavefunctions using the Davidson algorithm with a selected set of electron configurations. We describe the offload strategy, code transformations, and data-movement, with examples of measurements on the Frontier supercomputer and five other GPU accelerated systems. Our measurements show that GPUs provide an outstanding performance boost of order 100x on a per-node basis. This dramatically expedites the diagonalization step-essential for extracting ground and excited state energies-bringing the classical processing time down from hours to minutes.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16169v1">üìÑ Download PDF</a></p><hr><h3 id=even-gpt-52-cant-count-to-five-the-case-for-zero-error-horizons-in-trustworthy-llmshttpsarxivorgabs260115714v1><a href=https://arxiv.org/abs/2601.15714v1>Even GPT-5.2 Can&rsquo;t Count to Five: The Case for Zero-Error Horizons in Trustworthy LLMs</a><a hidden class=anchor aria-hidden=true href=#even-gpt-52-cant-count-to-five-the-case-for-zero-error-horizons-in-trustworthy-llmshttpsarxivorgabs260115714v1>#</a></h3><p><strong>Authors:</strong> Ryoma Sato
<strong>Venue:</strong> arXiv (2026)</p><p>We propose Zero-Error Horizon (ZEH) for trustworthy LLMs, which represents the maximum range that a model can solve without any errors. While ZEH itself is simple, we demonstrate that evaluating the ZEH of state-of-the-art LLMs yields abundant insights. For example, by evaluating the ZEH of GPT-5.2, we found that GPT-5.2 cannot even compute the parity of a short string like 11000, and GPT-5.2 cannot determine whether the parentheses in ((((()))))) are balanced. This is surprising given the excellent capabilities of GPT-5.2. The fact that LLMs make mistakes on such simple problems serves as an important lesson when applying LLMs to safety-critical domains. By applying ZEH to Qwen2.5 and conducting detailed analysis, we found that while ZEH correlates with accuracy, the detailed behaviors differ, and ZEH provides clues about the emergence of algorithmic capabilities. Finally, while computing ZEH incurs significant computational cost, we discuss how to mitigate this cost by achieving up to one order of magnitude speedup using tree structures and online softmax.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15714v1">üìÑ Download PDF</a></p><hr><h3 id=predictive-coding-and-information-bottleneck-for-hallucination-detection-in-large-language-modelshttpsarxivorgabs260115652v1><a href=https://arxiv.org/abs/2601.15652v1>Predictive Coding and Information Bottleneck for Hallucination Detection in Large Language Models</a><a hidden class=anchor aria-hidden=true href=#predictive-coding-and-information-bottleneck-for-hallucination-detection-in-large-language-modelshttpsarxivorgabs260115652v1>#</a></h3><p><strong>Authors:</strong> Manish Bhatt
<strong>Venue:</strong> arXiv (2026)</p><p>Hallucinations in Large Language Models (LLMs) &ndash; generations that are plausible but factually unfaithful &ndash; remain a critical barrier to high-stakes deployment. Current detection methods typically rely on computationally expensive external retrieval loops or opaque black-box LLM judges requiring 70B+ parameters. In this work, we introduce [Model Name], a hybrid detection framework that combines neuroscience-inspired signal design with supervised machine learning. We extract interpretable signals grounded in Predictive Coding (quantifying surprise against internal priors) and the Information Bottleneck (measuring signal retention under perturbation). Through systematic ablation, we demonstrate three key enhancements: Entity-Focused Uptake (concentrating on high-value tokens), Context Adherence (measuring grounding strength), and Falsifiability Score (detecting confident but contradictory claims).
Evaluating on HaluBench (n=200, perfectly balanced), our theory-guided baseline achieves 0.8017 AUROC. BASE supervised models reach 0.8274 AUROC, while IMPROVED features boost performance to 0.8669 AUROC (4.95% gain), demonstrating consistent improvements across architectures. This competitive performance is achieved while using 75x less training data than Lynx (200 vs 15,000 samples), 1000x faster inference (5ms vs 5s), and remaining fully interpretable. Crucially, we report a negative result: the Rationalization signal fails to distinguish hallucinations, suggesting that LLMs generate coherent reasoning for false premises (&ldquo;Sycophancy&rdquo;).
This work demonstrates that domain knowledge encoded in signal architecture provides superior data efficiency compared to scaling LLM judges, achieving strong performance with lightweight (less than 1M parameter), explainable models suitable for production deployment.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15652v1">üìÑ Download PDF</a></p><hr><h3 id=coloring-small-locally-sparse-degenerate-graphs-and-related-problemshttpsarxivorgabs260115245v1><a href=https://arxiv.org/abs/2601.15245v1>Coloring small locally sparse degenerate graphs and related problems</a><a hidden class=anchor aria-hidden=true href=#coloring-small-locally-sparse-degenerate-graphs-and-related-problemshttpsarxivorgabs260115245v1>#</a></h3><p><strong>Authors:</strong> Domagoj Bradaƒç, Jacob Fox, Raphael Steiner, Benny Sudakov, Shengtong Zhang
<strong>Venue:</strong> arXiv (2026)</p><p>The classic upper bound on the chromatic number of $d$-degenerate graphs is $d+1$, shown to be tight by complete graphs. A natural question is whether this bound remains tight if one forbids large cliques. Classic constructions of Tutte and Zykov from the early 50s show that there exist $d$-degenerate $(d+1)$-chromatic graphs that are triangle-free, however these constructions grow rapidly with $d$. Motivated by this and addressing a problem posed by the second author at the Oberwolfach Graph Theory workshop, we prove that the minimum order $f(d)$ of a $d$-degenerate triangle-free graph of chromatic number $d+1$ satisfies $e^{Œ©(d)}\le f(d)\le e^{O(d^2\log d)}.$ The lower bound follows from a novel upper bound on the chromatic number of triangle-free graphs: Every triangle-free $d$-degenerate graph $G$ on $n \le e^{O(d)}$ vertices satisfies $$œá(G)\le O\left(\frac{d}{\log\left(d/\log n\right)}\right).$$ We extend this to a more general result about degenerate graphs with sparse neighborhoods, which has applications to many graph coloring problems: For example, we prove that every counterexample to Hadwiger&rsquo;s conjecture with parameter $t$ must have a complete bipartite subgraph with one exponentially large side ($K_{a,b}$ where $a=(\log t)^{1/2-o(1)}$ and $b=e^{t^{1-o(1)}}$) or a small and very dense subgraph (of order $\le t$ with $t^{2-o(1)}$ edges) in some neighborhood.
For the upper bound on $f(d)$ we establish a surprising connection between $f(d)$ and the on-line-chromatic number $g(n)$ of $n$-vertex triangle-free graphs. We also give an asymptotic improvement of the previous best upper bound for $g(n)$ due to Lov√°sz, Saks and Trotter from 1989.
Along the way we disprove a generalization of Harris&rsquo; fractional coloring conjecture to graphs of bounded clique number and raise numerous problems which open up interesting directions to explore for future research.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15245v1">üìÑ Download PDF</a></p><hr><h3 id=information-mechanics-conservation-and-exchangehttpsarxivorgabs260115028v1><a href=https://arxiv.org/abs/2601.15028v1>Information mechanics: conservation and exchange</a><a hidden class=anchor aria-hidden=true href=#information-mechanics-conservation-and-exchangehttpsarxivorgabs260115028v1>#</a></h3><p><strong>Authors:</strong> Takuya Isomura
<strong>Venue:</strong> arXiv (2026)</p><p>Inference and learning are commonly cast in terms of optimisation, yet the fundamental constraints governing uncertainty reduction remain unclear. This work presents a first-principles framework inherent to Bayesian updating, termed information mechanics (infomechanics). Any pointwise reduction in posterior surprisal is exactly balanced by information gained from data, independently of algorithms, dynamics, or implementation. Imposing additivity, symmetry, and robustness collapses the freedom of this identity to only two independent conservation relations. One governs the global redistribution of uncertainty and recovers Shannon entropy. The other captures a complementary local geometric component, formalised as Fisher information. Together, these conserved quantities motivate a non-additive state function, the information potential $Œ¶$, which isolates structural degrees of freedom beyond entropy while remaining invariant under reparametrisation. $Œ¶$ quantifies local sharpness and ruggedness in posterior beliefs and vanishes uniquely for isotropic Gaussian distributions. In a low-temperature regime, $Œ¶$ scales logarithmically with the effective number of local optima, linking information geometry to computational complexity. This formalises an information-computation exchange, whereby information acquisition reshapes the inference landscape and reduces computational demands. By separating invariant informational constraints from inference mechanisms, this framework provides a unified, algorithm-independent foundation for inference, learning, and computation across biological and artificial systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15028v1">üìÑ Download PDF</a></p><hr><h3 id=resonant-excitation-induced-vibronic-mollow-tripletshttpsarxivorgabs260114963v1><a href=https://arxiv.org/abs/2601.14963v1>Resonant Excitation Induced Vibronic Mollow Triplets</a><a hidden class=anchor aria-hidden=true href=#resonant-excitation-induced-vibronic-mollow-tripletshttpsarxivorgabs260114963v1>#</a></h3><p><strong>Authors:</strong> Devashish Pandey, Corne Koks, Martijn Wubs, Nicolas Stenger, Jake Iles-Smith
<strong>Venue:</strong> arXiv (2026)</p><p>The Mollow triplet is the definitive spectral signature of an optically dressed quantum emitter. We predict that for emitters coupled to localized phonons, this signature is not confined to the zero-phonon line. Under a strong resonant drive, we show that Mollow triplets are strikingly replicated on the associated phonon sidebands -a surprising result, given that phonon sidebands are typically viewed as incoherent, inelastic scattering pathways. These vibronic Mollow triplets are a direct fingerprint of dynamically generated dressed states that hybridize the emitter&rsquo;s electronic, photonic, and vibrational degrees of freedom. We develop a scalable analytical formalism to model this effect in complex, multi-mode molecular systems, such as dibenzoterrylene. Our work provides the precise driving conditions for observing these novel spectral features, establishing a new signature of coherence in vibronically coupled systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.14963v1">üìÑ Download PDF</a></p><hr><h3 id=which-reasoning-trajectories-teach-students-to-reason-better-a-simple-metric-of-informative-alignmenthttpsarxivorgabs260114249v1><a href=https://arxiv.org/abs/2601.14249v1>Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment</a><a hidden class=anchor aria-hidden=true href=#which-reasoning-trajectories-teach-students-to-reason-better-a-simple-metric-of-informative-alignmenthttpsarxivorgabs260114249v1>#</a></h3><p><strong>Authors:</strong> Yuming Yang, Mingyoung Lai, Wanxu Zhao, Xiaoran Fan, Zhiheng Xi, Mingqi Wu, Chiyue Huang, Jun Zhao, Haijun Lv, Jian Tong, Yunhua Zhou, Yicheng Zou, Qipeng Guo, Tao Gui, Qi Zhang, Xuanjing Huang
<strong>Venue:</strong> arXiv (2026)</p><p>Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model&rsquo;s current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory&rsquo;s average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.14249v1">üìÑ Download PDF</a></p><hr><h3 id=cyclic-sunspot-activity-during-the-first-millennium-ce-as-reconstructed-from-radiocarbonhttpsarxivorgabs260116203v1><a href=https://arxiv.org/abs/2601.16203v1>Cyclic sunspot activity during the first millennium CE as reconstructed from radiocarbon</a><a hidden class=anchor aria-hidden=true href=#cyclic-sunspot-activity-during-the-first-millennium-ce-as-reconstructed-from-radiocarbonhttpsarxivorgabs260116203v1>#</a></h3><p><strong>Authors:</strong> Ilya Usoskin, Sami K. Solanki, Natalie A. Krivova, Theodosis Chatzistergos
<strong>Venue:</strong> arXiv (2026)</p><p>Context. Solar activity, dominated by the 11-year cyclic evolution, has been observed directly since 1610. Before that, indirect cosmogenic proxy data are used to reconstruct it over millennia. Recently, the precision of radiocarbon measurements has improved sufficiently to allow reconstructing solar activity over millennia. Aims. The first detailed reconstruction of solar activity, represented by annual sunspot numbers, is presented for 1-969 CE. Methods. The reconstruction of sunspot numbers from D14C was performed using a physics-based method involving several steps: using a carbon-cycle box model, the 14C production rate, corrected for the geomagnetic shielding, was computed from the measured data; The open solar magnetic flux was computed using a model of the heliospheric cosmic-ray modulation; Sunspot numbers were calculated using a model of the evolution of the Sun&rsquo;s magnetic field. The Markov Chain Monte Carlo approach was used to account for different sources of uncertainty. Results. Annual sunspot numbers were reconstructed for the first millennium CE. This period includes one extreme solar event of 774 CE and one Grand solar minimum of 650-730 CE. We could identify 91 solar cycles, of which 26 were well-defined, while 24 and 41 were reasonably and poorly defined, respectively. The mean cycle length was 10.6 years, but the lengths of individual cycles vary between 8 and 15 years. The existence of empirical Waldmeier&rsquo;s relations remains inconclusive. No significant periodicities were found beyond the 11-year cycle. Conclusions. This work fills the gap in the solar cycle statistics between the previously reconstructed first millennium BCE and the second millennium CE, providing vital constraints for the solar dynamo and irradiance models. A consistent 3-millennium-long reconstruction of sunspot numbers, based on a composite multi-proxy cosmogenic record, is pending.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16203v1">üìÑ Download PDF</a></p><hr><h3 id=a-forward-only-scheme-for-online-learning-of-proposal-distributions-in-particle-filtershttpsarxivorgabs260116089v1><a href=https://arxiv.org/abs/2601.16089v1>A forward-only scheme for online learning of proposal distributions in particle filters</a><a hidden class=anchor aria-hidden=true href=#a-forward-only-scheme-for-online-learning-of-proposal-distributions-in-particle-filtershttpsarxivorgabs260116089v1>#</a></h3><p><strong>Authors:</strong> Sylvain Procope-Mamert, Nicolas Chopin, Maud Delattre, Guillaume Kon Kam King
<strong>Venue:</strong> arXiv (2026)</p><p>We introduce a new online approach for constructing proposal distributions in particle filters using a forward scheme. Our method progressively incorporates future observations to refine proposals. This is in contrast to backward-scheme algorithms that require access to the entire dataset, such as the iterated auxiliary particle filters (Guarniero et al., 2017, arXiv:1511.06286) and controlled sequential Monte Carlo (Heng et al., 2020, arXiv:1708.08396) which leverage all future observations through backward recursion. In comparison, our forward scheme achieves a gradual improvement of proposals that converges toward the proposal targeted by these backward methods. We show that backward approaches can be numerically unstable even in simple settings. Our forward method, however, offers significantly greater robustness with only a minor trade-off in performance, measured by the variance of the marginal likelihood estimator. Numerical experiments on both simulated and real data illustrate the enhanced stability of our forward approach.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16089v1">üìÑ Download PDF</a></p><hr><h3 id=the-role-of-cognitive-abilities-in-requirements-inspection-comparing-uml-and-textual-representationshttpsarxivorgabs260116009v1><a href=https://arxiv.org/abs/2601.16009v1>The Role of Cognitive Abilities in Requirements Inspection: Comparing UML and Textual Representations</a><a hidden class=anchor aria-hidden=true href=#the-role-of-cognitive-abilities-in-requirements-inspection-comparing-uml-and-textual-representationshttpsarxivorgabs260116009v1>#</a></h3><p><strong>Authors:</strong> Giovanna Broccia, Sira Vegas, Alessio Ferrari
<strong>Venue:</strong> arXiv (2026)</p><p>The representation of requirements plays a critical role in the accuracy of requirements inspection. While visual representations, such as UML diagrams, are widely used alongside text-based requirements, their effectiveness in supporting inspection is still debated. Cognitive abilities, such as working memory and mental rotation skills, may also influence inspection accuracy. This study aims to evaluate whether the use of UML sequence diagrams alongside text-based requirements improves the accuracy of requirements inspection compared to text-based requirements alone and to explore whether cognitive abilities are associated with differences in performance across the two treatments (text vs text with UML support). We conducted a crossover experiment with 38 participants to assess the accuracy of requirements inspection under the two treatments in terms of issues found and justifications provided. Linear mixed-effects and generalized linear models were used to analyse the effects of treatment, period, sequence, and cognitive abilities. The results indicate a significant three-way interaction between representation type, working memory capacity, and mental rotation ability. This finding suggests that the effectiveness of UML support is not uniform across individuals: participants with high scores in both cognitive abilities experienced reduced performance when using UML for violation detection. Conversely, the same cognitive profile was associated with improved justification accuracy under UML-aided inspection, indicating that higher cognitive abilities may support deeper reasoning processes when dealing with multi-modal information, i.e., diagrams and text.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16009v1">üìÑ Download PDF</a></p><hr><h3 id=humanllm-towards-personalized-understanding-and-simulation-of-human-naturehttpsarxivorgabs260115793v1><a href=https://arxiv.org/abs/2601.15793v1>HumanLLM: Towards Personalized Understanding and Simulation of Human Nature</a><a hidden class=anchor aria-hidden=true href=#humanllm-towards-personalized-understanding-and-simulation-of-human-naturehttpsarxivorgabs260115793v1>#</a></h3><p><strong>Authors:</strong> Yuxuan Lei, Tianfu Wang, Jianxun Lian, Zhengyu Hu, Defu Lian, Xing Xie
<strong>Venue:</strong> arXiv (2026)</p><p>Motivated by the remarkable progress of large language models (LLMs) in objective tasks like mathematics and coding, there is growing interest in their potential to simulate human behavior&ndash;a capability with profound implications for transforming social science research and customer-centric business insights. However, LLMs often lack a nuanced understanding of human cognition and behavior, limiting their effectiveness in social simulation and personalized applications. We posit that this limitation stems from a fundamental misalignment: standard LLM pretraining on vast, uncontextualized web data does not capture the continuous, situated context of an individual&rsquo;s decisions, thoughts, and behaviors over time. To bridge this gap, we introduce HumanLLM, a foundation model designed for personalized understanding and simulation of individuals. We first construct the Cognitive Genome Dataset, a large-scale corpus curated from real-world user data on platforms like Reddit, Twitter, Blogger, and Amazon. Through a rigorous, multi-stage pipeline involving data filtering, synthesis, and quality control, we automatically extract over 5.5 million user logs to distill rich profiles, behaviors, and thinking patterns. We then formulate diverse learning tasks and perform supervised fine-tuning to empower the model to predict a wide range of individualized human behaviors, thoughts, and experiences. Comprehensive evaluations demonstrate that HumanLLM achieves superior performance in predicting user actions and inner thoughts, more accurately mimics user writing styles and preferences, and generates more authentic user profiles compared to base models. Furthermore, HumanLLM shows significant gains on out-of-domain social intelligence benchmarks, indicating enhanced generalization.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15793v1">üìÑ Download PDF</a></p><hr><h3 id=resting-state-functional-connectivity-correlates-of-emotional-memory-control-under-cognitive-load-in-subclinical-anxietyhttpsarxivorgabs260115689v1><a href=https://arxiv.org/abs/2601.15689v1>Resting-State Functional Connectivity Correlates of Emotional Memory Control under Cognitive load in Subclinical Anxiety</a><a hidden class=anchor aria-hidden=true href=#resting-state-functional-connectivity-correlates-of-emotional-memory-control-under-cognitive-load-in-subclinical-anxietyhttpsarxivorgabs260115689v1>#</a></h3><p><strong>Authors:</strong> Shruti Kinger, Mrinmoy Chakrabarty
<strong>Venue:</strong> arXiv (2026)</p><p>Volitional memory control supports adaptive cognition by enabling intentional Recall of goal-relevant information and Suppression of unwanted memories. While neural mechanisms underlying Recall and Suppression have been studied largely in isolation, less is known about the large-scale brain networks supporting these processes under competing cognitive demands, particularly as a function of subclinical anxiety. Here, we examined control of emotionally valenced memories during directed Recall and Suppression while 47 participants concurrently performed an independent visual working memory task. Cognitive control efficiency was quantified using the Balanced Integration Score (BIS), and seed-to-voxel resting-state functional connectivity (rsFC) was used to characterize intrinsic network organization. Dissociable rsFC profiles were associated with memory control efficiency across emotional valences and were selectively moderated by anxiety. More efficient Suppression of positive memories was linked to reduced connectivity between the anterior cingulate cortex and posterior perceptual-midline regions, as well as diminished hippocampal-frontal pole coupling. In contrast, efficient Suppression of negative memories was associated with increased connectivity between posterior parietal and lateral occipital regions. Anxiety moderated relationships between cognitive efficiency and prefrontal connectivity during Suppression of positive memories and Recall of positive and neutral memories. Direct comparisons further revealed stronger hippocampal-thalamic rsFC during Suppression relative to Recall of positive memories. Together, these findings delineate the functional brain architecture supporting volitional control of emotional memories under cognitive load and demonstrate that anxiety severity selectively shapes these network-level mechanisms across the anxiety continuum.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15689v1">üìÑ Download PDF</a></p><hr><h3 id=average-unfairness-in-routing-gameshttpsarxivorgabs260116187v1><a href=https://arxiv.org/abs/2601.16187v1>Average Unfairness in Routing Games</a><a hidden class=anchor aria-hidden=true href=#average-unfairness-in-routing-gameshttpsarxivorgabs260116187v1>#</a></h3><p><strong>Authors:</strong> Pan-Yang Su, Arwa Alanqary, Bryce L. Ferguson, Manxi Wu, Alexandre M. Bayen, Shankar Sastry
<strong>Venue:</strong> arXiv (2026)</p><p>We propose average unfairness as a new measure of fairness in routing games, defined as the ratio between the average latency and the minimum latency experienced by users. This measure is a natural complement to two existing unfairness notions: loaded unfairness, which compares maximum and minimum latencies of routes with positive flow, and user equilibrium (UE) unfairness, which compares maximum latency with the latency of a Nash equilibrium. We show that the worst-case values of all three unfairness measures coincide and are characterized by a steepness parameter intrinsic to the latency function class. We show that average unfairness is always no greater than loaded unfairness, and the two measures are equal only when the flow is fully fair. Besides that, we offer a complete comparison of the three unfairness measures, which, to the best of our knowledge, is the first theoretical analysis in this direction. Finally, we study the constrained system optimum (CSO) problem, where one seeks to minimize total latency subject to an upper bound on unfairness. We prove that, for the same tolerance level, the optimal flow under an average unfairness constraint achieves lower total latency than any flow satisfying a loaded unfairness constraint. We show that such improvement is always strict in parallel-link networks and establish sufficient conditions for general networks. We further illustrate the latter with numerical examples. Our results provide theoretical guarantees and valuable insights for evaluating fairness-efficiency tradeoffs in network routing.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16187v1">üìÑ Download PDF</a></p><hr><h3 id=eaifd-a-fast-and-scalable-algorithm-for-incremental-functional-dependency-discoveryhttpsarxivorgabs260116025v1><a href=https://arxiv.org/abs/2601.16025v1>EAIFD: A Fast and Scalable Algorithm for Incremental Functional Dependency Discovery</a><a hidden class=anchor aria-hidden=true href=#eaifd-a-fast-and-scalable-algorithm-for-incremental-functional-dependency-discoveryhttpsarxivorgabs260116025v1>#</a></h3><p><strong>Authors:</strong> Yajuan Xu, Xixian Han, Xiaolong Wan
<strong>Venue:</strong> arXiv (2026)</p><p>Functional dependencies (FDs) are fundamental integrity constraints in relational databases, but discovering them under incremental updates remains challenging. While static algorithms are inefficient due to full re-execution, incremental algorithms suffer from severe performance and memory bottlenecks. To address these challenges, this paper proposes EAIFD, a novel algorithm for incremental FD discovery. EAIFD maintains the partial hypergraph of difference sets and reframes the incremental FD discovery problem into minimal hitting set enumeration on hypergraph, avoiding full re-runs. EAIFD introduces two key innovations. First, a multi-attribute hash table ($MHT$) is devised for high-frequency key-value mappings of valid FDs, whose memory consumption is proven to be independent of the dataset size. Second, two-step validation strategy is developed to efficiently validate the enumerated candidates, which leverages $MHT$ to effectively reduce the validation space and then selectively loads data blocks for batch validation of remaining candidates, effectively avoiding repeated I/O operations. Experimental results on real-world datasets demonstrate the significant advantages of EAIFD. Compared to existing algorithms, EAIFD achieves up to an order-of-magnitude speedup in runtime while reducing memory usage by over two orders-of-magnitude, establishing it as a highly efficient and scalable solution for incremental FD discovery.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16025v1">üìÑ Download PDF</a></p><hr><h3 id=stability-analysis-of-power-electronics-dominated-grids-using-scaled-relative-graphshttpsarxivorgabs260116014v1><a href=https://arxiv.org/abs/2601.16014v1>Stability Analysis of Power-Electronics-Dominated Grids Using Scaled Relative Graphs</a><a hidden class=anchor aria-hidden=true href=#stability-analysis-of-power-electronics-dominated-grids-using-scaled-relative-graphshttpsarxivorgabs260116014v1>#</a></h3><p><strong>Authors:</strong> Eder Baron-Prada, Adolfo Anta, Florian D√∂rfler
<strong>Venue:</strong> arXiv (2026)</p><p>This paper presents a novel approach to stability analysis for grid-connected converters utilizing Scaled Relative Graphs (SRG). Our method effectively decouples grid and converter dynamics, thereby establishing a comprehensive and efficient framework for evaluating closed-loop stability. Our analysis accommodates both linear and non-linear loads, enhancing its practical applicability. Furthermore, we demonstrate that our stability assessment remains unaffected by angular variations resulting from dq-frame transformations, significantly increasing the method&rsquo;s robustness and versatility. The effectiveness of our approach is validated in several simulation case studies, which illustrate its broad applicability in modern power systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16014v1">üìÑ Download PDF</a></p><hr><h3 id=efficient-cloud-edge-collaborative-approaches-to-sparql-queries-over-large-rdf-graphshttpsarxivorgabs260115992v1><a href=https://arxiv.org/abs/2601.15992v1>Efficient Cloud-edge Collaborative Approaches to SPARQL Queries over Large RDF graphs</a><a hidden class=anchor aria-hidden=true href=#efficient-cloud-edge-collaborative-approaches-to-sparql-queries-over-large-rdf-graphshttpsarxivorgabs260115992v1>#</a></h3><p><strong>Authors:</strong> Shidan Ma, Peng Peng, Xu Zhou, M. Tamer √ñzsu, Lei Zou, Guo Chen
<strong>Venue:</strong> arXiv (2026)</p><p>With the increasing use of RDF graphs, storing and querying such data using SPARQL remains a critical problem. Current mainstream solutions rely on cloud-based data management architectures, but often suffer from performance bottle- necks in environments with limited bandwidth or high system load. To address this issue, this paper explores for the first time the integration of edge computing to move graph data storage and processing to edge environments, thereby improving query performance. This approach requires offloading query processing to edge servers, which involves addressing two challenges: data localization and network scheduling. First, the data localization challenge lies in computing the subgraphs maintained on edge servers to quickly identify the servers that can handle specific queries. To address this challenge, we introduce a new concept of pattern-induced subgraphs. Second, the network scheduling challenge involves efficiently assigning queries to edge and cloud servers to optimize overall system performance. We tackle this by constructing a overall system model that jointly captures data distribution, query characteristics, network communication, and computational resources. Accordingly, we further propose a joint formulation of query assignment and computational resource allocation, modeling it as a Mixed Integer Nonlinear Programming (MINLP) problem and solve this problem using a modified branch-and-bound algorithm. Experimental results on real datasets under a real cloud platform demonstrate that our proposed method outperforms the state-of-the-art baseline methods in terms of efficiency. The codes are available on GitHub</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15992v1">üìÑ Download PDF</a></p><hr><h2 id=-llm>üîç llm<a hidden class=anchor aria-hidden=true href=#-llm>#</a></h2><h3 id=ergodic-averages-for-commutative-transformations-along-return-timeshttpsarxivorgabs260116188v1><a href=https://arxiv.org/abs/2601.16188v1>Ergodic averages for commutative transformations along return times</a><a hidden class=anchor aria-hidden=true href=#ergodic-averages-for-commutative-transformations-along-return-timeshttpsarxivorgabs260116188v1>#</a></h3><p><strong>Authors:</strong> Sebasti√°n Donoso, Sovanlal Mondal, Vicente Saavedra-Araya
<strong>Venue:</strong> arXiv (2026)</p><p>In this paper, we extend recent results on the convergence of ergodic averages along sequences generated by return times to shrinking targets in rapidly mixing systems, partially answering questions posed by the first author, Maass and the third author in [6]. In particular, for a fixed parameter $a\in (0,1)$ and for generic $y\in [0,1]$, we establish both $L^2$ and pointwise convergence for single averages and multiple averages for commuting transformations along the sequences $(a_n(y))_{n\in \mathbb{N}}$, obtained by arranging the set $$\Big{n\in\mathbb{N}: 0&lt;2^ny \mod{1}&lt;n^{-a} \Big}$$ in an increasing order. We also obtain new results for semi-random ergodic averages along sequences of similar type.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16188v1">üìÑ Download PDF</a></p><hr><h3 id=contex-t-contextual-privacy-exploitation-via-transformer-spectral-analysis-for-iot-device-fingerprintinghttpsarxivorgabs260116160v1><a href=https://arxiv.org/abs/2601.16160v1>CONTEX-T: Contextual Privacy Exploitation via Transformer Spectral Analysis for IoT Device Fingerprinting</a><a hidden class=anchor aria-hidden=true href=#contex-t-contextual-privacy-exploitation-via-transformer-spectral-analysis-for-iot-device-fingerprintinghttpsarxivorgabs260116160v1>#</a></h3><p><strong>Authors:</strong> Nazmul Islam, Mohammad Zulkernine
<strong>Venue:</strong> arXiv (2026)</p><p>The rapid expansion of internet of things (IoT) devices have created a pervasive ecosystem where encrypted wireless communications serve as the primary privacy and security protection mechanism. While encryption effectively protects message content, packet metadata and statistics inadvertently expose device identities and user contexts. Various studies have exploited raw packet statistics and their visual representations for device fingerprinting and identification. However, these approaches remain confined to the spatial domain with limited feature representation. Therefore, this paper presents CONTEX-T, a novel framework that exploits contextual privacy vulnerabilities using spectral representation of encrypted wireless traffic for IoT device characterization. The experiments show that spectral analysis provides new and rich feature representation for covert reconnaissance attacks, revealing a complex and expanding threat landscape that would require robust countermeasures for IoT security management. CONTEXT-T first transforms raw packet length sequences into time-frequency spectral representations and then utilizes transformer-based spectral analysis for the device identification. We systematically evaluated multiple spectral representation techniques and transformer-based models across encrypted traffic samples from various IoT devices. CONTEXT-T effectively exploited privacy vulnerabilities and achieved device classification accuracy exceeding 99% across all devices while remaining completely passive and undetectable.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16160v1">üìÑ Download PDF</a></p><hr><h3 id=substrate-stability-under-persistent-disagreement-structural-constraints-for-neutral-ontological-substrateshttpsarxivorgabs260116152v1><a href=https://arxiv.org/abs/2601.16152v1>Substrate Stability Under Persistent Disagreement: Structural Constraints for Neutral Ontological Substrates</a><a hidden class=anchor aria-hidden=true href=#substrate-stability-under-persistent-disagreement-structural-constraints-for-neutral-ontological-substrateshttpsarxivorgabs260116152v1>#</a></h3><p><strong>Authors:</strong> Denise M. Case
<strong>Venue:</strong> arXiv (2026)</p><p>Modern data systems increasingly operate under conditions of persistent legal, political, and analytic disagreement. In such settings, interoperability cannot rely on shared interpretation, negotiated semantics, or centralized authority. Instead, representations must function as neutral substrates that preserve stable reference across incompatible extensions. This paper investigates the structural constraints imposed on ontological design by this requirement. Building on a neutrality framework that treats interpretive non-commitment and stability under extension as explicit design constraints, we ask what minimal ontological structure is forced if accountability relationships are to remain referable and comparable under disagreement. Minimality here is not mere parsimony: a reduction is admissible only if it does not reintroduce stability-critical distinctions as hidden roles, flags, or contextual predicates. We establish a conditional lower-bound result: any ontology capable of supporting accountability under persistent disagreement must realize at least six distinct identity-and-persistence regimes. We further show that a construction with exactly six such regimes is sufficient to satisfy the stated requirements without embedding causal or normative commitments in the substrate. The result is not a proposal for a universal ontology, but a constraint on what is possible when neutrality and stable reference are treated as non-negotiable design goals.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16152v1">üìÑ Download PDF</a></p><hr><h3 id=cis--trans-rotational-isomerism-of-seleno--thio--and-formic-acids-and-their-dimers-chemical-kinetics-under-interstellar-conditionshttpsarxivorgabs260116115v1><a href=https://arxiv.org/abs/2601.16115v1>Cis&ndash;Trans Rotational Isomerism of Seleno-, Thio-, and Formic Acids and Their Dimers: Chemical Kinetics under Interstellar Conditions</a><a hidden class=anchor aria-hidden=true href=#cis--trans-rotational-isomerism-of-seleno--thio--and-formic-acids-and-their-dimers-chemical-kinetics-under-interstellar-conditionshttpsarxivorgabs260116115v1>#</a></h3><p><strong>Authors:</strong> Judith Wurmel, John M. Simmie
<strong>Venue:</strong> arXiv (2026)</p><p>Tunnelling reactions of molecules embedded on cryogenic noble-gas matrices are being used in fundamental studies of how reactivity
varies with the nature of the supposedly inert matrix as well as pointers to the chemistry occurring in the interstellar medium
on ice-grains. To these ends we present chemical kinetic rate constants for the \textit{cis} to \textit{trans} isomerisation of
seleno-, thio- and monomeric formic acids and that of their three dimeric species, based on multidimensional calculations in the
gas-phase, from 10<del>K to 300</del>K as a guide to the matrix reactions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16115v1">üìÑ Download PDF</a></p><hr><h3 id=robust-quantum-algorithmic-binary-decision-making-on-displacement-signalshttpsarxivorgabs260116081v1><a href=https://arxiv.org/abs/2601.16081v1>Robust Quantum Algorithmic Binary Decision-Making on Displacement Signals</a><a hidden class=anchor aria-hidden=true href=#robust-quantum-algorithmic-binary-decision-making-on-displacement-signalshttpsarxivorgabs260116081v1>#</a></h3><p><strong>Authors:</strong> Aishwarya Majumdar, Yuan Liu
<strong>Venue:</strong> arXiv (2026)</p><p>A relevant signal in the quantum domain may manifest as a displacement or a phase shift operator in the bosonic phase space. For a real parameter $Œ≤$ embedded in such a displacement operator, the task of determining if $Œ≤\in [Œ≤_{-th}, Œ≤_{+th}]$ for real asymmetric thresholds $(Œ≤_{-th} \ne -Œ≤_{+th})$ is a binary decision problem. We propose a framework based on generalized quantum signal processing interferometry (GQSPI) on hybrid qubit-bosonic oscillator systems that addresses this parameter detection problem by recasting the practical task of active binary hypothesis testing on quantum systems to that of a polynomial approximation. We achieve a small decision error probability $p_{err}$ on the order of $O(\frac{1}{d}\log{(d)})$, with $d$ as the circuit depth. We analyze the protocol when (i) $Œ≤$ is a deterministic parameter, and (ii) when $Œ≤$ is drawn randomly from a known prior distribution. The performance of the sensing protocol under dephasing noise is also shown to be robust. We further extend our protocol from two thresholds to more general multi-threshold cases as well. Overall, the proposed framework enables decision-making over arbitrary thresholds for any general displacement signal in a single or a few shots.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16081v1">üìÑ Download PDF</a></p><hr><h3 id=pushing-the-limits-of-unconstrained-machine-learned-interatomic-potentialshttpsarxivorgabs260116195v1><a href=https://arxiv.org/abs/2601.16195v1>Pushing the limits of unconstrained machine-learned interatomic potentials</a><a hidden class=anchor aria-hidden=true href=#pushing-the-limits-of-unconstrained-machine-learned-interatomic-potentialshttpsarxivorgabs260116195v1>#</a></h3><p><strong>Authors:</strong> Filippo Bigi, Paolo Pegolo, Arslan Mazitov, Michele Ceriotti
<strong>Venue:</strong> arXiv (2026)</p><p>Machine-learned interatomic potentials (MLIPs) are increasingly used to replace computationally demanding electronic-structure calculations to model matter at the atomic scale. The most commonly used model architectures are constrained to fulfill a number of physical laws exactly, from geometric symmetries to energy conservation. Evidence is mounting that relaxing some of these constraints can be beneficial to the efficiency and (somewhat surprisingly) accuracy of MLIPs, even though care should be taken to avoid qualitative failures associated with the breaking of physical symmetries. Given the recent trend of \emph{scaling up} models to larger numbers of parameters and training samples, a very important question is how unconstrained MLIPs behave in this limit. Here we investigate this issue, showing that &ndash; when trained on large datasets &ndash; unconstrained models can be superior in accuracy and speed when compared to physically constrained models. We assess these models both in terms of benchmark accuracy and in terms of usability in practical scenarios, focusing on static simulation workflows such as geometry optimization and lattice dynamics. We conclude that accurate unconstrained models can be applied with confidence, especially since simple inference-time modifications can be used to recover observables that are consistent with the relevant physical symmetries.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16195v1">üìÑ Download PDF</a></p><hr><h3 id=inference-on-the-significance-of-modalities-in-multimodal-generalized-linear-modelshttpsarxivorgabs260116196v1><a href=https://arxiv.org/abs/2601.16196v1>Inference on the Significance of Modalities in Multimodal Generalized Linear Models</a><a hidden class=anchor aria-hidden=true href=#inference-on-the-significance-of-modalities-in-multimodal-generalized-linear-modelshttpsarxivorgabs260116196v1>#</a></h3><p><strong>Authors:</strong> Wanting Jin, Guorong Wu, Quefeng Li
<strong>Venue:</strong> arXiv (2026)</p><p>Despite the popular of multimodal statistical models, there lacks rigorous statistical inference tools for inferring the significance of a single modality within a multimodal model, especially in high-dimensional models. For high-dimensional multimodal generalized linear models, we propose a novel entropy-based metric, called the expected relative entropy, to quantify the information gain of one modality in addition to all other modalities in the model. We propose a deviance-based statistic to estimate the expected relative entropy, prove that it is consistent and its asymptotic distribution can be approximated by a non-central chi-squared distribution. That enables the calculation of confidence intervals and p-values to assess the significance of the expected relative entropy for a given modality. We numerically evaluate the empirical performance of our proposed inference tool by simulations and apply it to a multimodal neuroimaging dataset to demonstrate its good performance on various high-dimensional multimodal generalized linear models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16196v1">üìÑ Download PDF</a></p><hr><h3 id=learning-to-discover-at-test-timehttpsarxivorgabs260116175v1><a href=https://arxiv.org/abs/2601.16175v1>Learning to Discover at Test Time</a><a hidden class=anchor aria-hidden=true href=#learning-to-discover-at-test-timehttpsarxivorgabs260116175v1>#</a></h3><p><strong>Authors:</strong> Mert Yuksekgonul, Daniel Koceja, Xinhao Li, Federico Bianchi, Jed McCaleb, Xiaolong Wang, Jan Kautz, Yejin Choi, James Zou, Carlos Guestrin, Yu Sun
<strong>Venue:</strong> arXiv (2026)</p><p>How can we use AI to discover a new state of the art for a scientific problem? Prior work in test-time scaling, such as AlphaEvolve, performs search by prompting a frozen LLM. We perform reinforcement learning at test time, so the LLM can continue to train, but now with experience specific to the test problem. This form of continual learning is quite special, because its goal is to produce one great solution rather than many good ones on average, and to solve this very problem rather than generalize to other problems. Therefore, our learning objective and search subroutine are designed to prioritize the most promising solutions. We call this method Test-Time Training to Discover (TTT-Discover). Following prior work, we focus on problems with continuous rewards. We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erd≈ës&rsquo; minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to $2\times$ faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers. All our results are achieved with an open model, OpenAI gpt-oss-120b, and can be reproduced with our publicly available code, in contrast to previous best results that required closed frontier models. Our test-time training runs are performed using Tinker, an API by Thinking Machines, with a cost of only a few hundred dollars per problem.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16175v1">üìÑ Download PDF</a></p><hr><h3 id=structured-hints-for-sample-efficient-lean-theorem-provinghttpsarxivorgabs260116172v1><a href=https://arxiv.org/abs/2601.16172v1>Structured Hints for Sample-Efficient Lean Theorem Proving</a><a hidden class=anchor aria-hidden=true href=#structured-hints-for-sample-efficient-lean-theorem-provinghttpsarxivorgabs260116172v1>#</a></h3><p><strong>Authors:</strong> Zachary Burton
<strong>Venue:</strong> arXiv (2026)</p><p>State-of-the-art neural theorem provers like DeepSeek-Prover-V1.5 combine large language models with reinforcement learning, achieving impressive results through sophisticated training. We ask: do these highly-trained models still benefit from simple structural guidance at inference time? We evaluate a lightweight intervention &ndash; a fixed prompt schedule over 15 common tactic skeletons &ndash; on the miniF2F benchmark. This simple approach yields 21.7% pass@16 compared to 15.2% for standard sampling from the same model, a 43% relative improvement using the same number of samples (k=16) and same maximum generation length (1024 tokens). Our results suggest that even capable RL-trained provers underutilize structural priors available in the tactic language, and that simple inference-time guidance remains a cheap, complementary boost.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16172v1">üìÑ Download PDF</a></p><hr><h2 id=-neuroscience>üîç neuroscience<a hidden class=anchor aria-hidden=true href=#-neuroscience>#</a></h2><h3 id=interface-spin-orbit-coupling-induced-room-temperature-ferromagnetic-insulatorhttpsarxivorgabs260116069v1><a href=https://arxiv.org/abs/2601.16069v1>Interface Spin-orbit Coupling Induced Room-temperature Ferromagnetic Insulator</a><a hidden class=anchor aria-hidden=true href=#interface-spin-orbit-coupling-induced-room-temperature-ferromagnetic-insulatorhttpsarxivorgabs260116069v1>#</a></h3><p><strong>Authors:</strong> Yuhao Hong, Shilin Hu, Ziyue Shen, Chao Deng, Xiaodong Zhang, Lei Wang, Long Wei, Qinghua Zhang, Lingfei Wang, Liang Si, Yulin Gan, Kai Chen, Zhaoliang Liao
<strong>Venue:</strong> arXiv (2026)</p><p>To achieve room-temperature ferromagnetic insulators, which are crucial candidates for next-generation dissipation-free quantum and spintronic devices, remains a significant challenge. In this study, we report the epitaxial synthesis of novel room-temperature ferromagnetic insulating thin films, achieved through the precise construction of (111)-oriented 3d/5d interfaces. Our analysis indicates that, unlike conventional doping methods, the (111)-oriented SrIrO3/La2/3Sr1/3MnO3 (SIO/LSMO) interfaces exhibit markedly enhanced spin-orbit coupling (SOC). This enhanced interfacial SOC strengthens the electron-phonon coupling in LSMO, thereby shortening the electronic mean free path. As a result, the intrinsic metallicity of LSMO is suppressed, giving rise to a new FMI phase that emerges between the ferromagnetic metal and paramagnetic insulator regimes of the LSMO phase diagram. Furthermore, the temperature window of the FMI state can be tuned by precisely controlling the thickness of the LSMO layers. Our study reveals a new strategy for developing ferromagnetic insulators by engineering 3d/5d interfaces and orientations, paving a way for the development of novel dissipation-free quantum and spintronic devices.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16069v1">üìÑ Download PDF</a></p><hr><h3 id=can-platform-design-encourage-curiosity-evidence-from-an-independent-social-media-experimenthttpsarxivorgabs260116040v1><a href=https://arxiv.org/abs/2601.16040v1>Can Platform Design Encourage Curiosity? Evidence from an Independent Social Media Experiment</a><a hidden class=anchor aria-hidden=true href=#can-platform-design-encourage-curiosity-evidence-from-an-independent-social-media-experimenthttpsarxivorgabs260116040v1>#</a></h3><p><strong>Authors:</strong> Marie Neubrander, Markus Reiter-Haas, Ben Rochford, Max Allamong, Christopher Bail, Sunshine Hillygus, Alexander Volfovsky
<strong>Venue:</strong> arXiv (2026)</p><p>Social media platforms are often criticized for fostering antisocial behavior rather than prosocial behavior. Yet, testing interventions to encourage prosocial dispositions, such as open-mindedness, has been hindered by researchers&rsquo; limited ability to manipulate platform features and isolate causal effects in commercial environments. We address this challenge through a randomized controlled trial with 2,282 U.S. adults conducted on a new research platform we developed that uses AI bots to replicate live social media dynamics while enabling controlled experimentation. Participants engaged in 15-minute discussions about energy and climate topics, with treatment groups exposed to curiosity priming either through modified on-platform social norms, interface affordances, or both. Results demonstrate that curiosity priming significantly increased question-asking behavior and textual measures of curiosity in user posts, while also reducing toxicity. Although interventions decreased generic engagement behaviors like liking and commenting, they had no significant negative impact on reported app enjoyment or time spent writing posts and replies. Leveraging experimental control over platform features, our findings suggest that platform designs prioritizing curiosity can promote prosocial behaviors among users without compromising user experience.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16040v1">üìÑ Download PDF</a></p><hr><h3 id=jwst-advanced-deep-extragalactic-survey-jades-data-release-5-photometric-cataloghttpsarxivorgabs260115956v1><a href=https://arxiv.org/abs/2601.15956v1>JWST Advanced Deep Extragalactic Survey (JADES) Data Release 5: Photometric Catalog</a><a hidden class=anchor aria-hidden=true href=#jwst-advanced-deep-extragalactic-survey-jades-data-release-5-photometric-cataloghttpsarxivorgabs260115956v1>#</a></h3><p><strong>Authors:</strong> Brant E. Robertson, Benjamin D. Johnson, Sandro Tacchella, Daniel J. Eisenstein, Kevin Hainline, Stacey Alberts, Santiago Arribas, William M. Baker, Andrew J. Bunker, Alex J. Cameron, Stefano Carniani, Courtney Carreira, Jacopo Chevallard, Chiara Circosta, Emma Curtis-Lake, A. Lola Danhaive, Qiao Duan, Eiichi Egami, Ryan Hausen, Jakob M. Helton, Zhiyuan Ji, Roberto Maiolino, Pablo G. P√©rez-Gonz√°lez, D√°vid Pusk√°s, Marcia Rieke, Pierluigi Rinaldi, Fengwu Sun, Yang Sun, Hannah √úbler, James A. A. Trussler, Natalia C. Villanueva, Lily Whitler, Christina C. Williams, Christopher N. A. Willmer, Chris Willott, Zihao Wu, Yongda Zhu
<strong>Venue:</strong> arXiv (2026)</p><p>JADES Data Release 5 (DR5) photometric catalogs and describes the methodologies used for source detection, deblending, photometry, uncertainty estimation, and catalog curation. The catalogs are constructed from 35 space-based imaging mosaics obtained with JWST/NIRCam, JWST/MIRI, HST/ACS, and HST/WFC3, combining approximately 1250 hours of JADES imaging with extensive additional public JWST and HST observations in the GOODS fields. Sources are identified using custom signal-to-noise-based detection and deblending algorithms optimized for the depth, resolution, and complex point-spread-function structure of JWST imaging. Source centroids, shapes, and photometric apertures are determined using a new fast two-dimensional Gaussian regression method applied to detection-image profiles. We provide forced circular-aperture photometry, ellipsoidal Kron photometry, and curve-of-growth measurements for every source in every band. We introduce a new pixel-level regression framework to model photometric uncertainties as a function of aperture size and local mosaic properties, accounting for correlated noise in heterogeneous JWST mosaics. Photometric redshifts are computed using template-based fitting applied to both small-aperture photometry on unconvolved images and Kron photometry on common-PSF mosaics. The JADES DR5 catalogs supersede previous JADES photometric releases, and are publicly released through the Mikulski Archive for Space Telescopes and an interactive web interface.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15956v1">üìÑ Download PDF</a></p><hr><h3 id=natural-language-driven-global-mapping-of-martian-landformshttpsarxivorgabs260115949v1><a href=https://arxiv.org/abs/2601.15949v1>Natural Language-Driven Global Mapping of Martian Landforms</a><a hidden class=anchor aria-hidden=true href=#natural-language-driven-global-mapping-of-martian-landformshttpsarxivorgabs260115949v1>#</a></h3><p><strong>Authors:</strong> Yiran Wang, Shuoyuan Wang, Zhaoran Wei, Jiannan Zhao, Zhonghua Yao, Zejian Xie, Songxin Zhang, Jun Huang, Bingyi Jing, Hongxin Wei
<strong>Venue:</strong> arXiv (2026)</p><p>Planetary surfaces are typically analyzed using high-level semantic concepts in natural language, yet vast orbital image archives remain organized at the pixel level. This mismatch limits scalable, open-ended exploration of planetary surfaces. Here we present MarScope, a planetary-scale vision-language framework enabling natural language-driven, label-free mapping of Martian landforms. MarScope aligns planetary images and text in a shared semantic space, trained on over 200,000 curated image-text pairs. This framework transforms global geomorphic mapping on Mars by replacing pre-defined classifications with flexible semantic retrieval, enabling arbitrary user queries across the entire planet in 5 seconds with F1 scores up to 0.978. Applications further show that it extends beyond morphological classification to facilitate process-oriented analysis and similarity-based geomorphological mapping at a planetary scale. MarScope establishes a new paradigm where natural language serves as a direct interface for scientific discovery over massive geospatial datasets.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15949v1">üìÑ Download PDF</a></p><hr><h3 id=tenet-text-to-network-for-compact-policy-synthesishttpsarxivorgabs260115912v1><a href=https://arxiv.org/abs/2601.15912v1>TeNet: Text-to-Network for Compact Policy Synthesis</a><a hidden class=anchor aria-hidden=true href=#tenet-text-to-network-for-compact-policy-synthesishttpsarxivorgabs260115912v1>#</a></h3><p><strong>Authors:</strong> Ariyan Bighashdel, Kevin Sebastian Luck
<strong>Venue:</strong> arXiv (2026)</p><p>Robots that follow natural-language instructions often either plan at a high level using hand-designed interfaces or rely on large end-to-end models that are difficult to deploy for real-time control. We propose TeNet (Text-to-Network), a framework for instantiating compact, task-specific robot policies directly from natural language descriptions. TeNet conditions a hypernetwork on text embeddings produced by a pretrained large language model (LLM) to generate a fully executable policy, which then operates solely on low-dimensional state inputs at high control frequencies. By using the language only once at the policy instantiation time, TeNet inherits the general knowledge and paraphrasing robustness of pretrained LLMs while remaining lightweight and efficient at execution time. To improve generalization, we optionally ground language in behavior during training by aligning text embeddings with demonstrated actions, while requiring no demonstrations at inference time. Experiments on MuJoCo and Meta-World benchmarks show that TeNet produces policies that are orders of magnitude smaller than sequence-based baselines, while achieving strong performance in both multi-task and meta-learning settings and supporting high-frequency control. These results show that text-conditioned hypernetworks offer a practical way to build compact, language-driven controllers for ressource-constrained robot control tasks with real-time requirements.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15912v1">üìÑ Download PDF</a></p><hr><h2 id=-data_resources>üîç data_resources<a hidden class=anchor aria-hidden=true href=#-data_resources>#</a></h2><h3 id=cgpt-cluster-guided-partial-tables-with-llm-generated-supervision-for-table-retrievalhttpsarxivorgabs260115849v1><a href=https://arxiv.org/abs/2601.15849v1>CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval</a><a hidden class=anchor aria-hidden=true href=#cgpt-cluster-guided-partial-tables-with-llm-generated-supervision-for-table-retrievalhttpsarxivorgabs260115849v1>#</a></h3><p><strong>Authors:</strong> Tsung-Hsiang Chou, Chen-Jui Yu, Shui-Hsiang Hsu, Yao-Chung Fan
<strong>Venue:</strong> arXiv (2026)</p><p>General-purpose embedding models have demonstrated strong performance in text retrieval but remain suboptimal for table retrieval, where highly structured content leads to semantic compression and query-table mismatch. Recent LLM-based retrieval augmentation methods mitigate this issue by generating synthetic queries, yet they often rely on heuristic partial-table selection and seldom leverage these synthetic queries as supervision to improve the embedding model. We introduce CGPT, a training framework that enhances table retrieval through LLM-generated supervision. CGPT constructs semantically diverse partial tables by clustering table instances using K-means and sampling across clusters to broaden semantic coverage. An LLM then generates synthetic queries for these partial tables, which are used in hard-negative contrastive fine-tuning to refine the embedding model. Experiments across four public benchmarks (MimoTable, OTTQA, FetaQA, and E2E-WTQ) show that CGPT consistently outperforms retrieval baselines, including QGpT, with an average R@1 improvement of 16.54 percent. In a unified multi-domain corpus setting, CGPT further demonstrates strong cross-domain generalization and remains effective even when using smaller LLMs for synthetic query generation. These results indicate that semantically guided partial-table construction, combined with contrastive training from LLM-generated supervision, provides an effective and scalable paradigm for large-scale table retrieval. Our code is available at <a href=https://github.com/yumeow0122/CGPT>https://github.com/yumeow0122/CGPT</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15849v1">üìÑ Download PDF</a></p><hr><h3 id=synthocr-gen-a-synthetic-ocr-dataset-generator-for-low-resource-languages--breaking-the-data-barrierhttpsarxivorgabs260116113v1><a href=https://arxiv.org/abs/2601.16113v1>synthocr-gen: A synthetic ocr dataset generator for low-resource languages- breaking the data barrier</a><a hidden class=anchor aria-hidden=true href=#synthocr-gen-a-synthetic-ocr-dataset-generator-for-low-resource-languages--breaking-the-data-barrierhttpsarxivorgabs260116113v1>#</a></h3><p><strong>Authors:</strong> Haq Nawaz Malik, Kh Mohmad Shafi, Tanveer Ahmad Reshi
<strong>Venue:</strong> arXiv (2026)</p><p>Optical Character Recognition (OCR) for low-resource languages remains a significant challenge due to the scarcity of large-scale annotated training datasets. Languages such as Kashmiri, with approximately 7 million speakers and a complex Perso-Arabic script featuring unique diacritical marks, currently lack support in major OCR systems including Tesseract, TrOCR, and PaddleOCR. Manual dataset creation for such languages is prohibitively expensive, time-consuming, and error-prone, often requiring word by word transcription of printed or handwritten text.
We present SynthOCR-Gen, an open-source synthetic OCR dataset generator specifically designed for low-resource languages. Our tool addresses the fundamental bottleneck in OCR development by transforming digital Unicode text corpora into ready-to-use training datasets. The system implements a comprehensive pipeline encompassing text segmentation (character, word, n-gram, sentence, and line levels), Unicode normalization with script purity enforcement, multi-font rendering with configurable distribution, and 25+ data augmentation techniques simulating real-world document degradations including rotation, blur, noise, and scanner artifacts.
We demonstrate the efficacy of our approach by generating a 600,000-sample word-segmented Kashmiri OCR dataset, which we release publicly on HuggingFace. This work provides a practical pathway for bringing low-resource languages into the era of vision-language AI models, and the tool is openly available for researchers and practitioners working with underserved writing systems worldwide.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16113v1">üìÑ Download PDF</a></p><hr><h3 id=a-multi-view-pipeline-and-benchmark-dataset-for-3d-hand-pose-estimation-in-surgeryhttpsarxivorgabs260115918v1><a href=https://arxiv.org/abs/2601.15918v1>A Multi-View Pipeline and Benchmark Dataset for 3D Hand Pose Estimation in Surgery</a><a hidden class=anchor aria-hidden=true href=#a-multi-view-pipeline-and-benchmark-dataset-for-3d-hand-pose-estimation-in-surgeryhttpsarxivorgabs260115918v1>#</a></h3><p><strong>Authors:</strong> Valery Fischer, Alan Magdaleno, Anna-Katharina Calek, Nicola Cavalcanti, Nathan Hoffman, Christoph Germann, Joschua W√ºthrich, Max Kr√§henmann, Mazda Farshad, Philipp F√ºrnstahl, Lilian Calvet
<strong>Venue:</strong> arXiv (2026)</p><p>Purpose: Accurate 3D hand pose estimation supports surgical applications such as skill assessment, robot-assisted interventions, and geometry-aware workflow analysis. However, surgical environments pose severe challenges, including intense and localized lighting, frequent occlusions by instruments or staff, and uniform hand appearance due to gloves, combined with a scarcity of annotated datasets for reliable model training.
Method: We propose a robust multi-view pipeline for 3D hand pose estimation in surgical contexts that requires no domain-specific fine-tuning and relies solely on off-the-shelf pretrained models. The pipeline integrates reliable person detection, whole-body pose estimation, and state-of-the-art 2D hand keypoint prediction on tracked hand crops, followed by a constrained 3D optimization. In addition, we introduce a novel surgical benchmark dataset comprising over 68,000 frames and 3,000 manually annotated 2D hand poses with triangulated 3D ground truth, recorded in a replica operating room under varying levels of scene complexity.
Results: Quantitative experiments demonstrate that our method consistently outperforms baselines, achieving a 31% reduction in 2D mean joint error and a 76% reduction in 3D mean per-joint position error.
Conclusion: Our work establishes a strong baseline for 3D hand pose estimation in surgery, providing both a training-free pipeline and a comprehensive annotated dataset to facilitate future research in surgical computer vision.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15918v1">üìÑ Download PDF</a></p><hr><h3 id=a-lightweight-brain-inspired-machine-learning-framework-for-coronary-angiography-hybrid-neural-representation-and-robust-learning-strategieshttpsarxivorgabs260115865v1><a href=https://arxiv.org/abs/2601.15865v1>A Lightweight Brain-Inspired Machine Learning Framework for Coronary Angiography: Hybrid Neural Representation and Robust Learning Strategies</a><a hidden class=anchor aria-hidden=true href=#a-lightweight-brain-inspired-machine-learning-framework-for-coronary-angiography-hybrid-neural-representation-and-robust-learning-strategieshttpsarxivorgabs260115865v1>#</a></h3><p><strong>Authors:</strong> Jingsong Xia, Siqi Wang
<strong>Venue:</strong> arXiv (2026)</p><p>Background: Coronary angiography (CAG) is a cornerstone imaging modality for assessing coronary artery disease and guiding interventional treatment decisions. However, in real-world clinical settings, angiographic images are often characterized by complex lesion morphology, severe class imbalance, label uncertainty, and limited computational resources, posing substantial challenges to conventional deep learning approaches in terms of robustness and generalization.Methods: The proposed framework is built upon a pretrained convolutional neural network to construct a lightweight hybrid neural representation. A selective neural plasticity training strategy is introduced to enable efficient parameter adaptation. Furthermore, a brain-inspired attention-modulated loss function, combining Focal Loss with label smoothing, is employed to enhance sensitivity to hard samples and uncertain annotations. Class-imbalance-aware sampling and cosine annealing with warm restarts are adopted to mimic rhythmic regulation and attention allocation mechanisms observed in biological neural systems.Results: Experimental results demonstrate that the proposed lightweight brain-inspired model achieves strong and stable performance in binary coronary angiography classification, yielding competitive accuracy, recall, F1-score, and AUC metrics while maintaining high computational efficiency.Conclusion: This study validates the effectiveness of brain-inspired learning mechanisms in lightweight medical image analysis and provides a biologically plausible and deployable solution for intelligent clinical decision support under limited computational resources.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15865v1">üìÑ Download PDF</a></p><hr><h2 id=-emotion_language>üîç emotion_language<a hidden class=anchor aria-hidden=true href=#-emotion_language>#</a></h2><h3 id=synthetic-augmentation-in-imbalanced-learning-when-it-helps-when-it-hurts-and-how-much-to-addhttpsarxivorgabs260116120v1><a href=https://arxiv.org/abs/2601.16120v1>Synthetic Augmentation in Imbalanced Learning: When It Helps, When It Hurts, and How Much to Add</a><a hidden class=anchor aria-hidden=true href=#synthetic-augmentation-in-imbalanced-learning-when-it-helps-when-it-hurts-and-how-much-to-addhttpsarxivorgabs260116120v1>#</a></h3><p><strong>Authors:</strong> Zhengchi Ma, Anru R. Zhang
<strong>Venue:</strong> arXiv (2026)</p><p>Imbalanced classification, where one class is observed far less frequently than the other, often causes standard training procedures to prioritize the majority class and perform poorly on rare but important cases. A classic and widely used remedy is to augment the minority class with synthetic examples, but two basic questions remain under-resolved: when does synthetic augmentation actually help, and how many synthetic samples should be generated?
We develop a unified statistical framework for synthetic augmentation in imbalanced learning, studying models trained on imbalanced data augmented with synthetic minority samples and evaluated under the balanced population risk. Our theory shows that synthetic data is not always beneficial. In a <code>local symmetry" regime, imbalance is not the dominant source of error near the balanced optimum, so adding synthetic samples cannot improve learning rates and can even degrade performance by amplifying generator mismatch. When augmentation can help (a </code>local asymmetry" regime), the optimal synthetic size depends on generator accuracy and on whether the generator&rsquo;s residual mismatch is directionally aligned with the intrinsic majority-minority shift. This structure can make the best synthetic size deviate from naive full balancing, sometimes by a small refinement and sometimes substantially when generator bias is systematic. Practically, we recommend Validation-Tuned Synthetic Size (VTSS): select the synthetic size by minimizing balanced validation loss over a range centered near the fully balanced baseline, while allowing meaningful departures when the data indicate them. Simulations and a real sepsis prediction study support the theory and illustrate when synthetic augmentation helps, when it cannot, and how to tune its quantity effectively.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16120v1">üìÑ Download PDF</a></p><hr><h3 id=benchmarking-deep-learning-models-for-raman-spectroscopy-across-open-source-datasetshttpsarxivorgabs260116107v1><a href=https://arxiv.org/abs/2601.16107v1>Benchmarking Deep Learning Models for Raman Spectroscopy Across Open-Source Datasets</a><a hidden class=anchor aria-hidden=true href=#benchmarking-deep-learning-models-for-raman-spectroscopy-across-open-source-datasetshttpsarxivorgabs260116107v1>#</a></h3><p><strong>Authors:</strong> Adithya Sineesh, Akshita Kamsali
<strong>Venue:</strong> arXiv (2026)</p><p>Deep learning classifiers for Raman spectroscopy are increasingly reported to outperform classical chemometric approaches. However their evaluations are often conducted in isolation or compared against traditional machine learning methods or trivially adapted vision-based architectures that were not originally proposed for Raman spectroscopy. As a result, direct comparisons between existing deep learning models developed specifically for Raman spectral analysis on shared open-source datasets remain scarce. To the best of our knowledge, this study presents one of the first systematic benchmarks comparing three or more published Raman-specific deep learning classifiers across multiple open-source Raman datasets. We evaluate five representative deep learning architectures under a unified training and hyperparameter tuning protocol across three open-source Raman datasets selected to support standard evaluation, fine-tuning, and explicit distribution-shift testing. We report classification accuracies and macro-averaged F1 scores to provide a fair and reproducible comparison of deep learning models for Raman spectra based classification.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16107v1">üìÑ Download PDF</a></p><hr><h3 id=clustering-guided-spatial-spectral-mamba-for-hyperspectral-image-classificationhttpsarxivorgabs260116098v1><a href=https://arxiv.org/abs/2601.16098v1>Clustering-Guided Spatial-Spectral Mamba for Hyperspectral Image Classification</a><a hidden class=anchor aria-hidden=true href=#clustering-guided-spatial-spectral-mamba-for-hyperspectral-image-classificationhttpsarxivorgabs260116098v1>#</a></h3><p><strong>Authors:</strong> Zack Dewis, Yimin Zhu, Zhengsen Xu, Mabel Heffring, Saeid Taleghanidoozdoozan, Quinn Ledingham, Lincoln Linlin Xu
<strong>Venue:</strong> arXiv (2026)</p><p>Although Mamba models greatly improve Hyperspectral Image (HSI) classification, they have critical challenges in terms defining efficient and adaptive token sequences for improve performance. This paper therefore presents CSSMamba (Clustering-guided Spatial-Spectral Mamba) framework to better address the challenges, with the following contributions. First, to achieve efficient and adaptive token sequences for improved Mamba performance, we integrate the clustering mechanism into a spatial Mamba architecture, leading to a cluster-guided spatial Mamba module (CSpaMamba) that reduces the Mamba sequence length and improves Mamba feature learning capability. Second, to improve the learning of both spatial and spectral information, we integrate the CSpaMamba module with a spectral mamba module (SpeMamba), leading to a complete clustering-guided spatial-spectral Mamba framework. Third, to further improve feature learning capability, we introduce an Attention-Driven Token Selection mechanism to optimize Mamba token sequencing. Last, to seamlessly integrate clustering into the Mamba model in a coherent manner, we design a Learnable Clustering Module that learns the cluster memberships in an adaptive manner. Experiments on the Pavia University, Indian Pines, and Liao-Ning 01 datasets demonstrate that CSSMamba achieves higher accuracy and better boundary preservation compared to state-of-the-art CNN, Transformer, and Mamba-based methods.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16098v1">üìÑ Download PDF</a></p><hr><h3 id=constraining-dark-energy-models-using-jackknife-and-bootstrap-resamplinghttpsarxivorgabs260116197v1><a href=https://arxiv.org/abs/2601.16197v1>Constraining dark energy models using Jackknife and Bootstrap resampling</a><a hidden class=anchor aria-hidden=true href=#constraining-dark-energy-models-using-jackknife-and-bootstrap-resamplinghttpsarxivorgabs260116197v1>#</a></h3><p><strong>Authors:</strong> Roshna K, Nikhil Fernandes, P Praveen, V. Sreenath
<strong>Venue:</strong> arXiv (2026)</p><p>Analyses of type Ia supernovae have helped us shed light on the existence and nature of dark energy. Most of these analyses have relied on Bayesian techniques. In this work, we rely on resampling techniques to analyse supernova data. In particular, we use the generalised least squares method together with Jackknife and Bootstrap techniques to estimate parameters of $Œõ$CDM, flat $Œõ$CDM, $w$CDM, flat $w$CDM, and flat $w_0,w_a$CDM models from the recent PantheonPlus and SH0ES data. For completeness, we also perform Bayesian analysis using Markov chain Monte Carlo (MCMC) and nested sampling algorithms, and compare the results. We note that resampling techniques can help highlight the limitations of the data. For instance, we see that the Jackknife method estimates a strong positive correlation between $h$ and $M$ and higher standard deviations for both. This may have significant implications for the Hubble tension. We conclude with a discussion of our results.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16197v1">üìÑ Download PDF</a></p><hr><h3 id=evolution-of-the-recent-high-accretion-state-of-the-recurrent-nova-t-crb-hst-swift-nustar-and-xmm-newton-observationshttpsarxivorgabs260116190v1><a href=https://arxiv.org/abs/2601.16190v1>Evolution of the recent high-accretion state of the recurrent nova T CrB: HST, Swift, NuSTAR, and XMM-Newton observations</a><a hidden class=anchor aria-hidden=true href=#evolution-of-the-recent-high-accretion-state-of-the-recurrent-nova-t-crb-hst-swift-nustar-and-xmm-newton-observationshttpsarxivorgabs260116190v1>#</a></h3><p><strong>Authors:</strong> G. J. M. Luna, N. P. M. Kuin, K. Mukai, J. L. Sokoloski, K. Page, J. P. Osborne
<strong>Venue:</strong> arXiv (2026)</p><p>As the recurrent nova T Coronae Borealis (T CrB) approaches its next predicted thermonuclear eruption, it is currently exhibiting a &ldquo;super-active state&rdquo; (SAS) characterized by enhanced multiwavelength emission similar to the behavior recorded prior to the 1946 outburst. We present a multiwavelength analysis of the SAS and the subsequent &ldquo;faint state&rdquo; using observations from HST, Swift, NuSTAR, and XMM-Newton. Our results indicate that the SAS was driven by an increase in the mass accretion rate, which caused the accretion disk&rsquo;s boundary layer to become optically thick. A weighted least squares regression analysis quantifies the evolution of the accretion components, displaying a highly significant (4.5$œÉ$) increase in the luminosity of the optically thin cooling flow (L$<em>{cf}$) and a marginal (2.58$œÉ$) decrease in the optically thick boundary layer luminosity (L$</em>{bb}$) as the system transitioned into the faint state. We find that this dimming is consistent with an intrinsic change in the accretion flow rather than dust obscuration, supported by the lack of infrared excess and the stability of the 2175 √Ö feature. Additionally, a time-series analysis using autoregressive modeling to account for correlated red noise revealed no significant periodicities, thereby disputing the previously reported $\sim$6000 s signal. These findings suggest that the pre-outburst evolution of T CrB is characterized by significant changes in the accretion disk structure and boundary layer, providing a self-consistent physical framework for the system&rsquo;s behavior as it approaches eruption.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16190v1">üìÑ Download PDF</a></p><hr><h3 id=string-breaking-and-glueball-dynamics-in-21d-quantum-link-electrodynamicshttpsarxivorgabs260116166v1><a href=https://arxiv.org/abs/2601.16166v1>String Breaking and Glueball Dynamics in $2+1$D Quantum Link Electrodynamics</a><a hidden class=anchor aria-hidden=true href=#string-breaking-and-glueball-dynamics-in-21d-quantum-link-electrodynamicshttpsarxivorgabs260116166v1>#</a></h3><p><strong>Authors:</strong> Jiahao Cao, Rohan Joshi, Yizhuo Tian, N. S. Srivatsa, Jad C. Halimeh
<strong>Venue:</strong> arXiv (2026)</p><p>At the heart of quark confinement and hadronization, the physics of flux strings has recently become a focal point in the field of quantum simulation of high-energy physics (HEP). Despite considerable progress, a detailed understanding of the behavior of flux strings in quantum simulation-relevant lattice formulations of gauge theories has remained limited to the lowest truncations of the gauge field, which are severely limited in their ability to draw conclusions about the quantum field theory limit. Here, we employ tensor network simulations to investigate the behavior of flux strings in a quantum link formulation of $2+1$D quantum electrodynamics (QED) with a spin-$1$ representation of the gauge field. We first map out the ground-state phase diagram of this model in the presence of two spatially separated static charges, revealing distinct microscopic processes responsible for string breaking, including a two-stage breaking mechanism not possible in the spin-$\frac{1}{2}$ formulation. Starting in different initial product state string configurations, we then explore far-from-equilibrium quench dynamics across various parameter regimes, demonstrating genuine $2+1$D real-time string breaking and glueball-like bound state formation, with the latter not possible in the spin-$\frac{1}{2}$ formulation. In and out of equilibrium, we consider different values and placements of the static charges. Finally, we provide efficient qudit circuits for a quantum simulation experiment in which our results can be observed in state-of-the-art ion-trap setups. Our findings lay the groundwork for quantum simulations of flux strings towards the quantum field theory limit.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16166v1">üìÑ Download PDF</a></p><hr><h3 id=a-saturation-bound-for-cumulative-responses-under-local-linear-relaxationhttpsarxivorgabs260116157v1><a href=https://arxiv.org/abs/2601.16157v1>A saturation bound for cumulative responses under local linear relaxation</a><a hidden class=anchor aria-hidden=true href=#a-saturation-bound-for-cumulative-responses-under-local-linear-relaxationhttpsarxivorgabs260116157v1>#</a></h3><p><strong>Authors:</strong> Sanjeev Kumar Verma
<strong>Venue:</strong> arXiv (2026)</p><p>Saturation of cumulative observables is widely observed in systems with propagating or spreading signals and is commonly modeled using system-specific mechanisms such as scattering statistics, coherence functions, or phenomenological decay laws. This work shows that such saturation follows directly from linear local relaxation alone. Any linear observable accumulated over the lifetime of a relaxing signal is bounded by a scale set by the relaxation time, independent of geometry, dimensionality, or microscopic dynamics. When relaxation is mapped to space through transport or spreading, this temporal bound yields a corresponding spatial saturation scale. A closed-form expression reveals a two-regime behavior: linear growth at short times followed by saturation beyond the relaxation time. The result provides a minimal and unified explanation for cumulative saturation across transport, diffusive, and stochastic systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16157v1">üìÑ Download PDF</a></p><hr><h3 id=interconnection-based-model-reduction-for-linear-hybrid-systemshttpsarxivorgabs260116149v1><a href=https://arxiv.org/abs/2601.16149v1>Interconnection-based Model Reduction for Linear Hybrid Systems</a><a hidden class=anchor aria-hidden=true href=#interconnection-based-model-reduction-for-linear-hybrid-systemshttpsarxivorgabs260116149v1>#</a></h3><p><strong>Authors:</strong> Zirui Niu, Giordano Scarciotti, Alessandro Astolfi
<strong>Venue:</strong> arXiv (2026)</p><p>In this paper, we address the model reduction problem for linear hybrid systems via the interconnection-based technique called moment matching. We consider two classical interconnections, namely the direct and swapped interconnections, in the hybrid setting, and we present families of reduced-order models for each interconnection via a hybrid characterisation of the steady-state responses. By combining the results for each interconnection, the design of a reduced-order model that achieves moment matching simultaneously for both interconnections is studied. In addition, we show that the presented results have simplified counterparts when the jumps of the hybrid system are periodic. A numerical simulation is finally given to illustrate the results.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16149v1">üìÑ Download PDF</a></p><hr><h3 id=calibration-conditioned-film-decoders-for-low-latency-decoding-of-quantum-error-correction-evaluated-on-ibm-repetition-code-experimentshttpsarxivorgabs260116123v1><a href=https://arxiv.org/abs/2601.16123v1>Calibration-Conditioned FiLM Decoders for Low-Latency Decoding of Quantum Error Correction Evaluated on IBM Repetition-Code Experiments</a><a hidden class=anchor aria-hidden=true href=#calibration-conditioned-film-decoders-for-low-latency-decoding-of-quantum-error-correction-evaluated-on-ibm-repetition-code-experimentshttpsarxivorgabs260116123v1>#</a></h3><p><strong>Authors:</strong> Samuel Stein, Shuwen Kan, Chenxu Liu, Adrian Harkness, Sean Garner, Zefan Du, Yufei Ding, Ying Mao, Ang Li
<strong>Venue:</strong> arXiv (2026)</p><p>Real-time decoding of quantum error correction (QEC) is essential for enabling fault-tolerant quantum computation. A practical decoder must operate with high accuracy at low latency, while remaining robust to spatial and temporal variations in hardware noise. We introduce a hardware-conditioned neural decoder framework designed to exploit the natural separation of timescales in superconducting processors, where calibration drifts occur over hours while error correction requires microsecond-scale responses. By processing calibration data through a graph-based encoder and conditioning a lightweight convolutional backbone via feature-wise linear modulation (FiLM), we decouple the heavy processing of device statistics from the low-latency syndrome decoding.
We evaluate this approach using the 1D repetition code as a testbed on IBM Fez, Kingston, and Pittsburgh processors, collecting over 2.7 million experimental shots spanning distances up to d = 11. We demonstrate that a single trained model generalizes to unseen qubit chains and new calibration data acquired days later without retraining. On these unseen experiments, the FiLM-conditioned decoder achieves up to an 11.1x reduction in logical error rate relative to modified minimum-weight perfect matching. We observe that by employing a network architecture that exploits the highly asynchronous nature of system calibration and decoding, hardware-conditioned neural decoding demonstrates promising, adaptive performance with negligible latency overhead relative to unconditioned baselines.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16123v1">üìÑ Download PDF</a></p><hr><h3 id=controlling-long-horizon-behavior-in-language-model-agents-with-explicit-state-dynamicshttpsarxivorgabs260116087v1><a href=https://arxiv.org/abs/2601.16087v1>Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics</a><a hidden class=anchor aria-hidden=true href=#controlling-long-horizon-behavior-in-language-model-agents-with-explicit-state-dynamicshttpsarxivorgabs260116087v1>#</a></h3><p><strong>Authors:</strong> Sukesh Subaharan
<strong>Venue:</strong> arXiv (2026)</p><p>Large language model (LLM) agents often exhibit abrupt shifts in tone and persona during extended interaction, reflecting the absence of explicit temporal structure governing agent-level state. While prior work emphasizes turn-local sentiment or static emotion classification, the role of explicit affective dynamics in shaping long-horizon agent behavior remains underexplored. This work investigates whether imposing dynamical structure on an external affective state can induce temporal coherence and controlled recovery in multi-turn dialogue. We introduce an agent-level affective subsystem that maintains a continuous Valence-Arousal-Dominance (VAD) state external to the language model and governed by first- and second-order update rules. Instantaneous affective signals are extracted using a fixed, memoryless estimator and integrated over time via exponential smoothing or momentum-based dynamics. The resulting affective state is injected back into generation without modifying model parameters. Using a fixed 25-turn dialogue protocol, we compare stateless, first-order, and second-order affective dynamics. Stateless agents fail to exhibit coherent trajectories or recovery, while state persistence enables delayed responses and reliable recovery. Second-order dynamics introduce affective inertia and hysteresis that increase with momentum, revealing a trade-off between stability and responsiveness.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16087v1">üìÑ Download PDF</a></p><hr><h3 id=robust-bell-nonlocality-from-gottesman-kitaev-preskill-stateshttpsarxivorgabs260116189v1><a href=https://arxiv.org/abs/2601.16189v1>Robust Bell Nonlocality from Gottesman-Kitaev-Preskill States</a><a hidden class=anchor aria-hidden=true href=#robust-bell-nonlocality-from-gottesman-kitaev-preskill-stateshttpsarxivorgabs260116189v1>#</a></h3><p><strong>Authors:</strong> Xiaotian Yang, Santiago Zamora, Rafael Chaves, Ulrik L. Andersen, Jonatan Bohr Brask, A. de Oliveira Junior
<strong>Venue:</strong> arXiv (2026)</p><p>Bell tests based on homodyne detection are strongly constrained in continuous-variable systems. Can Gottesman-Kitaev-Preskill (GKP) encoding turn homodyne detection into a practical tool for revealing Bell nonlocality? We consider a physically motivated model in which each party performs homodyne detection and digitizes the continuous outcome via a fixed periodic binning, corresponding to logical Pauli measurements. Within this framework, we derive a bipartite no-go: CHSH cannot be violated for Bell-pair states. Moving beyond two parties, we show that finitely squeezed GKP-encoded GHZ and W states nevertheless exhibit strong multipartite nonlocality, violating multipartite Bell inequalities with homodyne-only readout. We quantify the required squeezing thresholds and robustness to loss, providing a route toward homodyne-based Bell tests in continuous-variable systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16189v1">üìÑ Download PDF</a></p><hr><h3 id=magnetar-fraction-in-core-collapse-supernovaehttpsarxivorgabs260116159v1><a href=https://arxiv.org/abs/2601.16159v1>Magnetar fraction in Core-Collapse Supernovae</a><a hidden class=anchor aria-hidden=true href=#magnetar-fraction-in-core-collapse-supernovaehttpsarxivorgabs260116159v1>#</a></h3><p><strong>Authors:</strong> Celsa Pardo-Araujo, Nanda Rea, Michele Ronchi, Vanessa Graber
<strong>Venue:</strong> arXiv (2026)</p><p>Magnetars are extreme neutron stars powered by ultra-strong magnetic fields ($\sim10^{14}$ Gauss) and are compelling engines for some of the most powerful extragalactic transients such as Super Luminous Supernovae, Gamma-Ray Bursts, and Fast Radio Bursts. Yet their formation rate relative to ordinary neutron stars remains uncertain, often precluding direct comparisons with the rates of these extragalactic transients. Furthermore, magnetars have been recently shown to be evolutionarily related to other neutron star classes, complicating the estimate of the exact magnetar fraction within the neutron star population. We study the magnetar birth fraction in core-collapse supernovae using pulsar population synthesis of all isolated neutron star classes in our Galaxy, incorporating self-consistently the Galactic dynamical evolution, spin-down and magneto-thermal evolution. This approach allows us to derive strong constraints from small close-to-complete observational samples. In particular, looking at the age-limited young ($&lt;$2 kyr) neutron star population in the Milky Way we find 24 detected young neutron stars, with only 10 of them (41%) being classical rotational powered pulsars, while the others (59%) are either magnetars or central compact objects, the latter believed to be equally magnetically powered. We further compare the results with the nearby volume-limited class ($&lt;$500 pc) of X-ray Dim Isolated Neutron stars, old nearby magnetars. We conclude that the observed population of isolated neutron stars in the Galaxy can be reproduced only by assuming a core-collapse supernova rate larger than two, and a larger magnetar fraction than previously inferred. By assuming a bimodal initial magnetic field ($B_0$) distribution at birth, we find that the magnetar class peaks between $B_0\sim 1-2.5\times10^{14}$ Gauss and represents on average $\sim50$% of the entire neutron star population.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16159v1">üìÑ Download PDF</a></p><hr><h3 id=charge-and-spin-orders-in-the-t-u-v-j-model-a-slave-spin-1-approachhttpsarxivorgabs260116153v1><a href=https://arxiv.org/abs/2601.16153v1>Charge and spin orders in the t-U-V-J model: a slave-spin-1 approach</a><a hidden class=anchor aria-hidden=true href=#charge-and-spin-orders-in-the-t-u-v-j-model-a-slave-spin-1-approachhttpsarxivorgabs260116153v1>#</a></h3><p><strong>Authors:</strong> Olivier Simard, Michel Ferrero, Thomas Ayral
<strong>Venue:</strong> arXiv (2026)</p><p>Strongly-correlated fermion systems on a lattice have been a subject of intense focus in the field of condensed-matter physics. These systems are notoriously difficult to solve, even with state-of-the-art numerical methods, especially in regimes of parameters where degrees of freedom compete or cooperate at similar energy and length scales. Here, we introduce a spin-1 slave-particle technique to approximately treat the t-U-V-J fermionic model at arbitrary electron dopings in an economical manner. This formalism respectively maps the original charge and spin degrees of freedom into effective pseudo-spin and pseudo-fermion sectors, which are treated using a self-consistent cluster mean-field method. We study the phase diagram of the model under various conditions and report the appearance of charge and spin stripes within this formalism. These stripes are a consequence of the cluster mean-field treatment of the pseudo-particle sectors and have not been detected in previous slave-particle studies. The results obtained agree qualitatively well with what more reliable numerical methods capture.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16153v1">üìÑ Download PDF</a></p><hr><h3 id=transition-in-splitting-probabilities-of-quantum-walkshttpsarxivorgabs260116111v1><a href=https://arxiv.org/abs/2601.16111v1>Transition in Splitting Probabilities of Quantum Walks</a><a hidden class=anchor aria-hidden=true href=#transition-in-splitting-probabilities-of-quantum-walkshttpsarxivorgabs260116111v1>#</a></h3><p><strong>Authors:</strong> Prashant Singh, David A. Kessler, Eli Barkai
<strong>Venue:</strong> arXiv (2026)</p><p>We investigate the splitting probability of a monitored continuous-time quantum walk with two targets and show that, in stark contrast to a classical random walk, it exhibits a nonanalytic, phase-transition-like behavior controlled by the sampling time at the targets. For large systems and sampling times smaller than a critical value $œÑ_c = 2œÄ/ŒîE$, where $ŒîE$ is the energy bandwidth, the splitting probability is universal and equal to $1/2$, independent of the initial condition and the sampling time. Above the critical sampling, a nonuniversal regime emerges in which the splitting probability deviates from $1/2$ and develops a fluctuating pattern of pronounced peaks and dips dependent on both the sampling time and the initial condition. These results follow from a nontrivial mapping of the splitting problem onto a pair of single-target detection problems enabled by the superposition principle.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16111v1">üìÑ Download PDF</a></p><hr><h3 id=engineering-polarization-how-contradictory-stimulation-systematically-undermines-political-moderationhttpsarxivorgabs260116181v1><a href=https://arxiv.org/abs/2601.16181v1>Engineering polarization: How contradictory stimulation systematically undermines political moderation</a><a hidden class=anchor aria-hidden=true href=#engineering-polarization-how-contradictory-stimulation-systematically-undermines-political-moderationhttpsarxivorgabs260116181v1>#</a></h3><p><strong>Authors:</strong> Renato Vieira dos Santos
<strong>Venue:</strong> arXiv (2026)</p><p>Political moderation, a key attractor in democratic systems, proves highly fragile under realistic information conditions. We develop a stochastic model of opinion dynamics to analyze how noise and differential susceptibility reshape the political spectrum. Extending Marvel et al.&rsquo;s deterministic framework, we incorporate stochastic media influence $Œ∂(t)$ and neuropolitically-grounded sensitivity differences ($œÉ_y > œÉ_x$). Analysis reveals the moderate population &ndash; stable in deterministic models &ndash; undergoes catastrophic collapse under stochastic forcing. This occurs through an effective deradicalization asymmetry ($u_{B}^{\text{eff}} = u + œÉ_y^2/2 > u_{A}^{\text{eff}}$) that drives conservatives to extinction, eliminating cross-cutting interactions that sustain moderates. The system exhibits a phase transition from multi-stable coexistence to liberal dominance, demonstrating how information flow architecture &ndash; independent of content &ndash; systematically dismantles the political center. Our findings reveal moderation as an emergent property highly vulnerable to stochastic perturbations in complex social systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16181v1">üìÑ Download PDF</a></p><hr><h3 id=from-harm-to-healing-understanding-individual-resilience-after-cybercrimeshttpsarxivorgabs260116050v1><a href=https://arxiv.org/abs/2601.16050v1>From Harm to Healing: Understanding Individual Resilience after Cybercrimes</a><a hidden class=anchor aria-hidden=true href=#from-harm-to-healing-understanding-individual-resilience-after-cybercrimeshttpsarxivorgabs260116050v1>#</a></h3><p><strong>Authors:</strong> Xiaowei Chen, Mindy Tran, Yue Deng, Bhupendra Acharya, Yixin Zou
<strong>Venue:</strong> arXiv (2026)</p><p>How do individuals recover from cybercrimes? Victims experience various types of harm after cybercrimes, including monetary loss, data breaches, negative emotions, and even psychological trauma. The aspects that support their recovery process and contribute to individual cyber resilience remain underinvestigated. To address this gap, we interviewed 18 cybercrime victims from Western Europe using a trauma-informed approach. We identified four common stages following victimization: recognition, coping, processing, and recovery. Participants adopted various strategies to mitigate the impact of cybercrime and used different indicators to describe recovery. While they mostly relied on social support and self-regulation for emotional coping, service providers largely determined whether victims were able to recover their money. Internal factors, external support, and context sensitivity collectively contribute to individuals&rsquo; cyber resilience. We recommend trauma-informed support for cybercrime victims. Extending our conceptualization of individual cyber resilience, we propose collaborative and context-sensitive strategies to address the harmful impacts of cybercrime.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.16050v1">üìÑ Download PDF</a></p><hr><h3 id=predicting-healthcare-system-visitation-flow-by-integrating-hospital-attributes-and-population-socioeconomics-with-human-mobility-datahttpsarxivorgabs260115977v1><a href=https://arxiv.org/abs/2601.15977v1>Predicting Healthcare System Visitation Flow by Integrating Hospital Attributes and Population Socioeconomics with Human Mobility Data</a><a hidden class=anchor aria-hidden=true href=#predicting-healthcare-system-visitation-flow-by-integrating-hospital-attributes-and-population-socioeconomics-with-human-mobility-datahttpsarxivorgabs260115977v1>#</a></h3><p><strong>Authors:</strong> Binbin Lin, Lei Zou, Hao Tian, Heng Cai, Yifan Yang, Bing Zhou
<strong>Venue:</strong> arXiv (2026)</p><p>Healthcare visitation patterns are influenced by a complex interplay of hospital attributes, population socioeconomics, and spatial factors. However, existing research often adopts a fragmented approach, examining these determinants in isolation. This study addresses this gap by integrating hospital capacities, occupancy rates, reputation, and popularity with population SES and spatial mobility patterns to predict visitation flows and analyze influencing factors. Utilizing four years of SafeGraph mobility data and user experience data from Google Maps Reviews, five flow prediction models, Naive Regression, Gradient Boosting, Multilayer Perceptrons (MLPs), Deep Gravity, and Heterogeneous Graph Neural Networks (HGNN),were trained and applied to simulate visitation flows in Houston, Texas, U.S. The Shapley additive explanation (SHAP) analysis and the Partial Dependence Plot (PDP) method were employed to examine the combined impacts of different factors on visitation patterns. The findings reveal that Deep Gravity outperformed other models. Hospital capacities, ICU occupancy rates, ratings, and popularity significantly influence visitation patterns, with their effects varying across different travel distances. Short-distance visits are primarily driven by convenience, whereas long-distance visits are influenced by hospital ratings. White-majority areas exhibited lower sensitivity to hospital ratings for short-distance visits, while Asian populations and those with higher education levels prioritized hospital rating in their visitation decisions. SES further influence these patterns, as areas with higher proportions of Hispanic, Black, under-18, and over-65 populations tend to have more frequent hospital visits, potentially reflecting greater healthcare needs or limited access to alternative medical services.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15977v1">üìÑ Download PDF</a></p><hr><h3 id=unveiling-and-simulating-short-video-addiction-behaviors-via-economic-addiction-theoryhttpsarxivorgabs260115975v1><a href=https://arxiv.org/abs/2601.15975v1>Unveiling and Simulating Short-Video Addiction Behaviors via Economic Addiction Theory</a><a hidden class=anchor aria-hidden=true href=#unveiling-and-simulating-short-video-addiction-behaviors-via-economic-addiction-theoryhttpsarxivorgabs260115975v1>#</a></h3><p><strong>Authors:</strong> Chen Xu, Zhipeng Yi, Ruizi Wang, Wenjie Wang, Jun Xu, Maarten de Rijke
<strong>Venue:</strong> arXiv (2026)</p><p>Short-video applications have attracted substantial user traffic. However, these platforms also foster problematic usage patterns, commonly referred to as short-video addiction, which pose risks to both user health and the sustainable development of platforms. Prior studies on this issue have primarily relied on questionnaires or volunteer-based data collection, which are often limited by small sample sizes and population biases. In contrast, short-video platforms have large-scale behavioral data, offering a valuable foundation for analyzing addictive behaviors. To examine addiction-aware behavior patterns, we combine economic addiction theory with users&rsquo; implicit behavior captured by recommendation systems. Our analysis shows that short-video addiction follows functional patterns similar to traditional forms of addictive behavior (e.g., substance abuse) and that its intensity is consistent with findings from previous social science studies. To develop a simulator that can learn and model these patterns, we introduce a novel training framework, AddictSim. To consider the personalized addiction patterns, AddictSim uses a mean-to-adapted strategy with group relative policy optimization training. Experiments on two large-scale datasets show that AddictSim consistently outperforms existing training strategies. Our simulation results show that integrating diversity-aware algorithms can mitigate addictive behaviors well.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2601.15975v1">üìÑ Download PDF</a></p><hr></div><footer class=post-footer><ul class=post-tags></ul></footer><div><div class=pagination__title><span class=pagination__title-h style=font-size:20px>Comments</span><hr></div><div id=tcomment></div><script src=https://cdn.staticfile.org/twikoo/1.6.39/twikoo.all.min.js></script><script>twikoo.init({envId:"https://mangodb-theta.vercel.app/",el:"#tcomment",lang:"en-US",path:window.TWIKOO_MAGIC_PATH||window.location.pathname})</script></div></article></main><footer class=footer><span>&copy; 2026 <a href=https://garyforreal.me/en/>Gary's House</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span><div class=busuanzi-footer><span id=busuanzi_container_site_pv>Views: <span id=busuanzi_value_site_pv></span>
</span><span id=busuanzi_container_site_uv>Visitors: <span id=busuanzi_value_site_uv></span></span></div></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>