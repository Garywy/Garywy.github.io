<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Weekly Paper Notes - 2025-12-28 | Gary's House</title>
<meta name=keywords content><meta name=description content="Weekly Paper Notes
üîç multilingual
Model Merging via Multi-Teacher Knowledge Distillation
Authors: Seyed Arshan Dalili, Mehrdad Mahdavi
Venue: arXiv (2025)
Model merging has emerged as a lightweight alternative to joint multi-task learning (MTL), yet the generalization properties of merged models remain largely unexplored. Establishing such theoretical guarantees is non-trivial, as the merging process typically forbids access to the original training data and involves combining fine-tuned models trained on fundamentally heterogeneous data distributions. Without a principled understanding of these dynamics, current methods often rely on heuristics to approximate the optimal combination of parameters. This dependence is most critical in coefficient scaling, the weighting factors that modulate the magnitude of each fine-tuned model&rsquo;s contribution to the shared parameter. However, without a principled objective to guide their selection, these methods lead to brittle performance and are highly sensitive to scaling initialization. We address this gap by (i) establishing a novel flatness-aware PAC-Bayes generalization bound specifically for the model merging setting. This analysis introduces a &ldquo;cross-task heterogeneity&rdquo; term that formally captures the mismatch between diverse fine-tuned model priors and the target multi-task distributions. Guided by this theoretical insight, (ii) we frame model merging as multi-teacher knowledge distillation on scarce, unlabeled data. We formally demonstrate that minimizing the student-teacher Kullback-Leibler divergence directly tightens the upper bound on the merged model&rsquo;s excess risk. Guided by the flatness-aware bound derived, (iii) we operationalize this objective via SAMerging, a method that employs Sharpness-Aware Minimization (SAM) to find flat minima. Empirically, SAMerging establishes a new state of the art across vision and NLP benchmarks, achieving remarkable performance. The code is available at https://github.com/arshandalili/SAMerging."><meta name=author content="Gary"><link rel=canonical href=https://garyforreal.me/en/posts/paper/paper-2025-12-28-weekly/><meta name=google-site-verification content="XYZabc"><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><meta name=referrer content="no-referrer-when-downgrade"><link crossorigin=anonymous href=/assets/css/stylesheet.7e5251d8716d933fafcf3df70d7ecd02729661d6d232fc5dd0b8a85ef75e3409.css integrity="sha256-flJR2HFtkz+vzz33DX7NAnKWYdbSMvxd0LioXvdeNAk=" rel="preload stylesheet" as=style><link rel=icon href=https://garyforreal.me/img/Q.jpg><link rel=icon type=image/png sizes=16x16 href=https://garyforreal.me/img/Q.jpg><link rel=icon type=image/png sizes=32x32 href=https://garyforreal.me/img/Q.jpg><link rel=apple-touch-icon href=https://garyforreal.me/Q.jpg><link rel=mask-icon href=https://garyforreal.me/Q.jpg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://garyforreal.me/zh/posts/paper/paper-2025-12-28-weekly/><link rel=alternate hreflang=en href=https://garyforreal.me/en/posts/paper/paper-2025-12-28-weekly/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@200..900&display=swap" rel=stylesheet><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous referrerpolicy=no-referrer></script><meta property="og:title" content="Weekly Paper Notes - 2025-12-28"><meta property="og:description" content="Weekly Paper Notes
üîç multilingual
Model Merging via Multi-Teacher Knowledge Distillation
Authors: Seyed Arshan Dalili, Mehrdad Mahdavi
Venue: arXiv (2025)
Model merging has emerged as a lightweight alternative to joint multi-task learning (MTL), yet the generalization properties of merged models remain largely unexplored. Establishing such theoretical guarantees is non-trivial, as the merging process typically forbids access to the original training data and involves combining fine-tuned models trained on fundamentally heterogeneous data distributions. Without a principled understanding of these dynamics, current methods often rely on heuristics to approximate the optimal combination of parameters. This dependence is most critical in coefficient scaling, the weighting factors that modulate the magnitude of each fine-tuned model&rsquo;s contribution to the shared parameter. However, without a principled objective to guide their selection, these methods lead to brittle performance and are highly sensitive to scaling initialization. We address this gap by (i) establishing a novel flatness-aware PAC-Bayes generalization bound specifically for the model merging setting. This analysis introduces a &ldquo;cross-task heterogeneity&rdquo; term that formally captures the mismatch between diverse fine-tuned model priors and the target multi-task distributions. Guided by this theoretical insight, (ii) we frame model merging as multi-teacher knowledge distillation on scarce, unlabeled data. We formally demonstrate that minimizing the student-teacher Kullback-Leibler divergence directly tightens the upper bound on the merged model&rsquo;s excess risk. Guided by the flatness-aware bound derived, (iii) we operationalize this objective via SAMerging, a method that employs Sharpness-Aware Minimization (SAM) to find flat minima. Empirically, SAMerging establishes a new state of the art across vision and NLP benchmarks, achieving remarkable performance. The code is available at https://github.com/arshandalili/SAMerging."><meta property="og:type" content="article"><meta property="og:url" content="https://garyforreal.me/en/posts/paper/paper-2025-12-28-weekly/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-12-28T15:24:24+00:00"><meta property="article:modified_time" content="2025-12-28T15:24:24+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Weekly Paper Notes - 2025-12-28"><meta name=twitter:description content="Weekly Paper Notes
üîç multilingual
Model Merging via Multi-Teacher Knowledge Distillation
Authors: Seyed Arshan Dalili, Mehrdad Mahdavi
Venue: arXiv (2025)
Model merging has emerged as a lightweight alternative to joint multi-task learning (MTL), yet the generalization properties of merged models remain largely unexplored. Establishing such theoretical guarantees is non-trivial, as the merging process typically forbids access to the original training data and involves combining fine-tuned models trained on fundamentally heterogeneous data distributions. Without a principled understanding of these dynamics, current methods often rely on heuristics to approximate the optimal combination of parameters. This dependence is most critical in coefficient scaling, the weighting factors that modulate the magnitude of each fine-tuned model&rsquo;s contribution to the shared parameter. However, without a principled objective to guide their selection, these methods lead to brittle performance and are highly sensitive to scaling initialization. We address this gap by (i) establishing a novel flatness-aware PAC-Bayes generalization bound specifically for the model merging setting. This analysis introduces a &ldquo;cross-task heterogeneity&rdquo; term that formally captures the mismatch between diverse fine-tuned model priors and the target multi-task distributions. Guided by this theoretical insight, (ii) we frame model merging as multi-teacher knowledge distillation on scarce, unlabeled data. We formally demonstrate that minimizing the student-teacher Kullback-Leibler divergence directly tightens the upper bound on the merged model&rsquo;s excess risk. Guided by the flatness-aware bound derived, (iii) we operationalize this objective via SAMerging, a method that employs Sharpness-Aware Minimization (SAM) to find flat minima. Empirically, SAMerging establishes a new state of the art across vision and NLP benchmarks, achieving remarkable performance. The code is available at https://github.com/arshandalili/SAMerging."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://garyforreal.me/en/posts/"},{"@type":"ListItem","position":2,"name":"Paper","item":"https://garyforreal.me/en/posts/paper/"},{"@type":"ListItem","position":3,"name":"Weekly Paper Notes - 2025-12-28","item":"https://garyforreal.me/en/posts/paper/paper-2025-12-28-weekly/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Weekly Paper Notes - 2025-12-28","name":"Weekly Paper Notes - 2025-12-28","description":"Weekly Paper Notes üîç multilingual Model Merging via Multi-Teacher Knowledge Distillation Authors: Seyed Arshan Dalili, Mehrdad Mahdavi Venue: arXiv (2025)\nModel merging has emerged as a lightweight alternative to joint multi-task learning (MTL), yet the generalization properties of merged models remain largely unexplored. Establishing such theoretical guarantees is non-trivial, as the merging process typically forbids access to the original training data and involves combining fine-tuned models trained on fundamentally heterogeneous data distributions. Without a principled understanding of these dynamics, current methods often rely on heuristics to approximate the optimal combination of parameters. This dependence is most critical in coefficient scaling, the weighting factors that modulate the magnitude of each fine-tuned model\u0026rsquo;s contribution to the shared parameter. However, without a principled objective to guide their selection, these methods lead to brittle performance and are highly sensitive to scaling initialization. We address this gap by (i) establishing a novel flatness-aware PAC-Bayes generalization bound specifically for the model merging setting. This analysis introduces a \u0026ldquo;cross-task heterogeneity\u0026rdquo; term that formally captures the mismatch between diverse fine-tuned model priors and the target multi-task distributions. Guided by this theoretical insight, (ii) we frame model merging as multi-teacher knowledge distillation on scarce, unlabeled data. We formally demonstrate that minimizing the student-teacher Kullback-Leibler divergence directly tightens the upper bound on the merged model\u0026rsquo;s excess risk. Guided by the flatness-aware bound derived, (iii) we operationalize this objective via SAMerging, a method that employs Sharpness-Aware Minimization (SAM) to find flat minima. Empirically, SAMerging establishes a new state of the art across vision and NLP benchmarks, achieving remarkable performance. The code is available at https://github.com/arshandalili/SAMerging.\n","keywords":[],"articleBody":"Weekly Paper Notes üîç multilingual Model Merging via Multi-Teacher Knowledge Distillation Authors: Seyed Arshan Dalili, Mehrdad Mahdavi Venue: arXiv (2025)\nModel merging has emerged as a lightweight alternative to joint multi-task learning (MTL), yet the generalization properties of merged models remain largely unexplored. Establishing such theoretical guarantees is non-trivial, as the merging process typically forbids access to the original training data and involves combining fine-tuned models trained on fundamentally heterogeneous data distributions. Without a principled understanding of these dynamics, current methods often rely on heuristics to approximate the optimal combination of parameters. This dependence is most critical in coefficient scaling, the weighting factors that modulate the magnitude of each fine-tuned model‚Äôs contribution to the shared parameter. However, without a principled objective to guide their selection, these methods lead to brittle performance and are highly sensitive to scaling initialization. We address this gap by (i) establishing a novel flatness-aware PAC-Bayes generalization bound specifically for the model merging setting. This analysis introduces a ‚Äúcross-task heterogeneity‚Äù term that formally captures the mismatch between diverse fine-tuned model priors and the target multi-task distributions. Guided by this theoretical insight, (ii) we frame model merging as multi-teacher knowledge distillation on scarce, unlabeled data. We formally demonstrate that minimizing the student-teacher Kullback-Leibler divergence directly tightens the upper bound on the merged model‚Äôs excess risk. Guided by the flatness-aware bound derived, (iii) we operationalize this objective via SAMerging, a method that employs Sharpness-Aware Minimization (SAM) to find flat minima. Empirically, SAMerging establishes a new state of the art across vision and NLP benchmarks, achieving remarkable performance. The code is available at https://github.com/arshandalili/SAMerging.\nüìÑ Download PDF\nLearning from Next-Frame Prediction: Autoregressive Video Modeling Encodes Effective Representations Authors: Jinghan Li, Yang Jin, Hao Jiang, Yadong Mu, Yang Song, Kun Xu Venue: arXiv (2025)\nRecent advances in pretraining general foundation models have significantly improved performance across diverse downstream tasks. While autoregressive (AR) generative models like GPT have revolutionized NLP, most visual generative pretraining methods still rely on BERT-style masked modeling, which often disregards the temporal information essential for video analysis. The few existing autoregressive visual pretraining methods suffer from issues such as inaccurate semantic localization and poor generation quality, leading to poor semantics. In this work, we propose NExT-Vid, a novel autoregressive visual generative pretraining framework that utilizes masked next-frame prediction to jointly model images and videos. NExT-Vid introduces a context-isolated autoregressive predictor to decouple semantic representation from target decoding, and a conditioned flow-matching decoder to enhance generation quality and diversity. Through context-isolated flow-matching pretraining, our approach achieves strong representations. Extensive experiments on large-scale pretrained models demonstrate that our proposed method consistently outperforms previous generative pretraining methods for visual representation learning via attentive probing in downstream classification.\nüìÑ Download PDF\nMultiMind at SemEval-2025 Task 7: Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment Authors: Mohammad Mahdi Abootorabi, Alireza Ghahramani Kure, Mohammadali Mohammadkhani, Sina Elahimanesh, Mohammad Ali Ali Panah Venue: arXiv (2025)\nThis paper presents our system for SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval. In an era where misinformation spreads rapidly, effective fact-checking is increasingly critical. We introduce TriAligner, a novel approach that leverages a dual-encoder architecture with contrastive learning and incorporates both native and English translations across different modalities. Our method effectively retrieves claims across multiple languages by learning the relative importance of different sources in alignment. To enhance robustness, we employ efficient data preprocessing and augmentation using large language models while incorporating hard negative sampling to improve representation learning. We evaluate our approach on monolingual and crosslingual benchmarks, demonstrating significant improvements in retrieval accuracy and fact-checking performance over baselines.\nüìÑ Download PDF\nSweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization Authors: Revanth Gangi Reddy, Ye Liu, Wenting Zhao, JaeHyeok Doo, Tarun Suresh, Daniel Lee, Caiming Xiong, Yingbo Zhou, Semih Yavuz, Shafiq Joty Venue: arXiv (2025)\nMaintaining large-scale, multilingual codebases hinges on accurately localizing issues, which requires mapping natural-language error descriptions to the relevant functions that need to be modified. However, existing ranking approaches are often Python-centric and perform a single-pass search over the codebase. This work introduces SweRank+, a framework that couples SweRankMulti, a cross-lingual code ranking tool, with SweRankAgent, an agentic search setup, for iterative, multi-turn reasoning over the code repository. SweRankMulti comprises a code embedding retriever and a listwise LLM reranker, and is trained using a carefully curated large-scale issue localization dataset spanning multiple popular programming languages. SweRankAgent adopts an agentic search loop that moves beyond single-shot localization with a memory buffer to reason and accumulate relevant localization candidates over multiple turns. Our experiments on issue localization benchmarks spanning various languages demonstrate new state-of-the-art performance with SweRankMulti, while SweRankAgent further improves localization over single-pass ranking.\nüìÑ Download PDF\nLinking Faces and Voices Across Languages: Insights from the FAME 2026 Challenge Authors: Marta Moscati, Ahmed Abdullah, Muhammad Saad Saeed, Shah Nawaz, Rohan Kumar Das, Muhammad Zaigham Zaheer, Junaid Mir, Muhammad Haroon Yousaf, Khalid Mahmood Malik, Markus Schedl Venue: arXiv (2025)\nOver half of the world‚Äôs population is bilingual and people often communicate under multilingual scenarios. The Face-Voice Association in Multilingual Environments (FAME) 2026 Challenge, held at ICASSP 2026, focuses on developing methods for face-voice association that are effective when the language at test-time is different than the training one. This report provides a brief summary of the challenge.\nüìÑ Download PDF\nCan LLMs Solve My Grandma‚Äôs Riddle? Evaluating Multilingual Large Language Models on Reasoning Traditional Bangla Tricky Riddles Authors: Nurul Labib Sayeedi, Md. Faiyaz Abdullah Sayeedi, Khushnur Binte Jahangir, Swakkhar Shatabda, Sarah Masud Preum Venue: arXiv (2025)\nLarge Language Models (LLMs) show impressive performance on many NLP benchmarks, yet their ability to reason in figurative, culturally grounded, and low-resource settings remains underexplored. We address this gap for Bangla by introducing BanglaRiddleEval, a benchmark of 1,244 traditional Bangla riddles instantiated across four tasks (4,976 riddle-task artifacts in total). Using an LLM-based pipeline, we generate Chain-of-Thought explanations, semantically coherent distractors, and fine-grained ambiguity annotations, and evaluate a diverse suite of open-source and closed-source models under different prompting strategies. Models achieve moderate semantic overlap on generative QA but low correctness, MCQ accuracy peaks at only about 56% versus an 83% human baseline, and ambiguity resolution ranges from roughly 26% to 68%, with high-quality explanations confined to the strongest models. These results show that current LLMs capture some cues needed for Bangla riddle reasoning but remain far from human-level performance, establishing BanglaRiddleEval as a challenging new benchmark for low-resource figurative reasoning. All data, code, and evaluation scripts are available on GitHub: https://github.com/Labib1610/BanglaRiddleEval.\nüìÑ Download PDF\nFoundation Model-based Evaluation of Neuropsychiatric Disorders: A Lifespan-Inclusive, Multi-Modal, and Multi-Lingual Study Authors: Zhongren Dong, Haotian Guo, Weixiang Xu, Huan Zhao, Zixing Zhang Venue: arXiv (2025)\nNeuropsychiatric disorders, such as Alzheimer‚Äôs disease (AD), depression, and autism spectrum disorder (ASD), are characterized by linguistic and acoustic abnormalities, offering potential biomarkers for early detection. Despite the promise of multi-modal approaches, challenges like multi-lingual generalization and the absence of a unified evaluation framework persist. To address these gaps, we propose FEND (Foundation model-based Evaluation of Neuropsychiatric Disorders), a comprehensive multi-modal framework integrating speech and text modalities for detecting AD, depression, and ASD across the lifespan. Leveraging 13 multi-lingual datasets spanning English, Chinese, Greek, French, and Dutch, we systematically evaluate multi-modal fusion performance. Our results show that multi-modal fusion excels in AD and depression detection but underperforms in ASD due to dataset heterogeneity. We also identify modality imbalance as a prevalent issue, where multi-modal fusion fails to surpass the best mono-modal models. Cross-corpus experiments reveal robust performance in task- and language-consistent scenarios but noticeable degradation in multi-lingual and task-heterogeneous settings. By providing extensive benchmarks and a detailed analysis of performance-influencing factors, FEND advances the field of automated, lifespan-inclusive, and multi-lingual neuropsychiatric disorder assessment. We encourage researchers to adopt the FEND framework for fair comparisons and reproducible research.\nüìÑ Download PDF\nCorpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings Authors: Marko ƒåechoviƒç, Nat√°lia Komorn√≠kov√°, Dominik Mach√°ƒçek, Ond≈ôej Bojar Venue: arXiv (2025)\nSpeech processing and translation technology have the potential to facilitate meetings of individuals who do not share any common language. To evaluate automatic systems for such a task, a versatile and realistic evaluation corpus is needed. Therefore, we create and present a corpus of cross-lingual dialogues between individuals without a common language who were facilitated by automatic simultaneous speech translation. The corpus consists of 5 hours of speech recordings with ASR and gold transcripts in 12 original languages and automatic and corrected translations into English. For the purposes of research into cross-lingual summarization, our corpus also includes written summaries (minutes) of the meetings. Moreover, we propose automatic detection of misunderstandings. For an overview of this task and its complexity, we attempt to quantify misunderstandings in cross-lingual meetings. We annotate misunderstandings manually and also test the ability of current large language models to detect them automatically. The results show that the Gemini model is able to identify text spans with misunderstandings with recall of 77% and precision of 47%.\nüìÑ Download PDF\nMauBERT: Universal Phonetic Inductive Biases for Few-Shot Acoustic Units Discovery Authors: Angelo Ortiz Tandazo, Manel Khentout, Youssef Benchekroun, Thomas Hueber, Emmanuel Dupoux Venue: arXiv (2025)\nThis paper introduces MauBERT, a multilingual extension of HuBERT that leverages articulatory features for robust cross-lingual phonetic representation learning. We continue HuBERT pre-training with supervision based on a phonetic-to-articulatory feature mapping in 55 languages. Our models learn from multilingual data to predict articulatory features or phones, resulting in language-independent representations that capture multilingual phonetic properties. Through comprehensive ABX discriminability testing, we show MauBERT models produce more context-invariant representations than state-of-the-art multilingual self-supervised learning models. Additionally, the models effectively adapt to unseen languages and casual speech with minimal self-supervised fine-tuning (10 hours of speech). This establishes an effective approach for instilling linguistic inductive biases in self-supervised speech models.\nüìÑ Download PDF\nEvent Extraction in Large Language Model Authors: Bobo Li, Xudong Han, Jiang Liu, Yuzhe Ding, Liqiang Jing, Zhaoqi Zhang, Jinheng Li, Xinya Du, Fei Li, Meishan Zhang, Min Zhang, Aixin Sun, Philip S. Yu, Hao Fei Venue: arXiv (2025)\nLarge language models (LLMs) and multimodal LLMs are changing event extraction (EE): prompting and generation can often produce structured outputs in zero shot or few shot settings. Yet LLM based pipelines face deployment gaps, including hallucinations under weak constraints, fragile temporal and causal linking over long contexts and across documents, and limited long horizon knowledge management within a bounded context window. We argue that EE should be viewed as a system component that provides a cognitive scaffold for LLM centered solutions. Event schemas and slot constraints create interfaces for grounding and verification; event centric structures act as controlled intermediate representations for stepwise reasoning; event links support relation aware retrieval with graph based RAG; and event stores offer updatable episodic and agent memory beyond the context window. This survey covers EE in text and multimodal settings, organizing tasks and taxonomy, tracing method evolution from rule based and neural models to instruction driven and generative frameworks, and summarizing formulations, decoding strategies, architectures, representations, datasets, and evaluation. We also review cross lingual, low resource, and domain specific settings, and highlight open challenges and future directions for reliable event centric systems. Finally, we outline open challenges and future directions that are central to the LLM era, aiming to evolve EE from static extraction into a structurally reliable, agent ready perception and memory layer for open world systems.\nüìÑ Download PDF\nOmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation Authors: Xueming Yan, Boyan Xu, Yaochu Jin, Lixian Xiao, Wenlong Ye, Runyang Cai, Zeqi Zheng, Jingfa Liu, Aimin Yang Venue: arXiv (2025)\nIndonesian, spoken by over 200 million people, remains underserved in multimodal emotion recognition research despite its dominant presence on Southeast Asian social media platforms. We introduce IndoMER, the first multimodal emotion recognition benchmark for Indonesian, comprising 1,944 video segments from 203 speakers with temporally aligned text, audio, and visual annotations across seven emotion categories. The dataset exhibits realistic challenges including cross-modal inconsistency and long-tailed class distributions shaped by Indonesian cultural communication norms. To address these challenges, we propose OmniMER, a multimodal adaptation framework built upon Qwen2.5-Omni that enhances emotion recognition through three auxiliary modality-specific perception tasks: emotion keyword extraction for text, facial expression analysis for video, and prosody analysis for audio. These auxiliary tasks help the model identify emotion-relevant cues in each modality before fusion, reducing reliance on spurious correlations in low-resource settings. Experiments on IndoMER show that OmniMER achieves 0.582 Macro-F1 on sentiment classification and 0.454 on emotion recognition, outperforming the base model by 7.6 and 22.1 absolute points respectively. Cross-lingual evaluation on the Chinese CH-SIMS dataset further demonstrates the generalizability of the proposed framework. The dataset and code are publicly available. https://github.com/yanxm01/INDOMER\nüìÑ Download PDF\nQuantitative Financial Modeling for Sri Lankan Markets: Approach Combining NLP, Clustering and Time-Series Forecasting Authors: Linuk Perera Venue: arXiv (2025)\nThis research introduces a novel quantitative methodology tailored for quantitative finance applications, enabling banks, stockbrokers, and investors to predict economic regimes and market signals in emerging markets, specifically Sri Lankan stock indices (S\u0026P SL20 and ASPI) by integrating Environmental, Social, and Governance (ESG) sentiment analysis with macroeconomic indicators and advanced time-series forecasting. Designed to leverage quantitative techniques for enhanced risk assessment, portfolio optimization, and trading strategies in volatile environments, the architecture employs FinBERT, a transformer-based NLP model, to extract sentiment from ESG texts, followed by unsupervised clustering (UMAP/HDBSCAN) to identify 5 latent ESG regimes, validated via PCA. These regimes are mapped to economic conditions using a dense neural network and gradient boosting classifier, achieving 84.04% training and 82.0% validation accuracy. Concurrently, time-series models (SRNN, MLP, LSTM, GRU) forecast daily closing prices, with GRU attaining an R-squared of 0.801 and LSTM delivering 52.78% directional accuracy on intraday data. A strong correlation between S\u0026P SL20 and S\u0026P 500, observed through moving average and volatility trend plots, further bolsters forecasting precision. A rule-based fusion logic merges ESG and time-series outputs for final market signals. By addressing literature gaps that overlook emerging markets and holistic integration, this quant-driven framework combines global correlations and local sentiment analysis to offer scalable, accurate tools for quantitative finance professionals navigating complex markets like Sri Lanka.\nüìÑ Download PDF\nNeuron-Guided Interpretation of Code LLMs: Where, Why, and How? Authors: Zhe Yin, Xiaodong Gu, Beijun Shen Venue: arXiv (2025)\nCode language models excel on code intelligence tasks, yet their internal interpretability is underexplored. Existing neuron interpretability techniques from NLP are suboptimal for source code due to programming languages formal, hierarchical, and executable nature. We empirically investigate code LLMs at the neuron level, localizing language-specific neurons (selectively responsive to one language) and concept layers (feed-forward layers encoding language-agnostic code representations). We analyze Llama-3.1-8B and Qwen2.5-Coder-32B on multilingual inputs in C++, Java, Python, Go, and JavaScript, measuring neuron selectivity and layerwise contributions during generation. We find (1) neurons specialized for individual languages alongside a universal subset supporting general-purpose generation; and (2) lower layers mainly encode language-specific syntax, while middle layers capture semantic abstractions shared across languages, emerging as concept layers. We demonstrate utility on three tasks: neuron-guided fine-tuning for code generation, clone detection via concept-layer embeddings, and concept-layer-guided transfer for code summarization, each yielding consistent gains in multilingual settings.\nüìÑ Download PDF\nA High-Dimensional Quantum Blockchain Protocol Based on Time- Entanglement Authors: Akta≈ü, Arzu, Yƒ±lmaz, ƒ∞hsan Venue: arXiv (2025)\nRapid advancements in quantum computing and machine learning threaten the long-term security of classical blockchain systems, whose protection mechanisms largely rely on computational difficulties. In this study, we propose a quantum blockchain protocol whose protection mechanism is directly derived from quantum mechanical principles. The protocol combines high-dimensional Bell states, time-entanglement, entanglement switching, and high-dimensional superdense coding. Encoding classical block information into time-delimited qudit states allows block identity and data verification to be implemented through the causal sequencing of quantum measurements instead of cryptographic hash functions. High-dimensional coding increases the information capacity per quantum carrier and improves noise resistance. Time-entanglement provides distributed authentication, non-repudiation, and tamper detection across the blockchain. Each block derives its own public-private key pair directly from the observed quantum correlations by performing high-dimensional Bell state measurements in successive time steps. Because these keys are dependent on the time ordering of measurements, attempts to alter block data or disrupt the protocol‚Äôs timing structure inevitably affect the reconstructed correlations and are revealed during validation. Recent advances in the creation and detection of high-dimensional time-slice entanglement demonstrate that the necessary quantum resources are compatible with emerging quantum communication platforms. Taken together, these considerations suggest that the proposed framework can be evaluated as a viable and scalable candidate for quantum-secure blockchain architectures in future quantum network environments.\nüìÑ Download PDF\nScalable Relay Switching Platform for Automated Multi-Point Resistance Measurements Authors: Edoardo Boretti, Kostiantyn Torokhtii, Enrico Silva, Andrea Alimenti Venue: arXiv (2025)\nIn both research and industrial settings, it is often necessary to expand the input/output channels of measurement instruments using relay-based multiplexer boards. In research activities in particular, the need for a highly flexible and easily configurable solution frequently leads to the development of customized systems. To address this challenge, we developed a system optimized for automated direct current (DC) measurements. The result is based on a 4x4 switching platform that simplifies measurement procedures that require instrument routing. The platform is based on a custom-designed circuit board controlled by a microcontroller. We selected bistable relays to guarantee contact stability after switching. We finally developed a system architecture that allows for straightforward expansion and scalability by connecting multiple platforms. We share both the hardware design source files and the firmware source code on GitHub with the open-source community. This work presents the design and development of the proposed system, followed by the performance evaluation. Finally, we present a test of our designed system applied to a specific case study: the DC analysis of complex resistive networks through multi-point resistance measurements using only a single voltmeter and current source.\nüìÑ Download PDF\nKunnafonidilaw ka Cadeau: an ASR dataset of present-day Bambara Authors: Yacouba Diarra, Panga Azazia Kamate, Nouhoum Souleymane Coulibaly, Michael Leventhal Venue: arXiv (2025)\nWe present Kunkado, a 160-hour Bambara ASR dataset compiled from Malian radio archives to capture present-day spontaneous speech across a wide range of topics. It includes code-switching, disfluencies, background noise, and overlapping speakers that practical ASR systems encounter in real-world use. We finetuned Parakeet-based models on a 33.47-hour human-reviewed subset and apply pragmatic transcript normalization to reduce variability in number formatting, tags, and code-switching annotations. Evaluated on two real-world test sets, finetuning with Kunkado reduces WER from 44.47% to 37.12% on one and from 36.07% to 32.33% on the other. In human evaluation, the resulting model also outperforms a comparable system with the same architecture trained on 98 hours of cleaner, less realistic speech. We release the data and models to support robust ASR for predominantly oral languages.\nüìÑ Download PDF\nMilton Friedman‚Äôs spending matrix revisited: ‚ÄòSpending efficiency‚Äô and ‚Äòpreference compatibility‚Äô across different economic systems Authors: Ali Zeytoon-Nejad Venue: arXiv (2025)\nThis article expands Milton Friedman‚Äôs spending matrix to analyse ‚Äòspending efficiency‚Äô and ‚Äòpreference compatibility‚Äô across different economic systems against five key outcome criteria. By generalising Friedman‚Äôs typology, it compares efficiency and freedom as systems shift from laissez-faire capitalism to communism, illustrating a gradual deterioration in their key outcomes. While government intervention is sometimes necessary to address market failures, its role should always be carefully limited to avoid inefficiency and misalignment with individual preferences. The insights may provide guidance for policymakers in designing economic systems and policies that promote both economic prosperity and personal liberty.\nüìÑ Download PDF\nBeyond Memorization: A Multi-Modal Ordinal Regression Benchmark to Expose Popularity Bias in Vision-Language Models Authors: Li-Zhong Szu-Tu, Ting-Lin Wu, Chia-Jui Chang, He Syu, Yu-Lun Liu Venue: arXiv (2025)\nWe expose a significant popularity bias in state-of-the-art vision-language models (VLMs), which achieve up to 34% higher accuracy on famous buildings compared to ordinary ones, indicating a reliance on memorization over generalizable understanding. To systematically investigate this, we introduce the largest open benchmark for this task: the YearGuessr dataset, a collection of 55,546 building images with multi-modal attributes from 157 countries, annotated with continuous ordinal labels of their construction year (1001-2024), GPS data, and page-view counts as a proxy for popularity. Using this dataset, we frame the construction year prediction task as ordinal regression and introduce popularity-aware interval accuracy metrics to quantify this bias. Our resulting benchmark of 30+ models, including our YearCLIP model, confirms that VLMs excel on popular, memorized items but struggle significantly with unrecognized subjects, exposing a critical flaw in their reasoning capabilities. Project page: https://sytwu.github.io/BeyondMemo/\nüìÑ Download PDF\nOptimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty Authors: Ziyu Chen, Xinbei Jiang, Peng Sun, Tao Lin Venue: arXiv (2025)\nMasked Diffusion Models (MDMs) offer flexible, non-autoregressive generation, but this freedom introduces a challenge: final output quality is highly sensitive to the decoding order. We are the first to formalize this issue, attributing the variability in output quality to the cumulative predictive uncertainty along a generative path. To quantify this uncertainty, we introduce Denoising Entropy, a computable metric that serves as an internal signal for evaluating generative process. Leveraging this metric, we propose two algorithms designed to optimize the decoding path: a post-hoc selection method and a real-time guidance strategy. Experiments demonstrate that our entropy-guided methods significantly improve generation quality, consistently boosting accuracy on challenging reasoning, planning, and code benchmarks. Our work establishes Denoising Entropy as a principled tool for understanding and controlling generation, effectively turning the uncertainty in MDMs from a liability into a key advantage for discovering high-quality solutions.\nüìÑ Download PDF\nC2LLM Technical Report: A New Frontier in Code Retrieval via Adaptive Cross-Attention Pooling Authors: Jin Qin, Zihan Liao, Ziyin Zhang, Hang Yu, Peng Di, Rui Wang Venue: arXiv (2025)\nWe present C2LLM - Contrastive Code Large Language Models, a family of code embedding models in both 0.5B and 7B sizes. Building upon Qwen-2.5-Coder backbones, C2LLM adopts a Pooling by Multihead Attention (PMA) module for generating sequence embedding from token embeddings, effectively 1) utilizing the LLM‚Äôs causal representations acquired during pretraining, while also 2) being able to aggregate information from all tokens in the sequence, breaking the information bottleneck in EOS-based sequence embeddings, and 3) supporting flexible adaptation of embedding dimension, serving as an alternative to MRL. Trained on three million publicly available data, C2LLM models set new records on MTEB-Code among models of similar sizes, with C2LLM-7B ranking 1st on the overall leaderboard.\nüìÑ Download PDF\nYour Reasoning Benchmark May Not Test Reasoning: Revealing Perception Bottleneck in Abstract Reasoning Benchmarks Authors: Xinhe Wang, Jin Huang, Xingjian Zhang, Tianhao Wang, Jiaqi W. Ma Venue: arXiv (2025)\nReasoning benchmarks such as the Abstraction and Reasoning Corpus (ARC) and ARC-AGI are widely used to assess progress in artificial intelligence and are often interpreted as probes of core, so-called ``fluid‚Äô‚Äô reasoning abilities. Despite their apparent simplicity for humans, these tasks remain challenging for frontier vision-language models (VLMs), a gap commonly attributed to deficiencies in machine reasoning. We challenge this interpretation and hypothesize that the gap arises primarily from limitations in visual perception rather than from shortcomings in inductive reasoning. To verify this hypothesis, we introduce a two-stage experimental pipeline that explicitly separates perception and reasoning. In the perception stage, each image is independently converted into a natural-language description, while in the reasoning stage a model induces and applies rules using these descriptions. This design prevents leakage of cross-image inductive signals and isolates reasoning from perception bottlenecks. Across three ARC-style datasets, Mini-ARC, ACRE, and Bongard-LOGO, we show that the perception capability is the dominant factor underlying the observed performance gap by comparing the two-stage pipeline with against standard end-to-end one-stage evaluation. Manual inspection of reasoning traces in the VLM outputs further reveals that approximately 80 percent of model failures stem from perception errors. Together, these results demonstrate that ARC-style benchmarks conflate perceptual and reasoning challenges and that observed performance gaps may overstate deficiencies in machine reasoning. Our findings underscore the need for evaluation protocols that disentangle perception from reasoning when assessing progress in machine intelligence.\nüìÑ Download PDF\nMeasuring all the noises of LLM Evals Authors: Sida Wang Venue: arXiv (2025)\nSeparating signal from noise is central to experimental science. Applying well-established statistical method effectively to LLM evals requires consideration of their unique noise characteristics. We clearly define and measure three types of noise: prediction noise from generating different answers on a given question, data noise from sampling questions, and their combined total noise following the law of total variance. To emphasize relative comparisons and gain statistical power, we propose the all-pairs paired method, which applies the paired analysis to all pairs of LLMs and measures all the noise components based on millions of question-level predictions across many evals and settings. These measurements revealed clear patterns. First, each eval exhibits a characteristic and highly predictable total noise level across all model pairs. Second, paired prediction noise typically exceeds paired data noise, which means reducing prediction noise by averaging can significantly increase statistical power. These findings enable practitioners to assess significance without custom testing and to detect much smaller effects in controlled experiments.\nüìÑ Download PDF\nParallel Token Prediction for Language Models Authors: Felix Draxler, Justus Will, Farrin Marouf Sofian, Theofanis Karaletsos, Sameer Singh, Stephan Mandt Venue: arXiv (2025)\nWe propose Parallel Token Prediction (PTP), a universal framework for parallel sequence generation in language models. PTP jointly predicts multiple dependent tokens in a single transformer call by incorporating the sampling procedure into the model. This reduces the latency bottleneck of autoregressive decoding, and avoids the restrictive independence assumptions common in existing multi-token prediction methods. We prove that PTP can represent arbitrary autoregressive sequence distributions. PTP is trained either by distilling an existing model or through inverse autoregressive training without a teacher. Experimentally, we achieve state-of-the-art speculative decoding performance on Vicuna-7B by accepting over four tokens per step on Spec-Bench. The universality of our framework indicates that parallel generation of long sequences is feasible without loss of modeling power.\nüìÑ Download PDF\nAutonomous Uncertainty Quantification for Computational Point-of-care Sensors Authors: Artem Goncharov, Rajesh Ghosh, Hyou-Arm Joung, Dino Di Carlo, Aydogan Ozcan Venue: arXiv (2025)\nComputational point-of-care (POC) sensors enable rapid, low-cost, and accessible diagnostics in emergency, remote and resource-limited areas that lack access to centralized medical facilities. These systems can utilize neural network-based algorithms to accurately infer a diagnosis from the signals generated by rapid diagnostic tests or sensors. However, neural network-based diagnostic models are subject to hallucinations and can produce erroneous predictions, posing a risk of misdiagnosis and inaccurate clinical decisions. To address this challenge, here we present an autonomous uncertainty quantification technique developed for POC diagnostics. As our testbed, we used a paper-based, computational vertical flow assay (xVFA) platform developed for rapid POC diagnosis of Lyme disease, the most prevalent tick-borne disease globally. The xVFA platform integrates a disposable paper-based assay, a handheld optical reader and a neural network-based inference algorithm, providing rapid and cost-effective Lyme disease diagnostics in under 20 min using only 20 uL of patient serum. By incorporating a Monte Carlo dropout (MCDO)-based uncertainty quantification approach into the diagnostics pipeline, we identified and excluded erroneous predictions with high uncertainty, significantly improving the sensitivity and reliability of the xVFA in an autonomous manner, without access to the ground truth diagnostic information of patients. Blinded testing using new patient samples demonstrated an increase in diagnostic sensitivity from 88.2% to 95.7%, indicating the effectiveness of MCDO-based uncertainty quantification in enhancing the robustness of neural network-driven computational POC sensing systems.\nüìÑ Download PDF\nCoherently Assisted Wireless Power Transfer Through Poorly Transparent Barriers Authors: Alex Krasnok Venue: arXiv (2025)\nPoorly transparent barriers (e.g., reinforced walls, shielding panels, metallic or high-contrast dielectrics) strongly reflect incident radiation, limiting wireless power transfer (WPT) unless the barrier is structurally modified to support a narrowband transparency window. Here we introduce a barrier-agnostic alternative based on coherent scattering control: a phase-locked auxiliary wave is launched from the receiver side with an amplitude and phase chosen from the measured complex scattering parameters of the barrier. In a two-port (single-channel-per-side) description, we derive closed-form conditions for (i) canceling back-reflection toward the transmitter and (ii) maximizing the net extracted power at the receiver side. In the lossless limit these conditions imply unit transmitter-to-receiver efficiency (all transmitter power is routed to the receiver side) even when the barrier is nearly opaque under one-sided illumination. We validate the concept using (1) an analytically solvable high-index Fabry‚ÄìP√©rot slab and (2) a numerically simulated perforated PEC metasurface exhibiting vanishing one-sided transmission; in both cases, coherent assistance yields near-unity transmission and large enhancement factors. We further analyze dissipative barriers using a receiver-side energy-balance metric, showing that substantial net delivery can persist well into the lossy regime. The approach is closely related to coherent perfect absorption and time-reversal ideas in wave physics, but targets \\emph{reflectionless delivery through barriers} without modifying the obstacle itself.\nüìÑ Download PDF\nCoTDeceptor:Adversarial Code Obfuscation Against CoT-Enhanced LLM Code Agents Authors: Haoyang Li, Mingjin Li, Jinxin Zuo, Siqi Li, Xiao Li, Hao Wu, Yueming Lu, Xiaochuan He Venue: arXiv (2025)\nLLM-based code agents(e.g., ChatGPT Codex) are increasingly deployed as detector for code review and security auditing tasks. Although CoT-enhanced LLM vulnerability detectors are believed to provide improved robustness against obfuscated malicious code, we find that their reasoning chains and semantic abstraction processes exhibit exploitable systematic weaknesses.This allows attackers to covertly embed malicious logic, bypass code review, and propagate backdoored components throughout real-world software supply chains.To investigate this issue, we present CoTDeceptor, the first adversarial code obfuscation framework targeting CoT-enhanced LLM detectors. CoTDeceptor autonomously constructs evolving, hard-to-reverse multi-stage obfuscation strategy chains that effectively disrupt CoT-driven detection logic.We obtained malicious code provided by security enterprise, experimental results demonstrate that CoTDeceptor achieves stable and transferable evasion performance against state-of-the-art LLMs and vulnerability detection agents. CoTDeceptor bypasses 14 out of 15 vulnerability categories, compared to only 2 bypassed by prior methods. Our findings highlight potential risks in real-world software supply chains and underscore the need for more robust and interpretable LLM-powered security analysis systems.\nüìÑ Download PDF\nUniTacHand: Unified Spatio-Tactile Representation for Human to Robotic Hand Skill Transfer Authors: Chi Zhang, Penglin Cai, Haoqi Yuan, Chaoyi Xu, Zongqing Lu Venue: arXiv (2025)\nTactile sensing is crucial for robotic hands to achieve human-level dexterous manipulation, especially in scenarios with visual occlusion. However, its application is often hindered by the difficulty of collecting large-scale real-world robotic tactile data. In this study, we propose to collect low-cost human manipulation data using haptic gloves for tactile-based robotic policy learning. The misalignment between human and robotic tactile data makes it challenging to transfer policies learned from human data to robots. To bridge this gap, we propose UniTacHand, a unified representation to align robotic tactile information captured by dexterous hands with human hand touch obtained from gloves. First, we project tactile signals from both human hands and robotic hands onto a morphologically consistent 2D surface space of the MANO hand model. This unification standardizes the heterogeneous data structures and inherently embeds the tactile signals with spatial context. Then, we introduce a contrastive learning method to align them into a unified latent space, trained on only 10 minutes of paired data from our data collection system. Our approach enables zero-shot tactile-based policy transfer from humans to a real robot, generalizing to objects unseen in the pre-training data. We also demonstrate that co-training on mixed data, including both human and robotic demonstrations via UniTacHand, yields better performance and data efficiency compared with using only robotic data. UniTacHand paves a path toward general, scalable, and data-efficient learning for tactile-based dexterous hands.\nüìÑ Download PDF\nA Multimodal Human-Centered Framework for Assessing Pedestrian Well-Being in the Wild Authors: Yasaman Hakiminejad, Arash Tavakoli Venue: arXiv (2025)\nPedestrian well-being is a critical yet rarely measured component of sustainable urban mobility and livable city design. Existing approaches to evaluating pedestrian environments often rely on static, infrastructure-based indices or retrospective surveys, which overlook the dynamic, subjective, and psychophysiological dimensions of everyday walking experience. This paper introduces a multimodal, human-centered framework for assessing pedestrian well-being in the wild by integrating three complementary data streams: continuous physiological sensing, geospatial tracking, and momentary self-reports collected using the Experience Sampling Method. The framework conceptualizes pedestrian experience as a triangulation enabling a holistic understanding of how urban environments influence well-being. The utility of our framework is then demonstrated through a naturalistic case study conducted in the Greater Philadelphia region, in which participants wore research-grade wearable sensors and carried GPS-enabled smartphones during their regular daily activities. Physiological indicators of autonomic nervous system activity, including heart rate variability and electrodermal activity, were synchronized with spatial trajectories and in situ self-reports of stress, affect, and perceived infrastructure conditions. Results illustrate substantial inter- and intra-individual variability in both subjective experience and physiological response, as well as context-dependent patterns associated with traffic exposure, pedestrian infrastructure quality, and environmental enclosure. The findings also suggest that commonly used walkability indices may not fully capture experiential dimensions of pedestrian well-being. By enabling real-world, multimodal measurement of pedestrian experience, the proposed framework offers a scalable and transferable approach for advancing human-centered urban analytics.\nüìÑ Download PDF\nThe disc instability model: original recipe and additional ingredients Authors: Jean-Marie Hameury Venue: arXiv (2025)\nThe disc instability model successfully reproduces many of the observed properties of cataclysmic variables. However, additional ingredients such as mass-transfer variations, disc irradiation, stream-disc overflow, or inner-disc truncation must be included to explain certain systems. The physics underlying these processes is often poorly constrained, and our lack of knowledge is typically absorbed into extra free parameters, much like the $Œ±$-prescription for viscosity. In this paper, I examine how each of these ingredients affects the predicted light curves and discuss the limitations that arise from the growing number of unconstrained parameters on the model‚Äôs predictive power.\nüìÑ Download PDF\nA Turn Toward Better Alignment: Few-Shot Generative Adaptation with Equivariant Feature Rotation Authors: Chenghao Xu, Qi Liu, Jiexi Yan, Muli Yang, Cheng Deng Venue: arXiv (2025)\nFew-shot image generation aims to effectively adapt a source generative model to a target domain using very few training images. Most existing approaches introduce consistency constraints-typically through instance-level or distribution-level loss functions-to directly align the distribution patterns of source and target domains within their respective latent spaces. However, these strategies often fall short: overly strict constraints can amplify the negative effects of the domain gap, leading to distorted or uninformative content, while overly relaxed constraints may fail to leverage the source domain effectively. This limitation primarily stems from the inherent discrepancy in the underlying distribution structures of the source and target domains. The scarcity of target samples further compounds this issue by hindering accurate estimation of the target domain‚Äôs distribution. To overcome these limitations, we propose Equivariant Feature Rotation (EFR), a novel adaptation strategy that aligns source and target domains at two complementary levels within a self-rotated proxy feature space. Specifically, we perform adaptive rotations within a parameterized Lie Group to transform both source and target features into an equivariant proxy space, where alignment is conducted. These learnable rotation matrices serve to bridge the domain gap by preserving intra-domain structural information without distortion, while the alignment optimization facilitates effective knowledge transfer from the source to the target domain. Comprehensive experiments on a variety of commonly used datasets demonstrate that our method significantly enhances the generative performance within the targeted domain.\nüìÑ Download PDF\nChannel-last gate-all-around nanosheet oxide semiconductor transistors Authors: Fabia F. Athena, Xiangjin Wu, Nathaniel S. Safron, Amy Siobhan McKeown-Green, Mauro Dossena, Jack C. Evans, Jonathan Hartanto, Yukio Cho, Donglai Zhong, Tara Pe√±a, Pawe≈Ç Czaja, Parivash Moradifar, Paul C. McIntyre, Mathieu Luisier, Yi Cui, Jennifer A. Dionne, Greg Pitner, Iuliana P. Radu, Eric Pop, Alberto Salleo, H. -S. Philip Wong Venue: arXiv (2025)\nAs we move beyond the era of transistor miniaturization, back-end-of-line-compatible transistors that can be stacked monolithically in the third dimension promise improved performance for low-power electronics. In advanced transistor architectures, such as gate-all-around nanosheets, the conventional channel-first process involves depositing dielectrics directly onto the channel. Atomic layer deposition of gate dielectrics on back-end-of-line compatible channel materials, such as amorphous oxide semiconductors, can induce defects or cause structural modifications that degrade electrical performance. While post-deposition annealing can partially repair this damage, it often degrades other device metrics. We report a novel channel-last concept that prevents such damage. Channel-last gate-all-around self-aligned transistors with amorphous oxide-semiconductor channels exhibit high on-state current ($\u003e$ 1 mA/$Œº$m) and low subthreshold swing (minimum of 63 mV/dec) without the need for post-deposition processing. This approach offers a general, scalable pathway for transistors with atomic layer deposited channel materials, enabling the future of low-power three-dimensional electronics.\nüìÑ Download PDF\nTranscriptome-Conditioned Personalized De Novo Drug Generation for AML Using Metaheuristic Assembly and Target-Driven Filtering Authors: Abdullah G. Elafifi, Basma Mamdouh, Mariam Hanafy, Muhammed Alaa Eldin, Yosef Khaled, Nesma Mohamed El-Gelany, Tarek H. M. Abou-El-Enien Venue: arXiv (2025)\nAcute Myeloid Leukemia (AML) remains a clinical challenge due to its extreme molecular heterogeneity and high relapse rates. While precision medicine has introduced mutation-specific therapies, many patients still lack effective, personalized options. This paper presents a novel, end-to-end computational framework that bridges the gap between patient-specific transcriptomics and de novo drug discovery. By analyzing bulk RNA sequencing data from the TCGA-LAML cohort, the study utilized Weighted Gene Co-expression Network Analysis (WGCNA) to prioritize 20 high-value biomarkers, including metabolic transporters like HK3 and immune-modulatory receptors such as SIGLEC9. The physical structures of these targets were modeled using AlphaFold3, and druggable hotspots were quantitatively mapped via the DOGSiteScorer engine. Then developed a novel, reaction-first evolutionary metaheuristic algorithm as well as multi-objective optimization programming that assembles novel ligands from fragment libraries, guided by spatial alignment to these identified hotspots. The generative model produced structurally unique chemical entities with a strong bias toward drug-like space, as evidenced by QED scores peaking between 0.5 and 0.7. Validation through ADMET profiling and SwissDock molecular docking identified high-confidence candidates, such as Ligand L1, which achieved a binding free energy of -6.571 kcal/mol against the A08A96 biomarker. These results demonstrate that integrating systems biology with metaheuristic molecular assembly can produce pharmacologically viable, patient tailored leads, offering a scalable blueprint for precision oncology in AML and beyond\nüìÑ Download PDF\nImpurity peaking of SPARC H-modes: a sensitivity study on physics and engineering assumptions Authors: Marco Muraca, Pablo Rodriguez-Fernandez, Joe Hall, Nathaniel T. Howard, Daniel Fajardo, Giovanni Tardini, Benedikt Zimmermann, Thomas Body Venue: arXiv (2025)\nIn this paper, an overview of the impurity transport for three H-mode plasmas in the upcoming SPARC tokamak has been provided. The simulations have been performed within the ASTRA+STRAHL framework, using FACIT and TGLF-SAT2 to predict, respectively, neoclassical and turbulent core transport, while a neural network trained on EPED simulations has been employed to calculate the pedestal height and width self-consistently. A benchmark with previous simulations at constant impurity fraction has been provided for three H-modes, spanning different plasma current and magnetic field values. For a scenario, additional simulations have been performed to account for uncertainties in the modeling assumptions. The predictions are nearly insensitive to changes in the top of pedestal W concentrations. Varying the Ar pedestal concentration has shown a small effect on the impurity peaking and nearly constant fusion gain values, due to multiple effects on pedestal pressure, main ion dilution and density peaking. The inclusion of rotation in ASTRA simulations has shown minimal impact on confinement and impurity transport predictions. An exploratory study has been provided with a first set of simulations treating D and T separately, experiencing a maximum fusion power at 55-45% DT fuel composition, and an asymmetric distribution with respect to the D concentration. All the results, including sensitivity scans of toroidal velocity and ion temperature and density gradients, highlighted that turbulent impurity transport prevails on the neoclassical component, aligning with previous ITER predictions, and suggesting that next generation devices like SPARC, operating at low collisionality, will experience low W accumulation.\nüìÑ Download PDF\nACD: Direct Conditional Control for Video Diffusion Models via Attention Supervision Authors: Weiqi Li, Zehao Zhang, Liang Lin, Guangrun Wang Venue: arXiv (2025)\nControllability is a fundamental requirement in video synthesis, where accurate alignment with conditioning signals is essential. Existing classifier-free guidance methods typically achieve conditioning indirectly by modeling the joint distribution of data and conditions, which often results in limited controllability over the specified conditions. Classifier-based guidance enforces conditions through an external classifier, but the model may exploit this mechanism to raise the classifier score without genuinely satisfying the intended condition, resulting in adversarial artifacts and limited effective controllability. In this paper, we propose Attention-Conditional Diffusion (ACD), a novel framework for direct conditional control in video diffusion models via attention supervision. By aligning the model‚Äôs attention maps with external control signals, ACD achieves better controllability. To support this, we introduce a sparse 3D-aware object layout as an efficient conditioning signal, along with a dedicated Layout ControlNet and an automated annotation pipeline for scalable layout integration. Extensive experiments on benchmark video generation datasets demonstrate that ACD delivers superior alignment with conditioning inputs while preserving temporal coherence and visual fidelity, establishing an effective paradigm for conditional video synthesis.\nüìÑ Download PDF\nAnyAD: Unified Any-Modality Anomaly Detection in Incomplete Multi-Sequence MRI Authors: Changwei Wu, Yifei Chen, Yuxin Du, Mingxuan Liu, Jinying Zong, Beining Wu, Jie Dong, Feiwei Qin, Yunkang Cao, Qiyuan Tian Venue: arXiv (2025)\nReliable anomaly detection in brain MRI remains challenging due to the scarcity of annotated abnormal cases and the frequent absence of key imaging modalities in real clinical workflows. Existing single-class or multi-class anomaly detection (AD) models typically rely on fixed modality configurations, require repetitive training, or fail to generalize to unseen modality combinations, limiting their clinical scalability. In this work, we present a unified Any-Modality AD framework that performs robust anomaly detection and localization under arbitrary MRI modality availability. The framework integrates a dual-pathway DINOv2 encoder with a feature distribution alignment mechanism that statistically aligns incomplete-modality features with full-modality representations, enabling stable inference even with severe modality dropout. To further enhance semantic consistency, we introduce an Intrinsic Normal Prototypes (INPs) extractor and an INP-guided decoder that reconstruct only normal anatomical patterns while naturally amplifying abnormal deviations. Through randomized modality masking and indirect feature completion during training, the model learns to adapt to all modality configurations without re-training. Extensive experiments on BraTS2018, MU-Glioma-Post, and Pretreat-MetsToBrain-Masks demonstrate that our approach consistently surpasses state-of-the-art industrial and medical AD baselines across 7 modality combinations, achieving superior generalization. This study establishes a scalable paradigm for multimodal medical AD under real-world, imperfect modality conditions. Our source code is available at https://github.com/wuchangw/AnyAD.\nüìÑ Download PDF\nSegMo: Segment-aligned Text to 3D Human Motion Generation Authors: Bowen Dang, Lin Wu, Xiaohang Yang, Zheng Yuan, Zhixiang Chen Venue: arXiv (2025)\nGenerating 3D human motions from textual descriptions is an important research problem with broad applications in video games, virtual reality, and augmented reality. Recent methods align the textual description with human motion at the sequence level, neglecting the internal semantic structure of modalities. However, both motion descriptions and motion sequences can be naturally decomposed into smaller and semantically coherent segments, which can serve as atomic alignment units to achieve finer-grained correspondence. Motivated by this, we propose SegMo, a novel Segment-aligned text-conditioned human Motion generation framework to achieve fine-grained text-motion alignment. Our framework consists of three modules: (1) Text Segment Extraction, which decomposes complex textual descriptions into temporally ordered phrases, each representing a simple atomic action; (2) Motion Segment Extraction, which partitions complete motion sequences into corresponding motion segments; and (3) Fine-grained Text-Motion Alignment, which aligns text and motion segments with contrastive learning. Extensive experiments demonstrate that SegMo improves the strong baseline on two widely used datasets, achieving an improved TOP 1 score of 0.553 on the HumanML3D test set. Moreover, thanks to the learned shared embedding space for text and motion segments, SegMo can also be applied to retrieval-style tasks such as motion grounding and motion-to-text retrieval.\nüìÑ Download PDF\nSMART SLM: Structured Memory and Reasoning Transformer, A Small Language Model for Accurate Document Assistance Authors: Divij Dudeja, Mayukha Pal Venue: arXiv (2025)\nThe user of Engineering Manuals (EM) finds it difficult to read EM s because they are long, have a dense format which includes written documents, step by step procedures, and standard parameter lists for engineering equipment. Off the shelf transformers, especially compact ones, treat this material as a flat stream of tokens. This approach leads to confident but incorrect numeric answers and forces the models to memorize separate facts inefficiently. SMART (Structured Memory and Reasoning Transformer) offers a different and practical solution to the above problem. SMART structures its processing by using a hierarchical approach, and is based upon three main job categories (1) A syntax-aware Fact Extractor (Grammarian) Tree LSTM which extracts facts as subject relation object relations from EM sentences (2) A compact indexed memory MANN (Memory Augmented Neural Network) that indexes these Rational Subject Relation Objects as 384 dimensional vectors that are associated with the source of the information, and (3) A 6 layer Transformer that learns to fuse the previously retrieved facts into its generated response. The entire SMART model utilizes 45.51M parameters, which is 64% less than GPT-2 (124M) and 69% less than BERT (133M), and it achieves a 21.3% higher accuracy than GPT-2, indicating that SMART fits the data better with the least amount of processing requirements. SMART employs dual modes of inference an indexed fast path for known documents (sub-second answer times) and an indexed dynamic path assisted by RAGs for new uploads (FAISS Top 20 results with memory severed at 64 slots). In real world deployment, this framework leads to more well supported results with reduced hallucinations than comparable small transformer models.\nüìÑ Download PDF\nRandom dilation superchannel Authors: Satoshi Yoshida, Ryotaro Niwa, Mio Murao Venue: arXiv (2025)\nWe present a quantum circuit that implements the random dilation superchannel, transforming parallel queries of an unknown quantum channel into parallel queries of a randomly chosen dilation isometry of the input channel. This is a natural generalization of a random purification channel, that transforms copies of an unknown mixed state to copies of a randomly chosen purification state. Our construction is based on the quantum Schur transform and the quantum Fourier transform over the symmetric group. By using the efficient construction of these quantum transforms, we can implement the random dilation superchannel with the circuit complexity $O(\\mathrm{poly}(n, \\log d_I, \\log d_O))$, where $n$ is the number of queries and $d_I$ and $d_O$ are the input and output dimensions of the input channel, respectively. As an application, we show an efficient storage-and-retrieval of an unknown quantum channel, which improves the program cost exponentially in the retrieval error $\\varepsilon$. For the case where the Kraus rank $r$ is the least possible (i.e., $r = d_I/d_O$), we show quantum circuits transforming $n$ parallel queries of an unknown quantum channel $Œõ$ to $Œò(n^Œ±)$ parallel queries of $Œõ$ for any $Œ±\u003c2$ approximately, and its Petz recovery map for the reference state given by the maximally mixed state probabilistically and exactly. We also show that our results can be further extended to the case of quantum superchannels.\nüìÑ Download PDF\nReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling Authors: Chuan Wang, Gaoming Yang, Han Wu, Jiakai Tang, Jiahao Yu, Jian Wu, Jianwu Hu, Junjun Zheng, Shuwen Xiao, Yeqiu Yang, Yuning Jiang, Ahjol Nurlanbek, Binbin Cao, Bo Zheng, Fangmei Zhu, Gaoming Zhou, Huimin Yi, Huiping Chu, Jin Huang, Jinzhe Shan, Kenan Cui, Longbin Li, Silu Zhou, Wen Chen, Xia Ming, Xiang Gao, Xin Yao, Xingyu Wen, Yan Zhang, Yiwen Hu, Yulin Wang, Ziheng Bao, Zongyuan Wu Venue: arXiv (2025)\nIndustrial recommender systems face two fundamental limitations under the log-driven paradigm: (1) knowledge poverty in ID-based item representations that causes brittle interest modeling under data sparsity, and (2) systemic blindness to beyond-log user interests that constrains model performance within platform boundaries. These limitations stem from an over-reliance on shallow interaction statistics and close-looped feedback while neglecting the rich world knowledge about product semantics and cross-domain behavioral patterns that Large Language Models have learned from vast corpora. To address these challenges, we introduce ReaSeq, a reasoning-enhanced framework that leverages world knowledge in Large Language Models to address both limitations through explicit and implicit reasoning. Specifically, ReaSeq employs explicit Chain-of-Thought reasoning via multi-agent collaboration to distill structured product knowledge into semantically enriched item representations, and latent reasoning via Diffusion Large Language Models to infer plausible beyond-log behaviors. Deployed on Taobao‚Äôs ranking system serving hundreds of millions of users, ReaSeq achieves substantial gains: \u003e6.0% in IPV and CTR, \u003e2.9% in Orders, and \u003e2.5% in GMV, validating the effectiveness of world-knowledge-enhanced reasoning over purely log-driven approaches.\nüìÑ Download PDF\nLeveraging Lightweight Entity Extraction for Scalable Event-Based Image Retrieval Authors: Dao Sy Duy Minh, Huynh Trung Kiet, Nguyen Lam Phu Quy, Phu-Hoa Pham, Tran Chi Nguyen Venue: arXiv (2025)\nRetrieving images from natural language descriptions is a core task at the intersection of computer vision and natural language processing, with wide-ranging applications in search engines, media archiving, and digital content management. However, real-world image-text retrieval remains challenging due to vague or context-dependent queries, linguistic variability, and the need for scalable solutions. In this work, we propose a lightweight two-stage retrieval pipeline that leverages event-centric entity extraction to incorporate temporal and contextual signals from real-world captions. The first stage performs efficient candidate filtering using BM25 based on salient entities, while the second stage applies BEiT-3 models to capture deep multimodal semantics and rerank the results. Evaluated on the OpenEvents v1 benchmark, our method achieves a mean average precision of 0.559, substantially outperforming prior baselines. These results highlight the effectiveness of combining event-guided filtering with long-text vision-language modeling for accurate and efficient retrieval in complex, real-world scenarios. Our code is available at https://github.com/PhamPhuHoa-23/Event-Based-Image-Retrieval\nüìÑ Download PDF\nüîç linguistics HiStream: Efficient High-Resolution Video Generation via Redundancy-Eliminated Streaming Authors: Haonan Qiu, Shikun Liu, Zijian Zhou, Zhaochong An, Weiming Ren, Zhiheng Liu, Jonas Schult, Sen He, Shoufa Chen, Yuren Cong, Tao Xiang, Ziwei Liu, Juan-Manuel Perez-Rua Venue: arXiv (2025)\nHigh-resolution video generation, while crucial for digital media and film, is computationally bottlenecked by the quadratic complexity of diffusion models, making practical inference infeasible. To address this, we introduce HiStream, an efficient autoregressive framework that systematically reduces redundancy across three axes: i) Spatial Compression: denoising at low resolution before refining at high resolution with cached features; ii) Temporal Compression: a chunk-by-chunk strategy with a fixed-size anchor cache, ensuring stable inference speed; and iii) Timestep Compression: applying fewer denoising steps to subsequent, cache-conditioned chunks. On 1080p benchmarks, our primary HiStream model (i+ii) achieves state-of-the-art visual quality while demonstrating up to 76.2x faster denoising compared to the Wan2.1 baseline and negligible quality loss. Our faster variant, HiStream+, applies all three optimizations (i+ii+iii), achieving a 107.5x acceleration over the baseline, offering a compelling trade-off between speed and quality, thereby making high-resolution video generation both practical and scalable.\nüìÑ Download PDF\nStreaming Video Instruction Tuning Authors: Jiaer Xia, Peixian Chen, Mengdan Zhang, Xing Sun, Kaiyang Zhou Venue: arXiv (2025)\nWe present Streamo, a real-time streaming video LLM that serves as a general-purpose interactive assistant. Unlike existing online video models that focus narrowly on question answering or captioning, Streamo performs a broad spectrum of streaming video tasks, including real-time narration, action understanding, event captioning, temporal event grounding, and time-sensitive question answering. To develop such versatility, we construct Streamo-Instruct-465K, a large-scale instruction-following dataset tailored for streaming video understanding. The dataset covers diverse temporal contexts and multi-task supervision, enabling unified training across heterogeneous streaming tasks. After training end-to-end on the instruction-following dataset through a streamlined pipeline, Streamo exhibits strong temporal reasoning, responsive interaction, and broad generalization across a variety of streaming benchmarks. Extensive experiments show that Streamo bridges the gap between offline video perception models and real-time multimodal assistants, making a step toward unified, intelligent video understanding in continuous video streams.\nüìÑ Download PDF\nFast SAM2 with Text-Driven Token Pruning Authors: Avilasha Mandal, Chaoning Zhang, Fachrina Dewi Puspitasari, Xudong Wang, Jiaquan Zhang, Caiyan Qin, Guoqing Wang, Yang Yang, Heng Tao Shen Venue: arXiv (2025)\nSegment Anything Model 2 (SAM2), a vision foundation model has significantly advanced in prompt-driven video object segmentation, yet their practical deployment remains limited by the high computational and memory cost of processing dense visual tokens across time. The SAM2 pipelines typically propagate all visual tokens produced by the image encoder through downstream temporal reasoning modules, regardless of their relevance to the target object, resulting in reduced scalability due to quadratic memory attention overhead. In this work, we introduce a text-guided token pruning framework that improves inference efficiency by selectively reducing token density prior to temporal propagation, without modifying the underlying segmentation architecture. Operating after visual encoding and before memory based propagation, our method ranks tokens using a lightweight routing mechanism that integrates local visual context, semantic relevance derived from object-centric textual descriptions (either user-provided or automatically generated), and uncertainty cues that help preserve ambiguous or boundary critical regions. By retaining only the most informative tokens for downstream processing, the proposed approach reduces redundant computation while maintaining segmentation fidelity. Extensive experiments across multiple challenging video segmentation benchmarks demonstrate that post-encoder token pruning provides a practical and effective pathway to efficient, prompt-aware video segmentation, achieving up to 42.50 percent faster inference and 37.41 percent lower GPU memory usage compared to the unpruned baseline SAM2, while preserving competitive J and F performance. These results highlight the potential of early token selection to improve the scalability of transformer-based video segmentation systems for real-time and resource-constrained applications.\nüìÑ Download PDF\nWhen Geometry Radiates Review: Gravitational Waves in Theory, Cosmology, and Observation Authors: Azadeh Maleknejad Venue: arXiv (2025)\nGravitational waves provide a unique window into gravity, cosmology, and high-energy physics, enabling the exploration of fundamental phenomena across a wide range of scales. This review presents a coherent and pedagogical framework that bridges foundational theory with observational frontiers. We begin by developing the theory of gravitational radiation within linearized general relativity, deriving gravitational waves as solutions to the linearized Einstein equations and clarifying their physical interpretation, polarization states, and key properties. We then deepen the discussion through a geometric perspective, tracing the connection between gravitational radiation and the algebraic structure of the Weyl tensor and its role in defining energy and angular momentum in asymptotically flat spacetimes. Extending beyond flat backgrounds, we examine gravitational waves in an expanding universe, following their evolution across cosmological epochs and their generation during inflation. Within this setting, we discuss adiabatic modes and consistency relations that reveal universal properties of long-wavelength perturbations, and derive the inflationary spectrum of vacuum gravitational waves together with their contribution to the integrated Sachs-Wolfe effect. We also survey the main observational strategies for detecting gravitational waves across a broad frequency range, including cosmic microwave background polarization, pulsar timing arrays, ground- and space-based laser interferometers, and resonant cavity detectors. We then discuss the astrophysical and cosmological mechanisms responsible for generating gravitational radiation. We conclude by summarizing the current status of the field and outlining promising directions for future theoretical and observational developments.\nüìÑ Download PDF\nAspects of holographic timelike entanglement entropy in black hole backgrounds Authors: Mir Afrasiar, Jaydeep Kumar Basak, Keun-Young Kim Venue: arXiv (2025)\nWe study the holographic construction of timelike entanglement entropy (tEE) in black hole backgrounds in Lorentzian geometries. The holographic tEE is realized through extremal surfaces consisting of spacelike and timelike branches that encode its real and imaginary components, respectively. In the BTZ black hole, these surfaces extend into the interior of the black hole and reproduce the field-theoretic results. The analysis is further generalized to higher-dimensional AdS-Schwarzschild black holes, where the characteristics of tEE are obtained with increasing size of the boundary subsystem. Besides, we also show that the boundary subsystem length diverges at a dimension-dependent critical turning point. Notably, this critical point moves closer to the black hole horizon as the dimensionality of the bulk increases. For large subsystem lengths, the finite part of the tEE displays a characteristic volume-plus-area structure, with a real volume term and a complex coefficient of the area term approaching constant values at large dimensions. Besides, we also study the monotonicity of a new quantity, timelike entanglement density, which offers insights into a timelike area theorem in specific limits. Subsequently, we investigate the near-horizon dynamics in various black hole backgrounds, where the spacelike and timelike surfaces exhibit exponential growth of the form $e^{\\frac{2œÄ}Œ≤ Œît}$ with inverse black hole temperature $Œ≤$.\nüìÑ Download PDF\nAn Allele-Centric Pan-Graph-Matrix Representation for Scalable Pangenome Analysis Authors: Roberto Garrone Venue: arXiv (2025)\nPopulation-scale pangenome analysis increasingly requires representations that unify single-nucleotide and structural variation while remaining scalable across large cohorts. Existing formats are typically sequence-centric, path-centric, or sample-centric, and often obscure population structure or fail to exploit carrier sparsity. We introduce the H1 pan-graph-matrix, an allele-centric representation that encodes exact haplotype membership using adaptive per-allele compression. By treating alleles as first-class objects and selecting optimal encodings based on carrier distribution, H1 achieves near-optimal storage across both common and rare variants. We further introduce H2, a path-centric dual representation derived from the same underlying allele-haplotype incidence information that restores explicit haplotype ordering while remaining exactly equivalent in information content. Using real human genome data, we show that this representation yields substantial compression gains, particularly for structural variants, while remaining equivalent in information content to pangenome graphs. H1 provides a unified, population-aware foundation for scalable pangenome analysis and downstream applications such as rare-variant interpretation and drug discovery.\nüìÑ Download PDF\nA Lyapunov-Based Small-Gain Theorem for Fixed-Time ISS: Theory, Optimization, and Games Authors: Michael Tang, Miroslav Krstic, Jorge Poveda Venue: arXiv (2025)\nWe develop a Lyapunov-based small-gain theorem for establishing fixed-time input-to-state stability (FxT-ISS) guarantees in interconnected nonlinear dynamical systems. The proposed framework considers interconnections in which each subsystem admits a FxT-ISS Lyapunov function, providing robustness with respect to external inputs. We show that, under an appropriate nonlinear small-gain condition, the overall interconnected system inherits the FxT-ISS property. In this sense, the proposed result complements existing Lyapunov-based smallgain theorems for asymptotic and finite-time stability, and enables a systematic analysis of interconnection structures exhibiting fixed-time stability. To illustrate the applicability of the theory, we study feedback-based optimization problems with time-varying cost functions, and Nash-equilibrium seeking for noncooperative games with nonlinear dynamical plants in the loop. For both problems, we present a class of non-smooth gradient or pseudogradient-based controllers that achieve fixed-time convergence without requiring time-scale separation and using real-time feedback. Numerical examples are provided to validate the theoretical findings.\nüìÑ Download PDF\nFORCE-$Œ±$ Numerical Fluxes within the Arbitrary High Order Semidiscrete WENO-DeC Framework: A Competitive Alternative to Upwind Fluxes Authors: Lorenzo Micalizzi, Eleuterio Toro Venue: arXiv (2025)\nThis work systematically investigates the performance of FORCE‚Äì$Œ±$ numerical fluxes within an arbitrary high order semidiscrete finite volume (FV) framework for hyperbolic partial differential equations (PDEs). Such numerical fluxes have been recently introduced by Toro, Saggiorato, Tokareva, and Hidalgo (Journal of Computational Physics, 416, 2020), and constitute a family of centred fluxes obtained from a suitable modification of First‚ÄìOrder Centred (FORCE) numerical fluxes. In contrast with upwind fluxes, such as Rusanov, Harten‚ÄìLax‚Äìvan Leer (HLL) or the exact Riemann solver (RS) numerical flux, centred ones do not consider in any way the structure of the Riemann problem at cell interfaces. Adopting centred numerical fluxes leads to a high level of flexibility of the resulting numerical schemes, for example in the context of complicated hyperbolic systems, for which RSs may be impossible to construct or computationally expensive. The baseline framework adopted in this investigation is a FV semidiscrete approach with Weighted Essentially Non‚ÄìOscillatory (WENO) spatial reconstruction and Deferred Correction (DeC) time discretization, and results are reported up to order 7. Previous investigations involving the same framework have established that increasing the order of accuracy tends to decrease the differences in the results obtained through different numerical fluxes. The goal of this paper is to show that the employment of FORCE‚Äì$Œ±$ numerical fluxes within such a framework is a competitive alternative to the adoption of more classical upwind fluxes. The hyperbolic system considered for this investigation is the ideal Euler equations in one and two space dimensions.\nüìÑ Download PDF\nDeforming and dissecting AdS$_3$ with matter Authors: Nele Callebaut, Blanca Hergueta, Ruben Monten, Matteo Selle Venue: arXiv (2025)\nWe study deformations of the model by Henneaux, Mart√≠nez, Troncoso and Zanelli [arXiv:hep-th/0201170] which features asymptotically AdS$_3$ black hole solutions that incorporate the exact backreaction of a scalar field. The presence of bulk matter causes the $T \\overline T$ deformation of the (putative) dual CFT$_2$ to differ from the deformation defined in the bulk by imposing Dirichlet boundary conditions at finite radius. We work out both of these deformations explicitly and verify that $T \\overline T$-deforming the boundary theory corresponds to imposing mixed boundary conditions on the metric at the conformal boundary, whereas the bulk ‚ÄúDirichlet deformation‚Äù gives rise to a field theory deforming operator that includes $T \\overline T$ as well as other irrelevant terms. We check our results by calculating the deformed energy spectrum for either case using both the bulk and boundary prescriptions, finding agreement after taking into account additional terms coming from the flow of the scalar source. We interpret our explicit results and compare them with the predictions of similar proposals in the literature.\nüìÑ Download PDF\nExact Infrared Triangle in Massless sQED with Long-range Interactions Authors: Sangmin Choi, Ameya Kadhe, Andrea Puhm Venue: arXiv (2025)\nThe logarithmic soft photon theorem in four spacetime dimensions encodes an infinite-dimensional asymptotic symmetry which acts on massive matter as a divergent superphaserotation. Here we extend this result to massless matter which is both more subtle and surprising. We derive the charge associated to divergent superphaserotations and show that it exactly vanishes to all orders in the electromagnetic coupling. This is in agreement with the vanishing of the classical logarithmic soft photon theorem which is one-loop exact. Special care is required for massless matter due to potential collinear divergences which, as we show, do however not affect the superphaserotation charge. We furthermore compute the infrared corrections to the charge associated to the subleading tree-level soft photon theorem. As a corollary of our result, we find that the tail to the velocity kick memory due to the long-range interactions between soft electromagnetic radiation and massless matter vanishes.\nüìÑ Download PDF\nLinking interior curvature to observable shadows: A case study of nonsingular black holes Authors: Ming-Xin Li, Jin Pu, Yi Ling, Guo-Ping Li Venue: arXiv (2025)\nWe establish a direct connection between the interior curvature structure of nonsingular black holes (BHs) with a Minkowski core and their observable optical signatures. By classifying these spacetimes into three fundamental types, Type I (Kretschmann scalar K_max increasing with mass M), Type II (mass-independent K_max), and Type III (K_max decreasing with M), we demonstrate how subtle variations in the core geometry imprint distinguishable features on the BH shadow. A detailed analysis of photon dynamics reveals that the parameters Œ± and n, which control the deviation from Schwarzschild geometry and the radial decay of the regularizing factor, respectively, systematically alter the properties of the photon sphere. These intrinsic geometric differences propagate outward: for fixed parameters, Type III BHs, with the most compact photon sphere, produce the smallest and brightest shadows, whereas Type I BHs yield the largest and dimmest ones. Shadow computations under both static and infalling spherical accretion models confirm that the curvature-based classification directly corresponds to observable differences. Critically, Type III BHs exhibit the strongest sensitivity to parameter variations, making them optimal probes for constraining the underlying spacetime geometry. Our work reveals that even among nonsingular BHs sharing the same asymptotic core, differences in internal curvature are reflected in the shadow morphology, thereby providing a new pathway to test quantum-gravity-inspired models using upcoming high-resolution observations.\nüìÑ Download PDF\n(Lovelock)$^2$ inflation: explaining the ACT data and equivalence to Higgs-Gauss-Bonnet inflation Authors: Andrea Addazi, Yermek Aldabergenov, Daulet Berkimbayev, Yifu Cai Venue: arXiv (2025)\nWe revisit the Starobinsky model of inflation in light of recent data from the Atacama Cosmology Telescope (ACT), which indicates a potential preference for a slightly larger scalar spectral index $n_s$ than predicted by the standard $R^2$ scenario. We demonstrate that a natural one-parameter generalization to a quadratic model $\\sim L+L^2$ in the Lovelock invariant $L=R+\\fracŒ±{4}{\\cal G}$ ($\\cal G$ is the Gauss‚ÄìBonnet term), can effectively resolve this minor tension. Scalar-tensor formulation of this theory yields an Einstein-frame Starobinsky-type scalar potential augmented by Gauss‚ÄìBonnet and derivative couplings, which modify the inflationary slow-roll dynamics. We show that a non-zero coupling $Œ±$ for the Gauss-Bonnet term can shift $(n_s, r)$ along a trajectory that brings the predictions into better agreement with the ACT likelihood. We also find that $L+L^2$ gravity, in its scalar-tensor formulation, is equivalent to Higgs inflation coupled to the Gauss‚ÄìBonnet term, and belongs to the Horndeski/galileon class of modified gravities. This work establishes the quadratic $f(L)$ gravity as a compelling and physically motivated extension that preserves the successes of Starobinsky inflation while improving its fit to modern precision cosmological data.\nüìÑ Download PDF\nORCA: Object Recognition and Comprehension for Archiving Marine Species Authors: Yuk-Kwan Wong, Haixin Liang, Zeyu Ma, Yiwei Chen, Ziqiang Zheng, Rinaldi Gotama, Pascal Sebastian, Lauren D. Sparks, Sai-Kit Yeung Venue: arXiv (2025)\nMarine visual understanding is essential for monitoring and protecting marine ecosystems, enabling automatic and scalable biological surveys. However, progress is hindered by limited training data and the lack of a systematic task formulation that aligns domain-specific marine challenges with well-defined computer vision tasks, thereby limiting effective model application. To address this gap, we present ORCA, a multi-modal benchmark for marine research comprising 14,647 images from 478 species, with 42,217 bounding box annotations and 22,321 expert-verified instance captions. The dataset provides fine-grained visual and textual annotations that capture morphology-oriented attributes across diverse marine species. To catalyze methodological advances, we evaluate 18 state-of-the-art models on three tasks: object detection (closed-set and open-vocabulary), instance captioning, and visual grounding. Results highlight key challenges, including species diversity, morphological overlap, and specialized domain demands, underscoring the difficulty of marine understanding. ORCA thus establishes a comprehensive benchmark to advance research in marine domain. Project Page: http://orca.hkustvgd.com/.\nüìÑ Download PDF\nTICON: A Slide-Level Tile Contextualizer for Histopathology Representation Learning Authors: Varun Belagali, Saarthak Kapse, Pierre Marza, Srijan Das, Zilinghan Li, Sofi√®ne Boutaj, Pushpak Pati, Srikar Yellapragada, Tarak Nath Nandi, Ravi K Madduri, Joel Saltz, Prateek Prasanna, Stergios Christodoulidis Maria Vakalopoulou, Dimitris Samaras Venue: arXiv (2025)\nThe interpretation of small tiles in large whole slide images (WSI) often needs a larger image context. We introduce TICON, a transformer-based tile representation contextualizer that produces rich, contextualized embeddings for ‚Äò‚Äòany‚Äô‚Äô application in computational pathology. Standard tile encoder-based pipelines, which extract embeddings of tiles stripped from their context, fail to model the rich slide-level information essential for both local and global tasks. Furthermore, different tile-encoders excel at different downstream tasks. Therefore, a unified model is needed to contextualize embeddings derived from ‚Äò‚Äòany‚Äô‚Äô tile-level foundation model. TICON addresses this need with a single, shared encoder, pretrained using a masked modeling objective to simultaneously unify and contextualize representations from diverse tile-level pathology foundation models. Our experiments demonstrate that TICON-contextualized embeddings significantly improve performance across many different tasks, establishing new state-of-the-art results on tile-level benchmarks (i.e., HEST-Bench, THUNDER, CATCH) and slide-level benchmarks (i.e., Patho-Bench). Finally, we pretrain an aggregator on TICON to form a slide-level foundation model, using only 11K WSIs, outperforming SoTA slide-level foundation models pretrained with up to 350K WSIs.\nüìÑ Download PDF\nTowards Practical Automatic Piano Reduction using BERT with Semi-supervised Learning Authors: Wan Ki Wong, Ka Ho To, Chuck-jee Chau, Lucas Wong, Kevin Y. Yip, Irwin King Venue: arXiv (2025)\nIn this study, we present a novel automatic piano reduction method with semi-supervised machine learning. Piano reduction is an important music transformation process, which helps musicians and composers as a musical sketch for performances and analysis. The automation of such is a highly challenging research problem but could bring huge conveniences as manually doing a piano reduction takes a lot of time and effort. While supervised machine learning is often a useful tool for learning input-output mappings, it is difficult to obtain a large quantity of labelled data. We aim to solve this problem by utilizing semi-supervised learning, so that the abundant available data in classical music can be leveraged to perform the task with little or no labelling effort. In this regard, we formulate a two-step approach of music simplification followed by harmonization. We further propose and implement two possible solutions making use of an existing machine learning framework ‚Äì MidiBERT. We show that our solutions can output practical and realistic samples with an accurate reduction that needs only small adjustments in post-processing. Our study forms the groundwork for the use of semi-supervised learning in automatic piano reduction, where future researchers can take reference to produce more state-of-the-art results.\nüìÑ Download PDF\nA Plan Reuse Mechanism for LLM-Driven Agent Authors: Guopeng Li, Ruiqi Wu, Haisheng Tan Venue: arXiv (2025)\nIntegrating large language models (LLMs) into personal assistants, like Xiao Ai and Blue Heart V, effectively enhances their ability to interact with humans, solve complex tasks, and manage IoT devices. Such assistants are also termed LLM-driven agents. Upon receiving user requests, the LLM-driven agent generates plans using an LLM, executes these plans through various tools, and then returns the response to the user. During this process, the latency for generating a plan with an LLM can reach tens of seconds, significantly degrading user experience. Real-world dataset analysis shows that about 30% of the requests received by LLM-driven agents are identical or similar, which allows the reuse of previously generated plans to reduce latency. However, it is difficult to accurately define the similarity between the request texts received by the LLM-driven agent through directly evaluating the original request texts. Moreover, the diverse expressions of natural language and the unstructured format of plan texts make implementing plan reuse challenging. To address these issues, we present and implement a plan reuse mechanism for LLM-driven agents called AgentReuse. AgentReuse leverages the similarities and differences among requests‚Äô semantics and uses intent classification to evaluate the similarities between requests and enable the reuse of plans. Experimental results based on a real-world dataset demonstrate that AgentReuse achieves a 93% effective plan reuse rate, an F1 score of 0.9718, and an accuracy of 0.9459 in evaluating request similarities, reducing latency by 93.12% compared with baselines without using the reuse mechanism.\nüìÑ Download PDF\nBar Formation in Disc Galaxies: Internal Kinematics and Environmental Influence in MaNGA Galaxies Authors: Erik Aquino-Ort√≠z, Bernardo Cervantes-Sodi, Karol Chim-Ramirez Venue: arXiv (2025)\nWe explore how the physical properties of disc galaxies relate to the presence of bars using data from the SDSS-IV MaNGA survey. By combining internal kinematical properties and environmental diagnostics, we find that barred galaxies are more frequently associated with centrally concentrated stellar mass distributions (within 1 and 2 effective radii) and exhibit lower values of the stellar angular momentum $Œª_{Re}$. At fixed total stellar mass, barred galaxies exhibit: (i) higher stellar mass, and (ii) lower angular momentum, both in their inner regions than their unbarred counterparts. We find a bimodal dependence of the bar fraction on tidal interactions produced by the nearest neighbour. Specifically, the bar fraction peaks in the most isolated galaxies, where bars form unequivocally through internal secular processes, decreases at intermediate interaction strengths, and rises again in the strong interaction regime, likely reflecting the role of dense environments in sustaining or triggering bars. Our results suggest that internal gravitational instabilities are the primary driver of bar formation. External tidal perturbations play a secondary role, capable of triggering or enhancing bar formation in galaxies that are already internally predisposed. Our findings provide robust observational validation of theoretical bar formation and evolution models in galaxies.\nüìÑ Download PDF\nUniRec-0.1B: Unified Text and Formula Recognition with 0.1B Parameters Authors: Yongkun Du, Zhineng Chen, Yazhen Xie, Weikang Baiand Hao Feng, Wei Shi, Yuchen Su, Can Huang, Yu-Gang Jiang Venue: arXiv (2025)\nText and formulas constitute the core informational components of many documents. Accurately and efficiently recognizing both is crucial for developing robust and generalizable document parsing systems. Recently, vision-language models (VLMs) have achieved impressive unified recognition of text and formulas. However, they are large-sized and computationally demanding, restricting their usage in many applications. In this paper, we propose UniRec-0.1B, a unified recognition model with only 0.1B parameters. It is capable of performing text and formula recognition at multiple levels, including characters, words, lines, paragraphs, and documents. To implement this task, we first establish UniRec40M, a large-scale dataset comprises 40 million text, formula and their mix samples, enabling the training of a powerful yet lightweight model. Secondly, we identify two challenges when building such a lightweight but unified expert model. They are: structural variability across hierarchies and semantic entanglement between textual and formulaic content. To tackle these, we introduce a hierarchical supervision training that explicitly guides structural comprehension, and a semantic-decoupled tokenizer that separates text and formula representations. Finally, we develop a comprehensive evaluation benchmark covering Chinese and English documents from multiple domains and with multiple levels. Experimental results on this and public benchmarks demonstrate that UniRec-0.1B outperforms both general-purpose VLMs and leading document parsing expert models, while achieving a 2-9$\\times$ speedup, validating its effectiveness and efficiency. Codebase and Dataset: https://github.com/Topdu/OpenOCR.\nüìÑ Download PDF\nLaser: Governing Long-Horizon Agentic Search via Structured Protocol and Context Register Authors: Shuting Wang, Qiaolin Xia, Hao Wang, Yu Lu, Bobsimons, Zhicheng Dou Venue: arXiv (2025)\nRecent advances in Large Language Models (LLMs) and Large Reasoning Models (LRMs) have enabled agentic search systems that interleave multi-step reasoning with external tool use. However, existing frameworks largely rely on unstructured natural-language reasoning and accumulate raw intermediate traces in the context, which often leads to unstable reasoning trajectories, context overflow, and degraded performance on complex multi-hop queries. In this study, we introduce Laser, a general framework for stabilizing and scaling agentic search. Laser defines a symbolic action protocol that organizes agent behaviors into three spaces: planning, task-solving, and retrospection. Each action is specified with explicit semantics and a deterministic execution format, enabling structured and logical reasoning processes and reliable action parsing. This design makes intermediate decisions interpretable and traceable, enhancing explicit retrospection and fine-grained control over reasoning trajectories. In coordination with parsable actions, Laser further maintains a compact context register that stores only essential states of the reasoning process, allowing the agent to reason over long horizons without uncontrolled context expansion. Experiments on Qwen2.5/3-series models across challenging multi-hop QA datasets show that Laser consistently outperforms existing agentic search baselines under both prompting-only and fine-tuning settings, demonstrating that Laser provides a principled and effective foundation for robust, scalable agentic search.\nüìÑ Download PDF\nFrom Cosmology to Cosmonomy Authors: Emmanuel N. Saridakis Venue: arXiv (2025)\nFor most of its history, cosmology was a qualitatively constrained discourse on the universe, shaped by limited observational access and the absence of global dynamical laws. This situation has changed decisively in recent decades. Modern cosmology is now driven by an unprecedented flow of high-precision data from a wide range of independent probes, including the cosmic microwave background, large-scale structure, supernovae, baryon acoustic oscillations, gravitational lensing, cosmic chronometers, redshift-space distortions, gravitational-wave standard sirens, and emerging 21-cm observations, among others. This observational wealth is matched by a concrete theoretical and mathematical framework, based on general relativity, which provides the dynamical equations governing the evolution of spacetime and matter at cosmic scales. Combined with explicit background and perturbative equations, this framework enables quantitative, predictive, and falsifiable descriptions of cosmic evolution. Thus, cosmology operates today as a nomological natural science of the observable universe, characterized by general laws, predictive power, and systematic empirical testing. We argue that this epistemic transformation motivates a corresponding conceptual shift, directly analogous to the historical transition from astrology to astronomy. In this sense, the transition from cosmology to \\emph{cosmonomy} should begin to be discussed among cosmologists, or, more precisely, among cosmonomers.\nüìÑ Download PDF\nIndicDLP: A Foundational Dataset for Multi-Lingual and Multi-Domain Document Layout Parsing Authors: Oikantik Nath, Sahithi Kukkala, Mitesh Khapra, Ravi Kiran Sarvadevabhatla Venue: arXiv (2025)\nDocument layout analysis is essential for downstream tasks such as information retrieval, extraction, OCR, and digitization. However, existing large-scale datasets like PubLayNet and DocBank lack fine-grained region labels and multilingual diversity, making them insufficient for representing complex document layouts. In contrast, human-annotated datasets such as M6Doc and D4LA offer richer labels and greater domain diversity, but are too small to train robust models and lack adequate multilingual coverage. This gap is especially pronounced for Indic documents, which encompass diverse scripts yet remain underrepresented in current datasets, further limiting progress in this space. To address these shortcomings, we introduce IndicDLP, a large-scale foundational document layout dataset spanning 11 representative Indic languages alongside English and 12 common document domains. Additionally, we curate UED-mini, a dataset derived from DocLayNet and M6Doc, to enhance pretraining and provide a solid foundation for Indic layout models. Our experiments demonstrate that fine-tuning existing English models on IndicDLP significantly boosts performance, validating its effectiveness. Moreover, models trained on IndicDLP generalize well beyond Indic layouts, making it a valuable resource for document digitization. This work bridges gaps in scale, diversity, and annotation granularity, driving inclusive and efficient document understanding.\nüìÑ Download PDF\nSegEarth-R2: Towards Comprehensive Language-guided Segmentation for Remote Sensing Images Authors: Zepeng Xin, Kaiyu Li, Luodi Chen, Wanchen Li, Yuchen Xiao, Hui Qiao, Weizhan Zhang, Deyu Meng, Xiangyong Cao Venue: arXiv (2025)\nEffectively grounding complex language to pixels in remote sensing (RS) images is a critical challenge for applications like disaster response and environmental monitoring. Current models can parse simple, single-target commands but fail when presented with complex geospatial scenarios, e.g., segmenting objects at various granularities, executing multi-target instructions, and interpreting implicit user intent. To drive progress against these failures, we present LaSeRS, the first large-scale dataset built for comprehensive training and evaluation across four critical dimensions of language-guided segmentation: hierarchical granularity, target multiplicity, reasoning requirements, and linguistic variability. By capturing these dimensions, LaSeRS moves beyond simple commands, providing a benchmark for complex geospatial reasoning. This addresses a critical gap: existing datasets oversimplify, leading to sensitivity-prone real-world models. We also propose SegEarth-R2, an MLLM architecture designed for comprehensive language-guided segmentation in RS, which directly confronts these challenges. The model‚Äôs effectiveness stems from two key improvements: (1) a spatial attention supervision mechanism specifically handles the localization of small objects and their components, and (2) a flexible and efficient segmentation query mechanism that handles both single-target and multi-target scenarios. Experimental results demonstrate that our SegEarth-R2 achieves outstanding performance on LaSeRS and other benchmarks, establishing a powerful baseline for the next generation of geospatial segmentation. All data and code will be released at https://github.com/earth-insights/SegEarth-R2.\nüìÑ Download PDF\nHow well do Large Language Models Recognize Instructional Moves? Establishing Baselines for Foundation Models in Educational Discourse Authors: Kirk Vanacore, Rene F. Kizilcec Venue: arXiv (2025)\nLarge language models (LLMs) are increasingly adopted in educational technologies for a variety of tasks, from generating instructional materials and assisting with assessment design to tutoring. While prior work has investigated how models can be adapted or optimized for specific tasks, far less is known about how well LLMs perform at interpreting authentic educational scenarios without significant customization. As LLM-based systems become widely adopted by learners and educators in everyday academic contexts, understanding their out-of-the-box capabilities is increasingly important for setting expectations and benchmarking. We compared six LLMs to estimate their baseline performance on a simple but important task: classifying instructional moves in authentic classroom transcripts. We evaluated typical prompting methods: zero-shot, one-shot, and few-shot prompting. We found that while zero-shot performance was moderate, providing comprehensive examples (few-shot prompting) significantly improved performance for state-of-the-art models, with the strongest configuration reaching Cohen‚Äôs Kappa = 0.58 against expert-coded annotations. At the same time, improvements were neither uniform nor complete: performance varied considerably by instructional move, and higher recall frequently came at the cost of increased false positives. Overall, these findings indicate that foundation models demonstrate meaningful yet limited capacity to interpret instructional discourse, with prompt design helping to surface capability but not eliminating fundamental reliability constraints.\nüìÑ Download PDF\nTopological Charge-2ne Superconductors Authors: Zhi-Qiang Gao, Yan-Qi Wang, Hui Yang, Congjun Wu Venue: arXiv (2025)\nCharge-$4e$ superconductors are phases where quartets of electrons condense in the absence of Cooper pairing condensation. They exhibit distinctive signatures including fractional flux quantization and anomalous Josephson effects, and are actively being explored in strongly correlated systems, such as moir√© materials. In this work we develop a general framework for \\emph{topological} charge-$2ne$ superconductors based on both wavefunction and field theory approaches. In particular, we generate topological charge-$2ne$ superconductors from charge-$2e$ ingredients, and by breaking the charge $U(1)$ symmetry in certain classes of quantum Hall states. Via bulk-edge correspondence, we further construct the corresponding edge conformal field theory and bulk topological quantum field theory for topological charge-$2ne$ superconductors that suggests fermionic nonabelian topological orders. Our results provide a unified low energy description of the topological charge-$2ne$ superconductivity, offer a concrete platform for studying symmetry breaking and enrichment in interacting topological phases of matter, and have direct implications for experimental probes such as quasiparticle interferometry.\nüìÑ Download PDF\nQuantum entanglement between partons in a strongly coupled quantum field theory Authors: Wenyu Zhang, Wenyang Qian, Yiyu Zhou, Yang Li, Qun Wang Venue: arXiv (2025)\nWe perform a first-principles, non-perturbative investigation of quantum entanglement between partonic constituents in a strongly coupled 3+1-dimensional scalar Yukawa theory, using light-front Hamiltonian methods with controlled Fock-space truncations. By explicitly constructing reduced density matrices for (mock) nucleon, pion, and anti-nucleon subsystems from light-front wave functions, we compute key entanglement witnesses, including von Neumann entropy, mutual information, and linear entropy, in both quenched (no sea pairs) and unquenched frameworks. We find that the entanglement entropy is closely related to the Shannon entropy of the transverse momentum dependent distribution, establishing a link between quantum information and parton structure. In contrast, the unquenched theory reveals genuinely non-classical correlations: the entanglement entropy cannot be reduced to any Shannon entropy of normalized parton distributions, demonstrating that the full hadronic wave function encodes quantum information beyond classical probabilities. Our findings highlight the role of entanglement as a fundamental probe of non-perturbative dynamics in relativistic quantum field theory and lay the groundwork for extending these concepts to QCD and future collider phenomenology.\nüìÑ Download PDF\nVisRes Bench: On Evaluating the Visual Reasoning Capabilities of VLMs Authors: Brigitta Malagurski T√∂rtei, Yasser Dahou, Ngoc Dung Huynh, Wamiq Reyaz Para, Ph√∫c H. L√™ Khac, Ankit Singh, Sofian Chaybouti, Sanath Narayan Venue: arXiv (2025)\nVision-Language Models (VLMs) have achieved remarkable progress across tasks such as visual question answering and image captioning. Yet, the extent to which these models perform visual reasoning as opposed to relying on linguistic priors remains unclear. To address this, we introduce VisRes Bench, a benchmark designed to study visual reasoning in naturalistic settings without contextual language supervision. Analyzing model behavior across three levels of complexity, we uncover clear limitations in perceptual and relational visual reasoning capacities. VisRes isolates distinct reasoning abilities across its levels. Level 1 probes perceptual completion and global image matching under perturbations such as blur, texture changes, occlusion, and rotation; Level 2 tests rule-based inference over a single attribute (e.g., color, count, orientation); and Level 3 targets compositional reasoning that requires integrating multiple visual attributes. Across more than 19,000 controlled task images, we find that state-of-the-art VLMs perform near random under subtle perceptual perturbations, revealing limited abstraction beyond pattern recognition. We conclude by discussing how VisRes provides a unified framework for advancing abstract visual reasoning in multimodal research.\nüìÑ Download PDF\nSearch for Light Dark Matter in Rare Meson Decays Authors: Ze-Kun Liu, Ying Li, Biao-Feng Hou, Qin Chang Venue: arXiv (2025)\nCurrent dark matter direct detection experiments have low sensitivity to sub-GeV dark matter. In this work, we demonstrate that rare $B$ and $K$ meson decays with missing energy in the final state can serve as efficient probes in this mass range. We analyze a generic $Z^{\\prime}$ portal dark matter model and derive upper limits on its parameters from experimental bounds on the rare $B$ and $K$ meson decays. Our results show that such meson decay processes provide complementary constraints to current direct detection experiments for sub-GeV dark matter, particularly for interaction forms mediated by dark matter momentum dependent operators.\nüìÑ Download PDF\nLarge time behavior of the solution to the Cauchy problem for the discrete p-Laplacian with density on infinite graphs Authors: Alan A. Tedeev Venue: arXiv (2025)\nWe consider the Cauchy problem for the nonstationary discrete p-Laplacian with inhomogeneous density \\r{ho}(x) on an infinite graph which supports the Sobolev inequality. For nonnegative solutions when p \u003e 2, we prove the precise rate of stabilization in time, provided \\r{ho}(x) is a non-power function. When p \u003e 2 and \\r{ho}(x) goes to zero fast enough, we prove the universal bound. Our technique relies on suitable energy inequalities and a new embedding result.\nüìÑ Download PDF\nUniversality of equilibration dynamics after quantum quenches Authors: Vincenzo Alba, Sanam Azarnia, Gianluca Lagnese, Federico Rottoli Venue: arXiv (2025)\nWe investigate the distribution of the eigenvalues of the reduced density matrix (entanglement spectrum) after a global quantum quench. We show that in an appropriate scaling limit the lower part of the entanglement spectrum exhibits ``universality‚Äô‚Äô. In the scaling limit and at asymptotically long times the distribution of the entanglement spectrum depends on two parameters that can be determined from the R√©nyi entropies. We show that two typical scenarios occur. In the first one, the distribution of the entanglement spectrum levels is similar to the one describing the ground-state entanglement spectrum in Conformal Field Theories. In the second scenario, the lower levels of the entanglement spectrum are highly degenerate and their distribution is given by a series of Dirac deltas. We benchmark our analytical results in free-fermion chains, such as the transverse field Ising chain and the XX chain, in the rule 54 chain, and in Bethe ansatz solvable spin models.\nüìÑ Download PDF\nThe Patterson-Sullivan construction and global leaf geometry for Anosov flows Authors: Clark Butler Venue: arXiv (2025)\nWe give a new construction of the measure of maximal entropy for transitive Anosov flows through a method analogous to the construction of Patterson-Sullivan measures in negative curvature. In order to carry out our procedure we prove several new results concerning the global geometry of the leaves of the center-unstable foliation of an Anosov flow. We show that the universal covers of the center-unstable leaves are Gromov hyperbolic in the induced Riemannian metric and their relative Gromov boundaries canonically identify with the unstable leaves within in such a way that the Hamenst√§dt metrics on these leaves correspond to visual metrics on the relative Gromov boundary. These center-unstable leaves are then uniformized according to a technique inspired by methods of Bonk-Heinonen-Koskela which, in addition to its utility in the construction itself, also leads to rich analytic properties for these uniformized leaves such as supporting a Poincar√© inequality. As a corollary we obtain that the fundamental group of a closed Riemannian manifold with Anosov geodesic flow must be Gromov hyperbolic.\nüìÑ Download PDF\nSemantic Refinement with LLMs for Graph Representations Authors: Safal Thapaliya, Zehong Wang, Jiazheng Li, Ziming Li, Yanfang Ye, Chuxu Zhang Venue: arXiv (2025)\nGraph-structured data exhibit substantial heterogeneity in where their predictive signals originate: in some domains, node-level semantics dominate, while in others, structural patterns play a central role. This structure-semantics heterogeneity implies that no graph learning model with a fixed inductive bias can generalize optimally across diverse graph domains. However, most existing methods address this challenge from the model side by incrementally injecting new inductive biases, which remains fundamentally limited given the open-ended diversity of real-world graphs. In this work, we take a data-centric perspective and treat node semantics as a task-adaptive variable. We propose a Data-Adaptive Semantic Refinement framework DAS for graph representation learning, which couples a fixed graph neural network (GNN) and a large language model (LLM) in a closed feedback loop. The GNN provides implicit supervisory signals to guide the semantic refinement of LLM, and the refined semantics are fed back to update the same graph learner. We evaluate our approach on both text-rich and text-free graphs. Results show consistent improvements on structure-dominated graphs while remaining competitive on semantics-rich graphs, demonstrating the effectiveness of data-centric semantic adaptation under structure-semantics heterogeneity.\nüìÑ Download PDF\nReflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models Authors: Xiang Zhang, Jiaqi Wei, Yuejin Yang, Zijie Qiu, Yuhan Chen, Zhiqiang Gao, Muhammad Abdul-Mageed, Laks V. S. Lakshmanan, Wanli Ouyang, Chenyu You, Siqi Sun Venue: arXiv (2025)\nChain-of-Thought (CoT) prompting has significantly advanced task-solving capabilities in natural language processing with large language models. Unlike standard prompting, CoT encourages the model to generate intermediate reasoning steps, non-answer tokens, that help guide the model toward more accurate final outputs. These intermediate steps enable more complex reasoning processes such as error correction, memory management, future planning, and self-reflection. However, applying CoT to non-natural language domains, such as protein and RNA language models, is not yet possible, primarily due to the limited expressiveness of their token spaces (e.g., amino acid tokens). In this work, we propose and define the concept of language expressiveness: the ability of a given language, using its tokens and grammar, to encode information. We show that the limited expressiveness of protein language severely restricts the applicability of CoT-style reasoning. To overcome this, we introduce reflection pretraining, for the first time in a biological sequence model, which enables the model to engage in intermediate reasoning through the generation of auxiliary ‚Äúthinking tokens‚Äù beyond simple answer tokens. Theoretically, we demonstrate that our augmented token set significantly enhances biological language expressiveness, thereby improving the overall reasoning capacity of the model. Experimentally, our pretraining approach teaches protein models to self-correct and leads to substantial performance gains compared to standard pretraining.\nüìÑ Download PDF\nTransductive Visual Programming: Evolving Tool Libraries from Experience for Spatial Reasoning Authors: Shengguang Wu, Xiaohan Wang, Yuhui Zhang, Hao Zhu, Serena Yeung-Levy Venue: arXiv (2025)\nSpatial reasoning in 3D scenes requires precise geometric calculations that challenge vision-language models. Visual programming addresses this by decomposing problems into steps calling specialized tools, yet existing methods rely on either fixed toolsets or speculative tool induction before solving problems, resulting in suboptimal programs and poor utilization of induced tools. We present Transductive Visual Programming (TVP), a novel framework that builds new tools from its own experience rather than speculation. TVP first solves problems using basic tools while accumulating experiential solutions into an Example Library, then abstracts recurring patterns from these programs into reusable higher-level tools for an evolving Tool Library. This allows TVP to tackle new problems with increasingly powerful tools learned from experience. On Omni3D-Bench, TVP achieves state-of-the-art performance, outperforming GPT-4o by 22% and the previous best visual programming system by 11%. Our transductively learned tools are used 5x more frequently as core program dependency than inductively created ones, demonstrating more effective tool discovery and reuse. The evolved tools also show strong generalization to unseen spatial tasks, achieving superior performance on benchmarks from SpatialScore-Hard collection without any testset-specific modification. Our work establishes experience-driven transductive tool creation as a powerful paradigm for building self-evolving visual programming agents that effectively tackle challenging spatial reasoning tasks. We release our code at https://transductive-visualprogram.github.io/.\nüìÑ Download PDF\nVirtual volumes of strata of meromorphic differentials with simple poles Authors: Adrien Sauvaget Venue: arXiv (2025)\nWe work over strata of meromorphic differentials with poles of order 1, and on affine subspaces defined by linear conditions on the residues. We propose a definition of the volume of these objects as the integral of a tautological class on the projectivization of the stratum. By previous work with Chen-M√∂ller-Zagier, this definition agrees with the Masur-Veech volumes in the holomorphic case. We show that these algebraic constants can be computed by induction on the genus and number of singularities. Besides, for strata with a single zero, we prove that the generating series of these volumes is a solution of an integrable system associated with the PDE: $u_tu_{xx}=u_tu_x+u_t - 1$.\nüìÑ Download PDF\nProcess Analytics ‚Äì Data-driven Business Process Management Authors: Matthias Stierle, Karsten Kraume, Martin Matzner Venue: arXiv (2025)\nData-driven analysis of business processes has a long tradition in research. However, recently the term of process mining is mostly used when referring to data-driven process analysis. As a consequence, awareness for the many facets of process analysis is decreasing. In particular, while an increasing focus is put onto technical aspects of the analysis, human and organisational concerns remain under the radar. Following the socio-technical perspective of information systems research, we propose a new perspective onto data-driven process analysis that combines the process of analysis with the organisation and its stakeholders. This paper conceptualises the term process analytics and its various dimensions by following both an inductive and deductive approach. The results are discussed by contrasting them to a real-life case study from a large company implementing data-driven process analysis and automation.\nüìÑ Download PDF\nüîç psycholinguistics Mixing time of the random walk on the giant component of the random geometric graph Authors: Magnus H. Haaland, Anƒëela ≈†arkoviƒá Venue: arXiv (2025)\nWe consider a random geometric graph obtained by placing a Poisson point process of intensity 1 in the d-dimensional torus of side length n^(1/d) and connecting two points by an edge if their distance is at most r. We consider the case of d\u003e=2 and r in [r_min, r_max], where r_minr_g and r_g is a constant above which this graph has a giant component with high probability. We show that, with high probability, the mixing time and the relaxation time of the simple random walk on the giant component in this case are both of order n^(2/d) and that therefore there is no cutoff. We also obtain bounds for the isoperimetric profile of subsets of the giant component of at least polylogarithmic size.\nüìÑ Download PDF\nDoes the Data Processing Inequality Reflect Practice? On the Utility of Low-Level Tasks Authors: Roy Turgeman, Tom Tirer Venue: arXiv (2025)\nThe data processing inequality is an information-theoretic principle stating that the information content of a signal cannot be increased by processing the observations. In particular, it suggests that there is no benefit in enhancing the signal or encoding it before addressing a classification problem. This assertion can be proven to be true for the case of the optimal Bayes classifier. However, in practice, it is common to perform ‚Äúlow-level‚Äù tasks before ‚Äúhigh-level‚Äù downstream tasks despite the overwhelming capabilities of modern deep neural networks. In this paper, we aim to understand when and why low-level processing can be beneficial for classification. We present a comprehensive theoretical study of a binary classification setup, where we consider a classifier that is tightly connected to the optimal Bayes classifier and converges to it as the number of training samples increases. We prove that for any finite number of training samples, there exists a pre-classification processing that improves the classification accuracy. We also explore the effect of class separation, training set size, and class balance on the relative gain from this procedure. We support our theory with an empirical investigation of the theoretical setup. Finally, we conduct an empirical study where we investigate the effect of denoising and encoding on the performance of practical deep classifiers on benchmark datasets. Specifically, we vary the size and class distribution of the training set, and the noise level, and demonstrate trends that are consistent with our theoretical results.\nüìÑ Download PDF\nCoding-Logic Correspondence: Turning Information and Communication Networks into Logical Formulae via Hypergraph Heyting Algebra Authors: Cheuk Ting Li Venue: arXiv (2025)\nWe propose using confusion hypergraphs (hyperconfusions) as a model of information. In contrast to the conventional approach using random variables, we can now perform conjunction, disjunction and implication of information, forming a Heyting algebra. Using the connection between Heyting algebra and intuitionistic logic, we can express the requirements of a communication network (e.g., network coding, index coding, Slepian-Wolf coding) as a logical formula, allowing us to use the hypergraph Heyting algebra to directly compute the optimal coding scheme. The optimal communication cost is simply given by the entropy of the hypergraph (within a logarithmic gap). This gives a surprising correspondence between coding settings and logical formulae, similar to the Curry-Howard correspondence between proofs and computer programs.\nüìÑ Download PDF\nSpatialTree: How Spatial Abilities Branch Out in MLLMs Authors: Yuxi Xiao, Longfei Li, Shen Yan, Xinhang Liu, Sida Peng, Yunchao Wei, Xiaowei Zhou, Bingyi Kang Venue: arXiv (2025)\nCognitive science suggests that spatial ability develops progressively-from perception to reasoning and interaction. Yet in multimodal LLMs (MLLMs), this hierarchy remains poorly understood, as most studies focus on a narrow set of tasks. We introduce SpatialTree, a cognitive-science-inspired hierarchy that organizes spatial abilities into four levels: low-level perception (L1), mental mapping (L2), simulation (L3), and agentic competence (L4). Based on this taxonomy, we construct the first capability-centric hierarchical benchmark, thoroughly evaluating mainstream MLLMs across 27 sub-abilities. The evaluation results reveal a clear structure: L1 skills are largely orthogonal, whereas higher-level skills are strongly correlated, indicating increasing interdependency. Through targeted supervised fine-tuning, we uncover a surprising transfer dynamic-negative transfer within L1, but strong cross-level transfer from low- to high-level abilities with notable synergy. Finally, we explore how to improve the entire hierarchy. We find that naive RL that encourages extensive ‚Äúthinking‚Äù is unreliable: it helps complex reasoning but hurts intuitive perception. We propose a simple auto-think strategy that suppresses unnecessary deliberation, enabling RL to consistently improve performance across all levels. By building SpatialTree, we provide a proof-of-concept framework for understanding and systematically scaling spatial abilities in MLLMs.\nüìÑ Download PDF\nUniform spanning trees and random matrix statistics Authors: Nathana√´l Berestycki, Marcin Lis, Mingchang Liu, Eveliina Peltola Venue: arXiv (2025)\nWe consider a uniform spanning tree in a $Œ¥$-square grid approximation of a planar domain $Œ©$. For given integer $n\\ge 2$, we condition the tree on the following $n$-arm event: we pick $n$ branches, emanating from $n$ points microscopically close to a given interior point, and condition them to connect to the boundary $\\partial Œ©$ without intersecting. What can be said about the geometry of these branches? We derive an exact formula for the characteristic function of the total winding of the branches. A surprising consequence of this formula is that in the scaling limit, the behaviour of this function depends on the total number of branches $n$ only through its parity. We also describe the scaling limit of the branches. If $Œ©$ is the unit disc, then they hit the boundary (i.e., the unit circle) at random positions which coincide exactly with the eigenvalues of a random matrix of size $n$ drawn from the Circular Orthogonal Ensemble (COE, also called C$Œ≤$E with $Œ≤=1$). Furthermore, the branches converge to Loewner evolution driven by the circular Dyson Brownian motion with parameter $Œ≤= 4$ (i.e., $n$-sided radial SLE$_Œ∫$ with $Œ∫=2$). We thus verify a prediction made by Cardy in this setting. Along the way, we develop a flow-line (imaginary geometry) coupling of $n$-sided radial SLE$_Œ∫$ with the Gaussian free field, which may be of independent interest. Surprisingly, we find that the variance of the corresponding field near the singularity also does not depend on the number $n\\ge 2$ of curves. In contrast, the variance of the the winding of the curves behaves as $Œ∫/n^2$, which agrees with the predictions from the physics literature made by Wieland and Wilson numerically, and by Duplantier and Binder using Coulomb gas methods ‚Äì but disagrees with a result of Kenyon.\nüìÑ Download PDF\nNumerical Analysis of Test Optimality Authors: Philipp Ketz, Adam McCloskey, Jan Scherer Venue: arXiv (2025)\nIn nonstandard testing environments, researchers often derive ad hoc tests with correct (asymptotic) size, but their optimality properties are typically unknown a priori and difficult to assess. This paper develops a numerical framework for determining whether an ad hoc test is effectively optimal - approximately maximizing a weighted average power criterion for some weights over the alternative and attaining a power envelope generated by a single weighted average power-maximizing test. Our approach uses nested optimization algorithms to approximate the weight function that makes an ad hoc test‚Äôs weighted average power as close as possible to that of a true weighted average power-maximizing test, and we show the surprising result that the rejection probabilities corresponding to the latter form an approximate power envelope for the former. We provide convergence guarantees, discuss practical implementation and apply the method to the weak instrument-robust conditional likelihood ratio test and a recently-proposed test for when a nuisance parameter may be on or near its boundary.\nüìÑ Download PDF\nYang-Mills energy quantization over non-collapsed degenerating Einstein manifolds and applications Authors: Youmin Chen, Miaomiao Zhu Venue: arXiv (2025)\nWe investigate a sequence of Yang-Mills connections $A_j$ lying in vector bundles $E_j$ over non-collapsed degenerating closed Einstein 4-manifolds $(M_j, g_ j)$ with uniformly bounded Einstein constants and bounded diameters. We establish a compactness theory modular three types of bubbles. As applications, we get some quantization results for several important topological number associated with the vector bundles, for instance, the first Pontrjagin numbers $p_1(E)$ of vector bundles over Einstein 4-manifolds and the Euler numbers $œá(M;E)$ of holomorphic vector bundles over K√§hler-Einstein surfaces. Furthermore, we get some quantization results about the volume $v(L_j)$ and certain cohomological numbers (e.g. $dim H^0(M_j;L_j)$) of holomorphic line bundles $L_j$ over non-collapsed degenerating K√§hler-Einstein surfaces $(M_j,J_j,g_j)$ with the aid of the classical vanishing theorems, the classical Hirzebruch-Riemann-Roch type theorems, and the profound convergence theory of K√§hler-Einstein manifolds. In particular, we obtain some interesting identities involving non-collapsed degenerating compact K√§hler-Einstein surfaces with non-zero scalar curvature, which indicate that we can know the Euler number of $M_j$ for large $j$ provided some topological information of the limit orbifold $M_\\infty$. For K√§hler-Einstein Del Pezzo surfaces, an interesting implication is that we can provide some preliminary estimates for the number of singularities of various types in $M_\\infty$ in an effective way. As an unexpected surprise, we find an identity which connects Milnor numbers for singularities in $M_\\infty$ and the correction terms in the Hirzebruch-Riemann-Roch theorem for orbifolds. Some quantization results can be extended to the case of higher dimensional $n$-manifolds.\nüìÑ Download PDF\nCharacterizing quantum synchronization in the van der Pol oscillator via tomogram and photon correlation Authors: Kingshuk Adhikary, K. M. Athira, M. Rohith Venue: arXiv (2025)\nWe access the quantum synchronization (QS) in the steady state of a driven quantum van der Pol oscillator (vdPo) using two distinct figures of merit: (i) the nonclassical area $Œ¥$ and (ii) the second-order correlation function $g^{(2)}(0)$, which are both viable in experimental architectures. The nonclassical area quantifier rooted in homodyne tomography, allows us to assess the nonclassical nature of the vdPo‚Äôs state directly from the tomogram without requiring full state reconstruction or the Wigner function negativity. Within a well-defined parameter regime of drive strength and detuning, both $Œ¥$ and $g^{(2)}(0)$ exhibit pronounced signatures of synchronization that complements the phase coherence between the drive and the vdPo. We derive an analytical expression for the steady-state density matrix and the corresponding tomogram of the system, valid for arbitrary strengths of the harmonic drive. Analysis of the quantum tomogram uncovers clear phase-locking behavior, enabling the identification of the synchronization region (Arnold tongue) directly in terms of experimentally measurable quantities. Furthermore, the behaviour of $g^{(2)}(0)$ provides a statistical perspective that reinforces the tomographic signatures of QS. By analyzing the interplay between these metrics, we can gain more profound insights into the underlying mechanisms that govern QS in such systems.\nüìÑ Download PDF\nImproving the Convergence Rate of Ray Search Optimization for Query-Efficient Hard-Label Attacks Authors: Xinjie Xu, Shuyu Cheng, Dongwei Xu, Qi Xuan, Chen Ma Venue: arXiv (2025)\nIn hard-label black-box adversarial attacks, where only the top-1 predicted label is accessible, the prohibitive query complexity poses a major obstacle to practical deployment. In this paper, we focus on optimizing a representative class of attacks that search for the optimal ray direction yielding the minimum $\\ell_2$-norm perturbation required to move a benign image into the adversarial region. Inspired by Nesterov‚Äôs Accelerated Gradient (NAG), we propose a momentum-based algorithm, ARS-OPT, which proactively estimates the gradient with respect to a future ray direction inferred from accumulated momentum. We provide a theoretical analysis of its convergence behavior, showing that ARS-OPT enables more accurate directional updates and achieves faster, more stable optimization. To further accelerate convergence, we incorporate surrogate-model priors into ARS-OPT‚Äôs gradient estimation, resulting in PARS-OPT with enhanced performance. The superiority of our approach is supported by theoretical guarantees under standard assumptions. Extensive experiments on ImageNet and CIFAR-10 demonstrate that our method surpasses 13 state-of-the-art approaches in query efficiency.\nüìÑ Download PDF\nCasting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking Authors: Yifan Huang, Xiaojun Jia, Wenbo Guo, Yuqiang Sun, Yihao Huang, Chong Wang, Yang Liu Venue: arXiv (2025)\nLarge language models (LLMs) have revolutionized software development through AI-assisted coding tools, enabling developers with limited programming expertise to create sophisticated applications. However, this accessibility extends to malicious actors who may exploit these powerful tools to generate harmful software. Existing jailbreaking research primarily focuses on general attack scenarios against LLMs, with limited exploration of malicious code generation as a jailbreak target. To address this gap, we propose SPELL, a comprehensive testing framework specifically designed to evaluate the weakness of security alignment in malicious code generation. Our framework employs a time-division selection strategy that systematically constructs jailbreaking prompts by intelligently combining sentences from a prior knowledge dataset, balancing exploration of novel attack patterns with exploitation of successful techniques. Extensive evaluation across three advanced code models (GPT-4.1, Claude-3.5, and Qwen2.5-Coder) demonstrates SPELL‚Äôs effectiveness, achieving attack success rates of 83.75%, 19.38%, and 68.12% respectively across eight malicious code categories. The generated prompts successfully produce malicious code in real-world AI development tools such as Cursor, with outputs confirmed as malicious by state-of-the-art detection systems at rates exceeding 73%. These findings reveal significant security gaps in current LLM implementations and provide valuable insights for improving AI safety alignment in code generation applications.\nüìÑ Download PDF\nRoboCade: Gamifying Robot Data Collection Authors: Suvir Mirchandani, Mia Tang, Jiafei Duan, Jubayer Ibn Hamid, Michael Cho, Dorsa Sadigh Venue: arXiv (2025)\nImitation learning from human demonstrations has become a dominant approach for training autonomous robot policies. However, collecting demonstration datasets is costly: it often requires access to robots and needs sustained effort in a tedious, long process. These factors limit the scale of data available for training policies. We aim to address this scalability challenge by involving a broader audience in a gamified data collection experience that is both accessible and motivating. Specifically, we develop a gamified remote teleoperation platform, RoboCade, to engage general users in collecting data that is beneficial for downstream policy training. To do this, we embed gamification strategies into the design of the system interface and data collection tasks. In the system interface, we include components such as visual feedback, sound effects, goal visualizations, progress bars, leaderboards, and badges. We additionally propose principles for constructing gamified tasks that have overlapping structure with useful downstream target tasks. We instantiate RoboCade on three manipulation tasks ‚Äì including spatial arrangement, scanning, and insertion. To illustrate the viability of gamified robot data collection, we collect a demonstration dataset through our platform, and show that co-training robot policies with this data can improve success rate on non-gamified target tasks (+16-56%). Further, we conduct a user study to validate that novice users find the gamified platform significantly more enjoyable than a standard non-gamified platform (+24%). These results highlight the promise of gamified data collection as a scalable, accessible, and engaging method for collecting demonstration data.\nüìÑ Download PDF\nProximal Survival Analysis for Dependent Left Truncation Authors: Yuyao Wang, Andrew Ying, Ronghui Xu Venue: arXiv (2025)\nIn prevalent cohort studies with delayed entry, time-to-event outcomes are often subject to left truncation where only subjects that have not experienced the event at study entry are included, leading to selection bias. Existing methods for handling left truncation mostly rely on the (quasi-)independence assumption or the weaker conditional (quasi-)independence assumption which assumes that conditional on observed covariates, the left truncation time and the event time are independent on the observed region. In practice, however, our analysis of the Honolulu Asia Aging Study (HAAS) suggests that the conditional quasi-independence assumption may fail because measured covariates often serve only as imperfect proxies for the underlying mechanisms, such as latent health status, that induce dependence between truncation and event times. To address this gap, we propose a proximal weighting identification framework that admits the dependence-inducing factors may not be fully observed. We then construct an estimator based on the framework and study its asymptotic properties. We examine the finite sample performance of the proposed estimator by comprehensive simulations, and apply it to analyzing the cognitive impairment-free survival probabilities using data from the Honolulu Asia Aging Study.\nüìÑ Download PDF\nAssessing the Software Security Comprehension of Large Language Models Authors: Mohammed Latif Siddiq, Natalie Sekerak, Antonio Karam, Maria Leal, Arvin Islam-Gomes, Joanna C. S. Santos Venue: arXiv (2025)\nLarge language models (LLMs) are increasingly used in software development, but their level of software security expertise remains unclear. This work systematically evaluates the security comprehension of five leading LLMs: GPT-4o-Mini, GPT-5-Mini, Gemini-2.5-Flash, Llama-3.1, and Qwen-2.5, using Blooms Taxonomy as a framework. We assess six cognitive dimensions: remembering, understanding, applying, analyzing, evaluating, and creating. Our methodology integrates diverse datasets, including curated multiple-choice questions, vulnerable code snippets (SALLM), course assessments from an Introduction to Software Security course, real-world case studies (XBOW), and project-based creation tasks from a Secure Software Engineering course. Results show that while LLMs perform well on lower-level cognitive tasks such as recalling facts and identifying known vulnerabilities, their performance degrades significantly on higher-order tasks that require reasoning, architectural evaluation, and secure system creation. Beyond reporting aggregate accuracy, we introduce a software security knowledge boundary that identifies the highest cognitive level at which a model consistently maintains reliable performance. In addition, we identify 51 recurring misconception patterns exhibited by LLMs across Blooms levels.\nüìÑ Download PDF\nActive inference and artificial reasoning Authors: Karl Friston, Lancelot Da Costa, Alexander Tschantz, Conor Heins, Christopher Buckley, Tim Verbelen, Thomas Parr Venue: arXiv (2025)\nThis technical note considers the sampling of outcomes that provide the greatest amount of information about the structure of underlying world models. This generalisation furnishes a principled approach to structure learning under a plausible set of generative models or hypotheses. In active inference, policies - i.e., combinations of actions - are selected based on their expected free energy, which comprises expected information gain and value. Information gain corresponds to the KL divergence between predictive posteriors with, and without, the consequences of action. Posteriors over models can be evaluated quickly and efficiently using Bayesian Model Reduction, based upon accumulated posterior beliefs about model parameters. The ensuing information gain can then be used to select actions that disambiguate among alternative models, in the spirit of optimal experimental design. We illustrate this kind of active selection or reasoning using partially observed discrete models; namely, a ‚Äôthree-ball‚Äô paradigm used previously to describe artificial insight and ‚Äòaha moments‚Äô via (synthetic) introspection or sleep. We focus on the sample efficiency afforded by seeking outcomes that resolve the greatest uncertainty about the world model, under which outcomes are generated.\nüìÑ Download PDF\nA Design Study Process Model for Medical Visualization Authors: Mengjie Fan, Liang Zhou Venue: arXiv (2025)\nWe introduce a design study process model for medical visualization based on the analysis of existing medical visualization and visual analysis works, and our own interdisciplinary research experience. With a literature review of related works covering various data types and applications, we identify features of medical visualization and visual analysis research and formulate our model thereafter. Compared to previous design study process models, our new model emphasizes: distinguishing between different stakeholders and target users before initiating specific designs, distinguishing design stages according to analytic logic or cognitive habits, and classifying task types as inferential or descriptive, and further hypothesis-based or hypothesis-free based on whether they involve multiple subgroups. In addition, our model refines previous models according to the characteristics of medical problems and provides referable guidance for each step. These improvements make the visualization design targeted, generalizable, and operational, which can adapt to the complexity and diversity of medical problems. We apply this model to guide the design of a visual analysis method and reanalyze three medical visualization-related works. These examples suggest that the new process model can provide a systematic theoretical framework and practical guidance for interdisciplinary medical visualization research. We give recommendations that future researchers can refer to, report on reflections on the model, and delineate it from existing models.\nüìÑ Download PDF\nAegisAgent: An Autonomous Defense Agent Against Prompt Injection Attacks in LLM-HARs Authors: Yihan Wang, Huanqi Yang, Shantanu Pal, Weitao Xu Venue: arXiv (2025)\nThe integration of Large Language Models (LLMs) into wearable sensing is creating a new class of mobile applications capable of nuanced human activity understanding. However, the reliability of these systems is critically undermined by their vulnerability to prompt injection attacks, where attackers deliberately input deceptive instructions into LLMs. Traditional defenses, based on static filters and rigid rules, are insufficient to address the semantic complexity of these new attacks. We argue that a paradigm shift is needed ‚Äì from passive filtering to active protection and autonomous reasoning. We introduce AegisAgent, an autonomous agent system designed to ensure the security of LLM-driven HAR systems. Instead of merely blocking threats, AegisAgent functions as a cognitive guardian. It autonomously perceives potential semantic inconsistencies, reasons about the user‚Äôs true intent by consulting a dynamic memory of past interactions, and acts by generating and executing a multi-step verification and repair plan. We implement AegisAgent as a lightweight, full-stack prototype and conduct a systematic evaluation on 15 common attacks with five state-of-the-art LLM-based HAR systems on three public datasets. Results show it reduces attack success rate by 30% on average while incurring only 78.6 ms of latency overhead on a GPU workstation. Our work makes the first step towards building secure and trustworthy LLM-driven HAR systems.\nüìÑ Download PDF\nInformation-Backed Currency (IBC): Designing a Resilient, Transparent, and Information-Centric Monetary Ecosystem Authors: Lalit Kumar Shukla Venue: arXiv (2025)\nThe accelerating digitization of economic activity has made information a dominant driver of market expectations, coordination, and systemic risk. Yet contemporary monetary systems remain anchored in architectures designed for material scarcity, institutional authority, or cryptographic constraint, leaving them increasingly misaligned with information-driven economies. This conceptual paper proposes Information-Backed Currency (IBC) as a monetary framework in which verified, high-integrity information functions as the primary source of value creation and monetary stability. Drawing on insights from econophysics, information theory, and cognitive economics, the paper advances the proposition that economic value emerges when information measurably reduces uncertainty within complex systems. Building on this premise, the study develops an architectural model in which currency issuance is linked to quantified entropy reduction achieved through multi-path information verification, reproducibility assessment, and contextual validation. An ethical governance layer, termed the Dharma Protocol, is introduced to ensure that only socially stabilizing, non-manipulative information qualifies as currency-backing input. The proposed IBC architecture comprises four interdependent layers: information ingestion, verification and validation, ethical oversight, and monetization through a Verification Value Unit tied to uncertainty reduction. While the framework is intentionally conceptual and non-empirical, it offers a coherent blueprint for re-imagining monetary governance in an era characterized by information abundance, cognitive constraints, and systemic fragility.\nüìÑ Download PDF\nEnhancing Grid Resilience for Giga-Watt Scale Data Centers Using High Voltage Circuit Breaker Operated Braking Resistors Authors: Soham Ghosh, Mohammad Ashraf Hossain Sadi Venue: arXiv (2025)\nAs hyperscale and co-located data centers scale, the electric grid sees an increase in large, voltage-sensitive IT loads with these data center plant size ranging between 500 MW to 2 GW. A sudden loss of these loads as they switch to onsite UPS during grid voltage excursion events causes a grid frequency rise from generation and load imbalance, and a voltage rise because less power is flowing through the network. This paper proposes and theoretically demonstrates the use of high voltage circuit breaker operated braking resistors at data center transmission substations as an effective strategy in enhancing grid resilience under such large load loss scenarios. We developed a test bed to illustrate the dynamic behavior of the system with resistive braking on a gigawatt scale data center load cluster connected to a 345 kV network. The braking resistor(s), which in the case of inverter rich system comes in a multi-stage configuration, are connected or disconnected via high-speed circuit breaker(s). Results show that insertion for 0.25 to 0.85 seconds sufficiently reduce rate of change of frequency and provides time for primary governor response and capacitor switching to restore steady state. Sensitivity across different synchronous machines and inverter-based resource mix are tested and confirms robustness. We conclude circuit breaker controlled resistive braking is a practical means to enhance Bulk Electric System (BES) resilience for gigawatt scale data centers. The approach integrates with protection, needs no generator changes, and can be scaled with cluster size or growth of the data center facility load.\nüìÑ Download PDF\nWireless Center of Pressure Feedback System for Humanoid Robot Balance Control using ESP32-C3 Authors: Muhtadin, Faris Rafi Pramana, Dion Hayu Fandiantoro, Moh Ismarintan Zazuli, Atar Fuady Babgei Venue: arXiv (2025)\nMaintaining stability during the single-support phase is a fundamental challenge in humanoid robotics, particularly in dance robots that require complex maneuvers and high mechanical freedom. Traditional tethered sensor configurations often restrict joint movement and introduce mechanical noises. This study proposes a wireless embedded balance system designed to maintain stability on uneven surfaces. The system utilizes a custom-designed foot unit integrated with four load cells and an ESP32-C3 microcontroller to estimate the Center of Pressure (CoP) in real time. The CoP data were transmitted wirelessly to the main controller to minimize the wiring complexity of the 29-DoF VI-ROSE humanoid robot. A PID control strategy is implemented to adjust the torso, hip, and ankle roll joints based on CoP feedback. Experimental characterization demonstrated high sensor precision with an average measurement error of 14.8 g. Furthermore, the proposed control system achieved a 100% success rate in maintaining balance during single-leg lifting tasks at a 3-degree inclination with optimized PID parameters (Kp=0.10, Kd=0.005). These results validate the efficacy of wireless CoP feedback in enhancing the postural stability of humanoid robots, without compromising their mechanical flexibility.\nüìÑ Download PDF\nAll-optical control and multiplexed readout of multiple superconducting qubits Authors: Xiaoxuan Pan, Chuanlong Ma, Jia-Qi Wang, Zheng-Xu Zhu, Linze Li, Jiajun Chen, Yuan-Hao Yang, Yilong Zhou, Jia-Hua Zou, Xin-Biao Xu, Weiting Wang, Baile Chen, Haifeng Yu, Chang-Ling Zou, Luyan Sun Venue: arXiv (2025)\nSuperconducting quantum circuits operate at millikelvin temperatures, typically requiring independent microwave cables for each qubit for connecting room-temperature control and readout electronics. However, scaling to large-scale processors hosting hundreds of qubits faces a severe input/output (I/O) bottleneck, as the dense cable arrays impose prohibitive constraints on physical footprint, thermal load, wiring complexity, and cost. Here we demonstrate a complete optical I/O architecture for superconducting quantum circuits, in which all control and readout signals are transmitted exclusively via optical photons. Employing a broadband traveling-wave Brillouin microwave-to-optical transducer, we achieve simultaneous frequency-multiplexed optical readout of two qubits. Combined with fiber-integrated photodiode arrays for control signal delivery, this closed-loop optical I/O introduces no measurable degradation to qubit coherence times, with an optically driven single-qubit gate fidelity showing only a 0.19% reduction relative to standard microwave operation. These results establish optical interconnects as a viable path toward large-scale superconducting quantum processors, and open the possibility of networking multiple superconducting quantum computers housed in separate dilution refrigerators through a centralized room-temperature control infrastructure.\nüìÑ Download PDF\nShared Representation Learning for High-Dimensional Multi-Task Forecasting under Resource Contention in Cloud-Native Backends Authors: Zixiao Huang, Jixiao Yang, Sijia Li, Chi Zhang, Jinyu Chen, Chengda Xu Venue: arXiv (2025)\nThis study proposes a unified forecasting framework for high-dimensional multi-task time series to meet the prediction demands of cloud native backend systems operating under highly dynamic loads, coupled metrics, and parallel tasks. The method builds a shared encoding structure to represent diverse monitoring indicators in a unified manner and employs a state fusion mechanism to capture trend changes and local disturbances across different time scales. A cross-task structural propagation module is introduced to model potential dependencies among nodes, enabling the model to understand complex structural patterns formed by resource contention, link interactions, and changes in service topology. To enhance adaptability to non-stationary behaviors, the framework incorporates a dynamic adjustment mechanism that automatically regulates internal feature flows according to system state changes, ensuring stable predictions in the presence of sudden load shifts, topology drift, and resource jitter. The experimental evaluation compares multiple models across various metrics and verifies the effectiveness of the framework through analyses of hyperparameter sensitivity, environmental sensitivity, and data sensitivity. The results show that the proposed method achieves superior performance on several error metrics and provides more accurate representations of future states under different operating conditions. Overall, the unified forecasting framework offers reliable predictive capability for high-dimensional, multi-task, and strongly dynamic environments in cloud native systems and provides essential technical support for intelligent backend management.\nüìÑ Download PDF\nüîç llm Optimizing Quantum State Transformation Under Locality Constraint Authors: Sasan Sarbishegi, Maryam Sadat Mirkamali Venue: arXiv (2025)\nIn this paper, we present a general numerical framework for both deterministic and probabilistic quantum state transformations, under locality constraints. For a given arbitrary bipartite initial state and a desired bipartite target state, we construct an optimized local quantum channel that transforms the initial state into the target state with high fidelity. To achieve this goal, local quantum channels are parametrized on a complex Stiefel manifold and optimized using gradient-based methods. We demonstrate that this approach significantly enhances entanglement distillation for weakly entangled states via two complementary strategies: optimized local state transformation and probabilistic local transformation. These results establish our method as a powerful and versatile tool for a broad class of quantum information processing tasks.\nüìÑ Download PDF\nObservation of the Aharonov-Bohm Effect in Pilot-Wave Hydrodynamics Authors: Georgi Gary Rozenman, Kyle I. McKee, Arnaud Lazarus, Valeri Frumkin, John W M Bush Venue: arXiv (2025)\nWe report the results of an experimental study of an analog of the Aharonov-Bohm (AB) effect achieved with the hydrodynamic pilot-wave system. A walking droplet is confined to an annular cavity that encircles a shielded vortex, but lies outside its range of direct influence. While there is no vortex-induced flow in the immediate vicinity of the droplets, the vortex modifies the droplet‚Äôs spatially extended pilot-wave field that guides its motion, producing a vortex-dependent bias in the droplet‚Äôs orbital speed. High-speed tracking and delay-embedding reconstructions yield Wigner-like phase-space distributions for this hydrodynamic system that exhibits a rigid, flux-dependent translation, providing a force-free, gauge-like realization of an AB-type phase.\nüìÑ Download PDF\nNeural Network-Assisted RIS Weight Optimization for Spatial Nulling in Distorted Reflector Antenna Systems Authors: Xinrui Li, R. Michael Buehrer Venue: arXiv (2025)\nReconfigurable intelligent surfaces (RIS) have recently been proposed as an effective means for spatial interference suppression in large reflector antenna systems. Existing RIS weight optimization algorithms typically rely on accurate theoretical radiation models. However, in practice, distortions on the reflector antenna may cause mismatches between the theoretical and true antenna patterns, leading to degraded interference cancellation performance when these weights are directly applied. In this report, a residual learning network-assisted simulated annealing (ResNet-SA) framework is proposed to address this mismatch without requiring explicit knowledge of the distorted electric field. By learning the residual difference between the theoretical and true antenna gains, a neural network (NN) is embedded in a heuristic optimization algorithm to find the optimal weight vector. Simulation results demonstrate that the proposed approach achieves improved null depth in the true radiation pattern as compared with conventional methods that optimize weights based solely on the theoretical model, validating the effectiveness of the ResNet-SA algorithm for reflector antenna systems with approximate knowledge of the pattern.\nüìÑ Download PDF\nScaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Consulting, Data Analyst, and Management Tasks Authors: Ali Merali Venue: arXiv (2025)\nThis paper derives `Scaling Laws for Economic Impacts‚Äô ‚Äì empirical relationships between the training compute of Large Language Models (LLMs) and professional productivity. In a preregistered experiment, over 500 consultants, data analysts, and managers completed professional tasks using one of 13 LLMs. We find that each year of AI model progress reduced task time by 8%, with 56% of gains driven by increased compute and 44% by algorithmic progress. However, productivity gains were significantly larger for non-agentic analytical tasks compared to agentic workflows requiring tool use. These findings suggest continued model scaling could boost U.S. productivity by approximately 20% over the next decade.\nüìÑ Download PDF\nüîç neuroscience AndroidLens: Long-latency Evaluation with Nested Sub-targets for Android GUI Agents Authors: Yue Cao, Yingyao Wang, Pi Bu, Jingxuan Xing, Wei Jiang, Zekun Zhu, Junpeng Ma, Sashuai Zhou, Tong Lu, Jun Song, Yu Cheng, Yuning Jiang, Bo Zheng Venue: arXiv (2025)\nGraphical user interface (GUI) agents can substantially improve productivity by automating frequently executed long-latency tasks on mobile devices. However, existing evaluation benchmarks are still constrained to limited applications, simple tasks, and coarse-grained metrics. To address this, we introduce AndroidLens, a challenging evaluation framework for mobile GUI agents, comprising 571 long-latency tasks in both Chinese and English environments, each requiring an average of more than 26 steps to complete. The framework features: (1) tasks derived from real-world user scenarios across 38 domains, covering complex types such as multi-constraint, multi-goal, and domain-specific tasks; (2) static evaluation that preserves real-world anomalies and allows multiple valid paths to reduce bias; and (3) dynamic evaluation that employs a milestone-based scheme for fine-grained progress measurement via Average Task Progress (ATP). Our evaluation indicates that even the best models reach only a 12.7% task success rate and 50.47% ATP. We also underscore key challenges in real-world environments, including environmental anomalies, adaptive exploration, and long-term memory retention.\nüìÑ Download PDF\nQuadrupped-Legged Robot Movement Plan Generation using Large Language Model Authors: Muhtadin, Vincentius Gusti Putu A. B. M., Ahmad Zaini, Mauridhi Hery Purnomo, I Ketut Eddy Purnama, Chastine Fatichah Venue: arXiv (2025)\nTraditional control interfaces for quadruped robots often impose a high barrier to entry, requiring specialized technical knowledge for effective operation. To address this, this paper presents a novel control framework that integrates Large Language Models (LLMs) to enable intuitive, natural language-based navigation. We propose a distributed architecture where high-level instruction processing is offloaded to an external server to overcome the onboard computational constraints of the DeepRobotics Jueying Lite 3 platform. The system grounds LLM-generated plans into executable ROS navigation commands using real-time sensor fusion (LiDAR, IMU, and Odometry). Experimental validation was conducted in a structured indoor environment across four distinct scenarios, ranging from single-room tasks to complex cross-zone navigation. The results demonstrate the system‚Äôs robustness, achieving an aggregate success rate of over 90% across all scenarios, validating the feasibility of offloaded LLM-based planning for autonomous quadruped deployment in real-world settings.\nüìÑ Download PDF\nNavier-Stokes-Cahn-Hilliard system in a $3$D perforated domain with free slip and source term: Existence and homogenization Authors: Amartya Chakrabortty, Haradhan Dutta, Hari Shankar Mahato Venue: arXiv (2025)\nWe study a diffuse-interface model for a binary incompressible mixture in a periodically perforated porous medium, described by a time-dependent Navier-Stokes-Cahn-Hilliard (NSCH) system posed on the pore domain $Œ©_p^\\varepsilon\\subset\\mathbb{R}^3$. The microscopic model involves a variable viscosity tensor, a non-conservative source term in the Cahn‚ÄìHilliard equation, and mixed boundary conditions: no-slip on the outer boundary and Navier slip with zero tangential stress on the surfaces of the solid inclusions. The capillarity strength $Œª^\\varepsilon\u003e0$ depends on the microscopic scale $\\varepsilon\u003e0$. The analysis consists of two main parts. First, for each fixed $\\varepsilon\u003e0$, we prove the existence of a weak solution on a finite time interval $(0,T)$ and derive a priori estimates that are uniform with respect to $\\varepsilon$ (and $Œª^\\varepsilon$). Second, we perform the periodic homogenization for the perforated setting, a limit $\\varepsilon\\to0$. Depending on the limit value $Œª$ of the capillarity strength $Œª^\\varepsilon$, we obtain two distinct effective models: (i) in the vanishing capillarity regime $Œª=0$, the limit system is of Stokes-Cahn-Hilliard type, with no macroscopic convection or advection; (ii) in the balanced regime $Œª\\in(0,+\\infty)$, we derive a Navier-Stokes-Cahn-Hilliard system with nonlinear convection and advective transport of the phase field at the macroscopic scale. Finally, we establish the convergence of the microscopic free energy to a homogenized energy functional satisfying an analogous dissipation law.\nüìÑ Download PDF\nTopological Interface States and Nonlinear Thermoelectric Performance in Armchair Graphene Nanoribbon Heterostructures Authors: David M T Kuo Venue: arXiv (2025)\nWe investigate the emergence and topological nature of interface states (IFs) in N-AGNR/$(N-2)$-AGNR/N-AGNR heterostructure (AGNRH) segments lacking translational symmetry, focusing on their relation to the end states (ESs) of the constituent armchair graphene nanoribbon (AGNR) segments. For AGNRs with $R_1$-type unit cells, the ES numbers under a longitudinal electric field follow the relations $N = N_{A(B)} \\times 6 + 1$ and $N = N_{A(B)} \\times 6 + 3$, whereas $R_2$-type unit cells exhibit $(N_{A(B)} + 1)$ ESs. The subscripts $A$ and $B$ denote the chirality types of the ESs. The Stark effect lifts ES degeneracy and enables clear spectral separation between ESs and IFs. Using a real-space bulk boundary perturbation approach, we show that opposite-chirality states hybridize through junction-site perturbations and may shift out of the bulk gap. The number and chirality of IFs in symmetric AGNRHs are determined by the difference between the ESs of the outer and central segments, $N_O$ and $N_C$, according to $N_{IF,Œ≤} = |N_{O,B(A)} - N_{C,A(B)}|$, where $Œ≤$ labels the chirality. Depending on whether $N_O \u003e N_C$ or $N_C \u003e N_O$, the resulting IFs acquire B- or A-chirality, respectively. Calculated transmission spectra ${\\cal T}_{GNR}(\\varepsilon)$ reveal that AGNRHs host a topological double quantum dot (TDQD) when IFs originate from the ESs of the central AGNR segment. Using an Anderson model with effective intra-dot and inter-dot Coulomb interactions, we derive an analytical expression for the tunneling current through the TDQD via a closed-form transmission coefficient. Thermoelectric analysis shows that TDQDs yield enhanced nonlinear power output in the electron-dilute and hole-dilute charge states, with Coulomb blockade suppressing thermal current but not thermal voltage.\nüìÑ Download PDF\nüîç data_resources Surgical Scene Segmentation using a Spike-Driven Video Transformer with Real-Time Potential Authors: Shihao Zou, Jingjing Li, Wei Ji, Jincai Huang, Kai Wang, Guo Dan, Weixin Si, Yi Pan Venue: arXiv (2025)\nModern surgical systems increasingly rely on intelligent scene understanding to provide timely situational awareness for enhanced intra-operative safety. Within this pipeline, surgical scene segmentation plays a central role in accurately perceiving operative events. Although recent deep learning models, particularly large-scale foundation models, achieve remarkable segmentation accuracy, their substantial computational demands and power consumption hinder real-time deployment in resource-constrained surgical environments. To address this limitation, we explore the emerging SNN as a promising paradigm for highly efficient surgical intelligence. However, their performance is still constrained by the scarcity of labeled surgical data and the inherently sparse nature of surgical video representations. To this end, we propose \\textit{SpikeSurgSeg}, the first spike-driven video Transformer framework tailored for surgical scene segmentation with real-time potential on non-GPU platforms. To address the limited availability of surgical annotations, we introduce a surgical-scene masked autoencoding pretraining strategy for SNNs that enables robust spatiotemporal representation learning via layer-wise tube masking. Building on this pretrained backbone, we further adopt a lightweight spike-driven segmentation head that produces temporally consistent predictions while preserving the low-latency characteristics of SNNs. Extensive experiments on EndoVis18 and our in-house SurgBleed dataset demonstrate that SpikeSurgSeg achieves mIoU comparable to SOTA ANN-based models while reducing inference latency by at least $8\\times$. Notably, it delivers over $20\\times$ acceleration relative to most foundation-model baselines, underscoring its potential for time-critical surgical scene segmentation.\nüìÑ Download PDF\nMarineEval: Assessing the Marine Intelligence of Vision-Language Models Authors: YuK-Kwan Wong, Tuan-An To, Jipeng Zhang, Ziqiang Zheng, Sai-Kit Yeung Venue: arXiv (2025)\nWe have witnessed promising progress led by large language models (LLMs) and further vision language models (VLMs) in handling various queries as a general-purpose assistant. VLMs, as a bridge to connect the visual world and language corpus, receive both visual content and various text-only user instructions to generate corresponding responses. Though great success has been achieved by VLMs in various fields, in this work, we ask whether the existing VLMs can act as domain experts, accurately answering marine questions, which require significant domain expertise and address special domain challenges/requirements. To comprehensively evaluate the effectiveness and explore the boundary of existing VLMs, we construct the first large-scale marine VLM dataset and benchmark called MarineEval, with 2,000 image-based question-answering pairs. During our dataset construction, we ensure the diversity and coverage of the constructed data: 7 task dimensions and 20 capacity dimensions. The domain requirements are specially integrated into the data construction and further verified by the corresponding marine domain experts. We comprehensively benchmark 17 existing VLMs on our MarineEval and also investigate the limitations of existing models in answering marine research questions. The experimental results reveal that existing VLMs cannot effectively answer the domain-specific questions, and there is still a large room for further performance improvements. We hope our new benchmark and observations will facilitate future research. Project Page: http://marineeval.hkustvgd.com/\nüìÑ Download PDF\nBeyond Pixel Simulation: Pathology Image Generation via Diagnostic Semantic Tokens and Prototype Control Authors: Minghao Han, YiChen Liu, Yizhou Liu, Zizhi Chen, Jingqun Tang, Xuecheng Wu, Dingkang Yang, Lihua Zhang Venue: arXiv (2025)\nIn computational pathology, understanding and generation have evolved along disparate paths: advanced understanding models already exhibit diagnostic-level competence, whereas generative models largely simulate pixels. Progress remains hindered by three coupled factors: the scarcity of large, high-quality image-text corpora; the lack of precise, fine-grained semantic control, which forces reliance on non-semantic cues; and terminological heterogeneity, where diverse phrasings for the same diagnostic concept impede reliable text conditioning. We introduce UniPath, a semantics-driven pathology image generation framework that leverages mature diagnostic understanding to enable controllable generation. UniPath implements Multi-Stream Control: a Raw-Text stream; a High-Level Semantics stream that uses learnable queries to a frozen pathology MLLM to distill paraphrase-robust Diagnostic Semantic Tokens and to expand prompts into diagnosis-aware attribute bundles; and a Prototype stream that affords component-level morphological control via a prototype bank. On the data front, we curate a 2.65M image-text corpus and a finely annotated, high-quality 68K subset to alleviate data scarcity. For a comprehensive assessment, we establish a four-tier evaluation hierarchy tailored to pathology. Extensive experiments demonstrate UniPath‚Äôs SOTA performance, including a Patho-FID of 80.9 (51% better than the second-best) and fine-grained semantic control achieving 98.7% of the real-image. The meticulously curated datasets, complete source code, and pre-trained model weights developed in this study will be made openly accessible to the public.\nüìÑ Download PDF\nLearning the Macroeconomic Language Authors: Siddhartha Chib, Fei Tan Venue: arXiv (2025)\nWe show how state-of-the-art large language models (LLMs), seemingly inapplicable to the small samples typical of macroeconomics, can be trained to learn the language of macroeconomy. We estimate a large-scale dynamic stochastic general equilibrium (DSGE) model on an initial segment of the data and obtain a posterior distribution over structural parameters. We sample from this posterior to generate millions of theory-consistent synthetic panels that, when mixed with actual macroeconomic data, form the training corpus for a time-series transformer with attention. The trained model is then used to forecast out-of-sample through 2025. The results show that this hybrid forecaster, which combines the theoretical coherence of DSGE models with the representational power of modern LLMs, successfully learns the macroeconomic language.\nüìÑ Download PDF\nLatent Implicit Visual Reasoning Authors: Kelvin Li, Chuyi Shang, Leonid Karlinsky, Rogerio Feris, Trevor Darrell, Roei Herzig Venue: arXiv (2025)\nWhile Large Multimodal Models (LMMs) have made significant progress, they remain largely text-centric, relying on language as their core reasoning modality. As a result, they are limited in their ability to handle reasoning tasks that are predominantly visual. Recent approaches have sought to address this by supervising intermediate visual steps with helper images, depth maps, or image crops. However, these strategies impose restrictive priors on what ‚Äúuseful‚Äù visual abstractions look like, add heavy annotation costs, and struggle to generalize across tasks. To address this critical limitation, we propose a task-agnostic mechanism that trains LMMs to discover and use visual reasoning tokens without explicit supervision. These tokens attend globally and re-encode the image in a task-adaptive way, enabling the model to extract relevant visual information without hand-crafted supervision. Our approach outperforms direct fine-tuning and achieves state-of-the-art results on a diverse range of vision-centric tasks ‚Äì including those where intermediate abstractions are hard to specify ‚Äì while also generalizing to multi-task instruction tuning.\nüìÑ Download PDF\nArchitectural Trade-offs in Small Language Models Under Compute Constraints Authors: Shivraj Singh Bhatti Venue: arXiv (2025)\nWe present a systematic empirical study of small language models under strict compute constraints, analyzing how architectural choices and training budget interact to determine performance. Starting from a linear next-token predictor, we progressively introduce nonlinearities, self-attention, and multi-layer transformer architectures, evaluating each on character-level modeling of Tiny Shakespeare and word-level modeling of Penn Treebank (PTB) and WikiText-2. We compare models using test negative log-likelihood (NLL), parameter count, and approximate training FLOPs to characterize accuracy-efficiency trade-offs. Our results show that attention-based models dominate MLPs in per-FLOP efficiency even at small scale, while increasing depth or context without sufficient optimization can degrade performance. We further examine rotary positional embeddings (RoPE), finding that architectural techniques successful in large language models do not necessarily transfer to small-model regimes.\nüìÑ Download PDF\nüîç emotion_language Pluricanonical Geometry of Varieties Isogenous to a Product: Chevalley-Weil Theory and Pluricanonical Decompositions of Abelian Covers Authors: Massimiliano Alessandro, Davide Frapporti, Christian Gleissner Venue: arXiv (2025)\nWe study canonical and pluricanonical maps of varieties isogenous to a product of curves, i.e., quotients of the form $ X = (C_1 \\times \\dots \\times C_n)/G $ with $g(C_i)\\ge 2$ and $G$ acting freely. We establish the Chevalley-Weil formula for pluricanonical representations of a curve with a finite group action and a decomposition theorem for pluricanonical systems of abelian covers. These tools allow an explicit study of geometric properties of $X$, such as base loci and the birationality of pluricanonical maps. For threefolds isogenous to a product, we prove that the 4-canonical map is birational for $p_g \\ge 5$ and construct an example attaining the maximal canonical degree for this class of threefolds. In this example, the canonical map is the normalization of its image, which admits isolated non-normal singularities. Computational classifications also reveal threefolds where the bicanonical map fails to be birational, even in the absence of genus-2 fibrations. This illustrates an interesting phenomenon similar to the non-standard case for surfaces.\nüìÑ Download PDF\nMultivariate scaling of proton and ion energies, divergence, and charge states in Target Normal Sheath Acceleration Authors: Vasiliki E. Alexopoulou Venue: arXiv (2025)\nThe interaction of an intense laser pulse with a solid target produces energetic proton and ion beams through the Target Normal Sheath Acceleration (TNSA) mechanism. Such beams are under active investigation for applications in proton beam therapy, materials modification, and nuclear and high-energy-density physics. Despite extensive experimental and theoretical effort, predictive correlations between laser and target parameters and the resulting ion-beam properties remain an open research question, owing to the intrinsically multiphysics and strongly coupled nature of laser-plasma interactions. Here, we employ our unified multiphysics model that reproduces laser-solid interaction dynamics with accuracy exceeding 95% over a broad range of short- and ultrashort-pulse conditions. Using this model, we derive statistically validated scaling laws and probability maps that correlate proton, carbon, and oxygen ion cutoff energies, beam divergences, and ionization states to a wide set of laser and target parameters, including pulse duration, laser power, laser beam spot, target thickness, prepulse-main pulse interval, contrast, laser wavelength, and polarization. Continuous beam properties (cutoff energies and beam divergences) are described using multivariate regression with cross-validation, while discrete ionization states are analyzed using classification and regression tree (CART) methods, enabling nonlinear and threshold-dependent behavior to be captured. The resulting scaling relations, contour maps, and box plots elucidate the coupled roles of laser pulse, and target geometry in governing TNSA ion acceleration and charge-state formation. These results provide a predictive and physically interpretable framework for understanding and optimizing laser-driven ion sources across a wide parameter space.\nüìÑ Download PDF\nA Unified Framework for EEG Seizure Detection Using Universum-Integrated Generalized Eigenvalues Proximal Support Vector Machine Authors: Yogesh Kumar, Vrushank Ahire, M. A. Ganaie Venue: arXiv (2025)\nThe paper presents novel Universum-enhanced classifiers: the Universum Generalized Eigenvalue Proximal Support Vector Machine (U-GEPSVM) and the Improved U-GEPSVM (IU-GEPSVM) for EEG signal classification. Using the computational efficiency of generalized eigenvalue decomposition and the generalization benefits of Universum learning, the proposed models address critical challenges in EEG analysis: non-stationarity, low signal-to-noise ratio, and limited labeled data. U-GEPSVM extends the GEPSVM framework by incorporating Universum constraints through a ratio-based objective function, while IU-GEPSVM enhances stability through a weighted difference-based formulation that provides independent control over class separation and Universum alignment. The models are evaluated on the Bonn University EEG dataset across two binary classification tasks: (O vs S)-healthy (eyes closed) vs seizure, and (Z vs S)-healthy (eyes open) vs seizure. IU-GEPSVM achieves peak accuracies of 85% (O vs S) and 80% (Z vs S), with mean accuracies of 81.29% and 77.57% respectively, outperforming baseline methods.\nüìÑ Download PDF\nVariationally correct operator learning: Reduced basis neural operator with a posteriori error estimation Authors: Yuan Qiu, Wolfgang Dahmen, Peng Chen Venue: arXiv (2025)\nMinimizing PDE-residual losses is a common strategy to promote physical consistency in neural operators. However, standard formulations often lack variational correctness, meaning that small residuals do not guarantee small solution errors due to the use of non-compliant norms or ad hoc penalty terms for boundary conditions. This work develops a variationally correct operator learning framework by constructing first-order system least-squares (FOSLS) objectives whose values are provably equivalent to the solution error in PDE-induced norms. We demonstrate this framework on stationary diffusion and linear elasticity, incorporating mixed Dirichlet-Neumann boundary conditions via variational lifts to preserve norm equivalence without inconsistent penalties. To ensure the function space conformity required by the FOSLS loss, we propose a Reduced Basis Neural Operator (RBNO). The RBNO predicts coefficients for a pre-computed, conforming reduced basis, thereby ensuring variational stability by design while enabling efficient training. We provide a rigorous convergence analysis that bounds the total error by the sum of finite element discretization bias, reduced basis truncation error, neural network approximation error, and statistical estimation errors arising from finite sampling and optimization. Numerical benchmarks validate these theoretical bounds and demonstrate that the proposed approach achieves superior accuracy in PDE-compliant norms compared to standard baselines, while the residual loss serves as a reliable, computable a posteriori error estimator.\nüìÑ Download PDF\nTwist-Tuned Strong Coupling in Sub-GHz Wire Metasurface Bilayers Authors: Ingrid Torres, Alex Krasnok Venue: arXiv (2025)\nTwist-angle control offers a bias-free route to reconfigurable metasurfaces, yet its extension to deeply subwavelength resonant platforms at VHF/UHF remains limited. We demonstrate a sub-GHz double-layer wire metasurface formed by two identical wire grids separated by a gap G, with in-plane rotation angle as the sole tuning parameter. One-port, loop-coupled S11 measurements supported by full-wave simulations reveal twist-driven hybridization of the dominant resonant manifold. For small G, the lower hybrid resonance redshifts continuously from 409 MHz to 210 MHz (2:1 tuning), enabling compact, twist-programmable resonant surfaces. Simulations further show that twisting imprints moire-like magnetic near-field super-modulations. From resonance frequencies, linewidths, and normal-mode splitting extracted from the complex response, we obtain normalized coupling up to g = 0.43 with cooperativity exceeding unity over broad angular ranges, meeting the resolved-splitting criterion. The rapid collapse of tunability at larger G confirms the near-field origin of the interaction.\nüìÑ Download PDF\nPost-Processing Mask-Based Table Segmentation for Structural Coordinate Extraction Authors: Suren Bandara Venue: arXiv (2025)\nStructured data extraction from tables plays a crucial role in document image analysis for scanned documents and digital archives. Although many methods have been proposed to detect table structures and extract cell contents, accurately identifying table segment boundaries (rows and columns) remains challenging, particularly in low-resolution or noisy images. In many real-world scenarios, table data are incomplete or degraded, limiting the adaptability of transformer-based methods to noisy inputs. Mask-based edge detection techniques have shown greater robustness under such conditions, as their sensitivity can be adjusted through threshold tuning; however, existing approaches typically apply masks directly to images, leading to noise sensitivity, resolution loss, or high computational cost. This paper proposes a novel multi-scale signal-processing method for detecting table edges from table masks. Row and column transitions are modeled as one-dimensional signals and processed using Gaussian convolution with progressively increasing variances, followed by statistical thresholding to suppress noise while preserving stable structural edges. Detected signal peaks are mapped back to image coordinates to obtain accurate segment boundaries. Experimental results show that applying the proposed approach to column edge detection improves Cell-Aware Segmentation Accuracy (CASA) a layout-aware metric evaluating both textual correctness and correct cell placement from 67% to 76% on the PubLayNet-1M benchmark when using TableNet with PyTesseract OCR. The method is robust to resolution variations through zero-padding and scaling strategies and produces optimized structured tabular outputs suitable for downstream analysis.\nüìÑ Download PDF\nIndustrial Ouroboros: Deep Lateral Movement via Living Off the Plant Authors: Richard Derbyshire Venue: arXiv (2025)\nLateral movement is a tactic that adversaries employ most frequently in enterprise IT environments to traverse between assets. In operational technology (OT) environments, however, few methods exist for lateral movement between domain-specific devices, particularly programmable logic controllers (PLCs). Existing techniques often rely on complex chains of vulnerabilities, which are noisy and can be patched. This paper describes the first PLC-centric lateral movement technique that relies exclusively on the native functionality of the victim environment. This OT-specific form of living off the land' is herein distinguished as living off the plant‚Äô (LOTP). The described technique also facilitates escape from IP networks onto legacy serial networks via dual-homed PLCs. Furthermore, this technique is covert, leveraging common network communication functions that are challenging to detect. This serves as a reminder of the risks posed by LOTP techniques within OT, highlighting the need for a fundamental reconsideration of traditional OT defensive practices.\nüìÑ Download PDF\nLearning to Solve PDEs on Neural Shape Representations Authors: Lilian Welschinger, Yilin Liu, Zican Wang, Niloy Mitra Venue: arXiv (2025)\nSolving partial differential equations (PDEs) on shapes underpins many shape analysis and engineering tasks; yet, prevailing PDE solvers operate on polygonal/triangle meshes while modern 3D assets increasingly live as neural representations. This mismatch leaves no suitable method to solve surface PDEs directly within the neural domain, forcing explicit mesh extraction or per-instance residual training, preventing end-to-end workflows. We present a novel, mesh-free formulation that learns a local update operator conditioned on neural (local) shape attributes, enabling surface PDEs to be solved directly where the (neural) data lives. The operator integrates naturally with prevalent neural surface representations, is trained once on a single representative shape, and generalizes across shape and topology variations, enabling accurate, fast inference without explicit meshing or per-instance optimization while preserving differentiability. Across analytic benchmarks (heat equation and Poisson solve on sphere) and real neural assets across different representations, our method slightly outperforms CPM while remaining reasonably close to FEM, and, to our knowledge, delivers the first end-to-end pipeline that solves surface PDEs on both neural and classical surface representations. Code will be released on acceptance.\nüìÑ Download PDF\nA Community-Enhanced Graph Representation Model for Link Prediction Authors: Lei Wang, Darong Lai Venue: arXiv (2025)\nAlthough Graph Neural Networks (GNNs) have become the dominant approach for graph representation learning, their performance on link prediction tasks does not always surpass that of traditional heuristic methods such as Common Neighbors and Jaccard Coefficient. This is mainly because existing GNNs tend to focus on learning local node representations, making it difficult to effectively capture structural relationships between node pairs. Furthermore, excessive reliance on local neighborhood information can lead to over-smoothing. Prior studies have shown that introducing global structural encoding can partially alleviate this issue. To address these limitations, we propose a Community-Enhanced Link Prediction (CELP) framework that incorporates community structure to jointly model local and global graph topology. Specifically, CELP enhances the graph via community-aware, confidence-guided edge completion and pruning, while integrating multi-scale structural features to achieve more accurate link prediction. Experimental results across multiple benchmark datasets demonstrate that CELP achieves superior performance, validating the crucial role of community structure in improving link prediction accuracy.\nüìÑ Download PDF\nEmotion Diffusion in Real and Simulated Social Graphs: Structural Limits of LLM-Based Social Simulation Authors: Qiqi Qiang Venue: arXiv (2025)\nUnderstanding how emotions diffuse through social networks is central to computational social science. Recently, large language models (LLMs) have been increasingly used to simulate social media interactions, raising the question of whether LLM-generated data can realistically reproduce emotion diffusion patterns observed in real online communities. In this study, we conduct a systematic comparison between emotion diffusion in real-world social graphs and in LLM-simulated interaction networks. We construct diffusion graphs from Reddit discussion data and compare them with synthetic social graphs generated through LLM-driven conversational simulations. Emotion states are inferred using established sentiment analysis pipelines, and both real and simulated graphs are analyzed from structural, behavioral, and predictive perspectives. Our results reveal substantial structural and dynamic discrepancies between real and simulated diffusion processes. Real-world emotion diffusion exhibits dense connectivity, repeated interactions, sentiment shifts, and emergent community structures, whereas LLM-simulated graphs largely consist of isolated linear chains with monotonic emotional trajectories. These structural limitations significantly affect downstream tasks such as graph-based emotion prediction, leading to reduced emotional diversity and class imbalance in simulated settings. Our findings highlight current limitations of LLM-based social simulation in capturing the interactive complexity and emotional heterogeneity of real social networks. This work provides empirical evidence for the cautious use of LLM-generated data in social science research and suggests directions for improving future simulation frameworks.\nüìÑ Download PDF\nMental Health Self-Disclosure on Social Media throughout the Pandemic Period Authors: Dino Husnic, Stefan Cobeli, Shweta Yadav Venue: arXiv (2025)\nThe COVID-19 pandemic has created many problems, especially in people‚Äôs social lives. There has been increasing isolation and economic hardships since the beginning of the pandemic for people all over the world. Quarantines and lockdowns also took part in that, and so, people have been expressing their emotions throughout the pandemic period using social media platforms like Reddit, Twitter, Facebook, etc. In this study, we seek to analyze the emotions and mental health labels throughout the time period of March 2, 2020, up until July 4, 2020, from the threads and comments gathered from the r/unitedkingdom subreddit. We used a soft labeling technique to generate mental health conditions for each Reddit comment. We compared the overall results with important dates related to COVID-19 policies that took place in the United Kingdom. This can give us a view on how the pandemic and the important dates affect people self disclosing their emotions on social media platforms. Finally, we have developed a proof of concept to show that using mental health features may increase emotion prediction accuracy.\nüìÑ Download PDF\nFrom Human Bias to Robot Choice: How Occupational Contexts and Racial Priming Shape Robot Selection Authors: Jiangen He, Wanqi Zhang, Jessica Barfield Venue: arXiv (2025)\nAs artificial agents increasingly integrate into professional environments, fundamental questions have emerged about how societal biases influence human-robot selection decisions. We conducted two comprehensive experiments (N = 1,038) examining how occupational contexts and stereotype activation shape robotic agent choices across construction, healthcare, educational, and athletic domains. Participants made selections from artificial agents that varied systematically in skin tone and anthropomorphic characteristics. Our study revealed distinct context-dependent patterns. Healthcare and educational scenarios demonstrated strong favoritism toward lighter-skinned artificial agents, while construction and athletic contexts showed greater acceptance of darker-toned alternatives. Participant race was associated with systematic differences in selection patterns across professional domains. The second experiment demonstrated that exposure to human professionals from specific racial backgrounds systematically shifted later robotic agent preferences in stereotype-consistent directions. These findings show that occupational biases and color-based discrimination transfer directly from human-human to human-robot evaluation contexts. The results highlight mechanisms through which robotic deployment may unintentionally perpetuate existing social inequalities.\nüìÑ Download PDF\nWelfare at Risk: Distributional impact of policy interventions Authors: Costas Lambros, Emerson Melo Venue: arXiv (2025)\nThis paper proposes a framewrok for analyzing how the welfare effects of policy interventions are distributed across individuals when those effects are unobserved. Rather than focusing solely on average outcomes, the approach uses readily available information on average welfare responses to uncover meaningful patterns in how gains and losses are distributed across different populations. The framework is built around the concept of superquantile and applies to a broad class of models with unobserved individual heterogeneity. It enables policymakers to identify which groups are most adversely affected by a policy and to evaluate trade-offs between efficiency and equity. We illustrate the approach in three widely studied economic settings: price changes and compensated variation, treatment allocation with self-selection, and the cost-benefit analysis of social programs. In this latter application, we show how standard tools from the marginal treatment effect and generalized Roy model literature are useful for implementing our bounds for both the overall population and for individuals who participate in the program.\nüìÑ Download PDF\n","wordCount":"25425","inLanguage":"en","datePublished":"2025-12-28T15:24:24.510017Z","dateModified":"2025-12-28T15:24:24.510017Z","author":{"@type":"Person","name":"Gary"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://garyforreal.me/en/posts/paper/paper-2025-12-28-weekly/"},"publisher":{"@type":"Organization","name":"Gary's House","logo":{"@type":"ImageObject","url":"https://garyforreal.me/img/Q.jpg"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css><script src=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><script src=https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js></script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://garyforreal.me/en/ accesskey=h title="Gary's Blog (Alt + H)"><img src=https://garyforreal.me/img/me.jpg alt aria-label=logo height=35>Gary's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://garyforreal.me/zh/ title=‰∏≠Êñá aria-label=‰∏≠Êñá>‰∏≠Êñá</a></li></ul></div></div><ul id=menu><li><a href=https://garyforreal.me/en/search title="üîçSearch (Alt + /)" accesskey=/><span>üîçSearch</span></a></li><li><a href=https://garyforreal.me/en/ title=üè†Homepage><span>üè†Homepage</span></a></li><li><a href=https://garyforreal.me/en/posts title=üìöArticle><span>üìöArticle</span></a></li><li><a href=https://garyforreal.me/en/archives/ title=‚è±Archives><span>‚è±Archives</span></a></li><li><a href=https://garyforreal.me/en/music/ title=üéµmusic><span>üéµmusic</span></a></li><li><a href=https://garyforreal.me/en/about title=üôãüèª‚Äç‚ôÇÔ∏èAbout><span>üôãüèª‚Äç‚ôÇÔ∏èAbout</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://garyforreal.me/en/>Home</a>&nbsp;¬ª&nbsp;<a href=https://garyforreal.me/en/posts/>Posts</a>&nbsp;¬ª&nbsp;<a href=https://garyforreal.me/en/posts/paper/>Paper</a></div><h1 class="post-title entry-hint-parent">Weekly Paper Notes - 2025-12-28</h1><div class=post-meta><span title='2025-12-28 15:24:24.510017 +0000 UTC'>2025-12-28</span>&nbsp;¬∑&nbsp;120 min&nbsp;¬∑&nbsp;Gary&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://garyforreal.me/zh/posts/paper/paper-2025-12-28-weekly/>‰∏≠Êñá</a></li></ul><div class=meta-item>&nbsp¬∑&nbsp
        <span id=busuanzi_container_page_pv>Êú¨ÊñáÈòÖËØªÈáè<span id=busuanzi_value_page_pv></span>Ê¨°</span></div></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#weekly-paper-notes aria-label="Weekly Paper Notes">Weekly Paper Notes</a><ul><li><a href=#-multilingual aria-label="üîç multilingual">üîç multilingual</a><ul><li><a href=#model-merging-via-multi-teacher-knowledge-distillationhttpsarxivorgabs251221288v1 aria-label="Model Merging via Multi-Teacher Knowledge Distillation"><a href=https://arxiv.org/abs/2512.21288v1>Model Merging via Multi-Teacher Knowledge Distillation</a></a></li><li><a href=#learning-from-next-frame-prediction-autoregressive-video-modeling-encodes-effective-representationshttpsarxivorgabs251221004v1 aria-label="Learning from Next-Frame Prediction: Autoregressive Video Modeling Encodes Effective Representations"><a href=https://arxiv.org/abs/2512.21004v1>Learning from Next-Frame Prediction: Autoregressive Video Modeling Encodes Effective Representations</a></a></li><li><a href=#multimind-at-semeval-2025-task-7-crosslingual-fact-checked-claim-retrieval-via-multi-source-alignmenthttpsarxivorgabs251220950v1 aria-label="MultiMind at SemEval-2025 Task 7: Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment"><a href=https://arxiv.org/abs/2512.20950v1>MultiMind at SemEval-2025 Task 7: Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment</a></a></li><li><a href=#swerank-multilingual-multi-turn-code-ranking-for-software-issue-localizationhttpsarxivorgabs251220482v1 aria-label="SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization"><a href=https://arxiv.org/abs/2512.20482v1>SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization</a></a></li><li><a href=#linking-faces-and-voices-across-languages-insights-from-the-fame-2026-challengehttpsarxivorgabs251220376v1 aria-label="Linking Faces and Voices Across Languages: Insights from the FAME 2026 Challenge"><a href=https://arxiv.org/abs/2512.20376v1>Linking Faces and Voices Across Languages: Insights from the FAME 2026 Challenge</a></a></li><li><a href=#can-llms-solve-my-grandmas-riddle-evaluating-multilingual-large-language-models-on-reasoning-traditional-bangla-tricky-riddleshttpsarxivorgabs251220324v1 aria-label="Can LLMs Solve My Grandma&rsquo;s Riddle? Evaluating Multilingual Large Language Models on Reasoning Traditional Bangla Tricky Riddles"><a href=https://arxiv.org/abs/2512.20324v1>Can LLMs Solve My Grandma&rsquo;s Riddle? Evaluating Multilingual Large Language Models on Reasoning Traditional Bangla Tricky Riddles</a></a></li><li><a href=#foundation-model-based-evaluation-of-neuropsychiatric-disorders-a-lifespan-inclusive-multi-modal-and-multi-lingual-studyhttpsarxivorgabs251220948v1 aria-label="Foundation Model-based Evaluation of Neuropsychiatric Disorders: A Lifespan-Inclusive, Multi-Modal, and Multi-Lingual Study"><a href=https://arxiv.org/abs/2512.20948v1>Foundation Model-based Evaluation of Neuropsychiatric Disorders: A Lifespan-Inclusive, Multi-Modal, and Multi-Lingual Study</a></a></li><li><a href=#corpus-of-cross-lingual-dialogues-with-minutes-and-detection-of-misunderstandingshttpsarxivorgabs251220204v1 aria-label="Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings"><a href=https://arxiv.org/abs/2512.20204v1>Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings</a></a></li><li><a href=#maubert-universal-phonetic-inductive-biases-for-few-shot-acoustic-units-discoveryhttpsarxivorgabs251219612v1 aria-label="MauBERT: Universal Phonetic Inductive Biases for Few-Shot Acoustic Units Discovery"><a href=https://arxiv.org/abs/2512.19612v1>MauBERT: Universal Phonetic Inductive Biases for Few-Shot Acoustic Units Discovery</a></a></li><li><a href=#event-extraction-in-large-language-modelhttpsarxivorgabs251219537v1 aria-label="Event Extraction in Large Language Model"><a href=https://arxiv.org/abs/2512.19537v1>Event Extraction in Large Language Model</a></a></li><li><a href=#omnimer-indonesian-multimodal-emotion-recognition-via-auxiliary-enhanced-llm-adaptationhttpsarxivorgabs251219379v1 aria-label="OmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation"><a href=https://arxiv.org/abs/2512.19379v1>OmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation</a></a></li><li><a href=#quantitative-financial-modeling-for-sri-lankan-markets-approach-combining-nlp-clustering-and-time-series-forecastinghttpsarxivorgabs251220216v1 aria-label="Quantitative Financial Modeling for Sri Lankan Markets: Approach Combining NLP, Clustering and Time-Series Forecasting"><a href=https://arxiv.org/abs/2512.20216v1>Quantitative Financial Modeling for Sri Lankan Markets: Approach Combining NLP, Clustering and Time-Series Forecasting</a></a></li><li><a href=#neuron-guided-interpretation-of-code-llms-where-why-and-howhttpsarxivorgabs251219980v1 aria-label="Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?"><a href=https://arxiv.org/abs/2512.19980v1>Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?</a></a></li><li><a href=#a-high-dimensional-quantum-blockchain-protocol-based-on-time--entanglementhttpsarxivorgabs251220489v1 aria-label="A High-Dimensional Quantum Blockchain Protocol Based on Time- Entanglement"><a href=https://arxiv.org/abs/2512.20489v1>A High-Dimensional Quantum Blockchain Protocol Based on Time- Entanglement</a></a></li><li><a href=#scalable-relay-switching-platform-for-automated-multi-point-resistance-measurementshttpsarxivorgabs251220419v1 aria-label="Scalable Relay Switching Platform for Automated Multi-Point Resistance Measurements"><a href=https://arxiv.org/abs/2512.20419v1>Scalable Relay Switching Platform for Automated Multi-Point Resistance Measurements</a></a></li><li><a href=#kunnafonidilaw-ka-cadeau-an-asr-dataset-of-present-day-bambarahttpsarxivorgabs251219400v1 aria-label="Kunnafonidilaw ka Cadeau: an ASR dataset of present-day Bambara"><a href=https://arxiv.org/abs/2512.19400v1>Kunnafonidilaw ka Cadeau: an ASR dataset of present-day Bambara</a></a></li><li><a href=#milton-friedmans-spending-matrix-revisited-spending-efficiency-and-preference-compatibility-across-different-economic-systemshttpsarxivorgabs251219984v1 aria-label="Milton Friedman&rsquo;s spending matrix revisited: &lsquo;Spending efficiency&rsquo; and &lsquo;preference compatibility&rsquo; across different economic systems"><a href=https://arxiv.org/abs/2512.19984v1>Milton Friedman&rsquo;s spending matrix revisited: &lsquo;Spending efficiency&rsquo; and &lsquo;preference compatibility&rsquo; across different economic systems</a></a></li><li><a href=#beyond-memorization-a-multi-modal-ordinal-regression-benchmark-to-expose-popularity-bias-in-vision-language-modelshttpsarxivorgabs251221337v1 aria-label="Beyond Memorization: A Multi-Modal Ordinal Regression Benchmark to Expose Popularity Bias in Vision-Language Models"><a href=https://arxiv.org/abs/2512.21337v1>Beyond Memorization: A Multi-Modal Ordinal Regression Benchmark to Expose Popularity Bias in Vision-Language Models</a></a></li><li><a href=#optimizing-decoding-paths-in-masked-diffusion-models-by-quantifying-uncertaintyhttpsarxivorgabs251221336v1 aria-label="Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty"><a href=https://arxiv.org/abs/2512.21336v1>Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty</a></a></li><li><a href=#c2llm-technical-report-a-new-frontier-in-code-retrieval-via-adaptive-cross-attention-poolinghttpsarxivorgabs251221332v1 aria-label="C2LLM Technical Report: A New Frontier in Code Retrieval via Adaptive Cross-Attention Pooling"><a href=https://arxiv.org/abs/2512.21332v1>C2LLM Technical Report: A New Frontier in Code Retrieval via Adaptive Cross-Attention Pooling</a></a></li><li><a href=#your-reasoning-benchmark-may-not-test-reasoning-revealing-perception-bottleneck-in-abstract-reasoning-benchmarkshttpsarxivorgabs251221329v1 aria-label="Your Reasoning Benchmark May Not Test Reasoning: Revealing Perception Bottleneck in Abstract Reasoning Benchmarks"><a href=https://arxiv.org/abs/2512.21329v1>Your Reasoning Benchmark May Not Test Reasoning: Revealing Perception Bottleneck in Abstract Reasoning Benchmarks</a></a></li><li><a href=#measuring-all-the-noises-of-llm-evalshttpsarxivorgabs251221326v1 aria-label="Measuring all the noises of LLM Evals"><a href=https://arxiv.org/abs/2512.21326v1>Measuring all the noises of LLM Evals</a></a></li><li><a href=#parallel-token-prediction-for-language-modelshttpsarxivorgabs251221323v1 aria-label="Parallel Token Prediction for Language Models"><a href=https://arxiv.org/abs/2512.21323v1>Parallel Token Prediction for Language Models</a></a></li><li><a href=#autonomous-uncertainty-quantification-for-computational-point-of-care-sensorshttpsarxivorgabs251221335v1 aria-label="Autonomous Uncertainty Quantification for Computational Point-of-care Sensors"><a href=https://arxiv.org/abs/2512.21335v1>Autonomous Uncertainty Quantification for Computational Point-of-care Sensors</a></a></li><li><a href=#coherently-assisted-wireless-power-transfer-through-poorly-transparent-barriershttpsarxivorgabs251221271v1 aria-label="Coherently Assisted Wireless Power Transfer Through Poorly Transparent Barriers"><a href=https://arxiv.org/abs/2512.21271v1>Coherently Assisted Wireless Power Transfer Through Poorly Transparent Barriers</a></a></li><li><a href=#cotdeceptoradversarial-code-obfuscation-against-cot-enhanced-llm-code-agentshttpsarxivorgabs251221250v1 aria-label="CoTDeceptor:Adversarial Code Obfuscation Against CoT-Enhanced LLM Code Agents"><a href=https://arxiv.org/abs/2512.21250v1>CoTDeceptor:Adversarial Code Obfuscation Against CoT-Enhanced LLM Code Agents</a></a></li><li><a href=#unitachand-unified-spatio-tactile-representation-for-human-to-robotic-hand-skill-transferhttpsarxivorgabs251221233v1 aria-label="UniTacHand: Unified Spatio-Tactile Representation for Human to Robotic Hand Skill Transfer"><a href=https://arxiv.org/abs/2512.21233v1>UniTacHand: Unified Spatio-Tactile Representation for Human to Robotic Hand Skill Transfer</a></a></li><li><a href=#a-multimodal-human-centered-framework-for-assessing-pedestrian-well-being-in-the-wildhttpsarxivorgabs251221200v1 aria-label="A Multimodal Human-Centered Framework for Assessing Pedestrian Well-Being in the Wild"><a href=https://arxiv.org/abs/2512.21200v1>A Multimodal Human-Centered Framework for Assessing Pedestrian Well-Being in the Wild</a></a></li><li><a href=#the-disc-instability-model-original-recipe-and-additional-ingredientshttpsarxivorgabs251221188v1 aria-label="The disc instability model: original recipe and additional ingredients"><a href=https://arxiv.org/abs/2512.21188v1>The disc instability model: original recipe and additional ingredients</a></a></li><li><a href=#a-turn-toward-better-alignment-few-shot-generative-adaptation-with-equivariant-feature-rotationhttpsarxivorgabs251221174v1 aria-label="A Turn Toward Better Alignment: Few-Shot Generative Adaptation with Equivariant Feature Rotation"><a href=https://arxiv.org/abs/2512.21174v1>A Turn Toward Better Alignment: Few-Shot Generative Adaptation with Equivariant Feature Rotation</a></a></li><li><a href=#channel-last-gate-all-around-nanosheet-oxide-semiconductor-transistorshttpsarxivorgabs251221330v1 aria-label="Channel-last gate-all-around nanosheet oxide semiconductor transistors"><a href=https://arxiv.org/abs/2512.21330v1>Channel-last gate-all-around nanosheet oxide semiconductor transistors</a></a></li><li><a href=#transcriptome-conditioned-personalized-de-novo-drug-generation-for-aml-using-metaheuristic-assembly-and-target-driven-filteringhttpsarxivorgabs251221301v1 aria-label="Transcriptome-Conditioned Personalized De Novo Drug Generation for AML Using Metaheuristic Assembly and Target-Driven Filtering"><a href=https://arxiv.org/abs/2512.21301v1>Transcriptome-Conditioned Personalized De Novo Drug Generation for AML Using Metaheuristic Assembly and Target-Driven Filtering</a></a></li><li><a href=#impurity-peaking-of-sparc-h-modes-a-sensitivity-study-on-physics-and-engineering-assumptionshttpsarxivorgabs251221286v1 aria-label="Impurity peaking of SPARC H-modes: a sensitivity study on physics and engineering assumptions"><a href=https://arxiv.org/abs/2512.21286v1>Impurity peaking of SPARC H-modes: a sensitivity study on physics and engineering assumptions</a></a></li><li><a href=#acd-direct-conditional-control-for-video-diffusion-models-via-attention-supervisionhttpsarxivorgabs251221268v1 aria-label="ACD: Direct Conditional Control for Video Diffusion Models via Attention Supervision"><a href=https://arxiv.org/abs/2512.21268v1>ACD: Direct Conditional Control for Video Diffusion Models via Attention Supervision</a></a></li><li><a href=#anyad-unified-any-modality-anomaly-detection-in-incomplete-multi-sequence-mrihttpsarxivorgabs251221264v1 aria-label="AnyAD: Unified Any-Modality Anomaly Detection in Incomplete Multi-Sequence MRI"><a href=https://arxiv.org/abs/2512.21264v1>AnyAD: Unified Any-Modality Anomaly Detection in Incomplete Multi-Sequence MRI</a></a></li><li><a href=#segmo-segment-aligned-text-to-3d-human-motion-generationhttpsarxivorgabs251221237v1 aria-label="SegMo: Segment-aligned Text to 3D Human Motion Generation"><a href=https://arxiv.org/abs/2512.21237v1>SegMo: Segment-aligned Text to 3D Human Motion Generation</a></a></li><li><a href=#smart-slm-structured-memory-and-reasoning-transformer-a-small-language-model-for-accurate-document-assistancehttpsarxivorgabs251221280v1 aria-label="SMART SLM: Structured Memory and Reasoning Transformer, A Small Language Model for Accurate Document Assistance"><a href=https://arxiv.org/abs/2512.21280v1>SMART SLM: Structured Memory and Reasoning Transformer, A Small Language Model for Accurate Document Assistance</a></a></li><li><a href=#random-dilation-superchannelhttpsarxivorgabs251221260v1 aria-label="Random dilation superchannel"><a href=https://arxiv.org/abs/2512.21260v1>Random dilation superchannel</a></a></li><li><a href=#reaseq-unleashing-world-knowledge-via-reasoning-for-sequential-modelinghttpsarxivorgabs251221257v1 aria-label="ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling"><a href=https://arxiv.org/abs/2512.21257v1>ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling</a></a></li><li><a href=#leveraging-lightweight-entity-extraction-for-scalable-event-based-image-retrievalhttpsarxivorgabs251221221v1 aria-label="Leveraging Lightweight Entity Extraction for Scalable Event-Based Image Retrieval"><a href=https://arxiv.org/abs/2512.21221v1>Leveraging Lightweight Entity Extraction for Scalable Event-Based Image Retrieval</a></a></li></ul></li><li><a href=#-linguistics aria-label="üîç linguistics">üîç linguistics</a><ul><li><a href=#histream-efficient-high-resolution-video-generation-via-redundancy-eliminated-streaminghttpsarxivorgabs251221338v1 aria-label="HiStream: Efficient High-Resolution Video Generation via Redundancy-Eliminated Streaming"><a href=https://arxiv.org/abs/2512.21338v1>HiStream: Efficient High-Resolution Video Generation via Redundancy-Eliminated Streaming</a></a></li><li><a href=#streaming-video-instruction-tuninghttpsarxivorgabs251221334v1 aria-label="Streaming Video Instruction Tuning"><a href=https://arxiv.org/abs/2512.21334v1>Streaming Video Instruction Tuning</a></a></li><li><a href=#fast-sam2-with-text-driven-token-pruninghttpsarxivorgabs251221333v1 aria-label="Fast SAM2 with Text-Driven Token Pruning"><a href=https://arxiv.org/abs/2512.21333v1>Fast SAM2 with Text-Driven Token Pruning</a></a></li><li><a href=#when-geometry-radiates-review-gravitational-waves-in-theory-cosmology-and-observationhttpsarxivorgabs251221328v1 aria-label="When Geometry Radiates Review: Gravitational Waves in Theory, Cosmology, and Observation"><a href=https://arxiv.org/abs/2512.21328v1>When Geometry Radiates Review: Gravitational Waves in Theory, Cosmology, and Observation</a></a></li><li><a href=#aspects-of-holographic-timelike-entanglement-entropy-in-black-hole-backgroundshttpsarxivorgabs251221327v1 aria-label="Aspects of holographic timelike entanglement entropy in black hole backgrounds"><a href=https://arxiv.org/abs/2512.21327v1>Aspects of holographic timelike entanglement entropy in black hole backgrounds</a></a></li><li><a href=#an-allele-centric-pan-graph-matrix-representation-for-scalable-pangenome-analysishttpsarxivorgabs251221320v1 aria-label="An Allele-Centric Pan-Graph-Matrix Representation for Scalable Pangenome Analysis"><a href=https://arxiv.org/abs/2512.21320v1>An Allele-Centric Pan-Graph-Matrix Representation for Scalable Pangenome Analysis</a></a></li><li><a href=#a-lyapunov-based-small-gain-theorem-for-fixed-time-iss-theory-optimization-and-gameshttpsarxivorgabs251221314v1 aria-label="A Lyapunov-Based Small-Gain Theorem for Fixed-Time ISS: Theory, Optimization, and Games"><a href=https://arxiv.org/abs/2512.21314v1>A Lyapunov-Based Small-Gain Theorem for Fixed-Time ISS: Theory, Optimization, and Games</a></a></li><li><a href=#force-%ce%b1-numerical-fluxes-within-the-arbitrary-high-order-semidiscrete-weno-dec-framework-a-competitive-alternative-to-upwind-fluxeshttpsarxivorgabs251221306v1 aria-label="FORCE-$Œ±$ Numerical Fluxes within the Arbitrary High Order Semidiscrete WENO-DeC Framework: A Competitive Alternative to Upwind Fluxes"><a href=https://arxiv.org/abs/2512.21306v1>FORCE-$Œ±$ Numerical Fluxes within the Arbitrary High Order Semidiscrete WENO-DeC Framework: A Competitive Alternative to Upwind Fluxes</a></a></li><li><a href=#deforming-and-dissecting-ads_3-with-matterhttpsarxivorgabs251221255v1 aria-label="Deforming and dissecting AdS$_3$ with matter"><a href=https://arxiv.org/abs/2512.21255v1>Deforming and dissecting AdS$_3$ with matter</a></a></li><li><a href=#exact-infrared-triangle-in-massless-sqed-with-long-range-interactionshttpsarxivorgabs251221239v1 aria-label="Exact Infrared Triangle in Massless sQED with Long-range Interactions"><a href=https://arxiv.org/abs/2512.21239v1>Exact Infrared Triangle in Massless sQED with Long-range Interactions</a></a></li><li><a href=#linking-interior-curvature-to-observable-shadows-a-case-study-of-nonsingular-black-holeshttpsarxivorgabs251221178v1 aria-label="Linking interior curvature to observable shadows: A case study of nonsingular black holes"><a href=https://arxiv.org/abs/2512.21178v1>Linking interior curvature to observable shadows: A case study of nonsingular black holes</a></a></li><li><a href=#lovelock2-inflation-explaining-the-act-data-and-equivalence-to-higgs-gauss-bonnet-inflationhttpsarxivorgabs251221167v1 aria-label="(Lovelock)$^2$ inflation: explaining the ACT data and equivalence to Higgs-Gauss-Bonnet inflation"><a href=https://arxiv.org/abs/2512.21167v1>(Lovelock)$^2$ inflation: explaining the ACT data and equivalence to Higgs-Gauss-Bonnet inflation</a></a></li><li><a href=#orca-object-recognition-and-comprehension-for-archiving-marine-specieshttpsarxivorgabs251221150v1 aria-label="ORCA: Object Recognition and Comprehension for Archiving Marine Species"><a href=https://arxiv.org/abs/2512.21150v1>ORCA: Object Recognition and Comprehension for Archiving Marine Species</a></a></li><li><a href=#ticon-a-slide-level-tile-contextualizer-for-histopathology-representation-learninghttpsarxivorgabs251221331v1 aria-label="TICON: A Slide-Level Tile Contextualizer for Histopathology Representation Learning"><a href=https://arxiv.org/abs/2512.21331v1>TICON: A Slide-Level Tile Contextualizer for Histopathology Representation Learning</a></a></li><li><a href=#towards-practical-automatic-piano-reduction-using-bert-with-semi-supervised-learninghttpsarxivorgabs251221324v1 aria-label="Towards Practical Automatic Piano Reduction using BERT with Semi-supervised Learning"><a href=https://arxiv.org/abs/2512.21324v1>Towards Practical Automatic Piano Reduction using BERT with Semi-supervised Learning</a></a></li><li><a href=#a-plan-reuse-mechanism-for-llm-driven-agenthttpsarxivorgabs251221309v1 aria-label="A Plan Reuse Mechanism for LLM-Driven Agent"><a href=https://arxiv.org/abs/2512.21309v1>A Plan Reuse Mechanism for LLM-Driven Agent</a></a></li><li><a href=#bar-formation-in-disc-galaxies-internal-kinematics-and-environmental-influence-in-manga-galaxieshttpsarxivorgabs251221303v1 aria-label="Bar Formation in Disc Galaxies: Internal Kinematics and Environmental Influence in MaNGA Galaxies"><a href=https://arxiv.org/abs/2512.21303v1>Bar Formation in Disc Galaxies: Internal Kinematics and Environmental Influence in MaNGA Galaxies</a></a></li><li><a href=#unirec-01b-unified-text-and-formula-recognition-with-01b-parametershttpsarxivorgabs251221095v1 aria-label="UniRec-0.1B: Unified Text and Formula Recognition with 0.1B Parameters"><a href=https://arxiv.org/abs/2512.21095v1>UniRec-0.1B: Unified Text and Formula Recognition with 0.1B Parameters</a></a></li><li><a href=#laser-governing-long-horizon-agentic-search-via-structured-protocol-and-context-registerhttpsarxivorgabs251220458v1 aria-label="Laser: Governing Long-Horizon Agentic Search via Structured Protocol and Context Register"><a href=https://arxiv.org/abs/2512.20458v1>Laser: Governing Long-Horizon Agentic Search via Structured Protocol and Context Register</a></a></li><li><a href=#from-cosmology-to-cosmonomyhttpsarxivorgabs251220416v1 aria-label="From Cosmology to Cosmonomy"><a href=https://arxiv.org/abs/2512.20416v1>From Cosmology to Cosmonomy</a></a></li><li><a href=#indicdlp-a-foundational-dataset-for-multi-lingual-and-multi-domain-document-layout-parsinghttpsarxivorgabs251220236v1 aria-label="IndicDLP: A Foundational Dataset for Multi-Lingual and Multi-Domain Document Layout Parsing"><a href=https://arxiv.org/abs/2512.20236v1>IndicDLP: A Foundational Dataset for Multi-Lingual and Multi-Domain Document Layout Parsing</a></a></li><li><a href=#segearth-r2-towards-comprehensive-language-guided-segmentation-for-remote-sensing-imageshttpsarxivorgabs251220013v1 aria-label="SegEarth-R2: Towards Comprehensive Language-guided Segmentation for Remote Sensing Images"><a href=https://arxiv.org/abs/2512.20013v1>SegEarth-R2: Towards Comprehensive Language-guided Segmentation for Remote Sensing Images</a></a></li><li><a href=#how-well-do-large-language-models-recognize-instructional-moves-establishing-baselines-for-foundation-models-in-educational-discoursehttpsarxivorgabs251219903v1 aria-label="How well do Large Language Models Recognize Instructional Moves? Establishing Baselines for Foundation Models in Educational Discourse"><a href=https://arxiv.org/abs/2512.19903v1>How well do Large Language Models Recognize Instructional Moves? Establishing Baselines for Foundation Models in Educational Discourse</a></a></li><li><a href=#topological-charge-2ne-superconductorshttpsarxivorgabs251221325v1 aria-label="Topological Charge-2ne Superconductors"><a href=https://arxiv.org/abs/2512.21325v1>Topological Charge-2ne Superconductors</a></a></li><li><a href=#quantum-entanglement-between-partons-in-a-strongly-coupled-quantum-field-theoryhttpsarxivorgabs251221228v1 aria-label="Quantum entanglement between partons in a strongly coupled quantum field theory"><a href=https://arxiv.org/abs/2512.21228v1>Quantum entanglement between partons in a strongly coupled quantum field theory</a></a></li><li><a href=#visres-bench-on-evaluating-the-visual-reasoning-capabilities-of-vlmshttpsarxivorgabs251221194v1 aria-label="VisRes Bench: On Evaluating the Visual Reasoning Capabilities of VLMs"><a href=https://arxiv.org/abs/2512.21194v1>VisRes Bench: On Evaluating the Visual Reasoning Capabilities of VLMs</a></a></li><li><a href=#search-for-light-dark-matter-in-rare-meson-decayshttpsarxivorgabs251221191v1 aria-label="Search for Light Dark Matter in Rare Meson Decays"><a href=https://arxiv.org/abs/2512.21191v1>Search for Light Dark Matter in Rare Meson Decays</a></a></li><li><a href=#large-time-behavior-of-the-solution-to-the-cauchy-problem-for-the-discrete-p-laplacian-with-density-on-infinite-graphshttpsarxivorgabs251221321v1 aria-label="Large time behavior of the solution to the Cauchy problem for the discrete p-Laplacian with density on infinite graphs"><a href=https://arxiv.org/abs/2512.21321v1>Large time behavior of the solution to the Cauchy problem for the discrete p-Laplacian with density on infinite graphs</a></a></li><li><a href=#universality-of-equilibration-dynamics-after-quantum-quencheshttpsarxivorgabs251221313v1 aria-label="Universality of equilibration dynamics after quantum quenches"><a href=https://arxiv.org/abs/2512.21313v1>Universality of equilibration dynamics after quantum quenches</a></a></li><li><a href=#the-patterson-sullivan-construction-and-global-leaf-geometry-for-anosov-flowshttpsarxivorgabs251221308v1 aria-label="The Patterson-Sullivan construction and global leaf geometry for Anosov flows"><a href=https://arxiv.org/abs/2512.21308v1>The Patterson-Sullivan construction and global leaf geometry for Anosov flows</a></a></li><li><a href=#semantic-refinement-with-llms-for-graph-representationshttpsarxivorgabs251221106v1 aria-label="Semantic Refinement with LLMs for Graph Representations"><a href=https://arxiv.org/abs/2512.21106v1>Semantic Refinement with LLMs for Graph Representations</a></a></li><li><a href=#reflection-pretraining-enables-token-level-self-correction-in-biological-sequence-modelshttpsarxivorgabs251220954v1 aria-label="Reflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models"><a href=https://arxiv.org/abs/2512.20954v1>Reflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models</a></a></li><li><a href=#transductive-visual-programming-evolving-tool-libraries-from-experience-for-spatial-reasoninghttpsarxivorgabs251220934v1 aria-label="Transductive Visual Programming: Evolving Tool Libraries from Experience for Spatial Reasoning"><a href=https://arxiv.org/abs/2512.20934v1>Transductive Visual Programming: Evolving Tool Libraries from Experience for Spatial Reasoning</a></a></li><li><a href=#virtual-volumes-of-strata-of-meromorphic-differentials-with-simple-poleshttpsarxivorgabs251220819v1 aria-label="Virtual volumes of strata of meromorphic differentials with simple poles"><a href=https://arxiv.org/abs/2512.20819v1>Virtual volumes of strata of meromorphic differentials with simple poles</a></a></li><li><a href=#process-analytics----data-driven-business-process-managementhttpsarxivorgabs251220703v1 aria-label="Process Analytics &ndash; Data-driven Business Process Management"><a href=https://arxiv.org/abs/2512.20703v1>Process Analytics &ndash; Data-driven Business Process Management</a></a></li></ul></li><li><a href=#-psycholinguistics aria-label="üîç psycholinguistics">üîç psycholinguistics</a><ul><li><a href=#mixing-time-of-the-random-walk-on-the-giant-component-of-the-random-geometric-graphhttpsarxivorgabs251221322v1 aria-label="Mixing time of the random walk on the giant component of the random geometric graph"><a href=https://arxiv.org/abs/2512.21322v1>Mixing time of the random walk on the giant component of the random geometric graph</a></a></li><li><a href=#does-the-data-processing-inequality-reflect-practice-on-the-utility-of-low-level-taskshttpsarxivorgabs251221315v1 aria-label="Does the Data Processing Inequality Reflect Practice? On the Utility of Low-Level Tasks"><a href=https://arxiv.org/abs/2512.21315v1>Does the Data Processing Inequality Reflect Practice? On the Utility of Low-Level Tasks</a></a></li><li><a href=#coding-logic-correspondence-turning-information-and-communication-networks-into-logical-formulae-via-hypergraph-heyting-algebrahttpsarxivorgabs251221112v1 aria-label="Coding-Logic Correspondence: Turning Information and Communication Networks into Logical Formulae via Hypergraph Heyting Algebra"><a href=https://arxiv.org/abs/2512.21112v1>Coding-Logic Correspondence: Turning Information and Communication Networks into Logical Formulae via Hypergraph Heyting Algebra</a></a></li><li><a href=#spatialtree-how-spatial-abilities-branch-out-in-mllmshttpsarxivorgabs251220617v1 aria-label="SpatialTree: How Spatial Abilities Branch Out in MLLMs"><a href=https://arxiv.org/abs/2512.20617v1>SpatialTree: How Spatial Abilities Branch Out in MLLMs</a></a></li><li><a href=#uniform-spanning-trees-and-random-matrix-statisticshttpsarxivorgabs251220540v1 aria-label="Uniform spanning trees and random matrix statistics"><a href=https://arxiv.org/abs/2512.20540v1>Uniform spanning trees and random matrix statistics</a></a></li><li><a href=#numerical-analysis-of-test-optimalityhttpsarxivorgabs251219843v1 aria-label="Numerical Analysis of Test Optimality"><a href=https://arxiv.org/abs/2512.19843v1>Numerical Analysis of Test Optimality</a></a></li><li><a href=#yang-mills-energy-quantization-over-non-collapsed-degenerating-einstein-manifolds-and-applicationshttpsarxivorgabs251219552v1 aria-label="Yang-Mills energy quantization over non-collapsed degenerating Einstein manifolds and applications"><a href=https://arxiv.org/abs/2512.19552v1>Yang-Mills energy quantization over non-collapsed degenerating Einstein manifolds and applications</a></a></li><li><a href=#characterizing-quantum-synchronization-in-the-van-der-pol-oscillator-via-tomogram-and-photon-correlationhttpsarxivorgabs251221272v1 aria-label="Characterizing quantum synchronization in the van der Pol oscillator via tomogram and photon correlation"><a href=https://arxiv.org/abs/2512.21272v1>Characterizing quantum synchronization in the van der Pol oscillator via tomogram and photon correlation</a></a></li><li><a href=#improving-the-convergence-rate-of-ray-search-optimization-for-query-efficient-hard-label-attackshttpsarxivorgabs251221241v1 aria-label="Improving the Convergence Rate of Ray Search Optimization for Query-Efficient Hard-Label Attacks"><a href=https://arxiv.org/abs/2512.21241v1>Improving the Convergence Rate of Ray Search Optimization for Query-Efficient Hard-Label Attacks</a></a></li><li><a href=#casting-a-spell-sentence-pairing-exploration-for-llm-limitation-breakinghttpsarxivorgabs251221236v1 aria-label="Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking"><a href=https://arxiv.org/abs/2512.21236v1>Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking</a></a></li><li><a href=#robocade-gamifying-robot-data-collectionhttpsarxivorgabs251221235v1 aria-label="RoboCade: Gamifying Robot Data Collection"><a href=https://arxiv.org/abs/2512.21235v1>RoboCade: Gamifying Robot Data Collection</a></a></li><li><a href=#proximal-survival-analysis-for-dependent-left-truncationhttpsarxivorgabs251221283v1 aria-label="Proximal Survival Analysis for Dependent Left Truncation"><a href=https://arxiv.org/abs/2512.21283v1>Proximal Survival Analysis for Dependent Left Truncation</a></a></li><li><a href=#assessing-the-software-security-comprehension-of-large-language-modelshttpsarxivorgabs251221238v1 aria-label="Assessing the Software Security Comprehension of Large Language Models"><a href=https://arxiv.org/abs/2512.21238v1>Assessing the Software Security Comprehension of Large Language Models</a></a></li><li><a href=#active-inference-and-artificial-reasoninghttpsarxivorgabs251221129v1 aria-label="Active inference and artificial reasoning"><a href=https://arxiv.org/abs/2512.21129v1>Active inference and artificial reasoning</a></a></li><li><a href=#a-design-study-process-model-for-medical-visualizationhttpsarxivorgabs251221034v1 aria-label="A Design Study Process Model for Medical Visualization"><a href=https://arxiv.org/abs/2512.21034v1>A Design Study Process Model for Medical Visualization</a></a></li><li><a href=#aegisagent-an-autonomous-defense-agent-against-prompt-injection-attacks-in-llm-harshttpsarxivorgabs251220986v1 aria-label="AegisAgent: An Autonomous Defense Agent Against Prompt Injection Attacks in LLM-HARs"><a href=https://arxiv.org/abs/2512.20986v1>AegisAgent: An Autonomous Defense Agent Against Prompt Injection Attacks in LLM-HARs</a></a></li><li><a href=#information-backed-currency-ibc-designing-a-resilient-transparent-and-information-centric-monetary-ecosystemhttpsarxivorgabs251220961v1 aria-label="Information-Backed Currency (IBC): Designing a Resilient, Transparent, and Information-Centric Monetary Ecosystem"><a href=https://arxiv.org/abs/2512.20961v1>Information-Backed Currency (IBC): Designing a Resilient, Transparent, and Information-Centric Monetary Ecosystem</a></a></li><li><a href=#enhancing-grid-resilience-for-giga-watt-scale-data-centers-using-high-voltage-circuit-breaker-operated-braking-resistorshttpsarxivorgabs251221295v1 aria-label="Enhancing Grid Resilience for Giga-Watt Scale Data Centers Using High Voltage Circuit Breaker Operated Braking Resistors"><a href=https://arxiv.org/abs/2512.21295v1>Enhancing Grid Resilience for Giga-Watt Scale Data Centers Using High Voltage Circuit Breaker Operated Braking Resistors</a></a></li><li><a href=#wireless-center-of-pressure-feedback-system-for-humanoid-robot-balance-control-using-esp32-c3httpsarxivorgabs251221219v1 aria-label="Wireless Center of Pressure Feedback System for Humanoid Robot Balance Control using ESP32-C3"><a href=https://arxiv.org/abs/2512.21219v1>Wireless Center of Pressure Feedback System for Humanoid Robot Balance Control using ESP32-C3</a></a></li><li><a href=#all-optical-control-and-multiplexed-readout-of-multiple-superconducting-qubitshttpsarxivorgabs251221199v1 aria-label="All-optical control and multiplexed readout of multiple superconducting qubits"><a href=https://arxiv.org/abs/2512.21199v1>All-optical control and multiplexed readout of multiple superconducting qubits</a></a></li><li><a href=#shared-representation-learning-for-high-dimensional-multi-task-forecasting-under-resource-contention-in-cloud-native-backendshttpsarxivorgabs251221102v1 aria-label="Shared Representation Learning for High-Dimensional Multi-Task Forecasting under Resource Contention in Cloud-Native Backends"><a href=https://arxiv.org/abs/2512.21102v1>Shared Representation Learning for High-Dimensional Multi-Task Forecasting under Resource Contention in Cloud-Native Backends</a></a></li></ul></li><li><a href=#-llm aria-label="üîç llm">üîç llm</a><ul><li><a href=#optimizing-quantum-state-transformation-under-locality-constrainthttpsarxivorgabs251221310v1 aria-label="Optimizing Quantum State Transformation Under Locality Constraint"><a href=https://arxiv.org/abs/2512.21310v1>Optimizing Quantum State Transformation Under Locality Constraint</a></a></li><li><a href=#observation-of-the-aharonov-bohm-effect-in-pilot-wave-hydrodynamicshttpsarxivorgabs251221263v1 aria-label="Observation of the Aharonov-Bohm Effect in Pilot-Wave Hydrodynamics"><a href=https://arxiv.org/abs/2512.21263v1>Observation of the Aharonov-Bohm Effect in Pilot-Wave Hydrodynamics</a></a></li><li><a href=#neural-network-assisted-ris-weight-optimization-for-spatial-nulling-in-distorted-reflector-antenna-systemshttpsarxivorgabs251221253v1 aria-label="Neural Network-Assisted RIS Weight Optimization for Spatial Nulling in Distorted Reflector Antenna Systems"><a href=https://arxiv.org/abs/2512.21253v1>Neural Network-Assisted RIS Weight Optimization for Spatial Nulling in Distorted Reflector Antenna Systems</a></a></li><li><a href=#scaling-laws-for-economic-productivity-experimental-evidence-in-llm-assisted-consulting-data-analyst-and-management-taskshttpsarxivorgabs251221316v1 aria-label="Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Consulting, Data Analyst, and Management Tasks"><a href=https://arxiv.org/abs/2512.21316v1>Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Consulting, Data Analyst, and Management Tasks</a></a></li></ul></li><li><a href=#-neuroscience aria-label="üîç neuroscience">üîç neuroscience</a><ul><li><a href=#androidlens-long-latency-evaluation-with-nested-sub-targets-for-android-gui-agentshttpsarxivorgabs251221302v1 aria-label="AndroidLens: Long-latency Evaluation with Nested Sub-targets for Android GUI Agents"><a href=https://arxiv.org/abs/2512.21302v1>AndroidLens: Long-latency Evaluation with Nested Sub-targets for Android GUI Agents</a></a></li><li><a href=#quadrupped-legged-robot-movement-plan-generation-using-large-language-modelhttpsarxivorgabs251221293v1 aria-label="Quadrupped-Legged Robot Movement Plan Generation using Large Language Model"><a href=https://arxiv.org/abs/2512.21293v1>Quadrupped-Legged Robot Movement Plan Generation using Large Language Model</a></a></li><li><a href=#navier-stokes-cahn-hilliard-system-in-a-3d-perforated-domain-with-free-slip-and-source-term-existence-and-homogenizationhttpsarxivorgabs251221171v1 aria-label="Navier-Stokes-Cahn-Hilliard system in a $3$D perforated domain with free slip and source term: Existence and homogenization"><a href=https://arxiv.org/abs/2512.21171v1>Navier-Stokes-Cahn-Hilliard system in a $3$D perforated domain with free slip and source term: Existence and homogenization</a></a></li><li><a href=#topological-interface-states-and-nonlinear-thermoelectric-performance-in-armchair-graphene-nanoribbon-heterostructureshttpsarxivorgabs251221121v1 aria-label="Topological Interface States and Nonlinear Thermoelectric Performance in Armchair Graphene Nanoribbon Heterostructures"><a href=https://arxiv.org/abs/2512.21121v1>Topological Interface States and Nonlinear Thermoelectric Performance in Armchair Graphene Nanoribbon Heterostructures</a></a></li></ul></li><li><a href=#-data_resources aria-label="üîç data_resources">üîç data_resources</a><ul><li><a href=#surgical-scene-segmentation-using-a-spike-driven-video-transformer-with-real-time-potentialhttpsarxivorgabs251221284v1 aria-label="Surgical Scene Segmentation using a Spike-Driven Video Transformer with Real-Time Potential"><a href=https://arxiv.org/abs/2512.21284v1>Surgical Scene Segmentation using a Spike-Driven Video Transformer with Real-Time Potential</a></a></li><li><a href=#marineeval-assessing-the-marine-intelligence-of-vision-language-modelshttpsarxivorgabs251221126v1 aria-label="MarineEval: Assessing the Marine Intelligence of Vision-Language Models"><a href=https://arxiv.org/abs/2512.21126v1>MarineEval: Assessing the Marine Intelligence of Vision-Language Models</a></a></li><li><a href=#beyond-pixel-simulation-pathology-image-generation-via-diagnostic-semantic-tokens-and-prototype-controlhttpsarxivorgabs251221058v1 aria-label="Beyond Pixel Simulation: Pathology Image Generation via Diagnostic Semantic Tokens and Prototype Control"><a href=https://arxiv.org/abs/2512.21058v1>Beyond Pixel Simulation: Pathology Image Generation via Diagnostic Semantic Tokens and Prototype Control</a></a></li><li><a href=#learning-the-macroeconomic-languagehttpsarxivorgabs251221031v1 aria-label="Learning the Macroeconomic Language"><a href=https://arxiv.org/abs/2512.21031v1>Learning the Macroeconomic Language</a></a></li><li><a href=#latent-implicit-visual-reasoninghttpsarxivorgabs251221218v1 aria-label="Latent Implicit Visual Reasoning"><a href=https://arxiv.org/abs/2512.21218v1>Latent Implicit Visual Reasoning</a></a></li><li><a href=#architectural-trade-offs-in-small-language-models-under-compute-constraintshttpsarxivorgabs251220877v1 aria-label="Architectural Trade-offs in Small Language Models Under Compute Constraints"><a href=https://arxiv.org/abs/2512.20877v1>Architectural Trade-offs in Small Language Models Under Compute Constraints</a></a></li></ul></li><li><a href=#-emotion_language aria-label="üîç emotion_language">üîç emotion_language</a><ul><li><a href=#pluricanonical-geometry-of-varieties-isogenous-to-a-product-chevalley-weil-theory-and-pluricanonical-decompositions-of-abelian-covershttpsarxivorgabs251221294v1 aria-label="Pluricanonical Geometry of Varieties Isogenous to a Product: Chevalley-Weil Theory and Pluricanonical Decompositions of Abelian Covers"><a href=https://arxiv.org/abs/2512.21294v1>Pluricanonical Geometry of Varieties Isogenous to a Product: Chevalley-Weil Theory and Pluricanonical Decompositions of Abelian Covers</a></a></li><li><a href=#multivariate-scaling-of-proton-and-ion-energies-divergence-and-charge-states-in-target-normal-sheath-accelerationhttpsarxivorgabs251221279v1 aria-label="Multivariate scaling of proton and ion energies, divergence, and charge states in Target Normal Sheath Acceleration"><a href=https://arxiv.org/abs/2512.21279v1>Multivariate scaling of proton and ion energies, divergence, and charge states in Target Normal Sheath Acceleration</a></a></li><li><a href=#a-unified-framework-for-eeg-seizure-detection-using-universum-integrated-generalized-eigenvalues-proximal-support-vector-machinehttpsarxivorgabs251221170v1 aria-label="A Unified Framework for EEG Seizure Detection Using Universum-Integrated Generalized Eigenvalues Proximal Support Vector Machine"><a href=https://arxiv.org/abs/2512.21170v1>A Unified Framework for EEG Seizure Detection Using Universum-Integrated Generalized Eigenvalues Proximal Support Vector Machine</a></a></li><li><a href=#variationally-correct-operator-learning-reduced-basis-neural-operator-with-a-posteriori-error-estimationhttpsarxivorgabs251221319v1 aria-label="Variationally correct operator learning: Reduced basis neural operator with a posteriori error estimation"><a href=https://arxiv.org/abs/2512.21319v1>Variationally correct operator learning: Reduced basis neural operator with a posteriori error estimation</a></a></li><li><a href=#twist-tuned-strong-coupling-in-sub-ghz-wire-metasurface-bilayershttpsarxivorgabs251221277v1 aria-label="Twist-Tuned Strong Coupling in Sub-GHz Wire Metasurface Bilayers"><a href=https://arxiv.org/abs/2512.21277v1>Twist-Tuned Strong Coupling in Sub-GHz Wire Metasurface Bilayers</a></a></li><li><a href=#post-processing-mask-based-table-segmentation-for-structural-coordinate-extractionhttpsarxivorgabs251221287v1 aria-label="Post-Processing Mask-Based Table Segmentation for Structural Coordinate Extraction"><a href=https://arxiv.org/abs/2512.21287v1>Post-Processing Mask-Based Table Segmentation for Structural Coordinate Extraction</a></a></li><li><a href=#industrial-ouroboros-deep-lateral-movement-via-living-off-the-planthttpsarxivorgabs251221248v1 aria-label="Industrial Ouroboros: Deep Lateral Movement via Living Off the Plant"><a href=https://arxiv.org/abs/2512.21248v1>Industrial Ouroboros: Deep Lateral Movement via Living Off the Plant</a></a></li><li><a href=#learning-to-solve-pdes-on-neural-shape-representationshttpsarxivorgabs251221311v1 aria-label="Learning to Solve PDEs on Neural Shape Representations"><a href=https://arxiv.org/abs/2512.21311v1>Learning to Solve PDEs on Neural Shape Representations</a></a></li><li><a href=#a-community-enhanced-graph-representation-model-for-link-predictionhttpsarxivorgabs251221166v1 aria-label="A Community-Enhanced Graph Representation Model for Link Prediction"><a href=https://arxiv.org/abs/2512.21166v1>A Community-Enhanced Graph Representation Model for Link Prediction</a></a></li><li><a href=#emotion-diffusion-in-real-and-simulated-social-graphs-structural-limits-of-llm-based-social-simulationhttpsarxivorgabs251221138v1 aria-label="Emotion Diffusion in Real and Simulated Social Graphs: Structural Limits of LLM-Based Social Simulation"><a href=https://arxiv.org/abs/2512.21138v1>Emotion Diffusion in Real and Simulated Social Graphs: Structural Limits of LLM-Based Social Simulation</a></a></li><li><a href=#mental-health-self-disclosure-on-social-media-throughout-the-pandemic-periodhttpsarxivorgabs251220990v1 aria-label="Mental Health Self-Disclosure on Social Media throughout the Pandemic Period"><a href=https://arxiv.org/abs/2512.20990v1>Mental Health Self-Disclosure on Social Media throughout the Pandemic Period</a></a></li><li><a href=#from-human-bias-to-robot-choice-how-occupational-contexts-and-racial-priming-shape-robot-selectionhttpsarxivorgabs251220951v1 aria-label="From Human Bias to Robot Choice: How Occupational Contexts and Racial Priming Shape Robot Selection"><a href=https://arxiv.org/abs/2512.20951v1>From Human Bias to Robot Choice: How Occupational Contexts and Racial Priming Shape Robot Selection</a></a></li><li><a href=#welfare-at-risk-distributional-impact-of-policy-interventionshttpsarxivorgabs251220918v1 aria-label="Welfare at Risk: Distributional impact of policy interventions"><a href=https://arxiv.org/abs/2512.20918v1>Welfare at Risk: Distributional impact of policy interventions</a></a></li></ul></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=weekly-paper-notes>Weekly Paper Notes<a hidden class=anchor aria-hidden=true href=#weekly-paper-notes>#</a></h1><h2 id=-multilingual>üîç multilingual<a hidden class=anchor aria-hidden=true href=#-multilingual>#</a></h2><h3 id=model-merging-via-multi-teacher-knowledge-distillationhttpsarxivorgabs251221288v1><a href=https://arxiv.org/abs/2512.21288v1>Model Merging via Multi-Teacher Knowledge Distillation</a><a hidden class=anchor aria-hidden=true href=#model-merging-via-multi-teacher-knowledge-distillationhttpsarxivorgabs251221288v1>#</a></h3><p><strong>Authors:</strong> Seyed Arshan Dalili, Mehrdad Mahdavi
<strong>Venue:</strong> arXiv (2025)</p><p>Model merging has emerged as a lightweight alternative to joint multi-task learning (MTL), yet the generalization properties of merged models remain largely unexplored. Establishing such theoretical guarantees is non-trivial, as the merging process typically forbids access to the original training data and involves combining fine-tuned models trained on fundamentally heterogeneous data distributions. Without a principled understanding of these dynamics, current methods often rely on heuristics to approximate the optimal combination of parameters. This dependence is most critical in coefficient scaling, the weighting factors that modulate the magnitude of each fine-tuned model&rsquo;s contribution to the shared parameter. However, without a principled objective to guide their selection, these methods lead to brittle performance and are highly sensitive to scaling initialization. We address this gap by (i) establishing a novel flatness-aware PAC-Bayes generalization bound specifically for the model merging setting. This analysis introduces a &ldquo;cross-task heterogeneity&rdquo; term that formally captures the mismatch between diverse fine-tuned model priors and the target multi-task distributions. Guided by this theoretical insight, (ii) we frame model merging as multi-teacher knowledge distillation on scarce, unlabeled data. We formally demonstrate that minimizing the student-teacher Kullback-Leibler divergence directly tightens the upper bound on the merged model&rsquo;s excess risk. Guided by the flatness-aware bound derived, (iii) we operationalize this objective via SAMerging, a method that employs Sharpness-Aware Minimization (SAM) to find flat minima. Empirically, SAMerging establishes a new state of the art across vision and NLP benchmarks, achieving remarkable performance. The code is available at <a href=https://github.com/arshandalili/SAMerging>https://github.com/arshandalili/SAMerging</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21288v1">üìÑ Download PDF</a></p><hr><h3 id=learning-from-next-frame-prediction-autoregressive-video-modeling-encodes-effective-representationshttpsarxivorgabs251221004v1><a href=https://arxiv.org/abs/2512.21004v1>Learning from Next-Frame Prediction: Autoregressive Video Modeling Encodes Effective Representations</a><a hidden class=anchor aria-hidden=true href=#learning-from-next-frame-prediction-autoregressive-video-modeling-encodes-effective-representationshttpsarxivorgabs251221004v1>#</a></h3><p><strong>Authors:</strong> Jinghan Li, Yang Jin, Hao Jiang, Yadong Mu, Yang Song, Kun Xu
<strong>Venue:</strong> arXiv (2025)</p><p>Recent advances in pretraining general foundation models have significantly improved performance across diverse downstream tasks. While autoregressive (AR) generative models like GPT have revolutionized NLP, most visual generative pretraining methods still rely on BERT-style masked modeling, which often disregards the temporal information essential for video analysis. The few existing autoregressive visual pretraining methods suffer from issues such as inaccurate semantic localization and poor generation quality, leading to poor semantics. In this work, we propose NExT-Vid, a novel autoregressive visual generative pretraining framework that utilizes masked next-frame prediction to jointly model images and videos. NExT-Vid introduces a context-isolated autoregressive predictor to decouple semantic representation from target decoding, and a conditioned flow-matching decoder to enhance generation quality and diversity. Through context-isolated flow-matching pretraining, our approach achieves strong representations. Extensive experiments on large-scale pretrained models demonstrate that our proposed method consistently outperforms previous generative pretraining methods for visual representation learning via attentive probing in downstream classification.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21004v1">üìÑ Download PDF</a></p><hr><h3 id=multimind-at-semeval-2025-task-7-crosslingual-fact-checked-claim-retrieval-via-multi-source-alignmenthttpsarxivorgabs251220950v1><a href=https://arxiv.org/abs/2512.20950v1>MultiMind at SemEval-2025 Task 7: Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment</a><a hidden class=anchor aria-hidden=true href=#multimind-at-semeval-2025-task-7-crosslingual-fact-checked-claim-retrieval-via-multi-source-alignmenthttpsarxivorgabs251220950v1>#</a></h3><p><strong>Authors:</strong> Mohammad Mahdi Abootorabi, Alireza Ghahramani Kure, Mohammadali Mohammadkhani, Sina Elahimanesh, Mohammad Ali Ali Panah
<strong>Venue:</strong> arXiv (2025)</p><p>This paper presents our system for SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval. In an era where misinformation spreads rapidly, effective fact-checking is increasingly critical. We introduce TriAligner, a novel approach that leverages a dual-encoder architecture with contrastive learning and incorporates both native and English translations across different modalities. Our method effectively retrieves claims across multiple languages by learning the relative importance of different sources in alignment. To enhance robustness, we employ efficient data preprocessing and augmentation using large language models while incorporating hard negative sampling to improve representation learning. We evaluate our approach on monolingual and crosslingual benchmarks, demonstrating significant improvements in retrieval accuracy and fact-checking performance over baselines.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20950v1">üìÑ Download PDF</a></p><hr><h3 id=swerank-multilingual-multi-turn-code-ranking-for-software-issue-localizationhttpsarxivorgabs251220482v1><a href=https://arxiv.org/abs/2512.20482v1>SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization</a><a hidden class=anchor aria-hidden=true href=#swerank-multilingual-multi-turn-code-ranking-for-software-issue-localizationhttpsarxivorgabs251220482v1>#</a></h3><p><strong>Authors:</strong> Revanth Gangi Reddy, Ye Liu, Wenting Zhao, JaeHyeok Doo, Tarun Suresh, Daniel Lee, Caiming Xiong, Yingbo Zhou, Semih Yavuz, Shafiq Joty
<strong>Venue:</strong> arXiv (2025)</p><p>Maintaining large-scale, multilingual codebases hinges on accurately localizing issues, which requires mapping natural-language error descriptions to the relevant functions that need to be modified. However, existing ranking approaches are often Python-centric and perform a single-pass search over the codebase. This work introduces SweRank+, a framework that couples SweRankMulti, a cross-lingual code ranking tool, with SweRankAgent, an agentic search setup, for iterative, multi-turn reasoning over the code repository. SweRankMulti comprises a code embedding retriever and a listwise LLM reranker, and is trained using a carefully curated large-scale issue localization dataset spanning multiple popular programming languages. SweRankAgent adopts an agentic search loop that moves beyond single-shot localization with a memory buffer to reason and accumulate relevant localization candidates over multiple turns. Our experiments on issue localization benchmarks spanning various languages demonstrate new state-of-the-art performance with SweRankMulti, while SweRankAgent further improves localization over single-pass ranking.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20482v1">üìÑ Download PDF</a></p><hr><h3 id=linking-faces-and-voices-across-languages-insights-from-the-fame-2026-challengehttpsarxivorgabs251220376v1><a href=https://arxiv.org/abs/2512.20376v1>Linking Faces and Voices Across Languages: Insights from the FAME 2026 Challenge</a><a hidden class=anchor aria-hidden=true href=#linking-faces-and-voices-across-languages-insights-from-the-fame-2026-challengehttpsarxivorgabs251220376v1>#</a></h3><p><strong>Authors:</strong> Marta Moscati, Ahmed Abdullah, Muhammad Saad Saeed, Shah Nawaz, Rohan Kumar Das, Muhammad Zaigham Zaheer, Junaid Mir, Muhammad Haroon Yousaf, Khalid Mahmood Malik, Markus Schedl
<strong>Venue:</strong> arXiv (2025)</p><p>Over half of the world&rsquo;s population is bilingual and people often communicate under multilingual scenarios. The Face-Voice Association in Multilingual Environments (FAME) 2026 Challenge, held at ICASSP 2026, focuses on developing methods for face-voice association that are effective when the language at test-time is different than the training one. This report provides a brief summary of the challenge.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20376v1">üìÑ Download PDF</a></p><hr><h3 id=can-llms-solve-my-grandmas-riddle-evaluating-multilingual-large-language-models-on-reasoning-traditional-bangla-tricky-riddleshttpsarxivorgabs251220324v1><a href=https://arxiv.org/abs/2512.20324v1>Can LLMs Solve My Grandma&rsquo;s Riddle? Evaluating Multilingual Large Language Models on Reasoning Traditional Bangla Tricky Riddles</a><a hidden class=anchor aria-hidden=true href=#can-llms-solve-my-grandmas-riddle-evaluating-multilingual-large-language-models-on-reasoning-traditional-bangla-tricky-riddleshttpsarxivorgabs251220324v1>#</a></h3><p><strong>Authors:</strong> Nurul Labib Sayeedi, Md. Faiyaz Abdullah Sayeedi, Khushnur Binte Jahangir, Swakkhar Shatabda, Sarah Masud Preum
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Models (LLMs) show impressive performance on many NLP benchmarks, yet their ability to reason in figurative, culturally grounded, and low-resource settings remains underexplored. We address this gap for Bangla by introducing BanglaRiddleEval, a benchmark of 1,244 traditional Bangla riddles instantiated across four tasks (4,976 riddle-task artifacts in total). Using an LLM-based pipeline, we generate Chain-of-Thought explanations, semantically coherent distractors, and fine-grained ambiguity annotations, and evaluate a diverse suite of open-source and closed-source models under different prompting strategies. Models achieve moderate semantic overlap on generative QA but low correctness, MCQ accuracy peaks at only about 56% versus an 83% human baseline, and ambiguity resolution ranges from roughly 26% to 68%, with high-quality explanations confined to the strongest models. These results show that current LLMs capture some cues needed for Bangla riddle reasoning but remain far from human-level performance, establishing BanglaRiddleEval as a challenging new benchmark for low-resource figurative reasoning. All data, code, and evaluation scripts are available on GitHub: <a href=https://github.com/Labib1610/BanglaRiddleEval>https://github.com/Labib1610/BanglaRiddleEval</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20324v1">üìÑ Download PDF</a></p><hr><h3 id=foundation-model-based-evaluation-of-neuropsychiatric-disorders-a-lifespan-inclusive-multi-modal-and-multi-lingual-studyhttpsarxivorgabs251220948v1><a href=https://arxiv.org/abs/2512.20948v1>Foundation Model-based Evaluation of Neuropsychiatric Disorders: A Lifespan-Inclusive, Multi-Modal, and Multi-Lingual Study</a><a hidden class=anchor aria-hidden=true href=#foundation-model-based-evaluation-of-neuropsychiatric-disorders-a-lifespan-inclusive-multi-modal-and-multi-lingual-studyhttpsarxivorgabs251220948v1>#</a></h3><p><strong>Authors:</strong> Zhongren Dong, Haotian Guo, Weixiang Xu, Huan Zhao, Zixing Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>Neuropsychiatric disorders, such as Alzheimer&rsquo;s disease (AD), depression, and autism spectrum disorder (ASD), are characterized by linguistic and acoustic abnormalities, offering potential biomarkers for early detection. Despite the promise of multi-modal approaches, challenges like multi-lingual generalization and the absence of a unified evaluation framework persist. To address these gaps, we propose FEND (Foundation model-based Evaluation of Neuropsychiatric Disorders), a comprehensive multi-modal framework integrating speech and text modalities for detecting AD, depression, and ASD across the lifespan. Leveraging 13 multi-lingual datasets spanning English, Chinese, Greek, French, and Dutch, we systematically evaluate multi-modal fusion performance. Our results show that multi-modal fusion excels in AD and depression detection but underperforms in ASD due to dataset heterogeneity. We also identify modality imbalance as a prevalent issue, where multi-modal fusion fails to surpass the best mono-modal models. Cross-corpus experiments reveal robust performance in task- and language-consistent scenarios but noticeable degradation in multi-lingual and task-heterogeneous settings. By providing extensive benchmarks and a detailed analysis of performance-influencing factors, FEND advances the field of automated, lifespan-inclusive, and multi-lingual neuropsychiatric disorder assessment. We encourage researchers to adopt the FEND framework for fair comparisons and reproducible research.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20948v1">üìÑ Download PDF</a></p><hr><h3 id=corpus-of-cross-lingual-dialogues-with-minutes-and-detection-of-misunderstandingshttpsarxivorgabs251220204v1><a href=https://arxiv.org/abs/2512.20204v1>Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings</a><a hidden class=anchor aria-hidden=true href=#corpus-of-cross-lingual-dialogues-with-minutes-and-detection-of-misunderstandingshttpsarxivorgabs251220204v1>#</a></h3><p><strong>Authors:</strong> Marko ƒåechoviƒç, Nat√°lia Komorn√≠kov√°, Dominik Mach√°ƒçek, Ond≈ôej Bojar
<strong>Venue:</strong> arXiv (2025)</p><p>Speech processing and translation technology have the potential to facilitate meetings of individuals who do not share any common language. To evaluate automatic systems for such a task, a versatile and realistic evaluation corpus is needed. Therefore, we create and present a corpus of cross-lingual dialogues between individuals without a common language who were facilitated by automatic simultaneous speech translation. The corpus consists of 5 hours of speech recordings with ASR and gold transcripts in 12 original languages and automatic and corrected translations into English. For the purposes of research into cross-lingual summarization, our corpus also includes written summaries (minutes) of the meetings.
Moreover, we propose automatic detection of misunderstandings. For an overview of this task and its complexity, we attempt to quantify misunderstandings in cross-lingual meetings. We annotate misunderstandings manually and also test the ability of current large language models to detect them automatically. The results show that the Gemini model is able to identify text spans with misunderstandings with recall of 77% and precision of 47%.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20204v1">üìÑ Download PDF</a></p><hr><h3 id=maubert-universal-phonetic-inductive-biases-for-few-shot-acoustic-units-discoveryhttpsarxivorgabs251219612v1><a href=https://arxiv.org/abs/2512.19612v1>MauBERT: Universal Phonetic Inductive Biases for Few-Shot Acoustic Units Discovery</a><a hidden class=anchor aria-hidden=true href=#maubert-universal-phonetic-inductive-biases-for-few-shot-acoustic-units-discoveryhttpsarxivorgabs251219612v1>#</a></h3><p><strong>Authors:</strong> Angelo Ortiz Tandazo, Manel Khentout, Youssef Benchekroun, Thomas Hueber, Emmanuel Dupoux
<strong>Venue:</strong> arXiv (2025)</p><p>This paper introduces MauBERT, a multilingual extension of HuBERT that leverages articulatory features for robust cross-lingual phonetic representation learning. We continue HuBERT pre-training with supervision based on a phonetic-to-articulatory feature mapping in 55 languages. Our models learn from multilingual data to predict articulatory features or phones, resulting in language-independent representations that capture multilingual phonetic properties. Through comprehensive ABX discriminability testing, we show MauBERT models produce more context-invariant representations than state-of-the-art multilingual self-supervised learning models. Additionally, the models effectively adapt to unseen languages and casual speech with minimal self-supervised fine-tuning (10 hours of speech). This establishes an effective approach for instilling linguistic inductive biases in self-supervised speech models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.19612v1">üìÑ Download PDF</a></p><hr><h3 id=event-extraction-in-large-language-modelhttpsarxivorgabs251219537v1><a href=https://arxiv.org/abs/2512.19537v1>Event Extraction in Large Language Model</a><a hidden class=anchor aria-hidden=true href=#event-extraction-in-large-language-modelhttpsarxivorgabs251219537v1>#</a></h3><p><strong>Authors:</strong> Bobo Li, Xudong Han, Jiang Liu, Yuzhe Ding, Liqiang Jing, Zhaoqi Zhang, Jinheng Li, Xinya Du, Fei Li, Meishan Zhang, Min Zhang, Aixin Sun, Philip S. Yu, Hao Fei
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) and multimodal LLMs are changing event extraction (EE): prompting and generation can often produce structured outputs in zero shot or few shot settings. Yet LLM based pipelines face deployment gaps, including hallucinations under weak constraints, fragile temporal and causal linking over long contexts and across documents, and limited long horizon knowledge management within a bounded context window. We argue that EE should be viewed as a system component that provides a cognitive scaffold for LLM centered solutions. Event schemas and slot constraints create interfaces for grounding and verification; event centric structures act as controlled intermediate representations for stepwise reasoning; event links support relation aware retrieval with graph based RAG; and event stores offer updatable episodic and agent memory beyond the context window. This survey covers EE in text and multimodal settings, organizing tasks and taxonomy, tracing method evolution from rule based and neural models to instruction driven and generative frameworks, and summarizing formulations, decoding strategies, architectures, representations, datasets, and evaluation. We also review cross lingual, low resource, and domain specific settings, and highlight open challenges and future directions for reliable event centric systems. Finally, we outline open challenges and future directions that are central to the LLM era, aiming to evolve EE from static extraction into a structurally reliable, agent ready perception and memory layer for open world systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.19537v1">üìÑ Download PDF</a></p><hr><h3 id=omnimer-indonesian-multimodal-emotion-recognition-via-auxiliary-enhanced-llm-adaptationhttpsarxivorgabs251219379v1><a href=https://arxiv.org/abs/2512.19379v1>OmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation</a><a hidden class=anchor aria-hidden=true href=#omnimer-indonesian-multimodal-emotion-recognition-via-auxiliary-enhanced-llm-adaptationhttpsarxivorgabs251219379v1>#</a></h3><p><strong>Authors:</strong> Xueming Yan, Boyan Xu, Yaochu Jin, Lixian Xiao, Wenlong Ye, Runyang Cai, Zeqi Zheng, Jingfa Liu, Aimin Yang
<strong>Venue:</strong> arXiv (2025)</p><p>Indonesian, spoken by over 200 million people, remains underserved in multimodal emotion recognition research despite its dominant presence on Southeast Asian social media platforms. We introduce IndoMER, the first multimodal emotion recognition benchmark for Indonesian, comprising 1,944 video segments from 203 speakers with temporally aligned text, audio, and visual annotations across seven emotion categories. The dataset exhibits realistic challenges including cross-modal inconsistency and long-tailed class distributions shaped by Indonesian cultural communication norms. To address these challenges, we propose OmniMER, a multimodal adaptation framework built upon Qwen2.5-Omni that enhances emotion recognition through three auxiliary modality-specific perception tasks: emotion keyword extraction for text, facial expression analysis for video, and prosody analysis for audio. These auxiliary tasks help the model identify emotion-relevant cues in each modality before fusion, reducing reliance on spurious correlations in low-resource settings. Experiments on IndoMER show that OmniMER achieves 0.582 Macro-F1 on sentiment classification and 0.454 on emotion recognition, outperforming the base model by 7.6 and 22.1 absolute points respectively. Cross-lingual evaluation on the Chinese CH-SIMS dataset further demonstrates the generalizability of the proposed framework. The dataset and code are publicly available. <a href=https://github.com/yanxm01/INDOMER>https://github.com/yanxm01/INDOMER</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.19379v1">üìÑ Download PDF</a></p><hr><h3 id=quantitative-financial-modeling-for-sri-lankan-markets-approach-combining-nlp-clustering-and-time-series-forecastinghttpsarxivorgabs251220216v1><a href=https://arxiv.org/abs/2512.20216v1>Quantitative Financial Modeling for Sri Lankan Markets: Approach Combining NLP, Clustering and Time-Series Forecasting</a><a hidden class=anchor aria-hidden=true href=#quantitative-financial-modeling-for-sri-lankan-markets-approach-combining-nlp-clustering-and-time-series-forecastinghttpsarxivorgabs251220216v1>#</a></h3><p><strong>Authors:</strong> Linuk Perera
<strong>Venue:</strong> arXiv (2025)</p><p>This research introduces a novel quantitative methodology tailored for quantitative finance applications, enabling banks, stockbrokers, and investors to predict economic regimes and market signals in emerging markets, specifically Sri Lankan stock indices (S&amp;P SL20 and ASPI) by integrating Environmental, Social, and Governance (ESG) sentiment analysis with macroeconomic indicators and advanced time-series forecasting. Designed to leverage quantitative techniques for enhanced risk assessment, portfolio optimization, and trading strategies in volatile environments, the architecture employs FinBERT, a transformer-based NLP model, to extract sentiment from ESG texts, followed by unsupervised clustering (UMAP/HDBSCAN) to identify 5 latent ESG regimes, validated via PCA. These regimes are mapped to economic conditions using a dense neural network and gradient boosting classifier, achieving 84.04% training and 82.0% validation accuracy. Concurrently, time-series models (SRNN, MLP, LSTM, GRU) forecast daily closing prices, with GRU attaining an R-squared of 0.801 and LSTM delivering 52.78% directional accuracy on intraday data. A strong correlation between S&amp;P SL20 and S&amp;P 500, observed through moving average and volatility trend plots, further bolsters forecasting precision. A rule-based fusion logic merges ESG and time-series outputs for final market signals. By addressing literature gaps that overlook emerging markets and holistic integration, this quant-driven framework combines global correlations and local sentiment analysis to offer scalable, accurate tools for quantitative finance professionals navigating complex markets like Sri Lanka.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20216v1">üìÑ Download PDF</a></p><hr><h3 id=neuron-guided-interpretation-of-code-llms-where-why-and-howhttpsarxivorgabs251219980v1><a href=https://arxiv.org/abs/2512.19980v1>Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?</a><a hidden class=anchor aria-hidden=true href=#neuron-guided-interpretation-of-code-llms-where-why-and-howhttpsarxivorgabs251219980v1>#</a></h3><p><strong>Authors:</strong> Zhe Yin, Xiaodong Gu, Beijun Shen
<strong>Venue:</strong> arXiv (2025)</p><p>Code language models excel on code intelligence tasks, yet their internal interpretability is underexplored. Existing neuron interpretability techniques from NLP are suboptimal for source code due to programming languages formal, hierarchical, and executable nature. We empirically investigate code LLMs at the neuron level, localizing language-specific neurons (selectively responsive to one language) and concept layers (feed-forward layers encoding language-agnostic code representations). We analyze Llama-3.1-8B and Qwen2.5-Coder-32B on multilingual inputs in C++, Java, Python, Go, and JavaScript, measuring neuron selectivity and layerwise contributions during generation. We find (1) neurons specialized for individual languages alongside a universal subset supporting general-purpose generation; and (2) lower layers mainly encode language-specific syntax, while middle layers capture semantic abstractions shared across languages, emerging as concept layers. We demonstrate utility on three tasks: neuron-guided fine-tuning for code generation, clone detection via concept-layer embeddings, and concept-layer-guided transfer for code summarization, each yielding consistent gains in multilingual settings.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.19980v1">üìÑ Download PDF</a></p><hr><h3 id=a-high-dimensional-quantum-blockchain-protocol-based-on-time--entanglementhttpsarxivorgabs251220489v1><a href=https://arxiv.org/abs/2512.20489v1>A High-Dimensional Quantum Blockchain Protocol Based on Time- Entanglement</a><a hidden class=anchor aria-hidden=true href=#a-high-dimensional-quantum-blockchain-protocol-based-on-time--entanglementhttpsarxivorgabs251220489v1>#</a></h3><p><strong>Authors:</strong> Akta≈ü, Arzu, Yƒ±lmaz, ƒ∞hsan
<strong>Venue:</strong> arXiv (2025)</p><p>Rapid advancements in quantum computing and machine learning threaten the long-term security of classical blockchain systems, whose protection mechanisms largely rely on computational difficulties. In this study, we propose a quantum blockchain protocol whose protection mechanism is directly derived from quantum mechanical principles. The protocol combines high-dimensional Bell states, time-entanglement, entanglement switching, and high-dimensional superdense coding. Encoding classical block information into time-delimited qudit states allows block identity and data verification to be implemented through the causal sequencing of quantum measurements instead of cryptographic hash functions. High-dimensional coding increases the information capacity per quantum carrier and improves noise resistance. Time-entanglement provides distributed authentication, non-repudiation, and tamper detection across the blockchain. Each block derives its own public-private key pair directly from the observed quantum correlations by performing high-dimensional Bell state measurements in successive time steps. Because these keys are dependent on the time ordering of measurements, attempts to alter block data or disrupt the protocol&rsquo;s timing structure inevitably affect the reconstructed correlations and are revealed during validation. Recent advances in the creation and detection of high-dimensional time-slice entanglement demonstrate that the necessary quantum resources are compatible with emerging quantum communication platforms. Taken together, these considerations suggest that the proposed framework can be evaluated as a viable and scalable candidate for quantum-secure blockchain architectures in future quantum network environments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20489v1">üìÑ Download PDF</a></p><hr><h3 id=scalable-relay-switching-platform-for-automated-multi-point-resistance-measurementshttpsarxivorgabs251220419v1><a href=https://arxiv.org/abs/2512.20419v1>Scalable Relay Switching Platform for Automated Multi-Point Resistance Measurements</a><a hidden class=anchor aria-hidden=true href=#scalable-relay-switching-platform-for-automated-multi-point-resistance-measurementshttpsarxivorgabs251220419v1>#</a></h3><p><strong>Authors:</strong> Edoardo Boretti, Kostiantyn Torokhtii, Enrico Silva, Andrea Alimenti
<strong>Venue:</strong> arXiv (2025)</p><p>In both research and industrial settings, it is often necessary to expand the input/output channels of measurement instruments using relay-based multiplexer boards. In research activities in particular, the need for a highly flexible and easily configurable solution frequently leads to the development of customized systems. To address this challenge, we developed a system optimized for automated direct current (DC) measurements. The result is based on a 4x4 switching platform that simplifies measurement procedures that require instrument routing. The platform is based on a custom-designed circuit board controlled by a microcontroller. We selected bistable relays to guarantee contact stability after switching. We finally developed a system architecture that allows for straightforward expansion and scalability by connecting multiple platforms. We share both the hardware design source files and the firmware source code on GitHub with the open-source community. This work presents the design and development of the proposed system, followed by the performance evaluation. Finally, we present a test of our designed system applied to a specific case study: the DC analysis of complex resistive networks through multi-point resistance measurements using only a single voltmeter and current source.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20419v1">üìÑ Download PDF</a></p><hr><h3 id=kunnafonidilaw-ka-cadeau-an-asr-dataset-of-present-day-bambarahttpsarxivorgabs251219400v1><a href=https://arxiv.org/abs/2512.19400v1>Kunnafonidilaw ka Cadeau: an ASR dataset of present-day Bambara</a><a hidden class=anchor aria-hidden=true href=#kunnafonidilaw-ka-cadeau-an-asr-dataset-of-present-day-bambarahttpsarxivorgabs251219400v1>#</a></h3><p><strong>Authors:</strong> Yacouba Diarra, Panga Azazia Kamate, Nouhoum Souleymane Coulibaly, Michael Leventhal
<strong>Venue:</strong> arXiv (2025)</p><p>We present Kunkado, a 160-hour Bambara ASR dataset compiled from Malian radio archives to capture present-day spontaneous speech across a wide range of topics. It includes code-switching, disfluencies, background noise, and overlapping speakers that practical ASR systems encounter in real-world use. We finetuned Parakeet-based models on a 33.47-hour human-reviewed subset and apply pragmatic transcript normalization to reduce variability in number formatting, tags, and code-switching annotations. Evaluated on two real-world test sets, finetuning with Kunkado reduces WER from 44.47% to 37.12% on one and from 36.07% to 32.33% on the other. In human evaluation, the resulting model also outperforms a comparable system with the same architecture trained on 98 hours of cleaner, less realistic speech. We release the data and models to support robust ASR for predominantly oral languages.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.19400v1">üìÑ Download PDF</a></p><hr><h3 id=milton-friedmans-spending-matrix-revisited-spending-efficiency-and-preference-compatibility-across-different-economic-systemshttpsarxivorgabs251219984v1><a href=https://arxiv.org/abs/2512.19984v1>Milton Friedman&rsquo;s spending matrix revisited: &lsquo;Spending efficiency&rsquo; and &lsquo;preference compatibility&rsquo; across different economic systems</a><a hidden class=anchor aria-hidden=true href=#milton-friedmans-spending-matrix-revisited-spending-efficiency-and-preference-compatibility-across-different-economic-systemshttpsarxivorgabs251219984v1>#</a></h3><p><strong>Authors:</strong> Ali Zeytoon-Nejad
<strong>Venue:</strong> arXiv (2025)</p><p>This article expands Milton Friedman&rsquo;s spending matrix to analyse &lsquo;spending efficiency&rsquo; and &lsquo;preference compatibility&rsquo; across different economic systems against five key outcome criteria. By generalising Friedman&rsquo;s typology, it compares efficiency and freedom as systems shift from laissez-faire capitalism to communism, illustrating a gradual deterioration in their key outcomes. While government intervention is sometimes necessary to address market failures, its role should always be carefully limited to avoid inefficiency and misalignment with individual preferences. The insights may provide guidance for policymakers in designing economic systems and policies that promote both economic prosperity and personal liberty.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.19984v1">üìÑ Download PDF</a></p><hr><h3 id=beyond-memorization-a-multi-modal-ordinal-regression-benchmark-to-expose-popularity-bias-in-vision-language-modelshttpsarxivorgabs251221337v1><a href=https://arxiv.org/abs/2512.21337v1>Beyond Memorization: A Multi-Modal Ordinal Regression Benchmark to Expose Popularity Bias in Vision-Language Models</a><a hidden class=anchor aria-hidden=true href=#beyond-memorization-a-multi-modal-ordinal-regression-benchmark-to-expose-popularity-bias-in-vision-language-modelshttpsarxivorgabs251221337v1>#</a></h3><p><strong>Authors:</strong> Li-Zhong Szu-Tu, Ting-Lin Wu, Chia-Jui Chang, He Syu, Yu-Lun Liu
<strong>Venue:</strong> arXiv (2025)</p><p>We expose a significant popularity bias in state-of-the-art vision-language models (VLMs), which achieve up to 34% higher accuracy on famous buildings compared to ordinary ones, indicating a reliance on memorization over generalizable understanding. To systematically investigate this, we introduce the largest open benchmark for this task: the YearGuessr dataset, a collection of 55,546 building images with multi-modal attributes from 157 countries, annotated with continuous ordinal labels of their construction year (1001-2024), GPS data, and page-view counts as a proxy for popularity. Using this dataset, we frame the construction year prediction task as ordinal regression and introduce popularity-aware interval accuracy metrics to quantify this bias. Our resulting benchmark of 30+ models, including our YearCLIP model, confirms that VLMs excel on popular, memorized items but struggle significantly with unrecognized subjects, exposing a critical flaw in their reasoning capabilities. Project page: <a href=https://sytwu.github.io/BeyondMemo/>https://sytwu.github.io/BeyondMemo/</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21337v1">üìÑ Download PDF</a></p><hr><h3 id=optimizing-decoding-paths-in-masked-diffusion-models-by-quantifying-uncertaintyhttpsarxivorgabs251221336v1><a href=https://arxiv.org/abs/2512.21336v1>Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty</a><a hidden class=anchor aria-hidden=true href=#optimizing-decoding-paths-in-masked-diffusion-models-by-quantifying-uncertaintyhttpsarxivorgabs251221336v1>#</a></h3><p><strong>Authors:</strong> Ziyu Chen, Xinbei Jiang, Peng Sun, Tao Lin
<strong>Venue:</strong> arXiv (2025)</p><p>Masked Diffusion Models (MDMs) offer flexible, non-autoregressive generation, but this freedom introduces a challenge: final output quality is highly sensitive to the decoding order. We are the first to formalize this issue, attributing the variability in output quality to the cumulative predictive uncertainty along a generative path. To quantify this uncertainty, we introduce Denoising Entropy, a computable metric that serves as an internal signal for evaluating generative process. Leveraging this metric, we propose two algorithms designed to optimize the decoding path: a post-hoc selection method and a real-time guidance strategy. Experiments demonstrate that our entropy-guided methods significantly improve generation quality, consistently boosting accuracy on challenging reasoning, planning, and code benchmarks. Our work establishes Denoising Entropy as a principled tool for understanding and controlling generation, effectively turning the uncertainty in MDMs from a liability into a key advantage for discovering high-quality solutions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21336v1">üìÑ Download PDF</a></p><hr><h3 id=c2llm-technical-report-a-new-frontier-in-code-retrieval-via-adaptive-cross-attention-poolinghttpsarxivorgabs251221332v1><a href=https://arxiv.org/abs/2512.21332v1>C2LLM Technical Report: A New Frontier in Code Retrieval via Adaptive Cross-Attention Pooling</a><a hidden class=anchor aria-hidden=true href=#c2llm-technical-report-a-new-frontier-in-code-retrieval-via-adaptive-cross-attention-poolinghttpsarxivorgabs251221332v1>#</a></h3><p><strong>Authors:</strong> Jin Qin, Zihan Liao, Ziyin Zhang, Hang Yu, Peng Di, Rui Wang
<strong>Venue:</strong> arXiv (2025)</p><p>We present C2LLM - Contrastive Code Large Language Models, a family of code embedding models in both 0.5B and 7B sizes. Building upon Qwen-2.5-Coder backbones, C2LLM adopts a Pooling by Multihead Attention (PMA) module for generating sequence embedding from token embeddings, effectively 1) utilizing the LLM&rsquo;s causal representations acquired during pretraining, while also 2) being able to aggregate information from all tokens in the sequence, breaking the information bottleneck in EOS-based sequence embeddings, and 3) supporting flexible adaptation of embedding dimension, serving as an alternative to MRL. Trained on three million publicly available data, C2LLM models set new records on MTEB-Code among models of similar sizes, with C2LLM-7B ranking 1st on the overall leaderboard.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21332v1">üìÑ Download PDF</a></p><hr><h3 id=your-reasoning-benchmark-may-not-test-reasoning-revealing-perception-bottleneck-in-abstract-reasoning-benchmarkshttpsarxivorgabs251221329v1><a href=https://arxiv.org/abs/2512.21329v1>Your Reasoning Benchmark May Not Test Reasoning: Revealing Perception Bottleneck in Abstract Reasoning Benchmarks</a><a hidden class=anchor aria-hidden=true href=#your-reasoning-benchmark-may-not-test-reasoning-revealing-perception-bottleneck-in-abstract-reasoning-benchmarkshttpsarxivorgabs251221329v1>#</a></h3><p><strong>Authors:</strong> Xinhe Wang, Jin Huang, Xingjian Zhang, Tianhao Wang, Jiaqi W. Ma
<strong>Venue:</strong> arXiv (2025)</p><p>Reasoning benchmarks such as the Abstraction and Reasoning Corpus (ARC) and ARC-AGI are widely used to assess progress in artificial intelligence and are often interpreted as probes of core, so-called ``fluid&rsquo;&rsquo; reasoning abilities. Despite their apparent simplicity for humans, these tasks remain challenging for frontier vision-language models (VLMs), a gap commonly attributed to deficiencies in machine reasoning. We challenge this interpretation and hypothesize that the gap arises primarily from limitations in visual perception rather than from shortcomings in inductive reasoning.
To verify this hypothesis, we introduce a two-stage experimental pipeline that explicitly separates perception and reasoning. In the perception stage, each image is independently converted into a natural-language description, while in the reasoning stage a model induces and applies rules using these descriptions. This design prevents leakage of cross-image inductive signals and isolates reasoning from perception bottlenecks. Across three ARC-style datasets, Mini-ARC, ACRE, and Bongard-LOGO, we show that the perception capability is the dominant factor underlying the observed performance gap by comparing the two-stage pipeline with against standard end-to-end one-stage evaluation. Manual inspection of reasoning traces in the VLM outputs further reveals that approximately 80 percent of model failures stem from perception errors. Together, these results demonstrate that ARC-style benchmarks conflate perceptual and reasoning challenges and that observed performance gaps may overstate deficiencies in machine reasoning. Our findings underscore the need for evaluation protocols that disentangle perception from reasoning when assessing progress in machine intelligence.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21329v1">üìÑ Download PDF</a></p><hr><h3 id=measuring-all-the-noises-of-llm-evalshttpsarxivorgabs251221326v1><a href=https://arxiv.org/abs/2512.21326v1>Measuring all the noises of LLM Evals</a><a hidden class=anchor aria-hidden=true href=#measuring-all-the-noises-of-llm-evalshttpsarxivorgabs251221326v1>#</a></h3><p><strong>Authors:</strong> Sida Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Separating signal from noise is central to experimental science. Applying well-established statistical method effectively to LLM evals requires consideration of their unique noise characteristics. We clearly define and measure three types of noise: prediction noise from generating different answers on a given question, data noise from sampling questions, and their combined total noise following the law of total variance. To emphasize relative comparisons and gain statistical power, we propose the all-pairs paired method, which applies the paired analysis to all pairs of LLMs and measures all the noise components based on millions of question-level predictions across many evals and settings. These measurements revealed clear patterns. First, each eval exhibits a characteristic and highly predictable total noise level across all model pairs. Second, paired prediction noise typically exceeds paired data noise, which means reducing prediction noise by averaging can significantly increase statistical power. These findings enable practitioners to assess significance without custom testing and to detect much smaller effects in controlled experiments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21326v1">üìÑ Download PDF</a></p><hr><h3 id=parallel-token-prediction-for-language-modelshttpsarxivorgabs251221323v1><a href=https://arxiv.org/abs/2512.21323v1>Parallel Token Prediction for Language Models</a><a hidden class=anchor aria-hidden=true href=#parallel-token-prediction-for-language-modelshttpsarxivorgabs251221323v1>#</a></h3><p><strong>Authors:</strong> Felix Draxler, Justus Will, Farrin Marouf Sofian, Theofanis Karaletsos, Sameer Singh, Stephan Mandt
<strong>Venue:</strong> arXiv (2025)</p><p>We propose Parallel Token Prediction (PTP), a universal framework for parallel sequence generation in language models. PTP jointly predicts multiple dependent tokens in a single transformer call by incorporating the sampling procedure into the model. This reduces the latency bottleneck of autoregressive decoding, and avoids the restrictive independence assumptions common in existing multi-token prediction methods. We prove that PTP can represent arbitrary autoregressive sequence distributions. PTP is trained either by distilling an existing model or through inverse autoregressive training without a teacher. Experimentally, we achieve state-of-the-art speculative decoding performance on Vicuna-7B by accepting over four tokens per step on Spec-Bench. The universality of our framework indicates that parallel generation of long sequences is feasible without loss of modeling power.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21323v1">üìÑ Download PDF</a></p><hr><h3 id=autonomous-uncertainty-quantification-for-computational-point-of-care-sensorshttpsarxivorgabs251221335v1><a href=https://arxiv.org/abs/2512.21335v1>Autonomous Uncertainty Quantification for Computational Point-of-care Sensors</a><a hidden class=anchor aria-hidden=true href=#autonomous-uncertainty-quantification-for-computational-point-of-care-sensorshttpsarxivorgabs251221335v1>#</a></h3><p><strong>Authors:</strong> Artem Goncharov, Rajesh Ghosh, Hyou-Arm Joung, Dino Di Carlo, Aydogan Ozcan
<strong>Venue:</strong> arXiv (2025)</p><p>Computational point-of-care (POC) sensors enable rapid, low-cost, and accessible diagnostics in emergency, remote and resource-limited areas that lack access to centralized medical facilities. These systems can utilize neural network-based algorithms to accurately infer a diagnosis from the signals generated by rapid diagnostic tests or sensors. However, neural network-based diagnostic models are subject to hallucinations and can produce erroneous predictions, posing a risk of misdiagnosis and inaccurate clinical decisions. To address this challenge, here we present an autonomous uncertainty quantification technique developed for POC diagnostics. As our testbed, we used a paper-based, computational vertical flow assay (xVFA) platform developed for rapid POC diagnosis of Lyme disease, the most prevalent tick-borne disease globally. The xVFA platform integrates a disposable paper-based assay, a handheld optical reader and a neural network-based inference algorithm, providing rapid and cost-effective Lyme disease diagnostics in under 20 min using only 20 uL of patient serum. By incorporating a Monte Carlo dropout (MCDO)-based uncertainty quantification approach into the diagnostics pipeline, we identified and excluded erroneous predictions with high uncertainty, significantly improving the sensitivity and reliability of the xVFA in an autonomous manner, without access to the ground truth diagnostic information of patients. Blinded testing using new patient samples demonstrated an increase in diagnostic sensitivity from 88.2% to 95.7%, indicating the effectiveness of MCDO-based uncertainty quantification in enhancing the robustness of neural network-driven computational POC sensing systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21335v1">üìÑ Download PDF</a></p><hr><h3 id=coherently-assisted-wireless-power-transfer-through-poorly-transparent-barriershttpsarxivorgabs251221271v1><a href=https://arxiv.org/abs/2512.21271v1>Coherently Assisted Wireless Power Transfer Through Poorly Transparent Barriers</a><a hidden class=anchor aria-hidden=true href=#coherently-assisted-wireless-power-transfer-through-poorly-transparent-barriershttpsarxivorgabs251221271v1>#</a></h3><p><strong>Authors:</strong> Alex Krasnok
<strong>Venue:</strong> arXiv (2025)</p><p>Poorly transparent barriers (e.g., reinforced walls, shielding panels, metallic or high-contrast dielectrics) strongly reflect incident radiation, limiting wireless power transfer (WPT) unless the barrier is structurally modified to support a narrowband transparency window. Here we introduce a barrier-agnostic alternative based on coherent scattering control: a phase-locked auxiliary wave is launched from the receiver side with an amplitude and phase chosen from the measured complex scattering parameters of the barrier. In a two-port (single-channel-per-side) description, we derive closed-form conditions for (i) canceling back-reflection toward the transmitter and (ii) maximizing the net extracted power at the receiver side. In the lossless limit these conditions imply unit transmitter-to-receiver efficiency (all transmitter power is routed to the receiver side) even when the barrier is nearly opaque under one-sided illumination. We validate the concept using (1) an analytically solvable high-index Fabry&ndash;P√©rot slab and (2) a numerically simulated perforated PEC metasurface exhibiting vanishing one-sided transmission; in both cases, coherent assistance yields near-unity transmission and large enhancement factors. We further analyze dissipative barriers using a receiver-side energy-balance metric, showing that substantial net delivery can persist well into the lossy regime. The approach is closely related to coherent perfect absorption and time-reversal ideas in wave physics, but targets \emph{reflectionless delivery through barriers} without modifying the obstacle itself.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21271v1">üìÑ Download PDF</a></p><hr><h3 id=cotdeceptoradversarial-code-obfuscation-against-cot-enhanced-llm-code-agentshttpsarxivorgabs251221250v1><a href=https://arxiv.org/abs/2512.21250v1>CoTDeceptor:Adversarial Code Obfuscation Against CoT-Enhanced LLM Code Agents</a><a hidden class=anchor aria-hidden=true href=#cotdeceptoradversarial-code-obfuscation-against-cot-enhanced-llm-code-agentshttpsarxivorgabs251221250v1>#</a></h3><p><strong>Authors:</strong> Haoyang Li, Mingjin Li, Jinxin Zuo, Siqi Li, Xiao Li, Hao Wu, Yueming Lu, Xiaochuan He
<strong>Venue:</strong> arXiv (2025)</p><p>LLM-based code agents(e.g., ChatGPT Codex) are increasingly deployed as detector for code review and security auditing tasks. Although CoT-enhanced LLM vulnerability detectors are believed to provide improved robustness against obfuscated malicious code, we find that their reasoning chains and semantic abstraction processes exhibit exploitable systematic weaknesses.This allows attackers to covertly embed malicious logic, bypass code review, and propagate backdoored components throughout real-world software supply chains.To investigate this issue, we present CoTDeceptor, the first adversarial code obfuscation framework targeting CoT-enhanced LLM detectors. CoTDeceptor autonomously constructs evolving, hard-to-reverse multi-stage obfuscation strategy chains that effectively disrupt CoT-driven detection logic.We obtained malicious code provided by security enterprise, experimental results demonstrate that CoTDeceptor achieves stable and transferable evasion performance against state-of-the-art LLMs and vulnerability detection agents. CoTDeceptor bypasses 14 out of 15 vulnerability categories, compared to only 2 bypassed by prior methods. Our findings highlight potential risks in real-world software supply chains and underscore the need for more robust and interpretable LLM-powered security analysis systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21250v1">üìÑ Download PDF</a></p><hr><h3 id=unitachand-unified-spatio-tactile-representation-for-human-to-robotic-hand-skill-transferhttpsarxivorgabs251221233v1><a href=https://arxiv.org/abs/2512.21233v1>UniTacHand: Unified Spatio-Tactile Representation for Human to Robotic Hand Skill Transfer</a><a hidden class=anchor aria-hidden=true href=#unitachand-unified-spatio-tactile-representation-for-human-to-robotic-hand-skill-transferhttpsarxivorgabs251221233v1>#</a></h3><p><strong>Authors:</strong> Chi Zhang, Penglin Cai, Haoqi Yuan, Chaoyi Xu, Zongqing Lu
<strong>Venue:</strong> arXiv (2025)</p><p>Tactile sensing is crucial for robotic hands to achieve human-level dexterous manipulation, especially in scenarios with visual occlusion. However, its application is often hindered by the difficulty of collecting large-scale real-world robotic tactile data. In this study, we propose to collect low-cost human manipulation data using haptic gloves for tactile-based robotic policy learning. The misalignment between human and robotic tactile data makes it challenging to transfer policies learned from human data to robots. To bridge this gap, we propose UniTacHand, a unified representation to align robotic tactile information captured by dexterous hands with human hand touch obtained from gloves. First, we project tactile signals from both human hands and robotic hands onto a morphologically consistent 2D surface space of the MANO hand model. This unification standardizes the heterogeneous data structures and inherently embeds the tactile signals with spatial context. Then, we introduce a contrastive learning method to align them into a unified latent space, trained on only 10 minutes of paired data from our data collection system. Our approach enables zero-shot tactile-based policy transfer from humans to a real robot, generalizing to objects unseen in the pre-training data. We also demonstrate that co-training on mixed data, including both human and robotic demonstrations via UniTacHand, yields better performance and data efficiency compared with using only robotic data. UniTacHand paves a path toward general, scalable, and data-efficient learning for tactile-based dexterous hands.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21233v1">üìÑ Download PDF</a></p><hr><h3 id=a-multimodal-human-centered-framework-for-assessing-pedestrian-well-being-in-the-wildhttpsarxivorgabs251221200v1><a href=https://arxiv.org/abs/2512.21200v1>A Multimodal Human-Centered Framework for Assessing Pedestrian Well-Being in the Wild</a><a hidden class=anchor aria-hidden=true href=#a-multimodal-human-centered-framework-for-assessing-pedestrian-well-being-in-the-wildhttpsarxivorgabs251221200v1>#</a></h3><p><strong>Authors:</strong> Yasaman Hakiminejad, Arash Tavakoli
<strong>Venue:</strong> arXiv (2025)</p><p>Pedestrian well-being is a critical yet rarely measured component of sustainable urban mobility and livable city design. Existing approaches to evaluating pedestrian environments often rely on static, infrastructure-based indices or retrospective surveys, which overlook the dynamic, subjective, and psychophysiological dimensions of everyday walking experience. This paper introduces a multimodal, human-centered framework for assessing pedestrian well-being in the wild by integrating three complementary data streams: continuous physiological sensing, geospatial tracking, and momentary self-reports collected using the Experience Sampling Method. The framework conceptualizes pedestrian experience as a triangulation enabling a holistic understanding of how urban environments influence well-being. The utility of our framework is then demonstrated through a naturalistic case study conducted in the Greater Philadelphia region, in which participants wore research-grade wearable sensors and carried GPS-enabled smartphones during their regular daily activities. Physiological indicators of autonomic nervous system activity, including heart rate variability and electrodermal activity, were synchronized with spatial trajectories and in situ self-reports of stress, affect, and perceived infrastructure conditions. Results illustrate substantial inter- and intra-individual variability in both subjective experience and physiological response, as well as context-dependent patterns associated with traffic exposure, pedestrian infrastructure quality, and environmental enclosure. The findings also suggest that commonly used walkability indices may not fully capture experiential dimensions of pedestrian well-being. By enabling real-world, multimodal measurement of pedestrian experience, the proposed framework offers a scalable and transferable approach for advancing human-centered urban analytics.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21200v1">üìÑ Download PDF</a></p><hr><h3 id=the-disc-instability-model-original-recipe-and-additional-ingredientshttpsarxivorgabs251221188v1><a href=https://arxiv.org/abs/2512.21188v1>The disc instability model: original recipe and additional ingredients</a><a hidden class=anchor aria-hidden=true href=#the-disc-instability-model-original-recipe-and-additional-ingredientshttpsarxivorgabs251221188v1>#</a></h3><p><strong>Authors:</strong> Jean-Marie Hameury
<strong>Venue:</strong> arXiv (2025)</p><p>The disc instability model successfully reproduces many of the observed properties of cataclysmic variables. However, additional ingredients such as mass-transfer variations, disc irradiation, stream-disc overflow, or inner-disc truncation must be included to explain certain systems. The physics underlying these processes is often poorly constrained, and our lack of knowledge is typically absorbed into extra free parameters, much like the $Œ±$-prescription for viscosity. In this paper, I examine how each of these ingredients affects the predicted light curves and discuss the limitations that arise from the growing number of unconstrained parameters on the model&rsquo;s predictive power.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21188v1">üìÑ Download PDF</a></p><hr><h3 id=a-turn-toward-better-alignment-few-shot-generative-adaptation-with-equivariant-feature-rotationhttpsarxivorgabs251221174v1><a href=https://arxiv.org/abs/2512.21174v1>A Turn Toward Better Alignment: Few-Shot Generative Adaptation with Equivariant Feature Rotation</a><a hidden class=anchor aria-hidden=true href=#a-turn-toward-better-alignment-few-shot-generative-adaptation-with-equivariant-feature-rotationhttpsarxivorgabs251221174v1>#</a></h3><p><strong>Authors:</strong> Chenghao Xu, Qi Liu, Jiexi Yan, Muli Yang, Cheng Deng
<strong>Venue:</strong> arXiv (2025)</p><p>Few-shot image generation aims to effectively adapt a source generative model to a target domain using very few training images. Most existing approaches introduce consistency constraints-typically through instance-level or distribution-level loss functions-to directly align the distribution patterns of source and target domains within their respective latent spaces. However, these strategies often fall short: overly strict constraints can amplify the negative effects of the domain gap, leading to distorted or uninformative content, while overly relaxed constraints may fail to leverage the source domain effectively. This limitation primarily stems from the inherent discrepancy in the underlying distribution structures of the source and target domains. The scarcity of target samples further compounds this issue by hindering accurate estimation of the target domain&rsquo;s distribution. To overcome these limitations, we propose Equivariant Feature Rotation (EFR), a novel adaptation strategy that aligns source and target domains at two complementary levels within a self-rotated proxy feature space. Specifically, we perform adaptive rotations within a parameterized Lie Group to transform both source and target features into an equivariant proxy space, where alignment is conducted. These learnable rotation matrices serve to bridge the domain gap by preserving intra-domain structural information without distortion, while the alignment optimization facilitates effective knowledge transfer from the source to the target domain. Comprehensive experiments on a variety of commonly used datasets demonstrate that our method significantly enhances the generative performance within the targeted domain.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21174v1">üìÑ Download PDF</a></p><hr><h3 id=channel-last-gate-all-around-nanosheet-oxide-semiconductor-transistorshttpsarxivorgabs251221330v1><a href=https://arxiv.org/abs/2512.21330v1>Channel-last gate-all-around nanosheet oxide semiconductor transistors</a><a hidden class=anchor aria-hidden=true href=#channel-last-gate-all-around-nanosheet-oxide-semiconductor-transistorshttpsarxivorgabs251221330v1>#</a></h3><p><strong>Authors:</strong> Fabia F. Athena, Xiangjin Wu, Nathaniel S. Safron, Amy Siobhan McKeown-Green, Mauro Dossena, Jack C. Evans, Jonathan Hartanto, Yukio Cho, Donglai Zhong, Tara Pe√±a, Pawe≈Ç Czaja, Parivash Moradifar, Paul C. McIntyre, Mathieu Luisier, Yi Cui, Jennifer A. Dionne, Greg Pitner, Iuliana P. Radu, Eric Pop, Alberto Salleo, H. -S. Philip Wong
<strong>Venue:</strong> arXiv (2025)</p><p>As we move beyond the era of transistor miniaturization, back-end-of-line-compatible transistors that can be stacked monolithically in the third dimension promise improved performance for low-power electronics. In advanced transistor architectures, such as gate-all-around nanosheets, the conventional channel-first process involves depositing dielectrics directly onto the channel. Atomic layer deposition of gate dielectrics on back-end-of-line compatible channel materials, such as amorphous oxide semiconductors, can induce defects or cause structural modifications that degrade electrical performance. While post-deposition annealing can partially repair this damage, it often degrades other device metrics. We report a novel channel-last concept that prevents such damage. Channel-last gate-all-around self-aligned transistors with amorphous oxide-semiconductor channels exhibit high on-state current ($>$ 1 mA/$Œº$m) and low subthreshold swing (minimum of 63 mV/dec) without the need for post-deposition processing. This approach offers a general, scalable pathway for transistors with atomic layer deposited channel materials, enabling the future of low-power three-dimensional electronics.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21330v1">üìÑ Download PDF</a></p><hr><h3 id=transcriptome-conditioned-personalized-de-novo-drug-generation-for-aml-using-metaheuristic-assembly-and-target-driven-filteringhttpsarxivorgabs251221301v1><a href=https://arxiv.org/abs/2512.21301v1>Transcriptome-Conditioned Personalized De Novo Drug Generation for AML Using Metaheuristic Assembly and Target-Driven Filtering</a><a hidden class=anchor aria-hidden=true href=#transcriptome-conditioned-personalized-de-novo-drug-generation-for-aml-using-metaheuristic-assembly-and-target-driven-filteringhttpsarxivorgabs251221301v1>#</a></h3><p><strong>Authors:</strong> Abdullah G. Elafifi, Basma Mamdouh, Mariam Hanafy, Muhammed Alaa Eldin, Yosef Khaled, Nesma Mohamed El-Gelany, Tarek H. M. Abou-El-Enien
<strong>Venue:</strong> arXiv (2025)</p><p>Acute Myeloid Leukemia (AML) remains a clinical challenge due to its extreme molecular heterogeneity and high relapse rates. While precision medicine has introduced mutation-specific therapies, many patients still lack effective, personalized options. This paper presents a novel, end-to-end computational framework that bridges the gap between patient-specific transcriptomics and de novo drug discovery. By analyzing bulk RNA sequencing data from the TCGA-LAML cohort, the study utilized Weighted Gene Co-expression Network Analysis (WGCNA) to prioritize 20 high-value biomarkers, including metabolic transporters like HK3 and immune-modulatory receptors such as SIGLEC9. The physical structures of these targets were modeled using AlphaFold3, and druggable hotspots were quantitatively mapped via the DOGSiteScorer engine. Then developed a novel, reaction-first evolutionary metaheuristic algorithm as well as multi-objective optimization programming that assembles novel ligands from fragment libraries, guided by spatial alignment to these identified hotspots. The generative model produced structurally unique chemical entities with a strong bias toward drug-like space, as evidenced by QED scores peaking between 0.5 and 0.7. Validation through ADMET profiling and SwissDock molecular docking identified high-confidence candidates, such as Ligand L1, which achieved a binding free energy of -6.571 kcal/mol against the A08A96 biomarker. These results demonstrate that integrating systems biology with metaheuristic molecular assembly can produce pharmacologically viable, patient tailored leads, offering a scalable blueprint for precision oncology in AML and beyond</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21301v1">üìÑ Download PDF</a></p><hr><h3 id=impurity-peaking-of-sparc-h-modes-a-sensitivity-study-on-physics-and-engineering-assumptionshttpsarxivorgabs251221286v1><a href=https://arxiv.org/abs/2512.21286v1>Impurity peaking of SPARC H-modes: a sensitivity study on physics and engineering assumptions</a><a hidden class=anchor aria-hidden=true href=#impurity-peaking-of-sparc-h-modes-a-sensitivity-study-on-physics-and-engineering-assumptionshttpsarxivorgabs251221286v1>#</a></h3><p><strong>Authors:</strong> Marco Muraca, Pablo Rodriguez-Fernandez, Joe Hall, Nathaniel T. Howard, Daniel Fajardo, Giovanni Tardini, Benedikt Zimmermann, Thomas Body
<strong>Venue:</strong> arXiv (2025)</p><p>In this paper, an overview of the impurity transport for three H-mode plasmas in the upcoming SPARC tokamak has been provided. The simulations have been performed within the ASTRA+STRAHL framework, using FACIT and TGLF-SAT2 to predict, respectively, neoclassical and turbulent core transport, while a neural network trained on EPED simulations has been employed to calculate the pedestal height and width self-consistently. A benchmark with previous simulations at constant impurity fraction has been provided for three H-modes, spanning different plasma current and magnetic field values. For a scenario, additional simulations have been performed to account for uncertainties in the modeling assumptions. The predictions are nearly insensitive to changes in the top of pedestal W concentrations. Varying the Ar pedestal concentration has shown a small effect on the impurity peaking and nearly constant fusion gain values, due to multiple effects on pedestal pressure, main ion dilution and density peaking. The inclusion of rotation in ASTRA simulations has shown minimal impact on confinement and impurity transport predictions. An exploratory study has been provided with a first set of simulations treating D and T separately, experiencing a maximum fusion power at 55-45% DT fuel composition, and an asymmetric distribution with respect to the D concentration. All the results, including sensitivity scans of toroidal velocity and ion temperature and density gradients, highlighted that turbulent impurity transport prevails on the neoclassical component, aligning with previous ITER predictions, and suggesting that next generation devices like SPARC, operating at low collisionality, will experience low W accumulation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21286v1">üìÑ Download PDF</a></p><hr><h3 id=acd-direct-conditional-control-for-video-diffusion-models-via-attention-supervisionhttpsarxivorgabs251221268v1><a href=https://arxiv.org/abs/2512.21268v1>ACD: Direct Conditional Control for Video Diffusion Models via Attention Supervision</a><a hidden class=anchor aria-hidden=true href=#acd-direct-conditional-control-for-video-diffusion-models-via-attention-supervisionhttpsarxivorgabs251221268v1>#</a></h3><p><strong>Authors:</strong> Weiqi Li, Zehao Zhang, Liang Lin, Guangrun Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Controllability is a fundamental requirement in video synthesis, where accurate alignment with conditioning signals is essential. Existing classifier-free guidance methods typically achieve conditioning indirectly by modeling the joint distribution of data and conditions, which often results in limited controllability over the specified conditions. Classifier-based guidance enforces conditions through an external classifier, but the model may exploit this mechanism to raise the classifier score without genuinely satisfying the intended condition, resulting in adversarial artifacts and limited effective controllability. In this paper, we propose Attention-Conditional Diffusion (ACD), a novel framework for direct conditional control in video diffusion models via attention supervision. By aligning the model&rsquo;s attention maps with external control signals, ACD achieves better controllability. To support this, we introduce a sparse 3D-aware object layout as an efficient conditioning signal, along with a dedicated Layout ControlNet and an automated annotation pipeline for scalable layout integration. Extensive experiments on benchmark video generation datasets demonstrate that ACD delivers superior alignment with conditioning inputs while preserving temporal coherence and visual fidelity, establishing an effective paradigm for conditional video synthesis.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21268v1">üìÑ Download PDF</a></p><hr><h3 id=anyad-unified-any-modality-anomaly-detection-in-incomplete-multi-sequence-mrihttpsarxivorgabs251221264v1><a href=https://arxiv.org/abs/2512.21264v1>AnyAD: Unified Any-Modality Anomaly Detection in Incomplete Multi-Sequence MRI</a><a hidden class=anchor aria-hidden=true href=#anyad-unified-any-modality-anomaly-detection-in-incomplete-multi-sequence-mrihttpsarxivorgabs251221264v1>#</a></h3><p><strong>Authors:</strong> Changwei Wu, Yifei Chen, Yuxin Du, Mingxuan Liu, Jinying Zong, Beining Wu, Jie Dong, Feiwei Qin, Yunkang Cao, Qiyuan Tian
<strong>Venue:</strong> arXiv (2025)</p><p>Reliable anomaly detection in brain MRI remains challenging due to the scarcity of annotated abnormal cases and the frequent absence of key imaging modalities in real clinical workflows. Existing single-class or multi-class anomaly detection (AD) models typically rely on fixed modality configurations, require repetitive training, or fail to generalize to unseen modality combinations, limiting their clinical scalability. In this work, we present a unified Any-Modality AD framework that performs robust anomaly detection and localization under arbitrary MRI modality availability. The framework integrates a dual-pathway DINOv2 encoder with a feature distribution alignment mechanism that statistically aligns incomplete-modality features with full-modality representations, enabling stable inference even with severe modality dropout. To further enhance semantic consistency, we introduce an Intrinsic Normal Prototypes (INPs) extractor and an INP-guided decoder that reconstruct only normal anatomical patterns while naturally amplifying abnormal deviations. Through randomized modality masking and indirect feature completion during training, the model learns to adapt to all modality configurations without re-training. Extensive experiments on BraTS2018, MU-Glioma-Post, and Pretreat-MetsToBrain-Masks demonstrate that our approach consistently surpasses state-of-the-art industrial and medical AD baselines across 7 modality combinations, achieving superior generalization. This study establishes a scalable paradigm for multimodal medical AD under real-world, imperfect modality conditions. Our source code is available at <a href=https://github.com/wuchangw/AnyAD>https://github.com/wuchangw/AnyAD</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21264v1">üìÑ Download PDF</a></p><hr><h3 id=segmo-segment-aligned-text-to-3d-human-motion-generationhttpsarxivorgabs251221237v1><a href=https://arxiv.org/abs/2512.21237v1>SegMo: Segment-aligned Text to 3D Human Motion Generation</a><a hidden class=anchor aria-hidden=true href=#segmo-segment-aligned-text-to-3d-human-motion-generationhttpsarxivorgabs251221237v1>#</a></h3><p><strong>Authors:</strong> Bowen Dang, Lin Wu, Xiaohang Yang, Zheng Yuan, Zhixiang Chen
<strong>Venue:</strong> arXiv (2025)</p><p>Generating 3D human motions from textual descriptions is an important research problem with broad applications in video games, virtual reality, and augmented reality. Recent methods align the textual description with human motion at the sequence level, neglecting the internal semantic structure of modalities. However, both motion descriptions and motion sequences can be naturally decomposed into smaller and semantically coherent segments, which can serve as atomic alignment units to achieve finer-grained correspondence. Motivated by this, we propose SegMo, a novel Segment-aligned text-conditioned human Motion generation framework to achieve fine-grained text-motion alignment. Our framework consists of three modules: (1) Text Segment Extraction, which decomposes complex textual descriptions into temporally ordered phrases, each representing a simple atomic action; (2) Motion Segment Extraction, which partitions complete motion sequences into corresponding motion segments; and (3) Fine-grained Text-Motion Alignment, which aligns text and motion segments with contrastive learning. Extensive experiments demonstrate that SegMo improves the strong baseline on two widely used datasets, achieving an improved TOP 1 score of 0.553 on the HumanML3D test set. Moreover, thanks to the learned shared embedding space for text and motion segments, SegMo can also be applied to retrieval-style tasks such as motion grounding and motion-to-text retrieval.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21237v1">üìÑ Download PDF</a></p><hr><h3 id=smart-slm-structured-memory-and-reasoning-transformer-a-small-language-model-for-accurate-document-assistancehttpsarxivorgabs251221280v1><a href=https://arxiv.org/abs/2512.21280v1>SMART SLM: Structured Memory and Reasoning Transformer, A Small Language Model for Accurate Document Assistance</a><a hidden class=anchor aria-hidden=true href=#smart-slm-structured-memory-and-reasoning-transformer-a-small-language-model-for-accurate-document-assistancehttpsarxivorgabs251221280v1>#</a></h3><p><strong>Authors:</strong> Divij Dudeja, Mayukha Pal
<strong>Venue:</strong> arXiv (2025)</p><p>The user of Engineering Manuals (EM) finds it difficult to read EM s because they are long, have a dense format which includes written documents, step by step procedures, and standard parameter lists for engineering equipment. Off the shelf transformers, especially compact ones, treat this material as a flat stream of tokens. This approach leads to confident but incorrect numeric answers and forces the models to memorize separate facts inefficiently. SMART (Structured Memory and Reasoning Transformer) offers a different and practical solution to the above problem. SMART structures its processing by using a hierarchical approach, and is based upon three main job categories (1) A syntax-aware Fact Extractor (Grammarian) Tree LSTM which extracts facts as subject relation object relations from EM sentences (2) A compact indexed memory MANN (Memory Augmented Neural Network) that indexes these Rational Subject Relation Objects as 384 dimensional vectors that are associated with the source of the information, and (3) A 6 layer Transformer that learns to fuse the previously retrieved facts into its generated response. The entire SMART model utilizes 45.51M parameters, which is 64% less than GPT-2 (124M) and 69% less than BERT (133M), and it achieves a 21.3% higher accuracy than GPT-2, indicating that SMART fits the data better with the least amount of processing requirements. SMART employs dual modes of inference an indexed fast path for known documents (sub-second answer times) and an indexed dynamic path assisted by RAGs for new uploads (FAISS Top 20 results with memory severed at 64 slots). In real world deployment, this framework leads to more well supported results with reduced hallucinations than comparable small transformer models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21280v1">üìÑ Download PDF</a></p><hr><h3 id=random-dilation-superchannelhttpsarxivorgabs251221260v1><a href=https://arxiv.org/abs/2512.21260v1>Random dilation superchannel</a><a hidden class=anchor aria-hidden=true href=#random-dilation-superchannelhttpsarxivorgabs251221260v1>#</a></h3><p><strong>Authors:</strong> Satoshi Yoshida, Ryotaro Niwa, Mio Murao
<strong>Venue:</strong> arXiv (2025)</p><p>We present a quantum circuit that implements the random dilation superchannel, transforming parallel queries of an unknown quantum channel into parallel queries of a randomly chosen dilation isometry of the input channel. This is a natural generalization of a random purification channel, that transforms copies of an unknown mixed state to copies of a randomly chosen purification state. Our construction is based on the quantum Schur transform and the quantum Fourier transform over the symmetric group. By using the efficient construction of these quantum transforms, we can implement the random dilation superchannel with the circuit complexity $O(\mathrm{poly}(n, \log d_I, \log d_O))$, where $n$ is the number of queries and $d_I$ and $d_O$ are the input and output dimensions of the input channel, respectively. As an application, we show an efficient storage-and-retrieval of an unknown quantum channel, which improves the program cost exponentially in the retrieval error $\varepsilon$. For the case where the Kraus rank $r$ is the least possible (i.e., $r = d_I/d_O$), we show quantum circuits transforming $n$ parallel queries of an unknown quantum channel $Œõ$ to $Œò(n^Œ±)$ parallel queries of $Œõ$ for any $Œ±&lt;2$ approximately, and its Petz recovery map for the reference state given by the maximally mixed state probabilistically and exactly. We also show that our results can be further extended to the case of quantum superchannels.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21260v1">üìÑ Download PDF</a></p><hr><h3 id=reaseq-unleashing-world-knowledge-via-reasoning-for-sequential-modelinghttpsarxivorgabs251221257v1><a href=https://arxiv.org/abs/2512.21257v1>ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling</a><a hidden class=anchor aria-hidden=true href=#reaseq-unleashing-world-knowledge-via-reasoning-for-sequential-modelinghttpsarxivorgabs251221257v1>#</a></h3><p><strong>Authors:</strong> Chuan Wang, Gaoming Yang, Han Wu, Jiakai Tang, Jiahao Yu, Jian Wu, Jianwu Hu, Junjun Zheng, Shuwen Xiao, Yeqiu Yang, Yuning Jiang, Ahjol Nurlanbek, Binbin Cao, Bo Zheng, Fangmei Zhu, Gaoming Zhou, Huimin Yi, Huiping Chu, Jin Huang, Jinzhe Shan, Kenan Cui, Longbin Li, Silu Zhou, Wen Chen, Xia Ming, Xiang Gao, Xin Yao, Xingyu Wen, Yan Zhang, Yiwen Hu, Yulin Wang, Ziheng Bao, Zongyuan Wu
<strong>Venue:</strong> arXiv (2025)</p><p>Industrial recommender systems face two fundamental limitations under the log-driven paradigm: (1) knowledge poverty in ID-based item representations that causes brittle interest modeling under data sparsity, and (2) systemic blindness to beyond-log user interests that constrains model performance within platform boundaries. These limitations stem from an over-reliance on shallow interaction statistics and close-looped feedback while neglecting the rich world knowledge about product semantics and cross-domain behavioral patterns that Large Language Models have learned from vast corpora.
To address these challenges, we introduce ReaSeq, a reasoning-enhanced framework that leverages world knowledge in Large Language Models to address both limitations through explicit and implicit reasoning. Specifically, ReaSeq employs explicit Chain-of-Thought reasoning via multi-agent collaboration to distill structured product knowledge into semantically enriched item representations, and latent reasoning via Diffusion Large Language Models to infer plausible beyond-log behaviors. Deployed on Taobao&rsquo;s ranking system serving hundreds of millions of users, ReaSeq achieves substantial gains: >6.0% in IPV and CTR, >2.9% in Orders, and >2.5% in GMV, validating the effectiveness of world-knowledge-enhanced reasoning over purely log-driven approaches.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21257v1">üìÑ Download PDF</a></p><hr><h3 id=leveraging-lightweight-entity-extraction-for-scalable-event-based-image-retrievalhttpsarxivorgabs251221221v1><a href=https://arxiv.org/abs/2512.21221v1>Leveraging Lightweight Entity Extraction for Scalable Event-Based Image Retrieval</a><a hidden class=anchor aria-hidden=true href=#leveraging-lightweight-entity-extraction-for-scalable-event-based-image-retrievalhttpsarxivorgabs251221221v1>#</a></h3><p><strong>Authors:</strong> Dao Sy Duy Minh, Huynh Trung Kiet, Nguyen Lam Phu Quy, Phu-Hoa Pham, Tran Chi Nguyen
<strong>Venue:</strong> arXiv (2025)</p><p>Retrieving images from natural language descriptions is a core task at the intersection of computer vision and natural language processing, with wide-ranging applications in search engines, media archiving, and digital content management. However, real-world image-text retrieval remains challenging due to vague or context-dependent queries, linguistic variability, and the need for scalable solutions. In this work, we propose a lightweight two-stage retrieval pipeline that leverages event-centric entity extraction to incorporate temporal and contextual signals from real-world captions. The first stage performs efficient candidate filtering using BM25 based on salient entities, while the second stage applies BEiT-3 models to capture deep multimodal semantics and rerank the results. Evaluated on the OpenEvents v1 benchmark, our method achieves a mean average precision of 0.559, substantially outperforming prior baselines. These results highlight the effectiveness of combining event-guided filtering with long-text vision-language modeling for accurate and efficient retrieval in complex, real-world scenarios. Our code is available at <a href=https://github.com/PhamPhuHoa-23/Event-Based-Image-Retrieval>https://github.com/PhamPhuHoa-23/Event-Based-Image-Retrieval</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21221v1">üìÑ Download PDF</a></p><hr><h2 id=-linguistics>üîç linguistics<a hidden class=anchor aria-hidden=true href=#-linguistics>#</a></h2><h3 id=histream-efficient-high-resolution-video-generation-via-redundancy-eliminated-streaminghttpsarxivorgabs251221338v1><a href=https://arxiv.org/abs/2512.21338v1>HiStream: Efficient High-Resolution Video Generation via Redundancy-Eliminated Streaming</a><a hidden class=anchor aria-hidden=true href=#histream-efficient-high-resolution-video-generation-via-redundancy-eliminated-streaminghttpsarxivorgabs251221338v1>#</a></h3><p><strong>Authors:</strong> Haonan Qiu, Shikun Liu, Zijian Zhou, Zhaochong An, Weiming Ren, Zhiheng Liu, Jonas Schult, Sen He, Shoufa Chen, Yuren Cong, Tao Xiang, Ziwei Liu, Juan-Manuel Perez-Rua
<strong>Venue:</strong> arXiv (2025)</p><p>High-resolution video generation, while crucial for digital media and film, is computationally bottlenecked by the quadratic complexity of diffusion models, making practical inference infeasible. To address this, we introduce HiStream, an efficient autoregressive framework that systematically reduces redundancy across three axes: i) Spatial Compression: denoising at low resolution before refining at high resolution with cached features; ii) Temporal Compression: a chunk-by-chunk strategy with a fixed-size anchor cache, ensuring stable inference speed; and iii) Timestep Compression: applying fewer denoising steps to subsequent, cache-conditioned chunks. On 1080p benchmarks, our primary HiStream model (i+ii) achieves state-of-the-art visual quality while demonstrating up to 76.2x faster denoising compared to the Wan2.1 baseline and negligible quality loss. Our faster variant, HiStream+, applies all three optimizations (i+ii+iii), achieving a 107.5x acceleration over the baseline, offering a compelling trade-off between speed and quality, thereby making high-resolution video generation both practical and scalable.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21338v1">üìÑ Download PDF</a></p><hr><h3 id=streaming-video-instruction-tuninghttpsarxivorgabs251221334v1><a href=https://arxiv.org/abs/2512.21334v1>Streaming Video Instruction Tuning</a><a hidden class=anchor aria-hidden=true href=#streaming-video-instruction-tuninghttpsarxivorgabs251221334v1>#</a></h3><p><strong>Authors:</strong> Jiaer Xia, Peixian Chen, Mengdan Zhang, Xing Sun, Kaiyang Zhou
<strong>Venue:</strong> arXiv (2025)</p><p>We present Streamo, a real-time streaming video LLM that serves as a general-purpose interactive assistant. Unlike existing online video models that focus narrowly on question answering or captioning, Streamo performs a broad spectrum of streaming video tasks, including real-time narration, action understanding, event captioning, temporal event grounding, and time-sensitive question answering. To develop such versatility, we construct Streamo-Instruct-465K, a large-scale instruction-following dataset tailored for streaming video understanding. The dataset covers diverse temporal contexts and multi-task supervision, enabling unified training across heterogeneous streaming tasks. After training end-to-end on the instruction-following dataset through a streamlined pipeline, Streamo exhibits strong temporal reasoning, responsive interaction, and broad generalization across a variety of streaming benchmarks. Extensive experiments show that Streamo bridges the gap between offline video perception models and real-time multimodal assistants, making a step toward unified, intelligent video understanding in continuous video streams.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21334v1">üìÑ Download PDF</a></p><hr><h3 id=fast-sam2-with-text-driven-token-pruninghttpsarxivorgabs251221333v1><a href=https://arxiv.org/abs/2512.21333v1>Fast SAM2 with Text-Driven Token Pruning</a><a hidden class=anchor aria-hidden=true href=#fast-sam2-with-text-driven-token-pruninghttpsarxivorgabs251221333v1>#</a></h3><p><strong>Authors:</strong> Avilasha Mandal, Chaoning Zhang, Fachrina Dewi Puspitasari, Xudong Wang, Jiaquan Zhang, Caiyan Qin, Guoqing Wang, Yang Yang, Heng Tao Shen
<strong>Venue:</strong> arXiv (2025)</p><p>Segment Anything Model 2 (SAM2), a vision foundation model has significantly advanced in prompt-driven video object segmentation, yet their practical deployment remains limited by the high computational and memory cost of processing dense visual tokens across time. The SAM2 pipelines typically propagate all visual tokens produced by the image encoder through downstream temporal reasoning modules, regardless of their relevance to the target object, resulting in reduced scalability due to quadratic memory attention overhead. In this work, we introduce a text-guided token pruning framework that improves inference efficiency by selectively reducing token density prior to temporal propagation, without modifying the underlying segmentation architecture. Operating after visual encoding and before memory based propagation, our method ranks tokens using a lightweight routing mechanism that integrates local visual context, semantic relevance derived from object-centric textual descriptions (either user-provided or automatically generated), and uncertainty cues that help preserve ambiguous or boundary critical regions. By retaining only the most informative tokens for downstream processing, the proposed approach reduces redundant computation while maintaining segmentation fidelity. Extensive experiments across multiple challenging video segmentation benchmarks demonstrate that post-encoder token pruning provides a practical and effective pathway to efficient, prompt-aware video segmentation, achieving up to 42.50 percent faster inference and 37.41 percent lower GPU memory usage compared to the unpruned baseline SAM2, while preserving competitive J and F performance. These results highlight the potential of early token selection to improve the scalability of transformer-based video segmentation systems for real-time and resource-constrained applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21333v1">üìÑ Download PDF</a></p><hr><h3 id=when-geometry-radiates-review-gravitational-waves-in-theory-cosmology-and-observationhttpsarxivorgabs251221328v1><a href=https://arxiv.org/abs/2512.21328v1>When Geometry Radiates Review: Gravitational Waves in Theory, Cosmology, and Observation</a><a hidden class=anchor aria-hidden=true href=#when-geometry-radiates-review-gravitational-waves-in-theory-cosmology-and-observationhttpsarxivorgabs251221328v1>#</a></h3><p><strong>Authors:</strong> Azadeh Maleknejad
<strong>Venue:</strong> arXiv (2025)</p><p>Gravitational waves provide a unique window into gravity, cosmology, and high-energy physics, enabling the exploration of fundamental phenomena across a wide range of scales. This review presents a coherent and pedagogical framework that bridges foundational theory with observational frontiers. We begin by developing the theory of gravitational radiation within linearized general relativity, deriving gravitational waves as solutions to the linearized Einstein equations and clarifying their physical interpretation, polarization states, and key properties. We then deepen the discussion through a geometric perspective, tracing the connection between gravitational radiation and the algebraic structure of the Weyl tensor and its role in defining energy and angular momentum in asymptotically flat spacetimes. Extending beyond flat backgrounds, we examine gravitational waves in an expanding universe, following their evolution across cosmological epochs and their generation during inflation. Within this setting, we discuss adiabatic modes and consistency relations that reveal universal properties of long-wavelength perturbations, and derive the inflationary spectrum of vacuum gravitational waves together with their contribution to the integrated Sachs-Wolfe effect. We also survey the main observational strategies for detecting gravitational waves across a broad frequency range, including cosmic microwave background polarization, pulsar timing arrays, ground- and space-based laser interferometers, and resonant cavity detectors. We then discuss the astrophysical and cosmological mechanisms responsible for generating gravitational radiation. We conclude by summarizing the current status of the field and outlining promising directions for future theoretical and observational developments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21328v1">üìÑ Download PDF</a></p><hr><h3 id=aspects-of-holographic-timelike-entanglement-entropy-in-black-hole-backgroundshttpsarxivorgabs251221327v1><a href=https://arxiv.org/abs/2512.21327v1>Aspects of holographic timelike entanglement entropy in black hole backgrounds</a><a hidden class=anchor aria-hidden=true href=#aspects-of-holographic-timelike-entanglement-entropy-in-black-hole-backgroundshttpsarxivorgabs251221327v1>#</a></h3><p><strong>Authors:</strong> Mir Afrasiar, Jaydeep Kumar Basak, Keun-Young Kim
<strong>Venue:</strong> arXiv (2025)</p><p>We study the holographic construction of timelike entanglement entropy (tEE) in black hole backgrounds in Lorentzian geometries. The holographic tEE is realized through extremal surfaces consisting of spacelike and timelike branches that encode its real and imaginary components, respectively. In the BTZ black hole, these surfaces extend into the interior of the black hole and reproduce the field-theoretic results. The analysis is further generalized to higher-dimensional AdS-Schwarzschild black holes, where the characteristics of tEE are obtained with increasing size of the boundary subsystem. Besides, we also show that the boundary subsystem length diverges at a dimension-dependent critical turning point. Notably, this critical point moves closer to the black hole horizon as the dimensionality of the bulk increases. For large subsystem lengths, the finite part of the tEE displays a characteristic volume-plus-area structure, with a real volume term and a complex coefficient of the area term approaching constant values at large dimensions. Besides, we also study the monotonicity of a new quantity, timelike entanglement density, which offers insights into a timelike area theorem in specific limits. Subsequently, we investigate the near-horizon dynamics in various black hole backgrounds, where the spacelike and timelike surfaces exhibit exponential growth of the form $e^{\frac{2œÄ}Œ≤ Œît}$ with inverse black hole temperature $Œ≤$.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21327v1">üìÑ Download PDF</a></p><hr><h3 id=an-allele-centric-pan-graph-matrix-representation-for-scalable-pangenome-analysishttpsarxivorgabs251221320v1><a href=https://arxiv.org/abs/2512.21320v1>An Allele-Centric Pan-Graph-Matrix Representation for Scalable Pangenome Analysis</a><a hidden class=anchor aria-hidden=true href=#an-allele-centric-pan-graph-matrix-representation-for-scalable-pangenome-analysishttpsarxivorgabs251221320v1>#</a></h3><p><strong>Authors:</strong> Roberto Garrone
<strong>Venue:</strong> arXiv (2025)</p><p>Population-scale pangenome analysis increasingly requires representations that unify single-nucleotide and structural variation while remaining scalable across large cohorts. Existing formats are typically sequence-centric, path-centric, or sample-centric, and often obscure population structure or fail to exploit carrier sparsity. We introduce the H1 pan-graph-matrix, an allele-centric representation that encodes exact haplotype membership using adaptive per-allele compression. By treating alleles as first-class objects and selecting optimal encodings based on carrier distribution, H1 achieves near-optimal storage across both common and rare variants. We further introduce H2, a path-centric dual representation derived from the same underlying allele-haplotype incidence information that restores explicit haplotype ordering while remaining exactly equivalent in information content. Using real human genome data, we show that this representation yields substantial compression gains, particularly for structural variants, while remaining equivalent in information content to pangenome graphs. H1 provides a unified, population-aware foundation for scalable pangenome analysis and downstream applications such as rare-variant interpretation and drug discovery.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21320v1">üìÑ Download PDF</a></p><hr><h3 id=a-lyapunov-based-small-gain-theorem-for-fixed-time-iss-theory-optimization-and-gameshttpsarxivorgabs251221314v1><a href=https://arxiv.org/abs/2512.21314v1>A Lyapunov-Based Small-Gain Theorem for Fixed-Time ISS: Theory, Optimization, and Games</a><a hidden class=anchor aria-hidden=true href=#a-lyapunov-based-small-gain-theorem-for-fixed-time-iss-theory-optimization-and-gameshttpsarxivorgabs251221314v1>#</a></h3><p><strong>Authors:</strong> Michael Tang, Miroslav Krstic, Jorge Poveda
<strong>Venue:</strong> arXiv (2025)</p><p>We develop a Lyapunov-based small-gain theorem for establishing fixed-time input-to-state stability (FxT-ISS) guarantees in interconnected nonlinear dynamical systems. The proposed framework considers interconnections in which each subsystem admits a FxT-ISS Lyapunov function, providing robustness with respect to external inputs. We show that, under an appropriate nonlinear small-gain condition, the overall interconnected system inherits the FxT-ISS property. In this sense, the proposed result complements existing Lyapunov-based smallgain theorems for asymptotic and finite-time stability, and enables a systematic analysis of interconnection structures exhibiting fixed-time stability. To illustrate the applicability of the theory, we study feedback-based optimization problems with time-varying cost functions, and Nash-equilibrium seeking for noncooperative games with nonlinear dynamical plants in the loop. For both problems, we present a class of non-smooth gradient or pseudogradient-based controllers that achieve fixed-time convergence without requiring time-scale separation and using real-time feedback. Numerical examples are provided to validate the theoretical findings.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21314v1">üìÑ Download PDF</a></p><hr><h3 id=force-Œ±-numerical-fluxes-within-the-arbitrary-high-order-semidiscrete-weno-dec-framework-a-competitive-alternative-to-upwind-fluxeshttpsarxivorgabs251221306v1><a href=https://arxiv.org/abs/2512.21306v1>FORCE-$Œ±$ Numerical Fluxes within the Arbitrary High Order Semidiscrete WENO-DeC Framework: A Competitive Alternative to Upwind Fluxes</a><a hidden class=anchor aria-hidden=true href=#force-Œ±-numerical-fluxes-within-the-arbitrary-high-order-semidiscrete-weno-dec-framework-a-competitive-alternative-to-upwind-fluxeshttpsarxivorgabs251221306v1>#</a></h3><p><strong>Authors:</strong> Lorenzo Micalizzi, Eleuterio Toro
<strong>Venue:</strong> arXiv (2025)</p><p>This work systematically investigates the performance of FORCE&ndash;$Œ±$ numerical fluxes within an arbitrary high order semidiscrete finite volume (FV) framework for hyperbolic partial differential equations (PDEs). Such numerical fluxes have been recently introduced by Toro, Saggiorato, Tokareva, and Hidalgo (Journal of Computational Physics, 416, 2020), and constitute a family of centred fluxes obtained from a suitable modification of First&ndash;Order Centred (FORCE) numerical fluxes. In contrast with upwind fluxes, such as Rusanov, Harten&ndash;Lax&ndash;van Leer (HLL) or the exact Riemann solver (RS) numerical flux, centred ones do not consider in any way the structure of the Riemann problem at cell interfaces. Adopting centred numerical fluxes leads to a high level of flexibility of the resulting numerical schemes, for example in the context of complicated hyperbolic systems, for which RSs may be impossible to construct or computationally expensive.
The baseline framework adopted in this investigation is a FV semidiscrete approach with Weighted Essentially Non&ndash;Oscillatory (WENO) spatial reconstruction and Deferred Correction (DeC) time discretization, and results are reported up to order 7. Previous investigations involving the same framework have established that increasing the order of accuracy tends to decrease the differences in the results obtained through different numerical fluxes. The goal of this paper is to show that the employment of FORCE&ndash;$Œ±$ numerical fluxes within such a framework is a competitive alternative to the adoption of more classical upwind fluxes. The hyperbolic system considered for this investigation is the ideal Euler equations in one and two space dimensions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21306v1">üìÑ Download PDF</a></p><hr><h3 id=deforming-and-dissecting-ads_3-with-matterhttpsarxivorgabs251221255v1><a href=https://arxiv.org/abs/2512.21255v1>Deforming and dissecting AdS$_3$ with matter</a><a hidden class=anchor aria-hidden=true href=#deforming-and-dissecting-ads_3-with-matterhttpsarxivorgabs251221255v1>#</a></h3><p><strong>Authors:</strong> Nele Callebaut, Blanca Hergueta, Ruben Monten, Matteo Selle
<strong>Venue:</strong> arXiv (2025)</p><p>We study deformations of the model by Henneaux, Mart√≠nez, Troncoso and Zanelli [arXiv:hep-th/0201170] which features asymptotically AdS$_3$ black hole solutions that incorporate the exact backreaction of a scalar field. The presence of bulk matter causes the $T \overline T$ deformation of the (putative) dual CFT$_2$ to differ from the deformation defined in the bulk by imposing Dirichlet boundary conditions at finite radius. We work out both of these deformations explicitly and verify that $T \overline T$-deforming the boundary theory corresponds to imposing mixed boundary conditions on the metric at the conformal boundary, whereas the bulk &ldquo;Dirichlet deformation&rdquo; gives rise to a field theory deforming operator that includes $T \overline T$ as well as other irrelevant terms. We check our results by calculating the deformed energy spectrum for either case using both the bulk and boundary prescriptions, finding agreement after taking into account additional terms coming from the flow of the scalar source. We interpret our explicit results and compare them with the predictions of similar proposals in the literature.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21255v1">üìÑ Download PDF</a></p><hr><h3 id=exact-infrared-triangle-in-massless-sqed-with-long-range-interactionshttpsarxivorgabs251221239v1><a href=https://arxiv.org/abs/2512.21239v1>Exact Infrared Triangle in Massless sQED with Long-range Interactions</a><a hidden class=anchor aria-hidden=true href=#exact-infrared-triangle-in-massless-sqed-with-long-range-interactionshttpsarxivorgabs251221239v1>#</a></h3><p><strong>Authors:</strong> Sangmin Choi, Ameya Kadhe, Andrea Puhm
<strong>Venue:</strong> arXiv (2025)</p><p>The logarithmic soft photon theorem in four spacetime dimensions encodes an infinite-dimensional asymptotic symmetry which acts on massive matter as a divergent superphaserotation. Here we extend this result to massless matter which is both more subtle and surprising. We derive the charge associated to divergent superphaserotations and show that it exactly vanishes to all orders in the electromagnetic coupling. This is in agreement with the vanishing of the classical logarithmic soft photon theorem which is one-loop exact. Special care is required for massless matter due to potential collinear divergences which, as we show, do however not affect the superphaserotation charge. We furthermore compute the infrared corrections to the charge associated to the subleading tree-level soft photon theorem. As a corollary of our result, we find that the tail to the velocity kick memory due to the long-range interactions between soft electromagnetic radiation and massless matter vanishes.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21239v1">üìÑ Download PDF</a></p><hr><h3 id=linking-interior-curvature-to-observable-shadows-a-case-study-of-nonsingular-black-holeshttpsarxivorgabs251221178v1><a href=https://arxiv.org/abs/2512.21178v1>Linking interior curvature to observable shadows: A case study of nonsingular black holes</a><a hidden class=anchor aria-hidden=true href=#linking-interior-curvature-to-observable-shadows-a-case-study-of-nonsingular-black-holeshttpsarxivorgabs251221178v1>#</a></h3><p><strong>Authors:</strong> Ming-Xin Li, Jin Pu, Yi Ling, Guo-Ping Li
<strong>Venue:</strong> arXiv (2025)</p><p>We establish a direct connection between the interior curvature structure of nonsingular black holes (BHs) with a Minkowski core and their observable optical signatures. By classifying these spacetimes into three fundamental types, Type I (Kretschmann scalar K_max increasing with mass M), Type II (mass-independent K_max), and Type III (K_max decreasing with M), we demonstrate how subtle variations in the core geometry imprint distinguishable features on the BH shadow. A detailed analysis of photon dynamics reveals that the parameters Œ± and n, which control the deviation from Schwarzschild geometry and the radial decay of the regularizing factor, respectively, systematically alter the properties of the photon sphere. These intrinsic geometric differences propagate outward: for fixed parameters, Type III BHs, with the most compact photon sphere, produce the smallest and brightest shadows, whereas Type I BHs yield the largest and dimmest ones. Shadow computations under both static and infalling spherical accretion models confirm that the curvature-based classification directly corresponds to observable differences. Critically, Type III BHs exhibit the strongest sensitivity to parameter variations, making them optimal probes for constraining the underlying spacetime geometry. Our work reveals that even among nonsingular BHs sharing the same asymptotic core, differences in internal curvature are reflected in the shadow morphology, thereby providing a new pathway to test quantum-gravity-inspired models using upcoming high-resolution observations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21178v1">üìÑ Download PDF</a></p><hr><h3 id=lovelock2-inflation-explaining-the-act-data-and-equivalence-to-higgs-gauss-bonnet-inflationhttpsarxivorgabs251221167v1><a href=https://arxiv.org/abs/2512.21167v1>(Lovelock)$^2$ inflation: explaining the ACT data and equivalence to Higgs-Gauss-Bonnet inflation</a><a hidden class=anchor aria-hidden=true href=#lovelock2-inflation-explaining-the-act-data-and-equivalence-to-higgs-gauss-bonnet-inflationhttpsarxivorgabs251221167v1>#</a></h3><p><strong>Authors:</strong> Andrea Addazi, Yermek Aldabergenov, Daulet Berkimbayev, Yifu Cai
<strong>Venue:</strong> arXiv (2025)</p><p>We revisit the Starobinsky model of inflation in light of recent data from the Atacama Cosmology Telescope (ACT), which indicates a potential preference for a slightly larger scalar spectral index $n_s$ than predicted by the standard $R^2$ scenario. We demonstrate that a natural one-parameter generalization to a quadratic model $\sim L+L^2$ in the Lovelock invariant $L=R+\fracŒ±{4}{\cal G}$ ($\cal G$ is the Gauss&ndash;Bonnet term), can effectively resolve this minor tension. Scalar-tensor formulation of this theory yields an Einstein-frame Starobinsky-type scalar potential augmented by Gauss&ndash;Bonnet and derivative couplings, which modify the inflationary slow-roll dynamics. We show that a non-zero coupling $Œ±$ for the Gauss-Bonnet term can shift $(n_s, r)$ along a trajectory that brings the predictions into better agreement with the ACT likelihood. We also find that $L+L^2$ gravity, in its scalar-tensor formulation, is equivalent to Higgs inflation coupled to the Gauss&ndash;Bonnet term, and belongs to the Horndeski/galileon class of modified gravities. This work establishes the quadratic $f(L)$ gravity as a compelling and physically motivated extension that preserves the successes of Starobinsky inflation while improving its fit to modern precision cosmological data.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21167v1">üìÑ Download PDF</a></p><hr><h3 id=orca-object-recognition-and-comprehension-for-archiving-marine-specieshttpsarxivorgabs251221150v1><a href=https://arxiv.org/abs/2512.21150v1>ORCA: Object Recognition and Comprehension for Archiving Marine Species</a><a hidden class=anchor aria-hidden=true href=#orca-object-recognition-and-comprehension-for-archiving-marine-specieshttpsarxivorgabs251221150v1>#</a></h3><p><strong>Authors:</strong> Yuk-Kwan Wong, Haixin Liang, Zeyu Ma, Yiwei Chen, Ziqiang Zheng, Rinaldi Gotama, Pascal Sebastian, Lauren D. Sparks, Sai-Kit Yeung
<strong>Venue:</strong> arXiv (2025)</p><p>Marine visual understanding is essential for monitoring and protecting marine ecosystems, enabling automatic and scalable biological surveys. However, progress is hindered by limited training data and the lack of a systematic task formulation that aligns domain-specific marine challenges with well-defined computer vision tasks, thereby limiting effective model application. To address this gap, we present ORCA, a multi-modal benchmark for marine research comprising 14,647 images from 478 species, with 42,217 bounding box annotations and 22,321 expert-verified instance captions. The dataset provides fine-grained visual and textual annotations that capture morphology-oriented attributes across diverse marine species. To catalyze methodological advances, we evaluate 18 state-of-the-art models on three tasks: object detection (closed-set and open-vocabulary), instance captioning, and visual grounding. Results highlight key challenges, including species diversity, morphological overlap, and specialized domain demands, underscoring the difficulty of marine understanding. ORCA thus establishes a comprehensive benchmark to advance research in marine domain. Project Page: <a href=http://orca.hkustvgd.com/>http://orca.hkustvgd.com/</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21150v1">üìÑ Download PDF</a></p><hr><h3 id=ticon-a-slide-level-tile-contextualizer-for-histopathology-representation-learninghttpsarxivorgabs251221331v1><a href=https://arxiv.org/abs/2512.21331v1>TICON: A Slide-Level Tile Contextualizer for Histopathology Representation Learning</a><a hidden class=anchor aria-hidden=true href=#ticon-a-slide-level-tile-contextualizer-for-histopathology-representation-learninghttpsarxivorgabs251221331v1>#</a></h3><p><strong>Authors:</strong> Varun Belagali, Saarthak Kapse, Pierre Marza, Srijan Das, Zilinghan Li, Sofi√®ne Boutaj, Pushpak Pati, Srikar Yellapragada, Tarak Nath Nandi, Ravi K Madduri, Joel Saltz, Prateek Prasanna, Stergios Christodoulidis Maria Vakalopoulou, Dimitris Samaras
<strong>Venue:</strong> arXiv (2025)</p><p>The interpretation of small tiles in large whole slide images (WSI) often needs a larger image context. We introduce TICON, a transformer-based tile representation contextualizer that produces rich, contextualized embeddings for &lsquo;&lsquo;any&rsquo;&rsquo; application in computational pathology. Standard tile encoder-based pipelines, which extract embeddings of tiles stripped from their context, fail to model the rich slide-level information essential for both local and global tasks. Furthermore, different tile-encoders excel at different downstream tasks. Therefore, a unified model is needed to contextualize embeddings derived from &lsquo;&lsquo;any&rsquo;&rsquo; tile-level foundation model. TICON addresses this need with a single, shared encoder, pretrained using a masked modeling objective to simultaneously unify and contextualize representations from diverse tile-level pathology foundation models. Our experiments demonstrate that TICON-contextualized embeddings significantly improve performance across many different tasks, establishing new state-of-the-art results on tile-level benchmarks (i.e., HEST-Bench, THUNDER, CATCH) and slide-level benchmarks (i.e., Patho-Bench). Finally, we pretrain an aggregator on TICON to form a slide-level foundation model, using only 11K WSIs, outperforming SoTA slide-level foundation models pretrained with up to 350K WSIs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21331v1">üìÑ Download PDF</a></p><hr><h3 id=towards-practical-automatic-piano-reduction-using-bert-with-semi-supervised-learninghttpsarxivorgabs251221324v1><a href=https://arxiv.org/abs/2512.21324v1>Towards Practical Automatic Piano Reduction using BERT with Semi-supervised Learning</a><a hidden class=anchor aria-hidden=true href=#towards-practical-automatic-piano-reduction-using-bert-with-semi-supervised-learninghttpsarxivorgabs251221324v1>#</a></h3><p><strong>Authors:</strong> Wan Ki Wong, Ka Ho To, Chuck-jee Chau, Lucas Wong, Kevin Y. Yip, Irwin King
<strong>Venue:</strong> arXiv (2025)</p><p>In this study, we present a novel automatic piano reduction method with semi-supervised machine learning. Piano reduction is an important music transformation process, which helps musicians and composers as a musical sketch for performances and analysis. The automation of such is a highly challenging research problem but could bring huge conveniences as manually doing a piano reduction takes a lot of time and effort. While supervised machine learning is often a useful tool for learning input-output mappings, it is difficult to obtain a large quantity of labelled data. We aim to solve this problem by utilizing semi-supervised learning, so that the abundant available data in classical music can be leveraged to perform the task with little or no labelling effort. In this regard, we formulate a two-step approach of music simplification followed by harmonization. We further propose and implement two possible solutions making use of an existing machine learning framework &ndash; MidiBERT. We show that our solutions can output practical and realistic samples with an accurate reduction that needs only small adjustments in post-processing. Our study forms the groundwork for the use of semi-supervised learning in automatic piano reduction, where future researchers can take reference to produce more state-of-the-art results.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21324v1">üìÑ Download PDF</a></p><hr><h3 id=a-plan-reuse-mechanism-for-llm-driven-agenthttpsarxivorgabs251221309v1><a href=https://arxiv.org/abs/2512.21309v1>A Plan Reuse Mechanism for LLM-Driven Agent</a><a hidden class=anchor aria-hidden=true href=#a-plan-reuse-mechanism-for-llm-driven-agenthttpsarxivorgabs251221309v1>#</a></h3><p><strong>Authors:</strong> Guopeng Li, Ruiqi Wu, Haisheng Tan
<strong>Venue:</strong> arXiv (2025)</p><p>Integrating large language models (LLMs) into personal assistants, like Xiao Ai and Blue Heart V, effectively enhances their ability to interact with humans, solve complex tasks, and manage IoT devices. Such assistants are also termed LLM-driven agents. Upon receiving user requests, the LLM-driven agent generates plans using an LLM, executes these plans through various tools, and then returns the response to the user. During this process, the latency for generating a plan with an LLM can reach tens of seconds, significantly degrading user experience. Real-world dataset analysis shows that about 30% of the requests received by LLM-driven agents are identical or similar, which allows the reuse of previously generated plans to reduce latency. However, it is difficult to accurately define the similarity between the request texts received by the LLM-driven agent through directly evaluating the original request texts. Moreover, the diverse expressions of natural language and the unstructured format of plan texts make implementing plan reuse challenging. To address these issues, we present and implement a plan reuse mechanism for LLM-driven agents called AgentReuse. AgentReuse leverages the similarities and differences among requests&rsquo; semantics and uses intent classification to evaluate the similarities between requests and enable the reuse of plans. Experimental results based on a real-world dataset demonstrate that AgentReuse achieves a 93% effective plan reuse rate, an F1 score of 0.9718, and an accuracy of 0.9459 in evaluating request similarities, reducing latency by 93.12% compared with baselines without using the reuse mechanism.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21309v1">üìÑ Download PDF</a></p><hr><h3 id=bar-formation-in-disc-galaxies-internal-kinematics-and-environmental-influence-in-manga-galaxieshttpsarxivorgabs251221303v1><a href=https://arxiv.org/abs/2512.21303v1>Bar Formation in Disc Galaxies: Internal Kinematics and Environmental Influence in MaNGA Galaxies</a><a hidden class=anchor aria-hidden=true href=#bar-formation-in-disc-galaxies-internal-kinematics-and-environmental-influence-in-manga-galaxieshttpsarxivorgabs251221303v1>#</a></h3><p><strong>Authors:</strong> Erik Aquino-Ort√≠z, Bernardo Cervantes-Sodi, Karol Chim-Ramirez
<strong>Venue:</strong> arXiv (2025)</p><p>We explore how the physical properties of disc galaxies relate to the presence of bars using data from the SDSS-IV MaNGA survey. By combining internal kinematical properties and environmental diagnostics, we find that barred galaxies are more frequently associated with centrally concentrated stellar mass distributions (within 1 and 2 effective radii) and exhibit lower values of the stellar angular momentum $Œª_{Re}$. At fixed total stellar mass, barred galaxies exhibit: (i) higher stellar mass, and (ii) lower angular momentum, both in their inner regions than their unbarred counterparts. We find a bimodal dependence of the bar fraction on tidal interactions produced by the nearest neighbour. Specifically, the bar fraction peaks in the most isolated galaxies, where bars form unequivocally through internal secular processes, decreases at intermediate interaction strengths, and rises again in the strong interaction regime, likely reflecting the role of dense environments in sustaining or triggering bars. Our results suggest that internal gravitational instabilities are the primary driver of bar formation. External tidal perturbations play a secondary role, capable of triggering or enhancing bar formation in galaxies that are already internally predisposed. Our findings provide robust observational validation of theoretical bar formation and evolution models in galaxies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21303v1">üìÑ Download PDF</a></p><hr><h3 id=unirec-01b-unified-text-and-formula-recognition-with-01b-parametershttpsarxivorgabs251221095v1><a href=https://arxiv.org/abs/2512.21095v1>UniRec-0.1B: Unified Text and Formula Recognition with 0.1B Parameters</a><a hidden class=anchor aria-hidden=true href=#unirec-01b-unified-text-and-formula-recognition-with-01b-parametershttpsarxivorgabs251221095v1>#</a></h3><p><strong>Authors:</strong> Yongkun Du, Zhineng Chen, Yazhen Xie, Weikang Baiand Hao Feng, Wei Shi, Yuchen Su, Can Huang, Yu-Gang Jiang
<strong>Venue:</strong> arXiv (2025)</p><p>Text and formulas constitute the core informational components of many documents. Accurately and efficiently recognizing both is crucial for developing robust and generalizable document parsing systems. Recently, vision-language models (VLMs) have achieved impressive unified recognition of text and formulas. However, they are large-sized and computationally demanding, restricting their usage in many applications. In this paper, we propose UniRec-0.1B, a unified recognition model with only 0.1B parameters. It is capable of performing text and formula recognition at multiple levels, including characters, words, lines, paragraphs, and documents. To implement this task, we first establish UniRec40M, a large-scale dataset comprises 40 million text, formula and their mix samples, enabling the training of a powerful yet lightweight model. Secondly, we identify two challenges when building such a lightweight but unified expert model. They are: structural variability across hierarchies and semantic entanglement between textual and formulaic content. To tackle these, we introduce a hierarchical supervision training that explicitly guides structural comprehension, and a semantic-decoupled tokenizer that separates text and formula representations. Finally, we develop a comprehensive evaluation benchmark covering Chinese and English documents from multiple domains and with multiple levels. Experimental results on this and public benchmarks demonstrate that UniRec-0.1B outperforms both general-purpose VLMs and leading document parsing expert models, while achieving a 2-9$\times$ speedup, validating its effectiveness and efficiency. Codebase and Dataset: <a href=https://github.com/Topdu/OpenOCR>https://github.com/Topdu/OpenOCR</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21095v1">üìÑ Download PDF</a></p><hr><h3 id=laser-governing-long-horizon-agentic-search-via-structured-protocol-and-context-registerhttpsarxivorgabs251220458v1><a href=https://arxiv.org/abs/2512.20458v1>Laser: Governing Long-Horizon Agentic Search via Structured Protocol and Context Register</a><a hidden class=anchor aria-hidden=true href=#laser-governing-long-horizon-agentic-search-via-structured-protocol-and-context-registerhttpsarxivorgabs251220458v1>#</a></h3><p><strong>Authors:</strong> Shuting Wang, Qiaolin Xia, Hao Wang, Yu Lu, Bobsimons, Zhicheng Dou
<strong>Venue:</strong> arXiv (2025)</p><p>Recent advances in Large Language Models (LLMs) and Large Reasoning Models (LRMs) have enabled agentic search systems that interleave multi-step reasoning with external tool use. However, existing frameworks largely rely on unstructured natural-language reasoning and accumulate raw intermediate traces in the context, which often leads to unstable reasoning trajectories, context overflow, and degraded performance on complex multi-hop queries. In this study, we introduce Laser, a general framework for stabilizing and scaling agentic search. Laser defines a symbolic action protocol that organizes agent behaviors into three spaces: planning, task-solving, and retrospection. Each action is specified with explicit semantics and a deterministic execution format, enabling structured and logical reasoning processes and reliable action parsing. This design makes intermediate decisions interpretable and traceable, enhancing explicit retrospection and fine-grained control over reasoning trajectories. In coordination with parsable actions, Laser further maintains a compact context register that stores only essential states of the reasoning process, allowing the agent to reason over long horizons without uncontrolled context expansion. Experiments on Qwen2.5/3-series models across challenging multi-hop QA datasets show that Laser consistently outperforms existing agentic search baselines under both prompting-only and fine-tuning settings, demonstrating that Laser provides a principled and effective foundation for robust, scalable agentic search.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20458v1">üìÑ Download PDF</a></p><hr><h3 id=from-cosmology-to-cosmonomyhttpsarxivorgabs251220416v1><a href=https://arxiv.org/abs/2512.20416v1>From Cosmology to Cosmonomy</a><a hidden class=anchor aria-hidden=true href=#from-cosmology-to-cosmonomyhttpsarxivorgabs251220416v1>#</a></h3><p><strong>Authors:</strong> Emmanuel N. Saridakis
<strong>Venue:</strong> arXiv (2025)</p><p>For most of its history, cosmology was a qualitatively constrained discourse on the universe, shaped by limited observational access and the absence of global dynamical laws. This situation has changed decisively in recent decades. Modern cosmology is now driven by an unprecedented flow of high-precision data from a wide range of independent probes, including the cosmic microwave background, large-scale structure, supernovae, baryon acoustic oscillations, gravitational lensing, cosmic chronometers, redshift-space distortions, gravitational-wave standard sirens, and emerging 21-cm observations, among others. This observational wealth is matched by a concrete theoretical and mathematical framework, based on general relativity, which provides the dynamical equations governing the evolution of spacetime and matter at cosmic scales. Combined with explicit background and perturbative equations, this framework enables quantitative, predictive, and falsifiable descriptions of cosmic evolution. Thus, cosmology operates today as a nomological natural science of the observable universe, characterized by general laws, predictive power, and systematic empirical testing. We argue that this epistemic transformation motivates a corresponding conceptual shift, directly analogous to the historical transition from astrology to astronomy. In this sense, the transition from cosmology to \emph{cosmonomy} should begin to be discussed among cosmologists, or, more precisely, among cosmonomers.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20416v1">üìÑ Download PDF</a></p><hr><h3 id=indicdlp-a-foundational-dataset-for-multi-lingual-and-multi-domain-document-layout-parsinghttpsarxivorgabs251220236v1><a href=https://arxiv.org/abs/2512.20236v1>IndicDLP: A Foundational Dataset for Multi-Lingual and Multi-Domain Document Layout Parsing</a><a hidden class=anchor aria-hidden=true href=#indicdlp-a-foundational-dataset-for-multi-lingual-and-multi-domain-document-layout-parsinghttpsarxivorgabs251220236v1>#</a></h3><p><strong>Authors:</strong> Oikantik Nath, Sahithi Kukkala, Mitesh Khapra, Ravi Kiran Sarvadevabhatla
<strong>Venue:</strong> arXiv (2025)</p><p>Document layout analysis is essential for downstream tasks such as information retrieval, extraction, OCR, and digitization. However, existing large-scale datasets like PubLayNet and DocBank lack fine-grained region labels and multilingual diversity, making them insufficient for representing complex document layouts. In contrast, human-annotated datasets such as M6Doc and D4LA offer richer labels and greater domain diversity, but are too small to train robust models and lack adequate multilingual coverage. This gap is especially pronounced for Indic documents, which encompass diverse scripts yet remain underrepresented in current datasets, further limiting progress in this space. To address these shortcomings, we introduce IndicDLP, a large-scale foundational document layout dataset spanning 11 representative Indic languages alongside English and 12 common document domains. Additionally, we curate UED-mini, a dataset derived from DocLayNet and M6Doc, to enhance pretraining and provide a solid foundation for Indic layout models. Our experiments demonstrate that fine-tuning existing English models on IndicDLP significantly boosts performance, validating its effectiveness. Moreover, models trained on IndicDLP generalize well beyond Indic layouts, making it a valuable resource for document digitization. This work bridges gaps in scale, diversity, and annotation granularity, driving inclusive and efficient document understanding.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20236v1">üìÑ Download PDF</a></p><hr><h3 id=segearth-r2-towards-comprehensive-language-guided-segmentation-for-remote-sensing-imageshttpsarxivorgabs251220013v1><a href=https://arxiv.org/abs/2512.20013v1>SegEarth-R2: Towards Comprehensive Language-guided Segmentation for Remote Sensing Images</a><a hidden class=anchor aria-hidden=true href=#segearth-r2-towards-comprehensive-language-guided-segmentation-for-remote-sensing-imageshttpsarxivorgabs251220013v1>#</a></h3><p><strong>Authors:</strong> Zepeng Xin, Kaiyu Li, Luodi Chen, Wanchen Li, Yuchen Xiao, Hui Qiao, Weizhan Zhang, Deyu Meng, Xiangyong Cao
<strong>Venue:</strong> arXiv (2025)</p><p>Effectively grounding complex language to pixels in remote sensing (RS) images is a critical challenge for applications like disaster response and environmental monitoring. Current models can parse simple, single-target commands but fail when presented with complex geospatial scenarios, e.g., segmenting objects at various granularities, executing multi-target instructions, and interpreting implicit user intent. To drive progress against these failures, we present LaSeRS, the first large-scale dataset built for comprehensive training and evaluation across four critical dimensions of language-guided segmentation: hierarchical granularity, target multiplicity, reasoning requirements, and linguistic variability. By capturing these dimensions, LaSeRS moves beyond simple commands, providing a benchmark for complex geospatial reasoning. This addresses a critical gap: existing datasets oversimplify, leading to sensitivity-prone real-world models. We also propose SegEarth-R2, an MLLM architecture designed for comprehensive language-guided segmentation in RS, which directly confronts these challenges. The model&rsquo;s effectiveness stems from two key improvements: (1) a spatial attention supervision mechanism specifically handles the localization of small objects and their components, and (2) a flexible and efficient segmentation query mechanism that handles both single-target and multi-target scenarios. Experimental results demonstrate that our SegEarth-R2 achieves outstanding performance on LaSeRS and other benchmarks, establishing a powerful baseline for the next generation of geospatial segmentation. All data and code will be released at <a href=https://github.com/earth-insights/SegEarth-R2>https://github.com/earth-insights/SegEarth-R2</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20013v1">üìÑ Download PDF</a></p><hr><h3 id=how-well-do-large-language-models-recognize-instructional-moves-establishing-baselines-for-foundation-models-in-educational-discoursehttpsarxivorgabs251219903v1><a href=https://arxiv.org/abs/2512.19903v1>How well do Large Language Models Recognize Instructional Moves? Establishing Baselines for Foundation Models in Educational Discourse</a><a hidden class=anchor aria-hidden=true href=#how-well-do-large-language-models-recognize-instructional-moves-establishing-baselines-for-foundation-models-in-educational-discoursehttpsarxivorgabs251219903v1>#</a></h3><p><strong>Authors:</strong> Kirk Vanacore, Rene F. Kizilcec
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) are increasingly adopted in educational technologies for a variety of tasks, from generating instructional materials and assisting with assessment design to tutoring. While prior work has investigated how models can be adapted or optimized for specific tasks, far less is known about how well LLMs perform at interpreting authentic educational scenarios without significant customization. As LLM-based systems become widely adopted by learners and educators in everyday academic contexts, understanding their out-of-the-box capabilities is increasingly important for setting expectations and benchmarking. We compared six LLMs to estimate their baseline performance on a simple but important task: classifying instructional moves in authentic classroom transcripts. We evaluated typical prompting methods: zero-shot, one-shot, and few-shot prompting. We found that while zero-shot performance was moderate, providing comprehensive examples (few-shot prompting) significantly improved performance for state-of-the-art models, with the strongest configuration reaching Cohen&rsquo;s Kappa = 0.58 against expert-coded annotations. At the same time, improvements were neither uniform nor complete: performance varied considerably by instructional move, and higher recall frequently came at the cost of increased false positives. Overall, these findings indicate that foundation models demonstrate meaningful yet limited capacity to interpret instructional discourse, with prompt design helping to surface capability but not eliminating fundamental reliability constraints.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.19903v1">üìÑ Download PDF</a></p><hr><h3 id=topological-charge-2ne-superconductorshttpsarxivorgabs251221325v1><a href=https://arxiv.org/abs/2512.21325v1>Topological Charge-2ne Superconductors</a><a hidden class=anchor aria-hidden=true href=#topological-charge-2ne-superconductorshttpsarxivorgabs251221325v1>#</a></h3><p><strong>Authors:</strong> Zhi-Qiang Gao, Yan-Qi Wang, Hui Yang, Congjun Wu
<strong>Venue:</strong> arXiv (2025)</p><p>Charge-$4e$ superconductors are phases where quartets of electrons condense in the absence of Cooper pairing condensation. They exhibit distinctive signatures including fractional flux quantization and anomalous Josephson effects, and are actively being explored in strongly correlated systems, such as moir√© materials. In this work we develop a general framework for \emph{topological} charge-$2ne$ superconductors based on both wavefunction and field theory approaches. In particular, we generate topological charge-$2ne$ superconductors from charge-$2e$ ingredients, and by breaking the charge $U(1)$ symmetry in certain classes of quantum Hall states. Via bulk-edge correspondence, we further construct the corresponding edge conformal field theory and bulk topological quantum field theory for topological charge-$2ne$ superconductors that suggests fermionic nonabelian topological orders. Our results provide a unified low energy description of the topological charge-$2ne$ superconductivity, offer a concrete platform for studying symmetry breaking and enrichment in interacting topological phases of matter, and have direct implications for experimental probes such as quasiparticle interferometry.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21325v1">üìÑ Download PDF</a></p><hr><h3 id=quantum-entanglement-between-partons-in-a-strongly-coupled-quantum-field-theoryhttpsarxivorgabs251221228v1><a href=https://arxiv.org/abs/2512.21228v1>Quantum entanglement between partons in a strongly coupled quantum field theory</a><a hidden class=anchor aria-hidden=true href=#quantum-entanglement-between-partons-in-a-strongly-coupled-quantum-field-theoryhttpsarxivorgabs251221228v1>#</a></h3><p><strong>Authors:</strong> Wenyu Zhang, Wenyang Qian, Yiyu Zhou, Yang Li, Qun Wang
<strong>Venue:</strong> arXiv (2025)</p><p>We perform a first-principles, non-perturbative investigation of quantum entanglement between partonic constituents in a strongly coupled 3+1-dimensional scalar Yukawa theory, using light-front Hamiltonian methods with controlled Fock-space truncations. By explicitly constructing reduced density matrices for (mock) nucleon, pion, and anti-nucleon subsystems from light-front wave functions, we compute key entanglement witnesses, including von Neumann entropy, mutual information, and linear entropy, in both quenched (no sea pairs) and unquenched frameworks. We find that the entanglement entropy is closely related to the Shannon entropy of the transverse momentum dependent distribution, establishing a link between quantum information and parton structure. In contrast, the unquenched theory reveals genuinely non-classical correlations: the entanglement entropy cannot be reduced to any Shannon entropy of normalized parton distributions, demonstrating that the full hadronic wave function encodes quantum information beyond classical probabilities. Our findings highlight the role of entanglement as a fundamental probe of non-perturbative dynamics in relativistic quantum field theory and lay the groundwork for extending these concepts to QCD and future collider phenomenology.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21228v1">üìÑ Download PDF</a></p><hr><h3 id=visres-bench-on-evaluating-the-visual-reasoning-capabilities-of-vlmshttpsarxivorgabs251221194v1><a href=https://arxiv.org/abs/2512.21194v1>VisRes Bench: On Evaluating the Visual Reasoning Capabilities of VLMs</a><a hidden class=anchor aria-hidden=true href=#visres-bench-on-evaluating-the-visual-reasoning-capabilities-of-vlmshttpsarxivorgabs251221194v1>#</a></h3><p><strong>Authors:</strong> Brigitta Malagurski T√∂rtei, Yasser Dahou, Ngoc Dung Huynh, Wamiq Reyaz Para, Ph√∫c H. L√™ Khac, Ankit Singh, Sofian Chaybouti, Sanath Narayan
<strong>Venue:</strong> arXiv (2025)</p><p>Vision-Language Models (VLMs) have achieved remarkable progress across tasks such as visual question answering and image captioning. Yet, the extent to which these models perform visual reasoning as opposed to relying on linguistic priors remains unclear. To address this, we introduce VisRes Bench, a benchmark designed to study visual reasoning in naturalistic settings without contextual language supervision. Analyzing model behavior across three levels of complexity, we uncover clear limitations in perceptual and relational visual reasoning capacities. VisRes isolates distinct reasoning abilities across its levels. Level 1 probes perceptual completion and global image matching under perturbations such as blur, texture changes, occlusion, and rotation; Level 2 tests rule-based inference over a single attribute (e.g., color, count, orientation); and Level 3 targets compositional reasoning that requires integrating multiple visual attributes. Across more than 19,000 controlled task images, we find that state-of-the-art VLMs perform near random under subtle perceptual perturbations, revealing limited abstraction beyond pattern recognition. We conclude by discussing how VisRes provides a unified framework for advancing abstract visual reasoning in multimodal research.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21194v1">üìÑ Download PDF</a></p><hr><h3 id=search-for-light-dark-matter-in-rare-meson-decayshttpsarxivorgabs251221191v1><a href=https://arxiv.org/abs/2512.21191v1>Search for Light Dark Matter in Rare Meson Decays</a><a hidden class=anchor aria-hidden=true href=#search-for-light-dark-matter-in-rare-meson-decayshttpsarxivorgabs251221191v1>#</a></h3><p><strong>Authors:</strong> Ze-Kun Liu, Ying Li, Biao-Feng Hou, Qin Chang
<strong>Venue:</strong> arXiv (2025)</p><p>Current dark matter direct detection experiments have low sensitivity to sub-GeV dark matter. In this work, we demonstrate that rare $B$ and $K$ meson decays with missing energy in the final state can serve as efficient probes in this mass range. We analyze a generic $Z^{\prime}$ portal dark matter model and derive upper limits on its parameters from experimental bounds on the rare $B$ and $K$ meson decays. Our results show that such meson decay processes provide complementary constraints to current direct detection experiments for sub-GeV dark matter, particularly for interaction forms mediated by dark matter momentum dependent operators.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21191v1">üìÑ Download PDF</a></p><hr><h3 id=large-time-behavior-of-the-solution-to-the-cauchy-problem-for-the-discrete-p-laplacian-with-density-on-infinite-graphshttpsarxivorgabs251221321v1><a href=https://arxiv.org/abs/2512.21321v1>Large time behavior of the solution to the Cauchy problem for the discrete p-Laplacian with density on infinite graphs</a><a hidden class=anchor aria-hidden=true href=#large-time-behavior-of-the-solution-to-the-cauchy-problem-for-the-discrete-p-laplacian-with-density-on-infinite-graphshttpsarxivorgabs251221321v1>#</a></h3><p><strong>Authors:</strong> Alan A. Tedeev
<strong>Venue:</strong> arXiv (2025)</p><p>We consider the Cauchy problem for the nonstationary discrete p-Laplacian with inhomogeneous density \r{ho}(x) on an infinite graph which supports the Sobolev inequality. For nonnegative solutions when p > 2, we prove the precise rate of stabilization in time, provided \r{ho}(x) is a non-power function. When p > 2 and \r{ho}(x) goes to zero fast enough, we prove the universal bound. Our technique relies on suitable energy inequalities and a new embedding result.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21321v1">üìÑ Download PDF</a></p><hr><h3 id=universality-of-equilibration-dynamics-after-quantum-quencheshttpsarxivorgabs251221313v1><a href=https://arxiv.org/abs/2512.21313v1>Universality of equilibration dynamics after quantum quenches</a><a hidden class=anchor aria-hidden=true href=#universality-of-equilibration-dynamics-after-quantum-quencheshttpsarxivorgabs251221313v1>#</a></h3><p><strong>Authors:</strong> Vincenzo Alba, Sanam Azarnia, Gianluca Lagnese, Federico Rottoli
<strong>Venue:</strong> arXiv (2025)</p><p>We investigate the distribution of the eigenvalues of the reduced density matrix (entanglement spectrum) after a global quantum quench. We show that in an appropriate scaling limit the lower part of the entanglement spectrum exhibits ``universality&rsquo;&rsquo;. In the scaling limit and at asymptotically long times the distribution of the entanglement spectrum depends on two parameters that can be determined from the R√©nyi entropies. We show that two typical scenarios occur. In the first one, the distribution of the entanglement spectrum levels is similar to the one describing the ground-state entanglement spectrum in Conformal Field Theories. In the second scenario, the lower levels of the entanglement spectrum are highly degenerate and their distribution is given by a series of Dirac deltas. We benchmark our analytical results in free-fermion chains, such as the transverse field Ising chain and the XX chain, in the rule 54 chain, and in Bethe ansatz solvable spin models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21313v1">üìÑ Download PDF</a></p><hr><h3 id=the-patterson-sullivan-construction-and-global-leaf-geometry-for-anosov-flowshttpsarxivorgabs251221308v1><a href=https://arxiv.org/abs/2512.21308v1>The Patterson-Sullivan construction and global leaf geometry for Anosov flows</a><a hidden class=anchor aria-hidden=true href=#the-patterson-sullivan-construction-and-global-leaf-geometry-for-anosov-flowshttpsarxivorgabs251221308v1>#</a></h3><p><strong>Authors:</strong> Clark Butler
<strong>Venue:</strong> arXiv (2025)</p><p>We give a new construction of the measure of maximal entropy for transitive Anosov flows through a method analogous to the construction of Patterson-Sullivan measures in negative curvature. In order to carry out our procedure we prove several new results concerning the global geometry of the leaves of the center-unstable foliation of an Anosov flow. We show that the universal covers of the center-unstable leaves are Gromov hyperbolic in the induced Riemannian metric and their relative Gromov boundaries canonically identify with the unstable leaves within in such a way that the Hamenst√§dt metrics on these leaves correspond to visual metrics on the relative Gromov boundary. These center-unstable leaves are then uniformized according to a technique inspired by methods of Bonk-Heinonen-Koskela which, in addition to its utility in the construction itself, also leads to rich analytic properties for these uniformized leaves such as supporting a Poincar√© inequality. As a corollary we obtain that the fundamental group of a closed Riemannian manifold with Anosov geodesic flow must be Gromov hyperbolic.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21308v1">üìÑ Download PDF</a></p><hr><h3 id=semantic-refinement-with-llms-for-graph-representationshttpsarxivorgabs251221106v1><a href=https://arxiv.org/abs/2512.21106v1>Semantic Refinement with LLMs for Graph Representations</a><a hidden class=anchor aria-hidden=true href=#semantic-refinement-with-llms-for-graph-representationshttpsarxivorgabs251221106v1>#</a></h3><p><strong>Authors:</strong> Safal Thapaliya, Zehong Wang, Jiazheng Li, Ziming Li, Yanfang Ye, Chuxu Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>Graph-structured data exhibit substantial heterogeneity in where their predictive signals originate: in some domains, node-level semantics dominate, while in others, structural patterns play a central role. This structure-semantics heterogeneity implies that no graph learning model with a fixed inductive bias can generalize optimally across diverse graph domains. However, most existing methods address this challenge from the model side by incrementally injecting new inductive biases, which remains fundamentally limited given the open-ended diversity of real-world graphs. In this work, we take a data-centric perspective and treat node semantics as a task-adaptive variable. We propose a Data-Adaptive Semantic Refinement framework DAS for graph representation learning, which couples a fixed graph neural network (GNN) and a large language model (LLM) in a closed feedback loop. The GNN provides implicit supervisory signals to guide the semantic refinement of LLM, and the refined semantics are fed back to update the same graph learner. We evaluate our approach on both text-rich and text-free graphs. Results show consistent improvements on structure-dominated graphs while remaining competitive on semantics-rich graphs, demonstrating the effectiveness of data-centric semantic adaptation under structure-semantics heterogeneity.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21106v1">üìÑ Download PDF</a></p><hr><h3 id=reflection-pretraining-enables-token-level-self-correction-in-biological-sequence-modelshttpsarxivorgabs251220954v1><a href=https://arxiv.org/abs/2512.20954v1>Reflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models</a><a hidden class=anchor aria-hidden=true href=#reflection-pretraining-enables-token-level-self-correction-in-biological-sequence-modelshttpsarxivorgabs251220954v1>#</a></h3><p><strong>Authors:</strong> Xiang Zhang, Jiaqi Wei, Yuejin Yang, Zijie Qiu, Yuhan Chen, Zhiqiang Gao, Muhammad Abdul-Mageed, Laks V. S. Lakshmanan, Wanli Ouyang, Chenyu You, Siqi Sun
<strong>Venue:</strong> arXiv (2025)</p><p>Chain-of-Thought (CoT) prompting has significantly advanced task-solving capabilities in natural language processing with large language models. Unlike standard prompting, CoT encourages the model to generate intermediate reasoning steps, non-answer tokens, that help guide the model toward more accurate final outputs. These intermediate steps enable more complex reasoning processes such as error correction, memory management, future planning, and self-reflection. However, applying CoT to non-natural language domains, such as protein and RNA language models, is not yet possible, primarily due to the limited expressiveness of their token spaces (e.g., amino acid tokens). In this work, we propose and define the concept of language expressiveness: the ability of a given language, using its tokens and grammar, to encode information. We show that the limited expressiveness of protein language severely restricts the applicability of CoT-style reasoning. To overcome this, we introduce reflection pretraining, for the first time in a biological sequence model, which enables the model to engage in intermediate reasoning through the generation of auxiliary &ldquo;thinking tokens&rdquo; beyond simple answer tokens. Theoretically, we demonstrate that our augmented token set significantly enhances biological language expressiveness, thereby improving the overall reasoning capacity of the model. Experimentally, our pretraining approach teaches protein models to self-correct and leads to substantial performance gains compared to standard pretraining.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20954v1">üìÑ Download PDF</a></p><hr><h3 id=transductive-visual-programming-evolving-tool-libraries-from-experience-for-spatial-reasoninghttpsarxivorgabs251220934v1><a href=https://arxiv.org/abs/2512.20934v1>Transductive Visual Programming: Evolving Tool Libraries from Experience for Spatial Reasoning</a><a hidden class=anchor aria-hidden=true href=#transductive-visual-programming-evolving-tool-libraries-from-experience-for-spatial-reasoninghttpsarxivorgabs251220934v1>#</a></h3><p><strong>Authors:</strong> Shengguang Wu, Xiaohan Wang, Yuhui Zhang, Hao Zhu, Serena Yeung-Levy
<strong>Venue:</strong> arXiv (2025)</p><p>Spatial reasoning in 3D scenes requires precise geometric calculations that challenge vision-language models. Visual programming addresses this by decomposing problems into steps calling specialized tools, yet existing methods rely on either fixed toolsets or speculative tool induction before solving problems, resulting in suboptimal programs and poor utilization of induced tools. We present Transductive Visual Programming (TVP), a novel framework that builds new tools from its own experience rather than speculation. TVP first solves problems using basic tools while accumulating experiential solutions into an Example Library, then abstracts recurring patterns from these programs into reusable higher-level tools for an evolving Tool Library. This allows TVP to tackle new problems with increasingly powerful tools learned from experience. On Omni3D-Bench, TVP achieves state-of-the-art performance, outperforming GPT-4o by 22% and the previous best visual programming system by 11%. Our transductively learned tools are used 5x more frequently as core program dependency than inductively created ones, demonstrating more effective tool discovery and reuse. The evolved tools also show strong generalization to unseen spatial tasks, achieving superior performance on benchmarks from SpatialScore-Hard collection without any testset-specific modification. Our work establishes experience-driven transductive tool creation as a powerful paradigm for building self-evolving visual programming agents that effectively tackle challenging spatial reasoning tasks. We release our code at <a href=https://transductive-visualprogram.github.io/>https://transductive-visualprogram.github.io/</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20934v1">üìÑ Download PDF</a></p><hr><h3 id=virtual-volumes-of-strata-of-meromorphic-differentials-with-simple-poleshttpsarxivorgabs251220819v1><a href=https://arxiv.org/abs/2512.20819v1>Virtual volumes of strata of meromorphic differentials with simple poles</a><a hidden class=anchor aria-hidden=true href=#virtual-volumes-of-strata-of-meromorphic-differentials-with-simple-poleshttpsarxivorgabs251220819v1>#</a></h3><p><strong>Authors:</strong> Adrien Sauvaget
<strong>Venue:</strong> arXiv (2025)</p><p>We work over strata of meromorphic differentials with poles of order 1, and on affine subspaces defined by linear conditions on the residues. We propose a definition of the volume of these objects as the integral of a tautological class on the projectivization of the stratum. By previous work with Chen-M√∂ller-Zagier, this definition agrees with the Masur-Veech volumes in the holomorphic case. We show that these algebraic constants can be computed by induction on the genus and number of singularities. Besides, for strata with a single zero, we prove that the generating series of these volumes is a solution of an integrable system associated with the PDE: $u_tu_{xx}=u_tu_x+u_t - 1$.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20819v1">üìÑ Download PDF</a></p><hr><h3 id=process-analytics----data-driven-business-process-managementhttpsarxivorgabs251220703v1><a href=https://arxiv.org/abs/2512.20703v1>Process Analytics &ndash; Data-driven Business Process Management</a><a hidden class=anchor aria-hidden=true href=#process-analytics----data-driven-business-process-managementhttpsarxivorgabs251220703v1>#</a></h3><p><strong>Authors:</strong> Matthias Stierle, Karsten Kraume, Martin Matzner
<strong>Venue:</strong> arXiv (2025)</p><p>Data-driven analysis of business processes has a long tradition in research. However, recently the term of process mining is mostly used when referring to data-driven process analysis. As a consequence, awareness for the many facets of process analysis is decreasing. In particular, while an increasing focus is put onto technical aspects of the analysis, human and organisational concerns remain under the radar. Following the socio-technical perspective of information systems research, we propose a new perspective onto data-driven process analysis that combines the process of analysis with the organisation and its stakeholders. This paper conceptualises the term process analytics and its various dimensions by following both an inductive and deductive approach. The results are discussed by contrasting them to a real-life case study from a large company implementing data-driven process analysis and automation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20703v1">üìÑ Download PDF</a></p><hr><h2 id=-psycholinguistics>üîç psycholinguistics<a hidden class=anchor aria-hidden=true href=#-psycholinguistics>#</a></h2><h3 id=mixing-time-of-the-random-walk-on-the-giant-component-of-the-random-geometric-graphhttpsarxivorgabs251221322v1><a href=https://arxiv.org/abs/2512.21322v1>Mixing time of the random walk on the giant component of the random geometric graph</a><a hidden class=anchor aria-hidden=true href=#mixing-time-of-the-random-walk-on-the-giant-component-of-the-random-geometric-graphhttpsarxivorgabs251221322v1>#</a></h3><p><strong>Authors:</strong> Magnus H. Haaland, Anƒëela ≈†arkoviƒá
<strong>Venue:</strong> arXiv (2025)</p><p>We consider a random geometric graph obtained by placing a Poisson point process of intensity 1 in the d-dimensional torus of side length n^(1/d) and connecting two points by an edge if their distance is at most r. We consider the case of d>=2 and r in [r_min, r_max], where r_min&lt;r_max are any constants with r_min>r_g and r_g is a constant above which this graph has a giant component with high probability. We show that, with high probability, the mixing time and the relaxation time of the simple random walk on the giant component in this case are both of order n^(2/d) and that therefore there is no cutoff. We also obtain bounds for the isoperimetric profile of subsets of the giant component of at least polylogarithmic size.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21322v1">üìÑ Download PDF</a></p><hr><h3 id=does-the-data-processing-inequality-reflect-practice-on-the-utility-of-low-level-taskshttpsarxivorgabs251221315v1><a href=https://arxiv.org/abs/2512.21315v1>Does the Data Processing Inequality Reflect Practice? On the Utility of Low-Level Tasks</a><a hidden class=anchor aria-hidden=true href=#does-the-data-processing-inequality-reflect-practice-on-the-utility-of-low-level-taskshttpsarxivorgabs251221315v1>#</a></h3><p><strong>Authors:</strong> Roy Turgeman, Tom Tirer
<strong>Venue:</strong> arXiv (2025)</p><p>The data processing inequality is an information-theoretic principle stating that the information content of a signal cannot be increased by processing the observations. In particular, it suggests that there is no benefit in enhancing the signal or encoding it before addressing a classification problem. This assertion can be proven to be true for the case of the optimal Bayes classifier. However, in practice, it is common to perform &ldquo;low-level&rdquo; tasks before &ldquo;high-level&rdquo; downstream tasks despite the overwhelming capabilities of modern deep neural networks. In this paper, we aim to understand when and why low-level processing can be beneficial for classification. We present a comprehensive theoretical study of a binary classification setup, where we consider a classifier that is tightly connected to the optimal Bayes classifier and converges to it as the number of training samples increases. We prove that for any finite number of training samples, there exists a pre-classification processing that improves the classification accuracy. We also explore the effect of class separation, training set size, and class balance on the relative gain from this procedure. We support our theory with an empirical investigation of the theoretical setup. Finally, we conduct an empirical study where we investigate the effect of denoising and encoding on the performance of practical deep classifiers on benchmark datasets. Specifically, we vary the size and class distribution of the training set, and the noise level, and demonstrate trends that are consistent with our theoretical results.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21315v1">üìÑ Download PDF</a></p><hr><h3 id=coding-logic-correspondence-turning-information-and-communication-networks-into-logical-formulae-via-hypergraph-heyting-algebrahttpsarxivorgabs251221112v1><a href=https://arxiv.org/abs/2512.21112v1>Coding-Logic Correspondence: Turning Information and Communication Networks into Logical Formulae via Hypergraph Heyting Algebra</a><a hidden class=anchor aria-hidden=true href=#coding-logic-correspondence-turning-information-and-communication-networks-into-logical-formulae-via-hypergraph-heyting-algebrahttpsarxivorgabs251221112v1>#</a></h3><p><strong>Authors:</strong> Cheuk Ting Li
<strong>Venue:</strong> arXiv (2025)</p><p>We propose using confusion hypergraphs (hyperconfusions) as a model of information. In contrast to the conventional approach using random variables, we can now perform conjunction, disjunction and implication of information, forming a Heyting algebra. Using the connection between Heyting algebra and intuitionistic logic, we can express the requirements of a communication network (e.g., network coding, index coding, Slepian-Wolf coding) as a logical formula, allowing us to use the hypergraph Heyting algebra to directly compute the optimal coding scheme. The optimal communication cost is simply given by the entropy of the hypergraph (within a logarithmic gap). This gives a surprising correspondence between coding settings and logical formulae, similar to the Curry-Howard correspondence between proofs and computer programs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21112v1">üìÑ Download PDF</a></p><hr><h3 id=spatialtree-how-spatial-abilities-branch-out-in-mllmshttpsarxivorgabs251220617v1><a href=https://arxiv.org/abs/2512.20617v1>SpatialTree: How Spatial Abilities Branch Out in MLLMs</a><a hidden class=anchor aria-hidden=true href=#spatialtree-how-spatial-abilities-branch-out-in-mllmshttpsarxivorgabs251220617v1>#</a></h3><p><strong>Authors:</strong> Yuxi Xiao, Longfei Li, Shen Yan, Xinhang Liu, Sida Peng, Yunchao Wei, Xiaowei Zhou, Bingyi Kang
<strong>Venue:</strong> arXiv (2025)</p><p>Cognitive science suggests that spatial ability develops progressively-from perception to reasoning and interaction. Yet in multimodal LLMs (MLLMs), this hierarchy remains poorly understood, as most studies focus on a narrow set of tasks. We introduce SpatialTree, a cognitive-science-inspired hierarchy that organizes spatial abilities into four levels: low-level perception (L1), mental mapping (L2), simulation (L3), and agentic competence (L4). Based on this taxonomy, we construct the first capability-centric hierarchical benchmark, thoroughly evaluating mainstream MLLMs across 27 sub-abilities. The evaluation results reveal a clear structure: L1 skills are largely orthogonal, whereas higher-level skills are strongly correlated, indicating increasing interdependency. Through targeted supervised fine-tuning, we uncover a surprising transfer dynamic-negative transfer within L1, but strong cross-level transfer from low- to high-level abilities with notable synergy. Finally, we explore how to improve the entire hierarchy. We find that naive RL that encourages extensive &ldquo;thinking&rdquo; is unreliable: it helps complex reasoning but hurts intuitive perception. We propose a simple auto-think strategy that suppresses unnecessary deliberation, enabling RL to consistently improve performance across all levels. By building SpatialTree, we provide a proof-of-concept framework for understanding and systematically scaling spatial abilities in MLLMs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20617v1">üìÑ Download PDF</a></p><hr><h3 id=uniform-spanning-trees-and-random-matrix-statisticshttpsarxivorgabs251220540v1><a href=https://arxiv.org/abs/2512.20540v1>Uniform spanning trees and random matrix statistics</a><a hidden class=anchor aria-hidden=true href=#uniform-spanning-trees-and-random-matrix-statisticshttpsarxivorgabs251220540v1>#</a></h3><p><strong>Authors:</strong> Nathana√´l Berestycki, Marcin Lis, Mingchang Liu, Eveliina Peltola
<strong>Venue:</strong> arXiv (2025)</p><p>We consider a uniform spanning tree in a $Œ¥$-square grid approximation of a planar domain $Œ©$. For given integer $n\ge 2$, we condition the tree on the following $n$-arm event: we pick $n$ branches, emanating from $n$ points microscopically close to a given interior point, and condition them to connect to the boundary $\partial Œ©$ without intersecting. What can be said about the geometry of these branches?
We derive an exact formula for the characteristic function of the total winding of the branches. A surprising consequence of this formula is that in the scaling limit, the behaviour of this function depends on the total number of branches $n$ only through its parity.
We also describe the scaling limit of the branches. If $Œ©$ is the unit disc, then they hit the boundary (i.e., the unit circle) at random positions which coincide exactly with the eigenvalues of a random matrix of size $n$ drawn from the Circular Orthogonal Ensemble (COE, also called C$Œ≤$E with $Œ≤=1$). Furthermore, the branches converge to Loewner evolution driven by the circular Dyson Brownian motion with parameter $Œ≤= 4$ (i.e., $n$-sided radial SLE$_Œ∫$ with $Œ∫=2$). We thus verify a prediction made by Cardy in this setting.
Along the way, we develop a flow-line (imaginary geometry) coupling of $n$-sided radial SLE$_Œ∫$ with the Gaussian free field, which may be of independent interest. Surprisingly, we find that the variance of the corresponding field near the singularity also does not depend on the number $n\ge 2$ of curves. In contrast, the variance of the the winding of the curves behaves as $Œ∫/n^2$, which agrees with the predictions from the physics literature made by Wieland and Wilson numerically, and by Duplantier and Binder using Coulomb gas methods &ndash; but disagrees with a result of Kenyon.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20540v1">üìÑ Download PDF</a></p><hr><h3 id=numerical-analysis-of-test-optimalityhttpsarxivorgabs251219843v1><a href=https://arxiv.org/abs/2512.19843v1>Numerical Analysis of Test Optimality</a><a hidden class=anchor aria-hidden=true href=#numerical-analysis-of-test-optimalityhttpsarxivorgabs251219843v1>#</a></h3><p><strong>Authors:</strong> Philipp Ketz, Adam McCloskey, Jan Scherer
<strong>Venue:</strong> arXiv (2025)</p><p>In nonstandard testing environments, researchers often derive ad hoc tests with correct (asymptotic) size, but their optimality properties are typically unknown a priori and difficult to assess. This paper develops a numerical framework for determining whether an ad hoc test is effectively optimal - approximately maximizing a weighted average power criterion for some weights over the alternative and attaining a power envelope generated by a single weighted average power-maximizing test. Our approach uses nested optimization algorithms to approximate the weight function that makes an ad hoc test&rsquo;s weighted average power as close as possible to that of a true weighted average power-maximizing test, and we show the surprising result that the rejection probabilities corresponding to the latter form an approximate power envelope for the former. We provide convergence guarantees, discuss practical implementation and apply the method to the weak instrument-robust conditional likelihood ratio test and a recently-proposed test for when a nuisance parameter may be on or near its boundary.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.19843v1">üìÑ Download PDF</a></p><hr><h3 id=yang-mills-energy-quantization-over-non-collapsed-degenerating-einstein-manifolds-and-applicationshttpsarxivorgabs251219552v1><a href=https://arxiv.org/abs/2512.19552v1>Yang-Mills energy quantization over non-collapsed degenerating Einstein manifolds and applications</a><a hidden class=anchor aria-hidden=true href=#yang-mills-energy-quantization-over-non-collapsed-degenerating-einstein-manifolds-and-applicationshttpsarxivorgabs251219552v1>#</a></h3><p><strong>Authors:</strong> Youmin Chen, Miaomiao Zhu
<strong>Venue:</strong> arXiv (2025)</p><p>We investigate a sequence of Yang-Mills connections $A_j$ lying in vector bundles $E_j$ over non-collapsed degenerating closed Einstein 4-manifolds $(M_j, g_ j)$ with uniformly bounded Einstein constants and bounded diameters. We establish a compactness theory modular three types of bubbles. As applications, we get some quantization results for several important topological number associated with the vector bundles, for instance, the first Pontrjagin numbers $p_1(E)$ of vector bundles over Einstein 4-manifolds and the Euler numbers $œá(M;E)$ of holomorphic vector bundles over K√§hler-Einstein surfaces. Furthermore, we get some quantization results about the volume $v(L_j)$ and certain cohomological numbers (e.g. $dim H^0(M_j;L_j)$) of holomorphic line bundles $L_j$ over non-collapsed degenerating K√§hler-Einstein surfaces $(M_j,J_j,g_j)$ with the aid of the classical vanishing theorems, the classical Hirzebruch-Riemann-Roch type theorems, and the profound convergence theory of K√§hler-Einstein manifolds. In particular, we obtain some interesting identities involving non-collapsed degenerating compact K√§hler-Einstein surfaces with non-zero scalar curvature, which indicate that we can know the Euler number of $M_j$ for large $j$ provided some topological information of the limit orbifold $M_\infty$. For K√§hler-Einstein Del Pezzo surfaces, an interesting implication is that we can provide some preliminary estimates for the number of singularities of various types in $M_\infty$ in an effective way. As an unexpected surprise, we find an identity which connects Milnor numbers for singularities in $M_\infty$ and the correction terms in the Hirzebruch-Riemann-Roch theorem for orbifolds. Some quantization results can be extended to the case of higher dimensional $n$-manifolds.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.19552v1">üìÑ Download PDF</a></p><hr><h3 id=characterizing-quantum-synchronization-in-the-van-der-pol-oscillator-via-tomogram-and-photon-correlationhttpsarxivorgabs251221272v1><a href=https://arxiv.org/abs/2512.21272v1>Characterizing quantum synchronization in the van der Pol oscillator via tomogram and photon correlation</a><a hidden class=anchor aria-hidden=true href=#characterizing-quantum-synchronization-in-the-van-der-pol-oscillator-via-tomogram-and-photon-correlationhttpsarxivorgabs251221272v1>#</a></h3><p><strong>Authors:</strong> Kingshuk Adhikary, K. M. Athira, M. Rohith
<strong>Venue:</strong> arXiv (2025)</p><p>We access the quantum synchronization (QS) in the steady state of a driven quantum van der Pol oscillator (vdPo) using two distinct figures of merit: (i) the nonclassical area $Œ¥$ and (ii) the second-order correlation function $g^{(2)}(0)$, which are both viable in experimental architectures. The nonclassical area quantifier rooted in homodyne tomography, allows us to assess the nonclassical nature of the vdPo&rsquo;s state directly from the tomogram without requiring full state reconstruction or the Wigner function negativity. Within a well-defined parameter regime of drive strength and detuning, both $Œ¥$ and $g^{(2)}(0)$ exhibit pronounced signatures of synchronization that complements the phase coherence between the drive and the vdPo. We derive an analytical expression for the steady-state density matrix and the corresponding tomogram of the system, valid for arbitrary strengths of the harmonic drive. Analysis of the quantum tomogram uncovers clear phase-locking behavior, enabling the identification of the synchronization region (Arnold tongue) directly in terms of experimentally measurable quantities. Furthermore, the behaviour of $g^{(2)}(0)$ provides a statistical perspective that reinforces the tomographic signatures of QS. By analyzing the interplay between these metrics, we can gain more profound insights into the underlying mechanisms that govern QS in such systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21272v1">üìÑ Download PDF</a></p><hr><h3 id=improving-the-convergence-rate-of-ray-search-optimization-for-query-efficient-hard-label-attackshttpsarxivorgabs251221241v1><a href=https://arxiv.org/abs/2512.21241v1>Improving the Convergence Rate of Ray Search Optimization for Query-Efficient Hard-Label Attacks</a><a hidden class=anchor aria-hidden=true href=#improving-the-convergence-rate-of-ray-search-optimization-for-query-efficient-hard-label-attackshttpsarxivorgabs251221241v1>#</a></h3><p><strong>Authors:</strong> Xinjie Xu, Shuyu Cheng, Dongwei Xu, Qi Xuan, Chen Ma
<strong>Venue:</strong> arXiv (2025)</p><p>In hard-label black-box adversarial attacks, where only the top-1 predicted label is accessible, the prohibitive query complexity poses a major obstacle to practical deployment. In this paper, we focus on optimizing a representative class of attacks that search for the optimal ray direction yielding the minimum $\ell_2$-norm perturbation required to move a benign image into the adversarial region. Inspired by Nesterov&rsquo;s Accelerated Gradient (NAG), we propose a momentum-based algorithm, ARS-OPT, which proactively estimates the gradient with respect to a future ray direction inferred from accumulated momentum. We provide a theoretical analysis of its convergence behavior, showing that ARS-OPT enables more accurate directional updates and achieves faster, more stable optimization. To further accelerate convergence, we incorporate surrogate-model priors into ARS-OPT&rsquo;s gradient estimation, resulting in PARS-OPT with enhanced performance. The superiority of our approach is supported by theoretical guarantees under standard assumptions. Extensive experiments on ImageNet and CIFAR-10 demonstrate that our method surpasses 13 state-of-the-art approaches in query efficiency.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21241v1">üìÑ Download PDF</a></p><hr><h3 id=casting-a-spell-sentence-pairing-exploration-for-llm-limitation-breakinghttpsarxivorgabs251221236v1><a href=https://arxiv.org/abs/2512.21236v1>Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking</a><a hidden class=anchor aria-hidden=true href=#casting-a-spell-sentence-pairing-exploration-for-llm-limitation-breakinghttpsarxivorgabs251221236v1>#</a></h3><p><strong>Authors:</strong> Yifan Huang, Xiaojun Jia, Wenbo Guo, Yuqiang Sun, Yihao Huang, Chong Wang, Yang Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) have revolutionized software development through AI-assisted coding tools, enabling developers with limited programming expertise to create sophisticated applications. However, this accessibility extends to malicious actors who may exploit these powerful tools to generate harmful software. Existing jailbreaking research primarily focuses on general attack scenarios against LLMs, with limited exploration of malicious code generation as a jailbreak target. To address this gap, we propose SPELL, a comprehensive testing framework specifically designed to evaluate the weakness of security alignment in malicious code generation. Our framework employs a time-division selection strategy that systematically constructs jailbreaking prompts by intelligently combining sentences from a prior knowledge dataset, balancing exploration of novel attack patterns with exploitation of successful techniques. Extensive evaluation across three advanced code models (GPT-4.1, Claude-3.5, and Qwen2.5-Coder) demonstrates SPELL&rsquo;s effectiveness, achieving attack success rates of 83.75%, 19.38%, and 68.12% respectively across eight malicious code categories. The generated prompts successfully produce malicious code in real-world AI development tools such as Cursor, with outputs confirmed as malicious by state-of-the-art detection systems at rates exceeding 73%. These findings reveal significant security gaps in current LLM implementations and provide valuable insights for improving AI safety alignment in code generation applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21236v1">üìÑ Download PDF</a></p><hr><h3 id=robocade-gamifying-robot-data-collectionhttpsarxivorgabs251221235v1><a href=https://arxiv.org/abs/2512.21235v1>RoboCade: Gamifying Robot Data Collection</a><a hidden class=anchor aria-hidden=true href=#robocade-gamifying-robot-data-collectionhttpsarxivorgabs251221235v1>#</a></h3><p><strong>Authors:</strong> Suvir Mirchandani, Mia Tang, Jiafei Duan, Jubayer Ibn Hamid, Michael Cho, Dorsa Sadigh
<strong>Venue:</strong> arXiv (2025)</p><p>Imitation learning from human demonstrations has become a dominant approach for training autonomous robot policies. However, collecting demonstration datasets is costly: it often requires access to robots and needs sustained effort in a tedious, long process. These factors limit the scale of data available for training policies. We aim to address this scalability challenge by involving a broader audience in a gamified data collection experience that is both accessible and motivating. Specifically, we develop a gamified remote teleoperation platform, RoboCade, to engage general users in collecting data that is beneficial for downstream policy training. To do this, we embed gamification strategies into the design of the system interface and data collection tasks. In the system interface, we include components such as visual feedback, sound effects, goal visualizations, progress bars, leaderboards, and badges. We additionally propose principles for constructing gamified tasks that have overlapping structure with useful downstream target tasks. We instantiate RoboCade on three manipulation tasks &ndash; including spatial arrangement, scanning, and insertion. To illustrate the viability of gamified robot data collection, we collect a demonstration dataset through our platform, and show that co-training robot policies with this data can improve success rate on non-gamified target tasks (+16-56%). Further, we conduct a user study to validate that novice users find the gamified platform significantly more enjoyable than a standard non-gamified platform (+24%). These results highlight the promise of gamified data collection as a scalable, accessible, and engaging method for collecting demonstration data.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21235v1">üìÑ Download PDF</a></p><hr><h3 id=proximal-survival-analysis-for-dependent-left-truncationhttpsarxivorgabs251221283v1><a href=https://arxiv.org/abs/2512.21283v1>Proximal Survival Analysis for Dependent Left Truncation</a><a hidden class=anchor aria-hidden=true href=#proximal-survival-analysis-for-dependent-left-truncationhttpsarxivorgabs251221283v1>#</a></h3><p><strong>Authors:</strong> Yuyao Wang, Andrew Ying, Ronghui Xu
<strong>Venue:</strong> arXiv (2025)</p><p>In prevalent cohort studies with delayed entry, time-to-event outcomes are often subject to left truncation where only subjects that have not experienced the event at study entry are included, leading to selection bias. Existing methods for handling left truncation mostly rely on the (quasi-)independence assumption or the weaker conditional (quasi-)independence assumption which assumes that conditional on observed covariates, the left truncation time and the event time are independent on the observed region. In practice, however, our analysis of the Honolulu Asia Aging Study (HAAS) suggests that the conditional quasi-independence assumption may fail because measured covariates often serve only as imperfect proxies for the underlying mechanisms, such as latent health status, that induce dependence between truncation and event times. To address this gap, we propose a proximal weighting identification framework that admits the dependence-inducing factors may not be fully observed. We then construct an estimator based on the framework and study its asymptotic properties. We examine the finite sample performance of the proposed estimator by comprehensive simulations, and apply it to analyzing the cognitive impairment-free survival probabilities using data from the Honolulu Asia Aging Study.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21283v1">üìÑ Download PDF</a></p><hr><h3 id=assessing-the-software-security-comprehension-of-large-language-modelshttpsarxivorgabs251221238v1><a href=https://arxiv.org/abs/2512.21238v1>Assessing the Software Security Comprehension of Large Language Models</a><a hidden class=anchor aria-hidden=true href=#assessing-the-software-security-comprehension-of-large-language-modelshttpsarxivorgabs251221238v1>#</a></h3><p><strong>Authors:</strong> Mohammed Latif Siddiq, Natalie Sekerak, Antonio Karam, Maria Leal, Arvin Islam-Gomes, Joanna C. S. Santos
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) are increasingly used in software development, but their level of software security expertise remains unclear. This work systematically evaluates the security comprehension of five leading LLMs: GPT-4o-Mini, GPT-5-Mini, Gemini-2.5-Flash, Llama-3.1, and Qwen-2.5, using Blooms Taxonomy as a framework. We assess six cognitive dimensions: remembering, understanding, applying, analyzing, evaluating, and creating. Our methodology integrates diverse datasets, including curated multiple-choice questions, vulnerable code snippets (SALLM), course assessments from an Introduction to Software Security course, real-world case studies (XBOW), and project-based creation tasks from a Secure Software Engineering course. Results show that while LLMs perform well on lower-level cognitive tasks such as recalling facts and identifying known vulnerabilities, their performance degrades significantly on higher-order tasks that require reasoning, architectural evaluation, and secure system creation. Beyond reporting aggregate accuracy, we introduce a software security knowledge boundary that identifies the highest cognitive level at which a model consistently maintains reliable performance. In addition, we identify 51 recurring misconception patterns exhibited by LLMs across Blooms levels.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21238v1">üìÑ Download PDF</a></p><hr><h3 id=active-inference-and-artificial-reasoninghttpsarxivorgabs251221129v1><a href=https://arxiv.org/abs/2512.21129v1>Active inference and artificial reasoning</a><a hidden class=anchor aria-hidden=true href=#active-inference-and-artificial-reasoninghttpsarxivorgabs251221129v1>#</a></h3><p><strong>Authors:</strong> Karl Friston, Lancelot Da Costa, Alexander Tschantz, Conor Heins, Christopher Buckley, Tim Verbelen, Thomas Parr
<strong>Venue:</strong> arXiv (2025)</p><p>This technical note considers the sampling of outcomes that provide the greatest amount of information about the structure of underlying world models. This generalisation furnishes a principled approach to structure learning under a plausible set of generative models or hypotheses. In active inference, policies - i.e., combinations of actions - are selected based on their expected free energy, which comprises expected information gain and value. Information gain corresponds to the KL divergence between predictive posteriors with, and without, the consequences of action. Posteriors over models can be evaluated quickly and efficiently using Bayesian Model Reduction, based upon accumulated posterior beliefs about model parameters. The ensuing information gain can then be used to select actions that disambiguate among alternative models, in the spirit of optimal experimental design. We illustrate this kind of active selection or reasoning using partially observed discrete models; namely, a &rsquo;three-ball&rsquo; paradigm used previously to describe artificial insight and &lsquo;aha moments&rsquo; via (synthetic) introspection or sleep. We focus on the sample efficiency afforded by seeking outcomes that resolve the greatest uncertainty about the world model, under which outcomes are generated.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21129v1">üìÑ Download PDF</a></p><hr><h3 id=a-design-study-process-model-for-medical-visualizationhttpsarxivorgabs251221034v1><a href=https://arxiv.org/abs/2512.21034v1>A Design Study Process Model for Medical Visualization</a><a hidden class=anchor aria-hidden=true href=#a-design-study-process-model-for-medical-visualizationhttpsarxivorgabs251221034v1>#</a></h3><p><strong>Authors:</strong> Mengjie Fan, Liang Zhou
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce a design study process model for medical visualization based on the analysis of existing medical visualization and visual analysis works, and our own interdisciplinary research experience. With a literature review of related works covering various data types and applications, we identify features of medical visualization and visual analysis research and formulate our model thereafter. Compared to previous design study process models, our new model emphasizes: distinguishing between different stakeholders and target users before initiating specific designs, distinguishing design stages according to analytic logic or cognitive habits, and classifying task types as inferential or descriptive, and further hypothesis-based or hypothesis-free based on whether they involve multiple subgroups. In addition, our model refines previous models according to the characteristics of medical problems and provides referable guidance for each step. These improvements make the visualization design targeted, generalizable, and operational, which can adapt to the complexity and diversity of medical problems. We apply this model to guide the design of a visual analysis method and reanalyze three medical visualization-related works. These examples suggest that the new process model can provide a systematic theoretical framework and practical guidance for interdisciplinary medical visualization research. We give recommendations that future researchers can refer to, report on reflections on the model, and delineate it from existing models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21034v1">üìÑ Download PDF</a></p><hr><h3 id=aegisagent-an-autonomous-defense-agent-against-prompt-injection-attacks-in-llm-harshttpsarxivorgabs251220986v1><a href=https://arxiv.org/abs/2512.20986v1>AegisAgent: An Autonomous Defense Agent Against Prompt Injection Attacks in LLM-HARs</a><a hidden class=anchor aria-hidden=true href=#aegisagent-an-autonomous-defense-agent-against-prompt-injection-attacks-in-llm-harshttpsarxivorgabs251220986v1>#</a></h3><p><strong>Authors:</strong> Yihan Wang, Huanqi Yang, Shantanu Pal, Weitao Xu
<strong>Venue:</strong> arXiv (2025)</p><p>The integration of Large Language Models (LLMs) into wearable sensing is creating a new class of mobile applications capable of nuanced human activity understanding. However, the reliability of these systems is critically undermined by their vulnerability to prompt injection attacks, where attackers deliberately input deceptive instructions into LLMs. Traditional defenses, based on static filters and rigid rules, are insufficient to address the semantic complexity of these new attacks. We argue that a paradigm shift is needed &ndash; from passive filtering to active protection and autonomous reasoning. We introduce AegisAgent, an autonomous agent system designed to ensure the security of LLM-driven HAR systems. Instead of merely blocking threats, AegisAgent functions as a cognitive guardian. It autonomously perceives potential semantic inconsistencies, reasons about the user&rsquo;s true intent by consulting a dynamic memory of past interactions, and acts by generating and executing a multi-step verification and repair plan. We implement AegisAgent as a lightweight, full-stack prototype and conduct a systematic evaluation on 15 common attacks with five state-of-the-art LLM-based HAR systems on three public datasets. Results show it reduces attack success rate by 30% on average while incurring only 78.6 ms of latency overhead on a GPU workstation. Our work makes the first step towards building secure and trustworthy LLM-driven HAR systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20986v1">üìÑ Download PDF</a></p><hr><h3 id=information-backed-currency-ibc-designing-a-resilient-transparent-and-information-centric-monetary-ecosystemhttpsarxivorgabs251220961v1><a href=https://arxiv.org/abs/2512.20961v1>Information-Backed Currency (IBC): Designing a Resilient, Transparent, and Information-Centric Monetary Ecosystem</a><a hidden class=anchor aria-hidden=true href=#information-backed-currency-ibc-designing-a-resilient-transparent-and-information-centric-monetary-ecosystemhttpsarxivorgabs251220961v1>#</a></h3><p><strong>Authors:</strong> Lalit Kumar Shukla
<strong>Venue:</strong> arXiv (2025)</p><p>The accelerating digitization of economic activity has made information a dominant driver of market expectations, coordination, and systemic risk. Yet contemporary monetary systems remain anchored in architectures designed for material scarcity, institutional authority, or cryptographic constraint, leaving them increasingly misaligned with information-driven economies. This conceptual paper proposes Information-Backed Currency (IBC) as a monetary framework in which verified, high-integrity information functions as the primary source of value creation and monetary stability.
Drawing on insights from econophysics, information theory, and cognitive economics, the paper advances the proposition that economic value emerges when information measurably reduces uncertainty within complex systems. Building on this premise, the study develops an architectural model in which currency issuance is linked to quantified entropy reduction achieved through multi-path information verification, reproducibility assessment, and contextual validation. An ethical governance layer, termed the Dharma Protocol, is introduced to ensure that only socially stabilizing, non-manipulative information qualifies as currency-backing input.
The proposed IBC architecture comprises four interdependent layers: information ingestion, verification and validation, ethical oversight, and monetization through a Verification Value Unit tied to uncertainty reduction. While the framework is intentionally conceptual and non-empirical, it offers a coherent blueprint for re-imagining monetary governance in an era characterized by information abundance, cognitive constraints, and systemic fragility.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20961v1">üìÑ Download PDF</a></p><hr><h3 id=enhancing-grid-resilience-for-giga-watt-scale-data-centers-using-high-voltage-circuit-breaker-operated-braking-resistorshttpsarxivorgabs251221295v1><a href=https://arxiv.org/abs/2512.21295v1>Enhancing Grid Resilience for Giga-Watt Scale Data Centers Using High Voltage Circuit Breaker Operated Braking Resistors</a><a hidden class=anchor aria-hidden=true href=#enhancing-grid-resilience-for-giga-watt-scale-data-centers-using-high-voltage-circuit-breaker-operated-braking-resistorshttpsarxivorgabs251221295v1>#</a></h3><p><strong>Authors:</strong> Soham Ghosh, Mohammad Ashraf Hossain Sadi
<strong>Venue:</strong> arXiv (2025)</p><p>As hyperscale and co-located data centers scale, the electric grid sees an increase in large, voltage-sensitive IT loads with these data center plant size ranging between 500 MW to 2 GW. A sudden loss of these loads as they switch to onsite UPS during grid voltage excursion events causes a grid frequency rise from generation and load imbalance, and a voltage rise because less power is flowing through the network. This paper proposes and theoretically demonstrates the use of high voltage circuit breaker operated braking resistors at data center transmission substations as an effective strategy in enhancing grid resilience under such large load loss scenarios. We developed a test bed to illustrate the dynamic behavior of the system with resistive braking on a gigawatt scale data center load cluster connected to a 345 kV network. The braking resistor(s), which in the case of inverter rich system comes in a multi-stage configuration, are connected or disconnected via high-speed circuit breaker(s). Results show that insertion for 0.25 to 0.85 seconds sufficiently reduce rate of change of frequency and provides time for primary governor response and capacitor switching to restore steady state. Sensitivity across different synchronous machines and inverter-based resource mix are tested and confirms robustness. We conclude circuit breaker controlled resistive braking is a practical means to enhance Bulk Electric System (BES) resilience for gigawatt scale data centers. The approach integrates with protection, needs no generator changes, and can be scaled with cluster size or growth of the data center facility load.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21295v1">üìÑ Download PDF</a></p><hr><h3 id=wireless-center-of-pressure-feedback-system-for-humanoid-robot-balance-control-using-esp32-c3httpsarxivorgabs251221219v1><a href=https://arxiv.org/abs/2512.21219v1>Wireless Center of Pressure Feedback System for Humanoid Robot Balance Control using ESP32-C3</a><a hidden class=anchor aria-hidden=true href=#wireless-center-of-pressure-feedback-system-for-humanoid-robot-balance-control-using-esp32-c3httpsarxivorgabs251221219v1>#</a></h3><p><strong>Authors:</strong> Muhtadin, Faris Rafi Pramana, Dion Hayu Fandiantoro, Moh Ismarintan Zazuli, Atar Fuady Babgei
<strong>Venue:</strong> arXiv (2025)</p><p>Maintaining stability during the single-support phase is a fundamental challenge in humanoid robotics, particularly in dance robots that require complex maneuvers and high mechanical freedom. Traditional tethered sensor configurations often restrict joint movement and introduce mechanical noises. This study proposes a wireless embedded balance system designed to maintain stability on uneven surfaces. The system utilizes a custom-designed foot unit integrated with four load cells and an ESP32-C3 microcontroller to estimate the Center of Pressure (CoP) in real time. The CoP data were transmitted wirelessly to the main controller to minimize the wiring complexity of the 29-DoF VI-ROSE humanoid robot. A PID control strategy is implemented to adjust the torso, hip, and ankle roll joints based on CoP feedback. Experimental characterization demonstrated high sensor precision with an average measurement error of 14.8 g. Furthermore, the proposed control system achieved a 100% success rate in maintaining balance during single-leg lifting tasks at a 3-degree inclination with optimized PID parameters (Kp=0.10, Kd=0.005). These results validate the efficacy of wireless CoP feedback in enhancing the postural stability of humanoid robots, without compromising their mechanical flexibility.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21219v1">üìÑ Download PDF</a></p><hr><h3 id=all-optical-control-and-multiplexed-readout-of-multiple-superconducting-qubitshttpsarxivorgabs251221199v1><a href=https://arxiv.org/abs/2512.21199v1>All-optical control and multiplexed readout of multiple superconducting qubits</a><a hidden class=anchor aria-hidden=true href=#all-optical-control-and-multiplexed-readout-of-multiple-superconducting-qubitshttpsarxivorgabs251221199v1>#</a></h3><p><strong>Authors:</strong> Xiaoxuan Pan, Chuanlong Ma, Jia-Qi Wang, Zheng-Xu Zhu, Linze Li, Jiajun Chen, Yuan-Hao Yang, Yilong Zhou, Jia-Hua Zou, Xin-Biao Xu, Weiting Wang, Baile Chen, Haifeng Yu, Chang-Ling Zou, Luyan Sun
<strong>Venue:</strong> arXiv (2025)</p><p>Superconducting quantum circuits operate at millikelvin temperatures, typically requiring independent microwave cables for each qubit for connecting room-temperature control and readout electronics. However, scaling to large-scale processors hosting hundreds of qubits faces a severe input/output (I/O) bottleneck, as the dense cable arrays impose prohibitive constraints on physical footprint, thermal load, wiring complexity, and cost. Here we demonstrate a complete optical I/O architecture for superconducting quantum circuits, in which all control and readout signals are transmitted exclusively via optical photons. Employing a broadband traveling-wave Brillouin microwave-to-optical transducer, we achieve simultaneous frequency-multiplexed optical readout of two qubits. Combined with fiber-integrated photodiode arrays for control signal delivery, this closed-loop optical I/O introduces no measurable degradation to qubit coherence times, with an optically driven single-qubit gate fidelity showing only a 0.19% reduction relative to standard microwave operation. These results establish optical interconnects as a viable path toward large-scale superconducting quantum processors, and open the possibility of networking multiple superconducting quantum computers housed in separate dilution refrigerators through a centralized room-temperature control infrastructure.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21199v1">üìÑ Download PDF</a></p><hr><h3 id=shared-representation-learning-for-high-dimensional-multi-task-forecasting-under-resource-contention-in-cloud-native-backendshttpsarxivorgabs251221102v1><a href=https://arxiv.org/abs/2512.21102v1>Shared Representation Learning for High-Dimensional Multi-Task Forecasting under Resource Contention in Cloud-Native Backends</a><a hidden class=anchor aria-hidden=true href=#shared-representation-learning-for-high-dimensional-multi-task-forecasting-under-resource-contention-in-cloud-native-backendshttpsarxivorgabs251221102v1>#</a></h3><p><strong>Authors:</strong> Zixiao Huang, Jixiao Yang, Sijia Li, Chi Zhang, Jinyu Chen, Chengda Xu
<strong>Venue:</strong> arXiv (2025)</p><p>This study proposes a unified forecasting framework for high-dimensional multi-task time series to meet the prediction demands of cloud native backend systems operating under highly dynamic loads, coupled metrics, and parallel tasks. The method builds a shared encoding structure to represent diverse monitoring indicators in a unified manner and employs a state fusion mechanism to capture trend changes and local disturbances across different time scales. A cross-task structural propagation module is introduced to model potential dependencies among nodes, enabling the model to understand complex structural patterns formed by resource contention, link interactions, and changes in service topology. To enhance adaptability to non-stationary behaviors, the framework incorporates a dynamic adjustment mechanism that automatically regulates internal feature flows according to system state changes, ensuring stable predictions in the presence of sudden load shifts, topology drift, and resource jitter. The experimental evaluation compares multiple models across various metrics and verifies the effectiveness of the framework through analyses of hyperparameter sensitivity, environmental sensitivity, and data sensitivity. The results show that the proposed method achieves superior performance on several error metrics and provides more accurate representations of future states under different operating conditions. Overall, the unified forecasting framework offers reliable predictive capability for high-dimensional, multi-task, and strongly dynamic environments in cloud native systems and provides essential technical support for intelligent backend management.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21102v1">üìÑ Download PDF</a></p><hr><h2 id=-llm>üîç llm<a hidden class=anchor aria-hidden=true href=#-llm>#</a></h2><h3 id=optimizing-quantum-state-transformation-under-locality-constrainthttpsarxivorgabs251221310v1><a href=https://arxiv.org/abs/2512.21310v1>Optimizing Quantum State Transformation Under Locality Constraint</a><a hidden class=anchor aria-hidden=true href=#optimizing-quantum-state-transformation-under-locality-constrainthttpsarxivorgabs251221310v1>#</a></h3><p><strong>Authors:</strong> Sasan Sarbishegi, Maryam Sadat Mirkamali
<strong>Venue:</strong> arXiv (2025)</p><p>In this paper, we present a general numerical framework for both deterministic and probabilistic quantum state transformations, under locality constraints. For a given arbitrary bipartite initial state and a desired bipartite target state, we construct an optimized local quantum channel that transforms the initial state into the target state with high fidelity. To achieve this goal, local quantum channels are parametrized on a complex Stiefel manifold and optimized using gradient-based methods. We demonstrate that this approach significantly enhances entanglement distillation for weakly entangled states via two complementary strategies: optimized local state transformation and probabilistic local transformation. These results establish our method as a powerful and versatile tool for a broad class of quantum information processing tasks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21310v1">üìÑ Download PDF</a></p><hr><h3 id=observation-of-the-aharonov-bohm-effect-in-pilot-wave-hydrodynamicshttpsarxivorgabs251221263v1><a href=https://arxiv.org/abs/2512.21263v1>Observation of the Aharonov-Bohm Effect in Pilot-Wave Hydrodynamics</a><a hidden class=anchor aria-hidden=true href=#observation-of-the-aharonov-bohm-effect-in-pilot-wave-hydrodynamicshttpsarxivorgabs251221263v1>#</a></h3><p><strong>Authors:</strong> Georgi Gary Rozenman, Kyle I. McKee, Arnaud Lazarus, Valeri Frumkin, John W M Bush
<strong>Venue:</strong> arXiv (2025)</p><p>We report the results of an experimental study of an analog of the Aharonov-Bohm (AB) effect achieved with the hydrodynamic pilot-wave system. A walking droplet is confined to an annular cavity that encircles a shielded vortex, but lies outside its range of direct influence. While there is no vortex-induced flow in the immediate vicinity of the droplets, the vortex modifies the droplet&rsquo;s spatially extended pilot-wave field that guides its motion, producing a vortex-dependent bias in the droplet&rsquo;s orbital speed. High-speed tracking and delay-embedding reconstructions yield Wigner-like phase-space distributions for this hydrodynamic system that exhibits a rigid, flux-dependent translation, providing a force-free, gauge-like realization of an AB-type phase.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21263v1">üìÑ Download PDF</a></p><hr><h3 id=neural-network-assisted-ris-weight-optimization-for-spatial-nulling-in-distorted-reflector-antenna-systemshttpsarxivorgabs251221253v1><a href=https://arxiv.org/abs/2512.21253v1>Neural Network-Assisted RIS Weight Optimization for Spatial Nulling in Distorted Reflector Antenna Systems</a><a hidden class=anchor aria-hidden=true href=#neural-network-assisted-ris-weight-optimization-for-spatial-nulling-in-distorted-reflector-antenna-systemshttpsarxivorgabs251221253v1>#</a></h3><p><strong>Authors:</strong> Xinrui Li, R. Michael Buehrer
<strong>Venue:</strong> arXiv (2025)</p><p>Reconfigurable intelligent surfaces (RIS) have recently been proposed as an effective means for spatial interference suppression in large reflector antenna systems. Existing RIS weight optimization algorithms typically rely on accurate theoretical radiation models. However, in practice, distortions on the reflector antenna may cause mismatches between the theoretical and true antenna patterns, leading to degraded interference cancellation performance when these weights are directly applied. In this report, a residual learning network-assisted simulated annealing (ResNet-SA) framework is proposed to address this mismatch without requiring explicit knowledge of the distorted electric field. By learning the residual difference between the theoretical and true antenna gains, a neural network (NN) is embedded in a heuristic optimization algorithm to find the optimal weight vector. Simulation results demonstrate that the proposed approach achieves improved null depth in the true radiation pattern as compared with conventional methods that optimize weights based solely on the theoretical model, validating the effectiveness of the ResNet-SA algorithm for reflector antenna systems with approximate knowledge of the pattern.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21253v1">üìÑ Download PDF</a></p><hr><h3 id=scaling-laws-for-economic-productivity-experimental-evidence-in-llm-assisted-consulting-data-analyst-and-management-taskshttpsarxivorgabs251221316v1><a href=https://arxiv.org/abs/2512.21316v1>Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Consulting, Data Analyst, and Management Tasks</a><a hidden class=anchor aria-hidden=true href=#scaling-laws-for-economic-productivity-experimental-evidence-in-llm-assisted-consulting-data-analyst-and-management-taskshttpsarxivorgabs251221316v1>#</a></h3><p><strong>Authors:</strong> Ali Merali
<strong>Venue:</strong> arXiv (2025)</p><p>This paper derives `Scaling Laws for Economic Impacts&rsquo; &ndash; empirical relationships between the training compute of Large Language Models (LLMs) and professional productivity. In a preregistered experiment, over 500 consultants, data analysts, and managers completed professional tasks using one of 13 LLMs. We find that each year of AI model progress reduced task time by 8%, with 56% of gains driven by increased compute and 44% by algorithmic progress. However, productivity gains were significantly larger for non-agentic analytical tasks compared to agentic workflows requiring tool use. These findings suggest continued model scaling could boost U.S. productivity by approximately 20% over the next decade.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21316v1">üìÑ Download PDF</a></p><hr><h2 id=-neuroscience>üîç neuroscience<a hidden class=anchor aria-hidden=true href=#-neuroscience>#</a></h2><h3 id=androidlens-long-latency-evaluation-with-nested-sub-targets-for-android-gui-agentshttpsarxivorgabs251221302v1><a href=https://arxiv.org/abs/2512.21302v1>AndroidLens: Long-latency Evaluation with Nested Sub-targets for Android GUI Agents</a><a hidden class=anchor aria-hidden=true href=#androidlens-long-latency-evaluation-with-nested-sub-targets-for-android-gui-agentshttpsarxivorgabs251221302v1>#</a></h3><p><strong>Authors:</strong> Yue Cao, Yingyao Wang, Pi Bu, Jingxuan Xing, Wei Jiang, Zekun Zhu, Junpeng Ma, Sashuai Zhou, Tong Lu, Jun Song, Yu Cheng, Yuning Jiang, Bo Zheng
<strong>Venue:</strong> arXiv (2025)</p><p>Graphical user interface (GUI) agents can substantially improve productivity by automating frequently executed long-latency tasks on mobile devices. However, existing evaluation benchmarks are still constrained to limited applications, simple tasks, and coarse-grained metrics. To address this, we introduce AndroidLens, a challenging evaluation framework for mobile GUI agents, comprising 571 long-latency tasks in both Chinese and English environments, each requiring an average of more than 26 steps to complete. The framework features: (1) tasks derived from real-world user scenarios across 38 domains, covering complex types such as multi-constraint, multi-goal, and domain-specific tasks; (2) static evaluation that preserves real-world anomalies and allows multiple valid paths to reduce bias; and (3) dynamic evaluation that employs a milestone-based scheme for fine-grained progress measurement via Average Task Progress (ATP). Our evaluation indicates that even the best models reach only a 12.7% task success rate and 50.47% ATP. We also underscore key challenges in real-world environments, including environmental anomalies, adaptive exploration, and long-term memory retention.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21302v1">üìÑ Download PDF</a></p><hr><h3 id=quadrupped-legged-robot-movement-plan-generation-using-large-language-modelhttpsarxivorgabs251221293v1><a href=https://arxiv.org/abs/2512.21293v1>Quadrupped-Legged Robot Movement Plan Generation using Large Language Model</a><a hidden class=anchor aria-hidden=true href=#quadrupped-legged-robot-movement-plan-generation-using-large-language-modelhttpsarxivorgabs251221293v1>#</a></h3><p><strong>Authors:</strong> Muhtadin, Vincentius Gusti Putu A. B. M., Ahmad Zaini, Mauridhi Hery Purnomo, I Ketut Eddy Purnama, Chastine Fatichah
<strong>Venue:</strong> arXiv (2025)</p><p>Traditional control interfaces for quadruped robots often impose a high barrier to entry, requiring specialized technical knowledge for effective operation. To address this, this paper presents a novel control framework that integrates Large Language Models (LLMs) to enable intuitive, natural language-based navigation. We propose a distributed architecture where high-level instruction processing is offloaded to an external server to overcome the onboard computational constraints of the DeepRobotics Jueying Lite 3 platform. The system grounds LLM-generated plans into executable ROS navigation commands using real-time sensor fusion (LiDAR, IMU, and Odometry). Experimental validation was conducted in a structured indoor environment across four distinct scenarios, ranging from single-room tasks to complex cross-zone navigation. The results demonstrate the system&rsquo;s robustness, achieving an aggregate success rate of over 90% across all scenarios, validating the feasibility of offloaded LLM-based planning for autonomous quadruped deployment in real-world settings.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21293v1">üìÑ Download PDF</a></p><hr><h3 id=navier-stokes-cahn-hilliard-system-in-a-3d-perforated-domain-with-free-slip-and-source-term-existence-and-homogenizationhttpsarxivorgabs251221171v1><a href=https://arxiv.org/abs/2512.21171v1>Navier-Stokes-Cahn-Hilliard system in a $3$D perforated domain with free slip and source term: Existence and homogenization</a><a hidden class=anchor aria-hidden=true href=#navier-stokes-cahn-hilliard-system-in-a-3d-perforated-domain-with-free-slip-and-source-term-existence-and-homogenizationhttpsarxivorgabs251221171v1>#</a></h3><p><strong>Authors:</strong> Amartya Chakrabortty, Haradhan Dutta, Hari Shankar Mahato
<strong>Venue:</strong> arXiv (2025)</p><p>We study a diffuse-interface model for a binary incompressible mixture in a periodically perforated porous medium, described by a time-dependent Navier-Stokes-Cahn-Hilliard (NSCH) system posed on the pore domain $Œ©_p^\varepsilon\subset\mathbb{R}^3$. The microscopic model involves a variable viscosity tensor, a non-conservative source term in the Cahn&ndash;Hilliard equation, and mixed boundary conditions: no-slip on the outer boundary and Navier slip with zero tangential stress on the surfaces of the solid inclusions. The capillarity strength $Œª^\varepsilon>0$ depends on the microscopic scale $\varepsilon>0$.
The analysis consists of two main parts. First, for each fixed $\varepsilon>0$, we prove the existence of a weak solution on a finite time interval $(0,T)$ and derive a priori estimates that are uniform with respect to $\varepsilon$ (and $Œª^\varepsilon$). Second, we perform the periodic homogenization for the perforated setting, a limit $\varepsilon\to0$. Depending on the limit value $Œª$ of the capillarity strength $Œª^\varepsilon$, we obtain two distinct effective models: (i) in the vanishing capillarity regime $Œª=0$, the limit system is of Stokes-Cahn-Hilliard type, with no macroscopic convection or advection; (ii) in the balanced regime $Œª\in(0,+\infty)$, we derive a Navier-Stokes-Cahn-Hilliard system with nonlinear convection and advective transport of the phase field at the macroscopic scale. Finally, we establish the convergence of the microscopic free energy to a homogenized energy functional satisfying an analogous dissipation law.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21171v1">üìÑ Download PDF</a></p><hr><h3 id=topological-interface-states-and-nonlinear-thermoelectric-performance-in-armchair-graphene-nanoribbon-heterostructureshttpsarxivorgabs251221121v1><a href=https://arxiv.org/abs/2512.21121v1>Topological Interface States and Nonlinear Thermoelectric Performance in Armchair Graphene Nanoribbon Heterostructures</a><a hidden class=anchor aria-hidden=true href=#topological-interface-states-and-nonlinear-thermoelectric-performance-in-armchair-graphene-nanoribbon-heterostructureshttpsarxivorgabs251221121v1>#</a></h3><p><strong>Authors:</strong> David M T Kuo
<strong>Venue:</strong> arXiv (2025)</p><p>We investigate the emergence and topological nature of interface states (IFs) in N-AGNR/$(N-2)$-AGNR/N-AGNR heterostructure (AGNRH) segments lacking translational symmetry, focusing on their relation to the end states (ESs) of the constituent armchair graphene nanoribbon (AGNR) segments. For AGNRs with $R_1$-type unit cells, the ES numbers under a longitudinal electric field follow the relations $N = N_{A(B)} \times 6 + 1$ and $N = N_{A(B)} \times 6 + 3$, whereas $R_2$-type unit cells exhibit $(N_{A(B)} + 1)$ ESs. The subscripts $A$ and $B$ denote the chirality types of the ESs. The Stark effect lifts ES degeneracy and enables clear spectral separation between ESs and IFs. Using a real-space bulk boundary perturbation approach, we show that opposite-chirality states hybridize through junction-site perturbations and may shift out of the bulk gap. The number and chirality of IFs in symmetric AGNRHs are determined by the difference between the ESs of the outer and central segments, $N_O$ and $N_C$, according to $N_{IF,Œ≤} = |N_{O,B(A)} - N_{C,A(B)}|$, where $Œ≤$ labels the chirality. Depending on whether $N_O > N_C$ or $N_C > N_O$, the resulting IFs acquire B- or A-chirality, respectively. Calculated transmission spectra ${\cal T}_{GNR}(\varepsilon)$ reveal that AGNRHs host a topological double quantum dot (TDQD) when IFs originate from the ESs of the central AGNR segment. Using an Anderson model with effective intra-dot and inter-dot Coulomb interactions, we derive an analytical expression for the tunneling current through the TDQD via a closed-form transmission coefficient. Thermoelectric analysis shows that TDQDs yield enhanced nonlinear power output in the electron-dilute and hole-dilute charge states, with Coulomb blockade suppressing thermal current but not thermal voltage.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21121v1">üìÑ Download PDF</a></p><hr><h2 id=-data_resources>üîç data_resources<a hidden class=anchor aria-hidden=true href=#-data_resources>#</a></h2><h3 id=surgical-scene-segmentation-using-a-spike-driven-video-transformer-with-real-time-potentialhttpsarxivorgabs251221284v1><a href=https://arxiv.org/abs/2512.21284v1>Surgical Scene Segmentation using a Spike-Driven Video Transformer with Real-Time Potential</a><a hidden class=anchor aria-hidden=true href=#surgical-scene-segmentation-using-a-spike-driven-video-transformer-with-real-time-potentialhttpsarxivorgabs251221284v1>#</a></h3><p><strong>Authors:</strong> Shihao Zou, Jingjing Li, Wei Ji, Jincai Huang, Kai Wang, Guo Dan, Weixin Si, Yi Pan
<strong>Venue:</strong> arXiv (2025)</p><p>Modern surgical systems increasingly rely on intelligent scene understanding to provide timely situational awareness for enhanced intra-operative safety. Within this pipeline, surgical scene segmentation plays a central role in accurately perceiving operative events. Although recent deep learning models, particularly large-scale foundation models, achieve remarkable segmentation accuracy, their substantial computational demands and power consumption hinder real-time deployment in resource-constrained surgical environments. To address this limitation, we explore the emerging SNN as a promising paradigm for highly efficient surgical intelligence. However, their performance is still constrained by the scarcity of labeled surgical data and the inherently sparse nature of surgical video representations. To this end, we propose \textit{SpikeSurgSeg}, the first spike-driven video Transformer framework tailored for surgical scene segmentation with real-time potential on non-GPU platforms. To address the limited availability of surgical annotations, we introduce a surgical-scene masked autoencoding pretraining strategy for SNNs that enables robust spatiotemporal representation learning via layer-wise tube masking. Building on this pretrained backbone, we further adopt a lightweight spike-driven segmentation head that produces temporally consistent predictions while preserving the low-latency characteristics of SNNs. Extensive experiments on EndoVis18 and our in-house SurgBleed dataset demonstrate that SpikeSurgSeg achieves mIoU comparable to SOTA ANN-based models while reducing inference latency by at least $8\times$. Notably, it delivers over $20\times$ acceleration relative to most foundation-model baselines, underscoring its potential for time-critical surgical scene segmentation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21284v1">üìÑ Download PDF</a></p><hr><h3 id=marineeval-assessing-the-marine-intelligence-of-vision-language-modelshttpsarxivorgabs251221126v1><a href=https://arxiv.org/abs/2512.21126v1>MarineEval: Assessing the Marine Intelligence of Vision-Language Models</a><a hidden class=anchor aria-hidden=true href=#marineeval-assessing-the-marine-intelligence-of-vision-language-modelshttpsarxivorgabs251221126v1>#</a></h3><p><strong>Authors:</strong> YuK-Kwan Wong, Tuan-An To, Jipeng Zhang, Ziqiang Zheng, Sai-Kit Yeung
<strong>Venue:</strong> arXiv (2025)</p><p>We have witnessed promising progress led by large language models (LLMs) and further vision language models (VLMs) in handling various queries as a general-purpose assistant. VLMs, as a bridge to connect the visual world and language corpus, receive both visual content and various text-only user instructions to generate corresponding responses. Though great success has been achieved by VLMs in various fields, in this work, we ask whether the existing VLMs can act as domain experts, accurately answering marine questions, which require significant domain expertise and address special domain challenges/requirements. To comprehensively evaluate the effectiveness and explore the boundary of existing VLMs, we construct the first large-scale marine VLM dataset and benchmark called MarineEval, with 2,000 image-based question-answering pairs. During our dataset construction, we ensure the diversity and coverage of the constructed data: 7 task dimensions and 20 capacity dimensions. The domain requirements are specially integrated into the data construction and further verified by the corresponding marine domain experts. We comprehensively benchmark 17 existing VLMs on our MarineEval and also investigate the limitations of existing models in answering marine research questions. The experimental results reveal that existing VLMs cannot effectively answer the domain-specific questions, and there is still a large room for further performance improvements. We hope our new benchmark and observations will facilitate future research. Project Page: <a href=http://marineeval.hkustvgd.com/>http://marineeval.hkustvgd.com/</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21126v1">üìÑ Download PDF</a></p><hr><h3 id=beyond-pixel-simulation-pathology-image-generation-via-diagnostic-semantic-tokens-and-prototype-controlhttpsarxivorgabs251221058v1><a href=https://arxiv.org/abs/2512.21058v1>Beyond Pixel Simulation: Pathology Image Generation via Diagnostic Semantic Tokens and Prototype Control</a><a hidden class=anchor aria-hidden=true href=#beyond-pixel-simulation-pathology-image-generation-via-diagnostic-semantic-tokens-and-prototype-controlhttpsarxivorgabs251221058v1>#</a></h3><p><strong>Authors:</strong> Minghao Han, YiChen Liu, Yizhou Liu, Zizhi Chen, Jingqun Tang, Xuecheng Wu, Dingkang Yang, Lihua Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>In computational pathology, understanding and generation have evolved along disparate paths: advanced understanding models already exhibit diagnostic-level competence, whereas generative models largely simulate pixels. Progress remains hindered by three coupled factors: the scarcity of large, high-quality image-text corpora; the lack of precise, fine-grained semantic control, which forces reliance on non-semantic cues; and terminological heterogeneity, where diverse phrasings for the same diagnostic concept impede reliable text conditioning. We introduce UniPath, a semantics-driven pathology image generation framework that leverages mature diagnostic understanding to enable controllable generation. UniPath implements Multi-Stream Control: a Raw-Text stream; a High-Level Semantics stream that uses learnable queries to a frozen pathology MLLM to distill paraphrase-robust Diagnostic Semantic Tokens and to expand prompts into diagnosis-aware attribute bundles; and a Prototype stream that affords component-level morphological control via a prototype bank. On the data front, we curate a 2.65M image-text corpus and a finely annotated, high-quality 68K subset to alleviate data scarcity. For a comprehensive assessment, we establish a four-tier evaluation hierarchy tailored to pathology. Extensive experiments demonstrate UniPath&rsquo;s SOTA performance, including a Patho-FID of 80.9 (51% better than the second-best) and fine-grained semantic control achieving 98.7% of the real-image. The meticulously curated datasets, complete source code, and pre-trained model weights developed in this study will be made openly accessible to the public.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21058v1">üìÑ Download PDF</a></p><hr><h3 id=learning-the-macroeconomic-languagehttpsarxivorgabs251221031v1><a href=https://arxiv.org/abs/2512.21031v1>Learning the Macroeconomic Language</a><a hidden class=anchor aria-hidden=true href=#learning-the-macroeconomic-languagehttpsarxivorgabs251221031v1>#</a></h3><p><strong>Authors:</strong> Siddhartha Chib, Fei Tan
<strong>Venue:</strong> arXiv (2025)</p><p>We show how state-of-the-art large language models (LLMs), seemingly inapplicable to the small samples typical of macroeconomics, can be trained to learn the language of macroeconomy. We estimate a large-scale dynamic stochastic general equilibrium (DSGE) model on an initial segment of the data and obtain a posterior distribution over structural parameters. We sample from this posterior to generate millions of theory-consistent synthetic panels that, when mixed with actual macroeconomic data, form the training corpus for a time-series transformer with attention. The trained model is then used to forecast out-of-sample through 2025. The results show that this hybrid forecaster, which combines the theoretical coherence of DSGE models with the representational power of modern LLMs, successfully learns the macroeconomic language.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21031v1">üìÑ Download PDF</a></p><hr><h3 id=latent-implicit-visual-reasoninghttpsarxivorgabs251221218v1><a href=https://arxiv.org/abs/2512.21218v1>Latent Implicit Visual Reasoning</a><a hidden class=anchor aria-hidden=true href=#latent-implicit-visual-reasoninghttpsarxivorgabs251221218v1>#</a></h3><p><strong>Authors:</strong> Kelvin Li, Chuyi Shang, Leonid Karlinsky, Rogerio Feris, Trevor Darrell, Roei Herzig
<strong>Venue:</strong> arXiv (2025)</p><p>While Large Multimodal Models (LMMs) have made significant progress, they remain largely text-centric, relying on language as their core reasoning modality. As a result, they are limited in their ability to handle reasoning tasks that are predominantly visual. Recent approaches have sought to address this by supervising intermediate visual steps with helper images, depth maps, or image crops. However, these strategies impose restrictive priors on what &ldquo;useful&rdquo; visual abstractions look like, add heavy annotation costs, and struggle to generalize across tasks. To address this critical limitation, we propose a task-agnostic mechanism that trains LMMs to discover and use visual reasoning tokens without explicit supervision. These tokens attend globally and re-encode the image in a task-adaptive way, enabling the model to extract relevant visual information without hand-crafted supervision. Our approach outperforms direct fine-tuning and achieves state-of-the-art results on a diverse range of vision-centric tasks &ndash; including those where intermediate abstractions are hard to specify &ndash; while also generalizing to multi-task instruction tuning.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21218v1">üìÑ Download PDF</a></p><hr><h3 id=architectural-trade-offs-in-small-language-models-under-compute-constraintshttpsarxivorgabs251220877v1><a href=https://arxiv.org/abs/2512.20877v1>Architectural Trade-offs in Small Language Models Under Compute Constraints</a><a hidden class=anchor aria-hidden=true href=#architectural-trade-offs-in-small-language-models-under-compute-constraintshttpsarxivorgabs251220877v1>#</a></h3><p><strong>Authors:</strong> Shivraj Singh Bhatti
<strong>Venue:</strong> arXiv (2025)</p><p>We present a systematic empirical study of small language models under strict compute constraints, analyzing how architectural choices and training budget interact to determine performance. Starting from a linear next-token predictor, we progressively introduce nonlinearities, self-attention, and multi-layer transformer architectures, evaluating each on character-level modeling of Tiny Shakespeare and word-level modeling of Penn Treebank (PTB) and WikiText-2. We compare models using test negative log-likelihood (NLL), parameter count, and approximate training FLOPs to characterize accuracy-efficiency trade-offs. Our results show that attention-based models dominate MLPs in per-FLOP efficiency even at small scale, while increasing depth or context without sufficient optimization can degrade performance. We further examine rotary positional embeddings (RoPE), finding that architectural techniques successful in large language models do not necessarily transfer to small-model regimes.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20877v1">üìÑ Download PDF</a></p><hr><h2 id=-emotion_language>üîç emotion_language<a hidden class=anchor aria-hidden=true href=#-emotion_language>#</a></h2><h3 id=pluricanonical-geometry-of-varieties-isogenous-to-a-product-chevalley-weil-theory-and-pluricanonical-decompositions-of-abelian-covershttpsarxivorgabs251221294v1><a href=https://arxiv.org/abs/2512.21294v1>Pluricanonical Geometry of Varieties Isogenous to a Product: Chevalley-Weil Theory and Pluricanonical Decompositions of Abelian Covers</a><a hidden class=anchor aria-hidden=true href=#pluricanonical-geometry-of-varieties-isogenous-to-a-product-chevalley-weil-theory-and-pluricanonical-decompositions-of-abelian-covershttpsarxivorgabs251221294v1>#</a></h3><p><strong>Authors:</strong> Massimiliano Alessandro, Davide Frapporti, Christian Gleissner
<strong>Venue:</strong> arXiv (2025)</p><p>We study canonical and pluricanonical maps of varieties isogenous to a product of curves, i.e., quotients of the form $ X = (C_1 \times \dots \times C_n)/G $ with $g(C_i)\ge 2$ and $G$ acting freely. We establish the Chevalley-Weil formula for pluricanonical representations of a curve with a finite group action and a decomposition theorem for pluricanonical systems of abelian covers. These tools allow an explicit study of geometric properties of $X$, such as base loci and the birationality of pluricanonical maps. For threefolds isogenous to a product, we prove that the 4-canonical map is birational for $p_g \ge 5$ and construct an example attaining the maximal canonical degree for this class of threefolds. In this example, the canonical map is the normalization of its image, which admits isolated non-normal singularities. Computational classifications also reveal threefolds where the bicanonical map fails to be birational, even in the absence of genus-2 fibrations. This illustrates an interesting phenomenon similar to the non-standard case for surfaces.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21294v1">üìÑ Download PDF</a></p><hr><h3 id=multivariate-scaling-of-proton-and-ion-energies-divergence-and-charge-states-in-target-normal-sheath-accelerationhttpsarxivorgabs251221279v1><a href=https://arxiv.org/abs/2512.21279v1>Multivariate scaling of proton and ion energies, divergence, and charge states in Target Normal Sheath Acceleration</a><a hidden class=anchor aria-hidden=true href=#multivariate-scaling-of-proton-and-ion-energies-divergence-and-charge-states-in-target-normal-sheath-accelerationhttpsarxivorgabs251221279v1>#</a></h3><p><strong>Authors:</strong> Vasiliki E. Alexopoulou
<strong>Venue:</strong> arXiv (2025)</p><p>The interaction of an intense laser pulse with a solid target produces energetic proton and ion beams through the Target Normal Sheath Acceleration (TNSA) mechanism. Such beams are under active investigation for applications in proton beam therapy, materials modification, and nuclear and high-energy-density physics. Despite extensive experimental and theoretical effort, predictive correlations between laser and target parameters and the resulting ion-beam properties remain an open research question, owing to the intrinsically multiphysics and strongly coupled nature of laser-plasma interactions. Here, we employ our unified multiphysics model that reproduces laser-solid interaction dynamics with accuracy exceeding 95% over a broad range of short- and ultrashort-pulse conditions. Using this model, we derive statistically validated scaling laws and probability maps that correlate proton, carbon, and oxygen ion cutoff energies, beam divergences, and ionization states to a wide set of laser and target parameters, including pulse duration, laser power, laser beam spot, target thickness, prepulse-main pulse interval, contrast, laser wavelength, and polarization. Continuous beam properties (cutoff energies and beam divergences) are described using multivariate regression with cross-validation, while discrete ionization states are analyzed using classification and regression tree (CART) methods, enabling nonlinear and threshold-dependent behavior to be captured. The resulting scaling relations, contour maps, and box plots elucidate the coupled roles of laser pulse, and target geometry in governing TNSA ion acceleration and charge-state formation. These results provide a predictive and physically interpretable framework for understanding and optimizing laser-driven ion sources across a wide parameter space.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21279v1">üìÑ Download PDF</a></p><hr><h3 id=a-unified-framework-for-eeg-seizure-detection-using-universum-integrated-generalized-eigenvalues-proximal-support-vector-machinehttpsarxivorgabs251221170v1><a href=https://arxiv.org/abs/2512.21170v1>A Unified Framework for EEG Seizure Detection Using Universum-Integrated Generalized Eigenvalues Proximal Support Vector Machine</a><a hidden class=anchor aria-hidden=true href=#a-unified-framework-for-eeg-seizure-detection-using-universum-integrated-generalized-eigenvalues-proximal-support-vector-machinehttpsarxivorgabs251221170v1>#</a></h3><p><strong>Authors:</strong> Yogesh Kumar, Vrushank Ahire, M. A. Ganaie
<strong>Venue:</strong> arXiv (2025)</p><p>The paper presents novel Universum-enhanced classifiers: the Universum Generalized Eigenvalue Proximal Support Vector Machine (U-GEPSVM) and the Improved U-GEPSVM (IU-GEPSVM) for EEG signal classification. Using the computational efficiency of generalized eigenvalue decomposition and the generalization benefits of Universum learning, the proposed models address critical challenges in EEG analysis: non-stationarity, low signal-to-noise ratio, and limited labeled data. U-GEPSVM extends the GEPSVM framework by incorporating Universum constraints through a ratio-based objective function, while IU-GEPSVM enhances stability through a weighted difference-based formulation that provides independent control over class separation and Universum alignment. The models are evaluated on the Bonn University EEG dataset across two binary classification tasks: (O vs S)-healthy (eyes closed) vs seizure, and (Z vs S)-healthy (eyes open) vs seizure. IU-GEPSVM achieves peak accuracies of 85% (O vs S) and 80% (Z vs S), with mean accuracies of 81.29% and 77.57% respectively, outperforming baseline methods.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21170v1">üìÑ Download PDF</a></p><hr><h3 id=variationally-correct-operator-learning-reduced-basis-neural-operator-with-a-posteriori-error-estimationhttpsarxivorgabs251221319v1><a href=https://arxiv.org/abs/2512.21319v1>Variationally correct operator learning: Reduced basis neural operator with a posteriori error estimation</a><a hidden class=anchor aria-hidden=true href=#variationally-correct-operator-learning-reduced-basis-neural-operator-with-a-posteriori-error-estimationhttpsarxivorgabs251221319v1>#</a></h3><p><strong>Authors:</strong> Yuan Qiu, Wolfgang Dahmen, Peng Chen
<strong>Venue:</strong> arXiv (2025)</p><p>Minimizing PDE-residual losses is a common strategy to promote physical consistency in neural operators. However, standard formulations often lack variational correctness, meaning that small residuals do not guarantee small solution errors due to the use of non-compliant norms or ad hoc penalty terms for boundary conditions. This work develops a variationally correct operator learning framework by constructing first-order system least-squares (FOSLS) objectives whose values are provably equivalent to the solution error in PDE-induced norms. We demonstrate this framework on stationary diffusion and linear elasticity, incorporating mixed Dirichlet-Neumann boundary conditions via variational lifts to preserve norm equivalence without inconsistent penalties. To ensure the function space conformity required by the FOSLS loss, we propose a Reduced Basis Neural Operator (RBNO). The RBNO predicts coefficients for a pre-computed, conforming reduced basis, thereby ensuring variational stability by design while enabling efficient training. We provide a rigorous convergence analysis that bounds the total error by the sum of finite element discretization bias, reduced basis truncation error, neural network approximation error, and statistical estimation errors arising from finite sampling and optimization. Numerical benchmarks validate these theoretical bounds and demonstrate that the proposed approach achieves superior accuracy in PDE-compliant norms compared to standard baselines, while the residual loss serves as a reliable, computable a posteriori error estimator.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21319v1">üìÑ Download PDF</a></p><hr><h3 id=twist-tuned-strong-coupling-in-sub-ghz-wire-metasurface-bilayershttpsarxivorgabs251221277v1><a href=https://arxiv.org/abs/2512.21277v1>Twist-Tuned Strong Coupling in Sub-GHz Wire Metasurface Bilayers</a><a hidden class=anchor aria-hidden=true href=#twist-tuned-strong-coupling-in-sub-ghz-wire-metasurface-bilayershttpsarxivorgabs251221277v1>#</a></h3><p><strong>Authors:</strong> Ingrid Torres, Alex Krasnok
<strong>Venue:</strong> arXiv (2025)</p><p>Twist-angle control offers a bias-free route to reconfigurable metasurfaces, yet its extension to deeply subwavelength resonant platforms at VHF/UHF remains limited. We demonstrate a sub-GHz double-layer wire metasurface formed by two identical wire grids separated by a gap G, with in-plane rotation angle as the sole tuning parameter. One-port, loop-coupled S11 measurements supported by full-wave simulations reveal twist-driven hybridization of the dominant resonant manifold. For small G, the lower hybrid resonance redshifts continuously from 409 MHz to 210 MHz (2:1 tuning), enabling compact, twist-programmable resonant surfaces. Simulations further show that twisting imprints moire-like magnetic near-field super-modulations. From resonance frequencies, linewidths, and normal-mode splitting extracted from the complex response, we obtain normalized coupling up to g = 0.43 with cooperativity exceeding unity over broad angular ranges, meeting the resolved-splitting criterion. The rapid collapse of tunability at larger G confirms the near-field origin of the interaction.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21277v1">üìÑ Download PDF</a></p><hr><h3 id=post-processing-mask-based-table-segmentation-for-structural-coordinate-extractionhttpsarxivorgabs251221287v1><a href=https://arxiv.org/abs/2512.21287v1>Post-Processing Mask-Based Table Segmentation for Structural Coordinate Extraction</a><a hidden class=anchor aria-hidden=true href=#post-processing-mask-based-table-segmentation-for-structural-coordinate-extractionhttpsarxivorgabs251221287v1>#</a></h3><p><strong>Authors:</strong> Suren Bandara
<strong>Venue:</strong> arXiv (2025)</p><p>Structured data extraction from tables plays a crucial role in document image analysis for scanned documents and digital archives. Although many methods have been proposed to detect table structures and extract cell contents, accurately identifying table segment boundaries (rows and columns) remains challenging, particularly in low-resolution or noisy images. In many real-world scenarios, table data are incomplete or degraded, limiting the adaptability of transformer-based methods to noisy inputs. Mask-based edge detection techniques have shown greater robustness under such conditions, as their sensitivity can be adjusted through threshold tuning; however, existing approaches typically apply masks directly to images, leading to noise sensitivity, resolution loss, or high computational cost. This paper proposes a novel multi-scale signal-processing method for detecting table edges from table masks. Row and column transitions are modeled as one-dimensional signals and processed using Gaussian convolution with progressively increasing variances, followed by statistical thresholding to suppress noise while preserving stable structural edges. Detected signal peaks are mapped back to image coordinates to obtain accurate segment boundaries. Experimental results show that applying the proposed approach to column edge detection improves Cell-Aware Segmentation Accuracy (CASA) a layout-aware metric evaluating both textual correctness and correct cell placement from 67% to 76% on the PubLayNet-1M benchmark when using TableNet with PyTesseract OCR. The method is robust to resolution variations through zero-padding and scaling strategies and produces optimized structured tabular outputs suitable for downstream analysis.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21287v1">üìÑ Download PDF</a></p><hr><h3 id=industrial-ouroboros-deep-lateral-movement-via-living-off-the-planthttpsarxivorgabs251221248v1><a href=https://arxiv.org/abs/2512.21248v1>Industrial Ouroboros: Deep Lateral Movement via Living Off the Plant</a><a hidden class=anchor aria-hidden=true href=#industrial-ouroboros-deep-lateral-movement-via-living-off-the-planthttpsarxivorgabs251221248v1>#</a></h3><p><strong>Authors:</strong> Richard Derbyshire
<strong>Venue:</strong> arXiv (2025)</p><p>Lateral movement is a tactic that adversaries employ most frequently in enterprise IT environments to traverse between assets. In operational technology (OT) environments, however, few methods exist for lateral movement between domain-specific devices, particularly programmable logic controllers (PLCs). Existing techniques often rely on complex chains of vulnerabilities, which are noisy and can be patched. This paper describes the first PLC-centric lateral movement technique that relies exclusively on the native functionality of the victim environment. This OT-specific form of <code>living off the land' is herein distinguished as </code>living off the plant&rsquo; (LOTP). The described technique also facilitates escape from IP networks onto legacy serial networks via dual-homed PLCs. Furthermore, this technique is covert, leveraging common network communication functions that are challenging to detect. This serves as a reminder of the risks posed by LOTP techniques within OT, highlighting the need for a fundamental reconsideration of traditional OT defensive practices.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21248v1">üìÑ Download PDF</a></p><hr><h3 id=learning-to-solve-pdes-on-neural-shape-representationshttpsarxivorgabs251221311v1><a href=https://arxiv.org/abs/2512.21311v1>Learning to Solve PDEs on Neural Shape Representations</a><a hidden class=anchor aria-hidden=true href=#learning-to-solve-pdes-on-neural-shape-representationshttpsarxivorgabs251221311v1>#</a></h3><p><strong>Authors:</strong> Lilian Welschinger, Yilin Liu, Zican Wang, Niloy Mitra
<strong>Venue:</strong> arXiv (2025)</p><p>Solving partial differential equations (PDEs) on shapes underpins many shape analysis and engineering tasks; yet, prevailing PDE solvers operate on polygonal/triangle meshes while modern 3D assets increasingly live as neural representations. This mismatch leaves no suitable method to solve surface PDEs directly within the neural domain, forcing explicit mesh extraction or per-instance residual training, preventing end-to-end workflows. We present a novel, mesh-free formulation that learns a local update operator conditioned on neural (local) shape attributes, enabling surface PDEs to be solved directly where the (neural) data lives. The operator integrates naturally with prevalent neural surface representations, is trained once on a single representative shape, and generalizes across shape and topology variations, enabling accurate, fast inference without explicit meshing or per-instance optimization while preserving differentiability. Across analytic benchmarks (heat equation and Poisson solve on sphere) and real neural assets across different representations, our method slightly outperforms CPM while remaining reasonably close to FEM, and, to our knowledge, delivers the first end-to-end pipeline that solves surface PDEs on both neural and classical surface representations. Code will be released on acceptance.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21311v1">üìÑ Download PDF</a></p><hr><h3 id=a-community-enhanced-graph-representation-model-for-link-predictionhttpsarxivorgabs251221166v1><a href=https://arxiv.org/abs/2512.21166v1>A Community-Enhanced Graph Representation Model for Link Prediction</a><a hidden class=anchor aria-hidden=true href=#a-community-enhanced-graph-representation-model-for-link-predictionhttpsarxivorgabs251221166v1>#</a></h3><p><strong>Authors:</strong> Lei Wang, Darong Lai
<strong>Venue:</strong> arXiv (2025)</p><p>Although Graph Neural Networks (GNNs) have become the dominant approach for graph representation learning, their performance on link prediction tasks does not always surpass that of traditional heuristic methods such as Common Neighbors and Jaccard Coefficient. This is mainly because existing GNNs tend to focus on learning local node representations, making it difficult to effectively capture structural relationships between node pairs. Furthermore, excessive reliance on local neighborhood information can lead to over-smoothing. Prior studies have shown that introducing global structural encoding can partially alleviate this issue. To address these limitations, we propose a Community-Enhanced Link Prediction (CELP) framework that incorporates community structure to jointly model local and global graph topology. Specifically, CELP enhances the graph via community-aware, confidence-guided edge completion and pruning, while integrating multi-scale structural features to achieve more accurate link prediction. Experimental results across multiple benchmark datasets demonstrate that CELP achieves superior performance, validating the crucial role of community structure in improving link prediction accuracy.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21166v1">üìÑ Download PDF</a></p><hr><h3 id=emotion-diffusion-in-real-and-simulated-social-graphs-structural-limits-of-llm-based-social-simulationhttpsarxivorgabs251221138v1><a href=https://arxiv.org/abs/2512.21138v1>Emotion Diffusion in Real and Simulated Social Graphs: Structural Limits of LLM-Based Social Simulation</a><a hidden class=anchor aria-hidden=true href=#emotion-diffusion-in-real-and-simulated-social-graphs-structural-limits-of-llm-based-social-simulationhttpsarxivorgabs251221138v1>#</a></h3><p><strong>Authors:</strong> Qiqi Qiang
<strong>Venue:</strong> arXiv (2025)</p><p>Understanding how emotions diffuse through social networks is central to computational social science. Recently, large language models (LLMs) have been increasingly used to simulate social media interactions, raising the question of whether LLM-generated data can realistically reproduce emotion diffusion patterns observed in real online communities. In this study, we conduct a systematic comparison between emotion diffusion in real-world social graphs and in LLM-simulated interaction networks. We construct diffusion graphs from Reddit discussion data and compare them with synthetic social graphs generated through LLM-driven conversational simulations. Emotion states are inferred using established sentiment analysis pipelines, and both real and simulated graphs are analyzed from structural, behavioral, and predictive perspectives. Our results reveal substantial structural and dynamic discrepancies between real and simulated diffusion processes. Real-world emotion diffusion exhibits dense connectivity, repeated interactions, sentiment shifts, and emergent community structures, whereas LLM-simulated graphs largely consist of isolated linear chains with monotonic emotional trajectories. These structural limitations significantly affect downstream tasks such as graph-based emotion prediction, leading to reduced emotional diversity and class imbalance in simulated settings. Our findings highlight current limitations of LLM-based social simulation in capturing the interactive complexity and emotional heterogeneity of real social networks. This work provides empirical evidence for the cautious use of LLM-generated data in social science research and suggests directions for improving future simulation frameworks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.21138v1">üìÑ Download PDF</a></p><hr><h3 id=mental-health-self-disclosure-on-social-media-throughout-the-pandemic-periodhttpsarxivorgabs251220990v1><a href=https://arxiv.org/abs/2512.20990v1>Mental Health Self-Disclosure on Social Media throughout the Pandemic Period</a><a hidden class=anchor aria-hidden=true href=#mental-health-self-disclosure-on-social-media-throughout-the-pandemic-periodhttpsarxivorgabs251220990v1>#</a></h3><p><strong>Authors:</strong> Dino Husnic, Stefan Cobeli, Shweta Yadav
<strong>Venue:</strong> arXiv (2025)</p><p>The COVID-19 pandemic has created many problems, especially in people&rsquo;s social lives. There has been increasing isolation and economic hardships since the beginning of the pandemic for people all over the world. Quarantines and lockdowns also took part in that, and so, people have been expressing their emotions throughout the pandemic period using social media platforms like Reddit, Twitter, Facebook, etc. In this study, we seek to analyze the emotions and mental health labels throughout the time period of March 2, 2020, up until July 4, 2020, from the threads and comments gathered from the r/unitedkingdom subreddit. We used a soft labeling technique to generate mental health conditions for each Reddit comment. We compared the overall results with important dates related to COVID-19 policies that took place in the United Kingdom. This can give us a view on how the pandemic and the important dates affect people self disclosing their emotions on social media platforms. Finally, we have developed a proof of concept to show that using mental health features may increase emotion prediction accuracy.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20990v1">üìÑ Download PDF</a></p><hr><h3 id=from-human-bias-to-robot-choice-how-occupational-contexts-and-racial-priming-shape-robot-selectionhttpsarxivorgabs251220951v1><a href=https://arxiv.org/abs/2512.20951v1>From Human Bias to Robot Choice: How Occupational Contexts and Racial Priming Shape Robot Selection</a><a hidden class=anchor aria-hidden=true href=#from-human-bias-to-robot-choice-how-occupational-contexts-and-racial-priming-shape-robot-selectionhttpsarxivorgabs251220951v1>#</a></h3><p><strong>Authors:</strong> Jiangen He, Wanqi Zhang, Jessica Barfield
<strong>Venue:</strong> arXiv (2025)</p><p>As artificial agents increasingly integrate into professional environments, fundamental questions have emerged about how societal biases influence human-robot selection decisions. We conducted two comprehensive experiments (N = 1,038) examining how occupational contexts and stereotype activation shape robotic agent choices across construction, healthcare, educational, and athletic domains. Participants made selections from artificial agents that varied systematically in skin tone and anthropomorphic characteristics. Our study revealed distinct context-dependent patterns. Healthcare and educational scenarios demonstrated strong favoritism toward lighter-skinned artificial agents, while construction and athletic contexts showed greater acceptance of darker-toned alternatives. Participant race was associated with systematic differences in selection patterns across professional domains. The second experiment demonstrated that exposure to human professionals from specific racial backgrounds systematically shifted later robotic agent preferences in stereotype-consistent directions. These findings show that occupational biases and color-based discrimination transfer directly from human-human to human-robot evaluation contexts. The results highlight mechanisms through which robotic deployment may unintentionally perpetuate existing social inequalities.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20951v1">üìÑ Download PDF</a></p><hr><h3 id=welfare-at-risk-distributional-impact-of-policy-interventionshttpsarxivorgabs251220918v1><a href=https://arxiv.org/abs/2512.20918v1>Welfare at Risk: Distributional impact of policy interventions</a><a hidden class=anchor aria-hidden=true href=#welfare-at-risk-distributional-impact-of-policy-interventionshttpsarxivorgabs251220918v1>#</a></h3><p><strong>Authors:</strong> Costas Lambros, Emerson Melo
<strong>Venue:</strong> arXiv (2025)</p><p>This paper proposes a framewrok for analyzing how the welfare effects of policy interventions are distributed across individuals when those effects are unobserved. Rather than focusing solely on average outcomes, the approach uses readily available information on average welfare responses to uncover meaningful patterns in how gains and losses are distributed across different populations. The framework is built around the concept of superquantile and applies to a broad class of models with unobserved individual heterogeneity. It enables policymakers to identify which groups are most adversely affected by a policy and to evaluate trade-offs between efficiency and equity. We illustrate the approach in three widely studied economic settings: price changes and compensated variation, treatment allocation with self-selection, and the cost-benefit analysis of social programs. In this latter application, we show how standard tools from the marginal treatment effect and generalized Roy model literature are useful for implementing our bounds for both the overall population and for individuals who participate in the program.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.20918v1">üìÑ Download PDF</a></p><hr></div><footer class=post-footer><ul class=post-tags></ul></footer><div><div class=pagination__title><span class=pagination__title-h style=font-size:20px>Comments</span><hr></div><div id=tcomment></div><script src=https://cdn.staticfile.org/twikoo/1.6.39/twikoo.all.min.js></script><script>twikoo.init({envId:"https://mangodb-theta.vercel.app/",el:"#tcomment",lang:"en-US",path:window.TWIKOO_MAGIC_PATH||window.location.pathname})</script></div></article></main><footer class=footer><span>&copy; 2026 <a href=https://garyforreal.me/en/>Gary's House</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span><div class=busuanzi-footer><span id=busuanzi_container_site_pv>Views: <span id=busuanzi_value_site_pv></span>
</span><span id=busuanzi_container_site_uv>Visitors: <span id=busuanzi_value_site_uv></span></span></div></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>