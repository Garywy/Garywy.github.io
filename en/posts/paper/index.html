<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Paper | Gary's House</title>
<meta name=keywords content><meta name=description content="Paper - Gary's House"><meta name=author content="Gary"><link rel=canonical href=https://garyforreal.me/en/posts/paper/><meta name=google-site-verification content="XYZabc"><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><meta name=referrer content="no-referrer-when-downgrade"><link crossorigin=anonymous href=/assets/css/stylesheet.7e5251d8716d933fafcf3df70d7ecd02729661d6d232fc5dd0b8a85ef75e3409.css integrity="sha256-flJR2HFtkz+vzz33DX7NAnKWYdbSMvxd0LioXvdeNAk=" rel="preload stylesheet" as=style><link rel=icon href=https://garyforreal.me/img/Q.jpg><link rel=icon type=image/png sizes=16x16 href=https://garyforreal.me/img/Q.jpg><link rel=icon type=image/png sizes=32x32 href=https://garyforreal.me/img/Q.jpg><link rel=apple-touch-icon href=https://garyforreal.me/Q.jpg><link rel=mask-icon href=https://garyforreal.me/Q.jpg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://garyforreal.me/en/posts/paper/index.xml><link rel=alternate hreflang=en href=https://garyforreal.me/en/posts/paper/><link rel=alternate hreflang=zh href=https://garyforreal.me/zh/posts/paper/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@200..900&display=swap" rel=stylesheet><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous referrerpolicy=no-referrer></script><meta property="og:title" content="Paper"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://garyforreal.me/en/posts/paper/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Paper"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://garyforreal.me/en/posts/"},{"@type":"ListItem","position":2,"name":"Paper","item":"https://garyforreal.me/en/posts/paper/"}]}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css><script src=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><script src=https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js></script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://garyforreal.me/en/ accesskey=h title="Gary's Blog (Alt + H)"><img src=https://garyforreal.me/img/me.jpg alt aria-label=logo height=35>Gary's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://garyforreal.me/zh/ title=‰∏≠Êñá aria-label=‰∏≠Êñá>‰∏≠Êñá</a></li></ul></div></div><ul id=menu><li><a href=https://garyforreal.me/en/search title="üîçSearch (Alt + /)" accesskey=/><span>üîçSearch</span></a></li><li><a href=https://garyforreal.me/en/ title=üè†Homepage><span>üè†Homepage</span></a></li><li><a href=https://garyforreal.me/en/posts title=üìöArticle><span>üìöArticle</span></a></li><li><a href=https://garyforreal.me/en/archives/ title=‚è±Archives><span>‚è±Archives</span></a></li><li><a href=https://garyforreal.me/en/music/ title=üéµmusic><span>üéµmusic</span></a></li><li><a href=https://garyforreal.me/en/about title=üôãüèª‚Äç‚ôÇÔ∏èAbout><span>üôãüèª‚Äç‚ôÇÔ∏èAbout</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://garyforreal.me/en/>Home</a>&nbsp;¬ª&nbsp;<a href=https://garyforreal.me/en/posts/>Posts</a></div><h1>Paper</h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Weekly Paper Notes - 2026-02-15</h2></header><div class=entry-content><p>Weekly Paper Notes üîç multilingual A technical curriculum on language-oriented artificial intelligence in translation and specialised communication Authors: Ralph Kr√ºger Venue: arXiv (2026)
This paper presents a technical curriculum on language-oriented artificial intelligence (AI) in the language and translation (L&amp;T) industry. The curriculum aims to foster domain-specific technical AI literacy among stakeholders in the fields of translation and specialised communication by exposing them to the conceptual and technical/algorithmic foundations of modern language-oriented AI in an accessible way. The core curriculum focuses on 1) vector embeddings, 2) the technical foundations of neural networks, 3) tokenization and 4) transformer neural networks. It is intended to help users develop computational thinking as well as algorithmic awareness and algorithmic agency, ultimately contributing to their digital resilience in AI-driven work environments. The didactic suitability of the curriculum was tested in an AI-focused MA course at the Institute of Translation and Multilingual Communication at TH Koeln. Results suggest the didactic effectiveness of the curriculum, but participant feedback indicates that it should be embedded into higher-level didactic scaffolding - e.g., in the form of lecturer support - in order to enable optimal learning conditions.
...</p></div><footer class=entry-footer><span title='2026-02-15 15:30:24.51342 +0000 UTC'>2026-02-15</span>&nbsp;¬∑&nbsp;104 min&nbsp;¬∑&nbsp;104 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Weekly Paper Notes - 2026-02-15" href=https://garyforreal.me/en/posts/paper/paper-2026-02-15-weekly/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Weekly Paper Notes - 2026-02-08</h2></header><div class=entry-content><p>Weekly Paper Notes üîç multilingual Self-Improving Multilingual Long Reasoning via Translation-Reasoning Integrated Training Authors: Junxiao Liu, Zhijun Wang, Yixiao Li, Zhejian Lai, Liqian Huang, Xin Huang, Xue Han, Junlan Feng, Shujian Huang Venue: arXiv (2026)
Long reasoning models often struggle in multilingual settings: they tend to reason in English for non-English questions; when constrained to reasoning in the question language, accuracies drop substantially. The struggle is caused by the limited abilities for both multilingual question understanding and multilingual reasoning. To address both problems, we propose TRIT (Translation-Reasoning Integrated Training), a self-improving framework that integrates the training of translation into multilingual reasoning. Without external feedback or additional multilingual data, our method jointly enhances multilingual question understanding and response generation. On MMATH, our method outperforms multiple baselines by an average of 7 percentage points, improving both answer correctness and language consistency. Further analysis reveals that integrating translation training improves cross-lingual question alignment by over 10 percentage points and enhances translation quality for both mathematical questions and general-domain text, with gains up to 8.4 COMET points on FLORES-200.
...</p></div><footer class=entry-footer><span title='2026-02-08 15:31:07.463236 +0000 UTC'>2026-02-08</span>&nbsp;¬∑&nbsp;107 min&nbsp;¬∑&nbsp;107 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Weekly Paper Notes - 2026-02-08" href=https://garyforreal.me/en/posts/paper/paper-2026-02-08-weekly/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Weekly Paper Notes - 2026-02-01</h2></header><div class=entry-content><p>Weekly Paper Notes üîç multilingual JUST-DUB-IT: Video Dubbing via Joint Audio-Visual Diffusion Authors: Anthony Chen, Naomi Ken Korem, Tavi Halperin, Matan Ben Yosef, Urska Jelercic, Ofir Bibi, Or Patashnik, Daniel Cohen-Or Venue: arXiv (2026)
Audio-Visual Foundation Models, which are pretrained to jointly generate sound and visual content, have recently shown an unprecedented ability to model multi-modal generation and editing, opening new opportunities for downstream tasks. Among these tasks, video dubbing could greatly benefit from such priors, yet most existing solutions still rely on complex, task-specific pipelines that struggle in real-world settings. In this work, we introduce a single-model approach that adapts a foundational audio-video diffusion model for video-to-video dubbing via a lightweight LoRA. The LoRA enables the model to condition on an input audio-video while jointly generating translated audio and synchronized facial motion. To train this LoRA, we leverage the generative model itself to synthesize paired multilingual videos of the same speaker. Specifically, we generate multilingual videos with language switches within a single clip, and then inpaint the face and audio in each half to match the language of the other half. By leveraging the rich generative prior of the audio-visual model, our approach preserves speaker identity and lip synchronization while remaining robust to complex motion and real-world dynamics. We demonstrate that our approach produces high-quality dubbed videos with improved visual fidelity, lip synchronization, and robustness compared to existing dubbing pipelines.
...</p></div><footer class=entry-footer><span title='2026-02-01 15:30:48.807773 +0000 UTC'>2026-02-01</span>&nbsp;¬∑&nbsp;116 min&nbsp;¬∑&nbsp;116 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Weekly Paper Notes - 2026-02-01" href=https://garyforreal.me/en/posts/paper/paper-2026-02-01-weekly/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Weekly Paper Notes - 2026-01-25</h2></header><div class=entry-content><p>Weekly Paper Notes üîç multilingual Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging Authors: Alphaeus Dmonte, Vidhi Gupta, Daniel J Perry, Mark Arehart Venue: arXiv (2026)
Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work.
...</p></div><footer class=entry-footer><span title='2026-01-25 15:25:20.581591 +0000 UTC'>2026-01-25</span>&nbsp;¬∑&nbsp;123 min&nbsp;¬∑&nbsp;123 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Weekly Paper Notes - 2026-01-25" href=https://garyforreal.me/en/posts/paper/paper-2026-01-25-weekly/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Weekly Paper Notes - 2026-01-18</h2></header><div class=entry-content><p>Weekly Paper Notes üîç multilingual CURVE: A Benchmark for Cultural and Multilingual Long Video Reasoning Authors: Darshan Singh, Arsha Nagrani, Kawshik Manikantan, Harman Singh, Dinesh Tewari, Tobias Weyand, Cordelia Schmid, Anelia Angelova, Shachi Dave Venue: arXiv (2026)
Recent advancements in video models have shown tremendous progress, particularly in long video understanding. However, current benchmarks predominantly feature western-centric data and English as the dominant language, introducing significant biases in evaluation. To address this, we introduce CURVE (Cultural Understanding and Reasoning in Video Evaluation), a challenging benchmark for multicultural and multilingual video reasoning. CURVE comprises high-quality, entirely human-generated annotations from diverse, region-specific cultural videos across 18 global locales. Unlike prior work that relies on automatic translations, CURVE provides complex questions, answers, and multi-step reasoning steps, all crafted in native languages. Making progress on CURVE requires a deeply situated understanding of visual cultural context. Furthermore, we leverage CURVE‚Äôs reasoning traces to construct evidence-based graphs and propose a novel iterative strategy using these graphs to identify fine-grained errors in reasoning. Our evaluations reveal that SoTA Video-LLMs struggle significantly, performing substantially below human-level accuracy, with errors primarily stemming from the visual perception of cultural elements. CURVE will be publicly available under https://github.com/google-deepmind/neptune?tab=readme-ov-file#minerva-cultural
...</p></div><footer class=entry-footer><span title='2026-01-18 15:24:18.873273 +0000 UTC'>2026-01-18</span>&nbsp;¬∑&nbsp;125 min&nbsp;¬∑&nbsp;125 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Weekly Paper Notes - 2026-01-18" href=https://garyforreal.me/en/posts/paper/paper-2026-01-18-weekly/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Weekly Paper Notes - 2026-01-11</h2></header><div class=entry-content><p>Weekly Paper Notes üîç multilingual Code-Mix Sentiment Analysis on Hinglish Tweets Authors: Aashi Garg, Aneshya Das, Arshi Arya, Anushka Goyal, Aditi Venue: arXiv (2026)
The effectiveness of brand monitoring in India is increasingly challenged by the rise of Hinglish‚Äìa hybrid of Hindi and English‚Äìused widely in user-generated content on platforms like Twitter. Traditional Natural Language Processing (NLP) models, built for monolingual data, often fail to interpret the syntactic and semantic complexity of this code-mixed language, resulting in inaccurate sentiment analysis and misleading market insights. To address this gap, we propose a high-performance sentiment classification framework specifically designed for Hinglish tweets. Our approach fine-tunes mBERT (Multilingual BERT), leveraging its multilingual capabilities to better understand the linguistic diversity of Indian social media. A key component of our methodology is the use of subword tokenization, which enables the model to effectively manage spelling variations, slang, and out-of-vocabulary terms common in Romanized Hinglish. This research delivers a production-ready AI solution for brand sentiment tracking and establishes a strong benchmark for multilingual NLP in low-resource, code-mixed environments.
...</p></div><footer class=entry-footer><span title='2026-01-11 15:25:07.694214 +0000 UTC'>2026-01-11</span>&nbsp;¬∑&nbsp;133 min&nbsp;¬∑&nbsp;133 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Weekly Paper Notes - 2026-01-11" href=https://garyforreal.me/en/posts/paper/paper-2026-01-11-weekly/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Weekly Paper Notes - 2026-01-04</h2></header><div class=entry-content><p>Weekly Paper Notes üîç multilingual Big AI is accelerating the metacrisis: What can we do? Authors: Steven Bird Venue: arXiv (2025)
The world is in the grip of ecological, meaning, and language crises which are converging into a metacrisis. Big AI is accelerating them all. Language engineers are playing a central role, persisting with a scalability story that is failing humanity, supplying critical talent to plutocrats and kleptocrats, and creating new technologies as if the whole endeavour was value-free. We urgently need to explore alternatives, applying our collective intelligence to design a life-affirming future for NLP that is centered on human flourishing on a living planet.
...</p></div><footer class=entry-footer><span title='2026-01-04 15:23:50.536198 +0000 UTC'>2026-01-04</span>&nbsp;¬∑&nbsp;108 min&nbsp;¬∑&nbsp;108 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Weekly Paper Notes - 2026-01-04" href=https://garyforreal.me/en/posts/paper/paper-2026-01-04-weekly/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Weekly Paper Notes - 2025-12-28</h2></header><div class=entry-content><p>Weekly Paper Notes üîç multilingual Model Merging via Multi-Teacher Knowledge Distillation Authors: Seyed Arshan Dalili, Mehrdad Mahdavi Venue: arXiv (2025)
Model merging has emerged as a lightweight alternative to joint multi-task learning (MTL), yet the generalization properties of merged models remain largely unexplored. Establishing such theoretical guarantees is non-trivial, as the merging process typically forbids access to the original training data and involves combining fine-tuned models trained on fundamentally heterogeneous data distributions. Without a principled understanding of these dynamics, current methods often rely on heuristics to approximate the optimal combination of parameters. This dependence is most critical in coefficient scaling, the weighting factors that modulate the magnitude of each fine-tuned model‚Äôs contribution to the shared parameter. However, without a principled objective to guide their selection, these methods lead to brittle performance and are highly sensitive to scaling initialization. We address this gap by (i) establishing a novel flatness-aware PAC-Bayes generalization bound specifically for the model merging setting. This analysis introduces a ‚Äúcross-task heterogeneity‚Äù term that formally captures the mismatch between diverse fine-tuned model priors and the target multi-task distributions. Guided by this theoretical insight, (ii) we frame model merging as multi-teacher knowledge distillation on scarce, unlabeled data. We formally demonstrate that minimizing the student-teacher Kullback-Leibler divergence directly tightens the upper bound on the merged model‚Äôs excess risk. Guided by the flatness-aware bound derived, (iii) we operationalize this objective via SAMerging, a method that employs Sharpness-Aware Minimization (SAM) to find flat minima. Empirically, SAMerging establishes a new state of the art across vision and NLP benchmarks, achieving remarkable performance. The code is available at https://github.com/arshandalili/SAMerging.
...</p></div><footer class=entry-footer><span title='2025-12-28 15:24:24.510017 +0000 UTC'>2025-12-28</span>&nbsp;¬∑&nbsp;120 min&nbsp;¬∑&nbsp;120 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Weekly Paper Notes - 2025-12-28" href=https://garyforreal.me/en/posts/paper/paper-2025-12-28-weekly/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Weekly Paper Notes - 2025-12-21</h2></header><div class=entry-content><p>Weekly Paper Notes üîç multilingual From Essence to Defense: Adaptive Semantic-aware Watermarking for Embedding-as-a-Service Copyright Protection Authors: Hao Li, Yubing Ren, Yanan Cao, Yingjie Li, Fang Fang, Xuebin Wang Venue: arXiv (2025)
Benefiting from the superior capabilities of large language models in natural language understanding and generation, Embeddings-as-a-Service (EaaS) has emerged as a successful commercial paradigm on the web platform. However, prior studies have revealed that EaaS is vulnerable to imitation attacks. Existing methods protect the intellectual property of EaaS through watermarking techniques, but they all ignore the most important properties of embedding: semantics, resulting in limited harmlessness and stealthiness. To this end, we propose SemMark, a novel semantic-based watermarking paradigm for EaaS copyright protection. SemMark employs locality-sensitive hashing to partition the semantic space and inject semantic-aware watermarks into specific regions, ensuring that the watermark signals remain imperceptible and diverse. In addition, we introduce the adaptive watermark weight mechanism based on the local outlier factor to preserve the original embedding distribution. Furthermore, we propose Detect-Sampling and Dimensionality-Reduction attacks and construct four scenarios to evaluate the watermarking method. Extensive experiments are conducted on four popular NLP datasets, and SemMark achieves superior verifiability, diversity, stealthiness, and harmlessness.
...</p></div><footer class=entry-footer><span title='2025-12-21 15:23:23.007415 +0000 UTC'>2025-12-21</span>&nbsp;¬∑&nbsp;120 min&nbsp;¬∑&nbsp;120 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Weekly Paper Notes - 2025-12-21" href=https://garyforreal.me/en/posts/paper/paper-2025-12-21-weekly/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Weekly Paper Notes - 2025-12-14</h2></header><div class=entry-content><p>Weekly Paper Notes üîç multilingual Grow Up and Merge: Scaling Strategies for Efficient Language Adaptation Authors: Kevin Glocker, K√§triin Kukk, Romina Oji, Marcel Bollmann, Marco Kuhlmann, Jenny Kunz Venue: arXiv (2025)
Achieving high-performing language models which include medium- and lower-resource languages remains a challenge. Massively multilingual models still underperform compared to language-specific adaptations, especially at smaller model scales. In this work, we investigate scaling as an efficient strategy for adapting pretrained models to new target languages. Through comprehensive scaling ablations with approximately FLOP-matched models, we test whether upscaling an English base model enables more effective and resource-efficient adaptation than standard continued pretraining. We find that, once exposed to sufficient target-language data, larger upscaled models can match or surpass the performance of smaller models continually pretrained on much more data, demonstrating the benefits of scaling for data efficiency. Scaling also helps preserve the base model‚Äôs capabilities in English, thus reducing catastrophic forgetting. Finally, we explore whether such scaled, language-specific models can be merged to construct modular and flexible multilingual systems. We find that while merging remains less effective than joint multilingual training, upscaled merges perform better than smaller ones. We observe large performance differences across merging methods, suggesting potential for improvement through merging approaches specialized for language-level integration.
...</p></div><footer class=entry-footer><span title='2025-12-14 15:23:14.907278 +0000 UTC'>2025-12-14</span>&nbsp;¬∑&nbsp;123 min&nbsp;¬∑&nbsp;123 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Weekly Paper Notes - 2025-12-14" href=https://garyforreal.me/en/posts/paper/paper-2025-12-14-weekly/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Research_lab_works</h2></header><div class=entry-content><p>CREPE: Open-Domain Question Answering with False Presuppositions üéØ Target The authors introduced CREPE, a QA dataset containing a natural distribution of presupposition failures from online information-seeking forums.
üì¶ Dataset CREPE, a QA dataset containing a natural distribution of presupposition failures from online information-seeking forums.
Data Source: Reddit, the ELI5 subreddit.
Data Numbers: 8,400 Reddit questions with:
Labels (whether there are any false presuppositions). The false presuppositions and their corrections, if there are any false presuppositions in questions. ...</p></div><footer class=entry-footer><span title='2025-03-21 15:15:43 +0900 JST'>2025-03-21</span>&nbsp;¬∑&nbsp;14 min&nbsp;¬∑&nbsp;14 min&nbsp;¬∑&nbsp;Gary</footer><a class=entry-link aria-label="post link to Research_lab_works" href=https://garyforreal.me/en/posts/paper/research_lab_works/></a></article></main><footer class=footer><span>&copy; 2026 <a href=https://garyforreal.me/en/>Gary's House</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span><div class=busuanzi-footer><span id=busuanzi_container_site_pv>Views: <span id=busuanzi_value_site_pv></span>
</span><span id=busuanzi_container_site_uv>Visitors: <span id=busuanzi_value_site_uv></span></span></div></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>