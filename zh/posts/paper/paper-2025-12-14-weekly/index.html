<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Weekly Paper Notes - 2025-12-14 | Gary's House</title>
<meta name=keywords content><meta name=description content="Weekly Paper Notes
üîç multilingual
Grow Up and Merge: Scaling Strategies for Efficient Language Adaptation
Authors: Kevin Glocker, K√§triin Kukk, Romina Oji, Marcel Bollmann, Marco Kuhlmann, Jenny Kunz
Venue: arXiv (2025)
Achieving high-performing language models which include medium- and lower-resource languages remains a challenge. Massively multilingual models still underperform compared to language-specific adaptations, especially at smaller model scales. In this work, we investigate scaling as an efficient strategy for adapting pretrained models to new target languages. Through comprehensive scaling ablations with approximately FLOP-matched models, we test whether upscaling an English base model enables more effective and resource-efficient adaptation than standard continued pretraining. We find that, once exposed to sufficient target-language data, larger upscaled models can match or surpass the performance of smaller models continually pretrained on much more data, demonstrating the benefits of scaling for data efficiency. Scaling also helps preserve the base model&rsquo;s capabilities in English, thus reducing catastrophic forgetting. Finally, we explore whether such scaled, language-specific models can be merged to construct modular and flexible multilingual systems. We find that while merging remains less effective than joint multilingual training, upscaled merges perform better than smaller ones. We observe large performance differences across merging methods, suggesting potential for improvement through merging approaches specialized for language-level integration."><meta name=author content="Gary"><link rel=canonical href=https://garyforreal.me/zh/posts/paper/paper-2025-12-14-weekly/><meta name=google-site-verification content="XYZabc"><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><meta name=referrer content="no-referrer-when-downgrade"><link crossorigin=anonymous href=/assets/css/stylesheet.7e5251d8716d933fafcf3df70d7ecd02729661d6d232fc5dd0b8a85ef75e3409.css integrity="sha256-flJR2HFtkz+vzz33DX7NAnKWYdbSMvxd0LioXvdeNAk=" rel="preload stylesheet" as=style><link rel=icon href=https://garyforreal.me/img/Q.jpg><link rel=icon type=image/png sizes=16x16 href=https://garyforreal.me/img/Q.jpg><link rel=icon type=image/png sizes=32x32 href=https://garyforreal.me/img/Q.jpg><link rel=apple-touch-icon href=https://garyforreal.me/Q.jpg><link rel=mask-icon href=https://garyforreal.me/Q.jpg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://garyforreal.me/zh/posts/paper/paper-2025-12-14-weekly/><link rel=alternate hreflang=en href=https://garyforreal.me/en/posts/paper/paper-2025-12-14-weekly/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@200..900&display=swap" rel=stylesheet><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous referrerpolicy=no-referrer></script><meta property="og:title" content="Weekly Paper Notes - 2025-12-14"><meta property="og:description" content="Weekly Paper Notes
üîç multilingual
Grow Up and Merge: Scaling Strategies for Efficient Language Adaptation
Authors: Kevin Glocker, K√§triin Kukk, Romina Oji, Marcel Bollmann, Marco Kuhlmann, Jenny Kunz
Venue: arXiv (2025)
Achieving high-performing language models which include medium- and lower-resource languages remains a challenge. Massively multilingual models still underperform compared to language-specific adaptations, especially at smaller model scales. In this work, we investigate scaling as an efficient strategy for adapting pretrained models to new target languages. Through comprehensive scaling ablations with approximately FLOP-matched models, we test whether upscaling an English base model enables more effective and resource-efficient adaptation than standard continued pretraining. We find that, once exposed to sufficient target-language data, larger upscaled models can match or surpass the performance of smaller models continually pretrained on much more data, demonstrating the benefits of scaling for data efficiency. Scaling also helps preserve the base model&rsquo;s capabilities in English, thus reducing catastrophic forgetting. Finally, we explore whether such scaled, language-specific models can be merged to construct modular and flexible multilingual systems. We find that while merging remains less effective than joint multilingual training, upscaled merges perform better than smaller ones. We observe large performance differences across merging methods, suggesting potential for improvement through merging approaches specialized for language-level integration."><meta property="og:type" content="article"><meta property="og:url" content="https://garyforreal.me/zh/posts/paper/paper-2025-12-14-weekly/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-12-14T15:23:14+00:00"><meta property="article:modified_time" content="2025-12-14T15:23:14+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Weekly Paper Notes - 2025-12-14"><meta name=twitter:description content="Weekly Paper Notes
üîç multilingual
Grow Up and Merge: Scaling Strategies for Efficient Language Adaptation
Authors: Kevin Glocker, K√§triin Kukk, Romina Oji, Marcel Bollmann, Marco Kuhlmann, Jenny Kunz
Venue: arXiv (2025)
Achieving high-performing language models which include medium- and lower-resource languages remains a challenge. Massively multilingual models still underperform compared to language-specific adaptations, especially at smaller model scales. In this work, we investigate scaling as an efficient strategy for adapting pretrained models to new target languages. Through comprehensive scaling ablations with approximately FLOP-matched models, we test whether upscaling an English base model enables more effective and resource-efficient adaptation than standard continued pretraining. We find that, once exposed to sufficient target-language data, larger upscaled models can match or surpass the performance of smaller models continually pretrained on much more data, demonstrating the benefits of scaling for data efficiency. Scaling also helps preserve the base model&rsquo;s capabilities in English, thus reducing catastrophic forgetting. Finally, we explore whether such scaled, language-specific models can be merged to construct modular and flexible multilingual systems. We find that while merging remains less effective than joint multilingual training, upscaled merges perform better than smaller ones. We observe large performance differences across merging methods, suggesting potential for improvement through merging approaches specialized for language-level integration."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Â∏ñÂ≠ê","item":"https://garyforreal.me/zh/posts/"},{"@type":"ListItem","position":2,"name":"ËÆ∫Êñá","item":"https://garyforreal.me/zh/posts/paper/"},{"@type":"ListItem","position":3,"name":"Weekly Paper Notes - 2025-12-14","item":"https://garyforreal.me/zh/posts/paper/paper-2025-12-14-weekly/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Weekly Paper Notes - 2025-12-14","name":"Weekly Paper Notes - 2025-12-14","description":"Weekly Paper Notes üîç multilingual Grow Up and Merge: Scaling Strategies for Efficient Language Adaptation Authors: Kevin Glocker, K√§triin Kukk, Romina Oji, Marcel Bollmann, Marco Kuhlmann, Jenny Kunz Venue: arXiv (2025)\nAchieving high-performing language models which include medium- and lower-resource languages remains a challenge. Massively multilingual models still underperform compared to language-specific adaptations, especially at smaller model scales. In this work, we investigate scaling as an efficient strategy for adapting pretrained models to new target languages. Through comprehensive scaling ablations with approximately FLOP-matched models, we test whether upscaling an English base model enables more effective and resource-efficient adaptation than standard continued pretraining. We find that, once exposed to sufficient target-language data, larger upscaled models can match or surpass the performance of smaller models continually pretrained on much more data, demonstrating the benefits of scaling for data efficiency. Scaling also helps preserve the base model\u0026rsquo;s capabilities in English, thus reducing catastrophic forgetting. Finally, we explore whether such scaled, language-specific models can be merged to construct modular and flexible multilingual systems. We find that while merging remains less effective than joint multilingual training, upscaled merges perform better than smaller ones. We observe large performance differences across merging methods, suggesting potential for improvement through merging approaches specialized for language-level integration.\n","keywords":[],"articleBody":"Weekly Paper Notes üîç multilingual Grow Up and Merge: Scaling Strategies for Efficient Language Adaptation Authors: Kevin Glocker, K√§triin Kukk, Romina Oji, Marcel Bollmann, Marco Kuhlmann, Jenny Kunz Venue: arXiv (2025)\nAchieving high-performing language models which include medium- and lower-resource languages remains a challenge. Massively multilingual models still underperform compared to language-specific adaptations, especially at smaller model scales. In this work, we investigate scaling as an efficient strategy for adapting pretrained models to new target languages. Through comprehensive scaling ablations with approximately FLOP-matched models, we test whether upscaling an English base model enables more effective and resource-efficient adaptation than standard continued pretraining. We find that, once exposed to sufficient target-language data, larger upscaled models can match or surpass the performance of smaller models continually pretrained on much more data, demonstrating the benefits of scaling for data efficiency. Scaling also helps preserve the base model‚Äôs capabilities in English, thus reducing catastrophic forgetting. Finally, we explore whether such scaled, language-specific models can be merged to construct modular and flexible multilingual systems. We find that while merging remains less effective than joint multilingual training, upscaled merges perform better than smaller ones. We observe large performance differences across merging methods, suggesting potential for improvement through merging approaches specialized for language-level integration.\nüìÑ Download PDF\nAgriGPT-Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence Authors: Bo Yang, Lanfei Feng, Yunkui Chen, Yu Zhang, Jianyu Zhang, Xiao Xu, Nueraili Aierken, Shijian Li Venue: arXiv (2025)\nDespite rapid advances in multimodal large language models, agricultural applications remain constrained by the lack of multilingual speech data, unified multimodal architectures, and comprehensive evaluation benchmarks. To address these challenges, we present AgriGPT-Omni, an agricultural omni-framework that integrates speech, vision, and text in a unified framework. First, we construct a scalable data synthesis and collection pipeline that converts agricultural texts and images into training data, resulting in the largest agricultural speech dataset to date, including 492K synthetic and 1.4K real speech samples across six languages. Second, based on this, we train the first agricultural omni-model via a three-stage paradigm: textual knowledge injection, progressive multimodal alignment, and GRPO-based reinforcement learning, enabling unified reasoning across languages and modalities. Third, we propose AgriBench-Omni-2K, the first tri-modal benchmark for agriculture, covering diverse speech-vision-text tasks and multilingual slices, with standardized protocols and reproducible tools. Experiments show that AgriGPT-Omni significantly outperforms general-purpose baselines on multilingual and multimodal reasoning as well as real-world speech understanding. All models, data, benchmarks, and code will be released to promote reproducible research, inclusive agricultural intelligence, and sustainable AI development for low-resource regions.\nüìÑ Download PDF\nXDoGE: Multilingual Data Reweighting to Enhance Language Inclusivity in LLMs Authors: I√±aki Lacunza, Jos√© Javier Saiz, Alexander Shvets, Aitor Gonzalez-Agirre, Marta Villegas Venue: arXiv (2025)\nCurrent large language models (LLMs) are trained on massive amounts of text data, primarily from a few dominant languages. Studies suggest that this over-reliance on high-resource languages, such as English, hampers LLM performance in mid- and low-resource languages. To mitigate this problem, we propose to (i) optimize the language distribution by training a small proxy model within a domain-reweighing DoGE algorithm that we extend to XDoGE for a multilingual setup, and (ii) rescale the data and train a full-size model with the established language weights either from scratch or within a continual pre-training phase (CPT). We target six languages possessing a variety of geographic and intra- and inter-language-family relations, namely, English and Spanish (high-resource), Portuguese and Catalan (mid-resource), Galician and Basque (low-resource). We experiment with Salamandra-2b, which is a promising model for these languages. We investigate the effects of substantial data repetition on minor languages and under-sampling on dominant languages using the IberoBench framework for quantitative evaluation. Finally, we release a new promising IberianLLM-7B-Instruct model centering on Iberian languages and English that we pretrained from scratch and further improved using CPT with the XDoGE weights.\nüìÑ Download PDF\nEnhancing Next-Generation Language Models with Knowledge Graphs: Extending Claude, Mistral IA, and GPT-4 via KG-BERT Authors: Nour El Houda Ben Chaabene, Hamza Hammami Venue: arXiv (2025)\nLarge language models (LLMs) like Claude, Mistral IA, and GPT-4 excel in NLP but lack structured knowledge, leading to factual inconsistencies. We address this by integrating Knowledge Graphs (KGs) via KG-BERT to enhance grounding and reasoning. Experiments show significant gains in knowledge-intensive tasks such as question answering and entity linking. This approach improves factual reliability and enables more context-aware next-generation LLMs.\nüìÑ Download PDF\nMultilingual VLM Training: Adapting an English-Trained VLM to French Authors: Jules Lahmi, Alexis Roger Venue: arXiv (2025)\nArtificial intelligence has made great progress in recent years, particularly in the development of Vision‚ÄìLanguage Models (VLMs) that understand both visual and textual data. However, these advancements remain largely limited to English, reducing their accessibility for non‚ÄìEnglish speakers. It is essential to extend these capabilities to a broader range of languages. This paper explores the challenges of adapting an English-trained VLM to different languages. To this end, we will explore and compare different methods for their performance and computational cost. We consider a translation-based pipeline, LoRA finetuning, and a two-stage finetuning strategy that separates vision adaptation from language adaptation. To evaluate these methods, we use a combination of standard multimodal benchmarks translated into the target language and manual assessments by native experts. The results reveal that dataset translation remains a major bottleneck in multilingual VLM performance, with data quality limiting the effectiveness of training and evaluation. These findings suggest that future efforts should focus on native-language dataset collection and improved translation strategies.\nüìÑ Download PDF\nLLM-PEA: Leveraging Large Language Models Against Phishing Email Attacks Authors: Najmul Hassan, Prashanth BusiReddyGari, Haitao Zhao, Yihao Ren, Jinsheng Xu, Shaohu Zhang Venue: arXiv (2025)\nEmail phishing is one of the most prevalent and globally consequential vectors of cyber intrusion. As systems increasingly deploy Large Language Models (LLMs) applications, these systems face evolving phishing email threats that exploit their fundamental architectures. Current LLMs require substantial hardening before deployment in email security systems, particularly against coordinated multi-vector attacks that exploit architectural vulnerabilities. This paper proposes LLMPEA, an LLM-based framework to detect phishing email attacks across multiple attack vectors, including prompt injection, text refinement, and multilingual attacks. We evaluate three frontier LLMs (e.g., GPT-4o, Claude Sonnet 4, and Grok-3) and comprehensive prompting design to assess their feasibility, robustness, and limitations against phishing email attacks. Our empirical analysis reveals that LLMs can detect the phishing email over 90% accuracy while we also highlight that LLM-based phishing email detection systems could be exploited by adversarial attack, prompt injection, and multilingual attacks. Our findings provide critical insights for LLM-based phishing detection in real-world settings where attackers exploit multiple vulnerabilities in combination.\nüìÑ Download PDF\nMitigating Social Bias in English and Urdu Language Models Using PRM-Guided Candidate Selection and Sequential Refinement Authors: Muneeb Ur Raheem Khan Venue: arXiv (2025)\nLarge language models (LLMs) increasingly mediate human communication, decision support, content creation, and information retrieval. Despite impressive fluency, these systems frequently produce biased or stereotypical content, especially when prompted with socially sensitive language. A growing body of research has demonstrated that such biases disproportionately affect low-resource languages, where training data is limited and culturally unrepresentative. This paper presents a comprehensive study of inference-time bias mitigation, a strategy that avoids retraining or fine-tuning and instead operates directly on model outputs. Building on preference-ranking models (PRMs), we introduce a unified evaluation framework comparing three methods: (1) baseline single-word generation, (2) PRM-Select best-of-N sampling, and (3) PRM-Sequential refinement guided by PRM critiques. We evaluate these techniques across 200 English prompts and their Urdu counterparts, designed to reflect socio-cultural contexts relevant to gender, ethnicity, religion, nationality, disability, profession, age, and socioeconomic categories. Using GPT-3.5 as a candidate generator and GPT-4o-mini as a PRM-based bias and utility scorer, we provide an extensive quantitative analysis of bias reduction, utility preservation, and cross-lingual disparities. Our findings show: (a) substantial gains over the baseline for both languages; (b) consistently lower fairness scores for Urdu across all methods, highlighting structural inequities in multilingual LLM training; and (c) distinct improvement trajectories between PRM-Select and PRM-Sequential. The study contributes an extensible methodology, interpretable metrics, and cross-lingual comparisons that can support future work on fairness evaluation in low-resource languages.\nüìÑ Download PDF\nSwissGov-RSD: A Human-annotated, Cross-lingual Benchmark for Token-level Recognition of Semantic Differences Between Related Documents Authors: Michelle Wastl, Jannis Vamvas, Rico Sennrich Venue: arXiv (2025)\nRecognizing semantic differences across documents, especially in different languages, is crucial for text generation evaluation and multilingual content alignment. However, as a standalone task it has received little attention. We address this by introducing SwissGov-RSD, the first naturalistic, document-level, cross-lingual dataset for semantic difference recognition. It encompasses a total of 224 multi-parallel documents in English-German, English-French, and English-Italian with token-level difference annotations by human annotators. We evaluate a variety of open-source and closed source large language models as well as encoder models across different fine-tuning settings on this new benchmark. Our results show that current automatic approaches perform poorly compared to their performance on monolingual, sentence-level, and synthetic benchmarks, revealing a considerable gap for both LLMs and encoder models. We make our code and datasets publicly available.\nüìÑ Download PDF\nPersian-Phi: Efficient Cross-Lingual Adaptation of Compact LLMs via Curriculum Learning Authors: Amir Mohammad Akhlaghi, Amirhossein Shabani, Mostafa Abdolmaleki, Saeed Reza Kheradpisheh Venue: arXiv (2025)\nThe democratization of AI is currently hindered by the immense computational costs required to train Large Language Models (LLMs) for low-resource languages. This paper presents Persian-Phi, a 3.8B parameter model that challenges the assumption that robust multilingual capabilities require massive model sizes or multilingual baselines. We demonstrate how Microsoft Phi-3 Mini ‚Äì originally a monolingual English model ‚Äì can be effectively adapted to Persian through a novel, resource-efficient curriculum learning pipeline. Our approach employs a unique ‚Äúwarm-up‚Äù stage using bilingual narratives (Tiny Stories) to align embeddings prior to heavy training, followed by continual pretraining and instruction tuning via Parameter-Efficient Fine-Tuning (PEFT). Despite its compact size, Persian-Phi achieves competitive results on Open Persian LLM Leaderboard in HuggingFace. Our findings provide a validated, scalable framework for extending the reach of state-of-the-art LLMs to underrepresented languages with minimal hardware resources. The Persian-Phi model is publicly available at https://huggingface.co/amirakhlaghiqqq/PersianPhi.\nüìÑ Download PDF\nEfficient ASR for Low-Resource Languages: Leveraging Cross-Lingual Unlabeled Data Authors: Srihari Bandarupalli, Bhavana Akkiraju, Charan Devarakonda, Vamsiraghusimha Narsinga, Anil Kumar Vuppala Venue: arXiv (2025)\nAutomatic speech recognition for low-resource languages remains fundamentally constrained by the scarcity of labeled data and computational resources required by state-of-the-art models. We present a systematic investigation into cross-lingual continuous pretraining for low-resource languages, using Perso-Arabic languages (Persian, Arabic, and Urdu) as our primary case study. Our approach demonstrates that strategic utilization of unlabeled speech data can effectively bridge the resource gap without sacrificing recognition accuracy. We construct a 3,000-hour multilingual corpus through a scalable unlabeled data collection pipeline and employ targeted continual pretraining combined with morphologically-aware tokenization to develop a 300M parameter model that achieves performance comparable to systems 5 times larger. Our model outperforms Whisper Large v3 (1.5B parameters) on Persian and achieves competitive results on Arabic and Urdu despite using significantly fewer parameters and substantially less labeled data. These findings challenge the prevailing assumption that ASR quality scales primarily with model size, revealing instead that data relevance and strategic pretraining are more critical factors for low-resource scenarios. This work provides a practical pathway toward inclusive speech technology, enabling effective ASR for underrepresented languages without dependence on massive computational infrastructure or proprietary datasets.\nüìÑ Download PDF\nCross-platform Product Matching Based on Entity Alignment of Knowledge Graph with RAEA model Authors: Wenlong Liu, Jiahua Pan, Xingyu Zhang, Xinxin Gong, Yang Ye, Xujin Zhao, Xin Wang, Kent Wu, Hua Xiang, Houmin Yan, Qingpeng Zhang Venue: arXiv (2025)\nProduct matching aims to identify identical or similar products sold on different platforms. By building knowledge graphs (KGs), the product matching problem can be converted to the Entity Alignment (EA) task, which aims to discover the equivalent entities from diverse KGs. The existing EA methods inadequately utilize both attribute triples and relation triples simultaneously, especially the interactions between them. This paper introduces a two-stage pipeline consisting of rough filter and fine filter to match products from eBay and Amazon. For fine filtering, a new framework for Entity Alignment, Relation-aware and Attribute-aware Graph Attention Networks for Entity Alignment (RAEA), is employed. RAEA focuses on the interactions between attribute triples and relation triples, where the entity representation aggregates the alignment signals from attributes and relations with Attribute-aware Entity Encoder and Relation-aware Graph Attention Networks. The experimental results indicate that the RAEA model achieves significant improvements over 12 baselines on EA task in the cross-lingual dataset DBP15K (6.59% on average Hits@1) and delivers competitive results in the monolingual dataset DWY100K. The source code for experiments on DBP15K and DWY100K is available at github (https://github.com/Mockingjay-liu/RAEA-model-for-Entity-Alignment).\nüìÑ Download PDF\nMASim: Multilingual Agent-Based Simulation for Social Science Authors: Xuan Zhang, Wenxuan Zhang, Anxu Wang, See-Kiong Ng, Yang Deng Venue: arXiv (2025)\nMulti-agent role-playing has recently shown promise for studying social behavior with language agents, but existing simulations are mostly monolingual and fail to model cross-lingual interaction, an essential property of real societies. We introduce MASim, the first multilingual agent-based simulation framework that supports multi-turn interaction among generative agents with diverse sociolinguistic profiles. MASim offers two key analyses: (i) global public opinion modeling, by simulating how attitudes toward open-domain hypotheses evolve across languages and cultures, and (ii) media influence and information diffusion, via autonomous news agents that dynamically generate content and shape user behavior. To instantiate simulations, we construct the MAPS benchmark, which combines survey questions and demographic personas drawn from global population distributions. Experiments on calibration, sensitivity, consistency, and cultural case studies show that MASim reproduces sociocultural phenomena and highlights the importance of multilingual simulation for scalable, controlled computational social science.\nüìÑ Download PDF\nMind the Gap! Pathways Towards Unifying AI Safety and Ethics Research Authors: Dani Roytburg, Beck Miller Venue: arXiv (2025)\nWhile much research in artificial intelligence (AI) has focused on scaling capabilities, the accelerating pace of development makes countervailing work on producing harmless, ‚Äúaligned‚Äù systems increasingly urgent. Yet research on alignment has diverged along two largely parallel tracks: safety‚Äìcentered on scaled intelligence, deceptive or scheming behaviors, and existential risk‚Äìand ethics‚Äìfocused on present harms, the reproduction of social bias, and flaws in production pipelines. Although both communities warn of insufficient investment in alignment, they disagree on what alignment means or ought to mean. As a result, their efforts have evolved in relative isolation, shaped by distinct methodologies, institutional homes, and disciplinary genealogies. We present a large-scale, quantitative study showing the structural split between AI safety and AI ethics. Using a bibliometric and co-authorship network analysis of 6,442 papers from twelve major ML and NLP conferences (2020-2025), we find that over 80% of collaborations occur within either the safety or ethics communities, and cross-field connectivity is highly concentrated: roughly 5% of papers account for more than 85% of bridging links. Removing a small number of these brokers sharply increases segregation, indicating that cross-disciplinary exchange depends on a handful of actors rather than broad, distributed collaboration. These results show that the safety-ethics divide is not only conceptual but institutional, with implications for research agendas, policy, and venues. We argue that integrating technical safety work with normative ethics‚Äìvia shared benchmarks, cross-institutional venues, and mixed-method methodologies‚Äìis essential for building AI systems that are both robust and just.\nüìÑ Download PDF\nLocal LLM Ensembles for Zero-shot Portuguese Named Entity Recognition Authors: Jo√£o Lucas Luz Lima Sarcinelli, Diego Furtado Silva Venue: arXiv (2025)\nLarge Language Models (LLMs) excel in many Natural Language Processing (NLP) tasks through in-context learning but often under-perform in Named Entity Recognition (NER), especially for lower-resource languages like Portuguese. While open-weight LLMs enable local deployment, no single model dominates all tasks, motivating ensemble approaches. However, existing LLM ensembles focus on text generation or classification, leaving NER under-explored. In this context, this work proposes a novel three-step ensemble pipeline for zero-shot NER using similarly capable, locally run LLMs. Our method outperforms individual LLMs in four out of five Portuguese NER datasets by leveraging a heuristic to select optimal model combinations with minimal annotated data. Moreover, we show that ensembles obtained on different source datasets generally outperform individual LLMs in cross-dataset configurations, potentially eliminating the need for annotated data for the current task. Our work advances scalable, low-resource, and zero-shot NER by effectively combining multiple small LLMs without fine-tuning. Code is available at https://github.com/Joao-Luz/local-llm-ner-ensemble.\nüìÑ Download PDF\nIF-Bench: Benchmarking and Enhancing MLLMs for Infrared Images with Generative Visual Prompting Authors: Tao Zhang, Yuyang Hong, Yang Xia, Kun Ding, Zeyu Zhang, Ying Wang, Shiming Xiang, Chunhong Pan Venue: arXiv (2025)\nRecent advances in multimodal large language models (MLLMs) have led to impressive progress across various benchmarks. However, their capability in understanding infrared images remains unexplored. To address this gap, we introduce IF-Bench, the first high-quality benchmark designed for evaluating multimodal understanding of infrared images. IF-Bench consists of 499 images sourced from 23 infrared datasets and 680 carefully curated visual question-answer pairs, covering 10 essential dimensions of image understanding. Based on this benchmark, we systematically evaluate over 40 open-source and closed-source MLLMs, employing cyclic evaluation, bilingual assessment, and hybrid judgment strategies to enhance the reliability of the results. Our analysis reveals how model scale, architecture, and inference paradigms affect infrared image comprehension, providing valuable insights for this area. Furthermore, we propose a training-free generative visual prompting (GenViP) method, which leverages advanced image editing models to translate infrared images into semantically and spatially aligned RGB counterparts, thereby mitigating domain distribution shifts. Extensive experiments demonstrate that our method consistently yields significant performance improvements across a wide range of MLLMs. The benchmark and code are available at https://github.com/casiatao/IF-Bench.\nüìÑ Download PDF\nCan LLMs Evaluate What They Cannot Annotate? Revisiting LLM Reliability in Hate Speech Detection Authors: Paloma Piot, David Otero, Patricia Mart√≠n-Rodilla, Javier Parapar Venue: arXiv (2025)\nHate speech spreads widely online, harming individuals and communities, making automatic detection essential for large-scale moderation, yet detecting it remains difficult. Part of the challenge lies in subjectivity: what one person flags as hate speech, another may see as benign. Traditional annotation agreement metrics, such as Cohen‚Äôs $Œ∫$, oversimplify this disagreement, treating it as an error rather than meaningful diversity. Meanwhile, Large Language Models (LLMs) promise scalable annotation, but prior studies demonstrate that they cannot fully replace human judgement, especially in subjective tasks. In this work, we reexamine LLM reliability using a subjectivity-aware framework, cross-Rater Reliability (xRR), revealing that even under fairer lens, LLMs still diverge from humans. Yet this limitation opens an opportunity: we find that LLM-generated annotations can reliably reflect performance trends across classification models, correlating with human evaluations. We test this by examining whether LLM-generated annotations preserve the relative ordering of model performance derived from human evaluation (i.e. whether models ranked as more reliable by human annotators preserve the same order when evaluated with LLM-generated labels). Our results show that, although LLMs differ from humans at the instance level, they reproduce similar ranking and classification patterns, suggesting their potential as proxy evaluators. While not a substitute for human annotators, they might serve as a scalable proxy for evaluation in subjective NLP tasks.\nüìÑ Download PDF\nCourtPressGER: A German Court Decision to Press Release Summarization Dataset Authors: Sebastian Nagl, Mohamed Elganayni, Melanie Pospisil, Matthias Grabmair Venue: arXiv (2025)\nOfficial court press releases from Germany‚Äôs highest courts present and explain judicial rulings to the public, as well as to expert audiences. Prior NLP efforts emphasize technical headnotes, ignoring citizen-oriented communication needs. We introduce CourtPressGER, a 6.4k dataset of triples: rulings, human-drafted press releases, and synthetic prompts for LLMs to generate comparable releases. This benchmark trains and evaluates LLMs in generating accurate, readable summaries from long judicial texts. We benchmark small and large LLMs using reference-based metrics, factual-consistency checks, LLM-as-judge, and expert ranking. Large LLMs produce high-quality drafts with minimal hierarchical performance loss; smaller models require hierarchical setups for long judgments. Initial benchmarks show varying model performance, with human-drafted releases ranking highest.\nüìÑ Download PDF\nTRIDENT: A Redundant Architecture for Caribbean-Accented Emergency Speech Triage Authors: Elroy Galbraith, Chadwick Sutherland, Donahue Morgan Venue: arXiv (2025)\nEmergency speech recognition systems exhibit systematic performance degradation on non-standard English varieties, creating a critical gap in services for Caribbean populations. We present TRIDENT (Transcription and Routing Intelligence for Dispatcher-Empowered National Triage), a three-layer dispatcher-support architecture designed to structure emergency call inputs for human application of established triage protocols (the ESI for routine operations and START for mass casualty events), even when automatic speech recognition fails. The system combines Caribbean-accent-tuned ASR, local entity extraction via large language models, and bio-acoustic distress detection to provide dispatchers with three complementary signals: transcription confidence, structured clinical entities, and vocal stress indicators. Our key insight is that low ASR confidence, rather than representing system failure, serves as a valuable queue prioritization signal ‚Äì particularly when combined with elevated vocal distress markers indicating a caller in crisis whose speech may have shifted toward basilectal registers. A complementary insight drives the entity extraction layer: trained responders and composed bystanders may report life-threatening emergencies without elevated vocal stress, requiring semantic analysis to capture clinical indicators that paralinguistic features miss. We describe the architectural design, theoretical grounding in psycholinguistic research on stress-induced code-switching, and deployment considerations for offline operation during disaster scenarios. This work establishes a framework for accent-resilient emergency AI that ensures Caribbean voices receive equitable access to established national triage protocols. Empirical validation on Caribbean emergency calls remains future work.\nüìÑ Download PDF\nTraining One Model to Master Cross-Level Agentic Actions via Reinforcement Learning Authors: Kaichen He, Zihao Wang, Muyao Li, Anji Liu, Yitao Liang Venue: arXiv (2025)\nThe paradigm of agentic AI is shifting from engineered complex workflows to post-training native models. However, existing agents are typically confined to static, predefined action spaces‚Äìsuch as exclusively using APIs, GUI events, or robotic commands. This rigidity limits their adaptability in dynamic environments where the optimal granularity of interaction varies contextually. To bridge this gap, we propose CrossAgent, a unified agentic model that masters heterogeneous action spaces and autonomously selects the most effective interface for each step of a trajectory. We introduce a comprehensive training pipeline that integrates cold-start supervised fine-tuning with a Multi-Turn Group Relative Policy Optimization (GRPO) algorithm. This approach enables the agent to learn adaptive action switching‚Äìbalancing high-level efficiency with low-level precision‚Äìwithout human-specified rules. Extensive experiments on over 800 tasks in the open-world Minecraft environment demonstrate that CrossAgent achieves state-of-the-art performance. By dynamically leveraging the strengths of diverse action spaces, our model significantly outperforms fixed-action baselines, exhibiting superior generalization and efficiency in long-horizon reasoning. All code and models are available at https://github.com/CraftJarvis/OpenHA\nüìÑ Download PDF\nStraggler Tolerant and Resilient DL Training on Homogeneous GPUs Authors: Zeyu Zhang, Haiying Shen Venue: arXiv (2025)\nDespite the popularity of homogeneous GPU-based deep learning (DL) training, the prevalence, causes and impact of stragglers and the effectiveness of existing straggler mitigation approaches are still not well understood in this scenario due to limited research on these questions. To fill this gap, we conducted comprehensive experiments and found that stragglers remain widespread due to CPU and bandwidth usage imbalances. Additionally, existing mitigation methods that switch from synchronous stochastic gradient descent (SSGD) to asynchronous SGD (ASGD) may not improve Time-To-Accuracy (TTA) and can even generate more stragglers due to its higher resource consumption. To address these newly found problems, we propose the Straggler Tolerant And Resilient DL training system (STAR). STAR includes new synchronization modes that group workers for each parameter updating. It has a heuristic and an ML method to choose the optimal synchronization mode for minimizing TTA, and reallocates resources to support the selected mode while minimizing the impact on co-located jobs. Moreover, it proactively prevents stragglers by avoiding overloading the CPU and bandwidth resources in allocating PSs (which consume high CPU and bandwidth) and in gradient transmission. Our trace-driven evaluation on AWS shows that STAR generates 48-84% and 51-70% lower TTA than state-of-the-art systems in the PS and all-reduce architectures, respectively, while maintaining the converged accuracy of SSGD. The code for STAR is open-sourced.\nüìÑ Download PDF\nREASAN: Learning Reactive Safe Navigation for Legged Robots Authors: Qihao Yuan, Ziyu Cao, Ming Cao, Kailai Li Venue: arXiv (2025)\nWe present a novel modularized end-to-end framework for legged reactive navigation in complex dynamic environments using a single light detection and ranging (LiDAR) sensor. The system comprises four simulation-trained modules: three reinforcement-learning (RL) policies for locomotion, safety shielding, and navigation, and a transformer-based exteroceptive estimator that processes raw point-cloud inputs. This modular decomposition of complex legged motor-control tasks enables lightweight neural networks with simple architectures, trained using standard RL practices with targeted reward shaping and curriculum design, without reliance on heuristics or sophisticated policy-switching mechanisms. We conduct comprehensive ablations to validate our design choices and demonstrate improved robustness compared to existing approaches in challenging navigation tasks. The resulting reactive safe navigation (REASAN) system achieves fully onboard and real-time reactive navigation across both single- and multi-robot settings in complex environments. We release our training and deployment code at https://github.com/ASIG-X/REASAN.\nüìÑ Download PDF\nBasic Lock Algorithms in Lightweight Thread Environments Authors: Taras Skazhenik, Nikolai Korobenikov, Andrei Churbanov, Anton Malakhov, Vitaly Aksenov Venue: arXiv (2025)\nTraditionally, multithreaded data structures have been designed for access by the threads of Operating Systems (OS). However, implementations for access by programmable alternatives known as lightweight threads (also referred to as asynchronous calls or coroutines) have not been thoroughly studied. The main advantage of lightweight threads is their significantly lower overhead during launch and context switching. However, this comes at a cost: to achieve proper parallelism, context switches must be manually invoked in the code; without these switches, new lightweight threads will never be executed. In this paper, we focus on the simplest multithreaded data structure: a mutex (also known as a lock). We demonstrate that original implementations for OS threads cannot be used effectively in this new context due to the potential for deadlocks. Furthermore, correctness is not the only concern. In certain languages, such as C++, there are various lightweight thread libraries, each with different implementations and interfaces, which necessitate distinct lock implementations. In this work, we present a modification of TTAS and MCS locks for the use from lightweight threads and demonstrate that the two context switch mechanisms of lightweight threads, yielding and sleeping, are crucial. However, the performance of TTAS and MCS may differ significantly depending on the settings. If one wants to have a lock that works well for any library, we suggest using the cohort lock, which strikes a balance between MCS and TTAS by utilizing several MCS queues with a common TTAS.\nüìÑ Download PDF\nPolyLingua: Margin-based Inter-class Transformer for Robust Cross-domain Language Detection Authors: Ali Lotfi Rezaabad, Bikram Khanal, Shashwat Chaurasia, Lu Zeng, Dezhi Hong, Hossein Bashashati, Thomas Butler, Megan Ganji Venue: arXiv (2025)\nLanguage identification is a crucial first step in multilingual systems such as chatbots and virtual assistants, enabling linguistically and culturally accurate user experiences. Errors at this stage can cascade into downstream failures, setting a high bar for accuracy. Yet, existing language identification tools struggle with key cases ‚Äì such as music requests where the song title and user language differ. Open-source tools like LangDetect, FastText are fast but less accurate, while large language models, though effective, are often too costly for low-latency or low-resource settings. We introduce PolyLingua, a lightweight Transformer-based model for in-domain language detection and fine-grained language classification. It employs a two-level contrastive learning framework combining instance-level separation and class-level alignment with adaptive margins, yielding compact and well-separated embeddings even for closely related languages. Evaluated on two challenging datasets ‚Äì Amazon Massive (multilingual digital assistant utterances) and a Song dataset (music requests with frequent code-switching) ‚Äì PolyLingua achieves 99.25% F1 and 98.15% F1, respectively, surpassing Sonnet 3.5 while using 10x fewer parameters, making it ideal for compute- and latency-constrained environments.\nüìÑ Download PDF\nOptimizing Data Extraction from Materials Science Literature: A Study of Tools Using Large Language Models Authors: Wenkai Ning, Musen Li, Jeffrey R. Reimers, Rika Kobayashi Venue: arXiv (2025)\nLarge Language Models (LLMs) are increasingly utilized for large-scale extraction and organization of unstructured data owing to their exceptional Natural Language Processing (NLP) capabilities. Empowering materials design, vast amounts of data from experiments and simulations are scattered across numerous scientific publications, but high-quality experimental databases are scarce. This study considers the effectiveness and practicality of five representative AI tools (ChemDataExtractor, BERT-PSIE, ChatExtract, LangChain, and Kimi) to extract bandgaps from 200 randomly selected Materials Science publications in two presentations (arXiv and publisher versions), comparing the results to those obtained by human processing. Although the integrity of data extraction has not met expectations, encouraging results have been achieved in terms of precision and the ability to eliminate irrelevant papers from human consideration. Our analysis highlights both the strengths and limitations of these tools, offering insights into improving future data extraction techniques for enhanced scientific discovery and innovation. In conjunction with recent research, we provide guidance on feasible improvements for future data extraction methodologies, helping to bridge the gap between unstructured scientific data and structured, actionable databases.\nüìÑ Download PDF\nEmpowering Dynamic Urban Navigation with Stereo and Mid-Level Vision Authors: Wentao Zhou, Xuweiyi Chen, Vignesh Rajagopal, Jeffrey Chen, Rohan Chandra, Zezhou Cheng Venue: arXiv (2025)\nThe success of foundation models in language and vision motivated research in fully end-to-end robot navigation foundation models (NFMs). NFMs directly map monocular visual input to control actions and ignore mid-level vision modules (tracking, depth estimation, etc) entirely. While the assumption that vision capabilities will emerge implicitly is compelling, it requires large amounts of pixel-to-action supervision that are difficult to obtain. The challenge is especially pronounced in dynamic and unstructured settings, where robust navigation requires precise geometric and dynamic understanding, while the depth-scale ambiguity in monocular views further limits accurate spatial reasoning. In this paper, we show that relying on monocular vision and ignoring mid-level vision priors is inefficient. We present StereoWalker, which augments NFMs with stereo inputs and explicit mid-level vision such as depth estimation and dense pixel tracking. Our intuition is straightforward: stereo inputs resolve the depth-scale ambiguity, and modern mid-level vision models provide reliable geometric and motion structure in dynamic scenes. We also curate a large stereo navigation dataset with automatic action annotation from Internet stereo videos to support training of StereoWalker and to facilitate future research. Through our experiments, we find that mid-level vision enables StereoWalker to achieve a comparable performance as the state-of-the-art using only 1.5% of the training data, and surpasses the state-of-the-art using the full data. We also observe that stereo vision yields higher navigation performance than monocular input.\nüìÑ Download PDF\nE-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training Authors: Qitao Zhao, Hao Tan, Qianqian Wang, Sai Bi, Kai Zhang, Kalyan Sunkavalli, Shubham Tulsiani, Hanwen Jiang Venue: arXiv (2025)\nSelf-supervised pre-training has revolutionized foundation models for languages, individual 2D images and videos, but remains largely unexplored for learning 3D-aware representations from multi-view images. In this paper, we present E-RayZer, a self-supervised large 3D Vision model that learns truly 3D-aware representations directly from unlabeled images. Unlike prior self-supervised methods such as RayZer that infer 3D indirectly through latent-space view synthesis, E-RayZer operates directly in 3D space, performing self-supervised 3D reconstruction with Explicit geometry. This formulation eliminates shortcut solutions and yields representations that are geometrically grounded. To ensure convergence and scalability, we introduce a novel fine-grained learning curriculum that organizes training from easy to hard samples and harmonizes heterogeneous data sources in an entirely unsupervised manner. Experiments demonstrate that E-RayZer significantly outperforms RayZer on pose estimation, matches or sometimes surpasses fully supervised reconstruction models such as VGGT. Furthermore, its learned representations outperform leading visual pre-training models (e.g., DINOv3, CroCo v2, VideoMAE V2, and RayZer) when transferring to 3D downstream tasks, establishing E-RayZer as a new paradigm for 3D-aware visual pre-training.\nüìÑ Download PDF\nAre We Ready for RL in Text-to-3D Generation? A Progressive Investigation Authors: Yiwen Tang, Zoey Guo, Kaixin Zhu, Ray Zhang, Qizhi Chen, Dongzhi Jiang, Junli Liu, Bohan Zeng, Haoming Song, Delin Qu, Tianyi Bai, Dan Xu, Wentao Zhang, Bin Zhao Venue: arXiv (2025)\nReinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.\nüìÑ Download PDF\nTowards Efficient and Effective Multi-Camera Encoding for End-to-End Driving Authors: Jiawei Yang, Ziyu Chen, Yurong You, Yan Wang, Yiming Li, Yuxiao Chen, Boyi Li, Boris Ivanovic, Marco Pavone, Yue Wang Venue: arXiv (2025)\nWe present Flex, an efficient and effective scene encoder that addresses the computational bottleneck of processing high-volume multi-camera data in end-to-end autonomous driving. Flex employs a small set of learnable scene tokens to jointly encode information from all image tokens across different cameras and timesteps. By design, our approach is geometry-agnostic, learning a compact scene representation directly from data without relying on the explicit 3D inductive biases, such as Bird-Eye-View (BEV), occupancy or tri-plane representations, which are common in prior work. This holistic encoding strategy aggressively compresses the visual input for the downstream Large Language Model (LLM) based policy model. Evaluated on a large-scale proprietary dataset of 20,000 driving hours, our Flex achieves 2.2x greater inference throughput while improving driving performance by a large margin compared to state-of-the-art methods. Furthermore, we show that these compact scene tokens develop an emergent capability for scene decomposition without any explicit supervision. Our findings challenge the prevailing assumption that 3D priors are necessary, demonstrating that a data-driven, joint encoding strategy offers a more scalable, efficient and effective path for future autonomous driving systems.\nüìÑ Download PDF\nMeViS: A Multi-Modal Dataset for Referring Motion Expression Video Segmentation Authors: Henghui Ding, Chang Liu, Shuting He, Kaining Ying, Xudong Jiang, Chen Change Loy, Yu-Gang Jiang Venue: arXiv (2025)\nThis paper proposes a large-scale multi-modal dataset for referring motion expression video segmentation, focusing on segmenting and tracking target objects in videos based on language description of objects‚Äô motions. Existing referring video segmentation datasets often focus on salient objects and use language expressions rich in static attributes, potentially allowing the target object to be identified in a single frame. Such datasets underemphasize the role of motion in both videos and languages. To explore the feasibility of using motion expressions and motion reasoning clues for pixel-level video understanding, we introduce MeViS, a dataset containing 33,072 human-annotated motion expressions in both text and audio, covering 8,171 objects in 2,006 videos of complex scenarios. We benchmark 15 existing methods across 4 tasks supported by MeViS, including 6 referring video object segmentation (RVOS) methods, 3 audio-guided video object segmentation (AVOS) methods, 2 referring multi-object tracking (RMOT) methods, and 4 video captioning methods for the newly introduced referring motion expression generation (RMEG) task. The results demonstrate weaknesses and limitations of existing methods in addressing motion expression-guided video understanding. We further analyze the challenges and propose an approach LMPM++ for RVOS/AVOS/RMOT that achieves new state-of-the-art results. Our dataset provides a platform that facilitates the development of motion expression-guided video understanding algorithms in complex video scenes. The proposed MeViS dataset and the method‚Äôs source code are publicly available at https://henghuiding.com/MeViS/\nüìÑ Download PDF\nVL-JEPA: Joint Embedding Predictive Architecture for Vision-language Authors: Delong Chen, Mustafa Shukor, Theo Moutakanni, Willy Chung, Jade Yu, Tejaswi Kasarla, Allen Bolourchi, Yann LeCun, Pascale Fung Venue: arXiv (2025)\nWe introduce VL-JEPA, a vision-language model built on a Joint Embedding Predictive Architecture (JEPA). Instead of autoregressively generating tokens as in classical VLMs, VL-JEPA predicts continuous embeddings of the target texts. By learning in an abstract representation space, the model focuses on task-relevant semantics while abstracting away surface-level linguistic variability. In a strictly controlled comparison against standard token-space VLM training with the same vision encoder and training data, VL-JEPA achieves stronger performance while having 50% fewer trainable parameters. At inference time, a lightweight text decoder is invoked only when needed to translate VL-JEPA predicted embeddings into text. We show that VL-JEPA natively supports selective decoding that reduces the number of decoding operations by 2.85x while maintaining similar performance compared to non-adaptive uniform decoding. Beyond generation, the VL-JEPA‚Äôs embedding space naturally supports open-vocabulary classification, text-to-video retrieval, and discriminative VQA without any architecture modification. On eight video classification and eight video retrieval datasets, the average performance VL-JEPA surpasses that of CLIP, SigLIP2, and Perception Encoder. At the same time, the model achieves comparable performance as classical VLMs (InstructBLIP, QwenVL) on four VQA datasets: GQA, TallyQA, POPE and POPEv2, despite only having 1.6B parameters.\nüìÑ Download PDF\nHierarchical Dataset Selection for High-Quality Data Sharing Authors: Xiaona Zhou, Yingyan Zeng, Ran Jin, Ismini Lourentzou Venue: arXiv (2025)\nThe success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.\nüìÑ Download PDF\nOmni-Attribute: Open-vocabulary Attribute Encoder for Visual Concept Personalization Authors: Tsai-Shien Chen, Aliaksandr Siarohin, Guocheng Gordon Qian, Kuan-Chieh Jackson Wang, Egor Nemchinov, Moayed Haji-Ali, Riza Alp Guler, Willi Menapace, Ivan Skorokhodov, Anil Kag, Jun-Yan Zhu, Sergey Tulyakov Venue: arXiv (2025)\nVisual concept personalization aims to transfer only specific image attributes, such as identity, expression, lighting, and style, into unseen contexts. However, existing methods rely on holistic embeddings from general-purpose image encoders, which entangle multiple visual factors and make it difficult to isolate a single attribute. This often leads to information leakage and incoherent synthesis. To address this limitation, we introduce Omni-Attribute, the first open-vocabulary image attribute encoder designed to learn high-fidelity, attribute-specific representations. Our approach jointly designs the data and model: (i) we curate semantically linked image pairs annotated with positive and negative attributes to explicitly teach the encoder what to preserve or suppress; and (ii) we adopt a dual-objective training paradigm that balances generative fidelity with contrastive disentanglement. The resulting embeddings prove effective for open-vocabulary attribute retrieval, personalization, and compositional generation, achieving state-of-the-art performance across multiple benchmarks.\nüìÑ Download PDF\nCurriculum-Based Reinforcement Learning for Autonomous UAV Navigation in Unknown Curved Tubular Conduit Authors: Zamirddine Mari, J√©r√¥me Pasquet, Julien Seinturier Venue: arXiv (2025)\nAutonomous drone navigation in confined tubular environments remains a major challenge due to the constraining geometry of the conduits, the proximity of the walls, and the perceptual limitations inherent to such scenarios. We propose a reinforcement learning approach enabling a drone to navigate unknown three-dimensional tubes without any prior knowledge of their geometry, relying solely on local observations from LiDAR and a conditional visual detection of the tube center. In contrast, the Pure Pursuit algorithm, used as a deterministic baseline, benefits from explicit access to the centerline, creating an information asymmetry designed to assess the ability of RL to compensate for the absence of a geometric model. The agent is trained through a progressive Curriculum Learning strategy that gradually exposes it to increasingly curved geometries, where the tube center frequently disappears from the visual field. A turning-negotiation mechanism, based on the combination of direct visibility, directional memory, and LiDAR symmetry cues, proves essential for ensuring stable navigation under such partial observability conditions. Experiments show that the PPO policy acquires robust and generalizable behavior, consistently outperforming the deterministic controller despite its limited access to geometric information. Validation in a high-fidelity 3D environment further confirms the transferability of the learned behavior to a continuous physical dynamics. The proposed approach thus provides a complete framework for autonomous navigation in unknown tubular environments and opens perspectives for industrial, underground, or medical applications where progressing through narrow and weakly perceptive conduits represents a central challenge.\nüìÑ Download PDF\nDigital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation Authors: Zamirddine Mari, Mohamad Motasem Nawaf, Pierre Drap Venue: arXiv (2025)\nAutonomous navigation in underwater environments remains a major challenge due to the absence of GPS, degraded visibility, and the presence of submerged obstacles. This article investigates these issues through the case of the BlueROV2, an open platform widely used for scientific experimentation. We propose a deep reinforcement learning approach based on the Proximal Policy Optimization (PPO) algorithm, using an observation space that combines target-oriented navigation information, a virtual occupancy grid, and ray-casting along the boundaries of the operational area. The learned policy is compared against a reference deterministic kinematic planner, the Dynamic Window Approach (DWA), commonly employed as a robust baseline for obstacle avoidance. The evaluation is conducted in a realistic simulation environment and complemented by validation on a physical BlueROV2 supervised by a 3D digital twin of the test site, helping to reduce risks associated with real-world experimentation. The results show that the PPO policy consistently outperforms DWA in highly cluttered environments, notably thanks to better local adaptation and reduced collisions. Finally, the experiments demonstrate the transferability of the learned behavior from simulation to the real world, confirming the relevance of deep RL for autonomous navigation in underwater robotics.\nüìÑ Download PDF\nPhysics-Informed Learning of Flow Distribution and Receiver Heat Losses in Parabolic Trough Solar Fields Authors: Stefan Matthes, Markus Schramm Venue: arXiv (2025)\nParabolic trough Concentrating Solar Power (CSP) plants operate large hydraulic networks of collector loops that must deliver a uniform outlet temperature despite spatially heterogeneous optical performance, heat losses, and pressure drops. While loop temperatures are measured, loop-level mass flows and receiver heat-loss parameters are unobserved, making it impossible to diagnose hydraulic imbalances or receiver degradation using standard monitoring tools. We present a physics-informed learning framework that infers (i) loop-level mass-flow ratios and (ii) time-varying receiver heat-transfer coefficients directly from routine operational data. The method exploits nocturnal homogenization periods ‚Äì when hot oil is circulated through a non-irradiated field ‚Äì to isolate hydraulic and thermal-loss effects. A differentiable conjugate heat-transfer model is discretized and embedded into an end-to-end learning pipeline optimized using historical plant data from the 50 MW Andasol 3 solar field. The model accurately reconstructs loop temperatures (RMSE $\u003c2^\\circ$C) and produces physically meaningful estimates of loop imbalances and receiver heat losses. Comparison against drone-based infrared thermography (QScan) shows strong correspondence, correctly identifying all areas with high-loss receivers. This demonstrates that noisy real-world CSP operational data contain enough information to recover latent physical parameters when combined with appropriate modeling and differentiable optimization.\nüìÑ Download PDF\nGuided Transfer Learning for Discrete Diffusion Models Authors: Julian Kleutgens, Claudio Battiloro, Lingkai Kong, Benjamin Grewe, Francesca Dominici, Mauricio Tec Venue: arXiv (2025)\nDiscrete diffusion models achieve strong performance across language and other discrete domains, providing a powerful alternative to autoregressive models. However, their strong performance relies on large training datasets, which are costly or risky to obtain, especially when adapting to new domains. Transfer learning is the natural way to adapt pretrained discrete diffusion models, but current methods require fine-tuning large diffusion models, which is computationally expensive and often impractical. Building on ratio-based transfer learning for continuous diffusion, we provide Guided Transfer Learning for discrete diffusion models (GTL). This enables sampling from a target distribution without modifying the pretrained denoiser. The same guidance formulation applies to both discrete-time diffusion and continuous-time score-based discrete diffusion, yielding a unified treatment. Guided discrete diffusion often requires many forward passes of the guidance network, which becomes impractical for large vocabularies and long sequences. To address this, we further present an efficient guided sampler that concentrates evaluations on planner-selected positions and top candidate tokens, thus lowering sampling time and computation. This makes guided language modeling practical at scale for large vocabularies and long sequences. We evaluate GTL on sequential data, including synthetic Markov chains and language modeling, and provide empirical analyses of its behavior.\nüìÑ Download PDF\nWorldLens: Full-Spectrum Evaluations of Driving World Models in Real World Authors: Ao Liang, Lingdong Kong, Tianyi Yan, Hongsi Liu, Wesley Yang, Ziqi Huang, Wei Yin, Jialong Zuo, Yixuan Hu, Dekai Zhu, Dongyue Lu, Youquan Liu, Guangfeng Jiang, Linfeng Li, Xiangtai Li, Long Zhuo, Lai Xing Ng, Benoit R. Cottereau, Changxin Gao, Liang Pan, Wei Tsang Ooi, Ziwei Liu Venue: arXiv (2025)\nGenerative world models are reshaping embodied AI, enabling agents to synthesize realistic 4D driving environments that look convincing but often fail physically or behaviorally. Despite rapid progress, the field still lacks a unified way to assess whether generated worlds preserve geometry, obey physics, or support reliable control. We introduce WorldLens, a full-spectrum benchmark evaluating how well a model builds, understands, and behaves within its generated world. It spans five aspects ‚Äì Generation, Reconstruction, Action-Following, Downstream Task, and Human Preference ‚Äì jointly covering visual realism, geometric consistency, physical plausibility, and functional reliability. Across these dimensions, no existing world model excels universally: those with strong textures often violate physics, while geometry-stable ones lack behavioral fidelity. To align objective metrics with human judgment, we further construct WorldLens-26K, a large-scale dataset of human-annotated videos with numerical scores and textual rationales, and develop WorldLens-Agent, an evaluation model distilled from these annotations to enable scalable, explainable scoring. Together, the benchmark, dataset, and agent form a unified ecosystem for measuring world fidelity ‚Äì standardizing how future models are judged not only by how real they look, but by how real they behave.\nüìÑ Download PDF\nEvidence of galaxy cluster rotation in the cosmic microwave background Authors: Samuel Goldstein, J. Colin Hill Venue: arXiv (2025)\nWe report the first robust evidence for the rotational kinematic Sunyaev-Zel‚Äôdovich (rkSZ) effect, produced by the Thomson scattering of cosmic microwave background (CMB) photons off rotating intracluster gas. By combining CMB intensity and polarization measurements from the $\\it{Planck}$ satellite with spectroscopic member-galaxy redshifts from the Sloan Digital Sky Survey in a sample of 25 X-ray cross-matched, low-redshift ($0.02\u003c z\u003c 0.09)$, massive ($10^{13.9}\\lesssim M_{\\rm 500c}/M_\\odot \\lesssim 10^{14.6}$) galaxy clusters, we detect a dipolar rkSZ signature aligned with the estimated rotation direction of each cluster, ruling out a chance fluctuation at 99.98% confidence (3.6$œÉ$). The significance of this measurement is enhanced by several new methodological improvements for isolating the rkSZ signal from primary CMB fluctuations and noise. The amplitude and shape of the signal are qualitatively consistent with predictions from state-of-the-art hydrodynamical simulations. These results establish a new tool with which to probe the dynamical state of galaxy clusters using CMB data.\nüìÑ Download PDF\nBabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models Authors: Shengao Wang, Wenqi Wang, Zecheng Wang, Max Whitton, Michael Wakeham, Arjun Chandra, Joey Huang, Pengyue Zhu, Helen Chen, David Li, Jeffrey Li, Shawn Li, Andrew Zagula, Amy Zhao, Andrew Zhu, Sayaka Nakamura, Yuki Yamamoto, Jerry Jun Yokono, Aaron Mueller, Bryan A. Plummer, Kate Saenko, Venkatesh Saligrama, Boqing Gong Venue: arXiv (2025)\nEarly children‚Äôs developmental trajectories set up a natural goal for sample-efficient pretraining of vision foundation models. We introduce BabyVLM-V2, a developmentally grounded framework for infant-inspired vision-language modeling that extensively improves upon BabyVLM-V1 through a longitudinal, multifaceted pretraining set, a versatile model, and, most importantly, DevCV Toolbox for cognitive evaluation. The pretraining set maximizes coverage while minimizing curation of a longitudinal, infant-centric audiovisual corpus, yielding video-utterance, image-utterance, and multi-turn conversational data that mirror infant experiences. DevCV Toolbox adapts all vision-related measures of the recently released NIH Baby Toolbox into a benchmark suite of ten multimodal tasks, covering spatial reasoning, memory, and vocabulary understanding aligned with early children‚Äôs capabilities. Experimental results show that a compact model pretrained from scratch can achieve competitive performance on DevCV Toolbox, outperforming GPT-4o on some tasks. We hope the principled, unified BabyVLM-V2 framework will accelerate research in developmentally plausible pretraining of vision foundation models.\nüìÑ Download PDF\nDuetSVG: Unified Multimodal SVG Generation with Internal Visual Guidance Authors: Peiying Zhang, Nanxuan Zhao, Matthew Fisher, Yiran Xu, Jing Liao, Difan Liu Venue: arXiv (2025)\nRecent vision-language model (VLM)-based approaches have achieved impressive results on SVG generation. However, because they generate only text and lack visual signals during decoding, they often struggle with complex semantics and fail to produce visually appealing or geometrically coherent SVGs. We introduce DuetSVG, a unified multimodal model that jointly generates image tokens and corresponding SVG tokens in an end-to-end manner. DuetSVG is trained on both image and SVG datasets. At inference, we apply a novel test-time scaling strategy that leverages the model‚Äôs native visual predictions as guidance to improve SVG decoding quality. Extensive experiments show that our method outperforms existing methods, producing visually faithful, semantically aligned, and syntactically clean SVGs across a wide range of applications.\nüìÑ Download PDF\nTwo-Dimensional Projective Collapse and Sharp Distortion Bounds for Products of Positive Matrices Authors: Eugene Kritchevski Venue: arXiv (2025)\nWe introduce an elementary framework that captures the mechanism driving the alignment of rows and columns in products of positive matrices. All worst-case misalignment occurs already in dimension two, leading to an explicit collapse principle and a sharp nonlinear bound for finite products. The proof avoids Hilbert-metric and cone-theoretic techniques, relying instead on basic calculus. In the Hilbert metric, the classical Birkhoff-Bushell contraction captures only the linearized asymptotic regime, whereas our nonlinear envelope function gives the exact worst-case behavior for finite products.\nüìÑ Download PDF\nA Stellar Magnesium to Silicon ratio in the atmosphere of an exoplanet Authors: Jorge A. Sanchez, Peter C. B. Smith, Krishna Kanumalla, Luis Welbanks, Michael R. Line, Stefan Pelletier, Steven Desch, Patrick Young, Jennifer Patience, Jacob Bean, Matteo Brogi, Dan Jaffe, Gregory N. Mace, Megan Weiner Mansfield, Vatsal Panwar, Vivien Parmentier, Lorenzo Pino, Arjun Baliga Savel, Lennart van Sluijs, Joost P. Wardenier Venue: arXiv (2025)\nThe elemental compositions of exoplanets encode information about their formation environments and internal structures. While volatile ratios such as carbon-to-oxygen (C/O) are used to trace formation location, the rock-forming elements - magnesium (Mg), silicon (Si), and iron (Fe) - govern interior mineralogy and are commonly assumed to reflect the host star‚Äôs abundances. Yet this assumption remains largely untested. Ultra-hot Jupiters, gas-giant exoplanets with dayside temperatures above 3000 K, provide rare access to refractory elements that remain gaseous. Here we present high-resolution thermal emission spectroscopy of the exoplanet WASP-189b (Teq = 3354^{+27}_{-34} K) obtained with the Immersion Grating Infrared Spectrometer (IGRINS) on Gemini South. We detect neutral iron (Fe I), magnesium (Mg I), silicon (Si I), water (H_2O), carbon monoxide (CO), and hydroxyl (OH) at signal-to-noise ratios exceeding 4, and retrieve their elemental abundances. We show that the Mg/Si, Fe/Mg, and Si/Fe ratios are consistent with stellar values, while the refractory-to-volatile ratio is enhanced by roughly a factor of ~2. These findings demonstrate that giant-planet atmospheres can preserve stellar-like rock-forming ratios, providing an empirical validation of the stellar-proxy assumption that underpins planetary composition and formation models across exoplanet systems.\nüìÑ Download PDF\nReplace, Don‚Äôt Expand: Mitigating Context Dilution in Multi-Hop RAG via Fixed-Budget Evidence Assembly Authors: Moshe Lahmy, Roi Yozevitch Venue: arXiv (2025)\nRetrieval-Augmented Generation (RAG) systems often fail on multi-hop queries when the initial retrieval misses a bridge fact. Prior corrective approaches, such as Self-RAG, CRAG, and Adaptive-$k$, typically address this by \\textit{adding} more context or pruning existing lists. However, simply expanding the context window often leads to \\textbf{context dilution}, where distractors crowd out relevant information. We propose \\textbf{SEAL-RAG}, a training-free controller that adopts a \\textbf{``replace, don‚Äôt expand‚Äô‚Äô} strategy to fight context dilution under a fixed retrieval depth $k$. SEAL executes a (\\textbf{S}earch $\\rightarrow$ \\textbf{E}xtract $\\rightarrow$ \\textbf{A}ssess $\\rightarrow$ \\textbf{L}oop) cycle: it performs on-the-fly, entity-anchored extraction to build a live \\textit{gap specification} (missing entities/relations), triggers targeted micro-queries, and uses \\textit{entity-first ranking} to actively swap out distractors for gap-closing evidence. We evaluate SEAL-RAG against faithful re-implementations of Basic RAG, CRAG, Self-RAG, and Adaptive-$k$ in a shared environment on \\textbf{HotpotQA} and \\textbf{2WikiMultiHopQA}. On HotpotQA ($k=3$), SEAL improves answer correctness by \\textbf{+3‚Äì13 pp} and evidence precision by \\textbf{+12‚Äì18 pp} over Self-RAG. On 2WikiMultiHopQA ($k=5$), it outperforms Adaptive-$k$ by \\textbf{+8.0 pp} in accuracy and maintains \\textbf{96%} evidence precision compared to 22% for CRAG. These gains are statistically significant ($p\u003c0.001$). By enforcing fixed-$k$ replacement, SEAL yields a predictable cost profile while ensuring the top-$k$ slots are optimized for precision rather than mere breadth. We release our code and data at https://github.com/mosherino/SEAL-RAG.\nüìÑ Download PDF\nRethinking Popularity Bias in Collaborative Filtering via Analytical Vector Decomposition Authors: Lingfeng Liu, Yixin Song, Dazhong Shen, Bing Yin, Hao Li, Yanyong Zhang, Chao Wang Venue: arXiv (2025)\nPopularity bias fundamentally undermines the personalization capabilities of collaborative filtering (CF) models, causing them to disproportionately recommend popular items while neglecting users‚Äô genuine preferences for niche content. While existing approaches treat this as an external confounding factor, we reveal that popularity bias is an intrinsic geometric artifact of Bayesian Pairwise Ranking (BPR) optimization in CF models. Through rigorous mathematical analysis, we prove that BPR systematically organizes item embeddings along a dominant ‚Äúpopularity direction‚Äù where embedding magnitudes directly correlate with interaction frequency. This geometric distortion forces user embeddings to simultaneously handle two conflicting tasks-expressing genuine preference and calibrating against global popularity-trapping them in suboptimal configurations that favor popular items regardless of individual tastes. We propose Directional Decomposition and Correction (DDC), a universally applicable framework that surgically corrects this embedding geometry through asymmetric directional updates. DDC guides positive interactions along personalized preference directions while steering negative interactions away from the global popularity direction, disentangling preference from popularity at the geometric source. Extensive experiments across multiple BPR-based architectures demonstrate that DDC significantly outperforms state-of-the-art debiasing methods, reducing training loss to less than 5% of heavily-tuned baselines while achieving superior recommendation quality and fairness. Code is available in https://github.com/LingFeng-Liu-AI/DDC.\nüìÑ Download PDF\nLang2Motion: Bridging Language and Motion through Joint Embedding Spaces Authors: Bishoy Galoaa, Xiangyu Bai, Sarah Ostadabbas Venue: arXiv (2025)\nWe present Lang2Motion, a framework for language-guided point trajectory generation by aligning motion manifolds with joint embedding spaces. Unlike prior work focusing on human motion or video synthesis, we generate explicit trajectories for arbitrary objects using motion extracted from real-world videos via point tracking. Our transformer-based auto-encoder learns trajectory representations through dual supervision: textual motion descriptions and rendered trajectory visualizations, both mapped through CLIP‚Äôs frozen encoders. Lang2Motion achieves 34.2% Recall@1 on text-to-trajectory retrieval, outperforming video-based methods by 12.5 points, and improves motion accuracy by 33-52% (12.4 ADE vs 18.3-25.3) compared to video generation baselines. We demonstrate 88.3% Top-1 accuracy on human action recognition despite training only on diverse object motions, showing effective transfer across motion domains. Lang2Motion supports style transfer, semantic interpolation, and latent-space editing through CLIP-aligned trajectory representations.\nüìÑ Download PDF\nüîç linguistics StereoSpace: Depth-Free Synthesis of Stereo Geometry via End-to-End Diffusion in a Canonical Space Authors: Tjark Behrens, Anton Obukhov, Bingxin Ke, Fabio Tosi, Matteo Poggi, Konrad Schindler Venue: arXiv (2025)\nWe introduce StereoSpace, a diffusion-based framework for monocular-to-stereo synthesis that models geometry purely through viewpoint conditioning, without explicit depth or warping. A canonical rectified space and the conditioning guide the generator to infer correspondences and fill disocclusions end-to-end. To ensure fair and leakage-free evaluation, we introduce an end-to-end protocol that excludes any ground truth or proxy geometry estimates at test time. The protocol emphasizes metrics reflecting downstream relevance: iSQoE for perceptual comfort and MEt3R for geometric consistency. StereoSpace surpasses other methods from the warp \u0026 inpaint, latent-warping, and warped-conditioning categories, achieving sharp parallax and strong robustness on layered and non-Lambertian scenes. This establishes viewpoint-conditioned diffusion as a scalable, depth-free solution for stereo generation.\nüìÑ Download PDF\nSceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model Authors: Yukai Shi, Weiyu Li, Zihao Wang, Hongyang Li, Xingyu Chen, Ping Tan, Lei Zhang Venue: arXiv (2025)\nWe propose a decoupled 3D scene generation framework called SceneMaker in this work. Due to the lack of sufficient open-set de-occlusion and pose estimation priors, existing methods struggle to simultaneously produce high-quality geometry and accurate poses under severe occlusion and open-set settings. To address these issues, we first decouple the de-occlusion model from 3D object generation, and enhance it by leveraging image datasets and collected de-occlusion datasets for much more diverse open-set occlusion patterns. Then, we propose a unified pose estimation model that integrates global and local mechanisms for both self-attention and cross-attention to improve accuracy. Besides, we construct an open-set 3D scene dataset to further extend the generalization of the pose estimation model. Comprehensive experiments demonstrate the superiority of our decoupled framework on both indoor and open-set scenes. Our codes and datasets is released at https://idea-research.github.io/SceneMaker/.\nüìÑ Download PDF\nBidirectional Normalizing Flow: From Data to Noise and Back Authors: Yiyang Lu, Qiao Sun, Xianbang Wang, Zhicheng Jiang, Hanhong Zhao, Kaiming He Venue: arXiv (2025)\nNormalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations are constrained by explicit invertibility, ensuring that the reverse process can serve as their exact analytic inverse. Recent developments in TARFlow and its variants have revitalized NF methods by combining Transformers and autoregressive flows, but have also exposed causal decoding as a major bottleneck. In this work, we introduce Bidirectional Normalizing Flow ($\\textbf{BiFlow}$), a framework that removes the need for an exact analytic inverse. BiFlow learns a reverse model that approximates the underlying noise-to-data inverse mapping, enabling more flexible loss functions and architectures. Experiments on ImageNet demonstrate that BiFlow, compared to its causal decoding counterpart, improves generation quality while accelerating sampling by up to two orders of magnitude. BiFlow yields state-of-the-art results among NF-based methods and competitive performance among single-evaluation (‚Äú1-NFE‚Äù) methods. Following recent encouraging progress on NFs, we hope our work will draw further attention to this classical paradigm.\nüìÑ Download PDF\nClusIR: Towards Cluster-Guided All-in-One Image Restoration Authors: Shengkai Hu, Jiaqi Ma, Jun Wan, Wenwen Min, Yongcheng Jing, Lefei Zhang, Dacheng Tao Venue: arXiv (2025)\nAll-in-One Image Restoration (AiOIR) aims to recover high-quality images from diverse degradations within a unified framework. However, existing methods often fail to explicitly model degradation types and struggle to adapt their restoration behavior to complex or mixed degradations. To address these issues, we propose ClusIR, a Cluster-Guided Image Restoration framework that explicitly models degradation semantics through learnable clustering and propagates cluster-aware cues across spatial and frequency domains for adaptive restoration. Specifically, ClusIR comprises two key components: a Probabilistic Cluster-Guided Routing Mechanism (PCGRM) and a Degradation-Aware Frequency Modulation Module (DAFMM). The proposed PCGRM disentangles degradation recognition from expert activation, enabling discriminative degradation perception and stable expert routing. Meanwhile, DAFMM leverages the cluster-guided priors to perform adaptive frequency decomposition and targeted modulation, collaboratively refining structural and textural representations for higher restoration fidelity. The cluster-guided synergy seamlessly bridges semantic cues with frequency-domain modulation, empowering ClusIR to attain remarkable restoration results across a wide range of degradations. Extensive experiments on diverse benchmarks validate that ClusIR reaches competitive performance under several scenarios.\nüìÑ Download PDF\nImplicitRDP: An End-to-End Visual-Force Diffusion Policy with Structural Slow-Fast Learning Authors: Wendi Chen, Han Xue, Yi Wang, Fangyuan Zhou, Jun Lv, Yang Jin, Shirun Tang, Chuan Wen, Cewu Lu Venue: arXiv (2025)\nHuman-level contact-rich manipulation relies on the distinct roles of two key modalities: vision provides spatially rich but temporally slow global context, while force sensing captures rapid, high-frequency local contact dynamics. Integrating these signals is challenging due to their fundamental frequency and informational disparities. In this work, we propose ImplicitRDP, a unified end-to-end visual-force diffusion policy that integrates visual planning and reactive force control within a single network. We introduce Structural Slow-Fast Learning, a mechanism utilizing causal attention to simultaneously process asynchronous visual and force tokens, allowing the policy to perform closed-loop adjustments at the force frequency while maintaining the temporal coherence of action chunks. Furthermore, to mitigate modality collapse where end-to-end models fail to adjust the weights across different modalities, we propose Virtual-target-based Representation Regularization. This auxiliary objective maps force feedback into the same space as the action, providing a stronger, physics-grounded learning signal than raw force prediction. Extensive experiments on contact-rich tasks demonstrate that ImplicitRDP significantly outperforms both vision-only and hierarchical baselines, achieving superior reactivity and success rates with a streamlined training pipeline. Code and videos will be publicly available at https://implicit-rdp.github.io.\nüìÑ Download PDF\nNoisy Quantum Learning Theory Authors: Jordan Cotler, Weiyuan Gong, Ishaan Kannan Venue: arXiv (2025)\nWe develop a framework for learning from noisy quantum experiments, focusing on fault-tolerant devices accessing uncharacterized systems through noisy couplings. Our starting point is the complexity class $\\textsf{NBQP}$ (‚Äúnoisy BQP‚Äù), modeling noisy fault-tolerant quantum computers that cannot, in general, error-correct the oracle systems they query. Using this class, we show that for natural oracle problems, noise can eliminate exponential quantum learning advantages of ideal noiseless learners while preserving a superpolynomial gap between NISQ and fault-tolerant devices. Beyond oracle separations, we study concrete noisy learning tasks. For purity testing, the exponential two-copy advantage collapses under a single application of local depolarizing noise. Nevertheless, we identify a setting motivated by AdS/CFT in which noise-resilient structure restores a quantum learning advantage in a noisy regime. We then analyze noisy Pauli shadow tomography, deriving lower bounds that characterize how instance size, quantum memory, and noise control sample complexity, and design algorithms with parametrically similar scalings. Together, our results show that the Bell-basis and SWAP-test primitives underlying most exponential quantum learning advantages are fundamentally fragile to noise unless the experimental system has latent noise-robust structure. Thus, realizing meaningful quantum advantages in future experiments will require understanding how noise-robust physical properties interface with available algorithmic techniques.\nüìÑ Download PDF\nFree plane curves with a linear Jacobian syzygy Authors: Valentina Beorchia, Matteo Gallet, Alessandro Logar Venue: arXiv (2025)\nThe study of planar free curves is a very active area of research, but a structural study of such a class is missing. We give a complete classification of the possible generators of the Jacobian syzygy module of a plane free curve under the assumption that one of them is linear. Specifically, we prove that, up to similarities, there are two possible forms for the Hilbert-Burch matrix. Our strategy relies on a translation of the problem into the accurate study of the geometry of maximal segments of a suitable triangle with integer points. Following this description, we are able to determine precisely the equations of free curves and the associated Hilbert-Burch matrices.\nüìÑ Download PDF\nStructural, physical, and Judd-Ofelt analysis of germanium magnesium-telluroborate glass containing different amounts of Tm2O3 Authors: A. A. El-Maaref, Kh. S. Shaaban, E. A. Abdel Wahab Venue: arXiv (2025)\nGermanium magnesium-telluroborate glasses with the composition 78B2O3-10GeO2-5TeO2-7-x MgO-xTm2O3, x = 0, 0.25, 0.5, 1, and 1.5 mol% were fabricated by using the melt quenching process. With the increase of Tm2O3 concentration, the density values increase from 3.574 to 4.153 g.cm-1, while the molar volume values decrease from 21.145 to 19.445 cm3/mol. Fourier transform infrared analysis supports the existence and conversion of BO3 and BO4. The conversion of BO3 to BO4 would lead to greater bridging oxygens BOs, influencing and reinforcing the glass network. The optical features were studied. The optical band gap decreased by increasing Tm2O3 content in the glass formula, while the index of refraction increased. The parameters take the values between 3.16 eV and 2.31 eV. Other optical and physical constants were determined like optical conductivity, electronegativity, metallization, reflection loss, steepness parameters, and transmission coefficient. Judd-Ofelt theory is used to estimate the optical intensities and line strengths of the present glasses. Radiative lifetimes and branching ratios are evaluated of different manifolds belonging to Tm3+ doped present glasses. The results showed the possibility of potential applications for these materials in the fields of laser development, Light-emitting diodes (LEDs), optical amplification and optoelectronic devices.\nüìÑ Download PDF\nThe LISA Astrophysics ‚ÄúDisc-IMRI‚Äù Code Comparison Project: Intermediate-Mass-Ratio Binaries in AGN-Like Discs Authors: Andrea Derdzinski, Alexander J. Dittmann, Alessia Franchini, Alessandro Lupi, No√© Brucy, Pedro R. Capelo, Fr√©d√©ric S. Masset, Rapha√´l Mignon-Risse, Michael Rizzo Smith, Edwin Santiago-Leandro, Martina Toscani, David A. Velasco-Romero, Robert Wissing, Mudit Garg, Lucio Mayer, Roberto Serafinelli, Lazaros Souvaitzis, Daniel J. D‚ÄôOrazio, Jonathan Menu Venue: arXiv (2025)\nUpcoming space-based gravitational wave detectors such as LISA, the Laser Interferometer Space Antenna, will be sensitive to extreme- and intermediate-mass-ratio inspirals (EMRIs and IMRIs). These binaries are comprised of a supermassive black hole and a stellar-mass object or intermediate-mass black hole. Their detection will probe the structure of galactic nuclei and enable tests of general relativity. As these events will be observed over thousands of orbital cycles, they will be extremely sensitive to both the underlying spacetime and astrophysical environment, demanding exquisite theoretical models on both fronts to avoid biased or even erroneous results. In particular, many (E/)IMRIs are expected to occur within accretion discs around supermassive black holes, and the nonlinearities present when modeling these systems require numerical simulations. In preparation for future modeling of LISA sources, we have conducted a comparison between eight different hydrodynamical codes and applied them to the problem of a q = 10^{-4} mass ratio binary interacting with an accretion disc. Thicker discs appear more lenient, and all codes at sufficiently high resolutions are in good agreement with each other and analytical predictions. For thinner discs, beyond the reach of analytical models, we find substantial disagreement between 2D and 3D simulations and between different codes, including both the magnitude and sign of the torque. With time and energy efficiency in mind, codes that leverage moving meshes or grid-based Lagrangian remapping seem preferable, as do codes that can leverage graphical processing units and other energy-efficient hardware.\nüìÑ Download PDF\nInflation in light of ACT/SPT: a new perspective from Weyl gravity Authors: Qing-Yang Wang Venue: arXiv (2025)\nRecent measurements from the Atacama Cosmology Telescope (ACT) and the South Pole Telescope (SPT) have placed the strictest constraints on the primordial scalar perturbation spectrum, reporting a spectral index of $n_s\\sim0.967-0.98$ at 95% confidence level. This result indicates a stronger scale invariance of the scalar perturbation than earlier estimates, posing challenges for numerous inflation models. In this work, we propose an appealing inflationary scenario from the Weyl scale-invariant gravity theory dominated by the higher-order curvatures. Specifically, the exponential curvature extensions are introduced to suppress the mass divergence of the inflaton. We find such scenario naturally yields leading-order predictions of $n_s\\simeq1-3/(2N)\\sim0.97-0.975$ or $n_s\\simeq1-5/(3N)\\sim0.967-0.972$ for various models, in excellent agreement with the ACT/SPT constraints. This result builds a concrete bridge between theoretical and observational scale invariance, implying an enduring cosmic echo of the primordial symmetry.\nüìÑ Download PDF\nModeling, Segmenting and Statistics of Transient Spindles via Two-Dimensional Ornstein-Uhlenbeck Dynamics Authors: C. Sun, D. Fettahoglu, D. Holcman Venue: arXiv (2025)\nWe develop here a stochastic framework for modeling and segmenting transient spindle-like oscillatory bursts in electroencephalogram (EEG) signals. At the modeling level, individual spindles are represented as path realizations of a two-dimensional Ornstein{Uhlenbeck (OU) process with a stable focus, providing a low-dimensional stochastic dynamical system whose trajectories reproduce key morphological features of spindles, including their characteristic rise{decay amplitude envelopes. On the signal processing side, we propose a segmentation procedure based on Empirical Mode Decomposition (EMD) combined with the detection of a central extremum, which isolates single spindle events and yields a collection of oscillatory atoms. This construction enables a systematic statistical analysis of spindle features: we derive empirical laws for the distributions of amplitudes, inter-spindle intervals, and rise/decay durations, and show that these exhibit exponential tails consistent with the underlying OU dynamics. We further extend the model to a pair of weakly coupled OU processes with distinct natural frequencies, generating a stochastic mixture of slow, fast, and mixed spindles in random temporal order. The resulting framework provides a data-driven framework for the analysis of transient oscillations in EEG and, more generally, in nonstationary time series.\nüìÑ Download PDF\nData-driven Pressure Recovery in Diffusers Authors: Juan Augusto Paredes Salazar, Ankit Goel, Rowen Costich, Meliksah Koca, Ozgur Tumuklu, Michael Amitay Venue: arXiv (2025)\nThis paper investigates the application of a data-driven technique based on retrospective cost optimization to optimize the frequency of mass injection into an S-shaped diffuser, with the objective of maximizing the pressure recovery. Experimental data indicated that there is an optimal injection frequency between 100 Hz and 300 Hz with a mass flow rate of 1 percent of the free stream. High-fidelity numerical simulations using compressible unsteady Reynolds-Averaged Navier-Stokes (URANS) are conducted to investigate the mean and temporal features resulting from mass injection into an S-shaped diffuser with differing injection speeds and pulse frequencies. The results are compared with experiments to confirm the accuracy of the numerical solution. Overall, 2-D simulations are relatively in good agreement with the experiment, with 3-D simulations currently under investigation to benchmark the effect of spanwise instabilities. Simulation results with the proposed data-driven technique show improvements upon a baseline case by increasing pressure recovery and reducing the region of flow recirculation within the diffuser.\nüìÑ Download PDF\nModeling Light Signals Using Data from the First Pulsed Neutron Source Program at the DUNE Vertical Drift ColdBox Test Facility at CERN Neutrino Platform Authors: A. Paudel, W. Shi, P. Sala, F. Cavanna, W. Johnson, J. Wang, W. Ketchum, F. Resnati, A. Heindel, A. Ashkenazi, E. Bertholet, E. Bertolini, D. A. Martinez Caicedo, E. Calvo, A. Canto, S. Manthey Corchado, C. Cuesta, Z. Djurcic, M. Fani, A. Feld, S. Fogarty, F. Galizzi, S. Gollapinni, Y. Kerma√Ødic, A. Kish, F. Marinho, D. Torres Mu√±oz, A. Verdugo de Osa, L. Paulucci, W. Pellico, V. Popov, J. Rodriguez Rondon, D. Leon Silverio, S. Sacerdoti, H. Souza, R. C Svoboda, D. Totani, V. Trabattoni, L. Zambelli Venue: arXiv (2025)\nIn this paper, we present a first quantitative test of detected light signals produced in a pulsed neutron source run in a small vertical drift LArTPC at the CERN neutrino platform ColdBox test facility. The ColdBox cryostat, detectors, neutron sources, and particle interactions are modeled and simulated using Fluka. A good agreement is found in the detected number of photoelectrons, with values below 650 photoelectrons in both data and simulation, for all four X-ARAPUCA photodetectors on the cathode in the LArTPC. A time constant is also fitted from the neutron-beam-off light signal spectrum and found consistent between data and MC. Several important systematic effects are discussed and serve as guides for future runs at larger LArTPCs.\nüìÑ Download PDF\nTheoretical and experimental development of a high-conversion-efficiency rectifier at X-band Authors: Feifei Tan, Changjun Liu Venue: arXiv (2025)\nVoltage doubler rectifiers are usually applied to systems with high voltage and low current requirement. An X band voltage doubler rectifier has been developed with 72% conversion efficiency. To the best of our knowledge, the obtained rectifying efficiency is the maximum reported to date at X band with Schottky diodes. The working characteristics of the diodes in the voltage doubler rectifier are analyzed in detail. Closed-form equations of diode input impedance and rectifying efficiency are presented and validated using Advanced Design System simulations. The matching network design of the proposed rectifier is based on the closed-form equations. The preliminary rectifying efficiency is predicted by the closed-form equations as well. Measured and simulated results are in good agreement.\nüìÑ Download PDF\nGroup Diffusion: Enhancing Image Generation by Unlocking Cross-Sample Collaboration Authors: Sicheng Mo, Thao Nguyen, Richard Zhang, Nick Kolkin, Siddharth Srinivasan Iyer, Eli Shechtman, Krishna Kumar Singh, Yong Jae Lee, Bolei Zhou, Yuheng Li Venue: arXiv (2025)\nIn this work, we explore an untapped signal in diffusion model inference. While all previous methods generate images independently at inference, we instead ask if samples can be generated collaboratively. We propose Group Diffusion, unlocking the attention mechanism to be shared across images, rather than limited to just the patches within an image. This enables images to be jointly denoised at inference time, learning both intra and inter-image correspondence. We observe a clear scaling effect - larger group sizes yield stronger cross-sample attention and better generation quality. Furthermore, we introduce a qualitative measure to capture this behavior and show that its strength closely correlates with FID. Built on standard diffusion transformers, our GroupDiff achieves up to 32.2% FID improvement on ImageNet-256x256. Our work reveals cross-sample inference as an effective, previously unexplored mechanism for generative modeling.\nüìÑ Download PDF\nFoundationMotion: Auto-Labeling and Reasoning about Spatial Movement in Videos Authors: Yulu Gan, Ligeng Zhu, Dandan Shan, Baifeng Shi, Hongxu Yin, Boris Ivanovic, Song Han, Trevor Darrell, Jitendra Malik, Marco Pavone, Boyi Li Venue: arXiv (2025)\nMotion understanding is fundamental to physical reasoning, enabling models to infer dynamics and predict future states. However, state-of-the-art models still struggle on recent motion benchmarks, primarily due to the scarcity of large-scale, fine-grained motion datasets. Existing motion datasets are often constructed from costly manual annotation, severely limiting scalability. To address this challenge, we introduce FoundationMotion, a fully automated data curation pipeline that constructs large-scale motion datasets. Our approach first detects and tracks objects in videos to extract their trajectories, then leverages these trajectories and video frames with Large Language Models (LLMs) to generate fine-grained captions and diverse question-answer pairs about motion and spatial reasoning. Using datasets produced by this pipeline, we fine-tune open-source models including NVILA-Video-15B and Qwen2.5-7B, achieving substantial improvements in motion understanding without compromising performance on other tasks. Notably, our models outperform strong closed-source baselines like Gemini-2.5 Flash and large open-source models such as Qwen2.5-VL-72B across diverse motion understanding datasets and benchmarks. FoundationMotion thus provides a scalable solution for curating fine-grained motion datasets that enable effective fine-tuning of diverse models to enhance motion understanding and spatial reasoning capabilities.\nüìÑ Download PDF\nEchoes of Automation: How Bots Shaped Political Discourse in Brazil Authors: Merve Ipek Bal, Diogo Pacheco Venue: arXiv (2025)\nIn an era where social media platforms are central to political communication, the activity of bots raises pressing concerns about amplification, manipulation, and misinformation. Drawing on more than 315 million tweets posted from August 2018 to June 2022, we examine behavioural patterns, sentiment dynamics, and the thematic focus of bot- versus human-generated content spanning the 2018 Brazilian presidential election and the lead-up to the 2022 contest. Our analysis shows that bots relied disproportionately on retweets and replies, with reply activity spiking after the 2018 election, suggesting tactics of conversational infiltration and amplification. Sentiment analysis indicates that bots maintained a narrower emotional tone, in contrast to humans, whose sentiment fluctuated more strongly with political events. Topic modelling further reveals bots‚Äô repetitive, Bolsonaro-centric messaging, while human users engaged with a broader range of candidates, civic concerns, and personal reflections. These findings underscore bots‚Äô role as amplifiers of narrow agendas and their potential to distort online political discourse.\nüìÑ Download PDF\nIntrinsically Correct Algorithms and Recursive Coalgebras Authors: Cass Alexandru, Henning Urbat, Thorsten Wi√ümann Venue: arXiv (2025)\nRecursive coalgebras provide an elegant categorical tool for modelling recursive algorithms and analysing their termination and correctness. By considering coalgebras over categories of suitably indexed families, the correctness of the corresponding algorithms follows intrinsically just from the type of the computed maps. However, proving recursivity of the underlying coalgebras is non-trivial, and proofs are typically ad hoc. This layer of complexity impedes the formalization of coalgebraically defined recursive algorithms in proof assistants. We introduce a framework for constructing coalgebras which are intrinsically recursive in the sense that the type of the coalgebra guarantees recursivity from the outset. Our approach is based on the novel concept of a well-founded functor on a category of families indexed by a well-founded relation. We show as our main result that every coalgebra for a well-founded functor is recursive, and demonstrate that well-known techniques for proving recursivity and termination such as ranking functions are subsumed by this abstract setup. We present a number of case studies, including Quicksort, the Euclidian algorithm, and CYK parsing. Both the main theoretical result and selected case studies have been formalized in Cubical Agda.\nüìÑ Download PDF\nKicking Politics: How Football Fan Communities Became Arenas for Political Influence Authors: Helen Paffard, Diogo Pacheco Venue: arXiv (2025)\nThis paper investigates how political campaigns engaged UK football fan communities on Twitter in the aftermath of the Brexit Referendum (2016-2017). Football fandom, with its strong collective identities and tribal behaviours, offers fertile ground for political influence. Combining social network and content analysis, we examine how political discourse became embedded in football conversations. We show that a wide range of actors ‚Äì including parties, media, activist groups, and pseudonymous influencers ‚Äì mobilised support, provoked reactions, and shaped opinion within these communities. Through case studies of hashtag hijacking, embedded activism, and political ‚Äúmegaphones‚Äù, we illustrate how campaigns leveraged fan cultures to amplify political messages. Our findings highlight mechanisms of political influence in ostensibly non-political online spaces and point toward the development of a broader framework in future work.\nüìÑ Download PDF\nThe Physics of Sustainability: Material and Power Constraints for the Long Term Authors: Jos√© Halloy, Petros Chatzimpiros, Fran√ßois Graner, Thomas Gregor Venue: arXiv (2025)\nMuch of today‚Äôs sustainability discourse emphasizes efficiency, clean technologies, and smart systems, but largely underestimates fundamental physical constraints relating to energy-matter interactions. These constraints stem from the fact that Earth is a materially closed yet energetically open system, driven by the sustained but low power-density flux of solar radiation. This Perspective reframes sustainability within these axiomatic limits, integrating relevant timescales and orders of magnitude. We argue that fossil-fueled industrial metabolism is inherently incompatible with long-term viability, while post-fossil systems are surface-, materials-, and power-intensive. Long-term sustainability must therefore be defined not only by how much energy or material is used, but also by how it is used: favoring organic, carbon-based chemistry with limited reliance on purified metals, operating at low power density, and maintaining low throughput rates. Achieving this requires radical technological shifts toward life-compatible systems and biogeochemical circular processes, and, likely as a consequence, a paradigm change toward degrowth to a steady-state. These two shifts are mutually reinforcing and together provide the necessary foundation for any viable future.\nüìÑ Download PDF\nDOCR-Inspector: Fine-Grained and Automated Evaluation of Document Parsing with VLM Authors: Qintong Zhang, Junyuan Zhang, Zhifei Ren, Linke Ouyang, Zichen Wen, Junbo Niu, Yuan Qu, Bin Wang, Ka-Ho Chow, Conghui He, Wentao Zhang Venue: arXiv (2025)\nDocument parsing aims to transform unstructured PDF images into semi-structured data, facilitating the digitization and utilization of information in diverse domains. While vision language models (VLMs) have significantly advanced this task, achieving reliable, high-quality parsing in real-world scenarios remains challenging. Common practice often selects the top-performing model on standard benchmarks. However, these benchmarks may carry dataset-specific biases, leading to inconsistent model rankings and limited correlation with real-world performance. Moreover, benchmark metrics typically provide only overall scores, which can obscure distinct error patterns in output. This raises a key challenge: how can we reliably and comprehensively assess document parsing quality in the wild? We address this problem with DOCR-Inspector, which formalizes document parsing assessment as fine-grained error detection and analysis. Leveraging VLM-as-a-Judge, DOCR-Inspector analyzes a document image and its parsed output, identifies all errors, assigns them to one of 28 predefined types, and produces a comprehensive quality assessment. To enable this capability, we construct DOCRcase-200K for training and propose the Chain-of-Checklist reasoning paradigm to enable the hierarchical structure of parsing quality assessment. For empirical validation, we introduce DOCRcaseBench, a set of 882 real-world document parsing cases with manual annotations. On this benchmark, DOCR-Inspector-7B outperforms commercial models like Gemini 2.5 Pro, as well as leading open-source models. Further experiments demonstrate that its quality assessments provide valuable guidance for parsing results refinement, making DOCR-Inspector both a practical evaluator and a driver for advancing document parsing systems at scale. Model and code are released at: https://github.com/ZZZZZQT/DOCR-Inspector.\nüìÑ Download PDF\nModeling Narrative Archetypes in Conspiratorial Narratives: Insights from Singapore-Based Telegram Groups Authors: Soorya Ram Shimgekar, Abhay Goyal, Lam Yin Cheung, Roy Ka-Wei Lee, Koustuv Saha, Pi Zonooz, Navin Kumar Venue: arXiv (2025)\nConspiratorial discourse is increasingly embedded within digital communication ecosystems, yet its structure and spread remain difficult to study. This work analyzes conspiratorial narratives in Singapore-based Telegram groups, showing that such content is woven into everyday discussions rather than confined to isolated echo chambers. We propose a two-stage computational framework. First, we fine-tune RoBERTa-large to classify messages as conspiratorial or not, achieving an F1-score of 0.866 on 2,000 expert-labeled messages. Second, we build a signed belief graph in which nodes represent messages and edge signs reflect alignment in belief labels, weighted by textual similarity. We introduce a Signed Belief Graph Neural Network (SiBeGNN) that uses a Sign Disentanglement Loss to learn embeddings that separate ideological alignment from stylistic features. Using hierarchical clustering on these embeddings, we identify seven narrative archetypes across 553,648 messages: legal topics, medical concerns, media discussions, finance, contradictions in authority, group moderation, and general chat. SiBeGNN yields stronger clustering quality (cDBI = 8.38) than baseline methods (13.60 to 67.27), supported by 88 percent inter-rater agreement in expert evaluations. Our analysis shows that conspiratorial messages appear not only in clusters focused on skepticism or distrust, but also within routine discussions of finance, law, and everyday matters. These findings challenge common assumptions about online radicalization by demonstrating that conspiratorial discourse operates within ordinary social interaction. The proposed framework advances computational methods for belief-driven discourse analysis and offers applications for stance detection, political communication studies, and content moderation policy.\nüìÑ Download PDF\nDetection prospects for heavy WIMP dark matter near supermassive black holes, particularly in M31 Authors: Andrei E. Egorov Venue: arXiv (2025)\nThis work analyzes the detection prospects for weakly interacting massive particles (WIMPs) in dark matter (DM) density spikes around nearby supermassive black holes (SMBHs) by observations in very high energy gamma-ray band. Such spikes are unique targets, which provide a possibility to discover the basic thermal s-wave annihilating WIMP with any mass up to the theoretical unitarity limit ~ 100 TeV. All relevant SMBHs were checked, and only MW* and M31* were identified as worthwhile objects. Cherenkov Telescope Array (CTA) sensitivity to heavy WIMPs in M31* was estimated. It was obtained that CTA will be able to probe a major part of TeV-scale WIMP parameter space in case of optimistic spike density configuration in M31*. In certain scenarios, M31* may yield even stronger constraints than MW*. Relevant systematic uncertainties were explored.\nüìÑ Download PDF\nHiding a Light Vector Boson from Terrestrial Experiments: A Chargephobic Dark Photon Authors: Haidar Esseili, Graham D. Kribs Venue: arXiv (2025)\nWe calculate the terrestrial, astrophysical and cosmological constraints on a light vector boson that couples to an arbitrary combination of the electromagnetic and $B-L$ currents of the Standard Model. The dark photon and a vector boson coupling to $B-L$ are special cases of our generalized flavor-universal anomaly-free vector boson, requiring just one additional parameter (the ‚Äúdark mixing angle‚Äù corresponding to the linear combination of the electromagnetic and $B-L$ currents) beyond that of the overall coupling strength and the vector boson mass, where we focus on the range $1, {\\rm MeV}$ to $60, {\\rm GeV}$. We perform a detailed investigation of a unique combination where the vector boson couplings to electrically charged leptons and protons are highly suppressed: the ‚Äúchargephobic dark photon‚Äù. A chargephobic vector boson is very weakly constrained by current terrestrial experiments including beam dumps and collider experiments, since they rely on couplings to electrons and protons. Instead, neutrino scattering experiments (such as COHERENT), astrophysical sources (supernova emission), and cosmology ($ŒîN_{\\rm eff}$) provide the strongest constraints due to the nonzero couplings of the chargephobic vector boson to neutrinos and neutrons. Indeed, we find that supernova emission and $ŒîN_{\\rm eff}$ provide constraints throughout the space of dark mixing angles, demonstrating their importance to provide model-independent constraints. For nearly all of the parameter space, a chargephobic vector boson is the most weakly constrained anomaly-free vector boson that couples to flavor-independent or flavor-dependent combinations of Standard Model currents. Finally, we highlight the importance of future experiments, including SHiP, that are able to probe new regions of the chargephobic parameter space due to the significantly improved detector capabilities.\nüìÑ Download PDF\nStandard Model Benchmarks for $D^0\\to K^- K^+, œÄ^-œÄ^+, K^0_{\\rm S} K^0_{\\rm S}$ Decays Authors: Robert Fleischer, Maria Laura Piscopo, K. Keri Vos, B. Yaƒümur Zubaroƒülu Venue: arXiv (2025)\nThe non-leptonic $D^0\\to K^- K^+$ and $D^0\\to œÄ^-œÄ^+$ decays are powerful probes of the Standard Model and are related to each other through the $U$-spin symmetry of the strong interaction. Using lattice QCD inputs we calculate the corresponding colour-allowed tree amplitudes in factorisation and demonstrate that non-factorisable contributions and $U$-spin-breaking effects at the level of 50% allow us to accommodate the measured branching ratios in the Standard Model. An exciting direct probe of such non-factorisable and $U$-spin breaking effects is provided by the $D^0\\to K^0_{\\rm S} K^0_{\\rm S}$ channel. This decay is governed by non-factorisable exchange topologies and essentially vanishes in the $U$-spin limit, although it is experimentally well established with a prominent branching ratio. Extrapolating our $D^0\\to K^- K^+$ results using the isospin symmetry, we find a consistent benchmark picture. Specifically, we can accommodate the measured $D^0\\to K^0_{\\rm S} K^0_{\\rm S}$ branching ratio with $U$-spin-breaking effects at the 50% level and exchange amplitudes at the level of 50% of the colour-allowed $D^0\\to K^- K^+$, $D^0\\to œÄ^-œÄ^+$ tree contributions. Finally, we explore the resulting range for direct CP violation in $D^0\\to K^0_{\\rm S} K^0_{\\rm S}$, obtaining upper bounds in our benchmark scenarios of a few per mille, offering an exciting target for future measurements.\nüìÑ Download PDF\nConformal Boundary Conditions and Higher Curvature Gravity Authors: Dami√°n A. Galante, Robert C. Myers, Themistocles Zikopoulos Venue: arXiv (2025)\nWe initiate a systematic study of Einstein-Gauss-Bonnet gravity in the presence of boundaries subject to conformal boundary conditions, in which the conformal class of the boundary metric is kept fixed. In Einstein gravity, the trace of the extrinsic curvature is also fixed at the boundary. Here we generalize this boundary condition with the appropriate higher curvature correction. We study the problem both in Euclidean and Lorentzian signature. In Euclidean signature, we show that, similarly to the Einstein gravity case, the entropy at large temperatures exhibits the behavior of a conformal field theory in one lower dimension. We also show that in the flat space limit, the higher curvature corrections do not contribute to the leading behavior at high temperatures. We conjecture that this result is a universal feature of the flat space limit in the presence of conformal boundaries. We test our conjecture by analyzing charged black holes. In Lorentzian signature, we analyze the dynamics of the boundary Weyl factor in black hole backgrounds at the linearized level.\nüìÑ Download PDF\nShedding Light on Large Space-Based Telescopes: Modeling Stray Light due to Primary Mirror Damage from Micrometeoroid Impacts Authors: Megan T. Gialluca, Jonathan W. Arenberg, Chris Stark, Blake Shepherd, Victoria S. Meadows, Aki Roberge, Tyler D. Robinson, Robert Podgurski Venue: arXiv (2025)\nA large space-based telescope aimed at detecting and characterizing the atmospheres of Earth-like planets orbiting Sun-like stars will require unprecedented contrast and stability. However, damage to the primary mirror due to micrometeoroid impacts will provide a stochastic, time-dependent source of stray light in the coronagraph‚Äôs field of view that could significantly lengthen exposure times and reduce the expected science yield. To better quantify the impact of stray light and inform the Habitable Worlds Observatory mission design process, we present estimates of stray light in different micrometeoroid damage scenarios for a broad range of targets, and use that to find the expected decrease in science yield (i.e., the expected number of detected exoEarth candidates). We find that stray light due to micrometeoroid damage may significantly reduce yield, by 30% ‚Äì 60% in some cases, but significant uncertainties remain due to the unknown maximum expected impactor energy, and the relationship between impact energy and expected crater size. Micrometeoroid damage therefore needs further exploration, as it has the potential to reduce scientific yield, and in turn drive the development of mitigation strategies, selection of telescope designs, and selection of observing priorities in the future.\nüìÑ Download PDF\nA vision for ground-based astronomy beyond the 2030s: How to build ESO‚Äôs next big telescope sustainably Authors: Laurane Fr√©our, Mathilde Bouvier, Tony Mroczkowski, Callie Clontz, Fatemeh Zahra Majidi, Vasundhara Shaw, Olivier Absil, Anna Cabr√©, Olivier Lai, Dylan Magill, Jake D. Turner Venue: arXiv (2025)\nAstronomy is the study of the Universe and all the objects that it comprises. Our attention is therefore usually focused beyond Earth, home to the only form of life known today. However, how can we continue to explore the secrets of the Universe, if we stand by and watch our only home burn? We know that there is no Planet B. It is therefore urgent that, as astronomers, we collectively work to protect the Earth, allowing future generations the opportunity to continue to uncover the secrets of the cosmos. As astronomical facilities account for the majority of our community‚Äôs carbon footprint, we propose guidelines that we hold crucial for the European Southern Observatory (ESO) to consider in the context of the Expanding Horizons programme as it plans a next-generation, transformational facility.\nüìÑ Download PDF\nHybrid quantum-classical matrix-product state and Lanczos methods for electron-phonon systems with strong electronic correlations: Application to disordered systems coupled to Einstein phonons Authors: Heiko Georg Menzler, Suman Mondal, Fabian Heidrich-Meisner Venue: arXiv (2025)\nWe present two quantum-classical hybrid methods for simulating the time-dependence of electron-phonon systems that treat electronic correlations numerically exactly and optical-phonon degrees of freedom classically. These are a time-dependent Lanczos and a matrix-product state method, each combined with the multi-trajectory Ehrenfest approach. Due to the approximations, reliable results are expected for the adiabatic regime of small phonon frequencies. We discuss the convergence properties of both methods for a system of interacting spinless fermions in one dimension and provide a benchmark for the Holstein chain. As a first application, we study the decay of charge density wave order in a system of interacting spinless fermions coupled to Einstein oscillators and in the presence of quenched disorder. We investigate the dependence of the relaxation dynamics on the electron-phonon coupling strength and provide numerical evidence that the coupling of strongly disordered systems to classical oscillators leads to delocalization, thus destabilizing the (finite-size) many-body localization in this system.\nüìÑ Download PDF\nPhysics-Informed Learning of Microvascular Flow Models using Graph Neural Networks Authors: Paolo Botta, Piermario Vitullo, Thomas Ventimiglia, Andreas Linninger, Paolo Zunino Venue: arXiv (2025)\nThe simulation of microcirculatory blood flow in realistic vascular architectures poses significant challenges due to the multiscale nature of the problem and the topological complexity of capillary networks. In this work, we propose a novel deep learning-based reduced-order modeling strategy, leveraging Graph Neural Networks (GNNs) trained on synthetic microvascular graphs to approximate hemodynamic quantities on anatomically realistic domains. Our method combines algorithms for synthetic vascular generation with a physics-informed training procedure that integrates graph topological information and local flow dynamics. To ensure the physical reliability of the learned surrogates, we incorporate a physics-informed loss functional derived from the governing equations, allowing enforcement of mass conservation and rheological constraints. The resulting GNN architecture demonstrates robust generalization capabilities across diverse network configurations. The GNN formulation is validated on benchmark problems with linear and nonlinear rheology, showing accurate pressure and velocity field reconstruction with substantial computational gains over full-order solvers. The methodology showcases significant generalization capabilities with respect to vascular complexity, as highlighted by tests on data from the mouse cerebral cortex. This work establishes a new class of graph-based surrogate models for microvascular flow, grounded in physical laws and equipped with inductive biases that mirror mass conservation and rheological models, opening new directions for real-time inference in vascular modeling and biomedical applications.\nüìÑ Download PDF\nTextual Data Bias Detection and Mitigation - An Extensible Pipeline with Experimental Evaluation Authors: Rebekka G√∂rge, Sujan Sai Gannamaneni, Tabea Naeven, Hammam Abdelwahab, H√©ctor Allende-Cid, Armin B. Cremers, Lennard Helmer, Michael Mock, Anna Schmitz, Songkai Xue, Elif Yildirir, Maximilian Poretschkin, Stefan Wrobel Venue: arXiv (2025)\nTextual data used to train large language models (LLMs) exhibits multifaceted bias manifestations encompassing harmful language and skewed demographic distributions. Regulations such as the European AI Act require identifying and mitigating biases against protected groups in data, with the ultimate goal of preventing unfair model outputs. However, practical guidance and operationalization are lacking. We propose a comprehensive data bias detection and mitigation pipeline comprising four components that address two data bias types, namely representation bias and (explicit) stereotypes for a configurable sensitive attribute. First, we leverage LLM-generated word lists created based on quality criteria to detect relevant group labels. Second, representation bias is quantified using the Demographic Representation Score. Third, we detect and mitigate stereotypes using sociolinguistically informed filtering. Finally, we compensate representation bias through Grammar- and Context-Aware Counterfactual Data Augmentation. We conduct a two-fold evaluation using the examples of gender, religion and age. First, the effectiveness of each individual component on data debiasing is evaluated through human validation and baseline comparison. The findings demonstrate that we successfully reduce representation bias and (explicit) stereotypes in a text dataset. Second, the effect of data debiasing on model bias reduction is evaluated by bias benchmarking of several models (0.6B-8B parameters), fine-tuned on the debiased text dataset. This evaluation reveals that LLMs fine-tuned on debiased data do not consistently show improved performance on bias benchmarks, exposing critical gaps in current evaluation methodologies and highlighting the need for targeted data manipulation to address manifested model bias.\nüìÑ Download PDF\nA Cryogenic Muon Tagging System Based on Kinetic Inductance Detectors for Superconducting Quantum Processors Authors: Ambra Mariani, Laura Cardani, Mustafa Bal, Nicola Casali, Ivan Colantoni, Angelo Cruciani, Giorgio Del Castello, Daniele Delicato, Francesco De Dominicis, Matteo del Gallo Raccagiovine, Matteo Folcarelli, Sabrina Garattoni, Anna Grassellino, Mehmood Khan Yasir Raja, Valerio Pettinacci, Alberto Ressa, Tanay Roy, Marco Vignati, David v Zanten Venue: arXiv (2025)\nIonizing radiation has emerged as a potential limiting factor for superconducting quantum processors, inducing quasiparticle bursts and correlated errors that challenge fault-tolerant operation. Atmospheric muons are particularly problematic due to their high energy and penetration power, making passive shielding ineffective. Therefore, monitoring the real-time muon flux is crucial to guide the development of alternative error-correction or protection strategies. We present the design, simulation, and first operation of a cryogenic muon-tagging system based on Kinetic Inductance Detectors (KIDs) for integration with superconducting quantum processors. The system consists of two KIDs arranged in a vertical stack and operated at ~20 mK. Monte Carlo simulations based on Geant4 guided the prototype design and provided reference expectations for muon-tagging efficiency and accidental coincidences due to ambient $Œ≥$-rays. We measured a muon-induced coincidence rate among the top and bottom detectors of (192 $\\pm$ 9) $\\times$ 10$^{-3}$ events/s, in excellent agreement with the Monte Carlo prediction. The prototype achieves a muon-tagging efficiency of about 90% with negligible dead time. These results demonstrate the feasibility of operating a muon-tagging system at millikelvin temperatures and open the path toward its integration with multi-qubit chips to veto or correct muon-induced errors in real time.\nüìÑ Download PDF\nTopology-Guided Quantum GANs for Constrained Graph Generation Authors: Tobias Rohe, Markus Baumann, Michael Poppel, Gerhard Stenzel, Maximilian Zorn, Claudia Linnhoff-Popien Venue: arXiv (2025)\nQuantum computing (QC) promises theoretical advantages, benefiting computational problems that would not be efficiently classically simulatable. However, much of this theoretical speedup depends on the quantum circuit design solving the problem. We argue that QC literature has yet to explore more domain specific ansatz-topologies, instead of relying on generic, one-size-fits-all architectures. In this work, we show that incorporating task-specific inductive biases ‚Äì specifically geometric priors ‚Äì into quantum circuit design can enhance the performance of hybrid Quantum Generative Adversarial Networks (QuGANs) on the task of generating geometrically constrained K4 graphs. We evaluate a portfolio of entanglement topologies and loss-function designs to assess their impact on both statistical fidelity and compliance with geometric constraints, including the Triangle and Ptolemaic inequalities. Our results show that aligning circuit topology with the underlying problem structure yields substantial benefits: the Triangle-topology QuGAN achieves the highest geometric validity among quantum models and matches the performance of classical Generative Adversarial Networks (GAN). Additionally, we showcase how specific architectural choices, such as entangling gate types, variance regularization and output-scaling govern the trade-off between geometric consistency and distributional accuracy, thus emphasizing the value of structured, task-aware quantum ansatz-topologies.\nüìÑ Download PDF\nGrammaticality Judgments in Humans and Language Models: Revisiting Generative Grammar with LLMs Authors: Lars G. B. Johnsen Venue: arXiv (2025)\nWhat counts as evidence for syntactic structure? In traditional generative grammar, systematic contrasts in grammaticality such as subject-auxiliary inversion and the licensing of parasitic gaps are taken as evidence for an internal, hierarchical grammar. In this paper, we test whether large language models (LLMs), trained only on surface forms, reproduce these contrasts in ways that imply an underlying structural representation. We focus on two classic constructions: subject-auxiliary inversion (testing recognition of the subject boundary) and parasitic gap licensing (testing abstract dependency structure). We evaluate models including GPT-4 and LLaMA-3 using prompts eliciting acceptability ratings. Results show that LLMs reliably distinguish between grammatical and ungrammatical variants in both constructions, and as such support that they are sensitive to structure and not just linear order. Structural generalizations, distinct from cognitive knowledge, emerge from predictive training on surface forms, suggesting functional sensitivity to syntax without explicit encoding.\nüìÑ Download PDF\nüîç psycholinguistics On Decision-Making Agents and Higher-Order Causal Processes Authors: Matt Wilson Venue: arXiv (2025)\nWe establish a precise correspondence between decision-making agents in partially observable Markov decision processes (POMDPs) and one-input process functions, the classical limit of higher-order quantum operations. In this identification an agent‚Äôs policy and memory update combine into a process function w that interacts with a POMDP environment via the link product. This suggests a dual interpretation: in the physics view, the process function acts as the environment into which local operations (agent interventions) are inserted, whereas in the AI view it encodes the agent and the inserted functions represent environments. We extend this perspective to multi-agent systems by identifying observation-independent decentralized POMDPs as natural domains for multi-input process functions.\nüìÑ Download PDF\nAny4D: Unified Feed-Forward Metric 4D Reconstruction Authors: Jay Karhade, Nikhil Keetha, Yuchen Zhang, Tanisha Gupta, Akash Sharma, Sebastian Scherer, Deva Ramanan Venue: arXiv (2025)\nWe present Any4D, a scalable multi-view transformer for metric-scale, dense feed-forward 4D reconstruction. Any4D directly generates per-pixel motion and geometry predictions for N frames, in contrast to prior work that typically focuses on either 2-view dense scene flow or sparse 3D point tracking. Moreover, unlike other recent methods for 4D reconstruction from monocular RGB videos, Any4D can process additional modalities and sensors such as RGB-D frames, IMU-based egomotion, and Radar Doppler measurements, when available. One of the key innovations that allows for such a flexible framework is a modular representation of a 4D scene; specifically, per-view 4D predictions are encoded using a variety of egocentric factors (depthmaps and camera intrinsics) represented in local camera coordinates, and allocentric factors (camera extrinsics and scene flow) represented in global world coordinates. We achieve superior performance across diverse setups - both in terms of accuracy (2-3X lower error) and compute efficiency (15X faster), opening avenues for multiple downstream applications.\nüìÑ Download PDF\nAnomalous scaling law for the two-dimensional Gaussian free field Authors: Pierre-Fran√ßois Rodriguez, Wen Zhang Venue: arXiv (2025)\nWe consider the Gaussian free field $\\varphi$ on $\\mathbb{Z}^2$ at large spatial scales $N$ and give sharp bounds on the probability $Œ∏(a,N)$ that the radius of a finite cluster in the excursion set ${\\varphi \\geq a}$ on the corresponding metric graph is macroscopic. We prove a scaling law for this probability, by which $Œ∏(a,N)$ transitions from fractional logarithmic decay for near-critical parameters $(a,N)$ to polynomial decay in the off-critical regime. The transition occurs across a certain scaling window determined by a correlation length scale $Œæ$, which is such that $Œ∏(a,N) \\sim Œ∏(0,Œæ)(\\tfrac{N}Œæ)^{-œÑ}$ for typical heights $a$ as $N/Œæ$ diverges, with an explicit exponent $œÑ$ that we identify in the process. This is in stark contrast with recent results from arXiv:2101.02200 and arXiv:2312.10030 in dimension three, where similar observables are shown to follow regular scaling laws, with polynomial decay at and near criticality, and rapid decay in ${N}/Œæ$ away from it.\nüìÑ Download PDF\nThe Localization Method for High-Dimensional Inequalities Authors: Yunbum Kook, Santosh S. Vempala Venue: arXiv (2025)\nWe survey the localization method for proving inequalities in high dimension, pioneered by Lov√°sz and Simonovits (1993), and its stochastic extension developed by Eldan (2012). The method has found applications in a surprising wide variety of settings, ranging from its original motivation in isoperimetric inequalities to optimization, concentration of measure, and bounding the mixing rate of Markov chains. At heart, the method converts a given instance of an inequality (for a set or distribution in high dimension) into a highly structured instance, often just one-dimensional.\nüìÑ Download PDF\nWhat matters for Representation Alignment: Global Information or Spatial Structure? Authors: Jaskirat Singh, Xingjian Leng, Zongze Wu, Liang Zheng, Richard Zhang, Eli Shechtman, Saining Xie Venue: arXiv (2025)\nRepresentation alignment (REPA) guides generative training by distilling representations from a strong, pretrained vision encoder to intermediate diffusion features. We investigate a fundamental question: what aspect of the target representation matters for generation, its \\textit{global} \\revision{semantic} information (e.g., measured by ImageNet-1K accuracy) or its spatial structure (i.e. pairwise cosine similarity between patch tokens)? Prevalent wisdom holds that stronger global semantic performance leads to better generation as a target representation. To study this, we first perform a large-scale empirical analysis across 27 different vision encoders and different model scales. The results are surprising; spatial structure, rather than global performance, drives the generation performance of a target representation. To further study this, we introduce two straightforward modifications, which specifically accentuate the transfer of \\emph{spatial} information. We replace the standard MLP projection layer in REPA with a simple convolution layer and introduce a spatial normalization layer for the external representation. Surprisingly, our simple method (implemented in $\u003c$4 lines of code), termed iREPA, consistently improves convergence speed of REPA, across a diverse set of vision encoders, model sizes, and training variants (such as REPA, REPA-E, Meanflow, JiT etc). %, etc. Our work motivates revisiting the fundamental working mechanism of representational alignment and how it can be leveraged for improved training of generative models. The code and project page are available at https://end2end-diffusion.github.io/irepa\nüìÑ Download PDF\nMaximal rigidity of random measure and uniqueness pairs: stealthy processes, quasicrystals and periodicity Authors: Rapha√´l Lachi√®ze-Rey Venue: arXiv (2025)\nThis article investigates the phenomenon of maximal rigidity in spatial processes, where perfect interpolation of the process is possible from partial information, specifically, from its restriction to a strict subdomain, often resulting in a trivial tail $œÉ$algebra. A classical example known since the 1930‚Äôs is that a time series is fully determined by its values on the negative integers if its spectrum has a gap, or at least a sufficiently deep zero. We extend such results to higher dimensions and continuous settings by establishing a connection with the concept of uniqueness pairs, rooted in the uncertainty principle of harmonic analysis. We present several other manifestations of this principle, unify and strengthen seemingly unrelated results across different models: quasicrystals and stealthy processes are shown to be maximally rigid on cones, and discrete integer-valued processes are necessarily periodic when they have a simply connected spectrum. Finally, we identify a surprising class of continuous fields with seemingly standard behavior, such as linear variance and finite dependency range, that undergo a phase transition: they are perfectly interpolable on B(0, $œÅ$) for $œÅ$ ___ 2 $œÄ$ but exhibit no rigidity for $œÅ$ \u003e 2.\nüìÑ Download PDF\nFano and Reflexive Polytopes from Feynman Integrals Authors: Leonardo de la Cruz, Pavel P. Novichkov, Pierre Vanhove Venue: arXiv (2025)\nWe classify the Fano and reflexive polytopes that arise from quasi-finite Feynman integrals. These polytopes appear as scaled Minkowski sums of the Newton polytopes associated with the Symanzik graph polynomials. For one-loop graphs and multiloop sunset graphs, we identify the Fano and reflexive cases by computing the number of interior points from the associated bivariate Ehrhart polynomials. More generally, we utilize the properties of Symanzik polynomials and their symmetries to conduct a direct search over all Feynman graphs in generic kinematics with up to ten edges and nine loops. We find that such cases are remarkably sparse: for example, we find only two two-dimensional reflexive polytopes, three three-dimensional reflexive polytopes, and four three-dimensional Fano polytopes. We also reveal a surprising feature of one-loop $N$-gon integrals in higher dimensions: their associated reflexive polytopes encode degenerate Calabi‚ÄìYau $(N-2)$-folds. We further analyze the geometric structures encoded by these polytopes and exhibit explicit connections with del Pezzo surfaces, $K3$ surfaces, and Calabi‚ÄìYau threefolds. Since reflexive polytopes naturally correspond to Calabi‚ÄìYau varieties, our classification demonstrates that quasi-finite Feynman integrals, with reflexive polytopes, are intrinsically linked to Calabi‚ÄìYau period integrals.\nüìÑ Download PDF\nNeighborhood Complexes of induced $k$-independent graphs Authors: Yufeng Shen, Zhiyu Song, Feneglin Yu, Leopold Wuhan Zhou, Jingqi Zhuang Venue: arXiv (2025)\nThis paper is devoted to the neighborhood complexes of the induced $k$-independent graphs. Inspired by the surprising correspondence between total $k$-cut complex of $n$-cycle $C_n$ and neighborhood complex of stable Kneser graph $SG(n,k)$, we anticipate that the homotopy type of total cut complexes may have some relationships with the neighborhood complexes of induced $k$-independent graphs. We investigated the homotopy type of some total cut complexes and neighborhood complexes of some other graphs, using techniques from algebraic topology and discrete Morse theory.\nüìÑ Download PDF\nUnderstanding the Failure Modes of Transformers through the Lens of Graph Neural Networks Authors: Hunjae Lee Venue: arXiv (2025)\nTransformers and more specifically decoder-only transformers dominate modern LLM architectures. While they have shown to work exceptionally well, they are not without issues, resulting in surprising failure modes and predictably asymmetric performance degradation. This article is a study of many of these observed failure modes of transformers through the lens of graph neural network (GNN) theory. We first make the case that much of deep learning, including transformers, is about learnable information mixing and propagation. This makes the study of model failure modes a study of bottlenecks in information propagation. This naturally leads to GNN theory, where there is already a rich literature on information propagation bottlenecks and theoretical failure modes of models. We then make the case that many issues faced by GNNs are also experienced by transformers. In addition, we analyze how the causal nature of decoder-only transformers create interesting geometric properties in information propagation, resulting in predictable and potentially devastating failure modes. Finally, we observe that existing solutions in transformer research tend to be ad-hoc and driven by intuition rather than grounded theoretical motivation. As such, we unify many such solutions under a more theoretical perspective, providing insight into why they work, what problem they are actually solving, and how they can be further improved to target specific failure modes of transformers. Overall, this article is an attempt to bridge the gap between observed failure modes in transformers and a general lack of theoretical understanding of them in this space.\nüìÑ Download PDF\nClassifier Reconstruction Through Counterfactual-Aware Wasserstein Prototypes Authors: Xuan Zhao, Zhuo Cao, Arya Bangun, Hanno Scharr, Ira Assent Venue: arXiv (2025)\nCounterfactual explanations provide actionable insights by identifying minimal input changes required to achieve a desired model prediction. Beyond their interpretability benefits, counterfactuals can also be leveraged for model reconstruction, where a surrogate model is trained to replicate the behavior of a target model. In this work, we demonstrate that model reconstruction can be significantly improved by recognizing that counterfactuals, which typically lie close to the decision boundary, can serve as informative though less representative samples for both classes. This is particularly beneficial in settings with limited access to labeled data. We propose a method that integrates original data samples with counterfactuals to approximate class prototypes using the Wasserstein barycenter, thereby preserving the underlying distributional structure of each class. This approach enhances the quality of the surrogate model and mitigates the issue of decision boundary shift, which commonly arises when counterfactuals are naively treated as ordinary training instances. Empirical results across multiple datasets show that our method improves fidelity between the surrogate and target models, validating its effectiveness.\nüìÑ Download PDF\nA Differentiable Digital Twin of Distributed Link Scheduling for Contention-Aware Networking Authors: Zhongyuan Zhao, Yujun Ming, Kevin Chan, Ananthram Swami, Santiago Segarra Venue: arXiv (2025)\nMany routing and flow optimization problems in wired networks can be solved efficiently using minimum cost flow formulations. However, this approach does not extend to wireless multi-hop networks, where the assumptions of fixed link capacity and linear cost structure collapse due to contention for shared spectrum resources. The key challenge is that the long-term capacity of a wireless link becomes a non-linear function of its network context, including network topology, link quality, and the traffic assigned to neighboring links. In this work, we pursue a new direction of modeling wireless network under randomized medium access control by developing an analytical network digital twin (NDT) that predicts link duty cycles from network context. We generalize randomized contention as finding a Maximal Independent Set (MIS) on the conflict graph using weighted Luby‚Äôs algorithm, derive an analytical model of link duty cycles, and introduce an iterative procedure that resolves the circular dependency among duty cycle, link capacity, and contention probability. Our numerical experiments show that the proposed NDT accurately predicts link duty cycles and congestion patterns with up to a 5000x speedup over packet-level simulation, and enables us to optimize link scheduling using gradient descent for reduced congestion and radio footprint.\nüìÑ Download PDF\nMultidimensional Sorting: Comparative Statics Authors: Job Boerma, Andrea Ottolini, Aleh Tsyvinski Venue: arXiv (2025)\nIn sorting literature, comparative statics for multidimensional assignment models with general output functions and input distributions is an important open question. We provide a complete theory of comparative statics for technological change in general multidimensional assignment models. Our main result is that any technological change is uniquely decomposed into two distinct components. The first component (gradient) gives a characterization of changes in marginal earnings through a Poisson equation. The second component (divergence-free) gives a characterization of labor reallocation. For U.S. data, we quantify equilibrium responses in sorting and earnings with respect to cognitive skill-biased technological change.\nüìÑ Download PDF\nAllometric scaling of brain activity explained by avalanche criticality Authors: Tiago S. A. N. Sim√µes, Jos√© S. Andrade, Hans J. Herrmann, Stefano Zapperi, Lucilla de Arcangelis Venue: arXiv (2025)\nAllometric scaling laws, such as Kleiber‚Äôs law for metabolic rate, highlight how efficiency emerges with size across living systems. The brain, with its characteristic sublinear scaling of activity, has long posed a puzzle: why do larger brains operate with disproportionately lower firing rates? Here we show that this economy of scale is a universal outcome of avalanche dynamics. We derive analytical scaling laws directly from avalanche statistics, establishing that any system governed by critical avalanches must exhibit sublinear activity-size relations. This theoretical prediction is then verified in integrate-and-fire neuronal networks at criticality and in classical self-organized criticality models, demonstrating that the effect is not model-specific but generic. The predicted exponents align with experimental observations across mammal species, bridging dynamical criticality with the allometry of brain metabolism. Our results reveal avalanche criticality as a fundamental mechanism underlying Kleiber-like scaling in the brain.\nüìÑ Download PDF\nAgile Deliberation: Concept Deliberation for Subjective Visual Classification Authors: Leijie Wang, Otilia Stretcu, Wei Qiao, Thomas Denby, Krishnamurthy Viswanathan, Enming Luo, Chun-Ta Lu, Tushar Dogra, Ranjay Krishna, Ariel Fuxman Venue: arXiv (2025)\nFrom content moderation to content curation, applications requiring vision classifiers for visual concepts are rapidly expanding. Existing human-in-the-loop approaches typically assume users begin with a clear, stable concept understanding to be able to provide high-quality supervision. In reality, users often start with a vague idea and must iteratively refine it through ‚Äúconcept deliberation‚Äù, a practice we uncovered through structured interviews with content moderation experts. We operationalize the common strategies in deliberation used by real content moderators into a human-in-the-loop framework called ‚ÄúAgile Deliberation‚Äù that explicitly supports evolving and subjective concepts. The system supports users in defining the concept for themselves by exposing them to borderline cases. The system does this with two deliberation stages: (1) concept scoping, which decomposes the initial concept into a structured hierarchy of sub-concepts, and (2) concept iteration, which surfaces semantically borderline examples for user reflection and feedback to iteratively align an image classifier with the user‚Äôs evolving intent. Since concept deliberation is inherently subjective and interactive, we painstakingly evaluate the framework through 18 user sessions, each 1.5h long, rather than standard benchmarking datasets. We find that Agile Deliberation achieves 7.5% higher F1 scores than automated decomposition baselines and more than 3% higher than manual deliberation, while participants reported clearer conceptual understanding and lower cognitive effort.\nüìÑ Download PDF\nParallel Neuron Groups in the Drosophila Brain Authors: Robert Worden Venue: arXiv (2025)\nThe full connectome of an adult Drosophila enables a search for novel neural structures in the insect brain. I describe a new neural structure, called a Parallel Neuron Group (PNG). Two neurons are called parallel if they share a significant number of input neurons and output neurons. Most pairs of neurons in the Drosophila brain have very small parallel match. There are about twenty larger groups of neurons for which any pair of neurons in the group has a high match. These are the parallel groups. Parallel groups contain only about 1000 out of the 65,000 neurons in the brain, and have distinctive properties. There are groups in the right mushroom bodies, the antennal lobes, the lobula, and in two central neuropils (GNG and EB). Most parallel groups do not have lateral symmetry. A group usually has one major input neuron, which inputs to all the neurons in the group, and a small number of major output neurons. The major input and output neurons are laterally asymmetric. Parallel neuron groups present puzzles, such as: what does a group do, that could not be done by one larger neuron? Do all neurons in a group fire in synchrony, or do they perform different functions? Why are they laterally asymmetric? These may merit further investigation.\nüìÑ Download PDF\nLow-Order $\\mathcal{H}2 / \\mathcal{H}\\infty$ Controller Design for Aeroelastic Vibration Suppression Authors: Mohammad Mirtaba, Juan Augusto Paredes Salazar, Daning Huang, Ankit Goel Venue: arXiv (2025)\nThis paper presents an $\\mathcal{H}2 / \\mathcal{H}\\infty$ minimization-based output-feedback controller for active aeroelastic vibration suppression in a cantilevered beam. First, a nonlinear structural model incorporating moderate deflection and aerodynamic loading is derived and discretized using the finite element method (FEM). Then, a low-order linear model is identified from random gaussian input response data from the FEM model to synthesize an output-feedback controller using the $\\mathcal{H}2 / \\mathcal{H}\\infty$ framework. A frequency-weighted dynamic filter is introduced to emphasize disturbance frequencies of interest, enabling the controller to target dominant vibration modes. Simulation results demonstrate the effectiveness of the proposed technique for vibration suppression and study its robustness to system parameter variations, including actuator placement.\nüìÑ Download PDF\nDecision Feedback-Aided Known-Interference Cancellation Authors: Karel P√§rlin, Aaron Byman, Tommi Meril√§inen, Taneli Riihonen Venue: arXiv (2025)\nKnown-interference cancellation (KIC) in combination with cooperative jamming can be used to provide covertness and security to wireless communications at the physical layer. However, since the signal of interest (SI) of a wireless communication system acts as estimation noise, i.e., interference, to KIC, the SI limits the extent to which the known interference (KI) can be canceled and that in turn limits the throughput of the wireless communication system that is being hidden or secured. In this letter, we analyze a decision feedback-aided known-interference cancellation (DF-KIC) structure in which both the KI and SI are canceled iteratively and successively. Measurement results demonstrate that introducing decision feedback to KIC improves its KI cancellation capability and hence increases the wireless communication system‚Äôs useful throughput, albeit at the expense of a higher computational load.\nüìÑ Download PDF\nIdentifiable factor analysis for mixed continuous and binary variables based on the Gaussian-Grassmann distribution Authors: Takashi Arai Venue: arXiv (2025)\nWe develop a factor analysis for mixed continuous and binary observed variables. To this end, we utilized a recently developed multivariate probability distribution for mixed-type random variables, the Gaussian-Grassmann distribution. In the proposed factor analysis, marginalization over latent variables can be performed analytically, yielding an analytical expression for the distribution of the observed variables. This analytical tractability allows model parameters to be estimated using standard gradient-based optimization techniques. We also address improper solutions associated with maximum likelihood factor analysis. We propose a prescription to avoid improper solutions by imposing a constraint that row vectors of the factor loading matrix have the same norm for all features. Then, we prove that the proposed factor analysis is identifiable under the norm constraint. We demonstrate the validity of this norm constraint prescription and numerically verified the model‚Äôs identifiability using both real and synthetic datasets. We also compare the proposed model with quantification method and found that the proposed model achieves better reproducibility of correlations than the quantification method.\nüìÑ Download PDF\nüîç llm AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation Authors: Sharath Girish, Viacheslav Ivanov, Tsai-Shien Chen, Hao Chen, Aliaksandr Siarohin, Sergey Tulyakov Venue: arXiv (2025)\nRecent advances in subject-driven video generation with large diffusion models have enabled personalized content synthesis conditioned on user-provided subjects. However, existing methods lack fine-grained temporal control over subject appearance and disappearance, which are essential for applications such as compositional video synthesis, storyboarding, and controllable animation. We propose AlcheMinT, a unified framework that introduces explicit timestamps conditioning for subject-driven video generation. Our approach introduces a novel positional encoding mechanism that unlocks the encoding of temporal intervals, associated in our case with subject identities, while seamlessly integrating with the pretrained video generation model positional embeddings. Additionally, we incorporate subject-descriptive text tokens to strengthen binding between visual identity and video captions, mitigating ambiguity during generation. Through token-wise concatenation, AlcheMinT avoids any additional cross-attention modules and incurs negligible parameter overhead. We establish a benchmark evaluating multiple subject identity preservation, video fidelity, and temporal adherence. Experimental results demonstrate that AlcheMinT achieves visual quality matching state-of-the-art video personalization methods, while, for the first time, enabling precise temporal control over multi-subject generation within videos. Project page is at https://snap-research.github.io/Video-AlcheMinT\nüìÑ Download PDF\nGaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting Authors: Madhav Agarwal, Mingtian Zhang, Laura Sevilla-Lara, Steven McDonagh Venue: arXiv (2025)\nSpeech-driven talking heads have recently emerged and enable interactive avatars. However, real-world applications are limited, as current methods achieve high visual fidelity but slow or fast yet temporally unstable. Diffusion methods provide realistic image generation, yet struggle with oneshot settings. Gaussian Splatting approaches are real-time, yet inaccuracies in facial tracking, or inconsistent Gaussian mappings, lead to unstable outputs and video artifacts that are detrimental to realistic use cases. We address this problem by mapping Gaussian Splatting using 3D Morphable Models to generate person-specific avatars. We introduce transformer-based prediction of model parameters, directly from audio, to drive temporal consistency. From monocular video and independent audio speech inputs, our method enables generation of real-time talking head videos where we report competitive quantitative and qualitative performance.\nüìÑ Download PDF\nStronger Normalization-Free Transformers Authors: Mingzhi Chen, Taiming Lu, Jiachen Zhu, Mingjie Sun, Zhuang Liu Venue: arXiv (2025)\nAlthough normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches normalization-level performance; this work seeks further for function designs that can surpass it. We first study how the intrinsic properties of point-wise functions influence training and performance. Building on these findings, we conduct a large-scale search for a more effective function design. Through this exploration, we introduce $\\mathrm{Derf}(x) = \\mathrm{erf}(Œ±x + s)$, where $\\mathrm{erf}(x)$ is the rescaled Gaussian cumulative distribution function, and identify it as the most performant design. Derf outperforms LayerNorm, RMSNorm, and DyT across a wide range of domains, including vision (image recognition and generation), speech representation, and DNA sequence modeling. Our findings suggest that the performance gains of Derf largely stem from its improved generalization rather than stronger fitting capacity. Its simplicity and stronger performance make Derf a practical choice for normalization-free Transformer architectures.\nüìÑ Download PDF\nEmpirical evaluation of the Frank-Wolfe methods for constructing white-box adversarial attacks Authors: Kristina Korotkova, Aleksandr Katrutsa Venue: arXiv (2025)\nThe construction of adversarial attacks for neural networks appears to be a crucial challenge for their deployment in various services. To estimate the adversarial robustness of a neural network, a fast and efficient approach is needed to construct adversarial attacks. Since the formalization of adversarial attack construction involves solving a specific optimization problem, we consider the problem of constructing an efficient and effective adversarial attack from a numerical optimization perspective. Specifically, we suggest utilizing advanced projection-free methods, known as modified Frank-Wolfe methods, to construct white-box adversarial attacks on the given input data. We perform a theoretical and numerical evaluation of these methods and compare them with standard approaches based on projection operations or geometrical intuition. Numerical experiments are performed on the MNIST and CIFAR-10 datasets, utilizing a multiclass logistic regression model, the convolutional neural networks (CNNs), and the Vision Transformer (ViT).\nüìÑ Download PDF\nAsynchronous Reasoning: Training-Free Interactive Thinking LLMs Authors: George Yakushev, Nataliia Babina, Masoud Vahid Dastgerdi, Vyacheslav Zhdanovskiy, Alina Shutova, Denis Kuznedelev Venue: arXiv (2025)\nMany state-of-the-art LLMs are trained to think before giving their answer. Reasoning can greatly improve language model capabilities and safety, but it also makes them less interactive: given a new input, a model must stop thinking before it can respond. Real-world use cases such as voice-based or embedded assistants require an LLM agent to respond and adapt to additional information in real time, which is incompatible with sequential interactions. In contrast, humans can listen, think, and act asynchronously: we begin thinking about the problem while reading it and continue thinking while formulating the answer. In this work, we augment LLMs capable of reasoning to operate in a similar way without additional training. Our method uses the properties of rotary embeddings to enable LLMs built for sequential interactions to simultaneously think, listen, and generate outputs. We evaluate our approach on math, commonsense, and safety reasoning and find that it can generate accurate thinking-augmented answers in real time, reducing time to first non-thinking token from minutes to \u003c= 5s. and the overall real-time delays by 6-11x.\nüìÑ Download PDF\nFLRW embeddings in $\\mathbb{R}^{n+2}$, differential geometry and conformal photon propagator Authors: E. Huguet, J. Queva, J. Renaud Venue: arXiv (2025)\nThis paper introduces differential-geometric methods to study $n$-dimensional locally conformally flat spaces as submanifolds in $\\mathbb{R}^{n+2}$. We derive explicit formulas relating intrinsic and ambient differential-geometric objects, including curvature tensors, the codifferential and laplacian operators. We apply this approach to Friedmann-Lema√Ætre-Robertson-Walker (FLRW) spaces using newfound embedding formulas, obtaining new and simplified expressions for the photon propagator in four dimensions.\nüìÑ Download PDF\nLLMs Can Assist with Proposal Selection at Large User Facilities Authors: Lijie Ding, Janell Thomson, Jon Taylor, Changwoo Do Venue: arXiv (2025)\nWe explore how large language models (LLMs) can enhance the proposal selection process at large user facilities, offering a scalable, consistent, and cost-effective alternative to traditional human review. Proposal selection depends on assessing the relative strength among submitted proposals; however, traditional human scoring often suffers from weak inter-proposal correlations and is subject to reviewer bias and inconsistency. A pairwise preference-based approach is logically superior, providing a more rigorous and internally consistent basis for ranking, but its quadratic workload makes it impractical for human reviewers. We address this limitation using LLMs. Leveraging the uniquely well-curated proposals and publication records from three beamlines at the Spallation Neutron Source (SNS), Oak Ridge National Laboratory (ORNL), we show that the LLM rankings correlate strongly with the human rankings (Spearman $œÅ\\simeq 0.2-0.8$, improving to $\\geq 0.5$ after 10% outlier removal). Moreover, LLM performance is no worse than that of human reviewers in identifying proposals with high publication potential, while costing over two orders of magnitude less. Beyond ranking, LLMs enable advanced analyses that are challenging for humans, such as quantitative assessment of proposal similarity via embedding models, which provides information crucial for review committees.\nüìÑ Download PDF\nüîç neuroscience Basic requirements for potential differences across solid‚Äìfluid interfaces Authors: David Fertig, Adrian L. Usler, Mathijs Janssen Venue: arXiv (2025)\nAt model water‚Äìvapor and water‚Äìsolid interfaces, molecular ordering leads to charge oscillations and, thereby, to a spatially varying electrostatic potential. Atomistic simulations indicate that such ordering leads to an electric potential difference $œá$, the surface potential, of about $-0.5,\\mathrm{V}$ across the first few molecular layers. Here, we calculate surface potentials at interfaces between a simple model fluids and a solid, with Molecular Dynamics simulations. The fluids are made up of either diatomic, dipolar molecules or a single Lennard-Jones particle with a dipole moment. All fluids show some structuring near the interface, but charge oscillations and a non-zero surface potential are present only for asymmetric molecules (unequal diameters of the atoms) or molecules with an off-center dipole. We condense this finding into the criterion that the geometric and dipolar centers of a molecule must differ for the fluid to exhibit a surface potential. Remarkably, while the solid‚Äìfluid interaction strength strongly affects the magnitude of charge oscillations, it hardly affects the potential drop $œá$. Further, our results demonstrate that changing the diameter of the smaller atom can flip the sign of the surface potential, thus highlighting the importance of steric effects.\nüìÑ Download PDF\nLabelFusion: Learning to Fuse LLMs and Transformer Classifiers for Robust Text Classification Authors: Michael Schlee, Christoph Weisser, Timo Kivim√§ki, Melchizedek Mashiku, Benjamin Saefken Venue: arXiv (2025)\nLabelFusion is a fusion ensemble for text classification that learns to combine a traditional transformer-based classifier (e.g., RoBERTa) with one or more Large Language Models (LLMs such as OpenAI GPT, Google Gemini, or DeepSeek) to deliver accurate and cost-aware predictions across multi-class and multi-label tasks. The package provides a simple high-level interface (AutoFusionClassifier) that trains the full pipeline end-to-end with minimal configuration, and a flexible API for advanced users. Under the hood, LabelFusion integrates vector signals from both sources by concatenating the ML backbone‚Äôs embeddings with the LLM-derived per-class scores ‚Äì obtained through structured prompt-engineering strategies ‚Äì and feeds this joint representation into a compact multi-layer perceptron (FusionMLP) that produces the final prediction. This learned fusion approach captures complementary strengths of LLM reasoning and traditional transformer-based classifiers, yielding robust performance across domains ‚Äì achieving 92.4% accuracy on AG News and 92.3% on 10-class Reuters 21578 topic classification ‚Äì while enabling practical trade-offs between accuracy, latency, and cost.\nüìÑ Download PDF\nNatural Language Interface for Firewall Configuration Authors: F. Taghiyev, A. Aslanbayli Venue: arXiv (2025)\nThis paper presents the design and prototype implementation of a natural language interface for configuring enterprise firewalls. The framework allows administrators to express access control policies in plain language, which are then translated into vendor specific configurations. A compact schema bound intermediate representation separates human intent from device syntax and in the current prototype compiles to Palo Alto PAN OS command line configuration while remaining extensible to other platforms. Large language models are used only as assistive parsers that generate typed intermediate representation objects, while compilation and enforcement remain deterministic. The prototype integrates three validation layers, namely a static linter that checks structural and vendor specific constraints, a safety gate that blocks overly permissive rules such as any to any allows, and a Batfish based simulator that validates configuration syntax and referential integrity against a synthetic device model. The paper describes the architecture, implementation, and test methodology on synthetic network context datasets and discusses how this approach can evolve into a scalable auditable and human centered workflow for firewall policy management.\nüìÑ Download PDF\nPerformance and reliability potential of Bi$_2$O$_2$Se/Bi$_2$SeO$_5$ transistors Authors: Mohammad Rasool Davoudi, Mina Bahrami, Axel Verdianu, Pedram Khakbaz, Dominic Waldhoer, Mahdi Pourfath, Alexander Karl, Christoph Wilhelmer, Yichi Zhang, Junchuan Tang, Aftab Nazir, Ye Li, Xiaoying Gao, Congwei Tan, Yu Zhang, Changze Liu, Hailin Peng, Theresia Knobloch, Tibor Grasser Venue: arXiv (2025)\nWhile 2D materials have enormous potential for future device technologies, many challenges must be overcome before they can be deployed at an industrial scale. One of these challenges is identifying the right semiconductor/insulator combination that ensures high performance, stability, and reliability. In contrast to conventional 2D interfaces, which suffer from van der Waals gaps or covalent bonding issues, zippered structures such as the high-mobility 2D semiconductor Bi$_2$O$_2$Se and its native high-$Œ∫$ oxide Bi$_2$SeO$_5$ offer high-quality interfaces, good scalability, and excellent device performance. While most prior work has focused mainly on basic device behavior, here we also thoroughly assess the stability and reliability of this material system using a multiscale approach that integrates electrical characterization, density functional theory, and TCAD simulations, linking atomistic states to device-scale reliability. By analyzing four transistor design generations (top-gated, fin, and two gate-all-around FETs), we provide realistic predictions for how this system performs at the ultimate scaling limit. We identify oxygen-related defects in the oxide as the main contributors to hysteresis and recoverable threshold shifts, and we propose mitigation strategies through encapsulation or oxygen-rich annealing. Benchmarking the extracted material parameters against IRDS 2037 requirements, we demonstrate that Bi$_2$O$_2$Se/Bi$_2$SeO$_5$ transistors can achieve high drain and low gate currents at ultra-scaled conditions. These findings position this material system as a technologically credible and manufacturing-relevant pathway for future nanoelectronics.\nüìÑ Download PDF\nEpitaxial Sr(Sn, Ge)${x}$Ti${1-x}$O${3}$ buffer layers for continuous strain engineering on SrTiO${3}$ substrates Authors: Ruben Hamming-Green, Ewout van der Veer, Beatriz Noheda Venue: arXiv (2025)\nEpitaxial strain plays a key role in determining the structure and functionality of thin films, with the choice of substrate being traditionally used to control the magnitude of the applied strain. However, even in the large family of perovskite materials, this allows for only a limited, discrete set of strain states to be achieved. Here we report on an approach to controlling epitaxial strain for the growth of perovskite materials by involving a single SrTiO${3}$ substrate (the most available perovskite in single crystal form) and a buffer layer that consists of the solid solution Sr(Sn, Ge)${x}$Ti${1-x}$O${3}$, of which the lattice parameter can be tuned in a continuous fashion, from 3.880 √Ö up to 4.007 √Ö, while maintaining coherent epitaxial growth on SrTiO${3}$ with high quality interfaces. Using a BaTiO${3}$ overlayer as a model system, we show that changes to the buffer layer composition, i.e. increase of in-plane lattice parameter, change the strain state of BaTiO$_{3}$ from fully relaxed, through highly compressively strained, to an exotic state showing ‚Äòinverted‚Äô epitaxy in which the buffer layer is relaxed from the substrate but lattice matched to the overlayer.\nüìÑ Download PDF\nüîç data_resources From Data Scarcity to Data Care: Reimagining Language Technologies for Serbian and other Low-Resource Languages Authors: Smiljana Antonijevic Ubois Venue: arXiv (2025)\nLarge language models are commonly trained on dominant languages like English, and their representation of low resource languages typically reflects cultural and linguistic biases present in the source language materials. Using the Serbian language as a case, this study examines the structural, historical, and sociotechnical factors shaping language technology development for low resource languages in the AI age. Drawing on semi structured interviews with ten scholars and practitioners, including linguists, digital humanists, and AI developers, it traces challenges rooted in historical destruction of Serbian textual heritage, intensified by contemporary issues that drive reductive, engineering first approaches prioritizing functionality over linguistic nuance. These include superficial transliteration, reliance on English-trained models, data bias, and dataset curation lacking cultural specificity. To address these challenges, the study proposes Data Care, a framework grounded in CARE principles (Collective Benefit, Authority to Control, Responsibility, and Ethics), that reframes bias mitigation from a post hoc technical fix to an integral component of corpus design, annotation, and governance, and positions Data Care as a replicable model for building inclusive, sustainable, and culturally grounded language technologies in contexts where traditional LLM development reproduces existing power imbalances and cultural blind spots.\nüìÑ Download PDF\nSemantic Reconstruction of Adversarial Plagiarism: A Context-Aware Framework for Detecting and Restoring ‚ÄúTortured Phrases‚Äù in Scientific Literature Authors: Agniva Maiti, Prajwal Panth, Suresh Chandra Satapathy Venue: arXiv (2025)\nThe integrity and reliability of scientific literature is facing a serious threat by adversarial text generation techniques, specifically from the use of automated paraphrasing tools to mask plagiarism. These tools generate ‚Äútortured phrases‚Äù, statistically improbable synonyms (e.g. ‚Äúcounterfeit consciousness‚Äù for ‚Äúartificial intelligence‚Äù), that preserve the local grammar while obscuring the original source. Most existing detection methods depend heavily on static blocklists or general-domain language models, which suffer from high false-negative rates for novel obfuscations and cannot determine the source of the plagiarized content. In this paper, we propose Semantic Reconstruction of Adversarial Plagiarism (SRAP), a framework designed not only to detect these anomalies but to mathematically recover the original terminology. We use a two-stage architecture: (1) statistical anomaly detection with a domain-specific masked language model (SciBERT) using token-level pseudo-perplexity, and (2) source-based semantic reconstruction using dense vector retrieval (FAISS) and sentence-level alignment (SBERT). Experiments on a parallel corpus of adversarial scientific text show that while zero-shot baselines fail completely (0.00 percent restoration accuracy), our retrieval-augmented approach achieves 23.67 percent restoration accuracy, significantly outperforming baseline methods. We also show that static decision boundaries are necessary for robust detection in jargon-heavy scientific text, since dynamic thresholding fails under high variance. SRAP enables forensic analysis by linking obfuscated expressions back to their most probable source documents.\nüìÑ Download PDF\nPrivTune: Efficient and Privacy-Preserving Fine-Tuning of Large Language Models via Device-Cloud Collaboration Authors: Yi Liu, Weixiang Han, Chengjun Cai, Xingliang Yuan, Cong Wang Venue: arXiv (2025)\nWith the rise of large language models, service providers offer language models as a service, enabling users to fine-tune customized models via uploaded private datasets. However, this raises concerns about sensitive data leakage. Prior methods, relying on differential privacy within device-cloud collaboration frameworks, struggle to balance privacy and utility, exposing users to inference attacks or degrading fine-tuning performance. To address this, we propose PrivTune, an efficient and privacy-preserving fine-tuning framework via Split Learning (SL). The key idea of PrivTune is to inject crafted noise into token representations from the SL bottom model, making each token resemble the $n$-hop indirect neighbors. PrivTune formulates this as an optimization problem to compute the optimal noise vector, aligning with defense-utility goals. On this basis, it then adjusts the parameters (i.e., mean) of the $d_œá$-Privacy noise distribution to align with the optimization direction and scales the noise according to token importance to minimize distortion. Experiments on five datasets (covering both classification and generation tasks) against three embedding inversion and three attribute inference attacks show that, using RoBERTa on the Stanford Sentiment Treebank dataset, PrivTune reduces the attack success rate to 10% with only a 3.33% drop in utility performance, outperforming state-of-the-art baselines.\nüìÑ Download PDF\nüîç emotion_language Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity Authors: Hauke Licht Venue: arXiv (2025)\nEmotions are central to politics and analyzing their role in political communication has a long tradition. As research increasingly leverages audio-visual materials to analyze the display of emotions, the emergence of multimodal generative AI promises great advances. However, we lack evidence about the effectiveness of multimodal AI in emotion analysis. This paper addresses this gap by evaluating current multimodal large language models (mLLMs) in video-based analysis of emotional arousal in two complementary data sets of human-labeled video recordings. I find that under ideal circumstances, mLLMs‚Äô emotional arousal ratings are highly reliable and show little to know indication of demographic bias. However, in recordings of speakers in real-world parliamentary debates, mLLMs‚Äô arousal ratings fail to deliver on this promise with potential negative consequences for downstream statistical inferences. This study therefore underscores the need for continued, thorough evaluation of emerging generative AI methods in political analysis and contributes a suitable replicable framework.\nüìÑ Download PDF\nQuantifying Emotional Tone in Tolkien‚Äôs The Hobbit: Dialogue Sentiment Analysis with RegEx, NRC-VAD, and Python Authors: Lilin Qiu Venue: arXiv (2025)\nThis study analyzes the emotional tone of dialogue in J. R. R. Tolkien‚Äôs The Hobbit (1937) using computational text analysis. Dialogue was extracted with regular expressions, then preprocessed, and scored using the NRC-VAD lexicon to quantify emotional dimensions. The results show that the dialogue maintains a generally positive (high valence) and calm (low arousal) tone, with a gradually increasing sense of agency (dominance) as the story progresses. These patterns reflect the novel‚Äôs emotional rhythm: moments of danger and excitement are regularly balanced by humor, camaraderie, and relief. Visualizations ‚Äì including emotional trajectory graphs and word clouds ‚Äì highlight how Tolkien‚Äôs language cycles between tension and comfort. By combining computational tools with literary interpretation, this study demonstrates how digital methods can uncover subtle emotional structures in literature, revealing the steady rhythm and emotional modulation that shape the storytelling in The Hobbit.\nüìÑ Download PDF\nSelf-Ensemble Post Learning for Noisy Domain Generalization Authors: Wang Lu, Jindong Wang Venue: arXiv (2025)\nWhile computer vision and machine learning have made great progress, their robustness is still challenged by two key issues: data distribution shift and label noise. When domain generalization (DG) encounters noise, noisy labels further exacerbate the emergence of spurious features in deep layers, i.e. spurious feature enlargement, leading to a degradation in the performance of existing algorithms. This paper, starting from domain generalization, explores how to make existing methods rework when meeting noise. We find that the latent features inside the model have certain discriminative capabilities, and different latent features focus on different parts of the image. Based on these observations, we propose the Self-Ensemble Post Learning approach (SEPL) to diversify features which can be leveraged. Specifically, SEPL consists of two parts: feature probing training and prediction ensemble inference. It leverages intermediate feature representations within the model architecture, training multiple probing classifiers to fully exploit the capabilities of pre-trained models, while the final predictions are obtained through the integration of outputs from these diverse classification heads. Considering the presence of noisy labels, we employ semi-supervised algorithms to train probing classifiers. Given that different probing classifiers focus on different areas, we integrate their predictions using a crowdsourcing inference approach. Extensive experimental evaluations demonstrate that the proposed method not only enhances the robustness of existing methods but also exhibits significant potential for real-world applications with high flexibility.\nüìÑ Download PDF\nSparseSwaps: Tractable LLM Pruning Mask Refinement at Scale Authors: Max Zimmer, Christophe Roux, Moritz Wagner, Deborah Hendrych, Sebastian Pokutta Venue: arXiv (2025)\nThe resource requirements of Neural Networks can be significantly reduced through pruning ‚Äì the removal of seemingly less important parameters. However, with the rise of Large Language Models (LLMs), full retraining to recover pruning-induced performance degradation is often prohibitive and classical approaches such as global magnitude pruning are suboptimal on Transformer architectures. State-of-the-art methods hence solve a layer-wise mask selection problem, the problem of finding a pruning mask which minimizes the per-layer pruning error on a small set of calibration data. Exactly solving this problem to optimality using Integer Programming (IP) solvers is computationally infeasible due to its combinatorial nature and the size of the search space, and existing approaches therefore rely on approximations or heuristics. In this work, we demonstrate that the mask selection problem can be made drastically more tractable at LLM scale. To that end, we decouple the rows by enforcing equal sparsity levels per row. This allows us to derive optimal 1-swaps (exchanging one kept and one pruned weight) that can be computed efficiently using the Gram matrix of the calibration data. Using these observations, we propose a tractable and simple 1-swap algorithm that warm starts from any pruning mask, runs efficiently on GPUs at LLM scale, and is essentially hyperparameter-free. We demonstrate that our approach reduces per-layer pruning error by up to 60% over Wanda (Sun et al., 2023) and consistently improves perplexity and zero-shot accuracy across state-of-the-art GPT architectures.\nüìÑ Download PDF\nQubit decoherence in dissipative two-photon resonator: real-time instantons and Wigner function Authors: V. Yu. Mylnikov, S. O. Potashin, Alex Kamenev Venue: arXiv (2025)\nWe study the quantum dynamics of a single bosonic cavity subject to two-photon driving and two-photon dissipation in the presence of finite detuning. Exploiting a hidden time-reversal symmetry, the Wigner representation and the WKB method, we introduce an effective phase-space potential for description of the steady state. It reveals two attracting points, which are metastable due to quantum fluctuations. By employing the Keldysh real-time path integral formalism, we compute the instanton trajectory governing the quantum activation process between these attractors and establish a fundamental connection with the Wigner representation. This relation unifies the steady-state phase-space description with dynamical quantum activation processes. We also derive an analytical expression for the decoherence rate of the system. Our work provides a coherent theoretical framework for analyzing quantum bistability, metastability, and decoherence in driven-dissipative nonlinear resonators, with direct implications for the design of bosonic qubits and quantum information processing.\nüìÑ Download PDF\nGlobal stabilization of the planar Ricker system with noisy PBC Authors: Elena Braverman, Alexandra Rodkina Venue: arXiv (2025)\nWe apply Prediction-Based control (PBC) in order to stabilize globally a positive equilibrium of a planar Ricker‚Äôs equation. We construct a closed invariant set in a strictly positive domain for the controlled map and derive conditions on control parameters ensuring that the increments of a specially constructed Lyapunov function are nonpositive on this set. By stochastic perturbation of the parameters we decrease the average values of controls providing global, as well as local, stabilization. Computer simulations illustrate our results.\nüìÑ Download PDF\nPair-density-wave in quarter-metals from a repulsive fermionic interaction in graphene heterostructures: A renormalization group study Authors: Sk Asrap Murshed, Bitan Roy Venue: arXiv (2025)\nElectronic bands in chirally stacked $n$ layer carbon-based honeycomb heterostructures, encompassing rhombohedral ($n \\geq 3$), Bernal bilayer ($n=2$), and monolayer ($n=1$) graphene, possess four-fold valley and spin degeneracy. Such systems with $n \\geq 2$, when subject to external perpendicular electric displacement fields, feature a fully degenerate metal at high doping, a spin non-degenerate but valley degenerate half-metal at moderate doping, and a non-degenerate quarter-metal at low doping. Due to the fully polarized nature of the quasiparticles in the quarter-metal, realized around one particular valley otherwise chosen spontaneously, it can sustain a single local superconducting ground state, representing a pair-density-wave that is chiral and odd parity in nature. From a leading order renormalization group analysis, here we show that repulsive density-density interaction among such polarized fermionic excitations can foster the pair-density-wave phase at low temperatures. Possible connections with experimentally observed superconducting states in the close vicinity of the quarter-metal in some members of such graphene heterostructures family are discussed.\nüìÑ Download PDF\nShaping chaos in bilayer graphene cavities Authors: Jucheng Lin, Yicheng Zhuang, Anton M. Graf, Joonas Keski-Rahkonen, Eric J. Heller Venue: arXiv (2025)\nBilayer graphene (BLG) cavities, where electrons are confined in finite graphene flakes, provide a suitable platform to study quantum chaotic phenomena in condensed matter systems due to the trigonal warping of the Fermi surface. Here, we investigate the effect of the misalignment between the BLG lattice and the cavity geometry, introduced by rotating the boundary relative to the lattice, which can drive the system towards chaos. Based on a tight-binding model, eigenenergy level statistics reveals that rotation leads to level repulsion following Wigner-Dyson statistics, while corresponding eigenstate analysis indicates a transition from near-integrability to spatially uncorrelated random waves. Analysis of the semiclassical ray-dynamics with the trigonal-warped dispersion unveils an ergodic phase space structure, providing a quantum-classical correspondence of the onset of chaos. These findings establish an avenue to quantum chaotic phenomena in BLG cavities with potential applications in quantum device engineering.\nüìÑ Download PDF\nObservability inequality for the von Neumann equation in crystals Authors: Thomas Borsoni, Virginie Ehrlacher Venue: arXiv (2025)\nWe provide a quantitative observability inequality for the von Neumann equation on $\\mathbb{R}^d$ in the crystal setting, uniform in small $\\hbar$. Following the method of Golse and Paul (2022) proving this result in the non-crystal setting, the method relies on a stability argument between the quantum (von Neumann) and classical (Liouville) dynamics and uses an optimal transport-like pseudo-distance between quantum and classical densities. Our contribution yields in the adaptation of all the required tools to the periodic setting, relying on the Bloch decomposition, notions of periodic Schr√∂dinger coherent state, periodic T√∂plitz operator and periodic Husimi densities.\nüìÑ Download PDF\nWeak Gravity Conjecture in the sky: gravitational waves from preheating in Einstein-Maxwell-Scalar EFT Authors: Jiaxin Cheng, Anna Tokareva Venue: arXiv (2025)\nThe effective field theory (EFT) concept provides a necessary tool for obtaining general predictions of low-energy theory valid below its unitarity-breaking scale (cutoff scale). Early Universe inflation and subsequent reheating could be a unique setup for testing potentially observable effects coming from the derivative expansion of the corresponding EFT around the flat space vacuum. In this work, we consider an EFT describing perturbative reheating dominated by the decay of inflaton to photons caused by the dimension-5 operator $œÜF_{ŒºŒΩ} F^{ŒºŒΩ}$. We compute the graviton production during reheating and high frequency gravitational wave signal due to the bremsstrahlung effect in the presence of $R_{ŒºŒΩŒªœÅ}F^{ŒºŒΩ} F^{ŒªœÅ}$ operator. It may lead to the dominant contribution at high momenta if the EFT cutoff is lower than the Planck mass. Assuming the general consequences of the unitarity and causality constraints, which imply that all EFT operators should be present, and be suppressed by the scales following from the dimension analysis, we obtain the observational constraints (CMB bound for the dark radiation) on the mass of the inflaton and UV cutoff of gravity. We find that for the typical parameters of large field inflation models, the gravitational cutoff scale cannot be lower than $10^{15}$ GeV.\nüìÑ Download PDF\nTwin-paradox and Entanglement Authors: K. Hari, Subhajit Barman, Dawood Kothawala Venue: arXiv (2025)\nWe study the quantum version of the classical twin paradox in special relativity by replacing the twins with quantum detectors, and studying the transitions and entanglement induced by coupling them to a quantum field. We show that the \\textit{changes} in direction of acceleration leave imprints on detector responses and entanglement, inducing novel features which might have relevance in black hole spacetimes.\nüìÑ Download PDF\nMulti-Granular Node Pruning for Circuit Discovery Authors: Muhammad Umair Haider, Hammad Rizwan, Hassan Sajjad, A. B. Siddique Venue: arXiv (2025)\nCircuit discovery aims to identify minimal subnetworks that are responsible for specific behaviors in large language models (LLMs). Existing approaches primarily rely on iterative edge pruning, which is computationally expensive and limited to coarse-grained units such as attention heads or MLP blocks, overlooking finer structures like individual neurons. We propose a node-level pruning framework for circuit discovery that addresses both scalability and granularity limitations. Our method introduces learnable masks across multiple levels of granularity, from entire blocks to individual neurons, within a unified optimization objective. Granularity-specific sparsity penalties guide the pruning process, allowing a comprehensive compression in a single fine-tuning run. Empirically, our approach identifies circuits that are smaller in nodes than those discovered by prior methods; moreover, we demonstrate that many neurons deemed important by coarse methods are actually irrelevant, while still maintaining task performance. Furthermore, our method has a significantly lower memory footprint, 5-10x, as it does not require keeping intermediate activations in the memory to work.\nüìÑ Download PDF\nThe FACTS Leaderboard: A Comprehensive Benchmark for Large Language Model Factuality Authors: Aileen Cheng, Alon Jacovi, Amir Globerson, Ben Golan, Charles Kwong, Chris Alberti, Connie Tao, Eyal Ben-David, Gaurav Singh Tomar, Lukas Haas, Yonatan Bitton, Adam Bloniarz, Aijun Bai, Andrew Wang, Anfal Siddiqui, Arturo Bajuelos Castillo, Aviel Atias, Chang Liu, Corey Fry, Daniel Balle, Deepanway Ghosal, Doron Kukliansky, Dror Marcus, Elena Gribovskaya, Eran Ofek, Honglei Zhuang, Itay Laish, Jan Ackermann, Lily Wang, Meg Risdal, Megan Barnes, Michael Fink, Mohamed Amin, Moran Ambar, Natan Potikha, Nikita Gupta, Nitzan Katz, Noam Velan, Ofir Roval, Ori Ram, Polina Zablotskaia, Prathamesh Bang, Priyanka Agrawal, Rakesh Ghiya, Sanjay Ganapathy, Simon Baumgartner, Sofia Erell, Sushant Prakash, Thibault Sellam, Vikram Rao, Xuanhui Wang, Yaroslav Akulov, Yulong Yang, Zhen Yang, Zhixin Lai, Zhongru Wu, Anca Dragan, Avinatan Hassidim, Fernando Pereira, Slav Petrov, Srinivasan Venkatachary, Tulsee Doshi, Yossi Matias, Sasha Goldshtein, Dipanjan Das Venue: arXiv (2025)\nWe introduce The FACTS Leaderboard, an online leaderboard suite and associated set of benchmarks that comprehensively evaluates the ability of language models to generate factually accurate text across diverse scenarios. The suite provides a holistic measure of factuality by aggregating the performance of models on four distinct sub-leaderboards: (1) FACTS Multimodal, which measures the factuality of responses to image-based questions; (2) FACTS Parametric, which assesses models‚Äô world knowledge by answering closed-book factoid questions from internal parameters; (3) FACTS Search, which evaluates factuality in information-seeking scenarios, where the model must use a search API; and (4) FACTS Grounding (v2), which evaluates whether long-form responses are grounded in provided documents, featuring significantly improved judge models. Each sub-leaderboard employs automated judge models to score model responses, and the final suite score is an average of the four components, designed to provide a robust and balanced assessment of a model‚Äôs overall factuality. The FACTS Leaderboard Suite will be actively maintained, containing both public and private splits to allow for external participation while guarding its integrity. It can be found at https://www.kaggle.com/benchmarks/google/facts .\nüìÑ Download PDF\nChemical enrichment in LINERs from MaNGA. II. Characterizing the shape of their radial metallicity gradients Authors: Borja P√©rez-D√≠az, Jos√© M. V√≠lchez, Enrique P√©rez Montero, Igor A. Zinchenko, Brian Tapia-Contreras, Patricia B. Tissera Venue: arXiv (2025)\nChemical abundance radial gradients provide key information on how the processes that affect chemical enrichment of the gas-phase interstellar medium (ISM) act at different galaxy scales. Whereas in the last decades there has been an increase in the number of galaxies studied with integral field spectroscopy, there is still not a clear picture on a subsequent characterization of the chemical abundance radial gradients in galaxies hosting Active Galactic Nuclei (AGNs). This lack of analysis is even more accentuated in the case of low-ionization nuclear emission-line regions (LINERs). For the first time, we analyze the chemical abundance radial gradients in a sample of LINER-like galaxies, whose nuclear emission has been previously (Paper I) discussed. We use a sample of 97 galaxies from the Mapping Nearby Galaxies at Apache Point Observatory (MaNGA), whose nuclear regions show LINER-like emission. We use the open-source code HII-CHI-Mistry to estimate the chemical abundance ratios 12+log(O/H) and log(N/O) in the HII regions across the disks in our sample, as well as in the nuclear parts where the LINER-like activity dominates. To fit the radial profiles we use a piecewise methodology which uses a non-fixed number of breaks to find the best fit for the data. We obtain that majority of our sample of galaxies exhibits departures from the single linear gradient both in 12+log(O/H) and log(N/O) (as expected from the inside-out scenario). We investigate whether these departures are driven by galaxy properties (stellar mass, neutral gas mass, stellar velocity dispersion), finding not correlation at all. We also report that in most cases there is no correlation between the shape of the 12+log(O/H) and log(N/O) radial profiles. We propose a model in which AGN (feed)back, acting at different scales depending on the galaxy and its evolutionary stage, might be responsible for these departures.\nüìÑ Download PDF\nSignatures of star formation inside galactic outflows Authors: Dily Duan Yi Ong, Francesco D‚ÄôEugenio, Roberto Maiolino, Santiago Arribas, Francesco Belfiore, Enrica Bellocchi, Stefano Carniani, Sara Cazzoli, Giovanni Cresci, Andrew Fabian, Wako Ishibashi, Filippo Mannucci, Alessandro Marconi, Helen Russell, Eckhard Sturm, Giacomo Venturi Venue: arXiv (2025)\nObservations have suggested that galactic outflows contain substantial amounts of dense and clumpy molecular gas, creating favourable conditions for igniting star formation. Indeed, theoretical models and hydrodynamical simulations have suggested that stars could form within galactic outflows, representing a new mode of star-formation that differs significantly from the typical star formation in star forming discs. In this paper, we examine 12 local galaxies with powerful Active Galactic Nuclei and high star-formation rate using spectroscopic data from the X-shooter spectrograph at the Very Large Telescope. We investigate the excitation mechanism and physical properties of these outflows via spatially resolved diagnostic diagrams (along with tests to rule out contribution by shocks and external photoionisation). Out of the seven galaxies with clearly detected outflows, we find robust evidence for star formation within the outflow of one galaxy (IRAS 20551-4250), with two additional galaxies showing tentative signs (IRAS 13120-5453 and F13229-2934). Therefore, our findings support previous results that star formation inside outflows can be a relatively common phenomenon among these active galaxies and may have played an important role in the formation and evolution of the spheroidal component of galaxies.\nüìÑ Download PDF\nCompanionCast: A Multi-Agent Conversational AI Framework with Spatial Audio for Social Co-Viewing Experiences Authors: Yiyang Wang, Chen Chen, Tica Lin, Vishnu Raj, Josh Kimball, Alex Cabral, Josiah Hester Venue: arXiv (2025)\nSocial presence is central to the enjoyment of watching content together, yet modern media consumption is increasingly solitary. We investigate whether multi-agent conversational AI systems can recreate the dynamics of shared viewing experiences across diverse content types. We present CompanionCast, a general framework for orchestrating multiple role-specialized AI agents that respond to video content using multimodal inputs, speech synthesis, and spatial audio. Distinctly, CompanionCast integrates an LLM-as-a-Judge module that iteratively scores and refines conversations across five dimensions (relevance, authenticity, engagement, diversity, personality consistency). We validate this framework through sports viewing, a domain with rich dynamics and strong social traditions, where a pilot study with soccer fans suggests that multi-agent interaction improves perceived social presence compared to solo viewing. We contribute: (1) a generalizable framework for orchestrating multi-agent conversations around multimodal video content, (2) a novel evaluator-agent pipeline for conversation quality control, and (3) exploratory evidence of increased social presence in AI-mediated co-viewing. We discuss challenges and future directions for applying this approach to diverse viewing contexts including entertainment, education, and collaborative watching experiences.\nüìÑ Download PDF\nQuantifying displacement: a gentrification‚Äôs consequence via persistent homology Authors: Rita Rodr√≠guez V√°zquez, Manuel Cuerno Venue: arXiv (2025)\nGentrification is the process by which wealthier individuals move into a previously lower-income neighbourhood. Among the effects of this multi-faceted phenomenon are rising living costs, cultural and social changes-where local traditions, businesses, and community networks are replaced or diluted by new, more affluent lifestyles-and population displacement, where long-term, lower-income residents are priced out by rising rents and property taxes. Despite its relevance, quantifying displacement presents difficulties stemming from lack of information on motives for relocation and from the fact that a long time-span must be analysed: displacement is a gradual process (leases end or conditions change at different times), impossible to capture in one data snapshot. We introduce a novel tool to overcome these difficulties. Using only publicly available address change data, we construct four cubical complexes which simultaneously incorporate geographical and temporal information of people moving, and then analyse them building on Topological Data Analysis tools. Finally, we demonstrate the potential of this method through a 20-year case study of Madrid, Spain. The results reveal its ability to capture population displacement and to identify the specific neighbourhoods and years affected‚Äìpatterns that cannot be inferred from raw address change data.\nüìÑ Download PDF\nSupporting Migration Policies with Forecasts: Illegal Border Crossings in Europe through a Mixed Approach Authors: C. Bosco, U. Minora, D. de Rigo, J. Pingsdorf, R. Cortinovis Venue: arXiv (2025)\nThis paper presents a mixed-methodology to forecast illegal border crossings in Europe across five key migratory routes, with a one-year time horizon. The methodology integrates machine learning techniques with qualitative insights from migration experts. This approach aims at improving the predictive capacity of data-driven models through the inclusion of a human-assessed covariate, an innovation that addresses challenges posed by sudden shifts in migration patterns and limitations in traditional datasets. The proposed methodology responds directly to the forecasting needs outlined in the EU Pact on Migration and Asylum, supporting the Asylum and Migration Management Regulation (AMMR). It is designed to provide policy-relevant forecasts that inform strategic decisions, early warning systems, and solidarity mechanisms among EU Member States. By joining data-driven modeling with expert judgment, this work aligns with existing academic recommendations and introduces a novel operational tool tailored for EU migration governance. The methodology is tested and validated with known data to demonstrate its applicability and reliability in migration-related policy context.\nüìÑ Download PDF\n","wordCount":"26129","inLanguage":"zh","datePublished":"2025-12-14T15:23:14.907278Z","dateModified":"2025-12-14T15:23:14.907278Z","author":{"@type":"Person","name":"Gary"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://garyforreal.me/zh/posts/paper/paper-2025-12-14-weekly/"},"publisher":{"@type":"Organization","name":"Gary's House","logo":{"@type":"ImageObject","url":"https://garyforreal.me/img/Q.jpg"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css><script src=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><script src=https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js></script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://garyforreal.me/zh/ accesskey=h title="Gary's Blog (Alt + H)"><img src=https://garyforreal.me/img/me.jpg alt aria-label=logo height=35>Gary's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://garyforreal.me/en/ title=English aria-label=English>English</a></li></ul></div></div><ul id=menu><li><a href=https://garyforreal.me/zh/search title="üîçÊêúÁ¥¢ (Alt + /)" accesskey=/><span>üîçÊêúÁ¥¢</span></a></li><li><a href=https://garyforreal.me/zh/ title=üè†‰∏ªÈ°µ><span>üè†‰∏ªÈ°µ</span></a></li><li><a href=https://garyforreal.me/zh/posts/ title=üìöÊñáÁ´†><span>üìöÊñáÁ´†</span></a></li><li><a href=https://garyforreal.me/zh/archives/ title=‚è±Â≠òÊ°£><span>‚è±Â≠òÊ°£</span></a></li><li><a href=https://garyforreal.me/zh/music/ title=üéµÈü≥‰πê><span>üéµÈü≥‰πê</span></a></li><li><a href=https://garyforreal.me/zh/about title=üôãüèª‚Äç‚ôÇÔ∏èÂÖ≥‰∫é><span>üôãüèª‚Äç‚ôÇÔ∏èÂÖ≥‰∫é</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://garyforreal.me/zh/>‰∏ªÈ°µ</a>&nbsp;¬ª&nbsp;<a href=https://garyforreal.me/zh/posts/>Â∏ñÂ≠ê</a>&nbsp;¬ª&nbsp;<a href=https://garyforreal.me/zh/posts/paper/>ËÆ∫Êñá</a></div><h1 class="post-title entry-hint-parent">Weekly Paper Notes - 2025-12-14</h1><div class=post-meta><span title='2025-12-14 15:23:14.907278 +0000 UTC'>2025-12-14</span>&nbsp;¬∑&nbsp;123 ÂàÜÈíü&nbsp;¬∑&nbsp;Gary&nbsp;|&nbsp;ËØ≠Ë®Ä:<ul class=i18n_list><li><a href=https://garyforreal.me/en/posts/paper/paper-2025-12-14-weekly/>English</a></li></ul><div class=meta-item>&nbsp¬∑&nbsp
        <span id=busuanzi_container_page_pv>Êú¨ÊñáÈòÖËØªÈáè<span id=busuanzi_value_page_pv></span>Ê¨°</span></div></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>ÁõÆÂΩï</span></summary><div class=inner><ul><li><a href=#weekly-paper-notes aria-label="Weekly Paper Notes">Weekly Paper Notes</a><ul><li><a href=#-multilingual aria-label="üîç multilingual">üîç multilingual</a><ul><li><a href=#grow-up-and-merge-scaling-strategies-for-efficient-language-adaptationhttpsarxivorgabs251210772v1 aria-label="Grow Up and Merge: Scaling Strategies for Efficient Language Adaptation"><a href=https://arxiv.org/abs/2512.10772v1>Grow Up and Merge: Scaling Strategies for Efficient Language Adaptation</a></a></li><li><a href=#agrigpt-omni-a-unified-speech-vision-text-framework-for-multilingual-agricultural-intelligencehttpsarxivorgabs251210624v1 aria-label="AgriGPT-Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence"><a href=https://arxiv.org/abs/2512.10624v1>AgriGPT-Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence</a></a></li><li><a href=#xdoge-multilingual-data-reweighting-to-enhance-language-inclusivity-in-llmshttpsarxivorgabs251210545v1 aria-label="XDoGE: Multilingual Data Reweighting to Enhance Language Inclusivity in LLMs"><a href=https://arxiv.org/abs/2512.10545v1>XDoGE: Multilingual Data Reweighting to Enhance Language Inclusivity in LLMs</a></a></li><li><a href=#enhancing-next-generation-language-models-with-knowledge-graphs-extending-claude-mistral-ia-and-gpt-4-via-kg-berthttpsarxivorgabs251210440v1 aria-label="Enhancing Next-Generation Language Models with Knowledge Graphs: Extending Claude, Mistral IA, and GPT-4 via KG-BERT"><a href=https://arxiv.org/abs/2512.10440v1>Enhancing Next-Generation Language Models with Knowledge Graphs: Extending Claude, Mistral IA, and GPT-4 via KG-BERT</a></a></li><li><a href=#multilingual-vlm-training-adapting-an-english-trained-vlm-to-frenchhttpsarxivorgabs251210336v1 aria-label="Multilingual VLM Training: Adapting an English-Trained VLM to French"><a href=https://arxiv.org/abs/2512.10336v1>Multilingual VLM Training: Adapting an English-Trained VLM to French</a></a></li><li><a href=#llm-pea-leveraging-large-language-models-against-phishing-email-attackshttpsarxivorgabs251210104v1 aria-label="LLM-PEA: Leveraging Large Language Models Against Phishing Email Attacks"><a href=https://arxiv.org/abs/2512.10104v1>LLM-PEA: Leveraging Large Language Models Against Phishing Email Attacks</a></a></li><li><a href=#mitigating-social-bias-in-english-and-urdu-language-models-using-prm-guided-candidate-selection-and-sequential-refinementhttpsarxivorgabs251209854v1 aria-label="Mitigating Social Bias in English and Urdu Language Models Using PRM-Guided Candidate Selection and Sequential Refinement"><a href=https://arxiv.org/abs/2512.09854v1>Mitigating Social Bias in English and Urdu Language Models Using PRM-Guided Candidate Selection and Sequential Refinement</a></a></li><li><a href=#swissgov-rsd-a-human-annotated-cross-lingual-benchmark-for-token-level-recognition-of-semantic-differences-between-related-documentshttpsarxivorgabs251207538v1 aria-label="SwissGov-RSD: A Human-annotated, Cross-lingual Benchmark for Token-level Recognition of Semantic Differences Between Related Documents"><a href=https://arxiv.org/abs/2512.07538v1>SwissGov-RSD: A Human-annotated, Cross-lingual Benchmark for Token-level Recognition of Semantic Differences Between Related Documents</a></a></li><li><a href=#persian-phi-efficient-cross-lingual-adaptation-of-compact-llms-via-curriculum-learninghttpsarxivorgabs251207454v1 aria-label="Persian-Phi: Efficient Cross-Lingual Adaptation of Compact LLMs via Curriculum Learning"><a href=https://arxiv.org/abs/2512.07454v1>Persian-Phi: Efficient Cross-Lingual Adaptation of Compact LLMs via Curriculum Learning</a></a></li><li><a href=#efficient-asr-for-low-resource-languages-leveraging-cross-lingual-unlabeled-datahttpsarxivorgabs251207277v1 aria-label="Efficient ASR for Low-Resource Languages: Leveraging Cross-Lingual Unlabeled Data"><a href=https://arxiv.org/abs/2512.07277v1>Efficient ASR for Low-Resource Languages: Leveraging Cross-Lingual Unlabeled Data</a></a></li><li><a href=#cross-platform-product-matching-based-on-entity-alignment-of-knowledge-graph-with-raea-modelhttpsarxivorgabs251207232v1 aria-label="Cross-platform Product Matching Based on Entity Alignment of Knowledge Graph with RAEA model"><a href=https://arxiv.org/abs/2512.07232v1>Cross-platform Product Matching Based on Entity Alignment of Knowledge Graph with RAEA model</a></a></li><li><a href=#masim-multilingual-agent-based-simulation-for-social-sciencehttpsarxivorgabs251207195v1 aria-label="MASim: Multilingual Agent-Based Simulation for Social Science"><a href=https://arxiv.org/abs/2512.07195v1>MASim: Multilingual Agent-Based Simulation for Social Science</a></a></li><li><a href=#mind-the-gap-pathways-towards-unifying-ai-safety-and-ethics-researchhttpsarxivorgabs251210058v1 aria-label="Mind the Gap! Pathways Towards Unifying AI Safety and Ethics Research"><a href=https://arxiv.org/abs/2512.10058v1>Mind the Gap! Pathways Towards Unifying AI Safety and Ethics Research</a></a></li><li><a href=#local-llm-ensembles-for-zero-shot-portuguese-named-entity-recognitionhttpsarxivorgabs251210043v1 aria-label="Local LLM Ensembles for Zero-shot Portuguese Named Entity Recognition"><a href=https://arxiv.org/abs/2512.10043v1>Local LLM Ensembles for Zero-shot Portuguese Named Entity Recognition</a></a></li><li><a href=#if-bench-benchmarking-and-enhancing-mllms-for-infrared-images-with-generative-visual-promptinghttpsarxivorgabs251209663v1 aria-label="IF-Bench: Benchmarking and Enhancing MLLMs for Infrared Images with Generative Visual Prompting"><a href=https://arxiv.org/abs/2512.09663v1>IF-Bench: Benchmarking and Enhancing MLLMs for Infrared Images with Generative Visual Prompting</a></a></li><li><a href=#can-llms-evaluate-what-they-cannot-annotate-revisiting-llm-reliability-in-hate-speech-detectionhttpsarxivorgabs251209662v1 aria-label="Can LLMs Evaluate What They Cannot Annotate? Revisiting LLM Reliability in Hate Speech Detection"><a href=https://arxiv.org/abs/2512.09662v1>Can LLMs Evaluate What They Cannot Annotate? Revisiting LLM Reliability in Hate Speech Detection</a></a></li><li><a href=#courtpressger-a-german-court-decision-to-press-release-summarization-datasethttpsarxivorgabs251209434v1 aria-label="CourtPressGER: A German Court Decision to Press Release Summarization Dataset"><a href=https://arxiv.org/abs/2512.09434v1>CourtPressGER: A German Court Decision to Press Release Summarization Dataset</a></a></li><li><a href=#trident-a-redundant-architecture-for-caribbean-accented-emergency-speech-triagehttpsarxivorgabs251210741v1 aria-label="TRIDENT: A Redundant Architecture for Caribbean-Accented Emergency Speech Triage"><a href=https://arxiv.org/abs/2512.10741v1>TRIDENT: A Redundant Architecture for Caribbean-Accented Emergency Speech Triage</a></a></li><li><a href=#training-one-model-to-master-cross-level-agentic-actions-via-reinforcement-learninghttpsarxivorgabs251209706v1 aria-label="Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning"><a href=https://arxiv.org/abs/2512.09706v1>Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning</a></a></li><li><a href=#straggler-tolerant-and-resilient-dl-training-on-homogeneous-gpushttpsarxivorgabs251209685v1 aria-label="Straggler Tolerant and Resilient DL Training on Homogeneous GPUs"><a href=https://arxiv.org/abs/2512.09685v1>Straggler Tolerant and Resilient DL Training on Homogeneous GPUs</a></a></li><li><a href=#reasan-learning-reactive-safe-navigation-for-legged-robotshttpsarxivorgabs251209537v1 aria-label="REASAN: Learning Reactive Safe Navigation for Legged Robots"><a href=https://arxiv.org/abs/2512.09537v1>REASAN: Learning Reactive Safe Navigation for Legged Robots</a></a></li><li><a href=#basic-lock-algorithms-in-lightweight-thread-environmentshttpsarxivorgabs251208563v1 aria-label="Basic Lock Algorithms in Lightweight Thread Environments"><a href=https://arxiv.org/abs/2512.08563v1>Basic Lock Algorithms in Lightweight Thread Environments</a></a></li><li><a href=#polylingua-margin-based-inter-class-transformer-for-robust-cross-domain-language-detectionhttpsarxivorgabs251208143v2 aria-label="PolyLingua: Margin-based Inter-class Transformer for Robust Cross-domain Language Detection"><a href=https://arxiv.org/abs/2512.08143v2>PolyLingua: Margin-based Inter-class Transformer for Robust Cross-domain Language Detection</a></a></li><li><a href=#optimizing-data-extraction-from-materials-science-literature-a-study-of-tools-using-large-language-modelshttpsarxivorgabs251209370v1 aria-label="Optimizing Data Extraction from Materials Science Literature: A Study of Tools Using Large Language Models"><a href=https://arxiv.org/abs/2512.09370v1>Optimizing Data Extraction from Materials Science Literature: A Study of Tools Using Large Language Models</a></a></li><li><a href=#empowering-dynamic-urban-navigation-with-stereo-and-mid-level-visionhttpsarxivorgabs251210956v1 aria-label="Empowering Dynamic Urban Navigation with Stereo and Mid-Level Vision"><a href=https://arxiv.org/abs/2512.10956v1>Empowering Dynamic Urban Navigation with Stereo and Mid-Level Vision</a></a></li><li><a href=#e-rayzer-self-supervised-3d-reconstruction-as-spatial-visual-pre-traininghttpsarxivorgabs251210950v1 aria-label="E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training"><a href=https://arxiv.org/abs/2512.10950v1>E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training</a></a></li><li><a href=#are-we-ready-for-rl-in-text-to-3d-generation-a-progressive-investigationhttpsarxivorgabs251210949v1 aria-label="Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation"><a href=https://arxiv.org/abs/2512.10949v1>Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation</a></a></li><li><a href=#towards-efficient-and-effective-multi-camera-encoding-for-end-to-end-drivinghttpsarxivorgabs251210947v1 aria-label="Towards Efficient and Effective Multi-Camera Encoding for End-to-End Driving"><a href=https://arxiv.org/abs/2512.10947v1>Towards Efficient and Effective Multi-Camera Encoding for End-to-End Driving</a></a></li><li><a href=#mevis-a-multi-modal-dataset-for-referring-motion-expression-video-segmentationhttpsarxivorgabs251210945v1 aria-label="MeViS: A Multi-Modal Dataset for Referring Motion Expression Video Segmentation"><a href=https://arxiv.org/abs/2512.10945v1>MeViS: A Multi-Modal Dataset for Referring Motion Expression Video Segmentation</a></a></li><li><a href=#vl-jepa-joint-embedding-predictive-architecture-for-vision-languagehttpsarxivorgabs251210942v1 aria-label="VL-JEPA: Joint Embedding Predictive Architecture for Vision-language"><a href=https://arxiv.org/abs/2512.10942v1>VL-JEPA: Joint Embedding Predictive Architecture for Vision-language</a></a></li><li><a href=#hierarchical-dataset-selection-for-high-quality-data-sharinghttpsarxivorgabs251210952v1 aria-label="Hierarchical Dataset Selection for High-Quality Data Sharing"><a href=https://arxiv.org/abs/2512.10952v1>Hierarchical Dataset Selection for High-Quality Data Sharing</a></a></li><li><a href=#omni-attribute-open-vocabulary-attribute-encoder-for-visual-concept-personalizationhttpsarxivorgabs251210955v1 aria-label="Omni-Attribute: Open-vocabulary Attribute Encoder for Visual Concept Personalization"><a href=https://arxiv.org/abs/2512.10955v1>Omni-Attribute: Open-vocabulary Attribute Encoder for Visual Concept Personalization</a></a></li><li><a href=#curriculum-based-reinforcement-learning-for-autonomous-uav-navigation-in-unknown-curved-tubular-conduithttpsarxivorgabs251210934v1 aria-label="Curriculum-Based Reinforcement Learning for Autonomous UAV Navigation in Unknown Curved Tubular Conduit"><a href=https://arxiv.org/abs/2512.10934v1>Curriculum-Based Reinforcement Learning for Autonomous UAV Navigation in Unknown Curved Tubular Conduit</a></a></li><li><a href=#digital-twin-supervised-reinforcement-learning-framework-for-autonomous-underwater-navigationhttpsarxivorgabs251210925v1 aria-label="Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation"><a href=https://arxiv.org/abs/2512.10925v1>Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation</a></a></li><li><a href=#physics-informed-learning-of-flow-distribution-and-receiver-heat-losses-in-parabolic-trough-solar-fieldshttpsarxivorgabs251210886v1 aria-label="Physics-Informed Learning of Flow Distribution and Receiver Heat Losses in Parabolic Trough Solar Fields"><a href=https://arxiv.org/abs/2512.10886v1>Physics-Informed Learning of Flow Distribution and Receiver Heat Losses in Parabolic Trough Solar Fields</a></a></li><li><a href=#guided-transfer-learning-for-discrete-diffusion-modelshttpsarxivorgabs251210877v1 aria-label="Guided Transfer Learning for Discrete Diffusion Models"><a href=https://arxiv.org/abs/2512.10877v1>Guided Transfer Learning for Discrete Diffusion Models</a></a></li><li><a href=#worldlens-full-spectrum-evaluations-of-driving-world-models-in-real-worldhttpsarxivorgabs251210958v1 aria-label="WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World"><a href=https://arxiv.org/abs/2512.10958v1>WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World</a></a></li><li><a href=#evidence-of-galaxy-cluster-rotation-in-the-cosmic-microwave-backgroundhttpsarxivorgabs251210951v1 aria-label="Evidence of galaxy cluster rotation in the cosmic microwave background"><a href=https://arxiv.org/abs/2512.10951v1>Evidence of galaxy cluster rotation in the cosmic microwave background</a></a></li><li><a href=#babyvlm-v2-toward-developmentally-grounded-pretraining-and-benchmarking-of-vision-foundation-modelshttpsarxivorgabs251210932v1 aria-label="BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models"><a href=https://arxiv.org/abs/2512.10932v1>BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models</a></a></li><li><a href=#duetsvg-unified-multimodal-svg-generation-with-internal-visual-guidancehttpsarxivorgabs251210894v1 aria-label="DuetSVG: Unified Multimodal SVG Generation with Internal Visual Guidance"><a href=https://arxiv.org/abs/2512.10894v1>DuetSVG: Unified Multimodal SVG Generation with Internal Visual Guidance</a></a></li><li><a href=#two-dimensional-projective-collapse-and-sharp-distortion-bounds-for-products-of-positive-matriceshttpsarxivorgabs251210872v1 aria-label="Two-Dimensional Projective Collapse and Sharp Distortion Bounds for Products of Positive Matrices"><a href=https://arxiv.org/abs/2512.10872v1>Two-Dimensional Projective Collapse and Sharp Distortion Bounds for Products of Positive Matrices</a></a></li><li><a href=#a-stellar-magnesium-to-silicon-ratio-in-the-atmosphere-of-an-exoplanethttpsarxivorgabs251210904v1 aria-label="A Stellar Magnesium to Silicon ratio in the atmosphere of an exoplanet"><a href=https://arxiv.org/abs/2512.10904v1>A Stellar Magnesium to Silicon ratio in the atmosphere of an exoplanet</a></a></li><li><a href=#replace-dont-expand-mitigating-context-dilution-in-multi-hop-rag-via-fixed-budget-evidence-assemblyhttpsarxivorgabs251210787v1 aria-label="Replace, Don&rsquo;t Expand: Mitigating Context Dilution in Multi-Hop RAG via Fixed-Budget Evidence Assembly"><a href=https://arxiv.org/abs/2512.10787v1>Replace, Don&rsquo;t Expand: Mitigating Context Dilution in Multi-Hop RAG via Fixed-Budget Evidence Assembly</a></a></li><li><a href=#rethinking-popularity-bias-in-collaborative-filtering-via-analytical-vector-decompositionhttpsarxivorgabs251210688v1 aria-label="Rethinking Popularity Bias in Collaborative Filtering via Analytical Vector Decomposition"><a href=https://arxiv.org/abs/2512.10688v1>Rethinking Popularity Bias in Collaborative Filtering via Analytical Vector Decomposition</a></a></li><li><a href=#lang2motion-bridging-language-and-motion-through-joint-embedding-spaceshttpsarxivorgabs251210617v1 aria-label="Lang2Motion: Bridging Language and Motion through Joint Embedding Spaces"><a href=https://arxiv.org/abs/2512.10617v1>Lang2Motion: Bridging Language and Motion through Joint Embedding Spaces</a></a></li></ul></li><li><a href=#-linguistics aria-label="üîç linguistics">üîç linguistics</a><ul><li><a href=#stereospace-depth-free-synthesis-of-stereo-geometry-via-end-to-end-diffusion-in-a-canonical-spacehttpsarxivorgabs251210959v1 aria-label="StereoSpace: Depth-Free Synthesis of Stereo Geometry via End-to-End Diffusion in a Canonical Space"><a href=https://arxiv.org/abs/2512.10959v1>StereoSpace: Depth-Free Synthesis of Stereo Geometry via End-to-End Diffusion in a Canonical Space</a></a></li><li><a href=#scenemaker-open-set-3d-scene-generation-with-decoupled-de-occlusion-and-pose-estimation-modelhttpsarxivorgabs251210957v1 aria-label="SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model"><a href=https://arxiv.org/abs/2512.10957v1>SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model</a></a></li><li><a href=#bidirectional-normalizing-flow-from-data-to-noise-and-backhttpsarxivorgabs251210953v1 aria-label="Bidirectional Normalizing Flow: From Data to Noise and Back"><a href=https://arxiv.org/abs/2512.10953v1>Bidirectional Normalizing Flow: From Data to Noise and Back</a></a></li><li><a href=#clusir-towards-cluster-guided-all-in-one-image-restorationhttpsarxivorgabs251210948v1 aria-label="ClusIR: Towards Cluster-Guided All-in-One Image Restoration"><a href=https://arxiv.org/abs/2512.10948v1>ClusIR: Towards Cluster-Guided All-in-One Image Restoration</a></a></li><li><a href=#implicitrdp-an-end-to-end-visual-force-diffusion-policy-with-structural-slow-fast-learninghttpsarxivorgabs251210946v1 aria-label="ImplicitRDP: An End-to-End Visual-Force Diffusion Policy with Structural Slow-Fast Learning"><a href=https://arxiv.org/abs/2512.10946v1>ImplicitRDP: An End-to-End Visual-Force Diffusion Policy with Structural Slow-Fast Learning</a></a></li><li><a href=#noisy-quantum-learning-theoryhttpsarxivorgabs251210929v1 aria-label="Noisy Quantum Learning Theory"><a href=https://arxiv.org/abs/2512.10929v1>Noisy Quantum Learning Theory</a></a></li><li><a href=#free-plane-curves-with-a-linear-jacobian-syzygyhttpsarxivorgabs251210928v1 aria-label="Free plane curves with a linear Jacobian syzygy"><a href=https://arxiv.org/abs/2512.10928v1>Free plane curves with a linear Jacobian syzygy</a></a></li><li><a href=#structural-physical-and-judd-ofelt-analysis-of-germanium-magnesium-telluroborate-glass-containing-different-amounts-of-tm2o3httpsarxivorgabs251210920v1 aria-label="Structural, physical, and Judd-Ofelt analysis of germanium magnesium-telluroborate glass containing different amounts of Tm2O3"><a href=https://arxiv.org/abs/2512.10920v1>Structural, physical, and Judd-Ofelt analysis of germanium magnesium-telluroborate glass containing different amounts of Tm2O3</a></a></li><li><a href=#the-lisa-astrophysics-disc-imri-code-comparison-project-intermediate-mass-ratio-binaries-in-agn-like-discshttpsarxivorgabs251210893v1 aria-label="The LISA Astrophysics &ldquo;Disc-IMRI&rdquo; Code Comparison Project: Intermediate-Mass-Ratio Binaries in AGN-Like Discs"><a href=https://arxiv.org/abs/2512.10893v1>The LISA Astrophysics &ldquo;Disc-IMRI&rdquo; Code Comparison Project: Intermediate-Mass-Ratio Binaries in AGN-Like Discs</a></a></li><li><a href=#inflation-in-light-of-actspt-a-new-perspective-from-weyl-gravityhttpsarxivorgabs251210862v1 aria-label="Inflation in light of ACT/SPT: a new perspective from Weyl gravity"><a href=https://arxiv.org/abs/2512.10862v1>Inflation in light of ACT/SPT: a new perspective from Weyl gravity</a></a></li><li><a href=#modeling-segmenting-and-statistics-of-transient-spindles-via-two-dimensional-ornstein-uhlenbeck-dynamicshttpsarxivorgabs251210844v1 aria-label="Modeling, Segmenting and Statistics of Transient Spindles via Two-Dimensional Ornstein-Uhlenbeck Dynamics"><a href=https://arxiv.org/abs/2512.10844v1>Modeling, Segmenting and Statistics of Transient Spindles via Two-Dimensional Ornstein-Uhlenbeck Dynamics</a></a></li><li><a href=#data-driven-pressure-recovery-in-diffusershttpsarxivorgabs251210801v1 aria-label="Data-driven Pressure Recovery in Diffusers"><a href=https://arxiv.org/abs/2512.10801v1>Data-driven Pressure Recovery in Diffusers</a></a></li><li><a href=#modeling-light-signals-using-data-from-the-first-pulsed-neutron-source-program-at-the-dune-vertical-drift-coldbox-test-facility-at-cern-neutrino-platformhttpsarxivorgabs251210790v1 aria-label="Modeling Light Signals Using Data from the First Pulsed Neutron Source Program at the DUNE Vertical Drift ColdBox Test Facility at CERN Neutrino Platform"><a href=https://arxiv.org/abs/2512.10790v1>Modeling Light Signals Using Data from the First Pulsed Neutron Source Program at the DUNE Vertical Drift ColdBox Test Facility at CERN Neutrino Platform</a></a></li><li><a href=#theoretical-and-experimental-development-of-a-high-conversion-efficiency-rectifier-at-x-bandhttpsarxivorgabs251210774v1 aria-label="Theoretical and experimental development of a high-conversion-efficiency rectifier at X-band"><a href=https://arxiv.org/abs/2512.10774v1>Theoretical and experimental development of a high-conversion-efficiency rectifier at X-band</a></a></li><li><a href=#group-diffusion-enhancing-image-generation-by-unlocking-cross-sample-collaborationhttpsarxivorgabs251210954v1 aria-label="Group Diffusion: Enhancing Image Generation by Unlocking Cross-Sample Collaboration"><a href=https://arxiv.org/abs/2512.10954v1>Group Diffusion: Enhancing Image Generation by Unlocking Cross-Sample Collaboration</a></a></li><li><a href=#foundationmotion-auto-labeling-and-reasoning-about-spatial-movement-in-videoshttpsarxivorgabs251210927v1 aria-label="FoundationMotion: Auto-Labeling and Reasoning about Spatial Movement in Videos"><a href=https://arxiv.org/abs/2512.10927v1>FoundationMotion: Auto-Labeling and Reasoning about Spatial Movement in Videos</a></a></li><li><a href=#echoes-of-automation-how-bots-shaped-political-discourse-in-brazilhttpsarxivorgabs251210749v1 aria-label="Echoes of Automation: How Bots Shaped Political Discourse in Brazil"><a href=https://arxiv.org/abs/2512.10749v1>Echoes of Automation: How Bots Shaped Political Discourse in Brazil</a></a></li><li><a href=#intrinsically-correct-algorithms-and-recursive-coalgebrashttpsarxivorgabs251210748v1 aria-label="Intrinsically Correct Algorithms and Recursive Coalgebras"><a href=https://arxiv.org/abs/2512.10748v1>Intrinsically Correct Algorithms and Recursive Coalgebras</a></a></li><li><a href=#kicking-politics-how-football-fan-communities-became-arenas-for-political-influencehttpsarxivorgabs251210737v1 aria-label="Kicking Politics: How Football Fan Communities Became Arenas for Political Influence"><a href=https://arxiv.org/abs/2512.10737v1>Kicking Politics: How Football Fan Communities Became Arenas for Political Influence</a></a></li><li><a href=#the-physics-of-sustainability-material-and-power-constraints-for-the-long-termhttpsarxivorgabs251210680v1 aria-label="The Physics of Sustainability: Material and Power Constraints for the Long Term"><a href=https://arxiv.org/abs/2512.10680v1>The Physics of Sustainability: Material and Power Constraints for the Long Term</a></a></li><li><a href=#docr-inspector-fine-grained-and-automated-evaluation-of-document-parsing-with-vlmhttpsarxivorgabs251210619v1 aria-label="DOCR-Inspector: Fine-Grained and Automated Evaluation of Document Parsing with VLM"><a href=https://arxiv.org/abs/2512.10619v1>DOCR-Inspector: Fine-Grained and Automated Evaluation of Document Parsing with VLM</a></a></li><li><a href=#modeling-narrative-archetypes-in-conspiratorial-narratives-insights-from-singapore-based-telegram-groupshttpsarxivorgabs251210105v1 aria-label="Modeling Narrative Archetypes in Conspiratorial Narratives: Insights from Singapore-Based Telegram Groups"><a href=https://arxiv.org/abs/2512.10105v1>Modeling Narrative Archetypes in Conspiratorial Narratives: Insights from Singapore-Based Telegram Groups</a></a></li><li><a href=#detection-prospects-for-heavy-wimp-dark-matter-near-supermassive-black-holes-particularly-in-m31httpsarxivorgabs251210923v1 aria-label="Detection prospects for heavy WIMP dark matter near supermassive black holes, particularly in M31"><a href=https://arxiv.org/abs/2512.10923v1>Detection prospects for heavy WIMP dark matter near supermassive black holes, particularly in M31</a></a></li><li><a href=#hiding-a-light-vector-boson-from-terrestrial-experiments-a-chargephobic-dark-photonhttpsarxivorgabs251210916v1 aria-label="Hiding a Light Vector Boson from Terrestrial Experiments: A Chargephobic Dark Photon"><a href=https://arxiv.org/abs/2512.10916v1>Hiding a Light Vector Boson from Terrestrial Experiments: A Chargephobic Dark Photon</a></a></li><li><a href=#standard-model-benchmarks-for-d0to-k--k-%cf%80-%cf%80-k0_rm-s-k0_rm-s-decayshttpsarxivorgabs251210911v1 aria-label="Standard Model Benchmarks for $D^0\to K^- K^+, œÄ^-œÄ^+, K^0_{\rm S} K^0_{\rm S}$ Decays"><a href=https://arxiv.org/abs/2512.10911v1>Standard Model Benchmarks for $D^0\to K^- K^+, œÄ^-œÄ^+, K^0_{\rm S} K^0_{\rm S}$ Decays</a></a></li><li><a href=#conformal-boundary-conditions-and-higher-curvature-gravityhttpsarxivorgabs251210930v1 aria-label="Conformal Boundary Conditions and Higher Curvature Gravity"><a href=https://arxiv.org/abs/2512.10930v1>Conformal Boundary Conditions and Higher Curvature Gravity</a></a></li><li><a href=#shedding-light-on-large-space-based-telescopes-modeling-stray-light-due-to-primary-mirror-damage-from-micrometeoroid-impactshttpsarxivorgabs251210915v1 aria-label="Shedding Light on Large Space-Based Telescopes: Modeling Stray Light due to Primary Mirror Damage from Micrometeoroid Impacts"><a href=https://arxiv.org/abs/2512.10915v1>Shedding Light on Large Space-Based Telescopes: Modeling Stray Light due to Primary Mirror Damage from Micrometeoroid Impacts</a></a></li><li><a href=#a-vision-for-ground-based-astronomy-beyond-the-2030s-how-to-build-esos-next-big-telescope-sustainablyhttpsarxivorgabs251210902v1 aria-label="A vision for ground-based astronomy beyond the 2030s: How to build ESO&rsquo;s next big telescope sustainably"><a href=https://arxiv.org/abs/2512.10902v1>A vision for ground-based astronomy beyond the 2030s: How to build ESO&rsquo;s next big telescope sustainably</a></a></li><li><a href=#hybrid-quantum-classical-matrix-product-state-and-lanczos-methods-for-electron-phonon-systems-with-strong-electronic-correlations-application-to-disordered-systems-coupled-to-einstein-phononshttpsarxivorgabs251210899v1 aria-label="Hybrid quantum-classical matrix-product state and Lanczos methods for electron-phonon systems with strong electronic correlations: Application to disordered systems coupled to Einstein phonons"><a href=https://arxiv.org/abs/2512.10899v1>Hybrid quantum-classical matrix-product state and Lanczos methods for electron-phonon systems with strong electronic correlations: Application to disordered systems coupled to Einstein phonons</a></a></li><li><a href=#physics-informed-learning-of-microvascular-flow-models-using-graph-neural-networkshttpsarxivorgabs251210792v1 aria-label="Physics-Informed Learning of Microvascular Flow Models using Graph Neural Networks"><a href=https://arxiv.org/abs/2512.10792v1>Physics-Informed Learning of Microvascular Flow Models using Graph Neural Networks</a></a></li><li><a href=#textual-data-bias-detection-and-mitigation---an-extensible-pipeline-with-experimental-evaluationhttpsarxivorgabs251210734v1 aria-label="Textual Data Bias Detection and Mitigation - An Extensible Pipeline with Experimental Evaluation"><a href=https://arxiv.org/abs/2512.10734v1>Textual Data Bias Detection and Mitigation - An Extensible Pipeline with Experimental Evaluation</a></a></li><li><a href=#a-cryogenic-muon-tagging-system-based-on-kinetic-inductance-detectors-for-superconducting-quantum-processorshttpsarxivorgabs251210679v1 aria-label="A Cryogenic Muon Tagging System Based on Kinetic Inductance Detectors for Superconducting Quantum Processors"><a href=https://arxiv.org/abs/2512.10679v1>A Cryogenic Muon Tagging System Based on Kinetic Inductance Detectors for Superconducting Quantum Processors</a></a></li><li><a href=#topology-guided-quantum-gans-for-constrained-graph-generationhttpsarxivorgabs251210582v1 aria-label="Topology-Guided Quantum GANs for Constrained Graph Generation"><a href=https://arxiv.org/abs/2512.10582v1>Topology-Guided Quantum GANs for Constrained Graph Generation</a></a></li><li><a href=#grammaticality-judgments-in-humans-and-language-models-revisiting-generative-grammar-with-llmshttpsarxivorgabs251210453v1 aria-label="Grammaticality Judgments in Humans and Language Models: Revisiting Generative Grammar with LLMs"><a href=https://arxiv.org/abs/2512.10453v1>Grammaticality Judgments in Humans and Language Models: Revisiting Generative Grammar with LLMs</a></a></li></ul></li><li><a href=#-psycholinguistics aria-label="üîç psycholinguistics">üîç psycholinguistics</a><ul><li><a href=#on-decision-making-agents-and-higher-order-causal-processeshttpsarxivorgabs251210937v1 aria-label="On Decision-Making Agents and Higher-Order Causal Processes"><a href=https://arxiv.org/abs/2512.10937v1>On Decision-Making Agents and Higher-Order Causal Processes</a></a></li><li><a href=#any4d-unified-feed-forward-metric-4d-reconstructionhttpsarxivorgabs251210935v1 aria-label="Any4D: Unified Feed-Forward Metric 4D Reconstruction"><a href=https://arxiv.org/abs/2512.10935v1>Any4D: Unified Feed-Forward Metric 4D Reconstruction</a></a></li><li><a href=#anomalous-scaling-law-for-the-two-dimensional-gaussian-free-fieldhttpsarxivorgabs251210933v1 aria-label="Anomalous scaling law for the two-dimensional Gaussian free field"><a href=https://arxiv.org/abs/2512.10933v1>Anomalous scaling law for the two-dimensional Gaussian free field</a></a></li><li><a href=#the-localization-method-for-high-dimensional-inequalitieshttpsarxivorgabs251210848v1 aria-label="The Localization Method for High-Dimensional Inequalities"><a href=https://arxiv.org/abs/2512.10848v1>The Localization Method for High-Dimensional Inequalities</a></a></li><li><a href=#what-matters-for-representation-alignment-global-information-or-spatial-structurehttpsarxivorgabs251210794v1 aria-label="What matters for Representation Alignment: Global Information or Spatial Structure?"><a href=https://arxiv.org/abs/2512.10794v1>What matters for Representation Alignment: Global Information or Spatial Structure?</a></a></li><li><a href=#maximal-rigidity-of-random-measure-and-uniqueness-pairs-stealthy-processes-quasicrystals-and-periodicityhttpsarxivorgabs251210686v1 aria-label="Maximal rigidity of random measure and uniqueness pairs: stealthy processes, quasicrystals and periodicity"><a href=https://arxiv.org/abs/2512.10686v1>Maximal rigidity of random measure and uniqueness pairs: stealthy processes, quasicrystals and periodicity</a></a></li><li><a href=#fano-and-reflexive-polytopes-from-feynman-integralshttpsarxivorgabs251210518v1 aria-label="Fano and Reflexive Polytopes from Feynman Integrals"><a href=https://arxiv.org/abs/2512.10518v1>Fano and Reflexive Polytopes from Feynman Integrals</a></a></li><li><a href=#neighborhood-complexes-of-induced-k-independent-graphshttpsarxivorgabs251209674v1 aria-label="Neighborhood Complexes of induced $k$-independent graphs"><a href=https://arxiv.org/abs/2512.09674v1>Neighborhood Complexes of induced $k$-independent graphs</a></a></li><li><a href=#understanding-the-failure-modes-of-transformers-through-the-lens-of-graph-neural-networkshttpsarxivorgabs251209182v1 aria-label="Understanding the Failure Modes of Transformers through the Lens of Graph Neural Networks"><a href=https://arxiv.org/abs/2512.09182v1>Understanding the Failure Modes of Transformers through the Lens of Graph Neural Networks</a></a></li><li><a href=#classifier-reconstruction-through-counterfactual-aware-wasserstein-prototypeshttpsarxivorgabs251210878v1 aria-label="Classifier Reconstruction Through Counterfactual-Aware Wasserstein Prototypes"><a href=https://arxiv.org/abs/2512.10878v1>Classifier Reconstruction Through Counterfactual-Aware Wasserstein Prototypes</a></a></li><li><a href=#a-differentiable-digital-twin-of-distributed-link-scheduling-for-contention-aware-networkinghttpsarxivorgabs251210874v1 aria-label="A Differentiable Digital Twin of Distributed Link Scheduling for Contention-Aware Networking"><a href=https://arxiv.org/abs/2512.10874v1>A Differentiable Digital Twin of Distributed Link Scheduling for Contention-Aware Networking</a></a></li><li><a href=#multidimensional-sorting-comparative-staticshttpsarxivorgabs251210853v1 aria-label="Multidimensional Sorting: Comparative Statics"><a href=https://arxiv.org/abs/2512.10853v1>Multidimensional Sorting: Comparative Statics</a></a></li><li><a href=#allometric-scaling-of-brain-activity-explained-by-avalanche-criticalityhttpsarxivorgabs251210834v1 aria-label="Allometric scaling of brain activity explained by avalanche criticality"><a href=https://arxiv.org/abs/2512.10834v1>Allometric scaling of brain activity explained by avalanche criticality</a></a></li><li><a href=#agile-deliberation-concept-deliberation-for-subjective-visual-classificationhttpsarxivorgabs251210821v1 aria-label="Agile Deliberation: Concept Deliberation for Subjective Visual Classification"><a href=https://arxiv.org/abs/2512.10821v1>Agile Deliberation: Concept Deliberation for Subjective Visual Classification</a></a></li><li><a href=#parallel-neuron-groups-in-the-drosophila-brainhttpsarxivorgabs251210525v1 aria-label="Parallel Neuron Groups in the Drosophila Brain"><a href=https://arxiv.org/abs/2512.10525v1>Parallel Neuron Groups in the Drosophila Brain</a></a></li><li><a href=#low-order-mathcalh_2--mathcalh_infty-controller-design-for-aeroelastic-vibration-suppressionhttpsarxivorgabs251210841v1 aria-label="Low-Order $\mathcal{H}2 / \mathcal{H}\infty$ Controller Design for Aeroelastic Vibration Suppression"><a href=https://arxiv.org/abs/2512.10841v1>Low-Order $\mathcal{H}<em>2 / \mathcal{H}</em>\infty$ Controller Design for Aeroelastic Vibration Suppression</a></a></li><li><a href=#decision-feedback-aided-known-interference-cancellationhttpsarxivorgabs251210833v1 aria-label="Decision Feedback-Aided Known-Interference Cancellation"><a href=https://arxiv.org/abs/2512.10833v1>Decision Feedback-Aided Known-Interference Cancellation</a></a></li><li><a href=#identifiable-factor-analysis-for-mixed-continuous-and-binary-variables-based-on-the-gaussian-grassmann-distributionhttpsarxivorgabs251210804v1 aria-label="Identifiable factor analysis for mixed continuous and binary variables based on the Gaussian-Grassmann distribution"><a href=https://arxiv.org/abs/2512.10804v1>Identifiable factor analysis for mixed continuous and binary variables based on the Gaussian-Grassmann distribution</a></a></li></ul></li><li><a href=#-llm aria-label="üîç llm">üîç llm</a><ul><li><a href=#alchemint-fine-grained-temporal-control-for-multi-reference-consistent-video-generationhttpsarxivorgabs251210943v1 aria-label="AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation"><a href=https://arxiv.org/abs/2512.10943v1>AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation</a></a></li><li><a href=#gaussianheadtalk-wobble-free-3d-talking-heads-with-audio-driven-gaussian-splattinghttpsarxivorgabs251210939v1 aria-label="GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting"><a href=https://arxiv.org/abs/2512.10939v1>GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting</a></a></li><li><a href=#stronger-normalization-free-transformershttpsarxivorgabs251210938v1 aria-label="Stronger Normalization-Free Transformers"><a href=https://arxiv.org/abs/2512.10938v1>Stronger Normalization-Free Transformers</a></a></li><li><a href=#empirical-evaluation-of-the-frank-wolfe-methods-for-constructing-white-box-adversarial-attackshttpsarxivorgabs251210936v1 aria-label="Empirical evaluation of the Frank-Wolfe methods for constructing white-box adversarial attacks"><a href=https://arxiv.org/abs/2512.10936v1>Empirical evaluation of the Frank-Wolfe methods for constructing white-box adversarial attacks</a></a></li><li><a href=#asynchronous-reasoning-training-free-interactive-thinking-llmshttpsarxivorgabs251210931v1 aria-label="Asynchronous Reasoning: Training-Free Interactive Thinking LLMs"><a href=https://arxiv.org/abs/2512.10931v1>Asynchronous Reasoning: Training-Free Interactive Thinking LLMs</a></a></li><li><a href=#flrw-embeddings-in-mathbbrn2-differential-geometry-and-conformal-photon-propagatorhttpsarxivorgabs251210901v1 aria-label="FLRW embeddings in $\mathbb{R}^{n+2}$, differential geometry and conformal photon propagator"><a href=https://arxiv.org/abs/2512.10901v1>FLRW embeddings in $\mathbb{R}^{n+2}$, differential geometry and conformal photon propagator</a></a></li><li><a href=#llms-can-assist-with-proposal-selection-at-large-user-facilitieshttpsarxivorgabs251210895v1 aria-label="LLMs Can Assist with Proposal Selection at Large User Facilities"><a href=https://arxiv.org/abs/2512.10895v1>LLMs Can Assist with Proposal Selection at Large User Facilities</a></a></li></ul></li><li><a href=#-neuroscience aria-label="üîç neuroscience">üîç neuroscience</a><ul><li><a href=#basic-requirements-for-potential-differences-across-solid--fluid-interfaceshttpsarxivorgabs251210859v1 aria-label="Basic requirements for potential differences across solid&ndash;fluid interfaces"><a href=https://arxiv.org/abs/2512.10859v1>Basic requirements for potential differences across solid&ndash;fluid interfaces</a></a></li><li><a href=#labelfusion-learning-to-fuse-llms-and-transformer-classifiers-for-robust-text-classificationhttpsarxivorgabs251210793v1 aria-label="LabelFusion: Learning to Fuse LLMs and Transformer Classifiers for Robust Text Classification"><a href=https://arxiv.org/abs/2512.10793v1>LabelFusion: Learning to Fuse LLMs and Transformer Classifiers for Robust Text Classification</a></a></li><li><a href=#natural-language-interface-for-firewall-configurationhttpsarxivorgabs251210789v1 aria-label="Natural Language Interface for Firewall Configuration"><a href=https://arxiv.org/abs/2512.10789v1>Natural Language Interface for Firewall Configuration</a></a></li><li><a href=#performance-and-reliability-potential-of-bi_2o_2sebi_2seo_5-transistorshttpsarxivorgabs251210786v1 aria-label="Performance and reliability potential of Bi$_2$O$_2$Se/Bi$_2$SeO$_5$ transistors"><a href=https://arxiv.org/abs/2512.10786v1>Performance and reliability potential of Bi$_2$O$_2$Se/Bi$_2$SeO$_5$ transistors</a></a></li><li><a href=#epitaxial-srsn-ge_xti_1-xo_3-buffer-layers-for-continuous-strain-engineering-on-srtio_3-substrateshttpsarxivorgabs251210609v1 aria-label="Epitaxial Sr(Sn, Ge)${x}$Ti${1-x}$O${3}$ buffer layers for continuous strain engineering on SrTiO${3}$ substrates"><a href=https://arxiv.org/abs/2512.10609v1>Epitaxial Sr(Sn, Ge)$<em>{x}$Ti$</em>{1-x}$O$<em>{3}$ buffer layers for continuous strain engineering on SrTiO$</em>{3}$ substrates</a></a></li></ul></li><li><a href=#-data_resources aria-label="üîç data_resources">üîç data_resources</a><ul><li><a href=#from-data-scarcity-to-data-care-reimagining-language-technologies-for-serbian-and-other-low-resource-languageshttpsarxivorgabs251210630v1 aria-label="From Data Scarcity to Data Care: Reimagining Language Technologies for Serbian and other Low-Resource Languages"><a href=https://arxiv.org/abs/2512.10630v1>From Data Scarcity to Data Care: Reimagining Language Technologies for Serbian and other Low-Resource Languages</a></a></li><li><a href=#semantic-reconstruction-of-adversarial-plagiarism-a-context-aware-framework-for-detecting-and-restoring-tortured-phrases-in-scientific-literaturehttpsarxivorgabs251210435v1 aria-label="Semantic Reconstruction of Adversarial Plagiarism: A Context-Aware Framework for Detecting and Restoring &ldquo;Tortured Phrases&rdquo; in Scientific Literature"><a href=https://arxiv.org/abs/2512.10435v1>Semantic Reconstruction of Adversarial Plagiarism: A Context-Aware Framework for Detecting and Restoring &ldquo;Tortured Phrases&rdquo; in Scientific Literature</a></a></li><li><a href=#privtune-efficient-and-privacy-preserving-fine-tuning-of-large-language-models-via-device-cloud-collaborationhttpsarxivorgabs251208809v1 aria-label="PrivTune: Efficient and Privacy-Preserving Fine-Tuning of Large Language Models via Device-Cloud Collaboration"><a href=https://arxiv.org/abs/2512.08809v1>PrivTune: Efficient and Privacy-Preserving Fine-Tuning of Large Language Models via Device-Cloud Collaboration</a></a></li></ul></li><li><a href=#-emotion_language aria-label="üîç emotion_language">üîç emotion_language</a><ul><li><a href=#computational-emotion-analysis-with-multimodal-llms-current-evidence-on-an-emerging-methodological-opportunityhttpsarxivorgabs251210882v1 aria-label="Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity"><a href=https://arxiv.org/abs/2512.10882v1>Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity</a></a></li><li><a href=#quantifying-emotional-tone-in-tolkiens-the-hobbit-dialogue-sentiment-analysis-with-regex-nrc-vad-and-pythonhttpsarxivorgabs251210865v1 aria-label="Quantifying Emotional Tone in Tolkien&rsquo;s The Hobbit: Dialogue Sentiment Analysis with RegEx, NRC-VAD, and Python"><a href=https://arxiv.org/abs/2512.10865v1>Quantifying Emotional Tone in Tolkien&rsquo;s The Hobbit: Dialogue Sentiment Analysis with RegEx, NRC-VAD, and Python</a></a></li><li><a href=#self-ensemble-post-learning-for-noisy-domain-generalizationhttpsarxivorgabs251210818v1 aria-label="Self-Ensemble Post Learning for Noisy Domain Generalization"><a href=https://arxiv.org/abs/2512.10818v1>Self-Ensemble Post Learning for Noisy Domain Generalization</a></a></li><li><a href=#sparseswaps-tractable-llm-pruning-mask-refinement-at-scalehttpsarxivorgabs251210922v1 aria-label="SparseSwaps: Tractable LLM Pruning Mask Refinement at Scale"><a href=https://arxiv.org/abs/2512.10922v1>SparseSwaps: Tractable LLM Pruning Mask Refinement at Scale</a></a></li><li><a href=#qubit-decoherence-in-dissipative-two-photon-resonator-real-time-instantons-and-wigner-functionhttpsarxivorgabs251210921v1 aria-label="Qubit decoherence in dissipative two-photon resonator: real-time instantons and Wigner function"><a href=https://arxiv.org/abs/2512.10921v1>Qubit decoherence in dissipative two-photon resonator: real-time instantons and Wigner function</a></a></li><li><a href=#global-stabilization-of-the-planar-ricker-system-with-noisy-pbchttpsarxivorgabs251210919v1 aria-label="Global stabilization of the planar Ricker system with noisy PBC"><a href=https://arxiv.org/abs/2512.10919v1>Global stabilization of the planar Ricker system with noisy PBC</a></a></li><li><a href=#pair-density-wave-in-quarter-metals-from-a-repulsive-fermionic-interaction-in-graphene-heterostructures-a-renormalization-group-studyhttpsarxivorgabs251210944v1 aria-label="Pair-density-wave in quarter-metals from a repulsive fermionic interaction in graphene heterostructures: A renormalization group study"><a href=https://arxiv.org/abs/2512.10944v1>Pair-density-wave in quarter-metals from a repulsive fermionic interaction in graphene heterostructures: A renormalization group study</a></a></li><li><a href=#shaping-chaos-in-bilayer-graphene-cavitieshttpsarxivorgabs251210914v1 aria-label="Shaping chaos in bilayer graphene cavities"><a href=https://arxiv.org/abs/2512.10914v1>Shaping chaos in bilayer graphene cavities</a></a></li><li><a href=#observability-inequality-for-the-von-neumann-equation-in-crystalshttpsarxivorgabs251210897v1 aria-label="Observability inequality for the von Neumann equation in crystals"><a href=https://arxiv.org/abs/2512.10897v1>Observability inequality for the von Neumann equation in crystals</a></a></li><li><a href=#weak-gravity-conjecture-in-the-sky-gravitational-waves-from-preheating-in-einstein-maxwell-scalar-efthttpsarxivorgabs251210890v1 aria-label="Weak Gravity Conjecture in the sky: gravitational waves from preheating in Einstein-Maxwell-Scalar EFT"><a href=https://arxiv.org/abs/2512.10890v1>Weak Gravity Conjecture in the sky: gravitational waves from preheating in Einstein-Maxwell-Scalar EFT</a></a></li><li><a href=#twin-paradox-and-entanglementhttpsarxivorgabs251210908v1 aria-label="Twin-paradox and Entanglement"><a href=https://arxiv.org/abs/2512.10908v1>Twin-paradox and Entanglement</a></a></li><li><a href=#multi-granular-node-pruning-for-circuit-discoveryhttpsarxivorgabs251210903v1 aria-label="Multi-Granular Node Pruning for Circuit Discovery"><a href=https://arxiv.org/abs/2512.10903v1>Multi-Granular Node Pruning for Circuit Discovery</a></a></li><li><a href=#the-facts-leaderboard-a-comprehensive-benchmark-for-large-language-model-factualityhttpsarxivorgabs251210791v1 aria-label="The FACTS Leaderboard: A Comprehensive Benchmark for Large Language Model Factuality"><a href=https://arxiv.org/abs/2512.10791v1>The FACTS Leaderboard: A Comprehensive Benchmark for Large Language Model Factuality</a></a></li><li><a href=#chemical-enrichment-in-liners-from-manga-ii-characterizing-the-shape-of-their-radial-metallicity-gradientshttpsarxivorgabs251210769v1 aria-label="Chemical enrichment in LINERs from MaNGA. II. Characterizing the shape of their radial metallicity gradients"><a href=https://arxiv.org/abs/2512.10769v1>Chemical enrichment in LINERs from MaNGA. II. Characterizing the shape of their radial metallicity gradients</a></a></li><li><a href=#signatures-of-star-formation-inside-galactic-outflowshttpsarxivorgabs251210924v1 aria-label="Signatures of star formation inside galactic outflows"><a href=https://arxiv.org/abs/2512.10924v1>Signatures of star formation inside galactic outflows</a></a></li><li><a href=#companioncast-a-multi-agent-conversational-ai-framework-with-spatial-audio-for-social-co-viewing-experienceshttpsarxivorgabs251210918v1 aria-label="CompanionCast: A Multi-Agent Conversational AI Framework with Spatial Audio for Social Co-Viewing Experiences"><a href=https://arxiv.org/abs/2512.10918v1>CompanionCast: A Multi-Agent Conversational AI Framework with Spatial Audio for Social Co-Viewing Experiences</a></a></li><li><a href=#quantifying-displacement-a-gentrifications-consequence-via-persistent-homologyhttpsarxivorgabs251210753v1 aria-label="Quantifying displacement: a gentrification&rsquo;s consequence via persistent homology"><a href=https://arxiv.org/abs/2512.10753v1>Quantifying displacement: a gentrification&rsquo;s consequence via persistent homology</a></a></li><li><a href=#supporting-migration-policies-with-forecasts-illegal-border-crossings-in-europe-through-a-mixed-approachhttpsarxivorgabs251210633v1 aria-label="Supporting Migration Policies with Forecasts: Illegal Border Crossings in Europe through a Mixed Approach"><a href=https://arxiv.org/abs/2512.10633v1>Supporting Migration Policies with Forecasts: Illegal Border Crossings in Europe through a Mixed Approach</a></a></li></ul></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=weekly-paper-notes>Weekly Paper Notes<a hidden class=anchor aria-hidden=true href=#weekly-paper-notes>#</a></h1><h2 id=-multilingual>üîç multilingual<a hidden class=anchor aria-hidden=true href=#-multilingual>#</a></h2><h3 id=grow-up-and-merge-scaling-strategies-for-efficient-language-adaptationhttpsarxivorgabs251210772v1><a href=https://arxiv.org/abs/2512.10772v1>Grow Up and Merge: Scaling Strategies for Efficient Language Adaptation</a><a hidden class=anchor aria-hidden=true href=#grow-up-and-merge-scaling-strategies-for-efficient-language-adaptationhttpsarxivorgabs251210772v1>#</a></h3><p><strong>Authors:</strong> Kevin Glocker, K√§triin Kukk, Romina Oji, Marcel Bollmann, Marco Kuhlmann, Jenny Kunz
<strong>Venue:</strong> arXiv (2025)</p><p>Achieving high-performing language models which include medium- and lower-resource languages remains a challenge. Massively multilingual models still underperform compared to language-specific adaptations, especially at smaller model scales. In this work, we investigate scaling as an efficient strategy for adapting pretrained models to new target languages. Through comprehensive scaling ablations with approximately FLOP-matched models, we test whether upscaling an English base model enables more effective and resource-efficient adaptation than standard continued pretraining. We find that, once exposed to sufficient target-language data, larger upscaled models can match or surpass the performance of smaller models continually pretrained on much more data, demonstrating the benefits of scaling for data efficiency. Scaling also helps preserve the base model&rsquo;s capabilities in English, thus reducing catastrophic forgetting. Finally, we explore whether such scaled, language-specific models can be merged to construct modular and flexible multilingual systems. We find that while merging remains less effective than joint multilingual training, upscaled merges perform better than smaller ones. We observe large performance differences across merging methods, suggesting potential for improvement through merging approaches specialized for language-level integration.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10772v1">üìÑ Download PDF</a></p><hr><h3 id=agrigpt-omni-a-unified-speech-vision-text-framework-for-multilingual-agricultural-intelligencehttpsarxivorgabs251210624v1><a href=https://arxiv.org/abs/2512.10624v1>AgriGPT-Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence</a><a hidden class=anchor aria-hidden=true href=#agrigpt-omni-a-unified-speech-vision-text-framework-for-multilingual-agricultural-intelligencehttpsarxivorgabs251210624v1>#</a></h3><p><strong>Authors:</strong> Bo Yang, Lanfei Feng, Yunkui Chen, Yu Zhang, Jianyu Zhang, Xiao Xu, Nueraili Aierken, Shijian Li
<strong>Venue:</strong> arXiv (2025)</p><p>Despite rapid advances in multimodal large language models, agricultural applications remain constrained by the lack of multilingual speech data, unified multimodal architectures, and comprehensive evaluation benchmarks. To address these challenges, we present AgriGPT-Omni, an agricultural omni-framework that integrates speech, vision, and text in a unified framework. First, we construct a scalable data synthesis and collection pipeline that converts agricultural texts and images into training data, resulting in the largest agricultural speech dataset to date, including 492K synthetic and 1.4K real speech samples across six languages. Second, based on this, we train the first agricultural omni-model via a three-stage paradigm: textual knowledge injection, progressive multimodal alignment, and GRPO-based reinforcement learning, enabling unified reasoning across languages and modalities. Third, we propose AgriBench-Omni-2K, the first tri-modal benchmark for agriculture, covering diverse speech-vision-text tasks and multilingual slices, with standardized protocols and reproducible tools. Experiments show that AgriGPT-Omni significantly outperforms general-purpose baselines on multilingual and multimodal reasoning as well as real-world speech understanding. All models, data, benchmarks, and code will be released to promote reproducible research, inclusive agricultural intelligence, and sustainable AI development for low-resource regions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10624v1">üìÑ Download PDF</a></p><hr><h3 id=xdoge-multilingual-data-reweighting-to-enhance-language-inclusivity-in-llmshttpsarxivorgabs251210545v1><a href=https://arxiv.org/abs/2512.10545v1>XDoGE: Multilingual Data Reweighting to Enhance Language Inclusivity in LLMs</a><a hidden class=anchor aria-hidden=true href=#xdoge-multilingual-data-reweighting-to-enhance-language-inclusivity-in-llmshttpsarxivorgabs251210545v1>#</a></h3><p><strong>Authors:</strong> I√±aki Lacunza, Jos√© Javier Saiz, Alexander Shvets, Aitor Gonzalez-Agirre, Marta Villegas
<strong>Venue:</strong> arXiv (2025)</p><p>Current large language models (LLMs) are trained on massive amounts of text data, primarily from a few dominant languages. Studies suggest that this over-reliance on high-resource languages, such as English, hampers LLM performance in mid- and low-resource languages. To mitigate this problem, we propose to (i) optimize the language distribution by training a small proxy model within a domain-reweighing DoGE algorithm that we extend to XDoGE for a multilingual setup, and (ii) rescale the data and train a full-size model with the established language weights either from scratch or within a continual pre-training phase (CPT). We target six languages possessing a variety of geographic and intra- and inter-language-family relations, namely, English and Spanish (high-resource), Portuguese and Catalan (mid-resource), Galician and Basque (low-resource). We experiment with Salamandra-2b, which is a promising model for these languages. We investigate the effects of substantial data repetition on minor languages and under-sampling on dominant languages using the IberoBench framework for quantitative evaluation. Finally, we release a new promising IberianLLM-7B-Instruct model centering on Iberian languages and English that we pretrained from scratch and further improved using CPT with the XDoGE weights.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10545v1">üìÑ Download PDF</a></p><hr><h3 id=enhancing-next-generation-language-models-with-knowledge-graphs-extending-claude-mistral-ia-and-gpt-4-via-kg-berthttpsarxivorgabs251210440v1><a href=https://arxiv.org/abs/2512.10440v1>Enhancing Next-Generation Language Models with Knowledge Graphs: Extending Claude, Mistral IA, and GPT-4 via KG-BERT</a><a hidden class=anchor aria-hidden=true href=#enhancing-next-generation-language-models-with-knowledge-graphs-extending-claude-mistral-ia-and-gpt-4-via-kg-berthttpsarxivorgabs251210440v1>#</a></h3><p><strong>Authors:</strong> Nour El Houda Ben Chaabene, Hamza Hammami
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) like Claude, Mistral IA, and GPT-4 excel in NLP but lack structured knowledge, leading to factual inconsistencies. We address this by integrating Knowledge Graphs (KGs) via KG-BERT to enhance grounding and reasoning. Experiments show significant gains in knowledge-intensive tasks such as question answering and entity linking. This approach improves factual reliability and enables more context-aware next-generation LLMs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10440v1">üìÑ Download PDF</a></p><hr><h3 id=multilingual-vlm-training-adapting-an-english-trained-vlm-to-frenchhttpsarxivorgabs251210336v1><a href=https://arxiv.org/abs/2512.10336v1>Multilingual VLM Training: Adapting an English-Trained VLM to French</a><a hidden class=anchor aria-hidden=true href=#multilingual-vlm-training-adapting-an-english-trained-vlm-to-frenchhttpsarxivorgabs251210336v1>#</a></h3><p><strong>Authors:</strong> Jules Lahmi, Alexis Roger
<strong>Venue:</strong> arXiv (2025)</p><p>Artificial intelligence has made great progress in recent years, particularly in the development of Vision&ndash;Language Models (VLMs) that understand both visual and textual data. However, these advancements remain largely limited to English, reducing their accessibility for non&ndash;English speakers. It is essential to extend these capabilities to a broader range of languages. This paper explores the challenges of adapting an English-trained VLM to different languages. To this end, we will explore and compare different methods for their performance and computational cost. We consider a translation-based pipeline, LoRA finetuning, and a two-stage finetuning strategy that separates vision adaptation from language adaptation. To evaluate these methods, we use a combination of standard multimodal benchmarks translated into the target language and manual assessments by native experts. The results reveal that dataset translation remains a major bottleneck in multilingual VLM performance, with data quality limiting the effectiveness of training and evaluation. These findings suggest that future efforts should focus on native-language dataset collection and improved translation strategies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10336v1">üìÑ Download PDF</a></p><hr><h3 id=llm-pea-leveraging-large-language-models-against-phishing-email-attackshttpsarxivorgabs251210104v1><a href=https://arxiv.org/abs/2512.10104v1>LLM-PEA: Leveraging Large Language Models Against Phishing Email Attacks</a><a hidden class=anchor aria-hidden=true href=#llm-pea-leveraging-large-language-models-against-phishing-email-attackshttpsarxivorgabs251210104v1>#</a></h3><p><strong>Authors:</strong> Najmul Hassan, Prashanth BusiReddyGari, Haitao Zhao, Yihao Ren, Jinsheng Xu, Shaohu Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>Email phishing is one of the most prevalent and globally consequential vectors of cyber intrusion. As systems increasingly deploy Large Language Models (LLMs) applications, these systems face evolving phishing email threats that exploit their fundamental architectures. Current LLMs require substantial hardening before deployment in email security systems, particularly against coordinated multi-vector attacks that exploit architectural vulnerabilities. This paper proposes LLMPEA, an LLM-based framework to detect phishing email attacks across multiple attack vectors, including prompt injection, text refinement, and multilingual attacks. We evaluate three frontier LLMs (e.g., GPT-4o, Claude Sonnet 4, and Grok-3) and comprehensive prompting design to assess their feasibility, robustness, and limitations against phishing email attacks. Our empirical analysis reveals that LLMs can detect the phishing email over 90% accuracy while we also highlight that LLM-based phishing email detection systems could be exploited by adversarial attack, prompt injection, and multilingual attacks. Our findings provide critical insights for LLM-based phishing detection in real-world settings where attackers exploit multiple vulnerabilities in combination.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10104v1">üìÑ Download PDF</a></p><hr><h3 id=mitigating-social-bias-in-english-and-urdu-language-models-using-prm-guided-candidate-selection-and-sequential-refinementhttpsarxivorgabs251209854v1><a href=https://arxiv.org/abs/2512.09854v1>Mitigating Social Bias in English and Urdu Language Models Using PRM-Guided Candidate Selection and Sequential Refinement</a><a hidden class=anchor aria-hidden=true href=#mitigating-social-bias-in-english-and-urdu-language-models-using-prm-guided-candidate-selection-and-sequential-refinementhttpsarxivorgabs251209854v1>#</a></h3><p><strong>Authors:</strong> Muneeb Ur Raheem Khan
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) increasingly mediate human communication, decision support, content creation, and information retrieval. Despite impressive fluency, these systems frequently produce biased or stereotypical content, especially when prompted with socially sensitive language. A growing body of research has demonstrated that such biases disproportionately affect low-resource languages, where training data is limited and culturally unrepresentative. This paper presents a comprehensive study of inference-time bias mitigation, a strategy that avoids retraining or fine-tuning and instead operates directly on model outputs. Building on preference-ranking models (PRMs), we introduce a unified evaluation framework comparing three methods: (1) baseline single-word generation, (2) PRM-Select best-of-N sampling, and (3) PRM-Sequential refinement guided by PRM critiques. We evaluate these techniques across 200 English prompts and their Urdu counterparts, designed to reflect socio-cultural contexts relevant to gender, ethnicity, religion, nationality, disability, profession, age, and socioeconomic categories. Using GPT-3.5 as a candidate generator and GPT-4o-mini as a PRM-based bias and utility scorer, we provide an extensive quantitative analysis of bias reduction, utility preservation, and cross-lingual disparities. Our findings show: (a) substantial gains over the baseline for both languages; (b) consistently lower fairness scores for Urdu across all methods, highlighting structural inequities in multilingual LLM training; and (c) distinct improvement trajectories between PRM-Select and PRM-Sequential. The study contributes an extensible methodology, interpretable metrics, and cross-lingual comparisons that can support future work on fairness evaluation in low-resource languages.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.09854v1">üìÑ Download PDF</a></p><hr><h3 id=swissgov-rsd-a-human-annotated-cross-lingual-benchmark-for-token-level-recognition-of-semantic-differences-between-related-documentshttpsarxivorgabs251207538v1><a href=https://arxiv.org/abs/2512.07538v1>SwissGov-RSD: A Human-annotated, Cross-lingual Benchmark for Token-level Recognition of Semantic Differences Between Related Documents</a><a hidden class=anchor aria-hidden=true href=#swissgov-rsd-a-human-annotated-cross-lingual-benchmark-for-token-level-recognition-of-semantic-differences-between-related-documentshttpsarxivorgabs251207538v1>#</a></h3><p><strong>Authors:</strong> Michelle Wastl, Jannis Vamvas, Rico Sennrich
<strong>Venue:</strong> arXiv (2025)</p><p>Recognizing semantic differences across documents, especially in different languages, is crucial for text generation evaluation and multilingual content alignment. However, as a standalone task it has received little attention. We address this by introducing SwissGov-RSD, the first naturalistic, document-level, cross-lingual dataset for semantic difference recognition. It encompasses a total of 224 multi-parallel documents in English-German, English-French, and English-Italian with token-level difference annotations by human annotators. We evaluate a variety of open-source and closed source large language models as well as encoder models across different fine-tuning settings on this new benchmark. Our results show that current automatic approaches perform poorly compared to their performance on monolingual, sentence-level, and synthetic benchmarks, revealing a considerable gap for both LLMs and encoder models. We make our code and datasets publicly available.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.07538v1">üìÑ Download PDF</a></p><hr><h3 id=persian-phi-efficient-cross-lingual-adaptation-of-compact-llms-via-curriculum-learninghttpsarxivorgabs251207454v1><a href=https://arxiv.org/abs/2512.07454v1>Persian-Phi: Efficient Cross-Lingual Adaptation of Compact LLMs via Curriculum Learning</a><a hidden class=anchor aria-hidden=true href=#persian-phi-efficient-cross-lingual-adaptation-of-compact-llms-via-curriculum-learninghttpsarxivorgabs251207454v1>#</a></h3><p><strong>Authors:</strong> Amir Mohammad Akhlaghi, Amirhossein Shabani, Mostafa Abdolmaleki, Saeed Reza Kheradpisheh
<strong>Venue:</strong> arXiv (2025)</p><p>The democratization of AI is currently hindered by the immense computational costs required to train Large Language Models (LLMs) for low-resource languages. This paper presents Persian-Phi, a 3.8B parameter model that challenges the assumption that robust multilingual capabilities require massive model sizes or multilingual baselines. We demonstrate how Microsoft Phi-3 Mini &ndash; originally a monolingual English model &ndash; can be effectively adapted to Persian through a novel, resource-efficient curriculum learning pipeline. Our approach employs a unique &ldquo;warm-up&rdquo; stage using bilingual narratives (Tiny Stories) to align embeddings prior to heavy training, followed by continual pretraining and instruction tuning via Parameter-Efficient Fine-Tuning (PEFT). Despite its compact size, Persian-Phi achieves competitive results on Open Persian LLM Leaderboard in HuggingFace. Our findings provide a validated, scalable framework for extending the reach of state-of-the-art LLMs to underrepresented languages with minimal hardware resources. The Persian-Phi model is publicly available at <a href=https://huggingface.co/amirakhlaghiqqq/PersianPhi>https://huggingface.co/amirakhlaghiqqq/PersianPhi</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.07454v1">üìÑ Download PDF</a></p><hr><h3 id=efficient-asr-for-low-resource-languages-leveraging-cross-lingual-unlabeled-datahttpsarxivorgabs251207277v1><a href=https://arxiv.org/abs/2512.07277v1>Efficient ASR for Low-Resource Languages: Leveraging Cross-Lingual Unlabeled Data</a><a hidden class=anchor aria-hidden=true href=#efficient-asr-for-low-resource-languages-leveraging-cross-lingual-unlabeled-datahttpsarxivorgabs251207277v1>#</a></h3><p><strong>Authors:</strong> Srihari Bandarupalli, Bhavana Akkiraju, Charan Devarakonda, Vamsiraghusimha Narsinga, Anil Kumar Vuppala
<strong>Venue:</strong> arXiv (2025)</p><p>Automatic speech recognition for low-resource languages remains fundamentally constrained by the scarcity of labeled data and computational resources required by state-of-the-art models. We present a systematic investigation into cross-lingual continuous pretraining for low-resource languages, using Perso-Arabic languages (Persian, Arabic, and Urdu) as our primary case study. Our approach demonstrates that strategic utilization of unlabeled speech data can effectively bridge the resource gap without sacrificing recognition accuracy. We construct a 3,000-hour multilingual corpus through a scalable unlabeled data collection pipeline and employ targeted continual pretraining combined with morphologically-aware tokenization to develop a 300M parameter model that achieves performance comparable to systems 5 times larger. Our model outperforms Whisper Large v3 (1.5B parameters) on Persian and achieves competitive results on Arabic and Urdu despite using significantly fewer parameters and substantially less labeled data. These findings challenge the prevailing assumption that ASR quality scales primarily with model size, revealing instead that data relevance and strategic pretraining are more critical factors for low-resource scenarios. This work provides a practical pathway toward inclusive speech technology, enabling effective ASR for underrepresented languages without dependence on massive computational infrastructure or proprietary datasets.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.07277v1">üìÑ Download PDF</a></p><hr><h3 id=cross-platform-product-matching-based-on-entity-alignment-of-knowledge-graph-with-raea-modelhttpsarxivorgabs251207232v1><a href=https://arxiv.org/abs/2512.07232v1>Cross-platform Product Matching Based on Entity Alignment of Knowledge Graph with RAEA model</a><a hidden class=anchor aria-hidden=true href=#cross-platform-product-matching-based-on-entity-alignment-of-knowledge-graph-with-raea-modelhttpsarxivorgabs251207232v1>#</a></h3><p><strong>Authors:</strong> Wenlong Liu, Jiahua Pan, Xingyu Zhang, Xinxin Gong, Yang Ye, Xujin Zhao, Xin Wang, Kent Wu, Hua Xiang, Houmin Yan, Qingpeng Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>Product matching aims to identify identical or similar products sold on different platforms. By building knowledge graphs (KGs), the product matching problem can be converted to the Entity Alignment (EA) task, which aims to discover the equivalent entities from diverse KGs. The existing EA methods inadequately utilize both attribute triples and relation triples simultaneously, especially the interactions between them. This paper introduces a two-stage pipeline consisting of rough filter and fine filter to match products from eBay and Amazon. For fine filtering, a new framework for Entity Alignment, Relation-aware and Attribute-aware Graph Attention Networks for Entity Alignment (RAEA), is employed. RAEA focuses on the interactions between attribute triples and relation triples, where the entity representation aggregates the alignment signals from attributes and relations with Attribute-aware Entity Encoder and Relation-aware Graph Attention Networks. The experimental results indicate that the RAEA model achieves significant improvements over 12 baselines on EA task in the cross-lingual dataset DBP15K (6.59% on average Hits@1) and delivers competitive results in the monolingual dataset DWY100K. The source code for experiments on DBP15K and DWY100K is available at github (<a href=https://github.com/Mockingjay-liu/RAEA-model-for-Entity-Alignment%29>https://github.com/Mockingjay-liu/RAEA-model-for-Entity-Alignment)</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.07232v1">üìÑ Download PDF</a></p><hr><h3 id=masim-multilingual-agent-based-simulation-for-social-sciencehttpsarxivorgabs251207195v1><a href=https://arxiv.org/abs/2512.07195v1>MASim: Multilingual Agent-Based Simulation for Social Science</a><a hidden class=anchor aria-hidden=true href=#masim-multilingual-agent-based-simulation-for-social-sciencehttpsarxivorgabs251207195v1>#</a></h3><p><strong>Authors:</strong> Xuan Zhang, Wenxuan Zhang, Anxu Wang, See-Kiong Ng, Yang Deng
<strong>Venue:</strong> arXiv (2025)</p><p>Multi-agent role-playing has recently shown promise for studying social behavior with language agents, but existing simulations are mostly monolingual and fail to model cross-lingual interaction, an essential property of real societies. We introduce MASim, the first multilingual agent-based simulation framework that supports multi-turn interaction among generative agents with diverse sociolinguistic profiles. MASim offers two key analyses: (i) global public opinion modeling, by simulating how attitudes toward open-domain hypotheses evolve across languages and cultures, and (ii) media influence and information diffusion, via autonomous news agents that dynamically generate content and shape user behavior. To instantiate simulations, we construct the MAPS benchmark, which combines survey questions and demographic personas drawn from global population distributions. Experiments on calibration, sensitivity, consistency, and cultural case studies show that MASim reproduces sociocultural phenomena and highlights the importance of multilingual simulation for scalable, controlled computational social science.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.07195v1">üìÑ Download PDF</a></p><hr><h3 id=mind-the-gap-pathways-towards-unifying-ai-safety-and-ethics-researchhttpsarxivorgabs251210058v1><a href=https://arxiv.org/abs/2512.10058v1>Mind the Gap! Pathways Towards Unifying AI Safety and Ethics Research</a><a hidden class=anchor aria-hidden=true href=#mind-the-gap-pathways-towards-unifying-ai-safety-and-ethics-researchhttpsarxivorgabs251210058v1>#</a></h3><p><strong>Authors:</strong> Dani Roytburg, Beck Miller
<strong>Venue:</strong> arXiv (2025)</p><p>While much research in artificial intelligence (AI) has focused on scaling capabilities, the accelerating pace of development makes countervailing work on producing harmless, &ldquo;aligned&rdquo; systems increasingly urgent. Yet research on alignment has diverged along two largely parallel tracks: safety&ndash;centered on scaled intelligence, deceptive or scheming behaviors, and existential risk&ndash;and ethics&ndash;focused on present harms, the reproduction of social bias, and flaws in production pipelines. Although both communities warn of insufficient investment in alignment, they disagree on what alignment means or ought to mean. As a result, their efforts have evolved in relative isolation, shaped by distinct methodologies, institutional homes, and disciplinary genealogies.
We present a large-scale, quantitative study showing the structural split between AI safety and AI ethics. Using a bibliometric and co-authorship network analysis of 6,442 papers from twelve major ML and NLP conferences (2020-2025), we find that over 80% of collaborations occur within either the safety or ethics communities, and cross-field connectivity is highly concentrated: roughly 5% of papers account for more than 85% of bridging links. Removing a small number of these brokers sharply increases segregation, indicating that cross-disciplinary exchange depends on a handful of actors rather than broad, distributed collaboration. These results show that the safety-ethics divide is not only conceptual but institutional, with implications for research agendas, policy, and venues. We argue that integrating technical safety work with normative ethics&ndash;via shared benchmarks, cross-institutional venues, and mixed-method methodologies&ndash;is essential for building AI systems that are both robust and just.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10058v1">üìÑ Download PDF</a></p><hr><h3 id=local-llm-ensembles-for-zero-shot-portuguese-named-entity-recognitionhttpsarxivorgabs251210043v1><a href=https://arxiv.org/abs/2512.10043v1>Local LLM Ensembles for Zero-shot Portuguese Named Entity Recognition</a><a hidden class=anchor aria-hidden=true href=#local-llm-ensembles-for-zero-shot-portuguese-named-entity-recognitionhttpsarxivorgabs251210043v1>#</a></h3><p><strong>Authors:</strong> Jo√£o Lucas Luz Lima Sarcinelli, Diego Furtado Silva
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Models (LLMs) excel in many Natural Language Processing (NLP) tasks through in-context learning but often under-perform in Named Entity Recognition (NER), especially for lower-resource languages like Portuguese. While open-weight LLMs enable local deployment, no single model dominates all tasks, motivating ensemble approaches. However, existing LLM ensembles focus on text generation or classification, leaving NER under-explored. In this context, this work proposes a novel three-step ensemble pipeline for zero-shot NER using similarly capable, locally run LLMs. Our method outperforms individual LLMs in four out of five Portuguese NER datasets by leveraging a heuristic to select optimal model combinations with minimal annotated data. Moreover, we show that ensembles obtained on different source datasets generally outperform individual LLMs in cross-dataset configurations, potentially eliminating the need for annotated data for the current task. Our work advances scalable, low-resource, and zero-shot NER by effectively combining multiple small LLMs without fine-tuning. Code is available at <a href=https://github.com/Joao-Luz/local-llm-ner-ensemble>https://github.com/Joao-Luz/local-llm-ner-ensemble</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10043v1">üìÑ Download PDF</a></p><hr><h3 id=if-bench-benchmarking-and-enhancing-mllms-for-infrared-images-with-generative-visual-promptinghttpsarxivorgabs251209663v1><a href=https://arxiv.org/abs/2512.09663v1>IF-Bench: Benchmarking and Enhancing MLLMs for Infrared Images with Generative Visual Prompting</a><a hidden class=anchor aria-hidden=true href=#if-bench-benchmarking-and-enhancing-mllms-for-infrared-images-with-generative-visual-promptinghttpsarxivorgabs251209663v1>#</a></h3><p><strong>Authors:</strong> Tao Zhang, Yuyang Hong, Yang Xia, Kun Ding, Zeyu Zhang, Ying Wang, Shiming Xiang, Chunhong Pan
<strong>Venue:</strong> arXiv (2025)</p><p>Recent advances in multimodal large language models (MLLMs) have led to impressive progress across various benchmarks. However, their capability in understanding infrared images remains unexplored. To address this gap, we introduce IF-Bench, the first high-quality benchmark designed for evaluating multimodal understanding of infrared images. IF-Bench consists of 499 images sourced from 23 infrared datasets and 680 carefully curated visual question-answer pairs, covering 10 essential dimensions of image understanding. Based on this benchmark, we systematically evaluate over 40 open-source and closed-source MLLMs, employing cyclic evaluation, bilingual assessment, and hybrid judgment strategies to enhance the reliability of the results. Our analysis reveals how model scale, architecture, and inference paradigms affect infrared image comprehension, providing valuable insights for this area. Furthermore, we propose a training-free generative visual prompting (GenViP) method, which leverages advanced image editing models to translate infrared images into semantically and spatially aligned RGB counterparts, thereby mitigating domain distribution shifts. Extensive experiments demonstrate that our method consistently yields significant performance improvements across a wide range of MLLMs. The benchmark and code are available at <a href=https://github.com/casiatao/IF-Bench>https://github.com/casiatao/IF-Bench</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.09663v1">üìÑ Download PDF</a></p><hr><h3 id=can-llms-evaluate-what-they-cannot-annotate-revisiting-llm-reliability-in-hate-speech-detectionhttpsarxivorgabs251209662v1><a href=https://arxiv.org/abs/2512.09662v1>Can LLMs Evaluate What They Cannot Annotate? Revisiting LLM Reliability in Hate Speech Detection</a><a hidden class=anchor aria-hidden=true href=#can-llms-evaluate-what-they-cannot-annotate-revisiting-llm-reliability-in-hate-speech-detectionhttpsarxivorgabs251209662v1>#</a></h3><p><strong>Authors:</strong> Paloma Piot, David Otero, Patricia Mart√≠n-Rodilla, Javier Parapar
<strong>Venue:</strong> arXiv (2025)</p><p>Hate speech spreads widely online, harming individuals and communities, making automatic detection essential for large-scale moderation, yet detecting it remains difficult. Part of the challenge lies in subjectivity: what one person flags as hate speech, another may see as benign. Traditional annotation agreement metrics, such as Cohen&rsquo;s $Œ∫$, oversimplify this disagreement, treating it as an error rather than meaningful diversity. Meanwhile, Large Language Models (LLMs) promise scalable annotation, but prior studies demonstrate that they cannot fully replace human judgement, especially in subjective tasks. In this work, we reexamine LLM reliability using a subjectivity-aware framework, cross-Rater Reliability (xRR), revealing that even under fairer lens, LLMs still diverge from humans. Yet this limitation opens an opportunity: we find that LLM-generated annotations can reliably reflect performance trends across classification models, correlating with human evaluations. We test this by examining whether LLM-generated annotations preserve the relative ordering of model performance derived from human evaluation (i.e. whether models ranked as more reliable by human annotators preserve the same order when evaluated with LLM-generated labels). Our results show that, although LLMs differ from humans at the instance level, they reproduce similar ranking and classification patterns, suggesting their potential as proxy evaluators. While not a substitute for human annotators, they might serve as a scalable proxy for evaluation in subjective NLP tasks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.09662v1">üìÑ Download PDF</a></p><hr><h3 id=courtpressger-a-german-court-decision-to-press-release-summarization-datasethttpsarxivorgabs251209434v1><a href=https://arxiv.org/abs/2512.09434v1>CourtPressGER: A German Court Decision to Press Release Summarization Dataset</a><a hidden class=anchor aria-hidden=true href=#courtpressger-a-german-court-decision-to-press-release-summarization-datasethttpsarxivorgabs251209434v1>#</a></h3><p><strong>Authors:</strong> Sebastian Nagl, Mohamed Elganayni, Melanie Pospisil, Matthias Grabmair
<strong>Venue:</strong> arXiv (2025)</p><p>Official court press releases from Germany&rsquo;s highest courts present and explain judicial rulings to the public, as well as to expert audiences. Prior NLP efforts emphasize technical headnotes, ignoring citizen-oriented communication needs. We introduce CourtPressGER, a 6.4k dataset of triples: rulings, human-drafted press releases, and synthetic prompts for LLMs to generate comparable releases. This benchmark trains and evaluates LLMs in generating accurate, readable summaries from long judicial texts. We benchmark small and large LLMs using reference-based metrics, factual-consistency checks, LLM-as-judge, and expert ranking. Large LLMs produce high-quality drafts with minimal hierarchical performance loss; smaller models require hierarchical setups for long judgments. Initial benchmarks show varying model performance, with human-drafted releases ranking highest.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.09434v1">üìÑ Download PDF</a></p><hr><h3 id=trident-a-redundant-architecture-for-caribbean-accented-emergency-speech-triagehttpsarxivorgabs251210741v1><a href=https://arxiv.org/abs/2512.10741v1>TRIDENT: A Redundant Architecture for Caribbean-Accented Emergency Speech Triage</a><a hidden class=anchor aria-hidden=true href=#trident-a-redundant-architecture-for-caribbean-accented-emergency-speech-triagehttpsarxivorgabs251210741v1>#</a></h3><p><strong>Authors:</strong> Elroy Galbraith, Chadwick Sutherland, Donahue Morgan
<strong>Venue:</strong> arXiv (2025)</p><p>Emergency speech recognition systems exhibit systematic performance degradation on non-standard English varieties, creating a critical gap in services for Caribbean populations. We present TRIDENT (Transcription and Routing Intelligence for Dispatcher-Empowered National Triage), a three-layer dispatcher-support architecture designed to structure emergency call inputs for human application of established triage protocols (the ESI for routine operations and START for mass casualty events), even when automatic speech recognition fails.
The system combines Caribbean-accent-tuned ASR, local entity extraction via large language models, and bio-acoustic distress detection to provide dispatchers with three complementary signals: transcription confidence, structured clinical entities, and vocal stress indicators. Our key insight is that low ASR confidence, rather than representing system failure, serves as a valuable queue prioritization signal &ndash; particularly when combined with elevated vocal distress markers indicating a caller in crisis whose speech may have shifted toward basilectal registers. A complementary insight drives the entity extraction layer: trained responders and composed bystanders may report life-threatening emergencies without elevated vocal stress, requiring semantic analysis to capture clinical indicators that paralinguistic features miss.
We describe the architectural design, theoretical grounding in psycholinguistic research on stress-induced code-switching, and deployment considerations for offline operation during disaster scenarios. This work establishes a framework for accent-resilient emergency AI that ensures Caribbean voices receive equitable access to established national triage protocols. Empirical validation on Caribbean emergency calls remains future work.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10741v1">üìÑ Download PDF</a></p><hr><h3 id=training-one-model-to-master-cross-level-agentic-actions-via-reinforcement-learninghttpsarxivorgabs251209706v1><a href=https://arxiv.org/abs/2512.09706v1>Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning</a><a hidden class=anchor aria-hidden=true href=#training-one-model-to-master-cross-level-agentic-actions-via-reinforcement-learninghttpsarxivorgabs251209706v1>#</a></h3><p><strong>Authors:</strong> Kaichen He, Zihao Wang, Muyao Li, Anji Liu, Yitao Liang
<strong>Venue:</strong> arXiv (2025)</p><p>The paradigm of agentic AI is shifting from engineered complex workflows to post-training native models. However, existing agents are typically confined to static, predefined action spaces&ndash;such as exclusively using APIs, GUI events, or robotic commands. This rigidity limits their adaptability in dynamic environments where the optimal granularity of interaction varies contextually. To bridge this gap, we propose CrossAgent, a unified agentic model that masters heterogeneous action spaces and autonomously selects the most effective interface for each step of a trajectory. We introduce a comprehensive training pipeline that integrates cold-start supervised fine-tuning with a Multi-Turn Group Relative Policy Optimization (GRPO) algorithm. This approach enables the agent to learn adaptive action switching&ndash;balancing high-level efficiency with low-level precision&ndash;without human-specified rules. Extensive experiments on over 800 tasks in the open-world Minecraft environment demonstrate that CrossAgent achieves state-of-the-art performance. By dynamically leveraging the strengths of diverse action spaces, our model significantly outperforms fixed-action baselines, exhibiting superior generalization and efficiency in long-horizon reasoning. All code and models are available at <a href=https://github.com/CraftJarvis/OpenHA>https://github.com/CraftJarvis/OpenHA</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.09706v1">üìÑ Download PDF</a></p><hr><h3 id=straggler-tolerant-and-resilient-dl-training-on-homogeneous-gpushttpsarxivorgabs251209685v1><a href=https://arxiv.org/abs/2512.09685v1>Straggler Tolerant and Resilient DL Training on Homogeneous GPUs</a><a hidden class=anchor aria-hidden=true href=#straggler-tolerant-and-resilient-dl-training-on-homogeneous-gpushttpsarxivorgabs251209685v1>#</a></h3><p><strong>Authors:</strong> Zeyu Zhang, Haiying Shen
<strong>Venue:</strong> arXiv (2025)</p><p>Despite the popularity of homogeneous GPU-based deep learning (DL) training, the prevalence, causes and impact of stragglers and the effectiveness of existing straggler mitigation approaches are still not well understood in this scenario due to limited research on these questions. To fill this gap, we conducted comprehensive experiments and found that stragglers remain widespread due to CPU and bandwidth usage imbalances. Additionally, existing mitigation methods that switch from synchronous stochastic gradient descent (SSGD) to asynchronous SGD (ASGD) may not improve Time-To-Accuracy (TTA) and can even generate more stragglers due to its higher resource consumption. To address these newly found problems, we propose the Straggler Tolerant And Resilient DL training system (STAR). STAR includes new synchronization modes that group workers for each parameter updating. It has a heuristic and an ML method to choose the optimal synchronization mode for minimizing TTA, and reallocates resources to support the selected mode while minimizing the impact on co-located jobs. Moreover, it proactively prevents stragglers by avoiding overloading the CPU and bandwidth resources in allocating PSs (which consume high CPU and bandwidth) and in gradient transmission. Our trace-driven evaluation on AWS shows that STAR generates 48-84% and 51-70% lower TTA than state-of-the-art systems in the PS and all-reduce architectures, respectively, while maintaining the converged accuracy of SSGD. The code for STAR is open-sourced.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.09685v1">üìÑ Download PDF</a></p><hr><h3 id=reasan-learning-reactive-safe-navigation-for-legged-robotshttpsarxivorgabs251209537v1><a href=https://arxiv.org/abs/2512.09537v1>REASAN: Learning Reactive Safe Navigation for Legged Robots</a><a hidden class=anchor aria-hidden=true href=#reasan-learning-reactive-safe-navigation-for-legged-robotshttpsarxivorgabs251209537v1>#</a></h3><p><strong>Authors:</strong> Qihao Yuan, Ziyu Cao, Ming Cao, Kailai Li
<strong>Venue:</strong> arXiv (2025)</p><p>We present a novel modularized end-to-end framework for legged reactive navigation in complex dynamic environments using a single light detection and ranging (LiDAR) sensor. The system comprises four simulation-trained modules: three reinforcement-learning (RL) policies for locomotion, safety shielding, and navigation, and a transformer-based exteroceptive estimator that processes raw point-cloud inputs. This modular decomposition of complex legged motor-control tasks enables lightweight neural networks with simple architectures, trained using standard RL practices with targeted reward shaping and curriculum design, without reliance on heuristics or sophisticated policy-switching mechanisms. We conduct comprehensive ablations to validate our design choices and demonstrate improved robustness compared to existing approaches in challenging navigation tasks. The resulting reactive safe navigation (REASAN) system achieves fully onboard and real-time reactive navigation across both single- and multi-robot settings in complex environments. We release our training and deployment code at <a href=https://github.com/ASIG-X/REASAN>https://github.com/ASIG-X/REASAN</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.09537v1">üìÑ Download PDF</a></p><hr><h3 id=basic-lock-algorithms-in-lightweight-thread-environmentshttpsarxivorgabs251208563v1><a href=https://arxiv.org/abs/2512.08563v1>Basic Lock Algorithms in Lightweight Thread Environments</a><a hidden class=anchor aria-hidden=true href=#basic-lock-algorithms-in-lightweight-thread-environmentshttpsarxivorgabs251208563v1>#</a></h3><p><strong>Authors:</strong> Taras Skazhenik, Nikolai Korobenikov, Andrei Churbanov, Anton Malakhov, Vitaly Aksenov
<strong>Venue:</strong> arXiv (2025)</p><p>Traditionally, multithreaded data structures have been designed for access by the threads of Operating Systems (OS). However, implementations for access by programmable alternatives known as lightweight threads (also referred to as asynchronous calls or coroutines) have not been thoroughly studied. The main advantage of lightweight threads is their significantly lower overhead during launch and context switching. However, this comes at a cost: to achieve proper parallelism, context switches must be manually invoked in the code; without these switches, new lightweight threads will never be executed.
In this paper, we focus on the simplest multithreaded data structure: a mutex (also known as a lock). We demonstrate that original implementations for OS threads cannot be used effectively in this new context due to the potential for deadlocks. Furthermore, correctness is not the only concern. In certain languages, such as C++, there are various lightweight thread libraries, each with different implementations and interfaces, which necessitate distinct lock implementations.
In this work, we present a modification of TTAS and MCS locks for the use from lightweight threads and demonstrate that the two context switch mechanisms of lightweight threads, yielding and sleeping, are crucial. However, the performance of TTAS and MCS may differ significantly depending on the settings. If one wants to have a lock that works well for any library, we suggest using the cohort lock, which strikes a balance between MCS and TTAS by utilizing several MCS queues with a common TTAS.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.08563v1">üìÑ Download PDF</a></p><hr><h3 id=polylingua-margin-based-inter-class-transformer-for-robust-cross-domain-language-detectionhttpsarxivorgabs251208143v2><a href=https://arxiv.org/abs/2512.08143v2>PolyLingua: Margin-based Inter-class Transformer for Robust Cross-domain Language Detection</a><a hidden class=anchor aria-hidden=true href=#polylingua-margin-based-inter-class-transformer-for-robust-cross-domain-language-detectionhttpsarxivorgabs251208143v2>#</a></h3><p><strong>Authors:</strong> Ali Lotfi Rezaabad, Bikram Khanal, Shashwat Chaurasia, Lu Zeng, Dezhi Hong, Hossein Bashashati, Thomas Butler, Megan Ganji
<strong>Venue:</strong> arXiv (2025)</p><p>Language identification is a crucial first step in multilingual systems such as chatbots and virtual assistants, enabling linguistically and culturally accurate user experiences. Errors at this stage can cascade into downstream failures, setting a high bar for accuracy. Yet, existing language identification tools struggle with key cases &ndash; such as music requests where the song title and user language differ. Open-source tools like LangDetect, FastText are fast but less accurate, while large language models, though effective, are often too costly for low-latency or low-resource settings. We introduce PolyLingua, a lightweight Transformer-based model for in-domain language detection and fine-grained language classification. It employs a two-level contrastive learning framework combining instance-level separation and class-level alignment with adaptive margins, yielding compact and well-separated embeddings even for closely related languages. Evaluated on two challenging datasets &ndash; Amazon Massive (multilingual digital assistant utterances) and a Song dataset (music requests with frequent code-switching) &ndash; PolyLingua achieves 99.25% F1 and 98.15% F1, respectively, surpassing Sonnet 3.5 while using 10x fewer parameters, making it ideal for compute- and latency-constrained environments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.08143v2">üìÑ Download PDF</a></p><hr><h3 id=optimizing-data-extraction-from-materials-science-literature-a-study-of-tools-using-large-language-modelshttpsarxivorgabs251209370v1><a href=https://arxiv.org/abs/2512.09370v1>Optimizing Data Extraction from Materials Science Literature: A Study of Tools Using Large Language Models</a><a hidden class=anchor aria-hidden=true href=#optimizing-data-extraction-from-materials-science-literature-a-study-of-tools-using-large-language-modelshttpsarxivorgabs251209370v1>#</a></h3><p><strong>Authors:</strong> Wenkai Ning, Musen Li, Jeffrey R. Reimers, Rika Kobayashi
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Models (LLMs) are increasingly utilized for large-scale extraction and organization of unstructured data owing to their exceptional Natural Language Processing (NLP) capabilities. Empowering materials design, vast amounts of data from experiments and simulations are scattered across numerous scientific publications, but high-quality experimental databases are scarce. This study considers the effectiveness and practicality of five representative AI tools (ChemDataExtractor, BERT-PSIE, ChatExtract, LangChain, and Kimi) to extract bandgaps from 200 randomly selected Materials Science publications in two presentations (arXiv and publisher versions), comparing the results to those obtained by human processing. Although the integrity of data extraction has not met expectations, encouraging results have been achieved in terms of precision and the ability to eliminate irrelevant papers from human consideration. Our analysis highlights both the strengths and limitations of these tools, offering insights into improving future data extraction techniques for enhanced scientific discovery and innovation. In conjunction with recent research, we provide guidance on feasible improvements for future data extraction methodologies, helping to bridge the gap between unstructured scientific data and structured, actionable databases.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.09370v1">üìÑ Download PDF</a></p><hr><h3 id=empowering-dynamic-urban-navigation-with-stereo-and-mid-level-visionhttpsarxivorgabs251210956v1><a href=https://arxiv.org/abs/2512.10956v1>Empowering Dynamic Urban Navigation with Stereo and Mid-Level Vision</a><a hidden class=anchor aria-hidden=true href=#empowering-dynamic-urban-navigation-with-stereo-and-mid-level-visionhttpsarxivorgabs251210956v1>#</a></h3><p><strong>Authors:</strong> Wentao Zhou, Xuweiyi Chen, Vignesh Rajagopal, Jeffrey Chen, Rohan Chandra, Zezhou Cheng
<strong>Venue:</strong> arXiv (2025)</p><p>The success of foundation models in language and vision motivated research in fully end-to-end robot navigation foundation models (NFMs). NFMs directly map monocular visual input to control actions and ignore mid-level vision modules (tracking, depth estimation, etc) entirely. While the assumption that vision capabilities will emerge implicitly is compelling, it requires large amounts of pixel-to-action supervision that are difficult to obtain. The challenge is especially pronounced in dynamic and unstructured settings, where robust navigation requires precise geometric and dynamic understanding, while the depth-scale ambiguity in monocular views further limits accurate spatial reasoning. In this paper, we show that relying on monocular vision and ignoring mid-level vision priors is inefficient.
We present StereoWalker, which augments NFMs with stereo inputs and explicit mid-level vision such as depth estimation and dense pixel tracking. Our intuition is straightforward: stereo inputs resolve the depth-scale ambiguity, and modern mid-level vision models provide reliable geometric and motion structure in dynamic scenes. We also curate a large stereo navigation dataset with automatic action annotation from Internet stereo videos to support training of StereoWalker and to facilitate future research. Through our experiments, we find that mid-level vision enables StereoWalker to achieve a comparable performance as the state-of-the-art using only 1.5% of the training data, and surpasses the state-of-the-art using the full data. We also observe that stereo vision yields higher navigation performance than monocular input.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10956v1">üìÑ Download PDF</a></p><hr><h3 id=e-rayzer-self-supervised-3d-reconstruction-as-spatial-visual-pre-traininghttpsarxivorgabs251210950v1><a href=https://arxiv.org/abs/2512.10950v1>E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training</a><a hidden class=anchor aria-hidden=true href=#e-rayzer-self-supervised-3d-reconstruction-as-spatial-visual-pre-traininghttpsarxivorgabs251210950v1>#</a></h3><p><strong>Authors:</strong> Qitao Zhao, Hao Tan, Qianqian Wang, Sai Bi, Kai Zhang, Kalyan Sunkavalli, Shubham Tulsiani, Hanwen Jiang
<strong>Venue:</strong> arXiv (2025)</p><p>Self-supervised pre-training has revolutionized foundation models for languages, individual 2D images and videos, but remains largely unexplored for learning 3D-aware representations from multi-view images. In this paper, we present E-RayZer, a self-supervised large 3D Vision model that learns truly 3D-aware representations directly from unlabeled images. Unlike prior self-supervised methods such as RayZer that infer 3D indirectly through latent-space view synthesis, E-RayZer operates directly in 3D space, performing self-supervised 3D reconstruction with Explicit geometry. This formulation eliminates shortcut solutions and yields representations that are geometrically grounded. To ensure convergence and scalability, we introduce a novel fine-grained learning curriculum that organizes training from easy to hard samples and harmonizes heterogeneous data sources in an entirely unsupervised manner. Experiments demonstrate that E-RayZer significantly outperforms RayZer on pose estimation, matches or sometimes surpasses fully supervised reconstruction models such as VGGT. Furthermore, its learned representations outperform leading visual pre-training models (e.g., DINOv3, CroCo v2, VideoMAE V2, and RayZer) when transferring to 3D downstream tasks, establishing E-RayZer as a new paradigm for 3D-aware visual pre-training.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10950v1">üìÑ Download PDF</a></p><hr><h3 id=are-we-ready-for-rl-in-text-to-3d-generation-a-progressive-investigationhttpsarxivorgabs251210949v1><a href=https://arxiv.org/abs/2512.10949v1>Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation</a><a hidden class=anchor aria-hidden=true href=#are-we-ready-for-rl-in-text-to-3d-generation-a-progressive-investigationhttpsarxivorgabs251210949v1>#</a></h3><p><strong>Authors:</strong> Yiwen Tang, Zoey Guo, Kaixin Zhu, Ray Zhang, Qizhi Chen, Dongzhi Jiang, Junli Liu, Bohan Zeng, Haoming Song, Delin Qu, Tianyi Bai, Dan Xu, Wentao Zhang, Bin Zhao
<strong>Venue:</strong> arXiv (2025)</p><p>Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at <a href=https://github.com/Ivan-Tang-3D/3DGen-R1>https://github.com/Ivan-Tang-3D/3DGen-R1</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10949v1">üìÑ Download PDF</a></p><hr><h3 id=towards-efficient-and-effective-multi-camera-encoding-for-end-to-end-drivinghttpsarxivorgabs251210947v1><a href=https://arxiv.org/abs/2512.10947v1>Towards Efficient and Effective Multi-Camera Encoding for End-to-End Driving</a><a hidden class=anchor aria-hidden=true href=#towards-efficient-and-effective-multi-camera-encoding-for-end-to-end-drivinghttpsarxivorgabs251210947v1>#</a></h3><p><strong>Authors:</strong> Jiawei Yang, Ziyu Chen, Yurong You, Yan Wang, Yiming Li, Yuxiao Chen, Boyi Li, Boris Ivanovic, Marco Pavone, Yue Wang
<strong>Venue:</strong> arXiv (2025)</p><p>We present Flex, an efficient and effective scene encoder that addresses the computational bottleneck of processing high-volume multi-camera data in end-to-end autonomous driving. Flex employs a small set of learnable scene tokens to jointly encode information from all image tokens across different cameras and timesteps. By design, our approach is geometry-agnostic, learning a compact scene representation directly from data without relying on the explicit 3D inductive biases, such as Bird-Eye-View (BEV), occupancy or tri-plane representations, which are common in prior work. This holistic encoding strategy aggressively compresses the visual input for the downstream Large Language Model (LLM) based policy model. Evaluated on a large-scale proprietary dataset of 20,000 driving hours, our Flex achieves 2.2x greater inference throughput while improving driving performance by a large margin compared to state-of-the-art methods. Furthermore, we show that these compact scene tokens develop an emergent capability for scene decomposition without any explicit supervision. Our findings challenge the prevailing assumption that 3D priors are necessary, demonstrating that a data-driven, joint encoding strategy offers a more scalable, efficient and effective path for future autonomous driving systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10947v1">üìÑ Download PDF</a></p><hr><h3 id=mevis-a-multi-modal-dataset-for-referring-motion-expression-video-segmentationhttpsarxivorgabs251210945v1><a href=https://arxiv.org/abs/2512.10945v1>MeViS: A Multi-Modal Dataset for Referring Motion Expression Video Segmentation</a><a hidden class=anchor aria-hidden=true href=#mevis-a-multi-modal-dataset-for-referring-motion-expression-video-segmentationhttpsarxivorgabs251210945v1>#</a></h3><p><strong>Authors:</strong> Henghui Ding, Chang Liu, Shuting He, Kaining Ying, Xudong Jiang, Chen Change Loy, Yu-Gang Jiang
<strong>Venue:</strong> arXiv (2025)</p><p>This paper proposes a large-scale multi-modal dataset for referring motion expression video segmentation, focusing on segmenting and tracking target objects in videos based on language description of objects&rsquo; motions. Existing referring video segmentation datasets often focus on salient objects and use language expressions rich in static attributes, potentially allowing the target object to be identified in a single frame. Such datasets underemphasize the role of motion in both videos and languages. To explore the feasibility of using motion expressions and motion reasoning clues for pixel-level video understanding, we introduce MeViS, a dataset containing 33,072 human-annotated motion expressions in both text and audio, covering 8,171 objects in 2,006 videos of complex scenarios. We benchmark 15 existing methods across 4 tasks supported by MeViS, including 6 referring video object segmentation (RVOS) methods, 3 audio-guided video object segmentation (AVOS) methods, 2 referring multi-object tracking (RMOT) methods, and 4 video captioning methods for the newly introduced referring motion expression generation (RMEG) task. The results demonstrate weaknesses and limitations of existing methods in addressing motion expression-guided video understanding. We further analyze the challenges and propose an approach LMPM++ for RVOS/AVOS/RMOT that achieves new state-of-the-art results. Our dataset provides a platform that facilitates the development of motion expression-guided video understanding algorithms in complex video scenes. The proposed MeViS dataset and the method&rsquo;s source code are publicly available at <a href=https://henghuiding.com/MeViS/>https://henghuiding.com/MeViS/</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10945v1">üìÑ Download PDF</a></p><hr><h3 id=vl-jepa-joint-embedding-predictive-architecture-for-vision-languagehttpsarxivorgabs251210942v1><a href=https://arxiv.org/abs/2512.10942v1>VL-JEPA: Joint Embedding Predictive Architecture for Vision-language</a><a hidden class=anchor aria-hidden=true href=#vl-jepa-joint-embedding-predictive-architecture-for-vision-languagehttpsarxivorgabs251210942v1>#</a></h3><p><strong>Authors:</strong> Delong Chen, Mustafa Shukor, Theo Moutakanni, Willy Chung, Jade Yu, Tejaswi Kasarla, Allen Bolourchi, Yann LeCun, Pascale Fung
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce VL-JEPA, a vision-language model built on a Joint Embedding Predictive Architecture (JEPA). Instead of autoregressively generating tokens as in classical VLMs, VL-JEPA predicts continuous embeddings of the target texts. By learning in an abstract representation space, the model focuses on task-relevant semantics while abstracting away surface-level linguistic variability. In a strictly controlled comparison against standard token-space VLM training with the same vision encoder and training data, VL-JEPA achieves stronger performance while having 50% fewer trainable parameters. At inference time, a lightweight text decoder is invoked only when needed to translate VL-JEPA predicted embeddings into text. We show that VL-JEPA natively supports selective decoding that reduces the number of decoding operations by 2.85x while maintaining similar performance compared to non-adaptive uniform decoding. Beyond generation, the VL-JEPA&rsquo;s embedding space naturally supports open-vocabulary classification, text-to-video retrieval, and discriminative VQA without any architecture modification. On eight video classification and eight video retrieval datasets, the average performance VL-JEPA surpasses that of CLIP, SigLIP2, and Perception Encoder. At the same time, the model achieves comparable performance as classical VLMs (InstructBLIP, QwenVL) on four VQA datasets: GQA, TallyQA, POPE and POPEv2, despite only having 1.6B parameters.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10942v1">üìÑ Download PDF</a></p><hr><h3 id=hierarchical-dataset-selection-for-high-quality-data-sharinghttpsarxivorgabs251210952v1><a href=https://arxiv.org/abs/2512.10952v1>Hierarchical Dataset Selection for High-Quality Data Sharing</a><a hidden class=anchor aria-hidden=true href=#hierarchical-dataset-selection-for-high-quality-data-sharinghttpsarxivorgabs251210952v1>#</a></h3><p><strong>Authors:</strong> Xiaona Zhou, Yingyan Zeng, Ran Jin, Ismini Lourentzou
<strong>Venue:</strong> arXiv (2025)</p><p>The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10952v1">üìÑ Download PDF</a></p><hr><h3 id=omni-attribute-open-vocabulary-attribute-encoder-for-visual-concept-personalizationhttpsarxivorgabs251210955v1><a href=https://arxiv.org/abs/2512.10955v1>Omni-Attribute: Open-vocabulary Attribute Encoder for Visual Concept Personalization</a><a hidden class=anchor aria-hidden=true href=#omni-attribute-open-vocabulary-attribute-encoder-for-visual-concept-personalizationhttpsarxivorgabs251210955v1>#</a></h3><p><strong>Authors:</strong> Tsai-Shien Chen, Aliaksandr Siarohin, Guocheng Gordon Qian, Kuan-Chieh Jackson Wang, Egor Nemchinov, Moayed Haji-Ali, Riza Alp Guler, Willi Menapace, Ivan Skorokhodov, Anil Kag, Jun-Yan Zhu, Sergey Tulyakov
<strong>Venue:</strong> arXiv (2025)</p><p>Visual concept personalization aims to transfer only specific image attributes, such as identity, expression, lighting, and style, into unseen contexts. However, existing methods rely on holistic embeddings from general-purpose image encoders, which entangle multiple visual factors and make it difficult to isolate a single attribute. This often leads to information leakage and incoherent synthesis. To address this limitation, we introduce Omni-Attribute, the first open-vocabulary image attribute encoder designed to learn high-fidelity, attribute-specific representations. Our approach jointly designs the data and model: (i) we curate semantically linked image pairs annotated with positive and negative attributes to explicitly teach the encoder what to preserve or suppress; and (ii) we adopt a dual-objective training paradigm that balances generative fidelity with contrastive disentanglement. The resulting embeddings prove effective for open-vocabulary attribute retrieval, personalization, and compositional generation, achieving state-of-the-art performance across multiple benchmarks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10955v1">üìÑ Download PDF</a></p><hr><h3 id=curriculum-based-reinforcement-learning-for-autonomous-uav-navigation-in-unknown-curved-tubular-conduithttpsarxivorgabs251210934v1><a href=https://arxiv.org/abs/2512.10934v1>Curriculum-Based Reinforcement Learning for Autonomous UAV Navigation in Unknown Curved Tubular Conduit</a><a hidden class=anchor aria-hidden=true href=#curriculum-based-reinforcement-learning-for-autonomous-uav-navigation-in-unknown-curved-tubular-conduithttpsarxivorgabs251210934v1>#</a></h3><p><strong>Authors:</strong> Zamirddine Mari, J√©r√¥me Pasquet, Julien Seinturier
<strong>Venue:</strong> arXiv (2025)</p><p>Autonomous drone navigation in confined tubular environments remains a major challenge due to the constraining geometry of the conduits, the proximity of the walls, and the perceptual limitations inherent to such scenarios. We propose a reinforcement learning approach enabling a drone to navigate unknown three-dimensional tubes without any prior knowledge of their geometry, relying solely on local observations from LiDAR and a conditional visual detection of the tube center. In contrast, the Pure Pursuit algorithm, used as a deterministic baseline, benefits from explicit access to the centerline, creating an information asymmetry designed to assess the ability of RL to compensate for the absence of a geometric model. The agent is trained through a progressive Curriculum Learning strategy that gradually exposes it to increasingly curved geometries, where the tube center frequently disappears from the visual field. A turning-negotiation mechanism, based on the combination of direct visibility, directional memory, and LiDAR symmetry cues, proves essential for ensuring stable navigation under such partial observability conditions. Experiments show that the PPO policy acquires robust and generalizable behavior, consistently outperforming the deterministic controller despite its limited access to geometric information. Validation in a high-fidelity 3D environment further confirms the transferability of the learned behavior to a continuous physical dynamics.
The proposed approach thus provides a complete framework for autonomous navigation in unknown tubular environments and opens perspectives for industrial, underground, or medical applications where progressing through narrow and weakly perceptive conduits represents a central challenge.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10934v1">üìÑ Download PDF</a></p><hr><h3 id=digital-twin-supervised-reinforcement-learning-framework-for-autonomous-underwater-navigationhttpsarxivorgabs251210925v1><a href=https://arxiv.org/abs/2512.10925v1>Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation</a><a hidden class=anchor aria-hidden=true href=#digital-twin-supervised-reinforcement-learning-framework-for-autonomous-underwater-navigationhttpsarxivorgabs251210925v1>#</a></h3><p><strong>Authors:</strong> Zamirddine Mari, Mohamad Motasem Nawaf, Pierre Drap
<strong>Venue:</strong> arXiv (2025)</p><p>Autonomous navigation in underwater environments remains a major challenge due to the absence of GPS, degraded visibility, and the presence of submerged obstacles. This article investigates these issues through the case of the BlueROV2, an open platform widely used for scientific experimentation. We propose a deep reinforcement learning approach based on the Proximal Policy Optimization (PPO) algorithm, using an observation space that combines target-oriented navigation information, a virtual occupancy grid, and ray-casting along the boundaries of the operational area. The learned policy is compared against a reference deterministic kinematic planner, the Dynamic Window Approach (DWA), commonly employed as a robust baseline for obstacle avoidance. The evaluation is conducted in a realistic simulation environment and complemented by validation on a physical BlueROV2 supervised by a 3D digital twin of the test site, helping to reduce risks associated with real-world experimentation. The results show that the PPO policy consistently outperforms DWA in highly cluttered environments, notably thanks to better local adaptation and reduced collisions. Finally, the experiments demonstrate the transferability of the learned behavior from simulation to the real world, confirming the relevance of deep RL for autonomous navigation in underwater robotics.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10925v1">üìÑ Download PDF</a></p><hr><h3 id=physics-informed-learning-of-flow-distribution-and-receiver-heat-losses-in-parabolic-trough-solar-fieldshttpsarxivorgabs251210886v1><a href=https://arxiv.org/abs/2512.10886v1>Physics-Informed Learning of Flow Distribution and Receiver Heat Losses in Parabolic Trough Solar Fields</a><a hidden class=anchor aria-hidden=true href=#physics-informed-learning-of-flow-distribution-and-receiver-heat-losses-in-parabolic-trough-solar-fieldshttpsarxivorgabs251210886v1>#</a></h3><p><strong>Authors:</strong> Stefan Matthes, Markus Schramm
<strong>Venue:</strong> arXiv (2025)</p><p>Parabolic trough Concentrating Solar Power (CSP) plants operate large hydraulic networks of collector loops that must deliver a uniform outlet temperature despite spatially heterogeneous optical performance, heat losses, and pressure drops. While loop temperatures are measured, loop-level mass flows and receiver heat-loss parameters are unobserved, making it impossible to diagnose hydraulic imbalances or receiver degradation using standard monitoring tools.
We present a physics-informed learning framework that infers (i) loop-level mass-flow ratios and (ii) time-varying receiver heat-transfer coefficients directly from routine operational data. The method exploits nocturnal homogenization periods &ndash; when hot oil is circulated through a non-irradiated field &ndash; to isolate hydraulic and thermal-loss effects. A differentiable conjugate heat-transfer model is discretized and embedded into an end-to-end learning pipeline optimized using historical plant data from the 50 MW Andasol 3 solar field.
The model accurately reconstructs loop temperatures (RMSE $&lt;2^\circ$C) and produces physically meaningful estimates of loop imbalances and receiver heat losses. Comparison against drone-based infrared thermography (QScan) shows strong correspondence, correctly identifying all areas with high-loss receivers. This demonstrates that noisy real-world CSP operational data contain enough information to recover latent physical parameters when combined with appropriate modeling and differentiable optimization.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10886v1">üìÑ Download PDF</a></p><hr><h3 id=guided-transfer-learning-for-discrete-diffusion-modelshttpsarxivorgabs251210877v1><a href=https://arxiv.org/abs/2512.10877v1>Guided Transfer Learning for Discrete Diffusion Models</a><a hidden class=anchor aria-hidden=true href=#guided-transfer-learning-for-discrete-diffusion-modelshttpsarxivorgabs251210877v1>#</a></h3><p><strong>Authors:</strong> Julian Kleutgens, Claudio Battiloro, Lingkai Kong, Benjamin Grewe, Francesca Dominici, Mauricio Tec
<strong>Venue:</strong> arXiv (2025)</p><p>Discrete diffusion models achieve strong performance across language and other discrete domains, providing a powerful alternative to autoregressive models. However, their strong performance relies on large training datasets, which are costly or risky to obtain, especially when adapting to new domains. Transfer learning is the natural way to adapt pretrained discrete diffusion models, but current methods require fine-tuning large diffusion models, which is computationally expensive and often impractical. Building on ratio-based transfer learning for continuous diffusion, we provide Guided Transfer Learning for discrete diffusion models (GTL). This enables sampling from a target distribution without modifying the pretrained denoiser. The same guidance formulation applies to both discrete-time diffusion and continuous-time score-based discrete diffusion, yielding a unified treatment. Guided discrete diffusion often requires many forward passes of the guidance network, which becomes impractical for large vocabularies and long sequences. To address this, we further present an efficient guided sampler that concentrates evaluations on planner-selected positions and top candidate tokens, thus lowering sampling time and computation. This makes guided language modeling practical at scale for large vocabularies and long sequences. We evaluate GTL on sequential data, including synthetic Markov chains and language modeling, and provide empirical analyses of its behavior.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10877v1">üìÑ Download PDF</a></p><hr><h3 id=worldlens-full-spectrum-evaluations-of-driving-world-models-in-real-worldhttpsarxivorgabs251210958v1><a href=https://arxiv.org/abs/2512.10958v1>WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World</a><a hidden class=anchor aria-hidden=true href=#worldlens-full-spectrum-evaluations-of-driving-world-models-in-real-worldhttpsarxivorgabs251210958v1>#</a></h3><p><strong>Authors:</strong> Ao Liang, Lingdong Kong, Tianyi Yan, Hongsi Liu, Wesley Yang, Ziqi Huang, Wei Yin, Jialong Zuo, Yixuan Hu, Dekai Zhu, Dongyue Lu, Youquan Liu, Guangfeng Jiang, Linfeng Li, Xiangtai Li, Long Zhuo, Lai Xing Ng, Benoit R. Cottereau, Changxin Gao, Liang Pan, Wei Tsang Ooi, Ziwei Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Generative world models are reshaping embodied AI, enabling agents to synthesize realistic 4D driving environments that look convincing but often fail physically or behaviorally. Despite rapid progress, the field still lacks a unified way to assess whether generated worlds preserve geometry, obey physics, or support reliable control. We introduce WorldLens, a full-spectrum benchmark evaluating how well a model builds, understands, and behaves within its generated world. It spans five aspects &ndash; Generation, Reconstruction, Action-Following, Downstream Task, and Human Preference &ndash; jointly covering visual realism, geometric consistency, physical plausibility, and functional reliability. Across these dimensions, no existing world model excels universally: those with strong textures often violate physics, while geometry-stable ones lack behavioral fidelity. To align objective metrics with human judgment, we further construct WorldLens-26K, a large-scale dataset of human-annotated videos with numerical scores and textual rationales, and develop WorldLens-Agent, an evaluation model distilled from these annotations to enable scalable, explainable scoring. Together, the benchmark, dataset, and agent form a unified ecosystem for measuring world fidelity &ndash; standardizing how future models are judged not only by how real they look, but by how real they behave.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10958v1">üìÑ Download PDF</a></p><hr><h3 id=evidence-of-galaxy-cluster-rotation-in-the-cosmic-microwave-backgroundhttpsarxivorgabs251210951v1><a href=https://arxiv.org/abs/2512.10951v1>Evidence of galaxy cluster rotation in the cosmic microwave background</a><a hidden class=anchor aria-hidden=true href=#evidence-of-galaxy-cluster-rotation-in-the-cosmic-microwave-backgroundhttpsarxivorgabs251210951v1>#</a></h3><p><strong>Authors:</strong> Samuel Goldstein, J. Colin Hill
<strong>Venue:</strong> arXiv (2025)</p><p>We report the first robust evidence for the rotational kinematic Sunyaev-Zel&rsquo;dovich (rkSZ) effect, produced by the Thomson scattering of cosmic microwave background (CMB) photons off rotating intracluster gas. By combining CMB intensity and polarization measurements from the $\it{Planck}$ satellite with spectroscopic member-galaxy redshifts from the Sloan Digital Sky Survey in a sample of 25 X-ray cross-matched, low-redshift ($0.02&lt; z&lt; 0.09)$, massive ($10^{13.9}\lesssim M_{\rm 500c}/M_\odot \lesssim 10^{14.6}$) galaxy clusters, we detect a dipolar rkSZ signature aligned with the estimated rotation direction of each cluster, ruling out a chance fluctuation at 99.98% confidence (3.6$œÉ$). The significance of this measurement is enhanced by several new methodological improvements for isolating the rkSZ signal from primary CMB fluctuations and noise. The amplitude and shape of the signal are qualitatively consistent with predictions from state-of-the-art hydrodynamical simulations. These results establish a new tool with which to probe the dynamical state of galaxy clusters using CMB data.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10951v1">üìÑ Download PDF</a></p><hr><h3 id=babyvlm-v2-toward-developmentally-grounded-pretraining-and-benchmarking-of-vision-foundation-modelshttpsarxivorgabs251210932v1><a href=https://arxiv.org/abs/2512.10932v1>BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models</a><a hidden class=anchor aria-hidden=true href=#babyvlm-v2-toward-developmentally-grounded-pretraining-and-benchmarking-of-vision-foundation-modelshttpsarxivorgabs251210932v1>#</a></h3><p><strong>Authors:</strong> Shengao Wang, Wenqi Wang, Zecheng Wang, Max Whitton, Michael Wakeham, Arjun Chandra, Joey Huang, Pengyue Zhu, Helen Chen, David Li, Jeffrey Li, Shawn Li, Andrew Zagula, Amy Zhao, Andrew Zhu, Sayaka Nakamura, Yuki Yamamoto, Jerry Jun Yokono, Aaron Mueller, Bryan A. Plummer, Kate Saenko, Venkatesh Saligrama, Boqing Gong
<strong>Venue:</strong> arXiv (2025)</p><p>Early children&rsquo;s developmental trajectories set up a natural goal for sample-efficient pretraining of vision foundation models. We introduce BabyVLM-V2, a developmentally grounded framework for infant-inspired vision-language modeling that extensively improves upon BabyVLM-V1 through a longitudinal, multifaceted pretraining set, a versatile model, and, most importantly, DevCV Toolbox for cognitive evaluation. The pretraining set maximizes coverage while minimizing curation of a longitudinal, infant-centric audiovisual corpus, yielding video-utterance, image-utterance, and multi-turn conversational data that mirror infant experiences. DevCV Toolbox adapts all vision-related measures of the recently released NIH Baby Toolbox into a benchmark suite of ten multimodal tasks, covering spatial reasoning, memory, and vocabulary understanding aligned with early children&rsquo;s capabilities. Experimental results show that a compact model pretrained from scratch can achieve competitive performance on DevCV Toolbox, outperforming GPT-4o on some tasks. We hope the principled, unified BabyVLM-V2 framework will accelerate research in developmentally plausible pretraining of vision foundation models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10932v1">üìÑ Download PDF</a></p><hr><h3 id=duetsvg-unified-multimodal-svg-generation-with-internal-visual-guidancehttpsarxivorgabs251210894v1><a href=https://arxiv.org/abs/2512.10894v1>DuetSVG: Unified Multimodal SVG Generation with Internal Visual Guidance</a><a hidden class=anchor aria-hidden=true href=#duetsvg-unified-multimodal-svg-generation-with-internal-visual-guidancehttpsarxivorgabs251210894v1>#</a></h3><p><strong>Authors:</strong> Peiying Zhang, Nanxuan Zhao, Matthew Fisher, Yiran Xu, Jing Liao, Difan Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Recent vision-language model (VLM)-based approaches have achieved impressive results on SVG generation. However, because they generate only text and lack visual signals during decoding, they often struggle with complex semantics and fail to produce visually appealing or geometrically coherent SVGs. We introduce DuetSVG, a unified multimodal model that jointly generates image tokens and corresponding SVG tokens in an end-to-end manner. DuetSVG is trained on both image and SVG datasets. At inference, we apply a novel test-time scaling strategy that leverages the model&rsquo;s native visual predictions as guidance to improve SVG decoding quality. Extensive experiments show that our method outperforms existing methods, producing visually faithful, semantically aligned, and syntactically clean SVGs across a wide range of applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10894v1">üìÑ Download PDF</a></p><hr><h3 id=two-dimensional-projective-collapse-and-sharp-distortion-bounds-for-products-of-positive-matriceshttpsarxivorgabs251210872v1><a href=https://arxiv.org/abs/2512.10872v1>Two-Dimensional Projective Collapse and Sharp Distortion Bounds for Products of Positive Matrices</a><a hidden class=anchor aria-hidden=true href=#two-dimensional-projective-collapse-and-sharp-distortion-bounds-for-products-of-positive-matriceshttpsarxivorgabs251210872v1>#</a></h3><p><strong>Authors:</strong> Eugene Kritchevski
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce an elementary framework that captures the mechanism driving the alignment of rows and columns in products of positive matrices. All worst-case misalignment occurs already in dimension two, leading to an explicit collapse principle and a sharp nonlinear bound for finite products. The proof avoids Hilbert-metric and cone-theoretic techniques, relying instead on basic calculus. In the Hilbert metric, the classical Birkhoff-Bushell contraction captures only the linearized asymptotic regime, whereas our nonlinear envelope function gives the exact worst-case behavior for finite products.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10872v1">üìÑ Download PDF</a></p><hr><h3 id=a-stellar-magnesium-to-silicon-ratio-in-the-atmosphere-of-an-exoplanethttpsarxivorgabs251210904v1><a href=https://arxiv.org/abs/2512.10904v1>A Stellar Magnesium to Silicon ratio in the atmosphere of an exoplanet</a><a hidden class=anchor aria-hidden=true href=#a-stellar-magnesium-to-silicon-ratio-in-the-atmosphere-of-an-exoplanethttpsarxivorgabs251210904v1>#</a></h3><p><strong>Authors:</strong> Jorge A. Sanchez, Peter C. B. Smith, Krishna Kanumalla, Luis Welbanks, Michael R. Line, Stefan Pelletier, Steven Desch, Patrick Young, Jennifer Patience, Jacob Bean, Matteo Brogi, Dan Jaffe, Gregory N. Mace, Megan Weiner Mansfield, Vatsal Panwar, Vivien Parmentier, Lorenzo Pino, Arjun Baliga Savel, Lennart van Sluijs, Joost P. Wardenier
<strong>Venue:</strong> arXiv (2025)</p><p>The elemental compositions of exoplanets encode information about their formation environments and internal structures. While volatile ratios such as carbon-to-oxygen (C/O) are used to trace formation location, the rock-forming elements - magnesium (Mg), silicon (Si), and iron (Fe) - govern interior mineralogy and are commonly assumed to reflect the host star&rsquo;s abundances. Yet this assumption remains largely untested. Ultra-hot Jupiters, gas-giant exoplanets with dayside temperatures above 3000 K, provide rare access to refractory elements that remain gaseous. Here we present high-resolution thermal emission spectroscopy of the exoplanet WASP-189b (Teq = 3354^{+27}_{-34} K) obtained with the Immersion Grating Infrared Spectrometer (IGRINS) on Gemini South. We detect neutral iron (Fe I), magnesium (Mg I), silicon (Si I), water (H_2O), carbon monoxide (CO), and hydroxyl (OH) at signal-to-noise ratios exceeding 4, and retrieve their elemental abundances. We show that the Mg/Si, Fe/Mg, and Si/Fe ratios are consistent with stellar values, while the refractory-to-volatile ratio is enhanced by roughly a factor of ~2. These findings demonstrate that giant-planet atmospheres can preserve stellar-like rock-forming ratios, providing an empirical validation of the stellar-proxy assumption that underpins planetary composition and formation models across exoplanet systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10904v1">üìÑ Download PDF</a></p><hr><h3 id=replace-dont-expand-mitigating-context-dilution-in-multi-hop-rag-via-fixed-budget-evidence-assemblyhttpsarxivorgabs251210787v1><a href=https://arxiv.org/abs/2512.10787v1>Replace, Don&rsquo;t Expand: Mitigating Context Dilution in Multi-Hop RAG via Fixed-Budget Evidence Assembly</a><a hidden class=anchor aria-hidden=true href=#replace-dont-expand-mitigating-context-dilution-in-multi-hop-rag-via-fixed-budget-evidence-assemblyhttpsarxivorgabs251210787v1>#</a></h3><p><strong>Authors:</strong> Moshe Lahmy, Roi Yozevitch
<strong>Venue:</strong> arXiv (2025)</p><p>Retrieval-Augmented Generation (RAG) systems often fail on multi-hop queries when the initial retrieval misses a bridge fact. Prior corrective approaches, such as Self-RAG, CRAG, and Adaptive-$k$, typically address this by \textit{adding} more context or pruning existing lists. However, simply expanding the context window often leads to \textbf{context dilution}, where distractors crowd out relevant information. We propose \textbf{SEAL-RAG}, a training-free controller that adopts a \textbf{``replace, don&rsquo;t expand&rsquo;&rsquo;} strategy to fight context dilution under a fixed retrieval depth $k$. SEAL executes a (\textbf{S}earch $\rightarrow$ \textbf{E}xtract $\rightarrow$ \textbf{A}ssess $\rightarrow$ \textbf{L}oop) cycle: it performs on-the-fly, entity-anchored extraction to build a live \textit{gap specification} (missing entities/relations), triggers targeted micro-queries, and uses \textit{entity-first ranking} to actively swap out distractors for gap-closing evidence. We evaluate SEAL-RAG against faithful re-implementations of Basic RAG, CRAG, Self-RAG, and Adaptive-$k$ in a shared environment on \textbf{HotpotQA} and \textbf{2WikiMultiHopQA}. On HotpotQA ($k=3$), SEAL improves answer correctness by \textbf{+3&ndash;13 pp} and evidence precision by \textbf{+12&ndash;18 pp} over Self-RAG. On 2WikiMultiHopQA ($k=5$), it outperforms Adaptive-$k$ by \textbf{+8.0 pp} in accuracy and maintains \textbf{96%} evidence precision compared to 22% for CRAG. These gains are statistically significant ($p&lt;0.001$). By enforcing fixed-$k$ replacement, SEAL yields a predictable cost profile while ensuring the top-$k$ slots are optimized for precision rather than mere breadth. We release our code and data at <a href=https://github.com/mosherino/SEAL-RAG>https://github.com/mosherino/SEAL-RAG</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10787v1">üìÑ Download PDF</a></p><hr><h3 id=rethinking-popularity-bias-in-collaborative-filtering-via-analytical-vector-decompositionhttpsarxivorgabs251210688v1><a href=https://arxiv.org/abs/2512.10688v1>Rethinking Popularity Bias in Collaborative Filtering via Analytical Vector Decomposition</a><a hidden class=anchor aria-hidden=true href=#rethinking-popularity-bias-in-collaborative-filtering-via-analytical-vector-decompositionhttpsarxivorgabs251210688v1>#</a></h3><p><strong>Authors:</strong> Lingfeng Liu, Yixin Song, Dazhong Shen, Bing Yin, Hao Li, Yanyong Zhang, Chao Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Popularity bias fundamentally undermines the personalization capabilities of collaborative filtering (CF) models, causing them to disproportionately recommend popular items while neglecting users&rsquo; genuine preferences for niche content. While existing approaches treat this as an external confounding factor, we reveal that popularity bias is an intrinsic geometric artifact of Bayesian Pairwise Ranking (BPR) optimization in CF models. Through rigorous mathematical analysis, we prove that BPR systematically organizes item embeddings along a dominant &ldquo;popularity direction&rdquo; where embedding magnitudes directly correlate with interaction frequency. This geometric distortion forces user embeddings to simultaneously handle two conflicting tasks-expressing genuine preference and calibrating against global popularity-trapping them in suboptimal configurations that favor popular items regardless of individual tastes. We propose Directional Decomposition and Correction (DDC), a universally applicable framework that surgically corrects this embedding geometry through asymmetric directional updates. DDC guides positive interactions along personalized preference directions while steering negative interactions away from the global popularity direction, disentangling preference from popularity at the geometric source. Extensive experiments across multiple BPR-based architectures demonstrate that DDC significantly outperforms state-of-the-art debiasing methods, reducing training loss to less than 5% of heavily-tuned baselines while achieving superior recommendation quality and fairness. Code is available in <a href=https://github.com/LingFeng-Liu-AI/DDC>https://github.com/LingFeng-Liu-AI/DDC</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10688v1">üìÑ Download PDF</a></p><hr><h3 id=lang2motion-bridging-language-and-motion-through-joint-embedding-spaceshttpsarxivorgabs251210617v1><a href=https://arxiv.org/abs/2512.10617v1>Lang2Motion: Bridging Language and Motion through Joint Embedding Spaces</a><a hidden class=anchor aria-hidden=true href=#lang2motion-bridging-language-and-motion-through-joint-embedding-spaceshttpsarxivorgabs251210617v1>#</a></h3><p><strong>Authors:</strong> Bishoy Galoaa, Xiangyu Bai, Sarah Ostadabbas
<strong>Venue:</strong> arXiv (2025)</p><p>We present Lang2Motion, a framework for language-guided point trajectory generation by aligning motion manifolds with joint embedding spaces. Unlike prior work focusing on human motion or video synthesis, we generate explicit trajectories for arbitrary objects using motion extracted from real-world videos via point tracking. Our transformer-based auto-encoder learns trajectory representations through dual supervision: textual motion descriptions and rendered trajectory visualizations, both mapped through CLIP&rsquo;s frozen encoders. Lang2Motion achieves 34.2% Recall@1 on text-to-trajectory retrieval, outperforming video-based methods by 12.5 points, and improves motion accuracy by 33-52% (12.4 ADE vs 18.3-25.3) compared to video generation baselines. We demonstrate 88.3% Top-1 accuracy on human action recognition despite training only on diverse object motions, showing effective transfer across motion domains. Lang2Motion supports style transfer, semantic interpolation, and latent-space editing through CLIP-aligned trajectory representations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10617v1">üìÑ Download PDF</a></p><hr><h2 id=-linguistics>üîç linguistics<a hidden class=anchor aria-hidden=true href=#-linguistics>#</a></h2><h3 id=stereospace-depth-free-synthesis-of-stereo-geometry-via-end-to-end-diffusion-in-a-canonical-spacehttpsarxivorgabs251210959v1><a href=https://arxiv.org/abs/2512.10959v1>StereoSpace: Depth-Free Synthesis of Stereo Geometry via End-to-End Diffusion in a Canonical Space</a><a hidden class=anchor aria-hidden=true href=#stereospace-depth-free-synthesis-of-stereo-geometry-via-end-to-end-diffusion-in-a-canonical-spacehttpsarxivorgabs251210959v1>#</a></h3><p><strong>Authors:</strong> Tjark Behrens, Anton Obukhov, Bingxin Ke, Fabio Tosi, Matteo Poggi, Konrad Schindler
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce StereoSpace, a diffusion-based framework for monocular-to-stereo synthesis that models geometry purely through viewpoint conditioning, without explicit depth or warping. A canonical rectified space and the conditioning guide the generator to infer correspondences and fill disocclusions end-to-end. To ensure fair and leakage-free evaluation, we introduce an end-to-end protocol that excludes any ground truth or proxy geometry estimates at test time. The protocol emphasizes metrics reflecting downstream relevance: iSQoE for perceptual comfort and MEt3R for geometric consistency. StereoSpace surpasses other methods from the warp & inpaint, latent-warping, and warped-conditioning categories, achieving sharp parallax and strong robustness on layered and non-Lambertian scenes. This establishes viewpoint-conditioned diffusion as a scalable, depth-free solution for stereo generation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10959v1">üìÑ Download PDF</a></p><hr><h3 id=scenemaker-open-set-3d-scene-generation-with-decoupled-de-occlusion-and-pose-estimation-modelhttpsarxivorgabs251210957v1><a href=https://arxiv.org/abs/2512.10957v1>SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model</a><a hidden class=anchor aria-hidden=true href=#scenemaker-open-set-3d-scene-generation-with-decoupled-de-occlusion-and-pose-estimation-modelhttpsarxivorgabs251210957v1>#</a></h3><p><strong>Authors:</strong> Yukai Shi, Weiyu Li, Zihao Wang, Hongyang Li, Xingyu Chen, Ping Tan, Lei Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>We propose a decoupled 3D scene generation framework called SceneMaker in this work. Due to the lack of sufficient open-set de-occlusion and pose estimation priors, existing methods struggle to simultaneously produce high-quality geometry and accurate poses under severe occlusion and open-set settings. To address these issues, we first decouple the de-occlusion model from 3D object generation, and enhance it by leveraging image datasets and collected de-occlusion datasets for much more diverse open-set occlusion patterns. Then, we propose a unified pose estimation model that integrates global and local mechanisms for both self-attention and cross-attention to improve accuracy. Besides, we construct an open-set 3D scene dataset to further extend the generalization of the pose estimation model. Comprehensive experiments demonstrate the superiority of our decoupled framework on both indoor and open-set scenes. Our codes and datasets is released at <a href=https://idea-research.github.io/SceneMaker/>https://idea-research.github.io/SceneMaker/</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10957v1">üìÑ Download PDF</a></p><hr><h3 id=bidirectional-normalizing-flow-from-data-to-noise-and-backhttpsarxivorgabs251210953v1><a href=https://arxiv.org/abs/2512.10953v1>Bidirectional Normalizing Flow: From Data to Noise and Back</a><a hidden class=anchor aria-hidden=true href=#bidirectional-normalizing-flow-from-data-to-noise-and-backhttpsarxivorgabs251210953v1>#</a></h3><p><strong>Authors:</strong> Yiyang Lu, Qiao Sun, Xianbang Wang, Zhicheng Jiang, Hanhong Zhao, Kaiming He
<strong>Venue:</strong> arXiv (2025)</p><p>Normalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations are constrained by explicit invertibility, ensuring that the reverse process can serve as their exact analytic inverse. Recent developments in TARFlow and its variants have revitalized NF methods by combining Transformers and autoregressive flows, but have also exposed causal decoding as a major bottleneck. In this work, we introduce Bidirectional Normalizing Flow ($\textbf{BiFlow}$), a framework that removes the need for an exact analytic inverse. BiFlow learns a reverse model that approximates the underlying noise-to-data inverse mapping, enabling more flexible loss functions and architectures. Experiments on ImageNet demonstrate that BiFlow, compared to its causal decoding counterpart, improves generation quality while accelerating sampling by up to two orders of magnitude. BiFlow yields state-of-the-art results among NF-based methods and competitive performance among single-evaluation (&ldquo;1-NFE&rdquo;) methods. Following recent encouraging progress on NFs, we hope our work will draw further attention to this classical paradigm.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10953v1">üìÑ Download PDF</a></p><hr><h3 id=clusir-towards-cluster-guided-all-in-one-image-restorationhttpsarxivorgabs251210948v1><a href=https://arxiv.org/abs/2512.10948v1>ClusIR: Towards Cluster-Guided All-in-One Image Restoration</a><a hidden class=anchor aria-hidden=true href=#clusir-towards-cluster-guided-all-in-one-image-restorationhttpsarxivorgabs251210948v1>#</a></h3><p><strong>Authors:</strong> Shengkai Hu, Jiaqi Ma, Jun Wan, Wenwen Min, Yongcheng Jing, Lefei Zhang, Dacheng Tao
<strong>Venue:</strong> arXiv (2025)</p><p>All-in-One Image Restoration (AiOIR) aims to recover high-quality images from diverse degradations within a unified framework. However, existing methods often fail to explicitly model degradation types and struggle to adapt their restoration behavior to complex or mixed degradations. To address these issues, we propose ClusIR, a Cluster-Guided Image Restoration framework that explicitly models degradation semantics through learnable clustering and propagates cluster-aware cues across spatial and frequency domains for adaptive restoration. Specifically, ClusIR comprises two key components: a Probabilistic Cluster-Guided Routing Mechanism (PCGRM) and a Degradation-Aware Frequency Modulation Module (DAFMM). The proposed PCGRM disentangles degradation recognition from expert activation, enabling discriminative degradation perception and stable expert routing. Meanwhile, DAFMM leverages the cluster-guided priors to perform adaptive frequency decomposition and targeted modulation, collaboratively refining structural and textural representations for higher restoration fidelity. The cluster-guided synergy seamlessly bridges semantic cues with frequency-domain modulation, empowering ClusIR to attain remarkable restoration results across a wide range of degradations. Extensive experiments on diverse benchmarks validate that ClusIR reaches competitive performance under several scenarios.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10948v1">üìÑ Download PDF</a></p><hr><h3 id=implicitrdp-an-end-to-end-visual-force-diffusion-policy-with-structural-slow-fast-learninghttpsarxivorgabs251210946v1><a href=https://arxiv.org/abs/2512.10946v1>ImplicitRDP: An End-to-End Visual-Force Diffusion Policy with Structural Slow-Fast Learning</a><a hidden class=anchor aria-hidden=true href=#implicitrdp-an-end-to-end-visual-force-diffusion-policy-with-structural-slow-fast-learninghttpsarxivorgabs251210946v1>#</a></h3><p><strong>Authors:</strong> Wendi Chen, Han Xue, Yi Wang, Fangyuan Zhou, Jun Lv, Yang Jin, Shirun Tang, Chuan Wen, Cewu Lu
<strong>Venue:</strong> arXiv (2025)</p><p>Human-level contact-rich manipulation relies on the distinct roles of two key modalities: vision provides spatially rich but temporally slow global context, while force sensing captures rapid, high-frequency local contact dynamics. Integrating these signals is challenging due to their fundamental frequency and informational disparities. In this work, we propose ImplicitRDP, a unified end-to-end visual-force diffusion policy that integrates visual planning and reactive force control within a single network. We introduce Structural Slow-Fast Learning, a mechanism utilizing causal attention to simultaneously process asynchronous visual and force tokens, allowing the policy to perform closed-loop adjustments at the force frequency while maintaining the temporal coherence of action chunks. Furthermore, to mitigate modality collapse where end-to-end models fail to adjust the weights across different modalities, we propose Virtual-target-based Representation Regularization. This auxiliary objective maps force feedback into the same space as the action, providing a stronger, physics-grounded learning signal than raw force prediction. Extensive experiments on contact-rich tasks demonstrate that ImplicitRDP significantly outperforms both vision-only and hierarchical baselines, achieving superior reactivity and success rates with a streamlined training pipeline. Code and videos will be publicly available at <a href=https://implicit-rdp.github.io>https://implicit-rdp.github.io</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10946v1">üìÑ Download PDF</a></p><hr><h3 id=noisy-quantum-learning-theoryhttpsarxivorgabs251210929v1><a href=https://arxiv.org/abs/2512.10929v1>Noisy Quantum Learning Theory</a><a hidden class=anchor aria-hidden=true href=#noisy-quantum-learning-theoryhttpsarxivorgabs251210929v1>#</a></h3><p><strong>Authors:</strong> Jordan Cotler, Weiyuan Gong, Ishaan Kannan
<strong>Venue:</strong> arXiv (2025)</p><p>We develop a framework for learning from noisy quantum experiments, focusing on fault-tolerant devices accessing uncharacterized systems through noisy couplings. Our starting point is the complexity class $\textsf{NBQP}$ (&ldquo;noisy BQP&rdquo;), modeling noisy fault-tolerant quantum computers that cannot, in general, error-correct the oracle systems they query. Using this class, we show that for natural oracle problems, noise can eliminate exponential quantum learning advantages of ideal noiseless learners while preserving a superpolynomial gap between NISQ and fault-tolerant devices. Beyond oracle separations, we study concrete noisy learning tasks. For purity testing, the exponential two-copy advantage collapses under a single application of local depolarizing noise. Nevertheless, we identify a setting motivated by AdS/CFT in which noise-resilient structure restores a quantum learning advantage in a noisy regime. We then analyze noisy Pauli shadow tomography, deriving lower bounds that characterize how instance size, quantum memory, and noise control sample complexity, and design algorithms with parametrically similar scalings. Together, our results show that the Bell-basis and SWAP-test primitives underlying most exponential quantum learning advantages are fundamentally fragile to noise unless the experimental system has latent noise-robust structure. Thus, realizing meaningful quantum advantages in future experiments will require understanding how noise-robust physical properties interface with available algorithmic techniques.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10929v1">üìÑ Download PDF</a></p><hr><h3 id=free-plane-curves-with-a-linear-jacobian-syzygyhttpsarxivorgabs251210928v1><a href=https://arxiv.org/abs/2512.10928v1>Free plane curves with a linear Jacobian syzygy</a><a hidden class=anchor aria-hidden=true href=#free-plane-curves-with-a-linear-jacobian-syzygyhttpsarxivorgabs251210928v1>#</a></h3><p><strong>Authors:</strong> Valentina Beorchia, Matteo Gallet, Alessandro Logar
<strong>Venue:</strong> arXiv (2025)</p><p>The study of planar free curves is a very active area of research, but a structural study of such a class is missing. We give a complete classification of the possible generators of the Jacobian syzygy module of a plane free curve under the assumption that one of them is linear. Specifically, we prove that, up to similarities, there are two possible forms for the Hilbert-Burch matrix. Our strategy relies on a translation of the problem into the accurate study of the geometry of maximal segments of a suitable triangle with integer points. Following this description, we are able to determine precisely the equations of free curves and the associated Hilbert-Burch matrices.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10928v1">üìÑ Download PDF</a></p><hr><h3 id=structural-physical-and-judd-ofelt-analysis-of-germanium-magnesium-telluroborate-glass-containing-different-amounts-of-tm2o3httpsarxivorgabs251210920v1><a href=https://arxiv.org/abs/2512.10920v1>Structural, physical, and Judd-Ofelt analysis of germanium magnesium-telluroborate glass containing different amounts of Tm2O3</a><a hidden class=anchor aria-hidden=true href=#structural-physical-and-judd-ofelt-analysis-of-germanium-magnesium-telluroborate-glass-containing-different-amounts-of-tm2o3httpsarxivorgabs251210920v1>#</a></h3><p><strong>Authors:</strong> A. A. El-Maaref, Kh. S. Shaaban, E. A. Abdel Wahab
<strong>Venue:</strong> arXiv (2025)</p><p>Germanium magnesium-telluroborate glasses with the composition 78B2O3-10GeO2-5TeO2-7-x MgO-xTm2O3, x = 0, 0.25, 0.5, 1, and 1.5 mol% were fabricated by using the melt quenching process. With the increase of Tm2O3 concentration, the density values increase from 3.574 to 4.153 g.cm-1, while the molar volume values decrease from 21.145 to 19.445 cm3/mol. Fourier transform infrared analysis supports the existence and conversion of BO3 and BO4. The conversion of BO3 to BO4 would lead to greater bridging oxygens BOs, influencing and reinforcing the glass network. The optical features were studied. The optical band gap decreased by increasing Tm2O3 content in the glass formula, while the index of refraction increased. The parameters take the values between 3.16 eV and 2.31 eV. Other optical and physical constants were determined like optical conductivity, electronegativity, metallization, reflection loss, steepness parameters, and transmission coefficient. Judd-Ofelt theory is used to estimate the optical intensities and line strengths of the present glasses. Radiative lifetimes and branching ratios are evaluated of different manifolds belonging to Tm3+ doped present glasses. The results showed the possibility of potential applications for these materials in the fields of laser development, Light-emitting diodes (LEDs), optical amplification and optoelectronic devices.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10920v1">üìÑ Download PDF</a></p><hr><h3 id=the-lisa-astrophysics-disc-imri-code-comparison-project-intermediate-mass-ratio-binaries-in-agn-like-discshttpsarxivorgabs251210893v1><a href=https://arxiv.org/abs/2512.10893v1>The LISA Astrophysics &ldquo;Disc-IMRI&rdquo; Code Comparison Project: Intermediate-Mass-Ratio Binaries in AGN-Like Discs</a><a hidden class=anchor aria-hidden=true href=#the-lisa-astrophysics-disc-imri-code-comparison-project-intermediate-mass-ratio-binaries-in-agn-like-discshttpsarxivorgabs251210893v1>#</a></h3><p><strong>Authors:</strong> Andrea Derdzinski, Alexander J. Dittmann, Alessia Franchini, Alessandro Lupi, No√© Brucy, Pedro R. Capelo, Fr√©d√©ric S. Masset, Rapha√´l Mignon-Risse, Michael Rizzo Smith, Edwin Santiago-Leandro, Martina Toscani, David A. Velasco-Romero, Robert Wissing, Mudit Garg, Lucio Mayer, Roberto Serafinelli, Lazaros Souvaitzis, Daniel J. D&rsquo;Orazio, Jonathan Menu
<strong>Venue:</strong> arXiv (2025)</p><p>Upcoming space-based gravitational wave detectors such as LISA, the Laser Interferometer Space Antenna, will be sensitive to extreme- and intermediate-mass-ratio inspirals (EMRIs and IMRIs). These binaries are comprised of a supermassive black hole and a stellar-mass object or intermediate-mass black hole. Their detection will probe the structure of galactic nuclei and enable tests of general relativity. As these events will be observed over thousands of orbital cycles, they will be extremely sensitive to both the underlying spacetime and astrophysical environment, demanding exquisite theoretical models on both fronts to avoid biased or even erroneous results. In particular, many (E/)IMRIs are expected to occur within accretion discs around supermassive black holes, and the nonlinearities present when modeling these systems require numerical simulations. In preparation for future modeling of LISA sources, we have conducted a comparison between eight different hydrodynamical codes and applied them to the problem of a q = 10^{-4} mass ratio binary interacting with an accretion disc. Thicker discs appear more lenient, and all codes at sufficiently high resolutions are in good agreement with each other and analytical predictions. For thinner discs, beyond the reach of analytical models, we find substantial disagreement between 2D and 3D simulations and between different codes, including both the magnitude and sign of the torque. With time and energy efficiency in mind, codes that leverage moving meshes or grid-based Lagrangian remapping seem preferable, as do codes that can leverage graphical processing units and other energy-efficient hardware.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10893v1">üìÑ Download PDF</a></p><hr><h3 id=inflation-in-light-of-actspt-a-new-perspective-from-weyl-gravityhttpsarxivorgabs251210862v1><a href=https://arxiv.org/abs/2512.10862v1>Inflation in light of ACT/SPT: a new perspective from Weyl gravity</a><a hidden class=anchor aria-hidden=true href=#inflation-in-light-of-actspt-a-new-perspective-from-weyl-gravityhttpsarxivorgabs251210862v1>#</a></h3><p><strong>Authors:</strong> Qing-Yang Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Recent measurements from the Atacama Cosmology Telescope (ACT) and the South Pole Telescope (SPT) have placed the strictest constraints on the primordial scalar perturbation spectrum, reporting a spectral index of $n_s\sim0.967-0.98$ at 95% confidence level. This result indicates a stronger scale invariance of the scalar perturbation than earlier estimates, posing challenges for numerous inflation models. In this work, we propose an appealing inflationary scenario from the Weyl scale-invariant gravity theory dominated by the higher-order curvatures. Specifically, the exponential curvature extensions are introduced to suppress the mass divergence of the inflaton. We find such scenario naturally yields leading-order predictions of $n_s\simeq1-3/(2N)\sim0.97-0.975$ or $n_s\simeq1-5/(3N)\sim0.967-0.972$ for various models, in excellent agreement with the ACT/SPT constraints. This result builds a concrete bridge between theoretical and observational scale invariance, implying an enduring cosmic echo of the primordial symmetry.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10862v1">üìÑ Download PDF</a></p><hr><h3 id=modeling-segmenting-and-statistics-of-transient-spindles-via-two-dimensional-ornstein-uhlenbeck-dynamicshttpsarxivorgabs251210844v1><a href=https://arxiv.org/abs/2512.10844v1>Modeling, Segmenting and Statistics of Transient Spindles via Two-Dimensional Ornstein-Uhlenbeck Dynamics</a><a hidden class=anchor aria-hidden=true href=#modeling-segmenting-and-statistics-of-transient-spindles-via-two-dimensional-ornstein-uhlenbeck-dynamicshttpsarxivorgabs251210844v1>#</a></h3><p><strong>Authors:</strong> C. Sun, D. Fettahoglu, D. Holcman
<strong>Venue:</strong> arXiv (2025)</p><p>We develop here a stochastic framework for modeling and segmenting transient spindle-like oscillatory bursts in electroencephalogram (EEG) signals. At the modeling level, individual spindles are represented as path realizations of a two-dimensional Ornstein{Uhlenbeck (OU) process with a stable focus, providing a low-dimensional stochastic dynamical system whose trajectories reproduce key morphological features of spindles, including their characteristic rise{decay amplitude envelopes. On the signal processing side, we propose a segmentation procedure based on Empirical Mode Decomposition (EMD) combined with the detection of a central extremum, which isolates single spindle events and yields a collection of oscillatory atoms. This construction enables a systematic statistical analysis of spindle features: we derive empirical laws for the distributions of amplitudes, inter-spindle intervals, and rise/decay durations, and show that these exhibit exponential tails consistent with the underlying OU dynamics. We further extend the model to a pair of weakly coupled OU processes with distinct natural frequencies, generating a stochastic mixture of slow, fast, and mixed spindles in random temporal order. The resulting framework provides a data-driven framework for the analysis of transient oscillations in EEG and, more generally, in nonstationary time series.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10844v1">üìÑ Download PDF</a></p><hr><h3 id=data-driven-pressure-recovery-in-diffusershttpsarxivorgabs251210801v1><a href=https://arxiv.org/abs/2512.10801v1>Data-driven Pressure Recovery in Diffusers</a><a hidden class=anchor aria-hidden=true href=#data-driven-pressure-recovery-in-diffusershttpsarxivorgabs251210801v1>#</a></h3><p><strong>Authors:</strong> Juan Augusto Paredes Salazar, Ankit Goel, Rowen Costich, Meliksah Koca, Ozgur Tumuklu, Michael Amitay
<strong>Venue:</strong> arXiv (2025)</p><p>This paper investigates the application of a data-driven technique based on retrospective cost optimization to optimize the frequency of mass injection into an S-shaped diffuser, with the objective of maximizing the pressure recovery. Experimental data indicated that there is an optimal injection frequency between 100 Hz and 300 Hz with a mass flow rate of 1 percent of the free stream. High-fidelity numerical simulations using compressible unsteady Reynolds-Averaged Navier-Stokes (URANS) are conducted to investigate the mean and temporal features resulting from mass injection into an S-shaped diffuser with differing injection speeds and pulse frequencies. The results are compared with experiments to confirm the accuracy of the numerical solution. Overall, 2-D simulations are relatively in good agreement with the experiment, with 3-D simulations currently under investigation to benchmark the effect of spanwise instabilities. Simulation results with the proposed data-driven technique show improvements upon a baseline case by increasing pressure recovery and reducing the region of flow recirculation within the diffuser.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10801v1">üìÑ Download PDF</a></p><hr><h3 id=modeling-light-signals-using-data-from-the-first-pulsed-neutron-source-program-at-the-dune-vertical-drift-coldbox-test-facility-at-cern-neutrino-platformhttpsarxivorgabs251210790v1><a href=https://arxiv.org/abs/2512.10790v1>Modeling Light Signals Using Data from the First Pulsed Neutron Source Program at the DUNE Vertical Drift ColdBox Test Facility at CERN Neutrino Platform</a><a hidden class=anchor aria-hidden=true href=#modeling-light-signals-using-data-from-the-first-pulsed-neutron-source-program-at-the-dune-vertical-drift-coldbox-test-facility-at-cern-neutrino-platformhttpsarxivorgabs251210790v1>#</a></h3><p><strong>Authors:</strong> A. Paudel, W. Shi, P. Sala, F. Cavanna, W. Johnson, J. Wang, W. Ketchum, F. Resnati, A. Heindel, A. Ashkenazi, E. Bertholet, E. Bertolini, D. A. Martinez Caicedo, E. Calvo, A. Canto, S. Manthey Corchado, C. Cuesta, Z. Djurcic, M. Fani, A. Feld, S. Fogarty, F. Galizzi, S. Gollapinni, Y. Kerma√Ødic, A. Kish, F. Marinho, D. Torres Mu√±oz, A. Verdugo de Osa, L. Paulucci, W. Pellico, V. Popov, J. Rodriguez Rondon, D. Leon Silverio, S. Sacerdoti, H. Souza, R. C Svoboda, D. Totani, V. Trabattoni, L. Zambelli
<strong>Venue:</strong> arXiv (2025)</p><p>In this paper, we present a first quantitative test of detected light signals produced in a pulsed neutron source run in a small vertical drift LArTPC at the CERN neutrino platform ColdBox test facility. The ColdBox cryostat, detectors, neutron sources, and particle interactions are modeled and simulated using Fluka. A good agreement is found in the detected number of photoelectrons, with values below 650 photoelectrons in both data and simulation, for all four X-ARAPUCA photodetectors on the cathode in the LArTPC. A time constant is also fitted from the neutron-beam-off light signal spectrum and found consistent between data and MC. Several important systematic effects are discussed and serve as guides for future runs at larger LArTPCs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10790v1">üìÑ Download PDF</a></p><hr><h3 id=theoretical-and-experimental-development-of-a-high-conversion-efficiency-rectifier-at-x-bandhttpsarxivorgabs251210774v1><a href=https://arxiv.org/abs/2512.10774v1>Theoretical and experimental development of a high-conversion-efficiency rectifier at X-band</a><a hidden class=anchor aria-hidden=true href=#theoretical-and-experimental-development-of-a-high-conversion-efficiency-rectifier-at-x-bandhttpsarxivorgabs251210774v1>#</a></h3><p><strong>Authors:</strong> Feifei Tan, Changjun Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Voltage doubler rectifiers are usually applied to systems with high voltage and low current requirement. An X band voltage doubler rectifier has been developed with 72% conversion efficiency. To the best of our knowledge, the obtained rectifying efficiency is the maximum reported to date at X band with Schottky diodes. The working characteristics of the diodes in the voltage doubler rectifier are analyzed in detail. Closed-form equations of diode input impedance and rectifying efficiency are presented and validated using Advanced Design System simulations. The matching network design of the proposed rectifier is based on the closed-form equations. The preliminary rectifying efficiency is predicted by the closed-form equations as well. Measured and simulated results are in good agreement.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10774v1">üìÑ Download PDF</a></p><hr><h3 id=group-diffusion-enhancing-image-generation-by-unlocking-cross-sample-collaborationhttpsarxivorgabs251210954v1><a href=https://arxiv.org/abs/2512.10954v1>Group Diffusion: Enhancing Image Generation by Unlocking Cross-Sample Collaboration</a><a hidden class=anchor aria-hidden=true href=#group-diffusion-enhancing-image-generation-by-unlocking-cross-sample-collaborationhttpsarxivorgabs251210954v1>#</a></h3><p><strong>Authors:</strong> Sicheng Mo, Thao Nguyen, Richard Zhang, Nick Kolkin, Siddharth Srinivasan Iyer, Eli Shechtman, Krishna Kumar Singh, Yong Jae Lee, Bolei Zhou, Yuheng Li
<strong>Venue:</strong> arXiv (2025)</p><p>In this work, we explore an untapped signal in diffusion model inference. While all previous methods generate images independently at inference, we instead ask if samples can be generated collaboratively. We propose Group Diffusion, unlocking the attention mechanism to be shared across images, rather than limited to just the patches within an image. This enables images to be jointly denoised at inference time, learning both intra and inter-image correspondence. We observe a clear scaling effect - larger group sizes yield stronger cross-sample attention and better generation quality. Furthermore, we introduce a qualitative measure to capture this behavior and show that its strength closely correlates with FID. Built on standard diffusion transformers, our GroupDiff achieves up to 32.2% FID improvement on ImageNet-256x256. Our work reveals cross-sample inference as an effective, previously unexplored mechanism for generative modeling.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10954v1">üìÑ Download PDF</a></p><hr><h3 id=foundationmotion-auto-labeling-and-reasoning-about-spatial-movement-in-videoshttpsarxivorgabs251210927v1><a href=https://arxiv.org/abs/2512.10927v1>FoundationMotion: Auto-Labeling and Reasoning about Spatial Movement in Videos</a><a hidden class=anchor aria-hidden=true href=#foundationmotion-auto-labeling-and-reasoning-about-spatial-movement-in-videoshttpsarxivorgabs251210927v1>#</a></h3><p><strong>Authors:</strong> Yulu Gan, Ligeng Zhu, Dandan Shan, Baifeng Shi, Hongxu Yin, Boris Ivanovic, Song Han, Trevor Darrell, Jitendra Malik, Marco Pavone, Boyi Li
<strong>Venue:</strong> arXiv (2025)</p><p>Motion understanding is fundamental to physical reasoning, enabling models to infer dynamics and predict future states. However, state-of-the-art models still struggle on recent motion benchmarks, primarily due to the scarcity of large-scale, fine-grained motion datasets. Existing motion datasets are often constructed from costly manual annotation, severely limiting scalability. To address this challenge, we introduce FoundationMotion, a fully automated data curation pipeline that constructs large-scale motion datasets. Our approach first detects and tracks objects in videos to extract their trajectories, then leverages these trajectories and video frames with Large Language Models (LLMs) to generate fine-grained captions and diverse question-answer pairs about motion and spatial reasoning. Using datasets produced by this pipeline, we fine-tune open-source models including NVILA-Video-15B and Qwen2.5-7B, achieving substantial improvements in motion understanding without compromising performance on other tasks. Notably, our models outperform strong closed-source baselines like Gemini-2.5 Flash and large open-source models such as Qwen2.5-VL-72B across diverse motion understanding datasets and benchmarks. FoundationMotion thus provides a scalable solution for curating fine-grained motion datasets that enable effective fine-tuning of diverse models to enhance motion understanding and spatial reasoning capabilities.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10927v1">üìÑ Download PDF</a></p><hr><h3 id=echoes-of-automation-how-bots-shaped-political-discourse-in-brazilhttpsarxivorgabs251210749v1><a href=https://arxiv.org/abs/2512.10749v1>Echoes of Automation: How Bots Shaped Political Discourse in Brazil</a><a hidden class=anchor aria-hidden=true href=#echoes-of-automation-how-bots-shaped-political-discourse-in-brazilhttpsarxivorgabs251210749v1>#</a></h3><p><strong>Authors:</strong> Merve Ipek Bal, Diogo Pacheco
<strong>Venue:</strong> arXiv (2025)</p><p>In an era where social media platforms are central to political communication, the activity of bots raises pressing concerns about amplification, manipulation, and misinformation. Drawing on more than 315 million tweets posted from August 2018 to June 2022, we examine behavioural patterns, sentiment dynamics, and the thematic focus of bot- versus human-generated content spanning the 2018 Brazilian presidential election and the lead-up to the 2022 contest. Our analysis shows that bots relied disproportionately on retweets and replies, with reply activity spiking after the 2018 election, suggesting tactics of conversational infiltration and amplification. Sentiment analysis indicates that bots maintained a narrower emotional tone, in contrast to humans, whose sentiment fluctuated more strongly with political events. Topic modelling further reveals bots&rsquo; repetitive, Bolsonaro-centric messaging, while human users engaged with a broader range of candidates, civic concerns, and personal reflections. These findings underscore bots&rsquo; role as amplifiers of narrow agendas and their potential to distort online political discourse.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10749v1">üìÑ Download PDF</a></p><hr><h3 id=intrinsically-correct-algorithms-and-recursive-coalgebrashttpsarxivorgabs251210748v1><a href=https://arxiv.org/abs/2512.10748v1>Intrinsically Correct Algorithms and Recursive Coalgebras</a><a hidden class=anchor aria-hidden=true href=#intrinsically-correct-algorithms-and-recursive-coalgebrashttpsarxivorgabs251210748v1>#</a></h3><p><strong>Authors:</strong> Cass Alexandru, Henning Urbat, Thorsten Wi√ümann
<strong>Venue:</strong> arXiv (2025)</p><p>Recursive coalgebras provide an elegant categorical tool for modelling recursive algorithms and analysing their termination and correctness. By considering coalgebras over categories of suitably indexed families, the correctness of the corresponding algorithms follows intrinsically just from the type of the computed maps. However, proving recursivity of the underlying coalgebras is non-trivial, and proofs are typically ad hoc. This layer of complexity impedes the formalization of coalgebraically defined recursive algorithms in proof assistants. We introduce a framework for constructing coalgebras which are intrinsically recursive in the sense that the type of the coalgebra guarantees recursivity from the outset. Our approach is based on the novel concept of a well-founded functor on a category of families indexed by a well-founded relation. We show as our main result that every coalgebra for a well-founded functor is recursive, and demonstrate that well-known techniques for proving recursivity and termination such as ranking functions are subsumed by this abstract setup. We present a number of case studies, including Quicksort, the Euclidian algorithm, and CYK parsing. Both the main theoretical result and selected case studies have been formalized in Cubical Agda.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10748v1">üìÑ Download PDF</a></p><hr><h3 id=kicking-politics-how-football-fan-communities-became-arenas-for-political-influencehttpsarxivorgabs251210737v1><a href=https://arxiv.org/abs/2512.10737v1>Kicking Politics: How Football Fan Communities Became Arenas for Political Influence</a><a hidden class=anchor aria-hidden=true href=#kicking-politics-how-football-fan-communities-became-arenas-for-political-influencehttpsarxivorgabs251210737v1>#</a></h3><p><strong>Authors:</strong> Helen Paffard, Diogo Pacheco
<strong>Venue:</strong> arXiv (2025)</p><p>This paper investigates how political campaigns engaged UK football fan communities on Twitter in the aftermath of the Brexit Referendum (2016-2017). Football fandom, with its strong collective identities and tribal behaviours, offers fertile ground for political influence. Combining social network and content analysis, we examine how political discourse became embedded in football conversations. We show that a wide range of actors &ndash; including parties, media, activist groups, and pseudonymous influencers &ndash; mobilised support, provoked reactions, and shaped opinion within these communities. Through case studies of hashtag hijacking, embedded activism, and political &ldquo;megaphones&rdquo;, we illustrate how campaigns leveraged fan cultures to amplify political messages. Our findings highlight mechanisms of political influence in ostensibly non-political online spaces and point toward the development of a broader framework in future work.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10737v1">üìÑ Download PDF</a></p><hr><h3 id=the-physics-of-sustainability-material-and-power-constraints-for-the-long-termhttpsarxivorgabs251210680v1><a href=https://arxiv.org/abs/2512.10680v1>The Physics of Sustainability: Material and Power Constraints for the Long Term</a><a hidden class=anchor aria-hidden=true href=#the-physics-of-sustainability-material-and-power-constraints-for-the-long-termhttpsarxivorgabs251210680v1>#</a></h3><p><strong>Authors:</strong> Jos√© Halloy, Petros Chatzimpiros, Fran√ßois Graner, Thomas Gregor
<strong>Venue:</strong> arXiv (2025)</p><p>Much of today&rsquo;s sustainability discourse emphasizes efficiency, clean technologies, and smart systems, but largely underestimates fundamental physical constraints relating to energy-matter interactions. These constraints stem from the fact that Earth is a materially closed yet energetically open system, driven by the sustained but low power-density flux of solar radiation. This Perspective reframes sustainability within these axiomatic limits, integrating relevant timescales and orders of magnitude. We argue that fossil-fueled industrial metabolism is inherently incompatible with long-term viability, while post-fossil systems are surface-, materials-, and power-intensive. Long-term sustainability must therefore be defined not only by how much energy or material is used, but also by how it is used: favoring organic, carbon-based chemistry with limited reliance on purified metals, operating at low power density, and maintaining low throughput rates. Achieving this requires radical technological shifts toward life-compatible systems and biogeochemical circular processes, and, likely as a consequence, a paradigm change toward degrowth to a steady-state. These two shifts are mutually reinforcing and together provide the necessary foundation for any viable future.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10680v1">üìÑ Download PDF</a></p><hr><h3 id=docr-inspector-fine-grained-and-automated-evaluation-of-document-parsing-with-vlmhttpsarxivorgabs251210619v1><a href=https://arxiv.org/abs/2512.10619v1>DOCR-Inspector: Fine-Grained and Automated Evaluation of Document Parsing with VLM</a><a hidden class=anchor aria-hidden=true href=#docr-inspector-fine-grained-and-automated-evaluation-of-document-parsing-with-vlmhttpsarxivorgabs251210619v1>#</a></h3><p><strong>Authors:</strong> Qintong Zhang, Junyuan Zhang, Zhifei Ren, Linke Ouyang, Zichen Wen, Junbo Niu, Yuan Qu, Bin Wang, Ka-Ho Chow, Conghui He, Wentao Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>Document parsing aims to transform unstructured PDF images into semi-structured data, facilitating the digitization and utilization of information in diverse domains. While vision language models (VLMs) have significantly advanced this task, achieving reliable, high-quality parsing in real-world scenarios remains challenging. Common practice often selects the top-performing model on standard benchmarks. However, these benchmarks may carry dataset-specific biases, leading to inconsistent model rankings and limited correlation with real-world performance. Moreover, benchmark metrics typically provide only overall scores, which can obscure distinct error patterns in output. This raises a key challenge: how can we reliably and comprehensively assess document parsing quality in the wild? We address this problem with DOCR-Inspector, which formalizes document parsing assessment as fine-grained error detection and analysis. Leveraging VLM-as-a-Judge, DOCR-Inspector analyzes a document image and its parsed output, identifies all errors, assigns them to one of 28 predefined types, and produces a comprehensive quality assessment. To enable this capability, we construct DOCRcase-200K for training and propose the Chain-of-Checklist reasoning paradigm to enable the hierarchical structure of parsing quality assessment. For empirical validation, we introduce DOCRcaseBench, a set of 882 real-world document parsing cases with manual annotations. On this benchmark, DOCR-Inspector-7B outperforms commercial models like Gemini 2.5 Pro, as well as leading open-source models. Further experiments demonstrate that its quality assessments provide valuable guidance for parsing results refinement, making DOCR-Inspector both a practical evaluator and a driver for advancing document parsing systems at scale. Model and code are released at: <a href=https://github.com/ZZZZZQT/DOCR-Inspector>https://github.com/ZZZZZQT/DOCR-Inspector</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10619v1">üìÑ Download PDF</a></p><hr><h3 id=modeling-narrative-archetypes-in-conspiratorial-narratives-insights-from-singapore-based-telegram-groupshttpsarxivorgabs251210105v1><a href=https://arxiv.org/abs/2512.10105v1>Modeling Narrative Archetypes in Conspiratorial Narratives: Insights from Singapore-Based Telegram Groups</a><a hidden class=anchor aria-hidden=true href=#modeling-narrative-archetypes-in-conspiratorial-narratives-insights-from-singapore-based-telegram-groupshttpsarxivorgabs251210105v1>#</a></h3><p><strong>Authors:</strong> Soorya Ram Shimgekar, Abhay Goyal, Lam Yin Cheung, Roy Ka-Wei Lee, Koustuv Saha, Pi Zonooz, Navin Kumar
<strong>Venue:</strong> arXiv (2025)</p><p>Conspiratorial discourse is increasingly embedded within digital communication ecosystems, yet its structure and spread remain difficult to study. This work analyzes conspiratorial narratives in Singapore-based Telegram groups, showing that such content is woven into everyday discussions rather than confined to isolated echo chambers. We propose a two-stage computational framework. First, we fine-tune RoBERTa-large to classify messages as conspiratorial or not, achieving an F1-score of 0.866 on 2,000 expert-labeled messages. Second, we build a signed belief graph in which nodes represent messages and edge signs reflect alignment in belief labels, weighted by textual similarity. We introduce a Signed Belief Graph Neural Network (SiBeGNN) that uses a Sign Disentanglement Loss to learn embeddings that separate ideological alignment from stylistic features.
Using hierarchical clustering on these embeddings, we identify seven narrative archetypes across 553,648 messages: legal topics, medical concerns, media discussions, finance, contradictions in authority, group moderation, and general chat. SiBeGNN yields stronger clustering quality (cDBI = 8.38) than baseline methods (13.60 to 67.27), supported by 88 percent inter-rater agreement in expert evaluations. Our analysis shows that conspiratorial messages appear not only in clusters focused on skepticism or distrust, but also within routine discussions of finance, law, and everyday matters. These findings challenge common assumptions about online radicalization by demonstrating that conspiratorial discourse operates within ordinary social interaction. The proposed framework advances computational methods for belief-driven discourse analysis and offers applications for stance detection, political communication studies, and content moderation policy.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10105v1">üìÑ Download PDF</a></p><hr><h3 id=detection-prospects-for-heavy-wimp-dark-matter-near-supermassive-black-holes-particularly-in-m31httpsarxivorgabs251210923v1><a href=https://arxiv.org/abs/2512.10923v1>Detection prospects for heavy WIMP dark matter near supermassive black holes, particularly in M31</a><a hidden class=anchor aria-hidden=true href=#detection-prospects-for-heavy-wimp-dark-matter-near-supermassive-black-holes-particularly-in-m31httpsarxivorgabs251210923v1>#</a></h3><p><strong>Authors:</strong> Andrei E. Egorov
<strong>Venue:</strong> arXiv (2025)</p><p>This work analyzes the detection prospects for weakly interacting massive particles (WIMPs) in dark matter (DM) density spikes around nearby supermassive black holes (SMBHs) by observations in very high energy gamma-ray band. Such spikes are unique targets, which provide a possibility to discover the basic thermal s-wave annihilating WIMP with any mass up to the theoretical unitarity limit ~ 100 TeV. All relevant SMBHs were checked, and only MW* and M31* were identified as worthwhile objects. Cherenkov Telescope Array (CTA) sensitivity to heavy WIMPs in M31* was estimated. It was obtained that CTA will be able to probe a major part of TeV-scale WIMP parameter space in case of optimistic spike density configuration in M31*. In certain scenarios, M31* may yield even stronger constraints than MW*. Relevant systematic uncertainties were explored.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10923v1">üìÑ Download PDF</a></p><hr><h3 id=hiding-a-light-vector-boson-from-terrestrial-experiments-a-chargephobic-dark-photonhttpsarxivorgabs251210916v1><a href=https://arxiv.org/abs/2512.10916v1>Hiding a Light Vector Boson from Terrestrial Experiments: A Chargephobic Dark Photon</a><a hidden class=anchor aria-hidden=true href=#hiding-a-light-vector-boson-from-terrestrial-experiments-a-chargephobic-dark-photonhttpsarxivorgabs251210916v1>#</a></h3><p><strong>Authors:</strong> Haidar Esseili, Graham D. Kribs
<strong>Venue:</strong> arXiv (2025)</p><p>We calculate the terrestrial, astrophysical and cosmological constraints on a light vector boson that couples to an arbitrary combination of the electromagnetic and $B-L$ currents of the Standard Model. The dark photon and a vector boson coupling to $B-L$ are special cases of our generalized flavor-universal anomaly-free vector boson, requiring just one additional parameter (the &ldquo;dark mixing angle&rdquo; corresponding to the linear combination of the electromagnetic and $B-L$ currents) beyond that of the overall coupling strength and the vector boson mass, where we focus on the range $1, {\rm MeV}$ to $60, {\rm GeV}$. We perform a detailed investigation of a unique combination where the vector boson couplings to electrically charged leptons and protons are highly suppressed: the &ldquo;chargephobic dark photon&rdquo;. A chargephobic vector boson is very weakly constrained by current terrestrial experiments including beam dumps and collider experiments, since they rely on couplings to electrons and protons. Instead, neutrino scattering experiments (such as COHERENT), astrophysical sources (supernova emission), and cosmology ($ŒîN_{\rm eff}$) provide the strongest constraints due to the nonzero couplings of the chargephobic vector boson to neutrinos and neutrons. Indeed, we find that supernova emission and $ŒîN_{\rm eff}$ provide constraints throughout the space of dark mixing angles, demonstrating their importance to provide model-independent constraints. For nearly all of the parameter space, a chargephobic vector boson is the most weakly constrained anomaly-free vector boson that couples to flavor-independent or flavor-dependent combinations of Standard Model currents. Finally, we highlight the importance of future experiments, including SHiP, that are able to probe new regions of the chargephobic parameter space due to the significantly improved detector capabilities.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10916v1">üìÑ Download PDF</a></p><hr><h3 id=standard-model-benchmarks-for-d0to-k--k-œÄ-œÄ-k0_rm-s-k0_rm-s-decayshttpsarxivorgabs251210911v1><a href=https://arxiv.org/abs/2512.10911v1>Standard Model Benchmarks for $D^0\to K^- K^+, œÄ^-œÄ^+, K^0_{\rm S} K^0_{\rm S}$ Decays</a><a hidden class=anchor aria-hidden=true href=#standard-model-benchmarks-for-d0to-k--k-œÄ-œÄ-k0_rm-s-k0_rm-s-decayshttpsarxivorgabs251210911v1>#</a></h3><p><strong>Authors:</strong> Robert Fleischer, Maria Laura Piscopo, K. Keri Vos, B. Yaƒümur Zubaroƒülu
<strong>Venue:</strong> arXiv (2025)</p><p>The non-leptonic $D^0\to K^- K^+$ and $D^0\to œÄ^-œÄ^+$ decays are powerful probes of the Standard Model and are related to each other through the $U$-spin symmetry of the strong interaction. Using lattice QCD inputs we calculate the corresponding colour-allowed tree amplitudes in factorisation and demonstrate that non-factorisable contributions and $U$-spin-breaking effects at the level of 50% allow us to accommodate the measured branching ratios in the Standard Model. An exciting direct probe of such non-factorisable and $U$-spin breaking effects is provided by the $D^0\to K^0_{\rm S} K^0_{\rm S}$ channel. This decay is governed by non-factorisable exchange topologies and essentially vanishes in the $U$-spin limit, although it is experimentally well established with a prominent branching ratio. Extrapolating our $D^0\to K^- K^+$ results using the isospin symmetry, we find a consistent benchmark picture. Specifically, we can accommodate the measured $D^0\to K^0_{\rm S} K^0_{\rm S}$ branching ratio with $U$-spin-breaking effects at the 50% level and exchange amplitudes at the level of 50% of the colour-allowed $D^0\to K^- K^+$, $D^0\to œÄ^-œÄ^+$ tree contributions. Finally, we explore the resulting range for direct CP violation in $D^0\to K^0_{\rm S} K^0_{\rm S}$, obtaining upper bounds in our benchmark scenarios of a few per mille, offering an exciting target for future measurements.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10911v1">üìÑ Download PDF</a></p><hr><h3 id=conformal-boundary-conditions-and-higher-curvature-gravityhttpsarxivorgabs251210930v1><a href=https://arxiv.org/abs/2512.10930v1>Conformal Boundary Conditions and Higher Curvature Gravity</a><a hidden class=anchor aria-hidden=true href=#conformal-boundary-conditions-and-higher-curvature-gravityhttpsarxivorgabs251210930v1>#</a></h3><p><strong>Authors:</strong> Dami√°n A. Galante, Robert C. Myers, Themistocles Zikopoulos
<strong>Venue:</strong> arXiv (2025)</p><p>We initiate a systematic study of Einstein-Gauss-Bonnet gravity in the presence of boundaries subject to conformal boundary conditions, in which the conformal class of the boundary metric is kept fixed. In Einstein gravity, the trace of the extrinsic curvature is also fixed at the boundary. Here we generalize this boundary condition with the appropriate higher curvature correction. We study the problem both in Euclidean and Lorentzian signature. In Euclidean signature, we show that, similarly to the Einstein gravity case, the entropy at large temperatures exhibits the behavior of a conformal field theory in one lower dimension. We also show that in the flat space limit, the higher curvature corrections do not contribute to the leading behavior at high temperatures. We conjecture that this result is a universal feature of the flat space limit in the presence of conformal boundaries. We test our conjecture by analyzing charged black holes. In Lorentzian signature, we analyze the dynamics of the boundary Weyl factor in black hole backgrounds at the linearized level.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10930v1">üìÑ Download PDF</a></p><hr><h3 id=shedding-light-on-large-space-based-telescopes-modeling-stray-light-due-to-primary-mirror-damage-from-micrometeoroid-impactshttpsarxivorgabs251210915v1><a href=https://arxiv.org/abs/2512.10915v1>Shedding Light on Large Space-Based Telescopes: Modeling Stray Light due to Primary Mirror Damage from Micrometeoroid Impacts</a><a hidden class=anchor aria-hidden=true href=#shedding-light-on-large-space-based-telescopes-modeling-stray-light-due-to-primary-mirror-damage-from-micrometeoroid-impactshttpsarxivorgabs251210915v1>#</a></h3><p><strong>Authors:</strong> Megan T. Gialluca, Jonathan W. Arenberg, Chris Stark, Blake Shepherd, Victoria S. Meadows, Aki Roberge, Tyler D. Robinson, Robert Podgurski
<strong>Venue:</strong> arXiv (2025)</p><p>A large space-based telescope aimed at detecting and characterizing the atmospheres of Earth-like planets orbiting Sun-like stars will require unprecedented contrast and stability. However, damage to the primary mirror due to micrometeoroid impacts will provide a stochastic, time-dependent source of stray light in the coronagraph&rsquo;s field of view that could significantly lengthen exposure times and reduce the expected science yield. To better quantify the impact of stray light and inform the Habitable Worlds Observatory mission design process, we present estimates of stray light in different micrometeoroid damage scenarios for a broad range of targets, and use that to find the expected decrease in science yield (i.e., the expected number of detected exoEarth candidates). We find that stray light due to micrometeoroid damage may significantly reduce yield, by 30% &ndash; 60% in some cases, but significant uncertainties remain due to the unknown maximum expected impactor energy, and the relationship between impact energy and expected crater size. Micrometeoroid damage therefore needs further exploration, as it has the potential to reduce scientific yield, and in turn drive the development of mitigation strategies, selection of telescope designs, and selection of observing priorities in the future.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10915v1">üìÑ Download PDF</a></p><hr><h3 id=a-vision-for-ground-based-astronomy-beyond-the-2030s-how-to-build-esos-next-big-telescope-sustainablyhttpsarxivorgabs251210902v1><a href=https://arxiv.org/abs/2512.10902v1>A vision for ground-based astronomy beyond the 2030s: How to build ESO&rsquo;s next big telescope sustainably</a><a hidden class=anchor aria-hidden=true href=#a-vision-for-ground-based-astronomy-beyond-the-2030s-how-to-build-esos-next-big-telescope-sustainablyhttpsarxivorgabs251210902v1>#</a></h3><p><strong>Authors:</strong> Laurane Fr√©our, Mathilde Bouvier, Tony Mroczkowski, Callie Clontz, Fatemeh Zahra Majidi, Vasundhara Shaw, Olivier Absil, Anna Cabr√©, Olivier Lai, Dylan Magill, Jake D. Turner
<strong>Venue:</strong> arXiv (2025)</p><p>Astronomy is the study of the Universe and all the objects that it comprises. Our attention is therefore usually focused beyond Earth, home to the only form of life known today. However, how can we continue to explore the secrets of the Universe, if we stand by and watch our only home burn? We know that there is no Planet B. It is therefore urgent that, as astronomers, we collectively work to protect the Earth, allowing future generations the opportunity to continue to uncover the secrets of the cosmos. As astronomical facilities account for the majority of our community&rsquo;s carbon footprint, we propose guidelines that we hold crucial for the European Southern Observatory (ESO) to consider in the context of the Expanding Horizons programme as it plans a next-generation, transformational facility.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10902v1">üìÑ Download PDF</a></p><hr><h3 id=hybrid-quantum-classical-matrix-product-state-and-lanczos-methods-for-electron-phonon-systems-with-strong-electronic-correlations-application-to-disordered-systems-coupled-to-einstein-phononshttpsarxivorgabs251210899v1><a href=https://arxiv.org/abs/2512.10899v1>Hybrid quantum-classical matrix-product state and Lanczos methods for electron-phonon systems with strong electronic correlations: Application to disordered systems coupled to Einstein phonons</a><a hidden class=anchor aria-hidden=true href=#hybrid-quantum-classical-matrix-product-state-and-lanczos-methods-for-electron-phonon-systems-with-strong-electronic-correlations-application-to-disordered-systems-coupled-to-einstein-phononshttpsarxivorgabs251210899v1>#</a></h3><p><strong>Authors:</strong> Heiko Georg Menzler, Suman Mondal, Fabian Heidrich-Meisner
<strong>Venue:</strong> arXiv (2025)</p><p>We present two quantum-classical hybrid methods for simulating the time-dependence of electron-phonon systems that treat electronic correlations numerically exactly and optical-phonon degrees of freedom classically. These are a time-dependent Lanczos and a matrix-product state method, each combined with the multi-trajectory Ehrenfest approach. Due to the approximations, reliable results are expected for the adiabatic regime of small phonon frequencies. We discuss the convergence properties of both methods for a system of interacting spinless fermions in one dimension and provide a benchmark for the Holstein chain. As a first application, we study the decay of charge density wave order in a system of interacting spinless fermions coupled to Einstein oscillators and in the presence of quenched disorder. We investigate the dependence of the relaxation dynamics on the electron-phonon coupling strength and provide numerical evidence that the coupling of strongly disordered systems to classical oscillators leads to delocalization, thus destabilizing the (finite-size) many-body localization in this system.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10899v1">üìÑ Download PDF</a></p><hr><h3 id=physics-informed-learning-of-microvascular-flow-models-using-graph-neural-networkshttpsarxivorgabs251210792v1><a href=https://arxiv.org/abs/2512.10792v1>Physics-Informed Learning of Microvascular Flow Models using Graph Neural Networks</a><a hidden class=anchor aria-hidden=true href=#physics-informed-learning-of-microvascular-flow-models-using-graph-neural-networkshttpsarxivorgabs251210792v1>#</a></h3><p><strong>Authors:</strong> Paolo Botta, Piermario Vitullo, Thomas Ventimiglia, Andreas Linninger, Paolo Zunino
<strong>Venue:</strong> arXiv (2025)</p><p>The simulation of microcirculatory blood flow in realistic vascular architectures poses significant challenges due to the multiscale nature of the problem and the topological complexity of capillary networks. In this work, we propose a novel deep learning-based reduced-order modeling strategy, leveraging Graph Neural Networks (GNNs) trained on synthetic microvascular graphs to approximate hemodynamic quantities on anatomically realistic domains. Our method combines algorithms for synthetic vascular generation with a physics-informed training procedure that integrates graph topological information and local flow dynamics. To ensure the physical reliability of the learned surrogates, we incorporate a physics-informed loss functional derived from the governing equations, allowing enforcement of mass conservation and rheological constraints. The resulting GNN architecture demonstrates robust generalization capabilities across diverse network configurations. The GNN formulation is validated on benchmark problems with linear and nonlinear rheology, showing accurate pressure and velocity field reconstruction with substantial computational gains over full-order solvers. The methodology showcases significant generalization capabilities with respect to vascular complexity, as highlighted by tests on data from the mouse cerebral cortex. This work establishes a new class of graph-based surrogate models for microvascular flow, grounded in physical laws and equipped with inductive biases that mirror mass conservation and rheological models, opening new directions for real-time inference in vascular modeling and biomedical applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10792v1">üìÑ Download PDF</a></p><hr><h3 id=textual-data-bias-detection-and-mitigation---an-extensible-pipeline-with-experimental-evaluationhttpsarxivorgabs251210734v1><a href=https://arxiv.org/abs/2512.10734v1>Textual Data Bias Detection and Mitigation - An Extensible Pipeline with Experimental Evaluation</a><a hidden class=anchor aria-hidden=true href=#textual-data-bias-detection-and-mitigation---an-extensible-pipeline-with-experimental-evaluationhttpsarxivorgabs251210734v1>#</a></h3><p><strong>Authors:</strong> Rebekka G√∂rge, Sujan Sai Gannamaneni, Tabea Naeven, Hammam Abdelwahab, H√©ctor Allende-Cid, Armin B. Cremers, Lennard Helmer, Michael Mock, Anna Schmitz, Songkai Xue, Elif Yildirir, Maximilian Poretschkin, Stefan Wrobel
<strong>Venue:</strong> arXiv (2025)</p><p>Textual data used to train large language models (LLMs) exhibits multifaceted bias manifestations encompassing harmful language and skewed demographic distributions. Regulations such as the European AI Act require identifying and mitigating biases against protected groups in data, with the ultimate goal of preventing unfair model outputs. However, practical guidance and operationalization are lacking. We propose a comprehensive data bias detection and mitigation pipeline comprising four components that address two data bias types, namely representation bias and (explicit) stereotypes for a configurable sensitive attribute. First, we leverage LLM-generated word lists created based on quality criteria to detect relevant group labels. Second, representation bias is quantified using the Demographic Representation Score. Third, we detect and mitigate stereotypes using sociolinguistically informed filtering. Finally, we compensate representation bias through Grammar- and Context-Aware Counterfactual Data Augmentation. We conduct a two-fold evaluation using the examples of gender, religion and age. First, the effectiveness of each individual component on data debiasing is evaluated through human validation and baseline comparison. The findings demonstrate that we successfully reduce representation bias and (explicit) stereotypes in a text dataset. Second, the effect of data debiasing on model bias reduction is evaluated by bias benchmarking of several models (0.6B-8B parameters), fine-tuned on the debiased text dataset. This evaluation reveals that LLMs fine-tuned on debiased data do not consistently show improved performance on bias benchmarks, exposing critical gaps in current evaluation methodologies and highlighting the need for targeted data manipulation to address manifested model bias.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10734v1">üìÑ Download PDF</a></p><hr><h3 id=a-cryogenic-muon-tagging-system-based-on-kinetic-inductance-detectors-for-superconducting-quantum-processorshttpsarxivorgabs251210679v1><a href=https://arxiv.org/abs/2512.10679v1>A Cryogenic Muon Tagging System Based on Kinetic Inductance Detectors for Superconducting Quantum Processors</a><a hidden class=anchor aria-hidden=true href=#a-cryogenic-muon-tagging-system-based-on-kinetic-inductance-detectors-for-superconducting-quantum-processorshttpsarxivorgabs251210679v1>#</a></h3><p><strong>Authors:</strong> Ambra Mariani, Laura Cardani, Mustafa Bal, Nicola Casali, Ivan Colantoni, Angelo Cruciani, Giorgio Del Castello, Daniele Delicato, Francesco De Dominicis, Matteo del Gallo Raccagiovine, Matteo Folcarelli, Sabrina Garattoni, Anna Grassellino, Mehmood Khan Yasir Raja, Valerio Pettinacci, Alberto Ressa, Tanay Roy, Marco Vignati, David v Zanten
<strong>Venue:</strong> arXiv (2025)</p><p>Ionizing radiation has emerged as a potential limiting factor for superconducting quantum processors, inducing quasiparticle bursts and correlated errors that challenge fault-tolerant operation. Atmospheric muons are particularly problematic due to their high energy and penetration power, making passive shielding ineffective. Therefore, monitoring the real-time muon flux is crucial to guide the development of alternative error-correction or protection strategies. We present the design, simulation, and first operation of a cryogenic muon-tagging system based on Kinetic Inductance Detectors (KIDs) for integration with superconducting quantum processors. The system consists of two KIDs arranged in a vertical stack and operated at ~20 mK. Monte Carlo simulations based on Geant4 guided the prototype design and provided reference expectations for muon-tagging efficiency and accidental coincidences due to ambient $Œ≥$-rays. We measured a muon-induced coincidence rate among the top and bottom detectors of (192 $\pm$ 9) $\times$ 10$^{-3}$ events/s, in excellent agreement with the Monte Carlo prediction. The prototype achieves a muon-tagging efficiency of about 90% with negligible dead time. These results demonstrate the feasibility of operating a muon-tagging system at millikelvin temperatures and open the path toward its integration with multi-qubit chips to veto or correct muon-induced errors in real time.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10679v1">üìÑ Download PDF</a></p><hr><h3 id=topology-guided-quantum-gans-for-constrained-graph-generationhttpsarxivorgabs251210582v1><a href=https://arxiv.org/abs/2512.10582v1>Topology-Guided Quantum GANs for Constrained Graph Generation</a><a hidden class=anchor aria-hidden=true href=#topology-guided-quantum-gans-for-constrained-graph-generationhttpsarxivorgabs251210582v1>#</a></h3><p><strong>Authors:</strong> Tobias Rohe, Markus Baumann, Michael Poppel, Gerhard Stenzel, Maximilian Zorn, Claudia Linnhoff-Popien
<strong>Venue:</strong> arXiv (2025)</p><p>Quantum computing (QC) promises theoretical advantages, benefiting computational problems that would not be efficiently classically simulatable. However, much of this theoretical speedup depends on the quantum circuit design solving the problem. We argue that QC literature has yet to explore more domain specific ansatz-topologies, instead of relying on generic, one-size-fits-all architectures. In this work, we show that incorporating task-specific inductive biases &ndash; specifically geometric priors &ndash; into quantum circuit design can enhance the performance of hybrid Quantum Generative Adversarial Networks (QuGANs) on the task of generating geometrically constrained K4 graphs. We evaluate a portfolio of entanglement topologies and loss-function designs to assess their impact on both statistical fidelity and compliance with geometric constraints, including the Triangle and Ptolemaic inequalities. Our results show that aligning circuit topology with the underlying problem structure yields substantial benefits: the Triangle-topology QuGAN achieves the highest geometric validity among quantum models and matches the performance of classical Generative Adversarial Networks (GAN). Additionally, we showcase how specific architectural choices, such as entangling gate types, variance regularization and output-scaling govern the trade-off between geometric consistency and distributional accuracy, thus emphasizing the value of structured, task-aware quantum ansatz-topologies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10582v1">üìÑ Download PDF</a></p><hr><h3 id=grammaticality-judgments-in-humans-and-language-models-revisiting-generative-grammar-with-llmshttpsarxivorgabs251210453v1><a href=https://arxiv.org/abs/2512.10453v1>Grammaticality Judgments in Humans and Language Models: Revisiting Generative Grammar with LLMs</a><a hidden class=anchor aria-hidden=true href=#grammaticality-judgments-in-humans-and-language-models-revisiting-generative-grammar-with-llmshttpsarxivorgabs251210453v1>#</a></h3><p><strong>Authors:</strong> Lars G. B. Johnsen
<strong>Venue:</strong> arXiv (2025)</p><p>What counts as evidence for syntactic structure? In traditional generative grammar, systematic contrasts in grammaticality such as subject-auxiliary inversion and the licensing of parasitic gaps are taken as evidence for an internal, hierarchical grammar. In this paper, we test whether large language models (LLMs), trained only on surface forms, reproduce these contrasts in ways that imply an underlying structural representation.
We focus on two classic constructions: subject-auxiliary inversion (testing recognition of the subject boundary) and parasitic gap licensing (testing abstract dependency structure). We evaluate models including GPT-4 and LLaMA-3 using prompts eliciting acceptability ratings. Results show that LLMs reliably distinguish between grammatical and ungrammatical variants in both constructions, and as such support that they are sensitive to structure and not just linear order. Structural generalizations, distinct from cognitive knowledge, emerge from predictive training on surface forms, suggesting functional sensitivity to syntax without explicit encoding.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10453v1">üìÑ Download PDF</a></p><hr><h2 id=-psycholinguistics>üîç psycholinguistics<a hidden class=anchor aria-hidden=true href=#-psycholinguistics>#</a></h2><h3 id=on-decision-making-agents-and-higher-order-causal-processeshttpsarxivorgabs251210937v1><a href=https://arxiv.org/abs/2512.10937v1>On Decision-Making Agents and Higher-Order Causal Processes</a><a hidden class=anchor aria-hidden=true href=#on-decision-making-agents-and-higher-order-causal-processeshttpsarxivorgabs251210937v1>#</a></h3><p><strong>Authors:</strong> Matt Wilson
<strong>Venue:</strong> arXiv (2025)</p><p>We establish a precise correspondence between decision-making agents in partially observable Markov decision processes (POMDPs) and one-input process functions, the classical limit of higher-order quantum operations. In this identification an agent&rsquo;s policy and memory update combine into a process function w that interacts with a POMDP environment via the link product. This suggests a dual interpretation: in the physics view, the process function acts as the environment into which local operations (agent interventions) are inserted, whereas in the AI view it encodes the agent and the inserted functions represent environments. We extend this perspective to multi-agent systems by identifying observation-independent decentralized POMDPs as natural domains for multi-input process functions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10937v1">üìÑ Download PDF</a></p><hr><h3 id=any4d-unified-feed-forward-metric-4d-reconstructionhttpsarxivorgabs251210935v1><a href=https://arxiv.org/abs/2512.10935v1>Any4D: Unified Feed-Forward Metric 4D Reconstruction</a><a hidden class=anchor aria-hidden=true href=#any4d-unified-feed-forward-metric-4d-reconstructionhttpsarxivorgabs251210935v1>#</a></h3><p><strong>Authors:</strong> Jay Karhade, Nikhil Keetha, Yuchen Zhang, Tanisha Gupta, Akash Sharma, Sebastian Scherer, Deva Ramanan
<strong>Venue:</strong> arXiv (2025)</p><p>We present Any4D, a scalable multi-view transformer for metric-scale, dense feed-forward 4D reconstruction. Any4D directly generates per-pixel motion and geometry predictions for N frames, in contrast to prior work that typically focuses on either 2-view dense scene flow or sparse 3D point tracking. Moreover, unlike other recent methods for 4D reconstruction from monocular RGB videos, Any4D can process additional modalities and sensors such as RGB-D frames, IMU-based egomotion, and Radar Doppler measurements, when available. One of the key innovations that allows for such a flexible framework is a modular representation of a 4D scene; specifically, per-view 4D predictions are encoded using a variety of egocentric factors (depthmaps and camera intrinsics) represented in local camera coordinates, and allocentric factors (camera extrinsics and scene flow) represented in global world coordinates. We achieve superior performance across diverse setups - both in terms of accuracy (2-3X lower error) and compute efficiency (15X faster), opening avenues for multiple downstream applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10935v1">üìÑ Download PDF</a></p><hr><h3 id=anomalous-scaling-law-for-the-two-dimensional-gaussian-free-fieldhttpsarxivorgabs251210933v1><a href=https://arxiv.org/abs/2512.10933v1>Anomalous scaling law for the two-dimensional Gaussian free field</a><a hidden class=anchor aria-hidden=true href=#anomalous-scaling-law-for-the-two-dimensional-gaussian-free-fieldhttpsarxivorgabs251210933v1>#</a></h3><p><strong>Authors:</strong> Pierre-Fran√ßois Rodriguez, Wen Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>We consider the Gaussian free field $\varphi$ on $\mathbb{Z}^2$ at large spatial scales $N$ and give sharp bounds on the probability $Œ∏(a,N)$ that the radius of a finite cluster in the excursion set ${\varphi \geq a}$ on the corresponding metric graph is macroscopic. We prove a scaling law for this probability, by which $Œ∏(a,N)$ transitions from fractional logarithmic decay for near-critical parameters $(a,N)$ to polynomial decay in the off-critical regime. The transition occurs across a certain scaling window determined by a correlation length scale $Œæ$, which is such that $Œ∏(a,N) \sim Œ∏(0,Œæ)(\tfrac{N}Œæ)^{-œÑ}$ for typical heights $a$ as $N/Œæ$ diverges, with an explicit exponent $œÑ$ that we identify in the process. This is in stark contrast with recent results from arXiv:2101.02200 and arXiv:2312.10030 in dimension three, where similar observables are shown to follow regular scaling laws, with polynomial decay at and near criticality, and rapid decay in ${N}/Œæ$ away from it.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10933v1">üìÑ Download PDF</a></p><hr><h3 id=the-localization-method-for-high-dimensional-inequalitieshttpsarxivorgabs251210848v1><a href=https://arxiv.org/abs/2512.10848v1>The Localization Method for High-Dimensional Inequalities</a><a hidden class=anchor aria-hidden=true href=#the-localization-method-for-high-dimensional-inequalitieshttpsarxivorgabs251210848v1>#</a></h3><p><strong>Authors:</strong> Yunbum Kook, Santosh S. Vempala
<strong>Venue:</strong> arXiv (2025)</p><p>We survey the localization method for proving inequalities in high dimension, pioneered by Lov√°sz and Simonovits (1993), and its stochastic extension developed by Eldan (2012). The method has found applications in a surprising wide variety of settings, ranging from its original motivation in isoperimetric inequalities to optimization, concentration of measure, and bounding the mixing rate of Markov chains. At heart, the method converts a given instance of an inequality (for a set or distribution in high dimension) into a highly structured instance, often just one-dimensional.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10848v1">üìÑ Download PDF</a></p><hr><h3 id=what-matters-for-representation-alignment-global-information-or-spatial-structurehttpsarxivorgabs251210794v1><a href=https://arxiv.org/abs/2512.10794v1>What matters for Representation Alignment: Global Information or Spatial Structure?</a><a hidden class=anchor aria-hidden=true href=#what-matters-for-representation-alignment-global-information-or-spatial-structurehttpsarxivorgabs251210794v1>#</a></h3><p><strong>Authors:</strong> Jaskirat Singh, Xingjian Leng, Zongze Wu, Liang Zheng, Richard Zhang, Eli Shechtman, Saining Xie
<strong>Venue:</strong> arXiv (2025)</p><p>Representation alignment (REPA) guides generative training by distilling representations from a strong, pretrained vision encoder to intermediate diffusion features. We investigate a fundamental question: what aspect of the target representation matters for generation, its \textit{global} \revision{semantic} information (e.g., measured by ImageNet-1K accuracy) or its spatial structure (i.e. pairwise cosine similarity between patch tokens)? Prevalent wisdom holds that stronger global semantic performance leads to better generation as a target representation. To study this, we first perform a large-scale empirical analysis across 27 different vision encoders and different model scales. The results are surprising; spatial structure, rather than global performance, drives the generation performance of a target representation. To further study this, we introduce two straightforward modifications, which specifically accentuate the transfer of \emph{spatial} information. We replace the standard MLP projection layer in REPA with a simple convolution layer and introduce a spatial normalization layer for the external representation. Surprisingly, our simple method (implemented in $&lt;$4 lines of code), termed iREPA, consistently improves convergence speed of REPA, across a diverse set of vision encoders, model sizes, and training variants (such as REPA, REPA-E, Meanflow, JiT etc). %, etc. Our work motivates revisiting the fundamental working mechanism of representational alignment and how it can be leveraged for improved training of generative models. The code and project page are available at <a href=https://end2end-diffusion.github.io/irepa>https://end2end-diffusion.github.io/irepa</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10794v1">üìÑ Download PDF</a></p><hr><h3 id=maximal-rigidity-of-random-measure-and-uniqueness-pairs-stealthy-processes-quasicrystals-and-periodicityhttpsarxivorgabs251210686v1><a href=https://arxiv.org/abs/2512.10686v1>Maximal rigidity of random measure and uniqueness pairs: stealthy processes, quasicrystals and periodicity</a><a hidden class=anchor aria-hidden=true href=#maximal-rigidity-of-random-measure-and-uniqueness-pairs-stealthy-processes-quasicrystals-and-periodicityhttpsarxivorgabs251210686v1>#</a></h3><p><strong>Authors:</strong> Rapha√´l Lachi√®ze-Rey
<strong>Venue:</strong> arXiv (2025)</p><p>This article investigates the phenomenon of maximal rigidity in spatial processes, where perfect interpolation of the process is possible from partial information, specifically, from its restriction to a strict subdomain, often resulting in a trivial tail $œÉ$algebra. A classical example known since the 1930&rsquo;s is that a time series is fully determined by its values on the negative integers if its spectrum has a gap, or at least a sufficiently deep zero. We extend such results to higher dimensions and continuous settings by establishing a connection with the concept of uniqueness pairs, rooted in the uncertainty principle of harmonic analysis. We present several other manifestations of this principle, unify and strengthen seemingly unrelated results across different models: quasicrystals and stealthy processes are shown to be maximally rigid on cones, and discrete integer-valued processes are necessarily periodic when they have a simply connected spectrum. Finally, we identify a surprising class of continuous fields with seemingly standard behavior, such as linear variance and finite dependency range, that undergo a phase transition: they are perfectly interpolable on B(0, $œÅ$) for $œÅ$ ___ 2 $œÄ$ but exhibit no rigidity for $œÅ$ > 2.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10686v1">üìÑ Download PDF</a></p><hr><h3 id=fano-and-reflexive-polytopes-from-feynman-integralshttpsarxivorgabs251210518v1><a href=https://arxiv.org/abs/2512.10518v1>Fano and Reflexive Polytopes from Feynman Integrals</a><a hidden class=anchor aria-hidden=true href=#fano-and-reflexive-polytopes-from-feynman-integralshttpsarxivorgabs251210518v1>#</a></h3><p><strong>Authors:</strong> Leonardo de la Cruz, Pavel P. Novichkov, Pierre Vanhove
<strong>Venue:</strong> arXiv (2025)</p><p>We classify the Fano and reflexive polytopes that arise from quasi-finite Feynman integrals. These polytopes appear as scaled Minkowski sums of the Newton polytopes associated with the Symanzik graph polynomials. For one-loop graphs and multiloop sunset graphs, we identify the Fano and reflexive cases by computing the number of interior points from the associated bivariate Ehrhart polynomials. More generally, we utilize the properties of Symanzik polynomials and their symmetries to conduct a direct search over all Feynman graphs in generic kinematics with up to ten edges and nine loops. We find that such cases are remarkably sparse: for example, we find only two two-dimensional reflexive polytopes, three three-dimensional reflexive polytopes, and four three-dimensional Fano polytopes. We also reveal a surprising feature of one-loop $N$-gon integrals in higher dimensions: their associated reflexive polytopes encode degenerate Calabi&ndash;Yau $(N-2)$-folds. We further analyze the geometric structures encoded by these polytopes and exhibit explicit connections with del Pezzo surfaces, $K3$ surfaces, and Calabi&ndash;Yau threefolds. Since reflexive polytopes naturally correspond to Calabi&ndash;Yau varieties, our classification demonstrates that quasi-finite Feynman integrals, with reflexive polytopes, are intrinsically linked to Calabi&ndash;Yau period integrals.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10518v1">üìÑ Download PDF</a></p><hr><h3 id=neighborhood-complexes-of-induced-k-independent-graphshttpsarxivorgabs251209674v1><a href=https://arxiv.org/abs/2512.09674v1>Neighborhood Complexes of induced $k$-independent graphs</a><a hidden class=anchor aria-hidden=true href=#neighborhood-complexes-of-induced-k-independent-graphshttpsarxivorgabs251209674v1>#</a></h3><p><strong>Authors:</strong> Yufeng Shen, Zhiyu Song, Feneglin Yu, Leopold Wuhan Zhou, Jingqi Zhuang
<strong>Venue:</strong> arXiv (2025)</p><p>This paper is devoted to the neighborhood complexes of the induced $k$-independent graphs. Inspired by the surprising correspondence between total $k$-cut complex of $n$-cycle $C_n$ and neighborhood complex of stable Kneser graph $SG(n,k)$, we anticipate that the homotopy type of total cut complexes may have some relationships with the neighborhood complexes of induced $k$-independent graphs. We investigated the homotopy type of some total cut complexes and neighborhood complexes of some other graphs, using techniques from algebraic topology and discrete Morse theory.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.09674v1">üìÑ Download PDF</a></p><hr><h3 id=understanding-the-failure-modes-of-transformers-through-the-lens-of-graph-neural-networkshttpsarxivorgabs251209182v1><a href=https://arxiv.org/abs/2512.09182v1>Understanding the Failure Modes of Transformers through the Lens of Graph Neural Networks</a><a hidden class=anchor aria-hidden=true href=#understanding-the-failure-modes-of-transformers-through-the-lens-of-graph-neural-networkshttpsarxivorgabs251209182v1>#</a></h3><p><strong>Authors:</strong> Hunjae Lee
<strong>Venue:</strong> arXiv (2025)</p><p>Transformers and more specifically decoder-only transformers dominate modern LLM architectures. While they have shown to work exceptionally well, they are not without issues, resulting in surprising failure modes and predictably asymmetric performance degradation. This article is a study of many of these observed failure modes of transformers through the lens of graph neural network (GNN) theory. We first make the case that much of deep learning, including transformers, is about learnable information mixing and propagation. This makes the study of model failure modes a study of bottlenecks in information propagation. This naturally leads to GNN theory, where there is already a rich literature on information propagation bottlenecks and theoretical failure modes of models. We then make the case that many issues faced by GNNs are also experienced by transformers. In addition, we analyze how the causal nature of decoder-only transformers create interesting geometric properties in information propagation, resulting in predictable and potentially devastating failure modes. Finally, we observe that existing solutions in transformer research tend to be ad-hoc and driven by intuition rather than grounded theoretical motivation. As such, we unify many such solutions under a more theoretical perspective, providing insight into why they work, what problem they are actually solving, and how they can be further improved to target specific failure modes of transformers. Overall, this article is an attempt to bridge the gap between observed failure modes in transformers and a general lack of theoretical understanding of them in this space.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.09182v1">üìÑ Download PDF</a></p><hr><h3 id=classifier-reconstruction-through-counterfactual-aware-wasserstein-prototypeshttpsarxivorgabs251210878v1><a href=https://arxiv.org/abs/2512.10878v1>Classifier Reconstruction Through Counterfactual-Aware Wasserstein Prototypes</a><a hidden class=anchor aria-hidden=true href=#classifier-reconstruction-through-counterfactual-aware-wasserstein-prototypeshttpsarxivorgabs251210878v1>#</a></h3><p><strong>Authors:</strong> Xuan Zhao, Zhuo Cao, Arya Bangun, Hanno Scharr, Ira Assent
<strong>Venue:</strong> arXiv (2025)</p><p>Counterfactual explanations provide actionable insights by identifying minimal input changes required to achieve a desired model prediction. Beyond their interpretability benefits, counterfactuals can also be leveraged for model reconstruction, where a surrogate model is trained to replicate the behavior of a target model. In this work, we demonstrate that model reconstruction can be significantly improved by recognizing that counterfactuals, which typically lie close to the decision boundary, can serve as informative though less representative samples for both classes. This is particularly beneficial in settings with limited access to labeled data. We propose a method that integrates original data samples with counterfactuals to approximate class prototypes using the Wasserstein barycenter, thereby preserving the underlying distributional structure of each class. This approach enhances the quality of the surrogate model and mitigates the issue of decision boundary shift, which commonly arises when counterfactuals are naively treated as ordinary training instances. Empirical results across multiple datasets show that our method improves fidelity between the surrogate and target models, validating its effectiveness.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10878v1">üìÑ Download PDF</a></p><hr><h3 id=a-differentiable-digital-twin-of-distributed-link-scheduling-for-contention-aware-networkinghttpsarxivorgabs251210874v1><a href=https://arxiv.org/abs/2512.10874v1>A Differentiable Digital Twin of Distributed Link Scheduling for Contention-Aware Networking</a><a hidden class=anchor aria-hidden=true href=#a-differentiable-digital-twin-of-distributed-link-scheduling-for-contention-aware-networkinghttpsarxivorgabs251210874v1>#</a></h3><p><strong>Authors:</strong> Zhongyuan Zhao, Yujun Ming, Kevin Chan, Ananthram Swami, Santiago Segarra
<strong>Venue:</strong> arXiv (2025)</p><p>Many routing and flow optimization problems in wired networks can be solved efficiently using minimum cost flow formulations. However, this approach does not extend to wireless multi-hop networks, where the assumptions of fixed link capacity and linear cost structure collapse due to contention for shared spectrum resources. The key challenge is that the long-term capacity of a wireless link becomes a non-linear function of its network context, including network topology, link quality, and the traffic assigned to neighboring links. In this work, we pursue a new direction of modeling wireless network under randomized medium access control by developing an analytical network digital twin (NDT) that predicts link duty cycles from network context. We generalize randomized contention as finding a Maximal Independent Set (MIS) on the conflict graph using weighted Luby&rsquo;s algorithm, derive an analytical model of link duty cycles, and introduce an iterative procedure that resolves the circular dependency among duty cycle, link capacity, and contention probability. Our numerical experiments show that the proposed NDT accurately predicts link duty cycles and congestion patterns with up to a 5000x speedup over packet-level simulation, and enables us to optimize link scheduling using gradient descent for reduced congestion and radio footprint.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10874v1">üìÑ Download PDF</a></p><hr><h3 id=multidimensional-sorting-comparative-staticshttpsarxivorgabs251210853v1><a href=https://arxiv.org/abs/2512.10853v1>Multidimensional Sorting: Comparative Statics</a><a hidden class=anchor aria-hidden=true href=#multidimensional-sorting-comparative-staticshttpsarxivorgabs251210853v1>#</a></h3><p><strong>Authors:</strong> Job Boerma, Andrea Ottolini, Aleh Tsyvinski
<strong>Venue:</strong> arXiv (2025)</p><p>In sorting literature, comparative statics for multidimensional assignment models with general output functions and input distributions is an important open question. We provide a complete theory of comparative statics for technological change in general multidimensional assignment models. Our main result is that any technological change is uniquely decomposed into two distinct components. The first component (gradient) gives a characterization of changes in marginal earnings through a Poisson equation. The second component (divergence-free) gives a characterization of labor reallocation. For U.S. data, we quantify equilibrium responses in sorting and earnings with respect to cognitive skill-biased technological change.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10853v1">üìÑ Download PDF</a></p><hr><h3 id=allometric-scaling-of-brain-activity-explained-by-avalanche-criticalityhttpsarxivorgabs251210834v1><a href=https://arxiv.org/abs/2512.10834v1>Allometric scaling of brain activity explained by avalanche criticality</a><a hidden class=anchor aria-hidden=true href=#allometric-scaling-of-brain-activity-explained-by-avalanche-criticalityhttpsarxivorgabs251210834v1>#</a></h3><p><strong>Authors:</strong> Tiago S. A. N. Sim√µes, Jos√© S. Andrade, Hans J. Herrmann, Stefano Zapperi, Lucilla de Arcangelis
<strong>Venue:</strong> arXiv (2025)</p><p>Allometric scaling laws, such as Kleiber&rsquo;s law for metabolic rate, highlight how efficiency emerges with size across living systems. The brain, with its characteristic sublinear scaling of activity, has long posed a puzzle: why do larger brains operate with disproportionately lower firing rates? Here we show that this economy of scale is a universal outcome of avalanche dynamics. We derive analytical scaling laws directly from avalanche statistics, establishing that any system governed by critical avalanches must exhibit sublinear activity-size relations. This theoretical prediction is then verified in integrate-and-fire neuronal networks at criticality and in classical self-organized criticality models, demonstrating that the effect is not model-specific but generic. The predicted exponents align with experimental observations across mammal species, bridging dynamical criticality with the allometry of brain metabolism. Our results reveal avalanche criticality as a fundamental mechanism underlying Kleiber-like scaling in the brain.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10834v1">üìÑ Download PDF</a></p><hr><h3 id=agile-deliberation-concept-deliberation-for-subjective-visual-classificationhttpsarxivorgabs251210821v1><a href=https://arxiv.org/abs/2512.10821v1>Agile Deliberation: Concept Deliberation for Subjective Visual Classification</a><a hidden class=anchor aria-hidden=true href=#agile-deliberation-concept-deliberation-for-subjective-visual-classificationhttpsarxivorgabs251210821v1>#</a></h3><p><strong>Authors:</strong> Leijie Wang, Otilia Stretcu, Wei Qiao, Thomas Denby, Krishnamurthy Viswanathan, Enming Luo, Chun-Ta Lu, Tushar Dogra, Ranjay Krishna, Ariel Fuxman
<strong>Venue:</strong> arXiv (2025)</p><p>From content moderation to content curation, applications requiring vision classifiers for visual concepts are rapidly expanding. Existing human-in-the-loop approaches typically assume users begin with a clear, stable concept understanding to be able to provide high-quality supervision. In reality, users often start with a vague idea and must iteratively refine it through &ldquo;concept deliberation&rdquo;, a practice we uncovered through structured interviews with content moderation experts. We operationalize the common strategies in deliberation used by real content moderators into a human-in-the-loop framework called &ldquo;Agile Deliberation&rdquo; that explicitly supports evolving and subjective concepts. The system supports users in defining the concept for themselves by exposing them to borderline cases. The system does this with two deliberation stages: (1) concept scoping, which decomposes the initial concept into a structured hierarchy of sub-concepts, and (2) concept iteration, which surfaces semantically borderline examples for user reflection and feedback to iteratively align an image classifier with the user&rsquo;s evolving intent. Since concept deliberation is inherently subjective and interactive, we painstakingly evaluate the framework through 18 user sessions, each 1.5h long, rather than standard benchmarking datasets. We find that Agile Deliberation achieves 7.5% higher F1 scores than automated decomposition baselines and more than 3% higher than manual deliberation, while participants reported clearer conceptual understanding and lower cognitive effort.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10821v1">üìÑ Download PDF</a></p><hr><h3 id=parallel-neuron-groups-in-the-drosophila-brainhttpsarxivorgabs251210525v1><a href=https://arxiv.org/abs/2512.10525v1>Parallel Neuron Groups in the Drosophila Brain</a><a hidden class=anchor aria-hidden=true href=#parallel-neuron-groups-in-the-drosophila-brainhttpsarxivorgabs251210525v1>#</a></h3><p><strong>Authors:</strong> Robert Worden
<strong>Venue:</strong> arXiv (2025)</p><p>The full connectome of an adult Drosophila enables a search for novel neural structures in the insect brain. I describe a new neural structure, called a Parallel Neuron Group (PNG). Two neurons are called parallel if they share a significant number of input neurons and output neurons. Most pairs of neurons in the Drosophila brain have very small parallel match. There are about twenty larger groups of neurons for which any pair of neurons in the group has a high match. These are the parallel groups. Parallel groups contain only about 1000 out of the 65,000 neurons in the brain, and have distinctive properties. There are groups in the right mushroom bodies, the antennal lobes, the lobula, and in two central neuropils (GNG and EB). Most parallel groups do not have lateral symmetry. A group usually has one major input neuron, which inputs to all the neurons in the group, and a small number of major output neurons. The major input and output neurons are laterally asymmetric. Parallel neuron groups present puzzles, such as: what does a group do, that could not be done by one larger neuron? Do all neurons in a group fire in synchrony, or do they perform different functions? Why are they laterally asymmetric? These may merit further investigation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10525v1">üìÑ Download PDF</a></p><hr><h3 id=low-order-mathcalh_2--mathcalh_infty-controller-design-for-aeroelastic-vibration-suppressionhttpsarxivorgabs251210841v1><a href=https://arxiv.org/abs/2512.10841v1>Low-Order $\mathcal{H}<em>2 / \mathcal{H}</em>\infty$ Controller Design for Aeroelastic Vibration Suppression</a><a hidden class=anchor aria-hidden=true href=#low-order-mathcalh_2--mathcalh_infty-controller-design-for-aeroelastic-vibration-suppressionhttpsarxivorgabs251210841v1>#</a></h3><p><strong>Authors:</strong> Mohammad Mirtaba, Juan Augusto Paredes Salazar, Daning Huang, Ankit Goel
<strong>Venue:</strong> arXiv (2025)</p><p>This paper presents an $\mathcal{H}<em>2 / \mathcal{H}</em>\infty$ minimization-based output-feedback controller for active aeroelastic vibration suppression in a cantilevered beam. First, a nonlinear structural model incorporating moderate deflection and aerodynamic loading is derived and discretized using the finite element method (FEM). Then, a low-order linear model is identified from random gaussian input response data from the FEM model to synthesize an output-feedback controller using the $\mathcal{H}<em>2 / \mathcal{H}</em>\infty$ framework. A frequency-weighted dynamic filter is introduced to emphasize disturbance frequencies of interest, enabling the controller to target dominant vibration modes. Simulation results demonstrate the effectiveness of the proposed technique for vibration suppression and study its robustness to system parameter variations, including actuator placement.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10841v1">üìÑ Download PDF</a></p><hr><h3 id=decision-feedback-aided-known-interference-cancellationhttpsarxivorgabs251210833v1><a href=https://arxiv.org/abs/2512.10833v1>Decision Feedback-Aided Known-Interference Cancellation</a><a hidden class=anchor aria-hidden=true href=#decision-feedback-aided-known-interference-cancellationhttpsarxivorgabs251210833v1>#</a></h3><p><strong>Authors:</strong> Karel P√§rlin, Aaron Byman, Tommi Meril√§inen, Taneli Riihonen
<strong>Venue:</strong> arXiv (2025)</p><p>Known-interference cancellation (KIC) in combination with cooperative jamming can be used to provide covertness and security to wireless communications at the physical layer. However, since the signal of interest (SI) of a wireless communication system acts as estimation noise, i.e., interference, to KIC, the SI limits the extent to which the known interference (KI) can be canceled and that in turn limits the throughput of the wireless communication system that is being hidden or secured. In this letter, we analyze a decision feedback-aided known-interference cancellation (DF-KIC) structure in which both the KI and SI are canceled iteratively and successively. Measurement results demonstrate that introducing decision feedback to KIC improves its KI cancellation capability and hence increases the wireless communication system&rsquo;s useful throughput, albeit at the expense of a higher computational load.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10833v1">üìÑ Download PDF</a></p><hr><h3 id=identifiable-factor-analysis-for-mixed-continuous-and-binary-variables-based-on-the-gaussian-grassmann-distributionhttpsarxivorgabs251210804v1><a href=https://arxiv.org/abs/2512.10804v1>Identifiable factor analysis for mixed continuous and binary variables based on the Gaussian-Grassmann distribution</a><a hidden class=anchor aria-hidden=true href=#identifiable-factor-analysis-for-mixed-continuous-and-binary-variables-based-on-the-gaussian-grassmann-distributionhttpsarxivorgabs251210804v1>#</a></h3><p><strong>Authors:</strong> Takashi Arai
<strong>Venue:</strong> arXiv (2025)</p><p>We develop a factor analysis for mixed continuous and binary observed variables. To this end, we utilized a recently developed multivariate probability distribution for mixed-type random variables, the Gaussian-Grassmann distribution. In the proposed factor analysis, marginalization over latent variables can be performed analytically, yielding an analytical expression for the distribution of the observed variables. This analytical tractability allows model parameters to be estimated using standard gradient-based optimization techniques. We also address improper solutions associated with maximum likelihood factor analysis. We propose a prescription to avoid improper solutions by imposing a constraint that row vectors of the factor loading matrix have the same norm for all features. Then, we prove that the proposed factor analysis is identifiable under the norm constraint. We demonstrate the validity of this norm constraint prescription and numerically verified the model&rsquo;s identifiability using both real and synthetic datasets. We also compare the proposed model with quantification method and found that the proposed model achieves better reproducibility of correlations than the quantification method.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10804v1">üìÑ Download PDF</a></p><hr><h2 id=-llm>üîç llm<a hidden class=anchor aria-hidden=true href=#-llm>#</a></h2><h3 id=alchemint-fine-grained-temporal-control-for-multi-reference-consistent-video-generationhttpsarxivorgabs251210943v1><a href=https://arxiv.org/abs/2512.10943v1>AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation</a><a hidden class=anchor aria-hidden=true href=#alchemint-fine-grained-temporal-control-for-multi-reference-consistent-video-generationhttpsarxivorgabs251210943v1>#</a></h3><p><strong>Authors:</strong> Sharath Girish, Viacheslav Ivanov, Tsai-Shien Chen, Hao Chen, Aliaksandr Siarohin, Sergey Tulyakov
<strong>Venue:</strong> arXiv (2025)</p><p>Recent advances in subject-driven video generation with large diffusion models have enabled personalized content synthesis conditioned on user-provided subjects. However, existing methods lack fine-grained temporal control over subject appearance and disappearance, which are essential for applications such as compositional video synthesis, storyboarding, and controllable animation. We propose AlcheMinT, a unified framework that introduces explicit timestamps conditioning for subject-driven video generation. Our approach introduces a novel positional encoding mechanism that unlocks the encoding of temporal intervals, associated in our case with subject identities, while seamlessly integrating with the pretrained video generation model positional embeddings. Additionally, we incorporate subject-descriptive text tokens to strengthen binding between visual identity and video captions, mitigating ambiguity during generation. Through token-wise concatenation, AlcheMinT avoids any additional cross-attention modules and incurs negligible parameter overhead. We establish a benchmark evaluating multiple subject identity preservation, video fidelity, and temporal adherence. Experimental results demonstrate that AlcheMinT achieves visual quality matching state-of-the-art video personalization methods, while, for the first time, enabling precise temporal control over multi-subject generation within videos. Project page is at <a href=https://snap-research.github.io/Video-AlcheMinT>https://snap-research.github.io/Video-AlcheMinT</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10943v1">üìÑ Download PDF</a></p><hr><h3 id=gaussianheadtalk-wobble-free-3d-talking-heads-with-audio-driven-gaussian-splattinghttpsarxivorgabs251210939v1><a href=https://arxiv.org/abs/2512.10939v1>GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting</a><a hidden class=anchor aria-hidden=true href=#gaussianheadtalk-wobble-free-3d-talking-heads-with-audio-driven-gaussian-splattinghttpsarxivorgabs251210939v1>#</a></h3><p><strong>Authors:</strong> Madhav Agarwal, Mingtian Zhang, Laura Sevilla-Lara, Steven McDonagh
<strong>Venue:</strong> arXiv (2025)</p><p>Speech-driven talking heads have recently emerged and enable interactive avatars. However, real-world applications are limited, as current methods achieve high visual fidelity but slow or fast yet temporally unstable. Diffusion methods provide realistic image generation, yet struggle with oneshot settings. Gaussian Splatting approaches are real-time, yet inaccuracies in facial tracking, or inconsistent Gaussian mappings, lead to unstable outputs and video artifacts that are detrimental to realistic use cases. We address this problem by mapping Gaussian Splatting using 3D Morphable Models to generate person-specific avatars. We introduce transformer-based prediction of model parameters, directly from audio, to drive temporal consistency. From monocular video and independent audio speech inputs, our method enables generation of real-time talking head videos where we report competitive quantitative and qualitative performance.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10939v1">üìÑ Download PDF</a></p><hr><h3 id=stronger-normalization-free-transformershttpsarxivorgabs251210938v1><a href=https://arxiv.org/abs/2512.10938v1>Stronger Normalization-Free Transformers</a><a hidden class=anchor aria-hidden=true href=#stronger-normalization-free-transformershttpsarxivorgabs251210938v1>#</a></h3><p><strong>Authors:</strong> Mingzhi Chen, Taiming Lu, Jiachen Zhu, Mingjie Sun, Zhuang Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Although normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches normalization-level performance; this work seeks further for function designs that can surpass it. We first study how the intrinsic properties of point-wise functions influence training and performance. Building on these findings, we conduct a large-scale search for a more effective function design. Through this exploration, we introduce $\mathrm{Derf}(x) = \mathrm{erf}(Œ±x + s)$, where $\mathrm{erf}(x)$ is the rescaled Gaussian cumulative distribution function, and identify it as the most performant design. Derf outperforms LayerNorm, RMSNorm, and DyT across a wide range of domains, including vision (image recognition and generation), speech representation, and DNA sequence modeling. Our findings suggest that the performance gains of Derf largely stem from its improved generalization rather than stronger fitting capacity. Its simplicity and stronger performance make Derf a practical choice for normalization-free Transformer architectures.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10938v1">üìÑ Download PDF</a></p><hr><h3 id=empirical-evaluation-of-the-frank-wolfe-methods-for-constructing-white-box-adversarial-attackshttpsarxivorgabs251210936v1><a href=https://arxiv.org/abs/2512.10936v1>Empirical evaluation of the Frank-Wolfe methods for constructing white-box adversarial attacks</a><a hidden class=anchor aria-hidden=true href=#empirical-evaluation-of-the-frank-wolfe-methods-for-constructing-white-box-adversarial-attackshttpsarxivorgabs251210936v1>#</a></h3><p><strong>Authors:</strong> Kristina Korotkova, Aleksandr Katrutsa
<strong>Venue:</strong> arXiv (2025)</p><p>The construction of adversarial attacks for neural networks appears to be a crucial challenge for their deployment in various services. To estimate the adversarial robustness of a neural network, a fast and efficient approach is needed to construct adversarial attacks. Since the formalization of adversarial attack construction involves solving a specific optimization problem, we consider the problem of constructing an efficient and effective adversarial attack from a numerical optimization perspective. Specifically, we suggest utilizing advanced projection-free methods, known as modified Frank-Wolfe methods, to construct white-box adversarial attacks on the given input data. We perform a theoretical and numerical evaluation of these methods and compare them with standard approaches based on projection operations or geometrical intuition. Numerical experiments are performed on the MNIST and CIFAR-10 datasets, utilizing a multiclass logistic regression model, the convolutional neural networks (CNNs), and the Vision Transformer (ViT).</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10936v1">üìÑ Download PDF</a></p><hr><h3 id=asynchronous-reasoning-training-free-interactive-thinking-llmshttpsarxivorgabs251210931v1><a href=https://arxiv.org/abs/2512.10931v1>Asynchronous Reasoning: Training-Free Interactive Thinking LLMs</a><a hidden class=anchor aria-hidden=true href=#asynchronous-reasoning-training-free-interactive-thinking-llmshttpsarxivorgabs251210931v1>#</a></h3><p><strong>Authors:</strong> George Yakushev, Nataliia Babina, Masoud Vahid Dastgerdi, Vyacheslav Zhdanovskiy, Alina Shutova, Denis Kuznedelev
<strong>Venue:</strong> arXiv (2025)</p><p>Many state-of-the-art LLMs are trained to think before giving their answer. Reasoning can greatly improve language model capabilities and safety, but it also makes them less interactive: given a new input, a model must stop thinking before it can respond. Real-world use cases such as voice-based or embedded assistants require an LLM agent to respond and adapt to additional information in real time, which is incompatible with sequential interactions. In contrast, humans can listen, think, and act asynchronously: we begin thinking about the problem while reading it and continue thinking while formulating the answer. In this work, we augment LLMs capable of reasoning to operate in a similar way without additional training. Our method uses the properties of rotary embeddings to enable LLMs built for sequential interactions to simultaneously think, listen, and generate outputs. We evaluate our approach on math, commonsense, and safety reasoning and find that it can generate accurate thinking-augmented answers in real time, reducing time to first non-thinking token from minutes to &lt;= 5s. and the overall real-time delays by 6-11x.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10931v1">üìÑ Download PDF</a></p><hr><h3 id=flrw-embeddings-in-mathbbrn2-differential-geometry-and-conformal-photon-propagatorhttpsarxivorgabs251210901v1><a href=https://arxiv.org/abs/2512.10901v1>FLRW embeddings in $\mathbb{R}^{n+2}$, differential geometry and conformal photon propagator</a><a hidden class=anchor aria-hidden=true href=#flrw-embeddings-in-mathbbrn2-differential-geometry-and-conformal-photon-propagatorhttpsarxivorgabs251210901v1>#</a></h3><p><strong>Authors:</strong> E. Huguet, J. Queva, J. Renaud
<strong>Venue:</strong> arXiv (2025)</p><p>This paper introduces differential-geometric methods to study $n$-dimensional locally conformally flat spaces as submanifolds in $\mathbb{R}^{n+2}$. We derive explicit formulas relating intrinsic and ambient differential-geometric objects, including curvature tensors, the codifferential and laplacian operators. We apply this approach to Friedmann-Lema√Ætre-Robertson-Walker (FLRW) spaces using newfound embedding formulas, obtaining new and simplified expressions for the photon propagator in four dimensions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10901v1">üìÑ Download PDF</a></p><hr><h3 id=llms-can-assist-with-proposal-selection-at-large-user-facilitieshttpsarxivorgabs251210895v1><a href=https://arxiv.org/abs/2512.10895v1>LLMs Can Assist with Proposal Selection at Large User Facilities</a><a hidden class=anchor aria-hidden=true href=#llms-can-assist-with-proposal-selection-at-large-user-facilitieshttpsarxivorgabs251210895v1>#</a></h3><p><strong>Authors:</strong> Lijie Ding, Janell Thomson, Jon Taylor, Changwoo Do
<strong>Venue:</strong> arXiv (2025)</p><p>We explore how large language models (LLMs) can enhance the proposal selection process at large user facilities, offering a scalable, consistent, and cost-effective alternative to traditional human review. Proposal selection depends on assessing the relative strength among submitted proposals; however, traditional human scoring often suffers from weak inter-proposal correlations and is subject to reviewer bias and inconsistency. A pairwise preference-based approach is logically superior, providing a more rigorous and internally consistent basis for ranking, but its quadratic workload makes it impractical for human reviewers. We address this limitation using LLMs. Leveraging the uniquely well-curated proposals and publication records from three beamlines at the Spallation Neutron Source (SNS), Oak Ridge National Laboratory (ORNL), we show that the LLM rankings correlate strongly with the human rankings (Spearman $œÅ\simeq 0.2-0.8$, improving to $\geq 0.5$ after 10% outlier removal). Moreover, LLM performance is no worse than that of human reviewers in identifying proposals with high publication potential, while costing over two orders of magnitude less. Beyond ranking, LLMs enable advanced analyses that are challenging for humans, such as quantitative assessment of proposal similarity via embedding models, which provides information crucial for review committees.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10895v1">üìÑ Download PDF</a></p><hr><h2 id=-neuroscience>üîç neuroscience<a hidden class=anchor aria-hidden=true href=#-neuroscience>#</a></h2><h3 id=basic-requirements-for-potential-differences-across-solid--fluid-interfaceshttpsarxivorgabs251210859v1><a href=https://arxiv.org/abs/2512.10859v1>Basic requirements for potential differences across solid&ndash;fluid interfaces</a><a hidden class=anchor aria-hidden=true href=#basic-requirements-for-potential-differences-across-solid--fluid-interfaceshttpsarxivorgabs251210859v1>#</a></h3><p><strong>Authors:</strong> David Fertig, Adrian L. Usler, Mathijs Janssen
<strong>Venue:</strong> arXiv (2025)</p><p>At model water&ndash;vapor and water&ndash;solid interfaces, molecular ordering leads to charge oscillations and, thereby, to a spatially varying electrostatic potential. Atomistic simulations indicate that such ordering leads to an electric potential difference $œá$, the surface potential, of about $-0.5,\mathrm{V}$ across the first few molecular layers. Here, we calculate surface potentials at interfaces between a simple model fluids and a solid, with Molecular Dynamics simulations. The fluids are made up of either diatomic, dipolar molecules or a single Lennard-Jones particle with a dipole moment. All fluids show some structuring near the interface, but charge oscillations and a non-zero surface potential are present only for asymmetric molecules (unequal diameters of the atoms) or molecules with an off-center dipole. We condense this finding into the criterion that the geometric and dipolar centers of a molecule must differ for the fluid to exhibit a surface potential. Remarkably, while the solid&ndash;fluid interaction strength strongly affects the magnitude of charge oscillations, it hardly affects the potential drop $œá$. Further, our results demonstrate that changing the diameter of the smaller atom can flip the sign of the surface potential, thus highlighting the importance of steric effects.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10859v1">üìÑ Download PDF</a></p><hr><h3 id=labelfusion-learning-to-fuse-llms-and-transformer-classifiers-for-robust-text-classificationhttpsarxivorgabs251210793v1><a href=https://arxiv.org/abs/2512.10793v1>LabelFusion: Learning to Fuse LLMs and Transformer Classifiers for Robust Text Classification</a><a hidden class=anchor aria-hidden=true href=#labelfusion-learning-to-fuse-llms-and-transformer-classifiers-for-robust-text-classificationhttpsarxivorgabs251210793v1>#</a></h3><p><strong>Authors:</strong> Michael Schlee, Christoph Weisser, Timo Kivim√§ki, Melchizedek Mashiku, Benjamin Saefken
<strong>Venue:</strong> arXiv (2025)</p><p>LabelFusion is a fusion ensemble for text classification that learns to combine a traditional transformer-based classifier (e.g., RoBERTa) with one or more Large Language Models (LLMs such as OpenAI GPT, Google Gemini, or DeepSeek) to deliver accurate and cost-aware predictions across multi-class and multi-label tasks. The package provides a simple high-level interface (AutoFusionClassifier) that trains the full pipeline end-to-end with minimal configuration, and a flexible API for advanced users. Under the hood, LabelFusion integrates vector signals from both sources by concatenating the ML backbone&rsquo;s embeddings with the LLM-derived per-class scores &ndash; obtained through structured prompt-engineering strategies &ndash; and feeds this joint representation into a compact multi-layer perceptron (FusionMLP) that produces the final prediction. This learned fusion approach captures complementary strengths of LLM reasoning and traditional transformer-based classifiers, yielding robust performance across domains &ndash; achieving 92.4% accuracy on AG News and 92.3% on 10-class Reuters 21578 topic classification &ndash; while enabling practical trade-offs between accuracy, latency, and cost.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10793v1">üìÑ Download PDF</a></p><hr><h3 id=natural-language-interface-for-firewall-configurationhttpsarxivorgabs251210789v1><a href=https://arxiv.org/abs/2512.10789v1>Natural Language Interface for Firewall Configuration</a><a hidden class=anchor aria-hidden=true href=#natural-language-interface-for-firewall-configurationhttpsarxivorgabs251210789v1>#</a></h3><p><strong>Authors:</strong> F. Taghiyev, A. Aslanbayli
<strong>Venue:</strong> arXiv (2025)</p><p>This paper presents the design and prototype implementation of a natural language interface for configuring enterprise firewalls. The framework allows administrators to express access control policies in plain language, which are then translated into vendor specific configurations. A compact schema bound intermediate representation separates human intent from device syntax and in the current prototype compiles to Palo Alto PAN OS command line configuration while remaining extensible to other platforms. Large language models are used only as assistive parsers that generate typed intermediate representation objects, while compilation and enforcement remain deterministic. The prototype integrates three validation layers, namely a static linter that checks structural and vendor specific constraints, a safety gate that blocks overly permissive rules such as any to any allows, and a Batfish based simulator that validates configuration syntax and referential integrity against a synthetic device model. The paper describes the architecture, implementation, and test methodology on synthetic network context datasets and discusses how this approach can evolve into a scalable auditable and human centered workflow for firewall policy management.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10789v1">üìÑ Download PDF</a></p><hr><h3 id=performance-and-reliability-potential-of-bi_2o_2sebi_2seo_5-transistorshttpsarxivorgabs251210786v1><a href=https://arxiv.org/abs/2512.10786v1>Performance and reliability potential of Bi$_2$O$_2$Se/Bi$_2$SeO$_5$ transistors</a><a hidden class=anchor aria-hidden=true href=#performance-and-reliability-potential-of-bi_2o_2sebi_2seo_5-transistorshttpsarxivorgabs251210786v1>#</a></h3><p><strong>Authors:</strong> Mohammad Rasool Davoudi, Mina Bahrami, Axel Verdianu, Pedram Khakbaz, Dominic Waldhoer, Mahdi Pourfath, Alexander Karl, Christoph Wilhelmer, Yichi Zhang, Junchuan Tang, Aftab Nazir, Ye Li, Xiaoying Gao, Congwei Tan, Yu Zhang, Changze Liu, Hailin Peng, Theresia Knobloch, Tibor Grasser
<strong>Venue:</strong> arXiv (2025)</p><p>While 2D materials have enormous potential for future device technologies, many challenges must be overcome before they can be deployed at an industrial scale. One of these challenges is identifying the right semiconductor/insulator combination that ensures high performance, stability, and reliability. In contrast to conventional 2D interfaces, which suffer from van der Waals gaps or covalent bonding issues, zippered structures such as the high-mobility 2D semiconductor Bi$_2$O$_2$Se and its native high-$Œ∫$ oxide Bi$_2$SeO$_5$ offer high-quality interfaces, good scalability, and excellent device performance. While most prior work has focused mainly on basic device behavior, here we also thoroughly assess the stability and reliability of this material system using a multiscale approach that integrates electrical characterization, density functional theory, and TCAD simulations, linking atomistic states to device-scale reliability. By analyzing four transistor design generations (top-gated, fin, and two gate-all-around FETs), we provide realistic predictions for how this system performs at the ultimate scaling limit. We identify oxygen-related defects in the oxide as the main contributors to hysteresis and recoverable threshold shifts, and we propose mitigation strategies through encapsulation or oxygen-rich annealing. Benchmarking the extracted material parameters against IRDS 2037 requirements, we demonstrate that Bi$_2$O$_2$Se/Bi$_2$SeO$_5$ transistors can achieve high drain and low gate currents at ultra-scaled conditions. These findings position this material system as a technologically credible and manufacturing-relevant pathway for future nanoelectronics.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10786v1">üìÑ Download PDF</a></p><hr><h3 id=epitaxial-srsn-ge_xti_1-xo_3-buffer-layers-for-continuous-strain-engineering-on-srtio_3-substrateshttpsarxivorgabs251210609v1><a href=https://arxiv.org/abs/2512.10609v1>Epitaxial Sr(Sn, Ge)$<em>{x}$Ti$</em>{1-x}$O$<em>{3}$ buffer layers for continuous strain engineering on SrTiO$</em>{3}$ substrates</a><a hidden class=anchor aria-hidden=true href=#epitaxial-srsn-ge_xti_1-xo_3-buffer-layers-for-continuous-strain-engineering-on-srtio_3-substrateshttpsarxivorgabs251210609v1>#</a></h3><p><strong>Authors:</strong> Ruben Hamming-Green, Ewout van der Veer, Beatriz Noheda
<strong>Venue:</strong> arXiv (2025)</p><p>Epitaxial strain plays a key role in determining the structure and functionality of thin films, with the choice of substrate being traditionally used to control the magnitude of the applied strain. However, even in the large family of perovskite materials, this allows for only a limited, discrete set of strain states to be achieved. Here we report on an approach to controlling epitaxial strain for the growth of perovskite materials by involving a single SrTiO$<em>{3}$ substrate (the most available perovskite in single crystal form) and a buffer layer that consists of the solid solution Sr(Sn, Ge)$</em>{x}$Ti$<em>{1-x}$O$</em>{3}$, of which the lattice parameter can be tuned in a continuous fashion, from 3.880 √Ö up to 4.007 √Ö, while maintaining coherent epitaxial growth on SrTiO$<em>{3}$ with high quality interfaces. Using a BaTiO$</em>{3}$ overlayer as a model system, we show that changes to the buffer layer composition, i.e. increase of in-plane lattice parameter, change the strain state of BaTiO$_{3}$ from fully relaxed, through highly compressively strained, to an exotic state showing &lsquo;inverted&rsquo; epitaxy in which the buffer layer is relaxed from the substrate but lattice matched to the overlayer.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10609v1">üìÑ Download PDF</a></p><hr><h2 id=-data_resources>üîç data_resources<a hidden class=anchor aria-hidden=true href=#-data_resources>#</a></h2><h3 id=from-data-scarcity-to-data-care-reimagining-language-technologies-for-serbian-and-other-low-resource-languageshttpsarxivorgabs251210630v1><a href=https://arxiv.org/abs/2512.10630v1>From Data Scarcity to Data Care: Reimagining Language Technologies for Serbian and other Low-Resource Languages</a><a hidden class=anchor aria-hidden=true href=#from-data-scarcity-to-data-care-reimagining-language-technologies-for-serbian-and-other-low-resource-languageshttpsarxivorgabs251210630v1>#</a></h3><p><strong>Authors:</strong> Smiljana Antonijevic Ubois
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models are commonly trained on dominant languages like English, and their representation of low resource languages typically reflects cultural and linguistic biases present in the source language materials. Using the Serbian language as a case, this study examines the structural, historical, and sociotechnical factors shaping language technology development for low resource languages in the AI age. Drawing on semi structured interviews with ten scholars and practitioners, including linguists, digital humanists, and AI developers, it traces challenges rooted in historical destruction of Serbian textual heritage, intensified by contemporary issues that drive reductive, engineering first approaches prioritizing functionality over linguistic nuance. These include superficial transliteration, reliance on English-trained models, data bias, and dataset curation lacking cultural specificity. To address these challenges, the study proposes Data Care, a framework grounded in CARE principles (Collective Benefit, Authority to Control, Responsibility, and Ethics), that reframes bias mitigation from a post hoc technical fix to an integral component of corpus design, annotation, and governance, and positions Data Care as a replicable model for building inclusive, sustainable, and culturally grounded language technologies in contexts where traditional LLM development reproduces existing power imbalances and cultural blind spots.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10630v1">üìÑ Download PDF</a></p><hr><h3 id=semantic-reconstruction-of-adversarial-plagiarism-a-context-aware-framework-for-detecting-and-restoring-tortured-phrases-in-scientific-literaturehttpsarxivorgabs251210435v1><a href=https://arxiv.org/abs/2512.10435v1>Semantic Reconstruction of Adversarial Plagiarism: A Context-Aware Framework for Detecting and Restoring &ldquo;Tortured Phrases&rdquo; in Scientific Literature</a><a hidden class=anchor aria-hidden=true href=#semantic-reconstruction-of-adversarial-plagiarism-a-context-aware-framework-for-detecting-and-restoring-tortured-phrases-in-scientific-literaturehttpsarxivorgabs251210435v1>#</a></h3><p><strong>Authors:</strong> Agniva Maiti, Prajwal Panth, Suresh Chandra Satapathy
<strong>Venue:</strong> arXiv (2025)</p><p>The integrity and reliability of scientific literature is facing a serious threat by adversarial text generation techniques, specifically from the use of automated paraphrasing tools to mask plagiarism. These tools generate &ldquo;tortured phrases&rdquo;, statistically improbable synonyms (e.g. &ldquo;counterfeit consciousness&rdquo; for &ldquo;artificial intelligence&rdquo;), that preserve the local grammar while obscuring the original source. Most existing detection methods depend heavily on static blocklists or general-domain language models, which suffer from high false-negative rates for novel obfuscations and cannot determine the source of the plagiarized content. In this paper, we propose Semantic Reconstruction of Adversarial Plagiarism (SRAP), a framework designed not only to detect these anomalies but to mathematically recover the original terminology. We use a two-stage architecture: (1) statistical anomaly detection with a domain-specific masked language model (SciBERT) using token-level pseudo-perplexity, and (2) source-based semantic reconstruction using dense vector retrieval (FAISS) and sentence-level alignment (SBERT). Experiments on a parallel corpus of adversarial scientific text show that while zero-shot baselines fail completely (0.00 percent restoration accuracy), our retrieval-augmented approach achieves 23.67 percent restoration accuracy, significantly outperforming baseline methods. We also show that static decision boundaries are necessary for robust detection in jargon-heavy scientific text, since dynamic thresholding fails under high variance. SRAP enables forensic analysis by linking obfuscated expressions back to their most probable source documents.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10435v1">üìÑ Download PDF</a></p><hr><h3 id=privtune-efficient-and-privacy-preserving-fine-tuning-of-large-language-models-via-device-cloud-collaborationhttpsarxivorgabs251208809v1><a href=https://arxiv.org/abs/2512.08809v1>PrivTune: Efficient and Privacy-Preserving Fine-Tuning of Large Language Models via Device-Cloud Collaboration</a><a hidden class=anchor aria-hidden=true href=#privtune-efficient-and-privacy-preserving-fine-tuning-of-large-language-models-via-device-cloud-collaborationhttpsarxivorgabs251208809v1>#</a></h3><p><strong>Authors:</strong> Yi Liu, Weixiang Han, Chengjun Cai, Xingliang Yuan, Cong Wang
<strong>Venue:</strong> arXiv (2025)</p><p>With the rise of large language models, service providers offer language models as a service, enabling users to fine-tune customized models via uploaded private datasets. However, this raises concerns about sensitive data leakage. Prior methods, relying on differential privacy within device-cloud collaboration frameworks, struggle to balance privacy and utility, exposing users to inference attacks or degrading fine-tuning performance. To address this, we propose PrivTune, an efficient and privacy-preserving fine-tuning framework via Split Learning (SL). The key idea of PrivTune is to inject crafted noise into token representations from the SL bottom model, making each token resemble the $n$-hop indirect neighbors. PrivTune formulates this as an optimization problem to compute the optimal noise vector, aligning with defense-utility goals. On this basis, it then adjusts the parameters (i.e., mean) of the $d_œá$-Privacy noise distribution to align with the optimization direction and scales the noise according to token importance to minimize distortion. Experiments on five datasets (covering both classification and generation tasks) against three embedding inversion and three attribute inference attacks show that, using RoBERTa on the Stanford Sentiment Treebank dataset, PrivTune reduces the attack success rate to 10% with only a 3.33% drop in utility performance, outperforming state-of-the-art baselines.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.08809v1">üìÑ Download PDF</a></p><hr><h2 id=-emotion_language>üîç emotion_language<a hidden class=anchor aria-hidden=true href=#-emotion_language>#</a></h2><h3 id=computational-emotion-analysis-with-multimodal-llms-current-evidence-on-an-emerging-methodological-opportunityhttpsarxivorgabs251210882v1><a href=https://arxiv.org/abs/2512.10882v1>Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity</a><a hidden class=anchor aria-hidden=true href=#computational-emotion-analysis-with-multimodal-llms-current-evidence-on-an-emerging-methodological-opportunityhttpsarxivorgabs251210882v1>#</a></h3><p><strong>Authors:</strong> Hauke Licht
<strong>Venue:</strong> arXiv (2025)</p><p>Emotions are central to politics and analyzing their role in political communication has a long tradition. As research increasingly leverages audio-visual materials to analyze the display of emotions, the emergence of multimodal generative AI promises great advances. However, we lack evidence about the effectiveness of multimodal AI in emotion analysis. This paper addresses this gap by evaluating current multimodal large language models (mLLMs) in video-based analysis of emotional arousal in two complementary data sets of human-labeled video recordings. I find that under ideal circumstances, mLLMs&rsquo; emotional arousal ratings are highly reliable and show little to know indication of demographic bias. However, in recordings of speakers in real-world parliamentary debates, mLLMs&rsquo; arousal ratings fail to deliver on this promise with potential negative consequences for downstream statistical inferences. This study therefore underscores the need for continued, thorough evaluation of emerging generative AI methods in political analysis and contributes a suitable replicable framework.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10882v1">üìÑ Download PDF</a></p><hr><h3 id=quantifying-emotional-tone-in-tolkiens-the-hobbit-dialogue-sentiment-analysis-with-regex-nrc-vad-and-pythonhttpsarxivorgabs251210865v1><a href=https://arxiv.org/abs/2512.10865v1>Quantifying Emotional Tone in Tolkien&rsquo;s The Hobbit: Dialogue Sentiment Analysis with RegEx, NRC-VAD, and Python</a><a hidden class=anchor aria-hidden=true href=#quantifying-emotional-tone-in-tolkiens-the-hobbit-dialogue-sentiment-analysis-with-regex-nrc-vad-and-pythonhttpsarxivorgabs251210865v1>#</a></h3><p><strong>Authors:</strong> Lilin Qiu
<strong>Venue:</strong> arXiv (2025)</p><p>This study analyzes the emotional tone of dialogue in J. R. R. Tolkien&rsquo;s The Hobbit (1937) using computational text analysis. Dialogue was extracted with regular expressions, then preprocessed, and scored using the NRC-VAD lexicon to quantify emotional dimensions. The results show that the dialogue maintains a generally positive (high valence) and calm (low arousal) tone, with a gradually increasing sense of agency (dominance) as the story progresses. These patterns reflect the novel&rsquo;s emotional rhythm: moments of danger and excitement are regularly balanced by humor, camaraderie, and relief. Visualizations &ndash; including emotional trajectory graphs and word clouds &ndash; highlight how Tolkien&rsquo;s language cycles between tension and comfort. By combining computational tools with literary interpretation, this study demonstrates how digital methods can uncover subtle emotional structures in literature, revealing the steady rhythm and emotional modulation that shape the storytelling in The Hobbit.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10865v1">üìÑ Download PDF</a></p><hr><h3 id=self-ensemble-post-learning-for-noisy-domain-generalizationhttpsarxivorgabs251210818v1><a href=https://arxiv.org/abs/2512.10818v1>Self-Ensemble Post Learning for Noisy Domain Generalization</a><a hidden class=anchor aria-hidden=true href=#self-ensemble-post-learning-for-noisy-domain-generalizationhttpsarxivorgabs251210818v1>#</a></h3><p><strong>Authors:</strong> Wang Lu, Jindong Wang
<strong>Venue:</strong> arXiv (2025)</p><p>While computer vision and machine learning have made great progress, their robustness is still challenged by two key issues: data distribution shift and label noise. When domain generalization (DG) encounters noise, noisy labels further exacerbate the emergence of spurious features in deep layers, i.e. spurious feature enlargement, leading to a degradation in the performance of existing algorithms. This paper, starting from domain generalization, explores how to make existing methods rework when meeting noise. We find that the latent features inside the model have certain discriminative capabilities, and different latent features focus on different parts of the image. Based on these observations, we propose the Self-Ensemble Post Learning approach (SEPL) to diversify features which can be leveraged. Specifically, SEPL consists of two parts: feature probing training and prediction ensemble inference. It leverages intermediate feature representations within the model architecture, training multiple probing classifiers to fully exploit the capabilities of pre-trained models, while the final predictions are obtained through the integration of outputs from these diverse classification heads. Considering the presence of noisy labels, we employ semi-supervised algorithms to train probing classifiers. Given that different probing classifiers focus on different areas, we integrate their predictions using a crowdsourcing inference approach. Extensive experimental evaluations demonstrate that the proposed method not only enhances the robustness of existing methods but also exhibits significant potential for real-world applications with high flexibility.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10818v1">üìÑ Download PDF</a></p><hr><h3 id=sparseswaps-tractable-llm-pruning-mask-refinement-at-scalehttpsarxivorgabs251210922v1><a href=https://arxiv.org/abs/2512.10922v1>SparseSwaps: Tractable LLM Pruning Mask Refinement at Scale</a><a hidden class=anchor aria-hidden=true href=#sparseswaps-tractable-llm-pruning-mask-refinement-at-scalehttpsarxivorgabs251210922v1>#</a></h3><p><strong>Authors:</strong> Max Zimmer, Christophe Roux, Moritz Wagner, Deborah Hendrych, Sebastian Pokutta
<strong>Venue:</strong> arXiv (2025)</p><p>The resource requirements of Neural Networks can be significantly reduced through pruning &ndash; the removal of seemingly less important parameters. However, with the rise of Large Language Models (LLMs), full retraining to recover pruning-induced performance degradation is often prohibitive and classical approaches such as global magnitude pruning are suboptimal on Transformer architectures. State-of-the-art methods hence solve a layer-wise mask selection problem, the problem of finding a pruning mask which minimizes the per-layer pruning error on a small set of calibration data. Exactly solving this problem to optimality using Integer Programming (IP) solvers is computationally infeasible due to its combinatorial nature and the size of the search space, and existing approaches therefore rely on approximations or heuristics. In this work, we demonstrate that the mask selection problem can be made drastically more tractable at LLM scale. To that end, we decouple the rows by enforcing equal sparsity levels per row. This allows us to derive optimal 1-swaps (exchanging one kept and one pruned weight) that can be computed efficiently using the Gram matrix of the calibration data. Using these observations, we propose a tractable and simple 1-swap algorithm that warm starts from any pruning mask, runs efficiently on GPUs at LLM scale, and is essentially hyperparameter-free. We demonstrate that our approach reduces per-layer pruning error by up to 60% over Wanda (Sun et al., 2023) and consistently improves perplexity and zero-shot accuracy across state-of-the-art GPT architectures.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10922v1">üìÑ Download PDF</a></p><hr><h3 id=qubit-decoherence-in-dissipative-two-photon-resonator-real-time-instantons-and-wigner-functionhttpsarxivorgabs251210921v1><a href=https://arxiv.org/abs/2512.10921v1>Qubit decoherence in dissipative two-photon resonator: real-time instantons and Wigner function</a><a hidden class=anchor aria-hidden=true href=#qubit-decoherence-in-dissipative-two-photon-resonator-real-time-instantons-and-wigner-functionhttpsarxivorgabs251210921v1>#</a></h3><p><strong>Authors:</strong> V. Yu. Mylnikov, S. O. Potashin, Alex Kamenev
<strong>Venue:</strong> arXiv (2025)</p><p>We study the quantum dynamics of a single bosonic cavity subject to two-photon driving and two-photon dissipation in the presence of finite detuning. Exploiting a hidden time-reversal symmetry, the Wigner representation and the WKB method, we introduce an effective phase-space potential for description of the steady state. It reveals two attracting points, which are metastable due to quantum fluctuations. By employing the Keldysh real-time path integral formalism, we compute the instanton trajectory governing the quantum activation process between these attractors and establish a fundamental connection with the Wigner representation. This relation unifies the steady-state phase-space description with dynamical quantum activation processes. We also derive an analytical expression for the decoherence rate of the system. Our work provides a coherent theoretical framework for analyzing quantum bistability, metastability, and decoherence in driven-dissipative nonlinear resonators, with direct implications for the design of bosonic qubits and quantum information processing.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10921v1">üìÑ Download PDF</a></p><hr><h3 id=global-stabilization-of-the-planar-ricker-system-with-noisy-pbchttpsarxivorgabs251210919v1><a href=https://arxiv.org/abs/2512.10919v1>Global stabilization of the planar Ricker system with noisy PBC</a><a hidden class=anchor aria-hidden=true href=#global-stabilization-of-the-planar-ricker-system-with-noisy-pbchttpsarxivorgabs251210919v1>#</a></h3><p><strong>Authors:</strong> Elena Braverman, Alexandra Rodkina
<strong>Venue:</strong> arXiv (2025)</p><p>We apply Prediction-Based control (PBC) in order to stabilize globally a positive equilibrium of a planar Ricker&rsquo;s equation. We construct a closed invariant set in a strictly positive domain for the controlled map and derive conditions on control parameters ensuring that the increments of a specially constructed Lyapunov function are nonpositive on this set. By stochastic perturbation of the parameters we decrease the average values of controls providing global, as well as local, stabilization. Computer simulations illustrate our results.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10919v1">üìÑ Download PDF</a></p><hr><h3 id=pair-density-wave-in-quarter-metals-from-a-repulsive-fermionic-interaction-in-graphene-heterostructures-a-renormalization-group-studyhttpsarxivorgabs251210944v1><a href=https://arxiv.org/abs/2512.10944v1>Pair-density-wave in quarter-metals from a repulsive fermionic interaction in graphene heterostructures: A renormalization group study</a><a hidden class=anchor aria-hidden=true href=#pair-density-wave-in-quarter-metals-from-a-repulsive-fermionic-interaction-in-graphene-heterostructures-a-renormalization-group-studyhttpsarxivorgabs251210944v1>#</a></h3><p><strong>Authors:</strong> Sk Asrap Murshed, Bitan Roy
<strong>Venue:</strong> arXiv (2025)</p><p>Electronic bands in chirally stacked $n$ layer carbon-based honeycomb heterostructures, encompassing rhombohedral ($n \geq 3$), Bernal bilayer ($n=2$), and monolayer ($n=1$) graphene, possess four-fold valley and spin degeneracy. Such systems with $n \geq 2$, when subject to external perpendicular electric displacement fields, feature a fully degenerate metal at high doping, a spin non-degenerate but valley degenerate half-metal at moderate doping, and a non-degenerate quarter-metal at low doping. Due to the fully polarized nature of the quasiparticles in the quarter-metal, realized around one particular valley otherwise chosen spontaneously, it can sustain a single local superconducting ground state, representing a pair-density-wave that is chiral and odd parity in nature. From a leading order renormalization group analysis, here we show that repulsive density-density interaction among such polarized fermionic excitations can foster the pair-density-wave phase at low temperatures. Possible connections with experimentally observed superconducting states in the close vicinity of the quarter-metal in some members of such graphene heterostructures family are discussed.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10944v1">üìÑ Download PDF</a></p><hr><h3 id=shaping-chaos-in-bilayer-graphene-cavitieshttpsarxivorgabs251210914v1><a href=https://arxiv.org/abs/2512.10914v1>Shaping chaos in bilayer graphene cavities</a><a hidden class=anchor aria-hidden=true href=#shaping-chaos-in-bilayer-graphene-cavitieshttpsarxivorgabs251210914v1>#</a></h3><p><strong>Authors:</strong> Jucheng Lin, Yicheng Zhuang, Anton M. Graf, Joonas Keski-Rahkonen, Eric J. Heller
<strong>Venue:</strong> arXiv (2025)</p><p>Bilayer graphene (BLG) cavities, where electrons are confined in finite graphene flakes, provide a suitable platform to study quantum chaotic phenomena in condensed matter systems due to the trigonal warping of the Fermi surface. Here, we investigate the effect of the misalignment between the BLG lattice and the cavity geometry, introduced by rotating the boundary relative to the lattice, which can drive the system towards chaos. Based on a tight-binding model, eigenenergy level statistics reveals that rotation leads to level repulsion following Wigner-Dyson statistics, while corresponding eigenstate analysis indicates a transition from near-integrability to spatially uncorrelated random waves. Analysis of the semiclassical ray-dynamics with the trigonal-warped dispersion unveils an ergodic phase space structure, providing a quantum-classical correspondence of the onset of chaos. These findings establish an avenue to quantum chaotic phenomena in BLG cavities with potential applications in quantum device engineering.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10914v1">üìÑ Download PDF</a></p><hr><h3 id=observability-inequality-for-the-von-neumann-equation-in-crystalshttpsarxivorgabs251210897v1><a href=https://arxiv.org/abs/2512.10897v1>Observability inequality for the von Neumann equation in crystals</a><a hidden class=anchor aria-hidden=true href=#observability-inequality-for-the-von-neumann-equation-in-crystalshttpsarxivorgabs251210897v1>#</a></h3><p><strong>Authors:</strong> Thomas Borsoni, Virginie Ehrlacher
<strong>Venue:</strong> arXiv (2025)</p><p>We provide a quantitative observability inequality for the von Neumann equation on $\mathbb{R}^d$ in the crystal setting, uniform in small $\hbar$. Following the method of Golse and Paul (2022) proving this result in the non-crystal setting, the method relies on a stability argument between the quantum (von Neumann) and classical (Liouville) dynamics and uses an optimal transport-like pseudo-distance between quantum and classical densities. Our contribution yields in the adaptation of all the required tools to the periodic setting, relying on the Bloch decomposition, notions of periodic Schr√∂dinger coherent state, periodic T√∂plitz operator and periodic Husimi densities.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10897v1">üìÑ Download PDF</a></p><hr><h3 id=weak-gravity-conjecture-in-the-sky-gravitational-waves-from-preheating-in-einstein-maxwell-scalar-efthttpsarxivorgabs251210890v1><a href=https://arxiv.org/abs/2512.10890v1>Weak Gravity Conjecture in the sky: gravitational waves from preheating in Einstein-Maxwell-Scalar EFT</a><a hidden class=anchor aria-hidden=true href=#weak-gravity-conjecture-in-the-sky-gravitational-waves-from-preheating-in-einstein-maxwell-scalar-efthttpsarxivorgabs251210890v1>#</a></h3><p><strong>Authors:</strong> Jiaxin Cheng, Anna Tokareva
<strong>Venue:</strong> arXiv (2025)</p><p>The effective field theory (EFT) concept provides a necessary tool for obtaining general predictions of low-energy theory valid below its unitarity-breaking scale (cutoff scale). Early Universe inflation and subsequent reheating could be a unique setup for testing potentially observable effects coming from the derivative expansion of the corresponding EFT around the flat space vacuum. In this work, we consider an EFT describing perturbative reheating dominated by the decay of inflaton to photons caused by the dimension-5 operator $œÜF_{ŒºŒΩ} F^{ŒºŒΩ}$. We compute the graviton production during reheating and high frequency gravitational wave signal due to the bremsstrahlung effect in the presence of $R_{ŒºŒΩŒªœÅ}F^{ŒºŒΩ} F^{ŒªœÅ}$ operator. It may lead to the dominant contribution at high momenta if the EFT cutoff is lower than the Planck mass. Assuming the general consequences of the unitarity and causality constraints, which imply that all EFT operators should be present, and be suppressed by the scales following from the dimension analysis, we obtain the observational constraints (CMB bound for the dark radiation) on the mass of the inflaton and UV cutoff of gravity. We find that for the typical parameters of large field inflation models, the gravitational cutoff scale cannot be lower than $10^{15}$ GeV.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10890v1">üìÑ Download PDF</a></p><hr><h3 id=twin-paradox-and-entanglementhttpsarxivorgabs251210908v1><a href=https://arxiv.org/abs/2512.10908v1>Twin-paradox and Entanglement</a><a hidden class=anchor aria-hidden=true href=#twin-paradox-and-entanglementhttpsarxivorgabs251210908v1>#</a></h3><p><strong>Authors:</strong> K. Hari, Subhajit Barman, Dawood Kothawala
<strong>Venue:</strong> arXiv (2025)</p><p>We study the quantum version of the classical twin paradox in special relativity by replacing the twins with quantum detectors, and studying the transitions and entanglement induced by coupling them to a quantum field. We show that the \textit{changes} in direction of acceleration leave imprints on detector responses and entanglement, inducing novel features which might have relevance in black hole spacetimes.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10908v1">üìÑ Download PDF</a></p><hr><h3 id=multi-granular-node-pruning-for-circuit-discoveryhttpsarxivorgabs251210903v1><a href=https://arxiv.org/abs/2512.10903v1>Multi-Granular Node Pruning for Circuit Discovery</a><a hidden class=anchor aria-hidden=true href=#multi-granular-node-pruning-for-circuit-discoveryhttpsarxivorgabs251210903v1>#</a></h3><p><strong>Authors:</strong> Muhammad Umair Haider, Hammad Rizwan, Hassan Sajjad, A. B. Siddique
<strong>Venue:</strong> arXiv (2025)</p><p>Circuit discovery aims to identify minimal subnetworks that are responsible for specific behaviors in large language models (LLMs). Existing approaches primarily rely on iterative edge pruning, which is computationally expensive and limited to coarse-grained units such as attention heads or MLP blocks, overlooking finer structures like individual neurons. We propose a node-level pruning framework for circuit discovery that addresses both scalability and granularity limitations. Our method introduces learnable masks across multiple levels of granularity, from entire blocks to individual neurons, within a unified optimization objective. Granularity-specific sparsity penalties guide the pruning process, allowing a comprehensive compression in a single fine-tuning run. Empirically, our approach identifies circuits that are smaller in nodes than those discovered by prior methods; moreover, we demonstrate that many neurons deemed important by coarse methods are actually irrelevant, while still maintaining task performance. Furthermore, our method has a significantly lower memory footprint, 5-10x, as it does not require keeping intermediate activations in the memory to work.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10903v1">üìÑ Download PDF</a></p><hr><h3 id=the-facts-leaderboard-a-comprehensive-benchmark-for-large-language-model-factualityhttpsarxivorgabs251210791v1><a href=https://arxiv.org/abs/2512.10791v1>The FACTS Leaderboard: A Comprehensive Benchmark for Large Language Model Factuality</a><a hidden class=anchor aria-hidden=true href=#the-facts-leaderboard-a-comprehensive-benchmark-for-large-language-model-factualityhttpsarxivorgabs251210791v1>#</a></h3><p><strong>Authors:</strong> Aileen Cheng, Alon Jacovi, Amir Globerson, Ben Golan, Charles Kwong, Chris Alberti, Connie Tao, Eyal Ben-David, Gaurav Singh Tomar, Lukas Haas, Yonatan Bitton, Adam Bloniarz, Aijun Bai, Andrew Wang, Anfal Siddiqui, Arturo Bajuelos Castillo, Aviel Atias, Chang Liu, Corey Fry, Daniel Balle, Deepanway Ghosal, Doron Kukliansky, Dror Marcus, Elena Gribovskaya, Eran Ofek, Honglei Zhuang, Itay Laish, Jan Ackermann, Lily Wang, Meg Risdal, Megan Barnes, Michael Fink, Mohamed Amin, Moran Ambar, Natan Potikha, Nikita Gupta, Nitzan Katz, Noam Velan, Ofir Roval, Ori Ram, Polina Zablotskaia, Prathamesh Bang, Priyanka Agrawal, Rakesh Ghiya, Sanjay Ganapathy, Simon Baumgartner, Sofia Erell, Sushant Prakash, Thibault Sellam, Vikram Rao, Xuanhui Wang, Yaroslav Akulov, Yulong Yang, Zhen Yang, Zhixin Lai, Zhongru Wu, Anca Dragan, Avinatan Hassidim, Fernando Pereira, Slav Petrov, Srinivasan Venkatachary, Tulsee Doshi, Yossi Matias, Sasha Goldshtein, Dipanjan Das
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce The FACTS Leaderboard, an online leaderboard suite and associated set of benchmarks that comprehensively evaluates the ability of language models to generate factually accurate text across diverse scenarios. The suite provides a holistic measure of factuality by aggregating the performance of models on four distinct sub-leaderboards: (1) FACTS Multimodal, which measures the factuality of responses to image-based questions; (2) FACTS Parametric, which assesses models&rsquo; world knowledge by answering closed-book factoid questions from internal parameters; (3) FACTS Search, which evaluates factuality in information-seeking scenarios, where the model must use a search API; and (4) FACTS Grounding (v2), which evaluates whether long-form responses are grounded in provided documents, featuring significantly improved judge models. Each sub-leaderboard employs automated judge models to score model responses, and the final suite score is an average of the four components, designed to provide a robust and balanced assessment of a model&rsquo;s overall factuality. The FACTS Leaderboard Suite will be actively maintained, containing both public and private splits to allow for external participation while guarding its integrity. It can be found at <a href=https://www.kaggle.com/benchmarks/google/facts>https://www.kaggle.com/benchmarks/google/facts</a> .</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10791v1">üìÑ Download PDF</a></p><hr><h3 id=chemical-enrichment-in-liners-from-manga-ii-characterizing-the-shape-of-their-radial-metallicity-gradientshttpsarxivorgabs251210769v1><a href=https://arxiv.org/abs/2512.10769v1>Chemical enrichment in LINERs from MaNGA. II. Characterizing the shape of their radial metallicity gradients</a><a hidden class=anchor aria-hidden=true href=#chemical-enrichment-in-liners-from-manga-ii-characterizing-the-shape-of-their-radial-metallicity-gradientshttpsarxivorgabs251210769v1>#</a></h3><p><strong>Authors:</strong> Borja P√©rez-D√≠az, Jos√© M. V√≠lchez, Enrique P√©rez Montero, Igor A. Zinchenko, Brian Tapia-Contreras, Patricia B. Tissera
<strong>Venue:</strong> arXiv (2025)</p><p>Chemical abundance radial gradients provide key information on how the processes that affect chemical enrichment of the gas-phase interstellar medium (ISM) act at different galaxy scales. Whereas in the last decades there has been an increase in the number of galaxies studied with integral field spectroscopy, there is still not a clear picture on a subsequent characterization of the chemical abundance radial gradients in galaxies hosting Active Galactic Nuclei (AGNs). This lack of analysis is even more accentuated in the case of low-ionization nuclear emission-line regions (LINERs). For the first time, we analyze the chemical abundance radial gradients in a sample of LINER-like galaxies, whose nuclear emission has been previously (Paper I) discussed. We use a sample of 97 galaxies from the Mapping Nearby Galaxies at Apache Point Observatory (MaNGA), whose nuclear regions show LINER-like emission. We use the open-source code HII-CHI-Mistry to estimate the chemical abundance ratios 12+log(O/H) and log(N/O) in the HII regions across the disks in our sample, as well as in the nuclear parts where the LINER-like activity dominates. To fit the radial profiles we use a piecewise methodology which uses a non-fixed number of breaks to find the best fit for the data. We obtain that majority of our sample of galaxies exhibits departures from the single linear gradient both in 12+log(O/H) and log(N/O) (as expected from the inside-out scenario). We investigate whether these departures are driven by galaxy properties (stellar mass, neutral gas mass, stellar velocity dispersion), finding not correlation at all. We also report that in most cases there is no correlation between the shape of the 12+log(O/H) and log(N/O) radial profiles. We propose a model in which AGN (feed)back, acting at different scales depending on the galaxy and its evolutionary stage, might be responsible for these departures.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10769v1">üìÑ Download PDF</a></p><hr><h3 id=signatures-of-star-formation-inside-galactic-outflowshttpsarxivorgabs251210924v1><a href=https://arxiv.org/abs/2512.10924v1>Signatures of star formation inside galactic outflows</a><a hidden class=anchor aria-hidden=true href=#signatures-of-star-formation-inside-galactic-outflowshttpsarxivorgabs251210924v1>#</a></h3><p><strong>Authors:</strong> Dily Duan Yi Ong, Francesco D&rsquo;Eugenio, Roberto Maiolino, Santiago Arribas, Francesco Belfiore, Enrica Bellocchi, Stefano Carniani, Sara Cazzoli, Giovanni Cresci, Andrew Fabian, Wako Ishibashi, Filippo Mannucci, Alessandro Marconi, Helen Russell, Eckhard Sturm, Giacomo Venturi
<strong>Venue:</strong> arXiv (2025)</p><p>Observations have suggested that galactic outflows contain substantial amounts of dense and clumpy molecular gas, creating favourable conditions for igniting star formation. Indeed, theoretical models and hydrodynamical simulations have suggested that stars could form within galactic outflows, representing a new mode of star-formation that differs significantly from the typical star formation in star forming discs. In this paper, we examine 12 local galaxies with powerful Active Galactic Nuclei and high star-formation rate using spectroscopic data from the X-shooter spectrograph at the Very Large Telescope. We investigate the excitation mechanism and physical properties of these outflows via spatially resolved diagnostic diagrams (along with tests to rule out contribution by shocks and external photoionisation). Out of the seven galaxies with clearly detected outflows, we find robust evidence for star formation within the outflow of one galaxy (IRAS 20551-4250), with two additional galaxies showing tentative signs (IRAS 13120-5453 and F13229-2934). Therefore, our findings support previous results that star formation inside outflows can be a relatively common phenomenon among these active galaxies and may have played an important role in the formation and evolution of the spheroidal component of galaxies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10924v1">üìÑ Download PDF</a></p><hr><h3 id=companioncast-a-multi-agent-conversational-ai-framework-with-spatial-audio-for-social-co-viewing-experienceshttpsarxivorgabs251210918v1><a href=https://arxiv.org/abs/2512.10918v1>CompanionCast: A Multi-Agent Conversational AI Framework with Spatial Audio for Social Co-Viewing Experiences</a><a hidden class=anchor aria-hidden=true href=#companioncast-a-multi-agent-conversational-ai-framework-with-spatial-audio-for-social-co-viewing-experienceshttpsarxivorgabs251210918v1>#</a></h3><p><strong>Authors:</strong> Yiyang Wang, Chen Chen, Tica Lin, Vishnu Raj, Josh Kimball, Alex Cabral, Josiah Hester
<strong>Venue:</strong> arXiv (2025)</p><p>Social presence is central to the enjoyment of watching content together, yet modern media consumption is increasingly solitary. We investigate whether multi-agent conversational AI systems can recreate the dynamics of shared viewing experiences across diverse content types. We present CompanionCast, a general framework for orchestrating multiple role-specialized AI agents that respond to video content using multimodal inputs, speech synthesis, and spatial audio. Distinctly, CompanionCast integrates an LLM-as-a-Judge module that iteratively scores and refines conversations across five dimensions (relevance, authenticity, engagement, diversity, personality consistency). We validate this framework through sports viewing, a domain with rich dynamics and strong social traditions, where a pilot study with soccer fans suggests that multi-agent interaction improves perceived social presence compared to solo viewing. We contribute: (1) a generalizable framework for orchestrating multi-agent conversations around multimodal video content, (2) a novel evaluator-agent pipeline for conversation quality control, and (3) exploratory evidence of increased social presence in AI-mediated co-viewing. We discuss challenges and future directions for applying this approach to diverse viewing contexts including entertainment, education, and collaborative watching experiences.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10918v1">üìÑ Download PDF</a></p><hr><h3 id=quantifying-displacement-a-gentrifications-consequence-via-persistent-homologyhttpsarxivorgabs251210753v1><a href=https://arxiv.org/abs/2512.10753v1>Quantifying displacement: a gentrification&rsquo;s consequence via persistent homology</a><a hidden class=anchor aria-hidden=true href=#quantifying-displacement-a-gentrifications-consequence-via-persistent-homologyhttpsarxivorgabs251210753v1>#</a></h3><p><strong>Authors:</strong> Rita Rodr√≠guez V√°zquez, Manuel Cuerno
<strong>Venue:</strong> arXiv (2025)</p><p>Gentrification is the process by which wealthier individuals move into a previously lower-income neighbourhood. Among the effects of this multi-faceted phenomenon are rising living costs, cultural and social changes-where local traditions, businesses, and community networks are replaced or diluted by new, more affluent lifestyles-and population displacement, where long-term, lower-income residents are priced out by rising rents and property taxes. Despite its relevance, quantifying displacement presents difficulties stemming from lack of information on motives for relocation and from the fact that a long time-span must be analysed: displacement is a gradual process (leases end or conditions change at different times), impossible to capture in one data snapshot. We introduce a novel tool to overcome these difficulties. Using only publicly available address change data, we construct four cubical complexes which simultaneously incorporate geographical and temporal information of people moving, and then analyse them building on Topological Data Analysis tools. Finally, we demonstrate the potential of this method through a 20-year case study of Madrid, Spain. The results reveal its ability to capture population displacement and to identify the specific neighbourhoods and years affected&ndash;patterns that cannot be inferred from raw address change data.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10753v1">üìÑ Download PDF</a></p><hr><h3 id=supporting-migration-policies-with-forecasts-illegal-border-crossings-in-europe-through-a-mixed-approachhttpsarxivorgabs251210633v1><a href=https://arxiv.org/abs/2512.10633v1>Supporting Migration Policies with Forecasts: Illegal Border Crossings in Europe through a Mixed Approach</a><a hidden class=anchor aria-hidden=true href=#supporting-migration-policies-with-forecasts-illegal-border-crossings-in-europe-through-a-mixed-approachhttpsarxivorgabs251210633v1>#</a></h3><p><strong>Authors:</strong> C. Bosco, U. Minora, D. de Rigo, J. Pingsdorf, R. Cortinovis
<strong>Venue:</strong> arXiv (2025)</p><p>This paper presents a mixed-methodology to forecast illegal border crossings in Europe across five key migratory routes, with a one-year time horizon. The methodology integrates machine learning techniques with qualitative insights from migration experts. This approach aims at improving the predictive capacity of data-driven models through the inclusion of a human-assessed covariate, an innovation that addresses challenges posed by sudden shifts in migration patterns and limitations in traditional datasets. The proposed methodology responds directly to the forecasting needs outlined in the EU Pact on Migration and Asylum, supporting the Asylum and Migration Management Regulation (AMMR). It is designed to provide policy-relevant forecasts that inform strategic decisions, early warning systems, and solidarity mechanisms among EU Member States. By joining data-driven modeling with expert judgment, this work aligns with existing academic recommendations and introduces a novel operational tool tailored for EU migration governance. The methodology is tested and validated with known data to demonstrate its applicability and reliability in migration-related policy context.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.10633v1">üìÑ Download PDF</a></p><hr></div><footer class=post-footer><ul class=post-tags></ul></footer><div><div class=pagination__title><span class=pagination__title-h style=font-size:20px>Comments</span><hr></div><div id=tcomment></div><script src=https://cdn.staticfile.org/twikoo/1.6.39/twikoo.all.min.js></script><script>twikoo.init({envId:"https://mangodb-theta.vercel.app/",el:"#tcomment",lang:"en-US",path:window.TWIKOO_MAGIC_PATH||window.location.pathname})</script></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://garyforreal.me/zh/>Gary's House</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span><div class=busuanzi-footer><span id=busuanzi_container_site_pv>Views: <span id=busuanzi_value_site_pv></span>
</span><span id=busuanzi_container_site_uv>Visitors: <span id=busuanzi_value_site_uv></span></span></div></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="Â§çÂà∂";function s(){t.innerHTML="Â∑≤Â§çÂà∂ÔºÅ",setTimeout(()=>{t.innerHTML="Â§çÂà∂"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>