<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Weekly Paper Notes - 2025-12-09 | Gary's House</title>
<meta name=keywords content><meta name=description content="Weekly Paper Notes
üîç multilingual
M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG
Authors: David Anugraha, Patrick Amadeus Irawan, Anshul Singh, En-Shiun Annie Lee, Genta Indra Winata
Venue: arXiv (2025)
Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts."><meta name=author content="Gary"><link rel=canonical href=https://garyforreal.me/zh/posts/paper/paper-2025-12-09-weekly/><meta name=google-site-verification content="XYZabc"><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><meta name=referrer content="no-referrer-when-downgrade"><link crossorigin=anonymous href=/assets/css/stylesheet.7e5251d8716d933fafcf3df70d7ecd02729661d6d232fc5dd0b8a85ef75e3409.css integrity="sha256-flJR2HFtkz+vzz33DX7NAnKWYdbSMvxd0LioXvdeNAk=" rel="preload stylesheet" as=style><link rel=icon href=https://garyforreal.me/img/Q.jpg><link rel=icon type=image/png sizes=16x16 href=https://garyforreal.me/img/Q.jpg><link rel=icon type=image/png sizes=32x32 href=https://garyforreal.me/img/Q.jpg><link rel=apple-touch-icon href=https://garyforreal.me/Q.jpg><link rel=mask-icon href=https://garyforreal.me/Q.jpg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://garyforreal.me/zh/posts/paper/paper-2025-12-09-weekly/><link rel=alternate hreflang=en href=https://garyforreal.me/en/posts/paper/paper-2025-12-09-weekly/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@200..900&display=swap" rel=stylesheet><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous referrerpolicy=no-referrer></script><meta property="og:title" content="Weekly Paper Notes - 2025-12-09"><meta property="og:description" content="Weekly Paper Notes
üîç multilingual
M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG
Authors: David Anugraha, Patrick Amadeus Irawan, Anshul Singh, En-Shiun Annie Lee, Genta Indra Winata
Venue: arXiv (2025)
Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts."><meta property="og:type" content="article"><meta property="og:url" content="https://garyforreal.me/zh/posts/paper/paper-2025-12-09-weekly/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-12-09T01:30:00+00:00"><meta property="article:modified_time" content="2025-12-09T01:30:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Weekly Paper Notes - 2025-12-09"><meta name=twitter:description content="Weekly Paper Notes
üîç multilingual
M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG
Authors: David Anugraha, Patrick Amadeus Irawan, Anshul Singh, En-Shiun Annie Lee, Genta Indra Winata
Venue: arXiv (2025)
Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Â∏ñÂ≠ê","item":"https://garyforreal.me/zh/posts/"},{"@type":"ListItem","position":2,"name":"ËÆ∫Êñá","item":"https://garyforreal.me/zh/posts/paper/"},{"@type":"ListItem","position":3,"name":"Weekly Paper Notes - 2025-12-09","item":"https://garyforreal.me/zh/posts/paper/paper-2025-12-09-weekly/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Weekly Paper Notes - 2025-12-09","name":"Weekly Paper Notes - 2025-12-09","description":"Weekly Paper Notes üîç multilingual M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG Authors: David Anugraha, Patrick Amadeus Irawan, Anshul Singh, En-Shiun Annie Lee, Genta Indra Winata Venue: arXiv (2025)\nVision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.\n","keywords":[],"articleBody":"Weekly Paper Notes üîç multilingual M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG Authors: David Anugraha, Patrick Amadeus Irawan, Anshul Singh, En-Shiun Annie Lee, Genta Indra Winata Venue: arXiv (2025)\nVision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.\nüìÑ Download PDF\nEfficient Text Classification with Conformal In-Context Learning Authors: Ippokratis Pantelidis, Korbinian Randl, Aron Henriksson Venue: arXiv (2025)\nLarge Language Models (LLMs) demonstrate strong in-context learning abilities, yet their effectiveness in text classification depends heavily on prompt design and incurs substantial computational cost. Conformal In-Context Learning (CICLe) has been proposed as a resource-efficient framework that integrates a lightweight base classifier with Conformal Prediction to guide LLM prompting by adaptively reducing the set of candidate classes. However, its broader applicability and efficiency benefits beyond a single domain have not yet been systematically explored. In this paper, we present a comprehensive evaluation of CICLe across diverse NLP classification benchmarks. The results show that CICLe consistently improves over its base classifier and outperforms few-shot prompting baselines when the sample size is sufficient for training the base classifier, and performs comparably in low-data regimes. In terms of efficiency, CICLe reduces the number of shots and prompt length by up to 34.45% and 25.16%, respectively, and enables the use of smaller models with competitive performance. CICLe is furthermore particularly advantageous for text classification tasks with high class imbalance. These findings highlight CICLe as a practical and scalable approach for efficient text classification, combining the robustness of traditional classifiers with the adaptability of LLMs, and achieving substantial gains in data and computational efficiency.\nüìÑ Download PDF\nGrounded Multilingual Medical Reasoning for Question Answering with Large Language Models Authors: Pietro Ferrazzi, Aitor Soroa, Rodrigo Agerri Venue: arXiv (2025)\nLarge Language Models (LLMs) with reasoning capabilities have recently demonstrated strong potential in medical Question Answering (QA). Existing approaches are largely English-focused and primarily rely on distillation from general-purpose LLMs, raising concerns about the reliability of their medical knowledge. In this work, we present a method to generate multilingual reasoning traces grounded in factual medical knowledge. We produce 500k traces in English, Italian, and Spanish, using a retrievalaugmented generation approach over medical information from Wikipedia. The traces are generated to solve medical questions drawn from MedQA and MedMCQA, which we extend to Italian and Spanish. We test our pipeline in both in-domain and outof-domain settings across Medical QA benchmarks, and demonstrate that our reasoning traces improve performance both when utilized via in-context learning (few-shot) and supervised fine-tuning, yielding state-of-the-art results among 8B-parameter LLMs. We believe that these resources can support the development of safer, more transparent clinical decision-support tools in multilingual settings. We release the full suite of resources: reasoning traces, translated QA datasets, Medical-Wikipedia, and fine-tuned models.\nüìÑ Download PDF\nStructured Reasoning with Tree-of-Thoughts for Bengali Math Word Problems Authors: Aurprita Mahmood, Sabrin alam, Neloy kumer Sagor, Md. Abdul Hadi, Md. Sehab Al Islam, Minhajul Islam Venue: arXiv (2025)\nMathematical Word Problems (MWPs) are among the most challenging tasks in natural language processing because they require both linguistic understanding and multi-step numerical reasoning. While Chain-of-Thought (CoT) prompting has shown promise, its linear structure often propagates errors, limiting overall effectiveness. To address this limitation, we present the a systematic study of Tree-of-Thought (ToT) reasoning for Bengali MWPs using the SOMADHAN dataset. Owing to computational and token-cost constraints, we evaluate a curated set of 100 representative problems across multiple large language models (LLMs), including GPT-OSS and LLaMA variants, under standard prompting, CoT, and ToT strategies. Our results show that CoT improves baseline accuracy from 78% (standard prompting) to 83% on average, while ToT further increases performance by up to 5 percentage points, achieving 88% accuracy with GPT-OSS-120B. These improvements highlight that ToT is particularly effective in medium-to-large-scale models but may offer less advantage for smaller ones. Overall, our findings establish ToT as a robust framework for solving mathematical problems in low-resource languages such as Bengali. More broadly, this study shows that structured reasoning methods like ToT can provide more reliable and globally consistent outcomes than CoT, paving the way for better reasoning strategies in multilingual NLP.\nüìÑ Download PDF\nSEA-SafeguardBench: Evaluating AI Safety in SEA Languages and Cultures Authors: Panuthep Tasawong, Jian Gang Ngui, Alham Fikri Aji, Trevor Cohn, Peerat Limkonchotiwat Venue: arXiv (2025)\nSafeguard models help large language models (LLMs) detect and block harmful content, but most evaluations remain English-centric and overlook linguistic and cultural diversity. Existing multilingual safety benchmarks often rely on machine-translated English data, which fails to capture nuances in low-resource languages. Southeast Asian (SEA) languages are underrepresented despite the region‚Äôs linguistic diversity and unique safety concerns, from culturally sensitive political speech to region-specific misinformation. Addressing these gaps requires benchmarks that are natively authored to reflect local norms and harm scenarios. We introduce SEA-SafeguardBench, the first human-verified safety benchmark for SEA, covering eight languages, 21,640 samples, across three subsets: general, in-the-wild, and content generation. The experimental results from our benchmark demonstrate that even state-of-the-art LLMs and guardrails are challenged by SEA cultural and harm scenarios and underperform when compared to English texts.\nüìÑ Download PDF\nDynamic Alignment for Collective Agency: Toward a Scalable Self-Improving Framework for Open-Ended LLM Alignment Authors: Panatchakorn Anantaprayoon, Nataliia Babina, Jad Tarifi, Nima Asgharbeygi Venue: arXiv (2025)\nLarge Language Models (LLMs) are typically aligned with human values using preference data or predefined principles such as helpfulness, honesty, and harmlessness. However, as AI systems progress toward Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI), such value systems may become insufficient. In addition, human feedback-based alignment remains resource-intensive and difficult to scale. While AI-feedback-based self-improving alignment methods have been explored as a scalable alternative, they have largely remained constrained to conventional alignment values. In this work, we explore both a more holistic alignment objective and a scalable, self-improving alignment approach. Aiming to transcend conventional alignment norms, we introduce Collective Agency (CA)-a unified and open-ended alignment value that encourages integrated agentic capabilities. We also propose Dynamic Alignment-an alignment framework that enables an LLM to iteratively align itself. Dynamic Alignment comprises two key components: (1) automated training dataset generation with LLMs, and (2) a self-rewarding mechanism, where the policy model evaluates its own output candidates and assigns rewards for GRPO-based learning. Experimental results demonstrate that our approach successfully aligns the model to CA while preserving general NLP capabilities.\nüìÑ Download PDF\nRRPO: Robust Reward Policy Optimization for LLM-based Emotional TTS Authors: Cong Wang, Changfeng Gao, Yang Xiang, Zhihao Du, Keyu An, Han Zhao, Qian Chen, Xiangang Li, Yingming Gao, Ya Li Venue: arXiv (2025)\nDifferentiable reinforcement learning (RL) frameworks like DiffRO offer a powerful approach for controllable text-to-speech (TTS), but are vulnerable to reward hacking, particularly for nuanced tasks like emotion control. The policy model can exploit a vanilla Reward Model (RM) by generating acoustic artifacts to achieve spurious rewards, but at the cost of degrading perceptual quality. To address this, we propose Robust Reward Policy Optimization (RRPO), a novel framework that employs a hybrid regularization scheme. This scheme develops a robust RM whose reward signal is more reliably aligned with human perception, compelling the policy to abandon detrimental shortcuts and instead learn the complex features of genuine emotions. Our ablation study confirms the enhanced robustness of our RM, as evidenced by its strong cross-lingual generalization. The subjective evaluation demonstrates that this robust RM effectively mitigates reward hacking, leading to significant improvements in both emotional expressiveness and naturalness over all baselines. Demo page: https://lrwinr.github.io/RRPO-CosyVoice.\nüìÑ Download PDF\nAdapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study Authors: Lifeng Chen, Ryan Lai, Tianming Liu Venue: arXiv (2025)\nAdapting large language models (LLMs) to low-resource languages remains a major challenge due to data scarcity and cross-lingual drift. This work presents a two-stage adaptation of Qwen2.5-3B to Tibetan, a morphologically rich and underrepresented language. We employ Continual Pretraining (CPT) to establish Tibetan linguistic grounding, followed by Supervised Fine-Tuning (SFT) for task and translation specialization. Empirical evaluations demonstrate a consistent decrease in perplexity (from 2.98 $\\rightarrow$ 1.54) and substantial improvements in Chinese$\\rightarrow$Tibetan translation quality (BLEU: 0.046 $\\rightarrow$ 0.261; chrF: 2.2 $\\rightarrow$ 6.6). Layer-wise analysis across 435 layers in Qwen3-4B reveals that adaptation primarily concentrates on embedding and output heads, with mid‚Äìlate MLP projections encoding domain-specific transformations. Our findings suggest that CPT constructs a Tibetan semantic manifold while SFT sharpens task alignment with minimal representational disruption. This study provides the first quantitative exploration of Tibetan adaptation dynamics for LLMs, and offers an open, reproducible framework for extending multilingual foundation models to low-resource settings.\nüìÑ Download PDF\nDifferent types of syntactic agreement recruit the same units within large language models Authors: Daria Kryvosheieva, Andrea de Varda, Evelina Fedorenko, Greta Tuckute Venue: arXiv (2025)\nLarge language models (LLMs) can reliably distinguish grammatical from ungrammatical sentences, but how grammatical knowledge is represented within the models remains an open question. We investigate whether different syntactic phenomena recruit shared or distinct components in LLMs. Using a functional localization approach inspired by cognitive neuroscience, we identify the LLM units most responsive to 67 English syntactic phenomena in seven open-weight models. These units are consistently recruited across sentences containing the phenomena and causally support the models‚Äô syntactic performance. Critically, different types of syntactic agreement (e.g., subject-verb, anaphor, determiner-noun) recruit overlapping sets of units, suggesting that agreement constitutes a meaningful functional category for LLMs. This pattern holds in English, Russian, and Chinese; and further, in a cross-lingual analysis of 57 diverse languages, structurally more similar languages share more units for subject-verb agreement. Taken together, these findings reveal that syntactic agreement-a critical marker of syntactic dependencies-constitutes a meaningful category within LLMs‚Äô representational spaces.\nüìÑ Download PDF\nM3DR: Towards Universal Multilingual Multimodal Document Retrieval Authors: Adithya S Kolavi, Vyoman Jain Venue: arXiv (2025)\nMultimodal document retrieval systems have shown strong progress in aligning visual and textual content for semantic search. However, most existing approaches remain heavily English-centric, limiting their effectiveness in multilingual contexts. In this work, we present M3DR (Multilingual Multimodal Document Retrieval), a framework designed to bridge this gap across languages, enabling applicability across diverse linguistic and cultural contexts. M3DR leverages synthetic multilingual document data and generalizes across different vision-language architectures and model sizes, enabling robust cross-lingual and cross-modal alignment. Using contrastive training, our models learn unified representations for text and document images that transfer effectively across languages. We validate this capability on 22 typologically diverse languages, demonstrating consistent performance and adaptability across linguistic and script variations. We further introduce a comprehensive benchmark that captures real-world multilingual scenarios, evaluating models under monolingual, multilingual, and mixed-language settings. M3DR generalizes across both single dense vector and ColBERT-style token-level multi-vector retrieval paradigms. Our models, NetraEmbed and ColNetraEmbed achieve state-of-the-art performance with ~150% relative improvements on cross-lingual retrieval.\nüìÑ Download PDF\nCross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages Authors: Lechen Zhang, Yusheng Zhou, Tolga Ergen, Lajanugen Logeswaran, Moontae Lee, David Jurgens Venue: arXiv (2025)\nSystem prompts provide a lightweight yet powerful mechanism for conditioning large language models (LLMs) at inference time. While prior work has focused on English-only settings, real-world deployments benefit from having a single prompt to operate reliably across languages. This paper presents a comprehensive study of how different system prompts steer models toward accurate and robust cross-lingual behavior. We propose a unified four-dimensional evaluation framework to assess system prompts in multilingual environments. Through large-scale experiments on five languages, three LLMs, and three benchmarks, we uncover that certain prompt components, such as CoT, emotion, and scenario, correlate with robust multilingual behavior. We develop a prompt optimization framework for multilingual settings and show it can automatically discover prompts that improve all metrics by 5-10%. Finally, we analyze over 10 million reasoning units and find that more performant system prompts induce more structured and consistent reasoning patterns, while reducing unnecessary language-switching. Together, we highlight system prompt optimization as a scalable path to accurate and robust multilingual LLM behavior.\nüìÑ Download PDF\nTriLex: A Framework for Multilingual Sentiment Analysis in Low-Resource South African Languages Authors: Mike Nkongolo, Hilton Vorster, Josh Warren, Trevor Naick, Deandre Vanmali, Masana Mashapha, Luke Brand, Alyssa Fernandes, Janco Calitz, Sibusiso Makhoba Venue: arXiv (2025)\nLow-resource African languages remain underrepresented in sentiment analysis, limiting both lexical coverage and the performance of multilingual Natural Language Processing (NLP) systems. This study proposes TriLex, a three-stage retrieval augmented framework that unifies corpus-based extraction, cross lingual mapping, and retrieval augmented generation (RAG) driven lexical refinement to systematically expand sentiment lexicons for low-resource languages. Using the enriched lexicon, the performance of two prominent African pretrained language models (AfroXLMR and AfriBERTa) is evaluated across multiple case studies. Results demonstrate that AfroXLMR delivers superior performance, achieving F1-scores above 80% for isiXhosa and isiZulu and exhibiting strong cross-lingual stability. Although AfriBERTa lacks pre-training on these target languages, it still achieves reliable F1-scores around 64%, validating its utility in computationally constrained settings. Both models outperform traditional machine learning baselines, and ensemble analyses further enhance precision and robustness. The findings establish TriLex as a scalable and effective framework for multilingual sentiment lexicon expansion and sentiment modeling in low-resource South African languages.\nüìÑ Download PDF\nBeyond Data Filtering: Knowledge Localization for Capability Removal in LLMs Authors: Igor Shilov, Alex Cloud, Aryo Pradipta Gema, Jacob Goldman-Wetzler, Nina Panickssery, Henry Sleight, Erik Jones, Cem Anil Venue: arXiv (2025)\nLarge Language Models increasingly possess capabilities that carry dual-use risks. While data filtering has emerged as a pretraining-time mitigation, it faces significant challenges: labeling whether data is harmful is expensive at scale, and given improving sample efficiency with larger models, even small amounts of mislabeled content could give rise to dangerous capabilities. To address risks associated with mislabeled harmful content, prior work proposed Gradient Routing (Cloud et al., 2024) ‚Äì a technique that localizes target knowledge into a dedicated subset of model parameters so they can later be removed. We explore an improved variant of Gradient Routing, which we call Selective GradienT Masking (SGTM), with particular focus on evaluating its robustness to label noise. SGTM zero-masks selected gradients such that target domain examples only update their dedicated parameters. We test SGTM‚Äôs effectiveness in two applications: removing knowledge of one language from a model trained on a bilingual synthetic dataset, and removing biology knowledge from a model trained on English Wikipedia. In both cases SGTM provides better retain/forget trade-off in the presence of labeling errors compared to both data filtering and a previously proposed instantiation of Gradient Routing. Unlike shallow unlearning approaches that can be quickly undone through fine-tuning, SGTM exhibits strong robustness to adversarial fine-tuning, requiring seven times more fine-tuning steps to reach baseline performance on the forget set compared to a finetuning-based unlearning method (RMU). Our results suggest SGTM provides a promising pretraining-time complement to existing safety mitigations, particularly in settings where label noise is unavoidable.\nüìÑ Download PDF\nDecoding the Black Box: Discerning AI Rhetorics About and Through Poetic Prompting Authors: P. D. Edgar, Alia Hall Venue: arXiv (2025)\nPrompt engineering has emerged as a useful way studying the algorithmic tendencies and biases of large language models. Meanwhile creatives and academics have leveraged LLMs to develop creative works and explore the boundaries of their writing capabilities through text generation and code. This study suggests that creative text prompting, specifically Poetry Prompt Patterns, may be a useful addition to the toolbox of the prompt engineer, and outlines the process by which this approach may be taken. Then, the paper uses poetic prompts to assess descriptions and evaluations of three models of a renowned poet and test the consequences of the willingness of models to adapt or rewrite original creative works for presumed audiences.\nüìÑ Download PDF\nFine-Tuning BERT for Domain-Specific Question Answering: Toward Educational NLP Resources at University Scale Authors: Aur√©lie Montfrond Venue: arXiv (2025)\nPrior work on scientific question answering has largely emphasized chatbot-style systems, with limited exploration of fine-tuning foundation models for domain-specific reasoning. In this study, we developed a chatbot for the University of Limerick‚Äôs Department of Electronic and Computer Engineering to provide course information to students. A custom dataset of 1,203 question-answer pairs in SQuAD format was constructed using the university book of modules, supplemented with manually and synthetically generated entries. We fine-tuned BERT (Devlin et al., 2019) using PyTorch and evaluated performance with Exact Match and F1 scores. Results show that even modest fine-tuning improves hypothesis framing and knowledge extraction, demonstrating the feasibility of adapting foundation models to educational domains. While domain-specific BERT variants such as BioBERT and SciBERT exist for biomedical and scientific literature, no foundation model has yet been tailored to university course materials. Our work addresses this gap by showing that fine-tuning BERT with academic QA pairs yields effective results, highlighting the potential to scale towards the first domain-specific QA model for universities and enabling autonomous educational knowledge systems.\nüìÑ Download PDF\nExploiting Spatial Multiplexing Based on Pixel Antennas: An Antenna Coding Approach Authors: Zixiang Han, Shanpu Shen, Ross Murch Venue: arXiv (2025)\nAn antenna coding approach for exploiting the spatial multiplexing capability of pixel antennas is proposed. This approach can leverage additional degrees of freedom in the beamspace domain to transmit more information streams. Pixel antennas are a general reconfigurable antenna design where a radiating structure with arbitrary shape and size can be discretized into sub-wavelength elements called pixels which are connected by radio frequency switches. By controlling the switch states, the pixel antenna topology can be flexibly adjusted so that the resulting radiation pattern can be reconfigured for beamspace spatial multiplexing. In this work, we introduce the antenna coder and pattern coder for pixel antennas, provide a multiple-input multiple-output (MIMO) communication system model with antenna coding in the beamspace domain, and derive the spectral efficiency. Utilizing the antenna coder, the radiation pattern of the pixel antenna is analyzed and efficient optimization algorithms are provided for antenna coding design. Numerical simulation results show that the proposed technique using pixel antennas can enhance spectral efficiency of 4-by-4 MIMO by up to 12 bits/s/Hz or equivalently reduce the required transmit power by up to 90% when compared to conventional MIMO, demonstrating the effectiveness of the antenna coding technique in spectral efficiency enhancement and its promise for future sixth generation (6G) wireless communication.\nüìÑ Download PDF\nThe Decision Path to Control AI Risks Completely: Fundamental Control Mechanisms for AI Governance Authors: Yong Tao Venue: arXiv (2025)\nArtificial intelligence (AI) advances rapidly but achieving complete human control over AI risks remains an unsolved problem, akin to driving the fast AI ‚Äútrain‚Äù without a ‚Äúbrake system.‚Äù By exploring fundamental control mechanisms at key elements of AI decisions, this paper develops a systematic solution to thoroughly control AI risks, providing an architecture for AI governance and legislation with five pillars supported by six control mechanisms, illustrated through a minimum set of AI Mandates (AIMs). Three of the AIMs must be built inside AI systems and three in society to address major areas of AI risks: 1) align AI values with human users; 2) constrain AI decision-actions by societal ethics, laws, and regulations; 3) build in human intervention options for emergencies and shut-off switches for existential threats; 4) limit AI access to resources to reinforce controls inside AI; 5) mitigate spillover risks like job loss from AI. We also highlight the differences in AI governance on physical AI systems versus generative AI. We discuss how to strengthen analog physical safeguards to prevent smarter AI/AGI/ASI from circumventing core safety controls by exploiting AI‚Äôs intrinsic disconnect from the analog physical world: AI‚Äôs nature as pure software code run on chips controlled by humans, and the prerequisite that all AI-driven physical actions must be digitized. These findings establish a theoretical foundation for AI governance and legislation as the basic structure of a ‚Äúbrake system‚Äù for AI decisions. If enacted, these controls can rein in AI dangers as completely as humanly possible, removing large chunks of currently wide-open AI risks, substantially reducing overall AI risks to residual human errors.\nüìÑ Download PDF\nMinimizing the Number of Code Switching Operations in Fault-Tolerant Quantum Circuits Authors: Erik Weilandt, Tom Peham, Robert Wille Venue: arXiv (2025)\nFault-tolerant quantum computers rely on Quantum Error-Correcting Codes (QECCs) to protect information from noise. However, no single error-correcting code supports a fully transversal and therefore fault-tolerant implementation of all gates required for universal quantum computation. Code switching addresses this limitation by moving quantum information between different codes that, together, support a universal gate set. Unfortunately, each switch is costly-adding time and space overhead and increasing the logical error rate. Minimizing the number of switching operations is, therefore, essential for quantum computations using code switching. In this work, we study the problem of minimizing the number of code switches required to run a given quantum circuit. We show that this problem can be solved efficiently in polynomial time by reducing it to a minimum-cut instance on a graph derived from the circuit. Our formulation is flexible and can incorporate additional considerations, such as reducing depth overhead by preferring switches during idle periods or biasing the compilation to favor one code over another. To the best of our knowledge, this is the first automated approach for compiling and optimizing code-switching-based quantum computations at the logical level.\nüìÑ Download PDF\nEnCompass: Enhancing Agent Programming with Search Over Program Execution Paths Authors: Zhening Li, Armando Solar-Lezama, Yisong Yue, Stephan Zheng Venue: arXiv (2025)\nWe introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce ‚Äúprobabilistic angelic nondeterminism‚Äù (‚ÄúPAN‚Äù), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.\nüìÑ Download PDF\nModeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaran√≠ Authors: Nemika Tyagi, Nelvin Licona Guevara, Olga Kellert Venue: arXiv (2025)\nThis study presents an LLM-assisted annotation pipeline for the sociolinguistic and topical analysis of bilingual discourse in two typologically distinct contexts: Spanish-English and Spanish-Guaran√≠. Using large language models, we automatically labeled topic, genre, and discourse-pragmatic functions across a total of 3,691 code-switched sentences, integrated demographic metadata from the Miami Bilingual Corpus, and enriched the Spanish-Guaran√≠ dataset with new topic annotations. The resulting distributions reveal systematic links between gender, language dominance, and discourse function in the Miami data, and a clear diglossic division between formal Guaran√≠ and informal Spanish in Paraguayan texts. These findings replicate and extend earlier interactional and sociolinguistic observations with corpus-scale quantitative evidence. The study demonstrates that large language models can reliably recover interpretable sociolinguistic patterns traditionally accessible only through manual annotation, advancing computational methods for cross-linguistic and low-resource bilingual research.\nüìÑ Download PDF\nKnowing Your Uncertainty ‚Äì On the application of LLM in social sciences Authors: Bolun Zhang, Linzhuo Li, Yunqi Chen, Qinlin Zhao, Zihan Zhu, Xiaoyuan Yi, Xing Xie Venue: arXiv (2025)\nLarge language models (LLMs) are rapidly being integrated into computational social science research, yet their blackboxed training and designed stochastic elements in inference pose unique challenges for scientific inquiry. This article argues that applying LLMs to social scientific tasks requires explicit assessment of uncertainty-an expectation long established in both quantitative methodology in the social sciences and machine learning. We introduce a unified framework for evaluating LLM uncertainty along two dimensions: the task type (T), which distinguishes between classification, short-form, and long-form generation, and the validation type (V), which captures the availability of reference data or evaluative criteria. Drawing from both computer science and social science literature, we map existing uncertainty quantification (UQ) methods to this T-V typology and offer practical recommendations for researchers. Our framework provides both a methodological safeguard and a practical guide for integrating LLMs into rigorous social science research.\nüìÑ Download PDF\nEnhancing Retrieval-Augmented Generation with Entity Linking for Educational Platforms Authors: Francesco Granata, Francesco Poggi, Misael Mongiov√¨ Venue: arXiv (2025)\nIn the era of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) architectures are gaining significant attention for their ability to ground language generation in reliable knowledge sources. Despite their impressive effectiveness in many areas, RAG systems based solely on semantic similarity often fail to ensure factual accuracy in specialized domains, where terminological ambiguity can affect retrieval relevance. This study proposes an enhanced RAG architecture that integrates a factual signal derived from Entity Linking to improve the accuracy of educational question-answering systems in Italian. The system includes a Wikidata-based Entity Linking module and implements three re-ranking strategies to combine semantic and entity-based information: a hybrid score weighting model, reciprocal rank fusion, and a cross-encoder re-ranker. Experiments were conducted on two benchmarks: a custom academic dataset and the standard SQuAD-it dataset. Results show that, in domain-specific contexts, the hybrid schema based on reciprocal rank fusion significantly outperforms both the baseline and the cross-encoder approach, while the cross-encoder achieves the best results on the general-domain dataset. These findings confirm the presence of an effect of domain mismatch and highlight the importance of domain adaptation and hybrid ranking strategies to enhance factual precision and reliability in retrieval-augmented generation. They also demonstrate the potential of entity-aware RAG systems in educational environments, fostering adaptive and reliable AI-based tutoring tools.\nüìÑ Download PDF\nTraining-Time Action Conditioning for Efficient Real-Time Chunking Authors: Kevin Black, Allen Z. Ren, Michael Equi, Sergey Levine Venue: arXiv (2025)\nReal-time chunking (RTC) enables vision-language-action models (VLAs) to generate smooth, reactive robot trajectories by asynchronously predicting action chunks and conditioning on previously committed actions via inference-time inpainting. However, this inpainting method introduces computational overhead that increases inference latency. In this work, we propose a simple alternative: simulating inference delay at training time and conditioning on action prefixes directly, eliminating any inference-time overhead. Our method requires no modifications to the model architecture or robot runtime, and can be implemented with only a few additional lines of code. In simulated experiments, we find that training-time RTC outperforms inference-time RTC at higher inference delays. In real-world experiments on box building and espresso making tasks with the $œÄ_{0.6}$ VLA, we demonstrate that training-time RTC maintains both task performance and speed parity with inference-time RTC while being computationally cheaper. Our results suggest that training-time action conditioning is a practical drop-in replacement for inference-time inpainting in real-time robot control.\nüìÑ Download PDF\nMaxShapley: Towards Incentive-compatible Generative Search with Fair Context Attribution Authors: Sara Patel, Mingxun Zhou, Giulia Fanti Venue: arXiv (2025)\nGenerative search engines based on large language models (LLMs) are replacing traditional search, fundamentally changing how information providers are compensated. To sustain this ecosystem, we need fair mechanisms to attribute and compensate content providers based on their contributions to generated answers. We introduce MaxShapley, an efficient algorithm for fair attribution in generative search pipelines that use retrieval-augmented generation (RAG). MaxShapley is a special case of the celebrated Shapley value; it leverages a decomposable max-sum utility function to compute attributions with linear computation in the number of documents, as opposed to the exponential cost of Shapley values. We evaluate MaxShapley on three multi-hop QA datasets (HotPotQA, MuSiQUE, MS MARCO); MaxShapley achieves comparable attribution quality to exact Shapley computation, while consuming a fraction of its tokens‚Äìfor instance, it gives up to an 8x reduction in resource consumption over prior state-of-the-art methods at the same attribution accuracy.\nüìÑ Download PDF\nSIMPACT: Simulation-Enabled Action Planning using Vision-Language Models Authors: Haowen Liu, Shaoxiong Yao, Haonan Chen, Jiawei Gao, Jiayuan Mao, Jia-Bin Huang, Yilun Du Venue: arXiv (2025)\nVision-Language Models (VLMs) exhibit remarkable common-sense and semantic reasoning capabilities. However, they lack a grounded understanding of physical dynamics. This limitation arises from training VLMs on static internet-scale visual-language data that contain no causal interactions or action-conditioned changes. Consequently, it remains challenging to leverage VLMs for fine-grained robotic manipulation tasks that require physical understanding, reasoning, and corresponding action planning. To overcome this, we present SIMPACT, a test-time, SIMulation-enabled ACTion Planning framework that equips VLMs with physical reasoning through simulation-in-the-loop world modeling, without requiring any additional training. From a single RGB-D observation, SIMPACT efficiently constructs physics simulations, enabling the VLM to propose informed actions, observe simulated rollouts, and iteratively refine its reasoning. By integrating language reasoning with physics prediction, our simulation-enabled VLM can understand contact dynamics and action outcomes in a physically grounded way. Our method demonstrates state-of-the-art performance on five challenging, real-world rigid-body and deformable manipulation tasks that require fine-grained physical reasoning, outperforming existing general-purpose robotic manipulation models. Our results demonstrate that embedding physics understanding via efficient simulation into VLM reasoning at test time offers a promising path towards generalizable embodied intelligence. Project webpage can be found at https://simpact-bot.github.io\nüìÑ Download PDF\nSymPyBench: A Dynamic Benchmark for Scientific Reasoning with Executable Python Code Authors: Shima Imani, Seungwhan Moon, Adel Ahmadyan, Lu Zhang, Kirmani Ahmed, Babak Damavandi Venue: arXiv (2025)\nWe introduce, a large-scale synthetic benchmark of 15,045 university-level physics problems (90/10% train/test split). Each problem is fully parameterized, supporting an effectively infinite range of input configurations, and is accompanied by structured, step-by-step reasoning and executable Python code that produces the ground-truth solution for any parameter set. The benchmark contains three question types: MC-Symbolic (multiple-choice with symbolic options), MC-Numerical (multiple-choice with numerical options), and free-form (open-ended responses). These diverse formats test complementary reasoning skills. By leveraging the dynamic, code-driven nature of the benchmark, we introduce three novel evaluation metrics in addition to standard accuracy: Consistency Score, Failure Rate, and Confusion Rate, that quantify variability and uncertainty across problem variants. Experiments with state-of-the-art instruction-tuned language models reveal both strengths and limitations in scientific reasoning, positioning SymPyBench as a foundation for developing more robust and interpretable reasoning systems\nüìÑ Download PDF\nThermodynamics of Shear Equilibration During Magnetic Reconnection Onset in Mixed-Equilibrium Current Sheets Authors: Dominic Payne, Marc Swisdak, James Drake, Tak Chu Li Venue: arXiv (2025)\nMagnetic shear across the polarity inversion line (PIL) plays an important role in the explosive nature of reconnection onset and in the equilibration of current sheets, acting as a source of free energy that can enhance or inhibit the onset process under certain conditions. In this study, we use a 2D PIC simulation to examine the local interaction between the reconnection guide field and thermodynamic variables during reconnection onset in a region of initially depleted thermal energy and enhanced magnetic energy in a large guide field background. We identify critical stages of the equilibration process, characterize intervals based on whether the pressure evolution is driven by changes in density or temperature, and discuss what these intervals imply about the evolution of local heat and work density. Finally, we examine power densities associated with electromagnetic field time evolution and electromagnetic energy transfer and compare to those related to thermodynamic changes.\nüìÑ Download PDF\nSCAIL: Towards Studio-Grade Character Animation via In-Context Learning of 3D-Consistent Pose Representations Authors: Wenhao Yan, Sheng Ye, Zhuoyi Yang, Jiayan Teng, ZhenHui Dong, Kairui Wen, Xiaotao Gu, Yong-Jin Liu, Jie Tang Venue: arXiv (2025)\nAchieving character animation that meets studio-grade production standards remains challenging despite recent progress. Existing approaches can transfer motion from a driving video to a reference image, but often fail to preserve structural fidelity and temporal consistency in wild scenarios involving complex motion and cross-identity animations. In this work, we present \\textbf{SCAIL} (\\textbf{S}tudio-grade \\textbf{C}haracter \\textbf{A}nimation via \\textbf{I}n-context \\textbf{L}earning), a framework designed to address these challenges from two key innovations. First, we propose a novel 3D pose representation, providing a more robust and flexible motion signal. Second, we introduce a full-context pose injection mechanism within a diffusion-transformer architecture, enabling effective spatio-temporal reasoning over full motion sequences. To align with studio-level requirements, we develop a curated data pipeline ensuring both diversity and quality, and establish a comprehensive benchmark for systematic evaluation. Experiments show that \\textbf{SCAIL} achieves state-of-the-art performance and advances character animation toward studio-grade reliability and realism.\nüìÑ Download PDF\nInterplay of ferroelectricity and interlayer superconductivity in van der Waals bilayers Authors: D. S. Annenkov, A. A. Kopasov, A. S. Mel‚Äônikov Venue: arXiv (2025)\nWe study the distinctive features of the interplay between the interlayer superconductivity and ferroelectricity in van der Waals heterostructures. Corresponding analysis is carried out within the framework of the quasiclassical Eilenberger equations for a tunnel coupled bilayer with inhomogeneous relative shift of the conduction bands between the layers, which describes the net charge transfer in sliding ferroelectrics. It is shown that the critical temperature of the interlayer superconductivity can be significantly enhanced for superconducting nuclei localized in the vicinity of ferroelectric domain walls. We demonstrate that the increase in the tunneling amplitude leads to the decrease (increase) in the difference between the critical temperatures for localized and homogeneous superconducting states for the spin-singlet (spin-triplet) interlayer superconductivity. We also perform an extensive analysis of the effects of the in-plane magnetic field on the interlayer superconductivity. It is shown that the orbital effect can result in the suppression of the spin-singlet interlayer superconductivity and to the enhancement of the spin-triplet one. We find that possible manifestations of the paramagnetic effect include the suppression of the interlayer superconductivity by rather weak Zeeman fields, the two-fold anisotropy of the critical magnetic field for the spin-triplet states as well as the appearance of the reentrant superconducting phases. It is shown that the joint influence of the orbital and paramagnetic mechanisms on the spin-triplet interlayer superconductivity can even lead to a nonmonotonic behavior of the superconducting critical temperature as a function of the external magnetic field. The obtained results are discussed in the context of recent experimental data on van der Waals structures with coexisting superconductivity and sliding ferroelectricity.\nüìÑ Download PDF\nPhase-OTDR Event Detection Using Image-Based Data Transformation and Deep Learning Authors: Muhammet Cagri Yeke, Samil Sirin, Kivilcim Yuksel, Abdurrahman Gumus Venue: arXiv (2025)\nThis study focuses on event detection in optical fibers, specifically classifying six events using the Phase-OTDR system. A novel approach is introduced to enhance Phase-OTDR data analysis by transforming 1D data into grayscale images through techniques such as Gramian Angular Difference Field, Gramian Angular Summation Field, and Recurrence Plot. These grayscale images are combined into a multi-channel RGB representation, enabling more robust and adaptable analysis using transfer learning models. The proposed methodology achieves high classification accuracies of 98.84% and 98.24% with the EfficientNetB0 and DenseNet121 models, respectively. A 5-fold cross-validation process confirms the reliability of these models, with test accuracy rates of 99.07% and 98.68%. Using a publicly available Phase-OTDR dataset, the study demonstrates an efficient approach to understanding optical fiber events while reducing dataset size and improving analysis efficiency. The results highlight the transformative potential of image-based analysis in interpreting complex fiber optic sensing data, offering significant advancements in the accuracy and reliability of fiber optic monitoring systems. The codes and the corresponding image-based dataset are made publicly available on GitHub to support further research: https://github.com/miralab-ai/Phase-OTDR-event-detection.\nüìÑ Download PDF\nHigher-order diffusion and Cahn-Hilliard-type models revisited on the half-line Authors: A. Chatziafratis, A. Miranville, G. Karali, A. S. Fokas, E. C. Aifantis Venue: arXiv (2025)\nIn this paper, we solve explicitly and analyze rigorously inhomogeneous initial-boundary-value problems (IBVP) for several fourth-order variations of the traditional diffusion equation and the associated linearized Cahn-Hilliard (C-H) model (also Kuramoto-Sivashinsky equation), formulated in the spatiotemporal quarter-plane. Such models are of relevance to heat-mass transfer phenomena, solid-fluid dynamics and the applied sciences. In particular, we derive formally effective solution representations, justifying a posteriori their validity. This includes the reconstruction of the prescribed initial and boundary data, which requires careful analysis of the various integral terms appearing in the formulae, proving that they converge in a strictly defined sense. In each IBVP, the novel formula is utilized to rigorously deduce the solution‚Äôs regularity and asymptotic properties near the boundaries of the domain, including uniform convergence, eventual (long-time) periodicity under (eventually) periodic boundary conditions, and null non-controllability. Importantly, this analysis is indispensable for exploring the (non)uniqueness of the problem‚Äôs solution and a new counter-example is constructed. Our work is based on the synergy between: (i) the well-known Fokas unified transform method and (ii) a new approach recently introduced for the rigorous analysis of the Fokas method and for investigating qualitative properties of linear evolution partial differential equations (PDE) on semi-infinite strips. Since only up to third-order evolution PDE have been investigated within this novel framework to date, we present our analysis and results in an illustrative manner and in order of progressively greater complexity, for the convenience of readers. The solution formulae established herein are expected to find utility in well-posedness studies for nonlinear counterparts too.\nüìÑ Download PDF\nHiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies Authors: Zhiying Du, Bei Liu, Yaobo Liang, Yichao Shen, Haidong Cao, Xiangyu Zheng, Zhiyuan Feng, Zuxuan Wu, Jiaolong Yang, Yu-Gang Jiang Venue: arXiv (2025)\nThe development of foundation models for embodied intelligence critically depends on access to large-scale, high-quality robot demonstration data. Recent approaches have sought to address this challenge by training on large collections of heterogeneous robotic datasets. However, unlike vision or language data, robotic demonstrations exhibit substantial heterogeneity across embodiments and action spaces as well as other prominent variations such as senor configurations and action control frequencies. The lack of explicit designs for handling such heterogeneity causes existing methods to struggle with integrating diverse factors, thereby limiting their generalization and leading to degraded performance when transferred to new settings. In this paper, we present HiMoE-VLA, a novel vision-language-action (VLA) framework tailored to effectively handle diverse robotic data with heterogeneity. Specifically, we introduce a Hierarchical Mixture-of-Experts (HiMoE) architecture for the action module which adaptively handles multiple sources of heterogeneity across layers and gradually abstracts them into shared knowledge representations. Through extensive experimentation with simulation benchmarks and real-world robotic platforms, HiMoE-VLA demonstrates a consistent performance boost over existing VLA baselines, achieving higher accuracy and robust generalization across diverse robots and action spaces. The code and models are publicly available at https://github.com/ZhiyingDu/HiMoE-VLA.\nüìÑ Download PDF\nEditThinker: Unlocking Iterative Reasoning for Any Image Editor Authors: Hongyu Li, Manyuan Zhang, Dian Zheng, Ziyu Guo, Yimeng Jia, Kaituo Feng, Hao Yu, Yexin Liu, Yan Feng, Peng Pei, Xunliang Cai, Linjiang Huang, Hongsheng Li, Si Liu Venue: arXiv (2025)\nInstruction-based image editing has emerged as a prominent research area, which, benefiting from image generation foundation models, have achieved high aesthetic quality, making instruction-following capability the primary challenge. Existing approaches improve instruction adherence via supervised or reinforcement learning, yet single-turn success rates remain limited due to inherent stochasticity and a lack of deliberation. In this work, we propose a deliberative editing framework to ‚Äôthink‚Äô while they edit, which simulates the human cognitive loop by iteratively executing a Think-while-Edit cycle: Critiquing results and Refining instructions , followed by Repeating the generation until satisfactory. Specifically, we train a single MLLM, EditThinker, to act as the reasoning engine of this framework, which jointly produce the critique score, reasoning process, and refined instructions. We employ reinforcement learning to align the EditThinker‚Äôs thinking with its editing, thereby generating more targeted instruction improvements. Extensive experiments on four benchmarks demonstrate that our approach significantly improves the instruction-following capability of any image editing model by a large margin. We will release our data construction framework, datasets, and models to benefit the community.\nüìÑ Download PDF\nVariational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem Authors: Truong Thanh Hung Nguyen, Truong Thinh Nguyen, Hung Cao Venue: arXiv (2025)\nResource allocation remains NP-hard due to combinatorial complexity. While deep reinforcement learning (DRL) methods, such as the Rainbow Deep Q-Network (DQN), improve scalability through prioritized replay and distributional heads, classical function approximators limit their representational power. We introduce Variational Quantum Rainbow DQN (VQR-DQN), which integrates ring-topology variational quantum circuits with Rainbow DQN to leverage quantum superposition and entanglement. We frame the human resource allocation problem (HRAP) as a Markov decision process (MDP) with combinatorial action spaces based on officer capabilities, event schedules, and transition times. On four HRAP benchmarks, VQR-DQN achieves 26.8% normalized makespan reduction versus random baselines and outperforms Double DQN and classical Rainbow DQN by 4.9-13.4%. These gains align with theoretical connections between circuit expressibility, entanglement, and policy quality, demonstrating the potential of quantum-enhanced DRL for large-scale resource allocation. Our implementation is available at: https://github.com/Analytics-Everywhere-Lab/qtrl/.\nüìÑ Download PDF\nQualitative and Quantitative Analysis of Riemannian Optimization Methods for Ground States of Rotating Multicomponent Bose-Einstein Condensates Authors: Martin Hermann, Tatjana Stykel, Mahima Yadav Venue: arXiv (2025)\nWe develop and analyze Riemannian optimization methods for computing ground states of rotating multicomponent Bose-Einstein condensates, defined as minimizers of the Gross-Pitaevskii energy functional. To resolve the non-uniqueness of ground states induced by phase invariance, we work on a quotient manifold endowed with a general Riemannian metric. By introducing an auxiliary phase-aligned iteration and employing fixed-point convergence theory, we establish a unified local convergence framework for Riemannian gradient descent methods and derive explicit convergence rates. Specializing this framework to two metrics tailored to the energy landscape, we study the energy-adaptive and Lagrangian-based Riemannian gradient descent methods. While monotone energy decay and global convergence are established only for the former, a quantified local convergence analysis is provided for both methods. Numerical experiments confirm the theoretical results and demonstrate that the Lagrangian-based method, which incorporates second-order information on the energy functional and mass constraints, achieves faster local convergence than the energy-adaptive scheme.\nüìÑ Download PDF\nPhysically-Based Simulation of Automotive LiDAR Authors: L. Dudzik, M. Roschani, A. Sielemann, K. Trampert, J. Ziehn, J. Beyerer, C. Neumann Venue: arXiv (2025)\nWe present an analytic model for simulating automotive time-of-flight (ToF) LiDAR that includes blooming, echo pulse width, and ambient light, along with steps to determine model parameters systematically through optical laboratory measurements. The model uses physically based rendering (PBR) in the near-infrared domain. It assumes single-bounce reflections and retroreflections over rasterized rendered images from shading or ray tracing, including light emitted from the sensor as well as stray light from other, non-correlated sources such as sunlight. Beams from the sensor and sensitivity of the receiving diodes are modeled with flexible beam steering patterns and with non-vanishing diameter. Different (all non-real time) computational approaches can be chosen based on system properties, computing capabilities, and desired output properties. Model parameters include system-specific properties, namely the physical spread of the LiDAR beam, combined with the sensitivity of the receiving diode; the intensity of the emitted light; the conversion between the intensity of reflected light and the echo pulse width; and scenario parameters such as environment lighting, positioning, and surface properties of the target(s) in the relevant infrared domain. System-specific properties of the model are determined from laboratory measurements of the photometric luminance on different target surfaces aligned with a goniometer at 0.01¬∞ resolution, which marks the best available resolution for measuring the beam pattern. The approach is calibrated for and tested on two automotive LiDAR systems, the Valeo Scala Gen. 2 and the Blickfeld Cube 1. Both systems differ notably in their properties and available interfaces, but the relevant model parameters could be extracted successfully.\nüìÑ Download PDF\nNatural Language Summarization Enables Multi-Repository Bug Localization by LLMs in Microservice Architectures Authors: Amirkia Rafiei Oskooei, S. Selcan Yukcu, Mehmet Cevheri Bozoglan, Mehmet S. Aktas Venue: arXiv (2025)\nBug localization in multi-repository microservice architectures is challenging due to the semantic gap between natural language bug reports and code, LLM context limitations, and the need to first identify the correct repository. We propose reframing this as a natural language reasoning task by transforming codebases into hierarchical NL summaries and performing NL-to-NL search instead of cross-modal retrieval. Our approach builds context-aware summaries at file, directory, and repository levels, then uses a two-phase search: first routing bug reports to relevant repositories, then performing top-down localization within those repositories. Evaluated on DNext, an industrial system with 46 repositories and 1.1M lines of code, our method achieves Pass@10 of 0.82 and MRR of 0.50, significantly outperforming retrieval baselines and agentic RAG systems like GitHub Copilot and Cursor. This work demonstrates that engineered natural language representations can be more effective than raw source code for scalable bug localization, providing an interpretable repository -\u003e directory -\u003e file search path, which is vital for building trust in enterprise AI tools by providing essential transparency.\nüìÑ Download PDF\nFrom Text to Returns: Using Large Language Models for Mutual Fund Portfolio Optimization and Risk-Adjusted Allocation Authors: Abrar Hossain Mufakir Qamar Ansari Haziq Jeelani Monia Digra Fayeq Jeelani Syed Venue: arXiv (2025)\nGenerative AI (GenAI) has enormous potential for improving two critical areas in investing, namely portfolio optimization (choosing the best combination of assets) and risk management (protecting those investments). Our study works at this intersection, using Large Language Models (LLMs) to upgrade how financial decisions are traditionally made. This research specifically tested how well advanced LLMs like Microsoft Phi 2, Mistral 7B, and Zypher 7B can create practical, risk-aware strategies for investing mutual funds in different sectors of the economy. Our method is sophisticated: it combines a Retrieval-Augmented Generation (RAG) pipeline, which enables the LLM to check external, real-time data with standard financial optimization methods. The model‚Äôs advice is context-aware because we feed it large economic signals, like changes in the global economy. The Zypher 7B model was the clear winner. It consistently produced strategies that maximized investment returns while delivering better risk-adjusted results than the other models. Its ability to process complex relationships and contextual information makes it a highly powerful tool for financial allocation. In conclusion, our findings show that GenAI substantially improves performance over basic allocation methods. By connecting GenAI to real-world financial applications, this work lays the groundwork for creating smarter, more efficient, and more adaptable solutions for asset management professionals.\nüìÑ Download PDF\nAsteroseismology of SPB stars: a comparison of forward asteroseismic modelling results from Kepler and TESS Authors: L. J. A. Scott, D. M. Bowman Venue: arXiv (2025)\nThe slowly pulsating B (SPB) stars are a class of variable star with masses between about 3 and 8 M$_{\\odot}$. Their gravity-mode pulsation frequencies are sensitive to the near-core structure, which makes them useful probes of rotation and mixing in the deep stellar interior. Time series photometry, such as from the Kepler and TESS space telescopes, allows the extraction of their pulsation frequencies and construction of period spacing patterns. Previously, samples of slowly pulsating B stars were observed by the Kepler mission and underwent forward asteroseismic modelling to retrieve stellar parameters such as mass, age and core mass. However, all of these stars have since been re-observed by the ongoing TESS mission with light curves that are usually shorter and non-continuous, resulting in more difficult frequency extraction and interpretation in terms of constructing period spacing patterns. In this paper we compare the results of forward asteroseismic modelling of a sample of SPB stars using intermittent TESS light curve data to those based on long-duration Kepler light curves. We show how in some cases that the masses and core masses derived from only a few sectors of TESS data agree well with the 4-yr Kepler mission results, despite the stars having far fewer significant pulsation frequencies in their TESS light curves. However, some stars yield incompatible results, emphasising the complexities in forward asteroseismic modelling of gravity-mode pulsators with sparsely sampled or short duration TESS light curves.\nüìÑ Download PDF\nüîç linguistics AQUA-Net: Adaptive Frequency Fusion and Illumination Aware Network for Underwater Image Enhancement Authors: Munsif Ali, Najmul Hassan, Lucia Ventura, Davide Di Bari, Simonepietro Canese Venue: arXiv (2025)\nUnderwater images often suffer from severe color distortion, low contrast, and a hazy appearance due to wavelength-dependent light absorption and scattering. Simultaneously, existing deep learning models exhibit high computational complexity, which limits their practical deployment for real-time underwater applications. To address these challenges, this paper presents a novel underwater image enhancement model, called Adaptive Frequency Fusion and Illumination Aware Network (AQUA-Net). It integrates a residual encoder decoder with dual auxiliary branches, which operate in the frequency and illumination domains. The frequency fusion encoder enriches spatial representations with frequency cues from the Fourier domain and preserves fine textures and structural details. Inspired by Retinex, the illumination-aware decoder performs adaptive exposure correction through a learned illumination map that separates reflectance from lighting effects. This joint spatial, frequency, and illumination design enables the model to restore color balance, visual contrast, and perceptual realism under diverse underwater conditions. Additionally, we present a high-resolution, real-world underwater video-derived dataset from the Mediterranean Sea, which captures challenging deep-sea conditions with realistic visual degradations to enable robust evaluation and development of deep learning models. Extensive experiments on multiple benchmark datasets show that AQUA-Net performs on par with SOTA in both qualitative and quantitative evaluations while using less number of parameters. Ablation studies further confirm that the frequency and illumination branches provide complementary contributions that improve visibility and color representation. Overall, the proposed model shows strong generalization capability and robustness, and it provides an effective solution for real-world underwater imaging applications.\nüìÑ Download PDF\nSpectroscopy and Coherent Control of Two-Level System Defect Ensembles Using a Broadband 3D Waveguide Authors: Qianxu Wang, Juan S. Salcedo-Gallo, Salil Bedkihal, Tian Xia, Maciej W. Olszewski, Valla Fatemi, Mattias Fitzpatrick Venue: arXiv (2025)\nDefects in solid-state materials play a central role in determining coherence, stability, and performance in quantum technologies. Although narrowband techniques can probe specific resonances with high precision, a broadband spectroscopic approach captures the full spectrum of defect properties and dynamics. Two-level system (TLS) defects in amorphous dielectrics are a particularly important example because they are major sources of decoherence and energy loss in superconducting quantum devices. However, accessing and characterizing their collective dynamics remains far more challenging than probing individual TLS defects. Building on our previously developed Broadband Cryogenic Transient Dielectric Spectroscopy (BCTDS) technique, we study the coherent control and time-resolved dynamics of TLS defect ensembles over a wide frequency range of 3-5 GHz without requiring full device fabrication, revealing quantum interference effects, memory-dependent dynamics, and dressed-state evolution within the TLS defect bath. The spectral response reveals distinct V-shaped structures corresponding to the bare eigenmode frequencies. Using these features, we extract a TLS defect spectral density of 84 GHz^-1 for a silicon sample, across a 4.1-4.6 GHz span. Furthermore, we systematically investigate amplitude- and phase-controlled interference fringes for multiple temperatures and inter-pulse delays, providing direct evidence of coherent dynamics and control. A driven minimal spin model with dipole-dipole interactions that qualitatively capture the observed behavior is presented. Our results establish BCTDS as a versatile platform for broadband defect spectroscopy, offering new capabilities for diagnosing and mitigating sources of decoherence, engineering many-body dynamics, and exploring non-equilibrium phenomena in disordered quantum systems.\nüìÑ Download PDF\nPRiSM: An Agentic Multimodal Benchmark for Scientific Reasoning via Python-Grounded Evaluation Authors: Shima Imani, Seungwhan Moon, Adel Ahmadyan, Lu Zhang, Kirmani Ahmed, Babak Damavandi Venue: arXiv (2025)\nEvaluating vision-language models (VLMs) in scientific domains like mathematics and physics poses unique challenges that go far beyond predicting final answers. These domains demand conceptual understanding, symbolic reasoning, and adherence to formal laws, requirements that most existing benchmarks fail to address. In particular, current datasets tend to be static, lacking intermediate reasoning steps, robustness to variations, or mechanisms for verifying scientific correctness. To address these limitations, we introduce PRiSM, a synthetic, fully dynamic, and multimodal benchmark for evaluating scientific reasoning via grounded Python code. PRiSM includes over 24,750 university-level physics and math problems, and it leverages our scalable agent-based pipeline, PrismAgent, to generate well-structured problem instances. Each problem contains dynamic textual and visual input, a generated figure, alongside rich structured outputs: executable Python code for ground truth generation and verification, and detailed step-by-step reasoning. The dynamic nature and Python-powered automated ground truth generation of our benchmark allow for fine-grained experimental auditing of multimodal VLMs, revealing failure modes, uncertainty behaviors, and limitations in scientific reasoning. To this end, we propose five targeted evaluation tasks covering generalization, symbolic program synthesis, perturbation robustness, reasoning correction, and ambiguity resolution. Through comprehensive evaluation of existing VLMs, we highlight their limitations and showcase how PRiSM enables deeper insights into their scientific reasoning capabilities.\nüìÑ Download PDF\nNumerically Reliable Brunovsky Transformations Authors: Shaohui Yang, Colin N. Jones Venue: arXiv (2025)\nThe Brunovsky canonical form provides sparse structural representations that are beneficial for computational optimal control, yet existing methods fail to compute it reliably. We propose a technique that produces Brunovsky transformations with substantially lower construction errors and improved conditioning. A controllable linear system is first reduced to staircase form via an orthogonal similarity transformation. We then derive a simple linear parametrization of the transformations yielding the unique Brunovsky form. Numerical stability is further enhanced by applying a deadbeat gain before computing system matrix powers and by optimizing the linear parameters to minimize condition numbers.\nüìÑ Download PDF\nLearning the Cosmic Web: Graph-based Classification of Simulated Galaxies by their Dark Matter Environments Authors: Dakshesh Kololgi, Krishna Naidoo, Amelie Saintonge, Ofer Lahav Venue: arXiv (2025)\nWe present a novel graph-based machine learning classifier for identifying the dark matter cosmic web environments of galaxies. Large galaxy surveys offer comprehensive statistical views of how galaxy properties are shaped by large-scale structure, but this requires robust classifications of galaxies‚Äô cosmic web environments. Using stellar mass-selected IllustrisTNG-300 galaxies, we apply a three-stage, simulation-based framework to link galaxies to the total (mainly dark) underlying matter distribution. Here, we apply the following three steps: First, we assign the positions of simulated galaxies to a void, wall, filament, or cluster environment using the T-Web classification of the underlying matter distribution. Second, we construct a Delaunay triangulation of the galaxy distribution to summarise the local geometric structure with ten graph metrics for each galaxy. Third, we train a graph attention network (GAT) on each galaxy‚Äôs graph metrics to predict its cosmic web environment. For galaxies with stellar mass $\\mathrm{\u003e10^9 M_{\\odot}}$, our GAT+ model achieves an accuracy of $85,%$, outperforming graph-agnostic multilayer perceptrons and graph convolutional networks. Our results demonstrate that graph-based representations of galaxy positions provide a powerful and physically meaningful way to infer dark matter environments. We plan to apply this simulation-based graph modelling to investigate how the properties of observed galaxies from the Dark Energy Spectroscopic Instrument (DESI) survey are influenced by their dark matter environments.\nüìÑ Download PDF\nLPD: Learnable Prototypes with Diversity Regularization for Weakly Supervised Histopathology Segmentation Authors: Khang Le, Anh Mai Vu, Thi Kim Trang Vo, Ha Thach, Ngoc Bui Lam Quang, Thanh-Huy Nguyen, Minh H. N. Le, Zhu Han, Chandra Mohan, Hien Van Nguyen Venue: arXiv (2025)\nWeakly supervised semantic segmentation (WSSS) in histopathology reduces pixel-level labeling by learning from image-level labels, but it is hindered by inter-class homogeneity, intra-class heterogeneity, and CAM-induced region shrinkage (global pooling-based class activation maps whose activations highlight only the most distinctive areas and miss nearby class regions). Recent works address these challenges by constructing a clustering prototype bank and then refining masks in a separate stage; however, such two-stage pipelines are costly, sensitive to hyperparameters, and decouple prototype discovery from segmentation learning, limiting their effectiveness and efficiency. We propose a cluster-free, one-stage learnable-prototype framework with diversity regularization to enhance morphological intra-class heterogeneity coverage. Our approach achieves state-of-the-art (SOTA) performance on BCSS-WSSS, outperforming prior methods in mIoU and mDice. Qualitative segmentation maps show sharper boundaries and fewer mislabels, and activation heatmaps further reveal that, compared with clustering-based prototypes, our learnable prototypes cover more diverse and complementary regions within each class, providing consistent qualitative evidence for their effectiveness.\nüìÑ Download PDF\nA redshift-independent theoretical halo mass function validated with the Uchuu simulations Authors: Elena Fern√°ndez-Garc√≠a, Juan E. Betancort-Rijo, Francisco Prada, Tomoaki Ishiyama, Anatoly Klypin, Jos√© Ruedas Venue: arXiv (2025)\nWe present a new theoretical framework for the halo mass function (HMF) that accurately predicts the abundance of dark matter haloes across an exceptionally wide range in mass and redshift. Building on a generalised Press \u0026 Schechter model and triaxial collapse (GPS+), we predict the HMF in terms of the variance of the linear density field, with only a weak explicit dependence on halo mass and no explicit dependence on redshift. The GPS+ model naturally provides the correct normalization and high-mass behaviour without requiring empirical fitting. We calibrate and validate the GPS+ model using the Uchuu N-body simulation suite, which combines large cosmological volume and high mass resolution under Planck cosmology. Using six simulations with up to 300 realizations, we obtain precision HMF measurements spanning halo masses in the range 6.5 \u003c log($M_{\\rm 200m}$/[h$^{-1}$ $M_{\\odot}$]) \u003c16 over 0 \u003c z \u003c 20, with reduced cosmic variance. Across this full domain, the GPS+ model reproduces the simulated HMF with deviations typically below 10-20%. Comparison with the Sheth-Tormen (ST) model shows similar performance at z \u003c 2, but markedly improved agreement at higher redshifts, where ST can deviate by 70-80% while our model remains within ~20%. Finally, we assess the impact of the halo mass definition: adopting the evolving virial overdensity of Bryan \u0026 Norman (1998) worsens agreement at low redshift and high masses, whereas M200m yields a more universal, nearly redshift-independent HMF.\nüìÑ Download PDF\nTwisting the Hagedorn temperature in planar $\\mathcal{N}=4$ super Yang-Mills Authors: Simon Ekhammar, Joseph A. Minahan, Charles Thull Venue: arXiv (2025)\nWe consider planar $\\mathcal{N}=4$ super Yang-Mills at finite temperature with chemical potentials that couple either to the $R$-charges or the spins of the operators. We find expressions for the Hagedorn temperatures at both zero coupling by explicitly counting states, and at strong coupling using the string theory dual. We then apply the quantum spectral curve (QSC) to this problem, which adds additional twists to the $Q$-functions. For a single chemical potential $Œº$ coupled to one of the $R$-charges, we find the analytic weak-coupling Hagedorn temperature to one-loop order for any value of $Œº$, and to two-loop order for $Œº=1/2$. We then solve the QSC numerically, showing that at strong coupling there is good agreement with the string theory prediction to order $1/Œª^{1/4}$. This provides further evidence for a recent conjecture of Harmark for the form of the world-sheet zero-point shift. We also use the QSC to find the analytic one-loop correction to the Hagedorn temperature with non-zero chemical potentials coupled to the spins.\nüìÑ Download PDF\nSize-effects on shift-current in layered CuInP$_2$S$_6$ Authors: Francesco Delodovici, Brahim Dkhil, Charles Paillard Venue: arXiv (2025)\nTwo-dimensional ferroelectrics have recently emerged as a promising avenue for next-generation optoelectronic and photovoltaic devices. Due to the intrinsic absence of inversion symmetry, 2D ferroelectrics exhibit bulk photovoltaic effect (BPVE), which relies on hot, non-thermalized photo-excited carriers to generate a photo-induced current with enhanced performances thanks to efficient charge separation mechanisms. The absence of a required p-n junction architecture makes these materials particularly attractive for nanoscale energy harvesting. Recent studies have reported enhanced BPVE in nanometer-thick CuInP$_2$S$_6$ ferroelectric embedded between two graphene wafers, driven by relatively strong polarization and reduced dimensionality. Short circuit photocurrent density values have been observed to reach up to mA/cm$^2$. In this paper, we demonstrate that the shift-current mechanism alone cannot fully account for these high conductivity values, suggesting that additional mechanisms may play a significant role. Furthermore, our work confirms the existence of a strong size effect, which drastically reduces the shift-conductivity response in the bulk limit, in agreement with experimental observations.\nüìÑ Download PDF\nMulti-band ALMA Polarization Observations of BHB07-11 Reveal Aligned Dust Grains in Complex Spiral Arm Structures Authors: Austen Fourkas, Leslie W. Looney, Zhe-Yu Daniel Lin, Martin Radecki, Zhi-Yun Li, John J. Tobin, Ian W. Stephens, Manuel Fern√°ndez-L√≥pez, Haifeng Yang, Woojin Kwon, Rachel Harrison Venue: arXiv (2025)\nPolarization-mode observations from the Atacama Large Millimeter/submillimeter Array (ALMA) are powerful tools for studying the dust grain populations in circumstellar disks. Many sources exhibit polarization signatures consistent with aligned dust grains, yet the physical origin of this alignment remains uncertain. One such source is BHB07-11, a Class I protobinary object in the Pipe Nebula with complex spiral arm structures in its circumbinary disk. While magnetic fields are often invoked to explain grain alignment in the interstellar medium, the contrasting conditions in circumstellar disk environments demand further investigation into grain alignment mechanisms. To determine BHB07-11‚Äôs dominant polarization mechanism, we leverage ALMA polarization-mode dust continuum observations in Bands 3 ($Œª$=3.1 mm), 6 ($Œª$=1.3 mm), and 7 ($Œª$=0.87 mm), in combination with high-resolution dust continuum and spectral line observations in Band 6. Observed polarization vectors in each band are consistent with emission from aligned grains and follow the structure of the spiral arms as shown in the high-resolution observations. Given the relationship between the observed polarization vector orientation and the spiral arms, we find that the polarization morphology is most consistent with grains aligned through a relative velocity flow between gas and dust in the spiral arms, as envisioned in the recently developed badminton birdie-like alignment mechanism, rather than alignment with a magnetic field or other known alignment mechanisms.\nüìÑ Download PDF\n4d/3d reduction of dualities with O6 Authors: Antonio Amariti, Pietro Glorioso, Chiara Mascherpa, Andrea Zanetti Venue: arXiv (2025)\nWe consider $\\mathrm{U}(N)$ gauge theories with a pair of two-index tensors interacting through a quartic superpotential, in addition to fundamentals and antifundamentals. The models have a brane engineering in terms of NS, D4, D6 branes and an O6 plane. Depending on the representation of the tensorial matter we have either an O6$^{+}$ plane, an O6$^{-}$ plane or a combined state of O6$^{+}$ and O6$^{-}$, with the addition of 8 semi-infinite half-D6 branes, where the last case realizes a chiral theory. The 4d IR duality is realized through an HW transition in the brane description. Here we study the circle reduction of these dualities from the brane perspective by T-dualizing along the compact direction. We then compare the results against the one obtained from field theoretical considerations and from localization, finding a precise agreement. When we consider the reduction of the 4d superconformal index to the 3d squashed three sphere partition function we observe that it is not always possible to obtain convergent 3d result with the standard reduction prescription, and that the double scaling limit is necessary.\nüìÑ Download PDF\nWhatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity Authors: Germ√°n Kruszewski, Pierre Erbacher, Jos Rozen, Marc Dymetman Venue: arXiv (2025)\nReinforcement Learning (RL) has become the de facto standard for tuning LLMs to solve tasks involving reasoning. However, growing evidence shows that models trained in such way often suffer from a significant loss in diversity. We argue that this arises because RL implicitly optimizes the ‚Äúmode-seeking‚Äù or ‚Äúzero-forcing‚Äù Reverse KL to a target distribution causing the model to concentrate mass on certain high-probability regions of the target while neglecting others. In this work, we instead begin from an explicit target distribution, obtained by filtering out incorrect answers while preserving the relative probabilities of correct ones. Starting from a pre-trained LLM, we approximate this target distribution using the $Œ±$-divergence family, which unifies prior approaches and enables direct control of the precision-diversity trade-off by interpolating between mode-seeking and mass-covering divergences. On a Lean theorem-proving benchmark, our method achieves state-of-the-art performance along the coverage-precision Pareto frontier, outperforming all prior methods on the coverage axis.\nüìÑ Download PDF\nConsequences of Kernel Regularity for Bandit Optimization Authors: Madison Lee, Tara Javidi Venue: arXiv (2025)\nIn this work we investigate the relationship between kernel regularity and algorithmic performance in the bandit optimization of RKHS functions. While reproducing kernel Hilbert space (RKHS) methods traditionally rely on global kernel regressors, it is also common to use a smoothness-based approach that exploits local approximations. We show that these perspectives are deeply connected through the spectral properties of isotropic kernels. In particular, we characterize the Fourier spectra of the Mat√©rn, square-exponential, rational-quadratic, $Œ≥$-exponential, piecewise-polynomial, and Dirichlet kernels, and show that the decay rate determines asymptotic regret from both viewpoints. For kernelized bandit algorithms, spectral decay yields upper bounds on the maximum information gain, governing worst-case regret, while for smoothness-based methods, the same decay rates establish H√∂lder space embeddings and Besov space norm-equivalences, enabling local continuity analysis. These connections show that kernel-based and locally adaptive algorithms can be analyzed within a unified framework. This allows us to derive explicit regret bounds for each kernel family, obtaining novel results in several cases and providing improved analysis for others. Furthermore, we analyze LP-GP-UCB, an algorithm that combines both approaches, augmenting global Gaussian process surrogates with local polynomial estimators. While the hybrid approach does not uniformly dominate specialized methods, it achieves order-optimality across multiple kernel families.\nüìÑ Download PDF\nCorrespondence-Oriented Imitation Learning: Flexible Visuomotor Control with 3D Conditioning Authors: Yunhao Cao, Zubin Bhaumik, Jessie Jia, Xingyi He, Kuan Fang Venue: arXiv (2025)\nWe introduce Correspondence-Oriented Imitation Learning (COIL), a conditional policy learning framework for visuomotor control with a flexible task representation in 3D. At the core of our approach, each task is defined by the intended motion of keypoints selected on objects in the scene. Instead of assuming a fixed number of keypoints or uniformly spaced time intervals, COIL supports task specifications with variable spatial and temporal granularity, adapting to different user intents and task requirements. To robustly ground this correspondence-oriented task representation into actions, we design a conditional policy with a spatio-temporal attention mechanism that effectively fuses information across multiple input modalities. The policy is trained via a scalable self-supervised pipeline using demonstrations collected in simulation, with correspondence labels automatically generated in hindsight. COIL generalizes across tasks, objects, and motion patterns, achieving superior performance compared to prior methods on real-world manipulation tasks under both sparse and dense specifications.\nüìÑ Download PDF\nHeard or Halted? Gender, Interruptions, and Emotional Tone in U.S. Supreme Court Oral Arguments Authors: Yifei Tong Venue: arXiv (2025)\nThis study examines how interruptions during U.S. Supreme Court oral arguments shape both the semantic content and emotional tone of advocates‚Äô speech, with a focus on gendered dynamics in judicial discourse. Using the ConvoKit Supreme Court Corpus (2010-2019), we analyze 12,663 speech chunks from advocate-justice interactions to assess whether interruptions alter the meaning of an advocate‚Äôs argument and whether interruptions toward female advocates exhibit more negative emotional valence. Semantic shifts are quantified using GloVe-based sentence embeddings, while sentiment is measured through lexicon-based analysis. We find that semantic similarity between pre- and post-interruption speech remains consistently high, suggesting that interruptions do not substantially alter argumentative content. However, interruptions directed at female advocates contain significantly higher levels of negative sentiment. These results deepen empirical understanding of gendered communication in elite institutional settings and demonstrate the value of computational linguistic methods for studying power, discourse, and equity in judicial proceedings.\nüìÑ Download PDF\nUnveiling Affective Polarization Trends in Parliamentary Proceedings Authors: Gili Goldin, Ella Rabinovich, Shuly Wintner Venue: arXiv (2025)\nRecent years have seen an increase in polarized discourse worldwide, on various platforms. We propose a novel method for quantifying polarization, based on the emotional style of the discourse rather than on differences in ideological stands. Using measures of Valence, Arousal and Dominance, we detect signals of emotional discourse and use them to operationalize the concept of affective polarization. Applying this method to a recently released corpus of proceedings of the Knesset, the Israeli parliament (in Hebrew), we find that the emotional style of members of government differs from that of opposition members; and that the level of affective polarization, as reflected by this style, is significantly increasing with time.\nüìÑ Download PDF\nToward Continuous Neurocognitive Monitoring: Integrating Speech AI with Relational Graph Transformers for Rare Neurological Diseases Authors: Raquel Norel, Michele Merler, Pavitra Modi Venue: arXiv (2025)\nPatients with rare neurological diseases report cognitive symptoms -‚Äúbrain fog‚Äù- invisible to traditional tests. We propose continuous neurocognitive monitoring via smartphone speech analysis integrated with Relational Graph Transformer (RELGT) architectures. Proof-of-concept in phenylketonuria (PKU) shows speech-derived ‚ÄúProficiency in Verbal Discourse‚Äù correlates with blood phenylalanine (p = -0.50, p \u003c 0.005) but not standard cognitive tests (all |r| \u003c 0.35). RELGT could overcome information bottlenecks in heterogeneous medical data (speech, labs, assessments), enabling predictive alerts weeks before decompensation. Key challenges: multi-disease validation, clinical workflow integration, equitable multilingual deployment. Success would transform episodic neurology into continuous personalized monitoring for millions globally.\nüìÑ Download PDF\nSEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs Authors: Hao Wang, Jialun Zhong, Changcheng Wang, Zhujun Nie, Zheng Li, Shunyu Yao, Yanzeng Li, Xinchi Li Venue: arXiv (2025)\nKnowledge-based conversational question answering (KBCQA) confronts persistent challenges in resolving coreference, modeling contextual dependencies, and executing complex logical reasoning. Existing approaches, whether end-to-end semantic parsing or stepwise agent-based reasoning, often suffer from structural inaccuracies and prohibitive computational costs, particularly when processing intricate queries over large knowledge graphs. To address these limitations, we introduce SEAL, a novel two-stage semantic parsing framework grounded in self-evolving agentic learning. In the first stage, a large language model (LLM) extracts a minimal S-expression core that captures the essential semantics of the input query. This core is then refined by an agentic calibration module, which corrects syntactic inconsistencies and aligns entities and relations precisely with the underlying knowledge graph. The second stage employs template-based completion, guided by question-type prediction and placeholder instantiation, to construct a fully executable S-expression. This decomposition not only simplifies logical form generation but also significantly enhances structural fidelity and linking efficiency. Crucially, SEAL incorporates a self-evolving mechanism that integrates local and global memory with a reflection module, enabling continuous adaptation from dialog history and execution feedback without explicit retraining. Extensive experiments on the SPICE benchmark demonstrate that SEAL achieves state-of-the-art performance, especially in multi-hop reasoning, comparison, and aggregation tasks. The results validate notable gains in both structural accuracy and computational efficiency, underscoring the framework‚Äôs capacity for robust and scalable conversational reasoning.\nüìÑ Download PDF\nPlaying the Player: A Heuristic Framework for Adaptive Poker AI Authors: Andrew Paterson, Carl Sanders Venue: arXiv (2025)\nFor years, the discourse around poker AI has been dominated by the concept of solvers and the pursuit of unexploitable, machine-perfect play. This paper challenges that orthodoxy. It presents Patrick, an AI built on the contrary philosophy: that the path to victory lies not in being unexploitable, but in being maximally exploitative. Patrick‚Äôs architecture is a purpose-built engine for understanding and attacking the flawed, psychological, and often irrational nature of human opponents. Through detailed analysis of its design, its novel prediction-anchored learning method, and its profitable performance in a 64,267-hand trial, this paper makes the case that the solved myth is a distraction from the real, far more interesting challenge: creating AI that can master the art of human imperfection.\nüìÑ Download PDF\nLLM-SrcLog: Towards Proactive and Unified Log Template Extraction via Large Language Models Authors: Jiaqi Sun, Wei Li, Heng Zhang, Chutong Ding, Shiyou Qian, Jian Cao, Guangtao Xue Venue: arXiv (2025)\nLog parsing transforms raw logs into structured templates containing constants and variables. It underpins anomaly detection, failure diagnosis, and other AIOps tasks. Current parsers are mostly reactive and log-centric. They only infer templates from logs, mostly overlooking the source code. This restricts their capacity to grasp dynamic log structures or adjust to evolving systems. Moreover, per-log LLM inference is too costly for practical deployment. In this paper, we propose LLM-SrcLog, a proactive and unified framework for log template parsing. It extracts templates directly from source code prior to deployment and supplements them with data-driven parsing for logs without available code. LLM-SrcLog integrates a cross-function static code analyzer to reconstruct meaningful logging contexts, an LLM-based white-box template extractor with post-processing to distinguish constants from variables, and a black-box template extractor that incorporates data-driven clustering for remaining unmatched logs. Experiments on two public benchmarks (Hadoop and Zookeeper) and a large-scale industrial system (Sunfire-Compute) show that, compared to two LLM-based baselines, LLM-SrcLog improves average F1-score by 2-17% and 8-35%. Meanwhile, its online parsing latency is comparable to data-driven methods and about 1,000 times faster than per-log LLM parsing. LLM-SrcLog achieves a near-ideal balance between speed and accuracy. Finally, we further validate the effectiveness of LLM-SrcLog through practical case studies in a real-world production environment.\nüìÑ Download PDF\nStrongly Coupled Quantum Forces Authors: Yuval Grossman, Chinhsan Sieng, Xun-Jie Xu, Bingrong Yu Venue: arXiv (2025)\nQuantum forces are long-range interactions originating from vacuum fluctuations of mediator fields. Such forces inevitably arise between ordinary matter particles whenever they couple to light mediator species. Conventional computations of quantum forces rely on evaluating one-loop Feynman diagrams of the relevant scattering processes. In this work, we introduce a novel framework to compute quantum forces. Instead of relying on perturbative scattering amplitudes, we directly evaluate the quantum fluctuations of the mediator field by solving its quantized equation of motion with appropriate boundary conditions. This approach remains valid beyond the Born approximation and thus applies to regimes of strong coupling between the mediator and matter fields. In the weak-coupling limit, our results reproduce the known expressions from the Feynman diagram approach. In the strong-coupling regime, the result is modified by a factor that can suppress or enhance the effect. In contrast to classical forces, quantum forces intrinsically violate the superposition principle. Our approach may therefore offer a useful tool for probing non-perturbative effects in the infrared regime.\nüìÑ Download PDF\nEntanglement-Enhanced Quantum Nano-Vibrometry Authors: Colin P. Lualdi, Joshua Rapp, Spencer J. Johnson, Michael Vayninger, Paul G. Kwiat Venue: arXiv (2025)\nThe study of dynamic systems at the nanometer scale can benefit from the loss and background resilience offered by quantum two-photon interference. However, fast measurements with the required resolution are difficult to realize. As a solution, we introduce extreme energy entanglement between the photons undergoing interference. Using a flux probing analysis technique, we recover vibrational signals with frequencies as high as 21 kHz. Along with validating nanometer-scale precision and accuracy, we observe a significant quantum advantage when measuring in the presence of loss and background.\nüìÑ Download PDF\nTopical issue on the intersection of low-energy nuclear structure and high-energy nuclear collisions Authors: T. Duguet, G. Giacalone, V. Som√†, Y. Zhou Venue: arXiv (2025)\nHigh-energy heavy-ion physics and low-energy nuclear structure physics have historically been disconnected fields. The hydrodynamic description of the quark-gluon plasma (QGP) requires input from nuclear structure to model the initial states of the colliding nuclei. Advances in both theory and experiment now show that the hydrodynamic evolution of the QGP is sensitive to the detailed features of the colliding nuclei, with remarkable consequences for experimental observables. The topical collection represents a joint effort between the low- and high-energy nuclear communities, reflecting the growing recognition that precision modeling of nuclear structure is essential for interpreting high-energy collision data. This new experimental approach opens outstanding opportunities to deepen our understanding of strong-interaction matter. Indeed, by probing many-body correlations of nucleons directly in the nuclear ground state, high-energy collisions provide a unique way to ‚Äúimage‚Äù nuclei, fully complementary to the techniques of low-energy experiments, where nuclear collectivity is usually inferred from spectroscopic information on excited states. Do emergent many-body QCD phenomena in nuclei manifest consistently across experiments and energy scales? Addressing this question requires synergy between collider data and state-of-the-art nuclear structure calculations. In view of the rapid progress of ab initio methods based on low-energy effective field theories of QCD, the implications are far-reaching: heavy-ion collisions can probe nuclear forces, while nuclear structure insights refine our understanding of QGP dynamics.\nüìÑ Download PDF\nResolving Abrikosov vortex entry in superconducting nano-string resonators via displacement-noise spectroscopy in cavity-optomechanics Authors: Thomas Luschmann, Tahereh Sadat Parvini, Lukas Niekamp, Achim Marx, Rudolf Gross, Hans Huebl Venue: arXiv (2025)\nAbrikosov vortices in type-II superconductors critically influence current flow and coherence, thereby imposing fundamental limits on superconducting quantum technologies. Quantum circuits employ superconducting elements at micro- and mesoscopic scales, where individual vortices can significantly impact device performance, necessitating investigation of vortex entry, motion, and pinning in these constrained geometries. Cavity-optomechanical platforms combining flux-tunable microwave resonators with superconducting nanomechanical elements offer a promising route to the single-photon strong-coupling regime and enable highly sensitive probing of the mechanical degree of freedom under elevated magnetic fields. Here, we exploit this platform to investigate vortex entry processes at the single-event level. We observe discrete jumps of the mechanical resonance frequency attributable to individual vortex entry, corresponding to attonewton-scale forces and allowing quantitative extraction of single-vortex pinning energies. These signatures are superimposed on a smooth power-law background characteristic of the collective Campbell-regime of vortex elasticity. Our results establish optomechanics-inspired sensing as a powerful method for exploring fundamental superconducting properties and identifying decoherence pathways in quantum circuits. Beyond advancing vortex physics, this work opens new opportunities for integrating mechanical sensing into superconducting device architectures, bridging condensed matter physics and quantum information science.\nüìÑ Download PDF\nCategorifying isomonodromic deformations via Lie groupoids I: Logarithmic singularities Authors: Waleed Qaisar Venue: arXiv (2025)\nWe upgrade the classical operation of \\textit{isomonodromic deformations} along a path $Œ≥$ to a functor $\\mathbb{P}_Œ≥$ between categories of flat connections with logarithmic singularities along a divisor $D$, which itself depends functorially on $Œ≥$, using tools from the theory of Lie groupoids. As applications, (1) we get that isomonodromy gives a map of moduli \\textit{stacks} of flat connections with logarithmic singularities, (2) we encode higher homotopical information at level 2, i.e. we get an action of the fundamental 2-groupoid of the base of our family on the categories of logarithmic flat connections on the fibres, and (3) our methods produce a geometric incarnation of the isomonodromy functors as Morita equivalences which are more primary than the isomonodromy functors themselves, and from which they can be formally extracted by passing to representation categories.\nüìÑ Download PDF\nImpugan: Learning Conditional Generative Models for Robust Data Imputation Authors: Zalish Mahmud, Anantaa Kotal, Aritran Piplai Venue: arXiv (2025)\nIncomplete data are common in real-world applications. Sensors fail, records are inconsistent, and datasets collected from different sources often differ in scale, sampling rate, and quality. These differences create missing values that make it difficult to combine data and build reliable models. Standard imputation methods such as regression models, expectation-maximization, and multiple imputation rely on strong assumptions about linearity and independence. These assumptions rarely hold for complex or heterogeneous data, which can lead to biased or over-smoothed estimates. We propose Impugan, a conditional Generative Adversarial Network (cGAN) for imputing missing values and integrating heterogeneous datasets. The model is trained on complete samples to learn how missing variables depend on observed ones. During inference, the generator reconstructs missing entries from available features, and the discriminator enforces realism by distinguishing true from imputed data. This adversarial process allows Impugan to capture nonlinear and multimodal relationships that conventional methods cannot represent. In experiments on benchmark datasets and a multi-source integration task, Impugan achieves up to 82% lower Earth Mover‚Äôs Distance (EMD) and 70% lower mutual-information deviation (MI) compared to leading baselines. These results show that adversarially trained generative models provide a scalable and principled approach for imputing and merging incomplete, heterogeneous data. Our model is available at: github.com/zalishmahmud/impuganBigData2025\nüìÑ Download PDF\nRemoving correlated noise stripes from the Nancy Grace Roman Space Telescope survey images Authors: Katherine Laliotis, Christopher M. Hirata, Emily Macbeth, Kaili Cao Venue: arXiv (2025)\nWeak gravitational lensing has emerged as a powerful tool for investigating the matter distribution in the Universe and how it has evolved over cosmic time. The Wide Field Instrument (WFI) on the Nancy Grace Roman Space Telescope (Roman) will deliver some of the highest precision measurements of weak lensing ever made. Since weak lensing is based on statistics of faint sources, it can be biased by even tiny instrument systematics, including correlated read noise. Previous works have shown the infrared detectors used in the Roman WFI show correlations in their noise fields at a level significant for weak lensing measurements, even after application of standard reference pixel corrections; of particular concern is 1/f noise, which appears as horizontal banding in the detector frame. In this paper, we present imDestripe: a new Python module utilizing the multiple roll angles in Roman‚Äôs observing strategy and linear algebra techniques to remove correlated noise stripes from observed images. We test imDestripe in a hybrid simulation by combining real noise realizations (from darks taken during ground testing) with simulated images of the astronomical scene, and find that the power spectrum of the banding can be suppressed by factors of 10‚Äì30 on large scales. We briefly discuss plans for further development of imDestripe in the context of the WFI pipeline.\nüìÑ Download PDF\nOn cable-graph percolation between dimensions 2 and 3 Authors: Pierre-Fran√ßois Rodriguez, Wen Zhang Venue: arXiv (2025)\nWe consider the Gaussian free field on two-dimensional slabs with a thickness described by a height $h$ at spatial scale $N$. We investigate the radius of critical clusters for the associated cable-graph percolation problem, which depends sensitively on the parameter $h$. Our results unveil a whole family of new ‚Äúfixed points‚Äù, which interpolate between recent results from arXiv:2303.03782 in two dimensions and from arXiv:2405.17417 and arXiv:2406.02397 in three dimensions, and describe critical behaviour beyond those regimes. In the delocalised phase, the one-arm decay exhibits a ‚Äúplateau‚Äù, i.e. it doesn‚Äôt depend on the speed at which the variance of the field diverges in the large-$N$ limit. Our methods rely on a careful analysis of the interplay between two- and three-dimensional effects for the underlying random walk, which manifest themselves in a corresponding decomposition of the field.\nüìÑ Download PDF\nBootstrapping Fuzzers for Compilers of Low-Resource Language Dialects Using Language Models Authors: Sairam Vaidya, Marcel B√∂hme, Loris D‚ÄôAntoni Venue: arXiv (2025)\nModern extensible compiler frameworks-such as MLIR-enable rapid creation of domain-specific language dialects. This flexibility, however, makes correctness harder to ensure as the same extensibility that accelerates development also complicates maintaining the testing infrastructure. Extensible languages require automated test generation that is both dialect-agnostic (works across dialects without manual adaptation) and dialect-effective (targets dialect-specific features to find bugs). Existing approaches typically sacrifice one of these goals by either requiring manually constructed seed corpora for each dialect, or by failing to be effective. We present a dialect-agnostic and dialect-effective grammar-based and coverage-guided fuzzing approach for extensible compilers that combines two key insights from existing work: (i) the grammars of dialects, which already encode the structural and type constraints, can often be extracted automatically from the dialect specification; and (ii) these grammars can be used in combination with pre-trained large language models to automatically generate representative and diverse seed inputs from the full dialect space without requiring any manual input or training data. These seeds can then be used to bootstrap coverage-guided fuzzers. We built this approach into a tool, Germinator. When evaluated on six MLIR projects spanning 91 dialects, Germinator generated seeds improve line coverage by 10-120% over grammar-based baselines. We compare against grammar-based baselines because they are the only class of existing automatic seed generators that can be applied uniformly across MLIR‚Äôs heterogeneous dialect ecosystem. Germinator discovers 88 previously unknown bugs (40 confirmed), including 23 in dialects with no prior automated test generators, demonstrating effective and controllable testing of low-resource dialects at scale.\nüìÑ Download PDF\nModel selection with uncertainty in estimating optimal dynamic treatment regimes Authors: Chunyu Wang, Brian Tom Venue: arXiv (2025)\nOptimal dynamic treatment regimes (DTRs), as a key part of precision medicine, have progressively gained more attention recently. To inform clinical decision making, interpretable and parsimonious models for contrast functions are preferred, raising concerns about undue misspecification. It is therefore important to properly evaluate the performance of candidate interpretable models and select the one that best approximates the unknown contrast function. Moreover, since a DTR usually involves multiple decision points, an inaccurate approximation at a later decision point affects its estimation at an earlier decision point when a backward induction algorithm is applied. This paper aims to perform model selection for contrast functions in the context of learning optimal DTRs from observed data. Note that the relative performance of candidate models may heavily depend on the sample size when, for example, the comparison is made between parametric and tree-based models. Therefore, instead of investigating the limiting behavior of each candidate model and developing methods to select asymptotically the `correct‚Äô one, we focus on the finite sample performance of each model and attempt to perform model selection under a given sample size. To this end, we adopt the counterfactual cross-validation metric and propose a novel method to estimate the variance of the metric. Supplementing the cross-validation metric with its estimated variance allows us to characterize the uncertainty in model selection under a given sample size and facilitates hypothesis testing associated with a preferred model structure.\nüìÑ Download PDF\nConscious Gaze: Adaptive Attention Mechanisms for Hallucination Mitigation in Vision-Language Models Authors: Weijue Bu, Guan Yuan, Guixian Zhang Venue: arXiv (2025)\nLarge Vision-Language Models (VLMs) often exhibit text inertia, where attention drifts from visual evidence toward linguistic priors, resulting in object hallucinations. Existing decoding strategies intervene only at the output logits and thus cannot correct internal reasoning drift, while recent internal-control methods based on heuristic head suppression or global steering vectors lack principled grounding. We introduce Conscious Gaze (CG-VLM), a training-free, inference-time framework that converts game-theoretic interpretability into actionable decoding control. A Cognitive Demand Sensor built on Harsanyi interactions estimates instantaneous vision-text synergy and identifies moments when visual grounding is necessary. Conditioned on this signal, a Focused Consensus Induction module selectively reorients mid-layer attention toward visual tokens before collapse into text priors. CG-VLM achieves state-of-the-art results on POPE and CHAIR across InstructBLIP, LLaVA, Qwen-VL, and mPLUG, while preserving general capabilities, demonstrating that token-level sensing enables precise, context-aware intervention without compromising foundational knowledge.\nüìÑ Download PDF\nAn evaluation of A15 Nb3Al superconducting thin films for application in quantum circuits Authors: Joseph Falvo, Brooke Henry, Bernardo Langa, Rohit Pant, Ashish Alexander, Jason Dong, Kasra Sardashti Venue: arXiv (2025)\nA15 superconductors are distinguished by their high critical temperatures, magnetic fields, and current-carrying capabilities. Among them, Nb$_3$Al is of particular interest for superconducting quantum circuits as a means to extend device operating temperatures, provided that its electrodynamic properties are well understood. Here, we report on the synthesis of Nb$_3$Al thin films by magnetron co-sputtering followed by rapid thermal processing, yielding superconducting transition temperatures above 16~K. Microwire devices patterned from these films exhibit a coherence length of $3.2,\\mathrm{nm}$ and superfluid densities as low as $1.1\\times 10^{26},\\mathrm{m}^{-3}$, suggesting that Nb$_3$Al may enable high kinetic inductance in thinner films. Coplanar waveguide resonators fabricated on Nb$_3$Al demonstrate single-photon internal quality factors up to $2.26\\times 10^{5}$. These results establish Nb$_3$Al as a promising material platform for the development of superconducting quantum circuits operating at elevated temperatures, contingent on appropriate control of interfacial chemistry and surface morphology.\nüìÑ Download PDF\nComparative Analysis of Barrier-like Function Methods for Reach-Avoid Verification in Stochastic Discrete-Time Systems Authors: Zhipeng Cao, Peixin Wang, Luke Ong, ƒêorƒëe ≈Ωikeliƒá, Dominik Wagner, Bai Xue Venue: arXiv (2025)\nIn this paper, we compare several representative barrier-like conditions from the literature for infinite-horizon reach-avoid verification of stochastic discrete-time systems. Our comparison examines both their theoretical properties and computational tractability, highlighting each condition‚Äôs strengths and limitations that affect applicability and conservativeness. Finally, we illustrate their practical performance through computational experiments using semidefinite programming (SDP) and counterexample-guided inductive synthesis (CEGIS).\nüìÑ Download PDF\nOn Planar Straight-Line Dominance Drawings Authors: Patrizio Angelini, Michael A. Bekos, Giuseppe Di Battista, Fabrizio Frati, Luca Grilli, Giacomo Ortali Venue: arXiv (2025)\nWe study the following question, which has been considered since the 90‚Äôs: Does every $st$-planar graph admit a planar straight-line dominance drawing? We show concrete evidence for the difficulty of this question, by proving that, unlike upward planar straight-line drawings, planar straight-line dominance drawings with prescribed $y$-coordinates do not always exist and planar straight-line dominance drawings cannot always be constructed via a contract-draw-expand inductive approach. We also show several classes of $st$-planar graphs that always admit a planar straight-line dominance drawing. These include $st$-planar $3$-trees in which every stacking operation introduces two edges incoming into the new vertex, $st$-planar graphs in which every vertex is adjacent to the sink, $st$-planar graphs in which no face has the left boundary that is a single edge, and $st$-planar graphs that have a leveling with span at most two.\nüìÑ Download PDF\nüîç psycholinguistics Constraining r-process nucleosynthesis via enhanced accuracy neutron-capture experiments Authors: C. Domingo-Pardo, C. Lederer-Woods, A. Mengoni Venue: arXiv (2025)\nThe isotopic abundances of r-process elements in the solar system are traditionally derived as residuals from the subtraction of s-process contributions from total solar abundances. However, the uncertainties in s-process nucleosynthesis ‚Äì particularly those arising from Maxwellian Averaged Cross Sections (MACS) ‚Äì propagate directly into the r-process residuals, affecting their reliability. Building upon the seminal work of Goriely (1999), who introduced a multi-event s-process model to quantify these uncertainties, we revisit the problem using a simplified yet effective approach. By assuming that the relative uncertainty in s-process isotopic abundances scales linearly with the MACS uncertainties from data libraries (KADoNiS), we identify a subset of isotopes for which the r-process residuals remain significantly uncertain. Using updated solar abundances (Lodders 2025) and s-process contributions from Bisterzo et al. (2014), we present a short list of isotopes that are prime candidates for improved (n,g) measurements at CERN n_TOF in the near future. Our analysis provides a practical framework for prioritizing future experimental efforts that will profit from upgrades and enhancements of the n_TOF facility. It also highlights the need to revisit key neutron-capture cross sections to refine our understanding of the r-process isotopic abundance pattern, commonly used as a benchmark in stellar models of explosive nucleosynthesis.\nüìÑ Download PDF\nEvolutionary System 2 Reasoning: An Empirical Proof Authors: Zeyuan Ma, Wenqi Huang, Guo-Huan Song, Hongshu Guo, Sijie Ma, Zhiguang Cao, Yue-Jiao Gong Venue: arXiv (2025)\nMachine intelligence marks the ultimate dream of making machines‚Äô intelligence comparable to human beings. While recent progress in Large Language Models (LLMs) show substantial specific skills for a wide array of downstream tasks, they more or less fall shorts in general intelligence. Following correlation between intelligence and system 2 reasoning (slow thinking), in this paper, we aim to answering a worthwhile research question: could machine intelligence such as LLMs be evolved to acquire reasoning ability (not specific skill) just like our human beings? To this end, we propose evolutionary reasoning optimization (ERO) framework which performs survival of the fittest over a population of LLMs to search for individual with strong reasoning ability. Given a reasoning task, ERO first initializes multiple LLMs as a population, after which an evolutionary strategy evolves the population to maximize quantified reasoning score of the best individual. Based on experiments on representative testsuites, we claim two surprising empirical discoveries: i) the latest LLMs such as GPT-5 still show limited system 2 reasoning ability; ii) with simple evolution-loop of ERO, a relatively weak model (Qwen-7B) could be enhanced to emerge powerful reasoning ability. Our project can be accessed at https://github.com/MetaEvo/ERO for reproduction needs.\nüìÑ Download PDF\nSqueezing Classical Antiferromagnets into Quantum Spin Liquids via Global Cavity Fluctuations Authors: Charlie-Ray Mann, Mark A. Oehlgrien, B≈Ça≈ºej Jaworowski, Giuseppe Calaj√≥, Jamir Marino, Kyung S. Choi, Darrick E. Chang Venue: arXiv (2025)\nCavity quantum electrodynamics with atomic ensembles is typically associated with collective spin phenomena, such as superradiance and spin squeezing, in which the atoms evolve collectively as a macroscopic spin ($S\\sim N/2$) on the Bloch sphere. Surprisingly, we show that the tendency toward a collective spin description need not imply collective spin phenomena; rather, it can be exploited to generate new forms of strongly correlated quantum matter. The key idea is to use uniform cavity-mediated interactions to energetically project the system into the total-spin singlet sector ($S=0$) - a highly entangled subspace where the physics is governed entirely by cavity fluctuations. Focusing on Rydberg atom arrays coupled to a single-mode cavity, we show that global cavity fluctuations can effectively squeeze classical antiferromagnets into quantum spin liquids, characterized by non-local entanglement, fractionalized excitations, and emergent gauge fields. This work suggests that cavity QED can be a surprising resource for inducing strongly correlated phenomena, which could be explored in the new generation of hybrid tweezer-cavity platforms.\nüìÑ Download PDF\nAnomaly cancellation and one-loop finiteness of 6D half-maximal supergravities Authors: Renata Kallosh Venue: arXiv (2025)\nWe explain why the surprising one-loop finiteness of 6D half-maximal supergravities recently discovered by Huang et al [1] is the result of the cancellation of the six-dimensional gravitational and gauge anomalies in (2,0) supergravity with 21 tensor multiplets and (1,1) supergravity with 20 vector multiplets.\nüìÑ Download PDF\nAn elementary approach to Wehrl-type entropy bounds in quantitative form Authors: Fabio Nicola, Federico Riccardi, Paolo Tilli Venue: arXiv (2025)\nWe consider the problem of the stability (with sharp exponent) of the Lieb‚ÄìSolovej inequality for symmetric $SU(N)$ coherent states, which was obtained only recently by the authors. Here, we propose an elementary proof of this result, based on reformulating the Wehrl-type entropy as a function defined on the unit sphere in $\\mathbb{C}^d$, for some suitable $d$, and on some explicit (and somewhat surprising) computations.\nüìÑ Download PDF\nCounting AdS Vacua Authors: Zihni Kaan Baykara, Alessandro Tomasiello, Cumrun Vafa Venue: arXiv (2025)\nWe study the ‚Äônumber‚Äô $\\mathfrak{N}(Œº)$ of AdS vacua with a UV cut off $ Œº$. It has been proposed that this number is finite. We find evidence that $\\mathfrak{N}(Œº)\\lesssim a \\ Œº^{-b}$ as $Œº\\rightarrow 0$ for some constants $a$ and $b$ of $O(1)$ in Planck units that may depend on dimension and the number of supercharges. For this result to hold it is crucial to integrate over the volume of massless and tachyonic directions of AdS which corresponds to the volume of the space of marginal and relevant deformations of the dual CFT. We are led to the surprising prediction that theories with large number of light moduli contribute very little to the volume measure among all theories. We also speculate about the dS case leading to the number of quasi-dS vacua of the order of $Œõ^{-Œ±}$ for some $O(1)$ parameter $Œ±$.\nüìÑ Download PDF\nStructure theorems for the heart of LCA Authors: Oliver Braunling, Fei Ren Venue: arXiv (2025)\nCohomology theories with values in LCA (locally compact abelian) groups suffer from the problem that the latter do not form an abelian category. However, the category LCA has a canonical abelian category envelope, the heart of a suitable t-structure. It adds formal cokernel objects. We show the surprising result that these abstract cokernels can also be interpreted as Hausdorff topological abelian groups, at least up to lattice isogenies. These need not be locally compact.\nüìÑ Download PDF\nGroup Classification (1+2)-dimensional Linear Equation of Asian Options Pricing Authors: Stanislav V. Spichak, Valeriy I. Stogniy, Inna M. Kopas Venue: arXiv (2025)\nWe consider a class of (1+2)-dimensional linear partial differential of Asian options pricing. Special cases have been used to models of financial mathematics. We carry out group classification of a class equations. In particular, the maximum dimension Lie invariance algebra within the above class is eight-dimensional. It is shown that an equation with such an algebra can be transformed into the linear Kolmogorov equation with the help of the point transformations of variables. Using the operators of invariance algebra symmetry reduction is carried out and invariant exact solutions are constructed for some equations.\nüìÑ Download PDF\nTrusted AI Agents in the Cloud Authors: Teofil Bodea, Masanori Misono, Julian Pritzi, Patrick Sabanic, Thore Sommer, Harshavardhan Unnibhavi, David Schall, Nuno Santos, Dimitrios Stavrakakis, Pramod Bhatotia Venue: arXiv (2025)\nAI agents powered by large language models are increasingly deployed as cloud services that autonomously access sensitive data, invoke external tools, and interact with other agents. However, these agents run within a complex multi-party ecosystem, where untrusted components can lead to data leakage, tampering, or unintended behavior. Existing Confidential Virtual Machines (CVMs) provide only per binary protection and offer no guarantees for cross-principal trust, accelerator-level isolation, or supervised agent behavior. We present Omega, a system that enables trusted AI agents by enforcing end-to-end isolation, establishing verifiable trust across all contributing principals, and supervising every external interaction with accountable provenance. Omega builds on Confidential VMs and Confidential GPUs to create a Trusted Agent Platform that hosts many agents within a single CVM using nested isolation. It also provides efficient multi-agent orchestration with cross-principal trust establishment via differential attestation, and a policy specification and enforcement framework that governs data access, tool usage, and inter-agent communication for data protection and regulatory compliance. Implemented on AMD SEV-SNP and NVIDIA H100, Omega fully secures agent state across CVM-GPU, and achieves high performance while enabling high-density, policy-compliant multi-agent deployments at cloud scale.\nüìÑ Download PDF\nA Comparative Study on Synthetic Facial Data Generation Techniques for Face Recognition Authors: Pedro Vidal, Bernardo Biesseck, Luiz E. L. Coelho, Roger Granada, David Menotti Venue: arXiv (2025)\nFacial recognition has become a widely used method for authentication and identification, with applications for secure access and locating missing persons. Its success is largely attributed to deep learning, which leverages large datasets and effective loss functions to learn discriminative features. Despite these advances, facial recognition still faces challenges in explainability, demographic bias, privacy, and robustness to aging, pose variations, lighting changes, occlusions, and facial expressions. Privacy regulations have also led to the degradation of several datasets, raising legal, ethical, and privacy concerns. Synthetic facial data generation has been proposed as a promising solution. It mitigates privacy issues, enables experimentation with controlled facial attributes, alleviates demographic bias, and provides supplementary data to improve models trained on real data. This study compares the effectiveness of synthetic facial datasets generated using different techniques in facial recognition tasks. We evaluate accuracy, rank-1, rank-5, and the true positive rate at a false positive rate of 0.01% on eight leading datasets, offering a comparative analysis not extensively explored in the literature. Results demonstrate the ability of synthetic data to capture realistic variations while emphasizing the need for further research to close the performance gap with real data. Techniques such as diffusion models, GANs, and 3D models show substantial progress; however, challenges remain.\nüìÑ Download PDF\nThe Bayesian Way: Uncertainty, Learning, and Statistical Reasoning Authors: Juan Sosa, Carlos A. Mart√≠nez, Danna Cruz Venue: arXiv (2025)\nThis paper offers a comprehensive introduction to Bayesian inference, combining historical context, theoretical foundations, and core analytical examples. Beginning with Bayes‚Äô theorem and the philosophical distinctions between Bayesian and frequentist approaches, we develop the inferential framework for estimation, interval construction, hypothesis testing, and prediction. Through canonical models, we illustrate how prior information and observed data are formally integrated to yield posterior distributions. We also explore key concepts including loss functions, credible intervals, Bayes factors, identifiability, and asymptotic behavior. While emphasizing analytical tractability in classical settings, we outline modern extensions that rely on simulation-based methods and discuss challenges related to prior specification and model evaluation. Though focused on foundational ideas, this paper sets the stage for applying Bayesian methods in contemporary domains such as hierarchical modeling, nonparametrics, and structured applications in time series, spatial data, networks, and political science. The goal is to provide a rigorous yet accessible entry point for students and researchers seeking to adopt a Bayesian perspective in statistical practice.\nüìÑ Download PDF\nUG-FedDA: Uncertainty-Guided Federated Domain Adaptation for Multi-Center Alzheimer‚Äôs Disease Detection Authors: Fubao Zhu, Zhanyuan Jia, Zhiguo Wang, Huan Huang, Danyang Sun, Chuang Han, Yanting Li, Jiaofen Nan, Chen Zhao, Weihua Zhou Venue: arXiv (2025)\nAlzheimer‚Äôs disease (AD) is an irreversible neurodegenerative disorder, and early diagnosis is critical for timely intervention. However, most existing classification frameworks face challenges in multicenter studies, as they often neglect inter-site heterogeneity and lack mechanisms to quantify uncertainty, which limits their robustness and clinical applicability. To address these issues, we proposed Uncertainty-Guided Federated Domain Adaptation (UG-FedDA), a novel multicenter AD classification framework that integrates uncertainty quantification (UQ) with federated domain adaptation to handle cross-site structure magnetic resonance imaging (MRI) heterogeneity under privacy constraints. Our approach extracts multi-template region-of-interest (RoI) features using a self-attention transformer, capturing both regional representations and their interactions. UQ is integrated to guide feature alignment, mitigating source-target distribution shifts by down-weighting uncertain samples. Experiments are conducted on three public datasets: the Alzheimer‚Äôs Disease Neuroimaging Initiative (ADNI), the Australian Imaging, Biomarkers and Lifestyle study (AIBL), and the Open Access Series of Imaging Studies (OASIS). UG-FedDA achieved consistent cross-domain improvements in accuracy, sensitivity, and area under the ROC curve across three classification tasks: AD vs. normal controls (NC), mild cognitive impairment (MCI) vs. AD, and NC vs. MCI. For NC vs. AD, UG-FedDA achieves accuracies of 90.54%, 89.04%, and 77.78% on ADNI, AIBL and OASIS datasets, respectively. For MCI vs. AD, accuracies are 80.20% (ADNI), 71.91% (AIBL), and 79.73% (OASIS). For NC vs. MCI, results are 76.87% (ADNI), 73.91% (AIBL), and 83.73% (OASIS). These results demonstrate that the proposed framework not only adapts efficiently across multiple sites but also preserves strict privacy.\nüìÑ Download PDF\nSpeech World Model: Causal State-Action Planning with Explicit Reasoning for Speech Authors: Xuanru Zhou, Jiachen Lian, Henry Hong, Xinyi Yang, Gopala Anumanchipalli Venue: arXiv (2025)\nCurrent speech-language models (SLMs) typically use a cascade of speech encoder and large language model, treating speech understanding as a single black box. They analyze the content of speech well but reason weakly about other aspects, especially under sparse supervision. Thus, we argue for explicit reasoning over speech states and actions with modular and transparent decisions. Inspired by cognitive science we adopt a modular perspective and a world model view in which the system learns forward dynamics over latent states. We factorize speech understanding into four modules that communicate through a causal graph, establishing a cognitive state search space. Guided by posterior traces from this space, an instruction-tuned language model produces a concise causal analysis and a user-facing response, enabling counterfactual interventions and interpretability under partial supervision. We present the first graph based modular speech model for explicit reasoning and we will open source the model and data to promote the development of advanced speech understanding.\nüìÑ Download PDF\nA Hybrid Dynamic Model for Predicting Human Cognition and Reliance during Automated Driving Authors: Sibibalan Jeevanandam, Neera Jain Venue: arXiv (2025)\nWe propose a simple (12 parameter) hybrid dynamic model that simultaneously captures the continuous-valued dynamics of three human cognitive states-trust, perceived risk, and mental workload-as well as discrete transitions in reliance on the automation. The discrete-time dynamic evolution of each cognitive state is modeled using a first-order affine difference equation. Reliance is defined as a single discrete-valued state, whose evolution at each time step depends on the cognitive states satisfying certain threshold conditions. Using data collected from 16 participants, we estimate participant-specific model parameters based on their reliance on the automation and intermittently self-reported cognitive states during a continuous drive in a vehicle simulator. The model can be estimated using a single user‚Äôs trajectory data (e.g. 8 minutes of driving), making it suitable for online parameter adaptation methods. Our results show that the model fits the observed trajectories well for several participants, with their reliance behavior primarily influenced by trust, perceived risk, or both. Importantly, the model is interpretable, such that the variations in model parameters across participants provide insights into differences in the time scales over which cognitive states evolve, and how these states are influenced by task complexity. Implications on the design of human-centric vehicle automation design are discussed.\nüìÑ Download PDF\nA Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning Authors: Wencheng Cai, Xuchao Gao, Congying Han, Mingqiang Li, Tiande Guo Venue: arXiv (2025)\nThe fast deployment of cognitive radar to counter jamming remains a critical challenge in modern warfare, where more efficient deployment leads to quicker detection of targets. Existing methods are primarily based on evolutionary algorithms, which are time-consuming and prone to falling into local optima. We tackle these drawbacks via the efficient inference of neural networks and propose a brand new framework: Fast Anti-Jamming Radar Deployment Algorithm (FARDA). We first model the radar deployment problem as an end-to-end task and design deep reinforcement learning algorithms to solve it, where we develop integrated neural modules to perceive heatmap information and a brand new reward format. Empirical results demonstrate that our method achieves coverage comparable to evolutionary algorithms while deploying radars approximately 7,000 times faster. Further ablation experiments confirm the necessity of each component of FARDA.\nüìÑ Download PDF\nEmergence of Language in the Developing Brain Authors: Linnea Evanson, Christine Bulteau, Mathilde Chipaux, Georg Dorfm√ºller, Sarah Ferrand-Sorbets, Emmanuel Raffo, Sarah Rosenberg, Pierre Bourdillon, Jean-R√©mi King Venue: arXiv (2025)\nA few million words suffice for children to acquire language. Yet, the brain mechanisms underlying this unique ability remain poorly understood. To address this issue, we investigate neural activity recorded from over 7,400 electrodes implanted in the brains of 46 children, teenagers, and adults for epilepsy monitoring, as they listened to an audiobook version of ‚ÄúThe Little Prince‚Äù. We then train neural encoding and decoding models using representations, derived either from linguistic theory or from large language models, to map the location, dynamics and development of the language hierarchy in the brain. We find that a broad range of linguistic features is robustly represented across the cortex, even in 2-5-year-olds. Crucially, these representations evolve with age: while fast phonetic features are already present in the superior temporal gyrus of the youngest individuals, slower word-level representations only emerge in the associative cortices of older individuals. Remarkably, this neuro-developmental trajectory is spontaneously captured by large language models: with training, these AI models learned representations that can only be identified in the adult human brain. Together, these findings reveal the maturation of language representations in the developing brain and show that modern AI systems provide a promising tool to model the neural bases of language acquisition.\nüìÑ Download PDF\nInstructMPC: A Human-LLM-in-the-Loop Framework for Context-Aware Power Grid Control Authors: Ruixiang Wu, Jiahao Ai, Tinko Sebastian Bartels Venue: arXiv (2025)\nThe transition toward power grids with high renewable penetration demands context-aware decision making frameworks. Traditional operational paradigms, which rely on static optimization of history-based load forecasting, often fail to capture the complex nature of real-time operational conditions, such as operator-issued maintenance mandates, emergency topology changes, or event-driven load surges. To address this challenge, we introduce InstructMPC, a closed-loop framework that integrates Large Language Models~(LLMs) to generate context-aware predictions, enabling the controller to optimize power system operation. Our method employs a Contextual Disturbances Predictor~(CDP) module to translate contextual information into predictive disturbance trajectories, which are then incorporated into the Model Predictive Control~(MPC) optimization. Unlike conventional open-loop forecasting frameworks, InstructMPC features an online tuning mechanism where the predictor‚Äôs parameters are continuously updated based on the realized control cost with a theoretical guarantee, achieving a regret bound of $O(\\sqrt{T \\log T})$ for linear dynamics when optimized via a tailored loss function, ensuring task-aware learning and adaption to non-stationary grid conditions.\nüìÑ Download PDF\nMachine-learning-enabled interpretation of tribological deformation patterns in large-scale MD data Authors: Hendrik J. Ehrich, Marvin C. May, Stefan J. Eder Venue: arXiv (2025)\nMolecular dynamics (MD) simulations have become indispensable for exploring tribological deformation patterns at the atomic scale. However, transforming the resulting high-dimensional data into interpretable deformation pattern maps remains a resource-intensive and largely manual process. In this work, we introduce a data-driven workflow that automates this interpretation step using unsupervised and supervised learning. Grain-orientation-colored computational tomograph pictures obtained from CuNi alloy simulations were first compressed through an autoencoder to a 32-dimensional global feature vector. Despite this strong compression, the reconstructed images retained the essential microstructural motifs: grain boundaries, stacking faults, twins, and partial lattice rotations, while omitting only the finest defects. The learned representations were then combined with simulation metadata (composition, load, time, temperature, and spatial position) to train a CNN-MLP model to predict the dominant deformation pattern. The resulting model achieves a prediction accuracy of approximately 96% on validation data. A refined evaluation strategy, in which an entire spatial region containing distinct grains was excluded from training, provides a more robust measure of generalization. The approach demonstrates that essential tribological deformation signatures can be automatically identified and classified from structural images using Machine Learning. This proof of concept constitutes a first step towards fully automated, data-driven construction of tribological mechanism maps and, ultimately, toward predictive modeling frameworks that may reduce the need for large-scale MD simulation campaigns.\nüìÑ Download PDF\nüîç llm Transformation of orientation and rotation angles of synchronous satellites: Application to the Galilean moons Authors: Marie Yseboodt, Rose-Marie Baland Venue: arXiv (2025)\nThe orientation and rotation of a synchronous satellite can be referred to both its Laplace plane and the ICRF equatorial plane, in terms of Euler angles or spin axis Cartesian coordinates and Earth equatorial coordinates, respectively. We computed second-order analytical expressions to make the transformation between the two systems and applied them to the Galilean satellites (Io, Europa, Ganymede, and Callisto). If one term of the spin axis Cartesian coordinates series is dominant, trigonometric series can be generated for the inertial and orbital obliquities, node longitude and offset with respect to the Cassini plane. Since the transformation does not require any fit of amplitudes and frequencies on numerical series, the physical meaning of the frequencies is preserved from the input series and the amplitudes can be directly related to the geophysical parameters of interest. We provide tables for the coordinates and angles‚Äô series assuming that the satellites are entirely solid, and considering two different orbital theories. The possible amplitude ranges for the main terms are also examined in the case where a liquid layer is assumed in the interior model. We use our transformation method to propose an updated IAU WG solution which would result in an improvement with respect to zero obliquity models used so far. This method will also be useful for the interpretation of future Earth-based radar observations or JUICE data.\nüìÑ Download PDF\nKQ-SVD: Compressing the KV Cache with Provable Guarantees on Attention Fidelity Authors: Damien Lesens, Beheshteh T. Rakhshan, Guillaume Rabusseau Venue: arXiv (2025)\nThe Key-Value (KV) cache is central to the efficiency of transformer-based large language models (LLMs), storing previously computed vectors to accelerate inference. Yet, as sequence length and batch size grow, the cache becomes a major memory bottleneck. Prior compression methods typically apply low-rank decomposition to keys alone or attempt to jointly embed queries and keys, but both approaches neglect that attention fundamentally depends on their inner products. In this work, we prove that such strategies are suboptimal for approximating the attention matrix. We introduce KQ-SVD, a simple and computationally efficient method that directly performs an optimal low-rank decomposition of the attention matrix via a closed-form solution. By targeting the true source of redundancy, KQ-SVD preserves attention outputs with higher fidelity under compression. Extensive evaluations on LLaMA and Mistral models demonstrate that our approach consistently delivers superior projection quality.\nüìÑ Download PDF\nDifferentially rotating neutron stars with dark matter cores Authors: Lorenzo Cipriani, Violetta Sagun, Kalin V. Staykov, Daniela D. Doneva, Stoytcho S. Yazadjiev Venue: arXiv (2025)\nDark matter is expected to accumulate inside neutron stars, modifying the structure of isolated stars and influencing both the dynamics of binary mergers and the evolution of the resulting hypermassive remnants. Since differential rotation is the primary mechanism delaying the collapse of these remnants, understanding its behavior is crucial when assessing the impact of an embedded dark component. In this work, we extend the numerical code RNS to describe two gravitationally coupled fluids in differential rotation, with baryonic matter modeled by a realistic nuclear equation of state and dark matter represented as a self-interacting bosonic condensate. Within this framework, we construct equilibrium sequences for a representative differential rotation law, providing a basis to explore how dark matter may influence the global properties and rotational dynamics of binary neutron star remnants.\nüìÑ Download PDF\nLog-linear Dynamic Inversion for Thrusting Spacecraft on SE2(3) Authors: Micah K. Condie, Abigaile E. Woodbury, Li-Yu Lin, Kartik A. Pant, Mike Walker, James Goppert Venue: arXiv (2025)\nWe show that the dynamics of a thrusting spacecraft can be embedded in the Lie group SE2(3) in a form that is group-affine with application of a feed-forward control law. This structure implies that the configuration-tracking error evolves exactly linearly in the associated Lie algebra coordinates (log-linear dynamics), rather than arising from a local linearization of the nonlinear system. As a result, a broad class of linear analysis and synthesis tools becomes directly applicable to powered spacecraft motion on SE2(3). A simple numerical example confirms that the error predicted by the linear Lie-algebra dynamics matches the error computed from the full nonlinear system, illustrating the exact log-linear behavior. This foundational property opens a path toward rigorous tools for satellite docking, autonomous rendezvous and proximity operations, robust controller design, and convex safety certification-capabilities that are difficult to achieve with classical local linearizations such as Tschauner-Hempel/Yamanaka-Ankersen (TH/YA).\nüìÑ Download PDF\nüîç neuroscience Zoom in, Click out: Unlocking and Evaluating the Potential of Zooming for GUI Grounding Authors: Zhiyuan Jiang, Shenghao Xie, Wenyi Li, Wenqiang Zu, Peihang Li, Jiahao Qiu, Siqi Pei, Lei Ma, Tiejun Huang, Mengdi Wang, Shilong Liu Venue: arXiv (2025)\nGrounding is a fundamental capability for building graphical user interface (GUI) agents. Although existing approaches rely on large-scale bounding box supervision, they still face various challenges, such as cross-platform generalization, complex layout analysis, and fine-grained element localization. In this paper, we investigate zoom as a strong yet underexplored prior for GUI grounding, and propose a training-free method, ZoomClick. By characterizing four key properties of zoom (i.e., pre-zoom, depth, shrink size, minimal crop size), we unlock its full capabilities for dynamic spatial focusing and adaptive context switching. Experiments demonstrate that our method significantly boosts the performance of both general vision-language and specialized GUI grounding models, achieving state-of-the-art results on several mainstream benchmarks; for example, UI-Venus-72B attains a 73.1% success rate on ScreenSpot-Pro. Furthermore, we present GUIZoom-Bench, a benchmark for evaluating model adaptability to zoom, aiming to inspire future research on improving zoom for further training and test-time scaling in GUI grounding tasks.\nüìÑ Download PDF\nA Continuous Nonlinear Optimization Perspective on the Spin Glass Problem Authors: Phil Duxbury, Carlile Lavor, Luiz Leduino de Salles-Neto Venue: arXiv (2025)\nWe present a continuous nonlinear optimization model for the Spin Glass Problem (SGP), building on a classical result by Rosenberg (1972), which shows that for a class of multilinear polynomial problems the optimal values of the continuous relaxation and the corresponding discrete model coincide. Using the SGP as a case study, we provide a simple, problem-specific argument showing how any optimal solution returned by a continuous solver can be converted into an optimal discrete spin configuration, even when the solver outputs non-integer values. The relaxed model remains nonconvex and does not alter the inherent computational hardness of the problem, but it offers a direct and conceptually transparent continuous formulation that can be handled by modern global optimization software. Computational experiments on standard benchmark instances indicate that this approach can match, and in several cases surpass, recent integer programming linearization techniques, making it a practical and complementary tool for researchers working at the interface between statistical physics and combinatorial optimization.\nüìÑ Download PDF\nSuperconformal interfaces from 5D N=4 gauged supergravity Authors: Parinya Karndumri Venue: arXiv (2025)\nWe find a large class of new supersymmetric Janus solutions from five-dimensional $N=4$ gauged supergravity coupled to five vector multiplets with $SO(2)D\\times SO(3)\\times SO(3)$ gauge group. The gauged supergravity admits four supersymmetric $AdS_5$ vacua, two $N=4$ with $SO(2)D\\times SO(3)\\times SO(3)$ and $SO(2)D\\times SO(3){\\textrm{diag}}$ symmetric $AdS_5$ vacua and two $N=2$ with $SO(2){\\textrm{diag}}\\times SO(3)$ and $SO(2){\\textrm{diag}}$ symmetric ones. In a truncation to three vector multiplets, the gauge group is given by $SO(2)\\times SO(3)\\times SO(3)$, and the resulting gauged supergravity admits only two $N=4$ supersymmetric $AdS_5$ vacua with $SO(2)\\times SO(3)\\times SO(3)$ and $SO(2)\\times SO(3){\\textrm{diag}}$ residual symmetries. By considering the $SO(2){\\textrm{diag}}$ invariant sector within this truncation, we find a number of supersymetric Janus interfaces between the two $N=4$ vacua on both sides as well as an RG-flow interface between $SO(2)\\times SO(3)\\times SO(3)$ and $SO(2)\\times SO(3)_{\\textrm{diag}}$ symmetric vacua on each side. By repeating the analysis in the full $SO(2)_D\\times SO(3)\\times SO(3)$ gauged supergravity, we find Janus solutions interpolating between the aforementioned four supersymmetric $AdS_5$ vacua as well as examples of multi-Janus interfaces between these vacua.\nüìÑ Download PDF\nA Multi-Channel Auditory Signal Encoder with Adaptive Resolution Using Volatile Memristors Authors: Dongxu Guo, Deepika Yadav, Patrick Foster, Spyros Stathopoulos, Mingyi Chen, Themis Prodromakis, Shiwei Wang Venue: arXiv (2025)\nWe demonstrate and experimentally validate an end-to-end hybrid CMOS-memristor auditory encoder that realises adaptive-threshold, asynchronous delta-modulation (ADM)-based spike encoding by exploiting the inherent volatility of HfTiOx devices. A spike-triggered programming pulse rapidly raises the ADM threshold Delta (desensitisation); the device‚Äôs volatility then passively lowers Delta when activity subsides (resensitisation), emphasising onsets while restoring sensitivity without static control energy. Our prototype couples an 8-channel 130 nm encoder IC to off-chip HfTiOx devices via a switch interface and an off-chip controller that monitors spike activity and issues programming events. An on-chip current-mirror transimpedance amplifier (TIA) converts device current into symmetric thresholds, enabling both sensitive and conservative encoding regimes. Evaluated with gammatone-filtered speech, the adaptive loop-at matched spike budget-sharpens onsets and preserves fine temporal detail that a fixed-Delta baseline misses; multi-channel spike cochleagrams show the same trend. Together, these results establish a practical hybrid CMOS-memristor pathway to onset-salient, spike-efficient neuromorphic audio front-ends and motivate low-power single-chip integration.\nüìÑ Download PDF\nüîç data_resources Designing an Optimal Sensor Network via Minimizing Information Loss Authors: Daniel Waxman, Fernando Llorente, Katia Lamer, Petar M. Djuriƒá Venue: arXiv (2025)\nOptimal experimental design is a classic topic in statistics, with many well-studied problems, applications, and solutions. The design problem we study is the placement of sensors to monitor spatiotemporal processes, explicitly accounting for the temporal dimension in our modeling and optimization. We observe that recent advancements in computational sciences often yield large datasets based on physics-based simulations, which are rarely leveraged in experimental design. We introduce a novel model-based sensor placement criterion, along with a highly-efficient optimization algorithm, which integrates physics-based simulations and Bayesian experimental design principles to identify sensor networks that ‚Äúminimize information loss‚Äù from simulated data. Our technique relies on sparse variational inference and (separable) Gauss-Markov priors, and thus may adapt many techniques from Bayesian experimental design. We validate our method through a case study monitoring air temperature in Phoenix, Arizona, using state-of-the-art physics-based simulations. Our results show our framework to be superior to random or quasi-random sampling, particularly with a limited number of sensors. We conclude by discussing practical considerations and implications of our framework, including more complex modeling tools and real-world deployments.\nüìÑ Download PDF\nA Greek Government Decisions Dataset for Public-Sector Analysis and Insight Authors: Giorgos Antoniou, Giorgos Filandrianos, Aggelos Vlachos, Giorgos Stamou, Lampros Kollimenos, Konstantinos Skianis, Michalis Vazirgiannis Venue: arXiv (2025)\nWe introduce an open, machine-readable corpus of Greek government decisions sourced from the national transparency platform Diavgeia. The resource comprises 1 million decisions, featuring and high-quality raw text extracted from PDFs. It is released with raw extracted text in Markdown format, alongside a fully reproducible extraction pipeline. Beyond the core dataset, we conduct qualitative analyses to explore boilerplate patterns and design a retrieval-augmented generation (RAG) task by formulating a set of representative questions, creating high-quality answers, and evaluating a baseline RAG system on its ability to retrieve and reason over public decisions. This evaluation demonstrates the potential of large-scale public-sector corpora to support advanced information access and transparency through structured retrieval and reasoning over governmental documents, and highlights how such a RAG pipeline could simulate a chat-based assistant capable of interactively answering questions about public decisions. Due to its scale, quality, and domain coverage, the corpus can also serve as high-value pre-training or fine-tuning material for new Language Models (LMs) and Large Language Models (LLMs) respectively, including specialized models for legal and governmental domains, and as a foundation for novel approaches in domain adaptation, knowledge-grounded generation, and explainable AI. Finally, we discuss limitations, outline future directions, and make both the data and the code accessible.\nüìÑ Download PDF\nUsing Large Language Models to Create Personalized Networks From Therapy Sessions Authors: Clarissa W. Ong, Hiba Arnaout, Kate Sheehan, Estella Fox, Eugen Owtscharow, Iryna Gurevych Venue: arXiv (2025)\nRecent advances in psychotherapy have focused on treatment personalization, such as by selecting treatment modules based on personalized networks. However, estimating personalized networks typically requires intensive longitudinal data, which is not always feasible. A solution to facilitate scalability of network-driven treatment personalization is leveraging LLMs. In this study, we present an end-to-end pipeline for automatically generating client networks from 77 therapy transcripts to support case conceptualization and treatment planning. We annotated 3364 psychological processes and their corresponding dimensions in therapy transcripts. Using these data, we applied in-context learning to jointly identify psychological processes and their dimensions. The method achieved high performance even with a few training examples. To organize the processes into networks, we introduced a two-step method that grouped them into clinically meaningful clusters. We then generated explanation-augmented relationships between clusters. Experts found that networks produced by our multi-step approach outperformed those built with direct prompting for clinical utility and interpretability, with up to 90% preferring our approach. In addition, the networks were rated favorably by experts, with scores for clinical relevance, novelty, and usefulness ranging from 72-75%. Our findings provide a proof of concept for using LLMs to create clinically relevant networks from therapy transcripts. Advantages of our approach include bottom-up case conceptualization from client utterances in therapy sessions and identification of latent themes. Networks generated from our pipeline may be used in clinical settings and supervision and training. Future research should examine whether these networks improve treatment outcomes relative to other methods of treatment personalization, including statistically estimated networks.\nüìÑ Download PDF\nLabel-Efficient Point Cloud Segmentation with Active Learning Authors: Johannes Meyer, Jasper Hoffmann, Felix Schulz, Dominik Merkle, Daniel Buescher, Alexander Reiterer, Joschka Boedecker, Wolfram Burgard Venue: arXiv (2025)\nSemantic segmentation of 3D point cloud data often comes with high annotation costs. Active learning automates the process of selecting which data to annotate, reducing the total amount of annotation needed to achieve satisfactory performance. Recent approaches to active learning for 3D point clouds are often based on sophisticated heuristics for both, splitting point clouds into annotatable regions and selecting the most beneficial for further neural network training. In this work, we propose a novel and easy-to-implement strategy to separate the point cloud into annotatable regions. In our approach, we utilize a 2D grid to subdivide the point cloud into columns. To identify the next data to be annotated, we employ a network ensemble to estimate the uncertainty in the network output. We evaluate our method on the S3DIS dataset, the Toronto-3D dataset, and a large-scale urban 3D point cloud of the city of Freiburg, which we labeled in parts manually. The extensive evaluation shows that our method yields performance on par with, or even better than, complex state-of-the-art methods on all datasets. Furthermore, we provide results suggesting that in the context of point clouds the annotated area can be a more meaningful measure for active learning algorithms than the number of annotated points.\nüìÑ Download PDF\nOWL: Unsupervised 3D Object Detection by Occupancy Guided Warm-up and Large Model Priors Reasoning Authors: Xusheng Guo, Wanfa Zhang, Shijia Zhao, Qiming Xia, Xiaolong Xie, Mingming Wang, Hai Wu, Chenglu Wen Venue: arXiv (2025)\nUnsupervised 3D object detection leverages heuristic algorithms to discover potential objects, offering a promising route to reduce annotation costs in autonomous driving. Existing approaches mainly generate pseudo labels and refine them through self-training iterations. However, these pseudo-labels are often incorrect at the beginning of training, resulting in misleading the optimization process. Moreover, effectively filtering and refining them remains a critical challenge. In this paper, we propose OWL for unsupervised 3D object detection by occupancy guided warm-up and large-model priors reasoning. OWL first employs an Occupancy Guided Warm-up (OGW) strategy to initialize the backbone weight with spatial perception capabilities, mitigating the interference of incorrect pseudo-labels on network convergence. Furthermore, OWL introduces an Instance-Cued Reasoning (ICR) module that leverages the prior knowledge of large models to assess pseudo-label quality, enabling precise filtering and refinement. Finally, we design a Weight-adapted Self-training (WAS) strategy to dynamically re-weight pseudo-labels, improving the performance through self-training. Extensive experiments on Waymo Open Dataset (WOD) and KITTI demonstrate that OWL outperforms state-of-the-art unsupervised methods by over 15.0% mAP, revealing the effectiveness of our method.\nüìÑ Download PDF\nDistillFSS: Synthesizing Few-Shot Knowledge into a Lightweight Segmentation Model Authors: Pasquale De Marinis, Pieter M. Blok, Uzay Kaymak, Rogier Brussee, Gennaro Vessio, Giovanna Castellano Venue: arXiv (2025)\nCross-Domain Few-Shot Semantic Segmentation (CD-FSS) seeks to segment unknown classes in unseen domains using only a few annotated examples. This setting is inherently challenging: source and target domains exhibit substantial distribution shifts, label spaces are disjoint, and support images are scarce‚Äìmaking standard episodic methods unreliable and computationally demanding at test time. To address these constraints, we propose DistillFSS, a framework that embeds support-set knowledge directly into a model‚Äôs parameters through a teacher‚Äìstudent distillation process. By internalizing few-shot reasoning into a dedicated layer within the student network, DistillFSS eliminates the need for support images at test time, enabling fast, lightweight inference, while allowing efficient extension to novel classes in unseen domains through rapid teacher-driven specialization. Combined with fine-tuning, the approach scales efficiently to large support sets and significantly reduces computational overhead. To evaluate the framework under realistic conditions, we introduce a new CD-FSS benchmark spanning medical imaging, industrial inspection, and remote sensing, with disjoint label spaces and variable support sizes. Experiments show that DistillFSS matches or surpasses state-of-the-art baselines, particularly in multi-class and multi-shot scenarios, while offering substantial efficiency gains. The code is available at https://github.com/pasqualedem/DistillFSS.\nüìÑ Download PDF\nüîç emotion_language Measuring the Effect of Background on Classification and Feature Importance in Deep Learning for AV Perception Authors: Anne Sielemann, Valentin Barner, Stefan Wolf, Masoud Roschani, Jens Ziehn, Juergen Beyerer Venue: arXiv (2025)\nCommon approaches to explainable AI (XAI) for deep learning focus on analyzing the importance of input features on the classification task in a given model: saliency methods like SHAP and GradCAM are used to measure the impact of spatial regions of the input image on the classification result. Combined with ground truth information about the location of the object in the input image (e.g., a binary mask), it is determined whether object pixels had a high impact on the classification result, or whether the classification focused on background pixels. The former is considered to be a sign of a healthy classifier, whereas the latter is assumed to suggest overfitting on spurious correlations. A major challenge, however, is that these intuitive interpretations are difficult to test quantitatively, and hence the output of such explanations lacks an explanation itself. One particular reason is that correlations in real-world data are difficult to avoid, and whether they are spurious or legitimate is debatable. Synthetic data in turn can facilitate to actively enable or disable correlations where desired but often lack a sufficient quantification of realism and stochastic properties. [‚Ä¶] Therefore, we systematically generate six synthetic datasets for the task of traffic sign recognition, which differ only in their degree of camera variation and background correlation [‚Ä¶] to quantify the isolated influence of background correlation, different levels of camera variation, and considered traffic sign shapes on the classification performance, as well as background feature importance. [‚Ä¶] Results include a quantification of when and how much background features gain importance to support the classification task based on changes in the training domain [‚Ä¶]. Download: synset.de/datasets/synset-signset-ger/background-effect\nüìÑ Download PDF\nMost Rocky Sub-Neptunes are Molten: Mapping the Solidification Shoreline for Gas Dwarf Exoplanets Authors: Robb Calder, Oliver Shorttle, Harrison Nicholls, Tim Lichtenberg, Claire-Marie Guimond Venue: arXiv (2025)\nSub-Neptunes are the most common type of detected exoplanet, yet their observed masses and radii are degenerate with several interior structures. One possibility is that sub-Neptunes have silicate/iron interiors and H$2$-dominated atmospheres, i.e., they are gas dwarfs'. If gas dwarfs have molten interiors, interactions between their magma oceans and atmospheres will produce distinct observational signatures. These signatures may break the degeneracy in interior structure, while providing insight into their interior processes, history, and population trends. We expect all such planets are born molten, but under what conditions do they remain molten today? We use the coupled interior-climate evolution model, PROTEUS, to estimate the solidification shoreline‚Äô: the instellation flux boundary (as a function of stellar $T{\\rm eff}$) that separates molten gas dwarfs from solidified ones. Our results show that 98% of detected sub-Neptunes occupy a region of parameter space consistent with their having permanent magma oceans, if they are gas dwarfs. While mantle $f{\\rm O}_2$ and bulk volatile C/H ratio both influence magma ocean lifetimes, planets with oxidising mantles and carbon-rich atmospheres are unlikely to have radii consistent with the sub-Neptune classification. Therefore, most detected sub-Neptunes (if they are gas dwarfs) have permanent magma oceans. This result motivates further research into the interactions between molten interiors and overlying atmospheres, and campaigns to identify unambiguous signatures of these interactions.\nüìÑ Download PDF\nDeveloping synthetic microdata through machine learning for firm-level business surveys Authors: Jorge Cisneros Paz, Timothy Wojan, Matthew Williams, Jennifer Ozawa, Robert Chew, Kimberly Janda, Timothy Navarro, Michael Floyd, Christine Task, Damon Streat Venue: arXiv (2025)\nPublic-use microdata samples (PUMS) from the United States (US) Census Bureau on individuals have been available for decades. However, large increases in computing power and the greater availability of Big Data have dramatically increased the probability of re-identifying anonymized data, potentially violating the pledge of confidentiality given to survey respondents. Data science tools can be used to produce synthetic data that preserve critical moments of the empirical data but do not contain the records of any existing individual respondent or business. Developing public-use firm data from surveys presents unique challenges different from demographic data, because there is a lack of anonymity and certain industries can be easily identified in each geographic area. This paper briefly describes a machine learning model used to construct a synthetic PUMS based on the Annual Business Survey (ABS) and discusses various quality metrics. Although the ABS PUMS is currently being refined and results are confidential, we present two synthetic PUMS developed for the 2007 Survey of Business Owners, similar to the ABS business data. Econometric replication of a high impact analysis published in Small Business Economics demonstrates the verisimilitude of the synthetic data to the true data and motivates discussion of possible ABS use cases.\nüìÑ Download PDF\nMinimal two band model and experimental proposals to distinguish pairing mechanisms of the high-T$_c$ superconductor La$_3$Ni$_2$O$_7$ Authors: Zheng-Duo Fan, Ashvin Vishwanath Venue: arXiv (2025)\nThe discovery of high-T$_c$ superconductivity in La$_3$Ni$_2$O$_7$ has opened the door to a new route to high temperature superconductivity, distinct from that in cuprates and iron-based materials. Yet, despite intense recent activity, we lack experimentally testable protocols for distinguishing between different pairing scenarios. In this Letter, we construct a minimal two-band model that reproduces the Fermi-surface topology observed in recent ARPES measurements and DFT calculations, and we analyze superconductivity arising from two distinct pairing mechanisms. We show that these mechanisms yield sharply different responses to an applied perpendicular electric field. Thus, La$_3$Ni$_2$O$_7$ offers the unique opportunity to cleanly distinguish between different pairing scenarios. Finally, we propose three concrete experimental proposals designed to distinguish these scenarios and thereby identify the pairing mechanism most relevant to the real material.\nüìÑ Download PDF\nLLM Harms: A Taxonomy and Discussion Authors: Kevin Chen, Saleh Afroogh, Abhejay Murali, David Atkinson, Amit Dhurandhar, Junfeng Jiao Venue: arXiv (2025)\nThis study addresses categories of harm surrounding Large Language Models (LLMs) in the field of artificial intelligence. It addresses five categories of harms addressed before, during, and after development of AI applications: pre-development, direct output, Misuse and Malicious Application, and downstream application. By underscoring the need to define risks of the current landscape to ensure accountability, transparency and navigating bias when adapting LLMs for practical applications. It proposes mitigation strategies and future directions for specific domains and a dynamic auditing system guiding responsible development and integration of LLMs in a standardized proposal.\nüìÑ Download PDF\nNICE: Neural Implicit Craniofacial Model for Orthognathic Surgery Prediction Authors: Jiawen Yang, Yihui Cao, Xuanyu Tian, Yuyao Zhang, Hongjiang Wei Venue: arXiv (2025)\nOrthognathic surgery is a crucial intervention for correcting dentofacial skeletal deformities to enhance occlusal functionality and facial aesthetics. Accurate postoperative facial appearance prediction remains challenging due to the complex nonlinear interactions between skeletal movements and facial soft tissue. Existing biomechanical, parametric models and deep-learning approaches either lack computational efficiency or fail to fully capture these intricate interactions. To address these limitations, we propose Neural Implicit Craniofacial Model (NICE) which employs implicit neural representations for accurate anatomical reconstruction and surgical outcome prediction. NICE comprises a shape module, which employs region-specific implicit Signed Distance Function (SDF) decoders to reconstruct the facial surface, maxilla, and mandible, and a surgery module, which employs region-specific deformation decoders. These deformation decoders are driven by a shared surgical latent code to effectively model the complex, nonlinear biomechanical response of the facial surface to skeletal movements, incorporating anatomical prior knowledge. The deformation decoders output point-wise displacement fields, enabling precise modeling of surgical outcomes. Extensive experiments demonstrate that NICE outperforms current state-of-the-art methods, notably improving prediction accuracy in critical facial regions such as lips and chin, while robustly preserving anatomical integrity. This work provides a clinically viable tool for enhanced surgical planning and patient consultation in orthognathic procedures.\nüìÑ Download PDF\nWorld Models That Know When They Don‚Äôt Know: Controllable Video Generation with Calibrated Uncertainty Authors: Zhiting Mei, Tenny Yin, Micah Baker, Ola Shorinwa, Anirudha Majumdar Venue: arXiv (2025)\nRecent advances in generative video models have led to significant breakthroughs in high-fidelity video synthesis, specifically in controllable video generation where the generated video is conditioned on text and action inputs, e.g., in instruction-guided video editing and world modeling in robotics. Despite these exceptional capabilities, controllable video models often hallucinate - generating future video frames that are misaligned with physical reality - which raises serious concerns in many tasks such as robot policy evaluation and planning. However, state-of-the-art video models lack the ability to assess and express their confidence, impeding hallucination mitigation. To rigorously address this challenge, we propose C3, an uncertainty quantification (UQ) method for training continuous-scale calibrated controllable video models for dense confidence estimation at the subpatch level, precisely localizing the uncertainty in each generated video frame. Our UQ method introduces three core innovations to empower video models to estimate their uncertainty. First, our method develops a novel framework that trains video models for correctness and calibration via strictly proper scoring rules. Second, we estimate the video model‚Äôs uncertainty in latent space, avoiding training instability and prohibitive training costs associated with pixel-space approaches. Third, we map the dense latent-space uncertainty to interpretable pixel-level uncertainty in the RGB space for intuitive visualization, providing high-resolution uncertainty heatmaps that identify untrustworthy regions. Through extensive experiments on large-scale robot learning datasets (Bridge and DROID) and real-world evaluations, we demonstrate that our method not only provides calibrated uncertainty estimates within the training distribution, but also enables effective out-of-distribution detection.\nüìÑ Download PDF\nTo Err Is Human: Systematic Quantification of Errors in Published AI Papers via LLM Analysis Authors: Federico Bianchi, Yongchan Kwon, Zachary Izzo, Linjun Zhang, James Zou Venue: arXiv (2025)\nHow many mistakes do published AI papers contain? Peer-reviewed publications form the foundation upon which new research and knowledge are built. Errors that persist in the literature can propagate unnoticed, creating confusion in follow-up studies and complicating reproducibility. The accelerating pace of research and the increasing demands on the peer-review system make such mistakes harder to detect and avoid. To address this, we developed a Paper Correctness Checker based on GPT-5 to systematically identify mistakes in papers previously published at top AI conferences and journals. Our analysis focuses on objective mistakes-e.g., errors in formulas, derivations, calculations, figures, and tables-that have a clearly verifiable ground truth. We intentionally exclude subjective considerations such as novelty, importance, or writing quality. We find that published papers contain a non-negligible number of objective mistakes and that the average number of mistakes per paper has increased over time-from 3.8 in NeurIPS 2021 to 5.9 in NeurIPS 2025 (55.3% increase); from 4.1 in ICLR 2018 to 5.2 in ICLR 2025; and from 5.0 in TMLR 2022/23 to 5.5 in TMLR 2025. Human experts reviewed 316 potential mistakes identified by the AI Checker and confirmed that 263 were actual mistakes, corresponding to a precision of 83.2%. While most identified issues are relatively minor, correcting them would reduce confusion in the literature and strengthen reproducibility. The AI Checker also surfaced potentially more substantive mistakes that could affect the interpretation of results. Moreover, we show that the AI Checker can propose correct fixes for 75.8% of the identified mistakes. Overall, this study highlights the potential of frontier LLMs to detect and correct objective mistakes in published papers, helping to establish a firmer foundation of knowledge.\nüìÑ Download PDF\nA Residual Variance Matching Recursive Least Squares Filter for Real-time UAV Terrain Following Authors: Xiaobo Wu, Youmin Zhang Venue: arXiv (2025)\nAccurate real-time waypoints estimation for the UAV-based online Terrain Following during wildfire patrol missions is critical to ensuring flight safety and enabling wildfire detection. However, existing real-time filtering algorithms struggle to maintain accurate waypoints under measurement noise in nonlinear and time-varying systems, posing risks of flight instability and missed wildfire detections during UAV-based terrain following. To address this issue, a Residual Variance Matching Recursive Least Squares (RVM-RLS) filter, guided by a Residual Variance Matching Estimation (RVME) criterion, is proposed to adaptively estimate the real-time waypoints of nonlinear, time-varying UAV-based terrain following systems. The proposed method is validated using a UAV-based online terrain following system within a simulated terrain environment. Experimental results show that the RVM-RLS filter improves waypoints estimation accuracy by approximately 88$%$ compared with benchmark algorithms across multiple evaluation metrics. These findings demonstrate both the methodological advances in real-time filtering and the practical potential of the RVM-RLS filter for UAV-based online wildfire patrol.\nüìÑ Download PDF\nUnitarization of $R + Œ±R^2$ gravity Authors: I√±igo Asi√°in, Antonio Dobado, Dom√®nec Espriu Venue: arXiv (2025)\nWe make use of the improved K-matrix algorithm to obtain unitarized amplitudes in $R+Œ±R^2$ gravity (the so-called Starobisnsky model, of cosmological relevance). The procedure is of some complexity because infrared divergences are present and need to be properly regulated. We focus on the behaviour of a bona fide scalar resonance, known to exist in this model, and compare it to an apparent resonance detected in previous studies, thus confirming that the latter seems to be an artifact due to the introduction of the infrared regulator. We analyze the existence of other dynamical resonances and dwell on the amplitudes made unitary by this procedure.\nüìÑ Download PDF\nEuclid Quick Data Release (Q1). From simulations to sky: Advancing machine-learning lens detection with real Euclid data Authors: Euclid Collaboration, N. E. P. Lines, T. E. Collett, P. Holloway, K. Rojas, S. Schuldt, R. B. Metcalf, T. Li, A. Verma, G. Despali, F. Courbin, R. Gavazzi, C. Tortora, B. Cl√©ment, N. Aghanim, B. Altieri, L. Amendola, S. Andreon, N. Auricchio, C. Baccigalupi, M. Baldi, A. Balestra, S. Bardelli, P. Battaglia, A. Biviano, E. Branchini, M. Brescia, S. Camera, G. Ca√±as-Herrera, V. Capobianco, C. Carbone, J. Carretero, M. Castellano, G. Castignani, S. Cavuoti, A. Cimatti, C. Colodro-Conde, G. Congedo, C. J. Conselice, L. Conversi, Y. Copin, H. M. Courtois, M. Cropper, H. Degaudenzi, G. De Lucia, H. Dole, F. Dubath, X. Dupac, S. Dusini, A. Ealet, S. Escoffier, M. Farina, R. Farinelli, F. Faustini, S. Ferriol, F. Finelli, M. Frailis, E. Franceschi, M. Fumana, S. Galeotta, K. George, B. Gillis, C. Giocoli, P. G√≥mez-Alvarez, J. Gracia-Carpio, A. Grazian, F. Grupp, S. V. H. Haugan, W. Holmes, I. M. Hook, F. Hormuth, A. Hornstrup, K. Jahnke, M. Jhabvala, B. Joachimi, E. Keih√§nen, S. Kermiche, A. Kiessling, B. Kubik, M. K√ºmmel, M. Kunz, H. Kurki-Suonio, A. M. C. Le Brun, S. Ligori, P. B. Lilje, V. Lindholm, I. Lloro, G. Mainetti, D. Maino, E. Maiorano, O. Mansutti, S. Marcin, O. Marggraf, M. Martinelli, N. Martinet, F. Marulli, R. J. Massey, E. Medinaceli, S. Mei, M. Melchior, Y. Mellier, M. Meneghetti, E. Merlin, G. Meylan, A. Mora, M. Moresco, L. Moscardini, R. Nakajima, C. Neissner, S. -M. Niemi, J. W. Nightingale, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, W. J. Percival, V. Pettorino, S. Pires, G. Polenta, M. Poncet, L. A. Popa, L. Pozzetti, F. Raison, A. Renzi, J. Rhodes, G. Riccio, E. Romelli, M. Roncarelli, C. Rosset, R. Saglia, Z. Sakr, A. G. S√°nchez, D. Sapone, B. Sartoris, J. A. Schewtschenko, P. Schneider, T. Schrabback, A. Secroun, G. Seidel, S. Serrano, C. Sirignano, G. Sirri, L. Stanco, J. Steinwagner, P. Tallada-Cresp√≠, A. N. Taylor, I. Tereno, N. Tessore, S. Toft, R. Toledo-Moreo, F. Torradeflot, I. Tutusaus, J. Valiviita, T. Vassallo, A. Veropalumbo, Y. Wang, J. Weller, A. Zacchei, G. Zamorani, F. M. Zerbi, E. Zucca, M. Ballardini, M. Bolzonella, E. Bozzo, C. Burigana, R. Cabanac, M. Calabrese, A. Cappi, T. Castro, J. A. Escartin Vigo, L. Gabarra, J. Garc√≠a-Bellido, V. Gautard, S. Hemmati, M. Huertas-Company, J. Macias-Perez, R. Maoli, J. Mart√≠n-Fleitas, M. Maturi, N. Mauri, P. Monaco, M. P√∂ntinen, C. Porciani, I. Risso, V. Scottez, M. Sereno, M. Tenti, M. Tucci, M. Viel, M. Wiesmann, Y. Akrami, I. T. Andika, G. Angora, S. Anselmi, M. Archidiacono, F. Atrio-Barandela, E. Aubourg, L. Bazzanini, D. Bertacca, M. Bethermin, F. Beutler, A. Blanchard, L. Blot, M. Bonici, S. Borgani, M. L. Brown, S. Bruton, A. Calabro, B. Camacho Quevedo, F. Caro, C. S. Carvalho, F. Cogato, S. Conseil, A. R. Cooray, O. Cucciati, S. Davini, F. De Paolis, G. Desprez, A. D√≠az-S√°nchez, S. Di Domizio, J. M. Diego, P. -A. Duc, V. Duret, M. Y. Elkhashab, A. Enia, Y. Fang, P. G. Ferreira, A. Finoguenov, A. Fontana, A. Franco, K. Ganga, T. Gasparetto, E. Gaztanaga, F. Giacomini, F. Gianotti, G. Gozaliasl, A. Gruppuso, M. Guidi, C. M. Gutierrez, A. Hall, H. Hildebrandt, J. Hjorth, J. J. E. Kajava, Y. Kang, V. Kansal, D. Karagiannis, K. Kiiveri, J. Kim, C. C. Kirkpatrick, S. Kruk, M. Lattanzi, L. Legrand, F. Lepori, G. Leroy, G. F. Lesci, J. Lesgourgues, T. I. Liaudat, M. Magliocchetti, A. Manj√≥n-Garc√≠a, F. Mannucci, C. J. A. P. Martins, L. Maurin, M. Miluzio, A. Montoro, C. Moretti, G. Morgante, S. Nadathur, K. Naidoo, P. Natoli, S. Nesseris, D. Paoletti, F. Passalacqua, K. Paterson, L. Patrizii, A. Pisani, D. Potter, G. W. Pratt, S. Quai, M. Radovich, W. Roster, S. Sacquegna, M. Sahl√©n, D. B. Sanders, E. Sarpa, A. Schneider, D. Sciotti, E. Sellentin, L. C. Smith, J. G. Sorce, K. Tanidis, C. Tao, F. Tarsitano, G. Testera, R. Teyssier, S. Tosi, A. Troja, A. Venhola, D. Vergani, G. Vernardos, G. Verza, S. Vinciguerra, M. Walmsley, N. A. Walton, A. H. Wright Venue: arXiv (2025)\nIn the era of large-scale surveys like Euclid, machine learning has become an essential tool for identifying rare yet scientifically valuable objects, such as strong gravitational lenses. However, supervised machine-learning approaches require large quantities of labelled examples to train on, and the limited number of known strong lenses has lead to a reliance on simulations for training. A well-known challenge is that machine-learning models trained on one data domain often underperform when applied to a different domain: in the context of lens finding, this means that strong performance on simulated lenses does not necessarily translate into equally good performance on real observations. In Euclid‚Äôs Quick Data Release 1 (Q1), covering 63 deg2, 500 strong lens candidates were discovered through a synergy of machine learning, citizen science, and expert visual inspection. These discoveries now allow us to quantify this performance gap and investigate the impact of training on real data. We find that a network trained only on simulations recovers up to 92% of simulated lenses with 100% purity, but only achieves 50% completeness with 24% purity on real Euclid data. By augmenting training data with real Euclid lenses and non-lenses, completeness improves by 25-30% in terms of the expected yield of discoverable lenses in Euclid DR1 and the full Euclid Wide Survey. Roughly 20% of this improvement comes from the inclusion of real lenses in the training data, while 5-10% comes from exposure to a more diverse set of non-lenses and false-positives from Q1. We show that the most effective lens-finding strategy for real-world performance combines the diversity of simulations with the fidelity of real lenses. This hybrid approach establishes a clear methodology for maximising lens discoveries in future data releases from Euclid, and will likely also be applicable to other surveys such as LSST.\nüìÑ Download PDF\nHadronic Emissions from the Microquasar V4641 Sgr, SS433, and its implications in the Diffuse Galactic Emission Authors: Basanti Paul, Abhijit Roy, Jagdish C. Joshi, Debanjan Bose Venue: arXiv (2025)\nMicroquasars (MQs) are Galactic binary systems, consisting of a star and a compact object, a neutron star or a stellar mass black hole, which accretes matter from its companion star and gives rise to relativistic jets. Recent detection of very-high-energy (VHE; $E \\gtrsim 100,\\text{GeV}$) and ultra-high-energy (UHE; $E \\gtrsim 100,\\text{TeV}$) gamma-rays by LHAASO, HAWC and HESS from the MQ V4641 Sgr and SS 433 suggests them as Galactic PeVatrons. In this work, we studied a hadronic origin of the observed TeV-PeV gamma-ray emission from these MQs. We considered the hadronic scenario where the gamma-rays are produced by the interaction of relativistic protons in the MQ jet with the stellar wind. We fitted our model with observed data and constrained physical parameters like the hadronic jet power fraction, the proton spectral index, the maximum proton energy and the jet bulk Lorentz factor. Our best-fit model shows hard proton spectra ($1.84-2.44$) and maximum proton energies between 1 and 5 PeV. We also estimated the all-flavor neutrino fluxes corresponding to the gamma-ray fluxes from the hadronic model and found that V4641 sgr can be detected by next-generation neutrino telescopes like KM3NeT-ARCA and TRIDENT. Furthermore, we modeled a synthetic population of Galactic MQs and estimated their contribution to the diffuse TeV-PeV gamma-ray flux. For the inner Galaxy PSR contribution dominates in the range 10-100 TeV, and above 100 TeV diffused cosmic ray interactions with the molecular clouds is most dominant. We find that a population $\\sim 14$ MQs is required to explain the LHAASO data above 100 TeV. For the outer Galaxy, we show that MQs are the dominant class of sources, and we constrain their population $\\sim$14. Our findings strongly suggest that MQs are efficient particle accelerators, contributing to Galactic PeVatrons and potential multimessenger sources in our Galaxy.\nüìÑ Download PDF\nQuantitatively mapping the Eady model onto a two-layer quasi-geostrophic model Authors: Julie Meunier, Basile Gallet Venue: arXiv (2025)\nThe two-layer quasigeostrophic model (2LQG) and the Eady model are two idealized systems illustrating the baroclinic instability of atmospheric jets and ocean currents. The two setups share many ingredients ‚Äì background vertically sheared zonal flow of density-stratified fluid in a rapidly rotating frame ‚Äì while differing in complexity and dimensionality. The Eady model has a continuous vertical direction, with baroclinic turbulence induced by boundary potential vorticity (PV) gradients at top and bottom. By contrast, the 2LQG sytem typically models baroclinic instability induced by interior PV gradients. This distinction challenges our ability to clearly identify a couple of ‚Äòmodes‚Äô through which the Eady dynamics could be inferred from a simpler 2LQG system. In the present study, we show that this difficulty can be circumvented in the turbulent regime arising for weak bottom drag. Namely, guided by the common organization of both systems into a gas of coherent vortices, we identify a quantitative mapping between the Eady and the 2LQG models. The mapping allows for parameter-free predictions of the eddy diffusivity of the Eady model based on the knowledge of the 2LQG diffusivity. We illustrate these results using numerical simulations of the Eady and 2LQG models with linear or quadratic bottom drag.\nüìÑ Download PDF\nInvariant Price of Anarchy: a Metric for Welfarist Traffic Control Authors: Ilia Shilov, Mingjia He, Heinrich H. Nax, Emilio Frazzoli, Gioele Zardini, Saverio Bolognani Venue: arXiv (2025)\nThe Price of Anarchy (PoA) is a standard metric for quantifying inefficiency in socio-technical systems, widely used to guide policies like traffic tolling. Conventional PoA analysis relies on exact numerical costs. However, in many settings, costs represent agents‚Äô preferences and may be defined only up to possibly arbitrary scaling and shifting, representing informational and modeling ambiguities. We observe that while such transformations preserve equilibrium and optimal outcomes, they change the PoA value. To resolve this issue, we rely on results from Social Choice Theory and define the Invariant PoA. By connecting admissible transformations to degrees of comparability of agents‚Äô costs, we derive the specific social welfare functions which ensure that efficiency evaluations do not depend on arbitrary rescalings or translations of individual costs. Case studies on a toy example and the Zurich network demonstrate that identical tolling strategies can lead to substantially different efficiency estimates depending on the assumed comparability. Our framework thus demonstrates that explicit axiomatic foundations are necessary in order to define efficiency metrics and to appropriately guide policy in large-scale infrastructure design robustly and effectively.\nüìÑ Download PDF\nTowards agent-based-model informed neural networks Authors: Nino Antulov-Fantulin Venue: arXiv (2025)\nIn this article, we present a framework for designing neural networks that remain consistent with the underlying principles of agent-based models. We begin by highlighting the limitations of standard neural differential equations in modeling complex systems, where physical invariants (like energy) are often absent but other constraints (like mass conservation, network locality, bounded rationality) must be enforced. To address this, we introduce Agent-Based-Model informed Neural Networks(ABM-NNs), which leverage restricted graph neural networks and hierarchical decomposition to learn interpretable, structure-preserving dynamics. We validate the framework across three case studies of increasing complexity: (i) a generalized Generalized Lotka‚ÄìVolterra system, where we recover ground-truth parameters from short trajectories in presence of interventions; (ii) a graph-based SIR contagion model, where our method outperforms state-of-the-art graph learning baselines (GCN, GraphSAGE, Graph Transformer) in out-of-sample forecasting and noise robustness; and (iii) a real-world macroeconomic model of the ten largest economies, where we learn coupled GDP dynamics from empirical data and demonstrate gradient-based counterfactual analysis for policy interventions.\nüìÑ Download PDF\nOpen Data, Privacy, and Fair Information Principles: Towards a Balancing Framework Authors: Frederik Zuiderveen Borgesius, Jonathan Gray, Mireille van Eechoud Venue: arXiv (2025)\nOpen data are held to contribute to a wide variety of social and political goals, including strengthening transparency, public participation and democratic accountability, promoting economic growth and innovation, and enabling greater public sector efficiency and cost savings. However, releasing government data that contain personal information may threaten privacy and related rights and interests. In this Article we ask how these privacy interests can be respected, without unduly hampering benefits from disclosing public sector information. We propose a balancing framework to help public authorities address this question in different contexts. The framework takes into account different levels of privacy risks for different types of data. It also separates decisions about access and re-use, and highlights a range of different disclosure routes. A circumstance catalogue lists factors that might be considered when assessing whether, under which conditions, and how a dataset can be released. While open data remains an important route for the publication of government information, we conclude that it is not the only route, and there must be clear and robust public interest arguments in order to justify the disclosure of personal information as open data.\nüìÑ Download PDF\nThe Power of Network Pluralism: Multi-Perspective Modeling of Heterogeneous Legal Document Networks Authors: Titus P√ºnder, Corinna Coupette Venue: arXiv (2025)\nInsights are relative - influenced by a range of factors such as assumptions, scopes, or methods that together define a research perspective. In normative and empirical fields alike, this insight has led to the conclusion that no single perspective can generate complete knowledge. As a response, epistemological pluralism mandates that researchers consider multiple perspectives simultaneously to obtain a holistic understanding of their phenomenon under study. Translating this mandate to network science, our work introduces Network Pluralism as a conceptual framework that leverages multi-perspectivity to yield more complete, meaningful, and robust results. We develop and demonstrate the benefits of this approach via a hands-on analysis of complex legal systems, constructing a network space from references across documents from different branches of government as well as including organizational hierarchy above and fine-grained structure below the document level. Leveraging the resulting heterogeneity in a multi-network analysis, we show how complementing perspectives can help contextualize otherwise high-level findings, how contrasting several networks derived from the same data enables researchers to learn by difference, and how relating metrics to perspectives may increase the transparency and robustness of network-analytical results. To analyze a space of networks as perspectives, researchers need to map dimensions of variation in a given domain to network-modeling decisions and network-metric parameters. While this remains a challenging and inherently interdisciplinary task, our work acts as a blueprint to facilitate the broader adoption of Network Pluralism in domain-driven network research.\nüìÑ Download PDF\nMIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models Authors: Chuang Yu, Jinmiao Zhao, Mingxuan Zhao, Yunpeng Liu, Xiujun Shu, Yuanhao Feng, Bo Wang, Xiangyu Yue Venue: arXiv (2025)\nRecently, multimodal large language models (MLLMs) have been widely applied to reasoning tasks. However, they suffer from limited multi-rationale semantic modeling, insufficient logical robustness, and are susceptible to misleading interpretations in complex scenarios. Therefore, we propose a Multi-rationale INtegrated Discriminative (MIND) reasoning framework, which is designed to endow MLLMs with human-like cognitive abilities of ‚ÄúUnderstand -\u003e Rethink -\u003e Correct‚Äù, and achieves a paradigm evolution from passive imitation-based reasoning to active discriminative reasoning. Specifically, we introduce a Rationale Augmentation and Discrimination (RAD) paradigm, which automatically and efficiently expands existing datasets by generating diverse rationales, providing a unified and extensible data foundation. Meanwhile, we design a Progressive Two-stage Correction Learning (P2CL) strategy. The first phase enhances multi-rationale positive learning, while the second phase enables active logic discrimination and correction. In addition, to mitigate representation entanglement in the multi-rationale semantic space, we propose a Multi-rationale Contrastive Alignment (MCA) optimization strategy, which achieves semantic aggregation of correct reasoning and boundary separation of incorrect reasoning. Extensive experiments demonstrate that the proposed MIND reasoning framework achieves state-of-the-art (SOTA) performance on multiple public datasets covering scientific, commonsense, and mathematical scenarios. It provides a new perspective for advancing MLLMs towards higher levels of cognitive intelligence. Our code is available at https://github.com/YuChuang1205/MIND\nüìÑ Download PDF\nLyrics Matter: Exploiting the Power of Learnt Representations for Music Popularity Prediction Authors: Yash Choudhary, Preeti Rao, Pushpak Bhattacharyya Venue: arXiv (2025)\nAccurately predicting music popularity is a critical challenge in the music industry, offering benefits to artists, producers, and streaming platforms. Prior research has largely focused on audio features, social metadata, or model architectures. This work addresses the under-explored role of lyrics in predicting popularity. We present an automated pipeline that uses LLM to extract high-dimensional lyric embeddings, capturing semantic, syntactic, and sequential information. These features are integrated into HitMusicLyricNet, a multimodal architecture that combines audio, lyrics, and social metadata for popularity score prediction in the range 0-100. Our method outperforms existing baselines on the SpotGenTrack dataset, which contains over 100,000 tracks, achieving 9% and 20% improvements in MAE and MSE, respectively. Ablation confirms that gains arise from our LLM-driven lyrics feature pipeline (LyricsAENet), underscoring the value of dense lyric representations.\nüìÑ Download PDF\n","wordCount":"25853","inLanguage":"zh","datePublished":"2025-12-09T01:30:00.403921Z","dateModified":"2025-12-09T01:30:00.403921Z","author":{"@type":"Person","name":"Gary"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://garyforreal.me/zh/posts/paper/paper-2025-12-09-weekly/"},"publisher":{"@type":"Organization","name":"Gary's House","logo":{"@type":"ImageObject","url":"https://garyforreal.me/img/Q.jpg"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css><script src=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><script src=https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js></script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://garyforreal.me/zh/ accesskey=h title="Gary's Blog (Alt + H)"><img src=https://garyforreal.me/img/me.jpg alt aria-label=logo height=35>Gary's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://garyforreal.me/en/ title=English aria-label=English>English</a></li></ul></div></div><ul id=menu><li><a href=https://garyforreal.me/zh/search title="üîçÊêúÁ¥¢ (Alt + /)" accesskey=/><span>üîçÊêúÁ¥¢</span></a></li><li><a href=https://garyforreal.me/zh/ title=üè†‰∏ªÈ°µ><span>üè†‰∏ªÈ°µ</span></a></li><li><a href=https://garyforreal.me/zh/posts/ title=üìöÊñáÁ´†><span>üìöÊñáÁ´†</span></a></li><li><a href=https://garyforreal.me/zh/archives/ title=‚è±Â≠òÊ°£><span>‚è±Â≠òÊ°£</span></a></li><li><a href=https://garyforreal.me/zh/music/ title=üéµÈü≥‰πê><span>üéµÈü≥‰πê</span></a></li><li><a href=https://garyforreal.me/zh/about title=üôãüèª‚Äç‚ôÇÔ∏èÂÖ≥‰∫é><span>üôãüèª‚Äç‚ôÇÔ∏èÂÖ≥‰∫é</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://garyforreal.me/zh/>‰∏ªÈ°µ</a>&nbsp;¬ª&nbsp;<a href=https://garyforreal.me/zh/posts/>Â∏ñÂ≠ê</a>&nbsp;¬ª&nbsp;<a href=https://garyforreal.me/zh/posts/paper/>ËÆ∫Êñá</a></div><h1 class="post-title entry-hint-parent">Weekly Paper Notes - 2025-12-09</h1><div class=post-meta><span title='2025-12-09 01:30:00.403921 +0000 UTC'>2025-12-09</span>&nbsp;¬∑&nbsp;122 ÂàÜÈíü&nbsp;¬∑&nbsp;Gary&nbsp;|&nbsp;ËØ≠Ë®Ä:<ul class=i18n_list><li><a href=https://garyforreal.me/en/posts/paper/paper-2025-12-09-weekly/>English</a></li></ul><div class=meta-item>&nbsp¬∑&nbsp
        <span id=busuanzi_container_page_pv>Êú¨ÊñáÈòÖËØªÈáè<span id=busuanzi_value_page_pv></span>Ê¨°</span></div></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>ÁõÆÂΩï</span></summary><div class=inner><ul><li><a href=#weekly-paper-notes aria-label="Weekly Paper Notes">Weekly Paper Notes</a><ul><li><a href=#-multilingual aria-label="üîç multilingual">üîç multilingual</a><ul><li><a href=#m4-rag-a-massive-scale-multilingual-multi-cultural-multimodal-raghttpsarxivorgabs251205959v1 aria-label="M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG"><a href=https://arxiv.org/abs/2512.05959v1>M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG</a></a></li><li><a href=#efficient-text-classification-with-conformal-in-context-learninghttpsarxivorgabs251205732v1 aria-label="Efficient Text Classification with Conformal In-Context Learning"><a href=https://arxiv.org/abs/2512.05732v1>Efficient Text Classification with Conformal In-Context Learning</a></a></li><li><a href=#grounded-multilingual-medical-reasoning-for-question-answering-with-large-language-modelshttpsarxivorgabs251205658v1 aria-label="Grounded Multilingual Medical Reasoning for Question Answering with Large Language Models"><a href=https://arxiv.org/abs/2512.05658v1>Grounded Multilingual Medical Reasoning for Question Answering with Large Language Models</a></a></li><li><a href=#structured-reasoning-with-tree-of-thoughts-for-bengali-math-word-problemshttpsarxivorgabs251205580v1 aria-label="Structured Reasoning with Tree-of-Thoughts for Bengali Math Word Problems"><a href=https://arxiv.org/abs/2512.05580v1>Structured Reasoning with Tree-of-Thoughts for Bengali Math Word Problems</a></a></li><li><a href=#sea-safeguardbench-evaluating-ai-safety-in-sea-languages-and-cultureshttpsarxivorgabs251205501v1 aria-label="SEA-SafeguardBench: Evaluating AI Safety in SEA Languages and Cultures"><a href=https://arxiv.org/abs/2512.05501v1>SEA-SafeguardBench: Evaluating AI Safety in SEA Languages and Cultures</a></a></li><li><a href=#dynamic-alignment-for-collective-agency-toward-a-scalable-self-improving-framework-for-open-ended-llm-alignmenthttpsarxivorgabs251205464v1 aria-label="Dynamic Alignment for Collective Agency: Toward a Scalable Self-Improving Framework for Open-Ended LLM Alignment"><a href=https://arxiv.org/abs/2512.05464v1>Dynamic Alignment for Collective Agency: Toward a Scalable Self-Improving Framework for Open-Ended LLM Alignment</a></a></li><li><a href=#rrpo-robust-reward-policy-optimization-for-llm-based-emotional-ttshttpsarxivorgabs251204552v1 aria-label="RRPO: Robust Reward Policy Optimization for LLM-based Emotional TTS"><a href=https://arxiv.org/abs/2512.04552v1>RRPO: Robust Reward Policy Optimization for LLM-based Emotional TTS</a></a></li><li><a href=#adapting-large-language-models-to-low-resource-tibetan-a-two-stage-continual-and-supervised-fine-tuning-studyhttpsarxivorgabs251203976v1 aria-label="Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study"><a href=https://arxiv.org/abs/2512.03976v1>Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study</a></a></li><li><a href=#different-types-of-syntactic-agreement-recruit-the-same-units-within-large-language-modelshttpsarxivorgabs251203676v1 aria-label="Different types of syntactic agreement recruit the same units within large language models"><a href=https://arxiv.org/abs/2512.03676v1>Different types of syntactic agreement recruit the same units within large language models</a></a></li><li><a href=#m3dr-towards-universal-multilingual-multimodal-document-retrievalhttpsarxivorgabs251203514v1 aria-label="M3DR: Towards Universal Multilingual Multimodal Document Retrieval"><a href=https://arxiv.org/abs/2512.03514v1>M3DR: Towards Universal Multilingual Multimodal Document Retrieval</a></a></li><li><a href=#cross-lingual-prompt-steerability-towards-accurate-and-robust-llm-behavior-across-languageshttpsarxivorgabs251202841v1 aria-label="Cross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages"><a href=https://arxiv.org/abs/2512.02841v1>Cross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages</a></a></li><li><a href=#trilex-a-framework-for-multilingual-sentiment-analysis-in-low-resource-south-african-languageshttpsarxivorgabs251202799v1 aria-label="TriLex: A Framework for Multilingual Sentiment Analysis in Low-Resource South African Languages"><a href=https://arxiv.org/abs/2512.02799v1>TriLex: A Framework for Multilingual Sentiment Analysis in Low-Resource South African Languages</a></a></li><li><a href=#beyond-data-filtering-knowledge-localization-for-capability-removal-in-llmshttpsarxivorgabs251205648v1 aria-label="Beyond Data Filtering: Knowledge Localization for Capability Removal in LLMs"><a href=https://arxiv.org/abs/2512.05648v1>Beyond Data Filtering: Knowledge Localization for Capability Removal in LLMs</a></a></li><li><a href=#decoding-the-black-box-discerning-ai-rhetorics-about-and-through-poetic-promptinghttpsarxivorgabs251205243v1 aria-label="Decoding the Black Box: Discerning AI Rhetorics About and Through Poetic Prompting"><a href=https://arxiv.org/abs/2512.05243v1>Decoding the Black Box: Discerning AI Rhetorics About and Through Poetic Prompting</a></a></li><li><a href=#fine-tuning-bert-for-domain-specific-question-answering-toward-educational-nlp-resources-at-university-scalehttpsarxivorgabs251205179v1 aria-label="Fine-Tuning BERT for Domain-Specific Question Answering: Toward Educational NLP Resources at University Scale"><a href=https://arxiv.org/abs/2512.05179v1>Fine-Tuning BERT for Domain-Specific Question Answering: Toward Educational NLP Resources at University Scale</a></a></li><li><a href=#exploiting-spatial-multiplexing-based-on-pixel-antennas-an-antenna-coding-approachhttpsarxivorgabs251205706v1 aria-label="Exploiting Spatial Multiplexing Based on Pixel Antennas: An Antenna Coding Approach"><a href=https://arxiv.org/abs/2512.05706v1>Exploiting Spatial Multiplexing Based on Pixel Antennas: An Antenna Coding Approach</a></a></li><li><a href=#the-decision-path-to-control-ai-risks-completely-fundamental-control-mechanisms-for-ai-governancehttpsarxivorgabs251204489v1 aria-label="The Decision Path to Control AI Risks Completely: Fundamental Control Mechanisms for AI Governance"><a href=https://arxiv.org/abs/2512.04489v1>The Decision Path to Control AI Risks Completely: Fundamental Control Mechanisms for AI Governance</a></a></li><li><a href=#minimizing-the-number-of-code-switching-operations-in-fault-tolerant-quantum-circuitshttpsarxivorgabs251204170v1 aria-label="Minimizing the Number of Code Switching Operations in Fault-Tolerant Quantum Circuits"><a href=https://arxiv.org/abs/2512.04170v1>Minimizing the Number of Code Switching Operations in Fault-Tolerant Quantum Circuits</a></a></li><li><a href=#encompass-enhancing-agent-programming-with-search-over-program-execution-pathshttpsarxivorgabs251203571v1 aria-label="EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths"><a href=https://arxiv.org/abs/2512.03571v1>EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths</a></a></li><li><a href=#modeling-topics-and-sociolinguistic-variation-in-code-switched-discourse-insights-from-spanish-english-and-spanish-guaran%c3%adhttpsarxivorgabs251203334v1 aria-label="Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaran√≠"><a href=https://arxiv.org/abs/2512.03334v1>Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaran√≠</a></a></li><li><a href=#knowing-your-uncertainty----on-the-application-of-llm-in-social-scienceshttpsarxivorgabs251205461v1 aria-label="Knowing Your Uncertainty &ndash; On the application of LLM in social sciences"><a href=https://arxiv.org/abs/2512.05461v1>Knowing Your Uncertainty &ndash; On the application of LLM in social sciences</a></a></li><li><a href=#enhancing-retrieval-augmented-generation-with-entity-linking-for-educational-platformshttpsarxivorgabs251205967v1 aria-label="Enhancing Retrieval-Augmented Generation with Entity Linking for Educational Platforms"><a href=https://arxiv.org/abs/2512.05967v1>Enhancing Retrieval-Augmented Generation with Entity Linking for Educational Platforms</a></a></li><li><a href=#training-time-action-conditioning-for-efficient-real-time-chunkinghttpsarxivorgabs251205964v1 aria-label="Training-Time Action Conditioning for Efficient Real-Time Chunking"><a href=https://arxiv.org/abs/2512.05964v1>Training-Time Action Conditioning for Efficient Real-Time Chunking</a></a></li><li><a href=#maxshapley-towards-incentive-compatible-generative-search-with-fair-context-attributionhttpsarxivorgabs251205958v1 aria-label="MaxShapley: Towards Incentive-compatible Generative Search with Fair Context Attribution"><a href=https://arxiv.org/abs/2512.05958v1>MaxShapley: Towards Incentive-compatible Generative Search with Fair Context Attribution</a></a></li><li><a href=#simpact-simulation-enabled-action-planning-using-vision-language-modelshttpsarxivorgabs251205955v1 aria-label="SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models"><a href=https://arxiv.org/abs/2512.05955v1>SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models</a></a></li><li><a href=#sympybench-a-dynamic-benchmark-for-scientific-reasoning-with-executable-python-codehttpsarxivorgabs251205954v1 aria-label="SymPyBench: A Dynamic Benchmark for Scientific Reasoning with Executable Python Code"><a href=https://arxiv.org/abs/2512.05954v1>SymPyBench: A Dynamic Benchmark for Scientific Reasoning with Executable Python Code</a></a></li><li><a href=#thermodynamics-of-shear-equilibration-during-magnetic-reconnection-onset-in-mixed-equilibrium-current-sheetshttpsarxivorgabs251205921v1 aria-label="Thermodynamics of Shear Equilibration During Magnetic Reconnection Onset in Mixed-Equilibrium Current Sheets"><a href=https://arxiv.org/abs/2512.05921v1>Thermodynamics of Shear Equilibration During Magnetic Reconnection Onset in Mixed-Equilibrium Current Sheets</a></a></li><li><a href=#scail-towards-studio-grade-character-animation-via-in-context-learning-of-3d-consistent-pose-representationshttpsarxivorgabs251205905v1 aria-label="SCAIL: Towards Studio-Grade Character Animation via In-Context Learning of 3D-Consistent Pose Representations"><a href=https://arxiv.org/abs/2512.05905v1>SCAIL: Towards Studio-Grade Character Animation via In-Context Learning of 3D-Consistent Pose Representations</a></a></li><li><a href=#interplay-of-ferroelectricity-and-interlayer-superconductivity-in-van-der-waals-bilayershttpsarxivorgabs251205871v1 aria-label="Interplay of ferroelectricity and interlayer superconductivity in van der Waals bilayers"><a href=https://arxiv.org/abs/2512.05871v1>Interplay of ferroelectricity and interlayer superconductivity in van der Waals bilayers</a></a></li><li><a href=#phase-otdr-event-detection-using-image-based-data-transformation-and-deep-learninghttpsarxivorgabs251205830v1 aria-label="Phase-OTDR Event Detection Using Image-Based Data Transformation and Deep Learning"><a href=https://arxiv.org/abs/2512.05830v1>Phase-OTDR Event Detection Using Image-Based Data Transformation and Deep Learning</a></a></li><li><a href=#higher-order-diffusion-and-cahn-hilliard-type-models-revisited-on-the-half-linehttpsarxivorgabs251205829v1 aria-label="Higher-order diffusion and Cahn-Hilliard-type models revisited on the half-line"><a href=https://arxiv.org/abs/2512.05829v1>Higher-order diffusion and Cahn-Hilliard-type models revisited on the half-line</a></a></li><li><a href=#himoe-vla-hierarchical-mixture-of-experts-for-generalist-vision-language-action-policieshttpsarxivorgabs251205693v1 aria-label="HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies"><a href=https://arxiv.org/abs/2512.05693v1>HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies</a></a></li><li><a href=#editthinker-unlocking-iterative-reasoning-for-any-image-editorhttpsarxivorgabs251205965v1 aria-label="EditThinker: Unlocking Iterative Reasoning for Any Image Editor"><a href=https://arxiv.org/abs/2512.05965v1>EditThinker: Unlocking Iterative Reasoning for Any Image Editor</a></a></li><li><a href=#variational-quantum-rainbow-deep-q-network-for-optimizing-resource-allocation-problemhttpsarxivorgabs251205946v1 aria-label="Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem"><a href=https://arxiv.org/abs/2512.05946v1>Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem</a></a></li><li><a href=#qualitative-and-quantitative-analysis-of-riemannian-optimization-methods-for-ground-states-of-rotating-multicomponent-bose-einstein-condensateshttpsarxivorgabs251205939v1 aria-label="Qualitative and Quantitative Analysis of Riemannian Optimization Methods for Ground States of Rotating Multicomponent Bose-Einstein Condensates"><a href=https://arxiv.org/abs/2512.05939v1>Qualitative and Quantitative Analysis of Riemannian Optimization Methods for Ground States of Rotating Multicomponent Bose-Einstein Condensates</a></a></li><li><a href=#physically-based-simulation-of-automotive-lidarhttpsarxivorgabs251205932v1 aria-label="Physically-Based Simulation of Automotive LiDAR"><a href=https://arxiv.org/abs/2512.05932v1>Physically-Based Simulation of Automotive LiDAR</a></a></li><li><a href=#natural-language-summarization-enables-multi-repository-bug-localization-by-llms-in-microservice-architectureshttpsarxivorgabs251205908v1 aria-label="Natural Language Summarization Enables Multi-Repository Bug Localization by LLMs in Microservice Architectures"><a href=https://arxiv.org/abs/2512.05908v1>Natural Language Summarization Enables Multi-Repository Bug Localization by LLMs in Microservice Architectures</a></a></li><li><a href=#from-text-to-returns-using-large-language-models-for-mutual-fund-portfolio-optimization-and-risk-adjusted-allocationhttpsarxivorgabs251205907v1 aria-label="From Text to Returns: Using Large Language Models for Mutual Fund Portfolio Optimization and Risk-Adjusted Allocation"><a href=https://arxiv.org/abs/2512.05907v1>From Text to Returns: Using Large Language Models for Mutual Fund Portfolio Optimization and Risk-Adjusted Allocation</a></a></li><li><a href=#asteroseismology-of-spb-stars-a-comparison-of-forward-asteroseismic-modelling-results-from-kepler-and-tesshttpsarxivorgabs251205864v1 aria-label="Asteroseismology of SPB stars: a comparison of forward asteroseismic modelling results from Kepler and TESS"><a href=https://arxiv.org/abs/2512.05864v1>Asteroseismology of SPB stars: a comparison of forward asteroseismic modelling results from Kepler and TESS</a></a></li></ul></li><li><a href=#-linguistics aria-label="üîç linguistics">üîç linguistics</a><ul><li><a href=#aqua-net-adaptive-frequency-fusion-and-illumination-aware-network-for-underwater-image-enhancementhttpsarxivorgabs251205960v1 aria-label="AQUA-Net: Adaptive Frequency Fusion and Illumination Aware Network for Underwater Image Enhancement"><a href=https://arxiv.org/abs/2512.05960v1>AQUA-Net: Adaptive Frequency Fusion and Illumination Aware Network for Underwater Image Enhancement</a></a></li><li><a href=#spectroscopy-and-coherent-control-of-two-level-system-defect-ensembles-using-a-broadband-3d-waveguidehttpsarxivorgabs251205934v1 aria-label="Spectroscopy and Coherent Control of Two-Level System Defect Ensembles Using a Broadband 3D Waveguide"><a href=https://arxiv.org/abs/2512.05934v1>Spectroscopy and Coherent Control of Two-Level System Defect Ensembles Using a Broadband 3D Waveguide</a></a></li><li><a href=#prism-an-agentic-multimodal-benchmark-for-scientific-reasoning-via-python-grounded-evaluationhttpsarxivorgabs251205930v1 aria-label="PRiSM: An Agentic Multimodal Benchmark for Scientific Reasoning via Python-Grounded Evaluation"><a href=https://arxiv.org/abs/2512.05930v1>PRiSM: An Agentic Multimodal Benchmark for Scientific Reasoning via Python-Grounded Evaluation</a></a></li><li><a href=#numerically-reliable-brunovsky-transformationshttpsarxivorgabs251205910v1 aria-label="Numerically Reliable Brunovsky Transformations"><a href=https://arxiv.org/abs/2512.05910v1>Numerically Reliable Brunovsky Transformations</a></a></li><li><a href=#learning-the-cosmic-web-graph-based-classification-of-simulated-galaxies-by-their-dark-matter-environmentshttpsarxivorgabs251205909v1 aria-label="Learning the Cosmic Web: Graph-based Classification of Simulated Galaxies by their Dark Matter Environments"><a href=https://arxiv.org/abs/2512.05909v1>Learning the Cosmic Web: Graph-based Classification of Simulated Galaxies by their Dark Matter Environments</a></a></li><li><a href=#lpd-learnable-prototypes-with-diversity-regularization-for-weakly-supervised-histopathology-segmentationhttpsarxivorgabs251205922v1 aria-label="LPD: Learnable Prototypes with Diversity Regularization for Weakly Supervised Histopathology Segmentation"><a href=https://arxiv.org/abs/2512.05922v1>LPD: Learnable Prototypes with Diversity Regularization for Weakly Supervised Histopathology Segmentation</a></a></li><li><a href=#a-redshift-independent-theoretical-halo-mass-function-validated-with-the-uchuu-simulationshttpsarxivorgabs251205847v1 aria-label="A redshift-independent theoretical halo mass function validated with the Uchuu simulations"><a href=https://arxiv.org/abs/2512.05847v1>A redshift-independent theoretical halo mass function validated with the Uchuu simulations</a></a></li><li><a href=#twisting-the-hagedorn-temperature-in-planar-mathcaln4-super-yang-millshttpsarxivorgabs251205810v1 aria-label="Twisting the Hagedorn temperature in planar $\mathcal{N}=4$ super Yang-Mills"><a href=https://arxiv.org/abs/2512.05810v1>Twisting the Hagedorn temperature in planar $\mathcal{N}=4$ super Yang-Mills</a></a></li><li><a href=#size-effects-on-shift-current-in-layered-cuinp_2s_6httpsarxivorgabs251205796v1 aria-label="Size-effects on shift-current in layered CuInP$_2$S$_6$"><a href=https://arxiv.org/abs/2512.05796v1>Size-effects on shift-current in layered CuInP$_2$S$_6$</a></a></li><li><a href=#multi-band-alma-polarization-observations-of-bhb07-11-reveal-aligned-dust-grains-in-complex-spiral-arm-structureshttpsarxivorgabs251205768v1 aria-label="Multi-band ALMA Polarization Observations of BHB07-11 Reveal Aligned Dust Grains in Complex Spiral Arm Structures"><a href=https://arxiv.org/abs/2512.05768v1>Multi-band ALMA Polarization Observations of BHB07-11 Reveal Aligned Dust Grains in Complex Spiral Arm Structures</a></a></li><li><a href=#4d3d-reduction-of-dualities-with-o6httpsarxivorgabs251205724v1 aria-label="4d/3d reduction of dualities with O6"><a href=https://arxiv.org/abs/2512.05724v1>4d/3d reduction of dualities with O6</a></a></li><li><a href=#whatever-remains-must-be-true-filtering-drives-reasoning-in-llms-shaping-diversityhttpsarxivorgabs251205962v1 aria-label="Whatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity"><a href=https://arxiv.org/abs/2512.05962v1>Whatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity</a></a></li><li><a href=#consequences-of-kernel-regularity-for-bandit-optimizationhttpsarxivorgabs251205957v1 aria-label="Consequences of Kernel Regularity for Bandit Optimization"><a href=https://arxiv.org/abs/2512.05957v1>Consequences of Kernel Regularity for Bandit Optimization</a></a></li><li><a href=#correspondence-oriented-imitation-learning-flexible-visuomotor-control-with-3d-conditioninghttpsarxivorgabs251205953v1 aria-label="Correspondence-Oriented Imitation Learning: Flexible Visuomotor Control with 3D Conditioning"><a href=https://arxiv.org/abs/2512.05953v1>Correspondence-Oriented Imitation Learning: Flexible Visuomotor Control with 3D Conditioning</a></a></li><li><a href=#heard-or-halted-gender-interruptions-and-emotional-tone-in-us-supreme-court-oral-argumentshttpsarxivorgabs251205832v1 aria-label="Heard or Halted? Gender, Interruptions, and Emotional Tone in U.S. Supreme Court Oral Arguments"><a href=https://arxiv.org/abs/2512.05832v1>Heard or Halted? Gender, Interruptions, and Emotional Tone in U.S. Supreme Court Oral Arguments</a></a></li><li><a href=#unveiling-affective-polarization-trends-in-parliamentary-proceedingshttpsarxivorgabs251205231v1 aria-label="Unveiling Affective Polarization Trends in Parliamentary Proceedings"><a href=https://arxiv.org/abs/2512.05231v1>Unveiling Affective Polarization Trends in Parliamentary Proceedings</a></a></li><li><a href=#toward-continuous-neurocognitive-monitoring-integrating-speech-ai-with-relational-graph-transformers-for-rare-neurological-diseaseshttpsarxivorgabs251204938v1 aria-label="Toward Continuous Neurocognitive Monitoring: Integrating Speech AI with Relational Graph Transformers for Rare Neurological Diseases"><a href=https://arxiv.org/abs/2512.04938v1>Toward Continuous Neurocognitive Monitoring: Integrating Speech AI with Relational Graph Transformers for Rare Neurological Diseases</a></a></li><li><a href=#seal-self-evolving-agentic-learning-for-conversational-question-answering-over-knowledge-graphshttpsarxivorgabs251204868v1 aria-label="SEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs"><a href=https://arxiv.org/abs/2512.04868v1>SEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs</a></a></li><li><a href=#playing-the-player-a-heuristic-framework-for-adaptive-poker-aihttpsarxivorgabs251204714v1 aria-label="Playing the Player: A Heuristic Framework for Adaptive Poker AI"><a href=https://arxiv.org/abs/2512.04714v1>Playing the Player: A Heuristic Framework for Adaptive Poker AI</a></a></li><li><a href=#llm-srclog-towards-proactive-and-unified-log-template-extraction-via-large-language-modelshttpsarxivorgabs251204474v1 aria-label="LLM-SrcLog: Towards Proactive and Unified Log Template Extraction via Large Language Models"><a href=https://arxiv.org/abs/2512.04474v1>LLM-SrcLog: Towards Proactive and Unified Log Template Extraction via Large Language Models</a></a></li><li><a href=#strongly-coupled-quantum-forceshttpsarxivorgabs251205968v1 aria-label="Strongly Coupled Quantum Forces"><a href=https://arxiv.org/abs/2512.05968v1>Strongly Coupled Quantum Forces</a></a></li><li><a href=#entanglement-enhanced-quantum-nano-vibrometryhttpsarxivorgabs251205961v1 aria-label="Entanglement-Enhanced Quantum Nano-Vibrometry"><a href=https://arxiv.org/abs/2512.05961v1>Entanglement-Enhanced Quantum Nano-Vibrometry</a></a></li><li><a href=#topical-issue-on-the-intersection-of-low-energy-nuclear-structure-and-high-energy-nuclear-collisionshttpsarxivorgabs251205874v1 aria-label="Topical issue on the intersection of low-energy nuclear structure and high-energy nuclear collisions"><a href=https://arxiv.org/abs/2512.05874v1>Topical issue on the intersection of low-energy nuclear structure and high-energy nuclear collisions</a></a></li><li><a href=#resolving-abrikosov-vortex-entry-in-superconducting-nano-string-resonators-via-displacement-noise-spectroscopy-in-cavity-optomechanicshttpsarxivorgabs251205873v1 aria-label="Resolving Abrikosov vortex entry in superconducting nano-string resonators via displacement-noise spectroscopy in cavity-optomechanics"><a href=https://arxiv.org/abs/2512.05873v1>Resolving Abrikosov vortex entry in superconducting nano-string resonators via displacement-noise spectroscopy in cavity-optomechanics</a></a></li><li><a href=#categorifying-isomonodromic-deformations-via-lie-groupoids-i-logarithmic-singularitieshttpsarxivorgabs251205966v1 aria-label="Categorifying isomonodromic deformations via Lie groupoids I: Logarithmic singularities"><a href=https://arxiv.org/abs/2512.05966v1>Categorifying isomonodromic deformations via Lie groupoids I: Logarithmic singularities</a></a></li><li><a href=#impugan-learning-conditional-generative-models-for-robust-data-imputationhttpsarxivorgabs251205950v1 aria-label="Impugan: Learning Conditional Generative Models for Robust Data Imputation"><a href=https://arxiv.org/abs/2512.05950v1>Impugan: Learning Conditional Generative Models for Robust Data Imputation</a></a></li><li><a href=#removing-correlated-noise-stripes-from-the-nancy-grace-roman-space-telescope-survey-imageshttpsarxivorgabs251205949v1 aria-label="Removing correlated noise stripes from the Nancy Grace Roman Space Telescope survey images"><a href=https://arxiv.org/abs/2512.05949v1>Removing correlated noise stripes from the Nancy Grace Roman Space Telescope survey images</a></a></li><li><a href=#on-cable-graph-percolation-between-dimensions-2-and-3httpsarxivorgabs251205947v1 aria-label="On cable-graph percolation between dimensions 2 and 3"><a href=https://arxiv.org/abs/2512.05947v1>On cable-graph percolation between dimensions 2 and 3</a></a></li><li><a href=#bootstrapping-fuzzers-for-compilers-of-low-resource-language-dialects-using-language-modelshttpsarxivorgabs251205887v1 aria-label="Bootstrapping Fuzzers for Compilers of Low-Resource Language Dialects Using Language Models"><a href=https://arxiv.org/abs/2512.05887v1>Bootstrapping Fuzzers for Compilers of Low-Resource Language Dialects Using Language Models</a></a></li><li><a href=#model-selection-with-uncertainty-in-estimating-optimal-dynamic-treatment-regimeshttpsarxivorgabs251205695v1 aria-label="Model selection with uncertainty in estimating optimal dynamic treatment regimes"><a href=https://arxiv.org/abs/2512.05695v1>Model selection with uncertainty in estimating optimal dynamic treatment regimes</a></a></li><li><a href=#conscious-gaze-adaptive-attention-mechanisms-for-hallucination-mitigation-in-vision-language-modelshttpsarxivorgabs251205546v1 aria-label="Conscious Gaze: Adaptive Attention Mechanisms for Hallucination Mitigation in Vision-Language Models"><a href=https://arxiv.org/abs/2512.05546v1>Conscious Gaze: Adaptive Attention Mechanisms for Hallucination Mitigation in Vision-Language Models</a></a></li><li><a href=#an-evaluation-of-a15-nb3al-superconducting-thin-films-for-application-in-quantum-circuitshttpsarxivorgabs251205396v1 aria-label="An evaluation of A15 Nb3Al superconducting thin films for application in quantum circuits"><a href=https://arxiv.org/abs/2512.05396v1>An evaluation of A15 Nb3Al superconducting thin films for application in quantum circuits</a></a></li><li><a href=#comparative-analysis-of-barrier-like-function-methods-for-reach-avoid-verification-in-stochastic-discrete-time-systemshttpsarxivorgabs251205348v1 aria-label="Comparative Analysis of Barrier-like Function Methods for Reach-Avoid Verification in Stochastic Discrete-Time Systems"><a href=https://arxiv.org/abs/2512.05348v1>Comparative Analysis of Barrier-like Function Methods for Reach-Avoid Verification in Stochastic Discrete-Time Systems</a></a></li><li><a href=#on-planar-straight-line-dominance-drawingshttpsarxivorgabs251205225v1 aria-label="On Planar Straight-Line Dominance Drawings"><a href=https://arxiv.org/abs/2512.05225v1>On Planar Straight-Line Dominance Drawings</a></a></li></ul></li><li><a href=#-psycholinguistics aria-label="üîç psycholinguistics">üîç psycholinguistics</a><ul><li><a href=#constraining-r-process-nucleosynthesis-via-enhanced-accuracy-neutron-capture-experimentshttpsarxivorgabs251205944v1 aria-label="Constraining r-process nucleosynthesis via enhanced accuracy neutron-capture experiments"><a href=https://arxiv.org/abs/2512.05944v1>Constraining r-process nucleosynthesis via enhanced accuracy neutron-capture experiments</a></a></li><li><a href=#evolutionary-system-2-reasoning-an-empirical-proofhttpsarxivorgabs251205760v1 aria-label="Evolutionary System 2 Reasoning: An Empirical Proof"><a href=https://arxiv.org/abs/2512.05760v1>Evolutionary System 2 Reasoning: An Empirical Proof</a></a></li><li><a href=#squeezing-classical-antiferromagnets-into-quantum-spin-liquids-via-global-cavity-fluctuationshttpsarxivorgabs251205630v1 aria-label="Squeezing Classical Antiferromagnets into Quantum Spin Liquids via Global Cavity Fluctuations"><a href=https://arxiv.org/abs/2512.05630v1>Squeezing Classical Antiferromagnets into Quantum Spin Liquids via Global Cavity Fluctuations</a></a></li><li><a href=#anomaly-cancellation-and-one-loop-finiteness-of-6d-half-maximal-supergravitieshttpsarxivorgabs251205082v1 aria-label="Anomaly cancellation and one-loop finiteness of 6D half-maximal supergravities"><a href=https://arxiv.org/abs/2512.05082v1>Anomaly cancellation and one-loop finiteness of 6D half-maximal supergravities</a></a></li><li><a href=#an-elementary-approach-to-wehrl-type-entropy-bounds-in-quantitative-formhttpsarxivorgabs251204245v1 aria-label="An elementary approach to Wehrl-type entropy bounds in quantitative form"><a href=https://arxiv.org/abs/2512.04245v1>An elementary approach to Wehrl-type entropy bounds in quantitative form</a></a></li><li><a href=#counting-ads-vacuahttpsarxivorgabs251204151v1 aria-label="Counting AdS Vacua"><a href=https://arxiv.org/abs/2512.04151v1>Counting AdS Vacua</a></a></li><li><a href=#structure-theorems-for-the-heart-of-lcahttpsarxivorgabs251203338v1 aria-label="Structure theorems for the heart of LCA"><a href=https://arxiv.org/abs/2512.03338v1>Structure theorems for the heart of LCA</a></a></li><li><a href=#group-classification-12-dimensional-linear-equation-of-asian-options-pricinghttpsarxivorgabs251205963v1 aria-label="Group Classification (1+2)-dimensional Linear Equation of Asian Options Pricing"><a href=https://arxiv.org/abs/2512.05963v1>Group Classification (1+2)-dimensional Linear Equation of Asian Options Pricing</a></a></li><li><a href=#trusted-ai-agents-in-the-cloudhttpsarxivorgabs251205951v1 aria-label="Trusted AI Agents in the Cloud"><a href=https://arxiv.org/abs/2512.05951v1>Trusted AI Agents in the Cloud</a></a></li><li><a href=#a-comparative-study-on-synthetic-facial-data-generation-techniques-for-face-recognitionhttpsarxivorgabs251205928v1 aria-label="A Comparative Study on Synthetic Facial Data Generation Techniques for Face Recognition"><a href=https://arxiv.org/abs/2512.05928v1>A Comparative Study on Synthetic Facial Data Generation Techniques for Face Recognition</a></a></li><li><a href=#the-bayesian-way-uncertainty-learning-and-statistical-reasoninghttpsarxivorgabs251205883v1 aria-label="The Bayesian Way: Uncertainty, Learning, and Statistical Reasoning"><a href=https://arxiv.org/abs/2512.05883v1>The Bayesian Way: Uncertainty, Learning, and Statistical Reasoning</a></a></li><li><a href=#ug-fedda-uncertainty-guided-federated-domain-adaptation-for-multi-center-alzheimers-disease-detectionhttpsarxivorgabs251205814v1 aria-label="UG-FedDA: Uncertainty-Guided Federated Domain Adaptation for Multi-Center Alzheimer&rsquo;s Disease Detection"><a href=https://arxiv.org/abs/2512.05814v1>UG-FedDA: Uncertainty-Guided Federated Domain Adaptation for Multi-Center Alzheimer&rsquo;s Disease Detection</a></a></li><li><a href=#speech-world-model-causal-state-action-planning-with-explicit-reasoning-for-speechhttpsarxivorgabs251205933v1 aria-label="Speech World Model: Causal State-Action Planning with Explicit Reasoning for Speech"><a href=https://arxiv.org/abs/2512.05933v1>Speech World Model: Causal State-Action Planning with Explicit Reasoning for Speech</a></a></li><li><a href=#a-hybrid-dynamic-model-for-predicting-human-cognition-and-reliance-during-automated-drivinghttpsarxivorgabs251205845v1 aria-label="A Hybrid Dynamic Model for Predicting Human Cognition and Reliance during Automated Driving"><a href=https://arxiv.org/abs/2512.05845v1>A Hybrid Dynamic Model for Predicting Human Cognition and Reliance during Automated Driving</a></a></li><li><a href=#a-fast-anti-jamming-cognitive-radar-deployment-algorithm-based-on-reinforcement-learninghttpsarxivorgabs251205753v1 aria-label="A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning"><a href=https://arxiv.org/abs/2512.05753v1>A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning</a></a></li><li><a href=#emergence-of-language-in-the-developing-brainhttpsarxivorgabs251205718v1 aria-label="Emergence of Language in the Developing Brain"><a href=https://arxiv.org/abs/2512.05718v1>Emergence of Language in the Developing Brain</a></a></li><li><a href=#instructmpc-a-human-llm-in-the-loop-framework-for-context-aware-power-grid-controlhttpsarxivorgabs251205876v1 aria-label="InstructMPC: A Human-LLM-in-the-Loop Framework for Context-Aware Power Grid Control"><a href=https://arxiv.org/abs/2512.05876v1>InstructMPC: A Human-LLM-in-the-Loop Framework for Context-Aware Power Grid Control</a></a></li><li><a href=#machine-learning-enabled-interpretation-of-tribological-deformation-patterns-in-large-scale-md-datahttpsarxivorgabs251205818v1 aria-label="Machine-learning-enabled interpretation of tribological deformation patterns in large-scale MD data"><a href=https://arxiv.org/abs/2512.05818v1>Machine-learning-enabled interpretation of tribological deformation patterns in large-scale MD data</a></a></li></ul></li><li><a href=#-llm aria-label="üîç llm">üîç llm</a><ul><li><a href=#transformation-of-orientation-and-rotation-angles-of-synchronous-satellites-application-to-the-galilean-moonshttpsarxivorgabs251205935v1 aria-label="Transformation of orientation and rotation angles of synchronous satellites: Application to the Galilean moons"><a href=https://arxiv.org/abs/2512.05935v1>Transformation of orientation and rotation angles of synchronous satellites: Application to the Galilean moons</a></a></li><li><a href=#kq-svd-compressing-the-kv-cache-with-provable-guarantees-on-attention-fidelityhttpsarxivorgabs251205916v1 aria-label="KQ-SVD: Compressing the KV Cache with Provable Guarantees on Attention Fidelity"><a href=https://arxiv.org/abs/2512.05916v1>KQ-SVD: Compressing the KV Cache with Provable Guarantees on Attention Fidelity</a></a></li><li><a href=#differentially-rotating-neutron-stars-with-dark-matter-coreshttpsarxivorgabs251205898v1 aria-label="Differentially rotating neutron stars with dark matter cores"><a href=https://arxiv.org/abs/2512.05898v1>Differentially rotating neutron stars with dark matter cores</a></a></li><li><a href=#log-linear-dynamic-inversion-for-thrusting-spacecraft-on-se23httpsarxivorgabs251205888v1 aria-label="Log-linear Dynamic Inversion for Thrusting Spacecraft on SE2(3)"><a href=https://arxiv.org/abs/2512.05888v1>Log-linear Dynamic Inversion for Thrusting Spacecraft on SE2(3)</a></a></li></ul></li><li><a href=#-neuroscience aria-label="üîç neuroscience">üîç neuroscience</a><ul><li><a href=#zoom-in-click-out-unlocking-and-evaluating-the-potential-of-zooming-for-gui-groundinghttpsarxivorgabs251205941v1 aria-label="Zoom in, Click out: Unlocking and Evaluating the Potential of Zooming for GUI Grounding"><a href=https://arxiv.org/abs/2512.05941v1>Zoom in, Click out: Unlocking and Evaluating the Potential of Zooming for GUI Grounding</a></a></li><li><a href=#a-continuous-nonlinear-optimization-perspective-on-the-spin-glass-problemhttpsarxivorgabs251205852v1 aria-label="A Continuous Nonlinear Optimization Perspective on the Spin Glass Problem"><a href=https://arxiv.org/abs/2512.05852v1>A Continuous Nonlinear Optimization Perspective on the Spin Glass Problem</a></a></li><li><a href=#superconformal-interfaces-from-5d-n4-gauged-supergravityhttpsarxivorgabs251205805v1 aria-label="Superconformal interfaces from 5D N=4 gauged supergravity"><a href=https://arxiv.org/abs/2512.05805v1>Superconformal interfaces from 5D N=4 gauged supergravity</a></a></li><li><a href=#a-multi-channel-auditory-signal-encoder-with-adaptive-resolution-using-volatile-memristorshttpsarxivorgabs251205701v1 aria-label="A Multi-Channel Auditory Signal Encoder with Adaptive Resolution Using Volatile Memristors"><a href=https://arxiv.org/abs/2512.05701v1>A Multi-Channel Auditory Signal Encoder with Adaptive Resolution Using Volatile Memristors</a></a></li></ul></li><li><a href=#-data_resources aria-label="üîç data_resources">üîç data_resources</a><ul><li><a href=#designing-an-optimal-sensor-network-via-minimizing-information-losshttpsarxivorgabs251205940v1 aria-label="Designing an Optimal Sensor Network via Minimizing Information Loss"><a href=https://arxiv.org/abs/2512.05940v1>Designing an Optimal Sensor Network via Minimizing Information Loss</a></a></li><li><a href=#a-greek-government-decisions-dataset-for-public-sector-analysis-and-insighthttpsarxivorgabs251205647v1 aria-label="A Greek Government Decisions Dataset for Public-Sector Analysis and Insight"><a href=https://arxiv.org/abs/2512.05647v1>A Greek Government Decisions Dataset for Public-Sector Analysis and Insight</a></a></li><li><a href=#using-large-language-models-to-create-personalized-networks-from-therapy-sessionshttpsarxivorgabs251205836v1 aria-label="Using Large Language Models to Create Personalized Networks From Therapy Sessions"><a href=https://arxiv.org/abs/2512.05836v1>Using Large Language Models to Create Personalized Networks From Therapy Sessions</a></a></li><li><a href=#label-efficient-point-cloud-segmentation-with-active-learninghttpsarxivorgabs251205759v1 aria-label="Label-Efficient Point Cloud Segmentation with Active Learning"><a href=https://arxiv.org/abs/2512.05759v1>Label-Efficient Point Cloud Segmentation with Active Learning</a></a></li><li><a href=#owl-unsupervised-3d-object-detection-by-occupancy-guided-warm-up-and-large-model-priors-reasoninghttpsarxivorgabs251205698v1 aria-label="OWL: Unsupervised 3D Object Detection by Occupancy Guided Warm-up and Large Model Priors Reasoning"><a href=https://arxiv.org/abs/2512.05698v1>OWL: Unsupervised 3D Object Detection by Occupancy Guided Warm-up and Large Model Priors Reasoning</a></a></li><li><a href=#distillfss-synthesizing-few-shot-knowledge-into-a-lightweight-segmentation-modelhttpsarxivorgabs251205613v1 aria-label="DistillFSS: Synthesizing Few-Shot Knowledge into a Lightweight Segmentation Model"><a href=https://arxiv.org/abs/2512.05613v1>DistillFSS: Synthesizing Few-Shot Knowledge into a Lightweight Segmentation Model</a></a></li></ul></li><li><a href=#-emotion_language aria-label="üîç emotion_language">üîç emotion_language</a><ul><li><a href=#measuring-the-effect-of-background-on-classification-and-feature-importance-in-deep-learning-for-av-perceptionhttpsarxivorgabs251205937v1 aria-label="Measuring the Effect of Background on Classification and Feature Importance in Deep Learning for AV Perception"><a href=https://arxiv.org/abs/2512.05937v1>Measuring the Effect of Background on Classification and Feature Importance in Deep Learning for AV Perception</a></a></li><li><a href=#most-rocky-sub-neptunes-are-molten-mapping-the-solidification-shoreline-for-gas-dwarf-exoplanetshttpsarxivorgabs251205816v1 aria-label="Most Rocky Sub-Neptunes are Molten: Mapping the Solidification Shoreline for Gas Dwarf Exoplanets"><a href=https://arxiv.org/abs/2512.05816v1>Most Rocky Sub-Neptunes are Molten: Mapping the Solidification Shoreline for Gas Dwarf Exoplanets</a></a></li><li><a href=#developing-synthetic-microdata-through-machine-learning-for-firm-level-business-surveyshttpsarxivorgabs251205948v1 aria-label="Developing synthetic microdata through machine learning for firm-level business surveys"><a href=https://arxiv.org/abs/2512.05948v1>Developing synthetic microdata through machine learning for firm-level business surveys</a></a></li><li><a href=#minimal-two-band-model-and-experimental-proposals-to-distinguish-pairing-mechanisms-of-the-high-t_c-superconductor-la_3ni_2o_7httpsarxivorgabs251205956v1 aria-label="Minimal two band model and experimental proposals to distinguish pairing mechanisms of the high-T$_c$ superconductor La$_3$Ni$_2$O$_7$"><a href=https://arxiv.org/abs/2512.05956v1>Minimal two band model and experimental proposals to distinguish pairing mechanisms of the high-T$_c$ superconductor La$_3$Ni$_2$O$_7$</a></a></li><li><a href=#llm-harms-a-taxonomy-and-discussionhttpsarxivorgabs251205929v1 aria-label="LLM Harms: A Taxonomy and Discussion"><a href=https://arxiv.org/abs/2512.05929v1>LLM Harms: A Taxonomy and Discussion</a></a></li><li><a href=#nice-neural-implicit-craniofacial-model-for-orthognathic-surgery-predictionhttpsarxivorgabs251205920v1 aria-label="NICE: Neural Implicit Craniofacial Model for Orthognathic Surgery Prediction"><a href=https://arxiv.org/abs/2512.05920v1>NICE: Neural Implicit Craniofacial Model for Orthognathic Surgery Prediction</a></a></li><li><a href=#world-models-that-know-when-they-dont-know-controllable-video-generation-with-calibrated-uncertaintyhttpsarxivorgabs251205927v1 aria-label="World Models That Know When They Don&rsquo;t Know: Controllable Video Generation with Calibrated Uncertainty"><a href=https://arxiv.org/abs/2512.05927v1>World Models That Know When They Don&rsquo;t Know: Controllable Video Generation with Calibrated Uncertainty</a></a></li><li><a href=#to-err-is-human-systematic-quantification-of-errors-in-published-ai-papers-via-llm-analysishttpsarxivorgabs251205925v1 aria-label="To Err Is Human: Systematic Quantification of Errors in Published AI Papers via LLM Analysis"><a href=https://arxiv.org/abs/2512.05925v1>To Err Is Human: Systematic Quantification of Errors in Published AI Papers via LLM Analysis</a></a></li><li><a href=#a-residual-variance-matching-recursive-least-squares-filter-for-real-time-uav-terrain-followinghttpsarxivorgabs251205918v1 aria-label="A Residual Variance Matching Recursive Least Squares Filter for Real-time UAV Terrain Following"><a href=https://arxiv.org/abs/2512.05918v1>A Residual Variance Matching Recursive Least Squares Filter for Real-time UAV Terrain Following</a></a></li><li><a href=#unitarization-of-r--%ce%b1r2-gravityhttpsarxivorgabs251205911v1 aria-label="Unitarization of $R + Œ±R^2$ gravity"><a href=https://arxiv.org/abs/2512.05911v1>Unitarization of $R + Œ±R^2$ gravity</a></a></li><li><a href=#euclid-quick-data-release-q1-from-simulations-to-sky-advancing-machine-learning-lens-detection-with-real-euclid-datahttpsarxivorgabs251205899v1 aria-label="Euclid Quick Data Release (Q1). From simulations to sky: Advancing machine-learning lens detection with real Euclid data"><a href=https://arxiv.org/abs/2512.05899v1>Euclid Quick Data Release (Q1). From simulations to sky: Advancing machine-learning lens detection with real Euclid data</a></a></li><li><a href=#hadronic-emissions-from-the-microquasar-v4641-sgr-ss433-and-its-implications-in-the-diffuse-galactic-emissionhttpsarxivorgabs251205839v1 aria-label="Hadronic Emissions from the Microquasar V4641 Sgr, SS433, and its implications in the Diffuse Galactic Emission"><a href=https://arxiv.org/abs/2512.05839v1>Hadronic Emissions from the Microquasar V4641 Sgr, SS433, and its implications in the Diffuse Galactic Emission</a></a></li><li><a href=#quantitatively-mapping-the-eady-model-onto-a-two-layer-quasi-geostrophic-modelhttpsarxivorgabs251205902v1 aria-label="Quantitatively mapping the Eady model onto a two-layer quasi-geostrophic model"><a href=https://arxiv.org/abs/2512.05902v1>Quantitatively mapping the Eady model onto a two-layer quasi-geostrophic model</a></a></li><li><a href=#invariant-price-of-anarchy-a-metric-for-welfarist-traffic-controlhttpsarxivorgabs251205843v1 aria-label="Invariant Price of Anarchy: a Metric for Welfarist Traffic Control"><a href=https://arxiv.org/abs/2512.05843v1>Invariant Price of Anarchy: a Metric for Welfarist Traffic Control</a></a></li><li><a href=#towards-agent-based-model-informed-neural-networkshttpsarxivorgabs251205764v1 aria-label="Towards agent-based-model informed neural networks"><a href=https://arxiv.org/abs/2512.05764v1>Towards agent-based-model informed neural networks</a></a></li><li><a href=#open-data-privacy-and-fair-information-principles-towards-a-balancing-frameworkhttpsarxivorgabs251205728v1 aria-label="Open Data, Privacy, and Fair Information Principles: Towards a Balancing Framework"><a href=https://arxiv.org/abs/2512.05728v1>Open Data, Privacy, and Fair Information Principles: Towards a Balancing Framework</a></a></li><li><a href=#the-power-of-network-pluralism-multi-perspective-modeling-of-heterogeneous-legal-document-networkshttpsarxivorgabs251205679v1 aria-label="The Power of Network Pluralism: Multi-Perspective Modeling of Heterogeneous Legal Document Networks"><a href=https://arxiv.org/abs/2512.05679v1>The Power of Network Pluralism: Multi-Perspective Modeling of Heterogeneous Legal Document Networks</a></a></li><li><a href=#mind-multi-rationale-integrated-discriminative-reasoning-framework-for-multi-modal-large-modelshttpsarxivorgabs251205530v1 aria-label="MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models"><a href=https://arxiv.org/abs/2512.05530v1>MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models</a></a></li><li><a href=#lyrics-matter-exploiting-the-power-of-learnt-representations-for-music-popularity-predictionhttpsarxivorgabs251205508v1 aria-label="Lyrics Matter: Exploiting the Power of Learnt Representations for Music Popularity Prediction"><a href=https://arxiv.org/abs/2512.05508v1>Lyrics Matter: Exploiting the Power of Learnt Representations for Music Popularity Prediction</a></a></li></ul></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=weekly-paper-notes>Weekly Paper Notes<a hidden class=anchor aria-hidden=true href=#weekly-paper-notes>#</a></h1><h2 id=-multilingual>üîç multilingual<a hidden class=anchor aria-hidden=true href=#-multilingual>#</a></h2><h3 id=m4-rag-a-massive-scale-multilingual-multi-cultural-multimodal-raghttpsarxivorgabs251205959v1><a href=https://arxiv.org/abs/2512.05959v1>M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG</a><a hidden class=anchor aria-hidden=true href=#m4-rag-a-massive-scale-multilingual-multi-cultural-multimodal-raghttpsarxivorgabs251205959v1>#</a></h3><p><strong>Authors:</strong> David Anugraha, Patrick Amadeus Irawan, Anshul Singh, En-Shiun Annie Lee, Genta Indra Winata
<strong>Venue:</strong> arXiv (2025)</p><p>Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05959v1">üìÑ Download PDF</a></p><hr><h3 id=efficient-text-classification-with-conformal-in-context-learninghttpsarxivorgabs251205732v1><a href=https://arxiv.org/abs/2512.05732v1>Efficient Text Classification with Conformal In-Context Learning</a><a hidden class=anchor aria-hidden=true href=#efficient-text-classification-with-conformal-in-context-learninghttpsarxivorgabs251205732v1>#</a></h3><p><strong>Authors:</strong> Ippokratis Pantelidis, Korbinian Randl, Aron Henriksson
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Models (LLMs) demonstrate strong in-context learning abilities, yet their effectiveness in text classification depends heavily on prompt design and incurs substantial computational cost. Conformal In-Context Learning (CICLe) has been proposed as a resource-efficient framework that integrates a lightweight base classifier with Conformal Prediction to guide LLM prompting by adaptively reducing the set of candidate classes. However, its broader applicability and efficiency benefits beyond a single domain have not yet been systematically explored. In this paper, we present a comprehensive evaluation of CICLe across diverse NLP classification benchmarks. The results show that CICLe consistently improves over its base classifier and outperforms few-shot prompting baselines when the sample size is sufficient for training the base classifier, and performs comparably in low-data regimes. In terms of efficiency, CICLe reduces the number of shots and prompt length by up to 34.45% and 25.16%, respectively, and enables the use of smaller models with competitive performance. CICLe is furthermore particularly advantageous for text classification tasks with high class imbalance. These findings highlight CICLe as a practical and scalable approach for efficient text classification, combining the robustness of traditional classifiers with the adaptability of LLMs, and achieving substantial gains in data and computational efficiency.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05732v1">üìÑ Download PDF</a></p><hr><h3 id=grounded-multilingual-medical-reasoning-for-question-answering-with-large-language-modelshttpsarxivorgabs251205658v1><a href=https://arxiv.org/abs/2512.05658v1>Grounded Multilingual Medical Reasoning for Question Answering with Large Language Models</a><a hidden class=anchor aria-hidden=true href=#grounded-multilingual-medical-reasoning-for-question-answering-with-large-language-modelshttpsarxivorgabs251205658v1>#</a></h3><p><strong>Authors:</strong> Pietro Ferrazzi, Aitor Soroa, Rodrigo Agerri
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Models (LLMs) with reasoning capabilities have recently demonstrated strong potential in medical Question Answering (QA). Existing approaches are largely English-focused and primarily rely on distillation from general-purpose LLMs, raising concerns about the reliability of their medical knowledge. In this work, we present a method to generate multilingual reasoning traces grounded in factual medical knowledge. We produce 500k traces in English, Italian, and Spanish, using a retrievalaugmented generation approach over medical information from Wikipedia. The traces are generated to solve medical questions drawn from MedQA and MedMCQA, which we extend to Italian and Spanish. We test our pipeline in both in-domain and outof-domain settings across Medical QA benchmarks, and demonstrate that our reasoning traces improve performance both when utilized via in-context learning (few-shot) and supervised fine-tuning, yielding state-of-the-art results among 8B-parameter LLMs. We believe that these resources can support the development of safer, more transparent clinical decision-support tools in multilingual settings. We release the full suite of resources: reasoning traces, translated QA datasets, Medical-Wikipedia, and fine-tuned models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05658v1">üìÑ Download PDF</a></p><hr><h3 id=structured-reasoning-with-tree-of-thoughts-for-bengali-math-word-problemshttpsarxivorgabs251205580v1><a href=https://arxiv.org/abs/2512.05580v1>Structured Reasoning with Tree-of-Thoughts for Bengali Math Word Problems</a><a hidden class=anchor aria-hidden=true href=#structured-reasoning-with-tree-of-thoughts-for-bengali-math-word-problemshttpsarxivorgabs251205580v1>#</a></h3><p><strong>Authors:</strong> Aurprita Mahmood, Sabrin alam, Neloy kumer Sagor, Md. Abdul Hadi, Md. Sehab Al Islam, Minhajul Islam
<strong>Venue:</strong> arXiv (2025)</p><p>Mathematical Word Problems (MWPs) are among the most challenging tasks in natural language processing because they require both linguistic understanding and multi-step numerical reasoning. While Chain-of-Thought (CoT) prompting has shown promise, its linear structure often propagates errors, limiting overall effectiveness. To address this limitation, we present the a systematic study of Tree-of-Thought (ToT) reasoning for Bengali MWPs using the SOMADHAN dataset. Owing to computational and token-cost constraints, we evaluate a curated set of 100 representative problems across multiple large language models (LLMs), including GPT-OSS and LLaMA variants, under standard prompting, CoT, and ToT strategies. Our results show that CoT improves baseline accuracy from 78% (standard prompting) to 83% on average, while ToT further increases performance by up to 5 percentage points, achieving 88% accuracy with GPT-OSS-120B. These improvements highlight that ToT is particularly effective in medium-to-large-scale models but may offer less advantage for smaller ones. Overall, our findings establish ToT as a robust framework for solving mathematical problems in low-resource languages such as Bengali. More broadly, this study shows that structured reasoning methods like ToT can provide more reliable and globally consistent outcomes than CoT, paving the way for better reasoning strategies in multilingual NLP.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05580v1">üìÑ Download PDF</a></p><hr><h3 id=sea-safeguardbench-evaluating-ai-safety-in-sea-languages-and-cultureshttpsarxivorgabs251205501v1><a href=https://arxiv.org/abs/2512.05501v1>SEA-SafeguardBench: Evaluating AI Safety in SEA Languages and Cultures</a><a hidden class=anchor aria-hidden=true href=#sea-safeguardbench-evaluating-ai-safety-in-sea-languages-and-cultureshttpsarxivorgabs251205501v1>#</a></h3><p><strong>Authors:</strong> Panuthep Tasawong, Jian Gang Ngui, Alham Fikri Aji, Trevor Cohn, Peerat Limkonchotiwat
<strong>Venue:</strong> arXiv (2025)</p><p>Safeguard models help large language models (LLMs) detect and block harmful content, but most evaluations remain English-centric and overlook linguistic and cultural diversity. Existing multilingual safety benchmarks often rely on machine-translated English data, which fails to capture nuances in low-resource languages. Southeast Asian (SEA) languages are underrepresented despite the region&rsquo;s linguistic diversity and unique safety concerns, from culturally sensitive political speech to region-specific misinformation. Addressing these gaps requires benchmarks that are natively authored to reflect local norms and harm scenarios. We introduce SEA-SafeguardBench, the first human-verified safety benchmark for SEA, covering eight languages, 21,640 samples, across three subsets: general, in-the-wild, and content generation. The experimental results from our benchmark demonstrate that even state-of-the-art LLMs and guardrails are challenged by SEA cultural and harm scenarios and underperform when compared to English texts.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05501v1">üìÑ Download PDF</a></p><hr><h3 id=dynamic-alignment-for-collective-agency-toward-a-scalable-self-improving-framework-for-open-ended-llm-alignmenthttpsarxivorgabs251205464v1><a href=https://arxiv.org/abs/2512.05464v1>Dynamic Alignment for Collective Agency: Toward a Scalable Self-Improving Framework for Open-Ended LLM Alignment</a><a hidden class=anchor aria-hidden=true href=#dynamic-alignment-for-collective-agency-toward-a-scalable-self-improving-framework-for-open-ended-llm-alignmenthttpsarxivorgabs251205464v1>#</a></h3><p><strong>Authors:</strong> Panatchakorn Anantaprayoon, Nataliia Babina, Jad Tarifi, Nima Asgharbeygi
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Models (LLMs) are typically aligned with human values using preference data or predefined principles such as helpfulness, honesty, and harmlessness. However, as AI systems progress toward Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI), such value systems may become insufficient. In addition, human feedback-based alignment remains resource-intensive and difficult to scale. While AI-feedback-based self-improving alignment methods have been explored as a scalable alternative, they have largely remained constrained to conventional alignment values. In this work, we explore both a more holistic alignment objective and a scalable, self-improving alignment approach. Aiming to transcend conventional alignment norms, we introduce Collective Agency (CA)-a unified and open-ended alignment value that encourages integrated agentic capabilities. We also propose Dynamic Alignment-an alignment framework that enables an LLM to iteratively align itself. Dynamic Alignment comprises two key components: (1) automated training dataset generation with LLMs, and (2) a self-rewarding mechanism, where the policy model evaluates its own output candidates and assigns rewards for GRPO-based learning. Experimental results demonstrate that our approach successfully aligns the model to CA while preserving general NLP capabilities.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05464v1">üìÑ Download PDF</a></p><hr><h3 id=rrpo-robust-reward-policy-optimization-for-llm-based-emotional-ttshttpsarxivorgabs251204552v1><a href=https://arxiv.org/abs/2512.04552v1>RRPO: Robust Reward Policy Optimization for LLM-based Emotional TTS</a><a hidden class=anchor aria-hidden=true href=#rrpo-robust-reward-policy-optimization-for-llm-based-emotional-ttshttpsarxivorgabs251204552v1>#</a></h3><p><strong>Authors:</strong> Cong Wang, Changfeng Gao, Yang Xiang, Zhihao Du, Keyu An, Han Zhao, Qian Chen, Xiangang Li, Yingming Gao, Ya Li
<strong>Venue:</strong> arXiv (2025)</p><p>Differentiable reinforcement learning (RL) frameworks like DiffRO offer a powerful approach for controllable text-to-speech (TTS), but are vulnerable to reward hacking, particularly for nuanced tasks like emotion control. The policy model can exploit a vanilla Reward Model (RM) by generating acoustic artifacts to achieve spurious rewards, but at the cost of degrading perceptual quality. To address this, we propose Robust Reward Policy Optimization (RRPO), a novel framework that employs a hybrid regularization scheme. This scheme develops a robust RM whose reward signal is more reliably aligned with human perception, compelling the policy to abandon detrimental shortcuts and instead learn the complex features of genuine emotions. Our ablation study confirms the enhanced robustness of our RM, as evidenced by its strong cross-lingual generalization. The subjective evaluation demonstrates that this robust RM effectively mitigates reward hacking, leading to significant improvements in both emotional expressiveness and naturalness over all baselines. Demo page: <a href=https://lrwinr.github.io/RRPO-CosyVoice>https://lrwinr.github.io/RRPO-CosyVoice</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04552v1">üìÑ Download PDF</a></p><hr><h3 id=adapting-large-language-models-to-low-resource-tibetan-a-two-stage-continual-and-supervised-fine-tuning-studyhttpsarxivorgabs251203976v1><a href=https://arxiv.org/abs/2512.03976v1>Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study</a><a hidden class=anchor aria-hidden=true href=#adapting-large-language-models-to-low-resource-tibetan-a-two-stage-continual-and-supervised-fine-tuning-studyhttpsarxivorgabs251203976v1>#</a></h3><p><strong>Authors:</strong> Lifeng Chen, Ryan Lai, Tianming Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Adapting large language models (LLMs) to low-resource languages remains a major challenge due to data scarcity and cross-lingual drift. This work presents a two-stage adaptation of Qwen2.5-3B to Tibetan, a morphologically rich and underrepresented language. We employ Continual Pretraining (CPT) to establish Tibetan linguistic grounding, followed by Supervised Fine-Tuning (SFT) for task and translation specialization. Empirical evaluations demonstrate a consistent decrease in perplexity (from 2.98 $\rightarrow$ 1.54) and substantial improvements in Chinese$\rightarrow$Tibetan translation quality (BLEU: 0.046 $\rightarrow$ 0.261; chrF: 2.2 $\rightarrow$ 6.6). Layer-wise analysis across 435 layers in Qwen3-4B reveals that adaptation primarily concentrates on embedding and output heads, with mid&ndash;late MLP projections encoding domain-specific transformations. Our findings suggest that CPT constructs a Tibetan semantic manifold while SFT sharpens task alignment with minimal representational disruption. This study provides the first quantitative exploration of Tibetan adaptation dynamics for LLMs, and offers an open, reproducible framework for extending multilingual foundation models to low-resource settings.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03976v1">üìÑ Download PDF</a></p><hr><h3 id=different-types-of-syntactic-agreement-recruit-the-same-units-within-large-language-modelshttpsarxivorgabs251203676v1><a href=https://arxiv.org/abs/2512.03676v1>Different types of syntactic agreement recruit the same units within large language models</a><a hidden class=anchor aria-hidden=true href=#different-types-of-syntactic-agreement-recruit-the-same-units-within-large-language-modelshttpsarxivorgabs251203676v1>#</a></h3><p><strong>Authors:</strong> Daria Kryvosheieva, Andrea de Varda, Evelina Fedorenko, Greta Tuckute
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) can reliably distinguish grammatical from ungrammatical sentences, but how grammatical knowledge is represented within the models remains an open question. We investigate whether different syntactic phenomena recruit shared or distinct components in LLMs. Using a functional localization approach inspired by cognitive neuroscience, we identify the LLM units most responsive to 67 English syntactic phenomena in seven open-weight models. These units are consistently recruited across sentences containing the phenomena and causally support the models&rsquo; syntactic performance. Critically, different types of syntactic agreement (e.g., subject-verb, anaphor, determiner-noun) recruit overlapping sets of units, suggesting that agreement constitutes a meaningful functional category for LLMs. This pattern holds in English, Russian, and Chinese; and further, in a cross-lingual analysis of 57 diverse languages, structurally more similar languages share more units for subject-verb agreement. Taken together, these findings reveal that syntactic agreement-a critical marker of syntactic dependencies-constitutes a meaningful category within LLMs&rsquo; representational spaces.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03676v1">üìÑ Download PDF</a></p><hr><h3 id=m3dr-towards-universal-multilingual-multimodal-document-retrievalhttpsarxivorgabs251203514v1><a href=https://arxiv.org/abs/2512.03514v1>M3DR: Towards Universal Multilingual Multimodal Document Retrieval</a><a hidden class=anchor aria-hidden=true href=#m3dr-towards-universal-multilingual-multimodal-document-retrievalhttpsarxivorgabs251203514v1>#</a></h3><p><strong>Authors:</strong> Adithya S Kolavi, Vyoman Jain
<strong>Venue:</strong> arXiv (2025)</p><p>Multimodal document retrieval systems have shown strong progress in aligning visual and textual content for semantic search. However, most existing approaches remain heavily English-centric, limiting their effectiveness in multilingual contexts. In this work, we present M3DR (Multilingual Multimodal Document Retrieval), a framework designed to bridge this gap across languages, enabling applicability across diverse linguistic and cultural contexts. M3DR leverages synthetic multilingual document data and generalizes across different vision-language architectures and model sizes, enabling robust cross-lingual and cross-modal alignment. Using contrastive training, our models learn unified representations for text and document images that transfer effectively across languages. We validate this capability on 22 typologically diverse languages, demonstrating consistent performance and adaptability across linguistic and script variations. We further introduce a comprehensive benchmark that captures real-world multilingual scenarios, evaluating models under monolingual, multilingual, and mixed-language settings. M3DR generalizes across both single dense vector and ColBERT-style token-level multi-vector retrieval paradigms. Our models, NetraEmbed and ColNetraEmbed achieve state-of-the-art performance with ~150% relative improvements on cross-lingual retrieval.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03514v1">üìÑ Download PDF</a></p><hr><h3 id=cross-lingual-prompt-steerability-towards-accurate-and-robust-llm-behavior-across-languageshttpsarxivorgabs251202841v1><a href=https://arxiv.org/abs/2512.02841v1>Cross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages</a><a hidden class=anchor aria-hidden=true href=#cross-lingual-prompt-steerability-towards-accurate-and-robust-llm-behavior-across-languageshttpsarxivorgabs251202841v1>#</a></h3><p><strong>Authors:</strong> Lechen Zhang, Yusheng Zhou, Tolga Ergen, Lajanugen Logeswaran, Moontae Lee, David Jurgens
<strong>Venue:</strong> arXiv (2025)</p><p>System prompts provide a lightweight yet powerful mechanism for conditioning large language models (LLMs) at inference time. While prior work has focused on English-only settings, real-world deployments benefit from having a single prompt to operate reliably across languages. This paper presents a comprehensive study of how different system prompts steer models toward accurate and robust cross-lingual behavior. We propose a unified four-dimensional evaluation framework to assess system prompts in multilingual environments. Through large-scale experiments on five languages, three LLMs, and three benchmarks, we uncover that certain prompt components, such as CoT, emotion, and scenario, correlate with robust multilingual behavior. We develop a prompt optimization framework for multilingual settings and show it can automatically discover prompts that improve all metrics by 5-10%. Finally, we analyze over 10 million reasoning units and find that more performant system prompts induce more structured and consistent reasoning patterns, while reducing unnecessary language-switching. Together, we highlight system prompt optimization as a scalable path to accurate and robust multilingual LLM behavior.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02841v1">üìÑ Download PDF</a></p><hr><h3 id=trilex-a-framework-for-multilingual-sentiment-analysis-in-low-resource-south-african-languageshttpsarxivorgabs251202799v1><a href=https://arxiv.org/abs/2512.02799v1>TriLex: A Framework for Multilingual Sentiment Analysis in Low-Resource South African Languages</a><a hidden class=anchor aria-hidden=true href=#trilex-a-framework-for-multilingual-sentiment-analysis-in-low-resource-south-african-languageshttpsarxivorgabs251202799v1>#</a></h3><p><strong>Authors:</strong> Mike Nkongolo, Hilton Vorster, Josh Warren, Trevor Naick, Deandre Vanmali, Masana Mashapha, Luke Brand, Alyssa Fernandes, Janco Calitz, Sibusiso Makhoba
<strong>Venue:</strong> arXiv (2025)</p><p>Low-resource African languages remain underrepresented in sentiment analysis, limiting both lexical coverage and the performance of multilingual Natural Language Processing (NLP) systems. This study proposes TriLex, a three-stage retrieval augmented framework that unifies corpus-based extraction, cross lingual mapping, and retrieval augmented generation (RAG) driven lexical refinement to systematically expand sentiment lexicons for low-resource languages. Using the enriched lexicon, the performance of two prominent African pretrained language models (AfroXLMR and AfriBERTa) is evaluated across multiple case studies. Results demonstrate that AfroXLMR delivers superior performance, achieving F1-scores above 80% for isiXhosa and isiZulu and exhibiting strong cross-lingual stability. Although AfriBERTa lacks pre-training on these target languages, it still achieves reliable F1-scores around 64%, validating its utility in computationally constrained settings. Both models outperform traditional machine learning baselines, and ensemble analyses further enhance precision and robustness. The findings establish TriLex as a scalable and effective framework for multilingual sentiment lexicon expansion and sentiment modeling in low-resource South African languages.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02799v1">üìÑ Download PDF</a></p><hr><h3 id=beyond-data-filtering-knowledge-localization-for-capability-removal-in-llmshttpsarxivorgabs251205648v1><a href=https://arxiv.org/abs/2512.05648v1>Beyond Data Filtering: Knowledge Localization for Capability Removal in LLMs</a><a hidden class=anchor aria-hidden=true href=#beyond-data-filtering-knowledge-localization-for-capability-removal-in-llmshttpsarxivorgabs251205648v1>#</a></h3><p><strong>Authors:</strong> Igor Shilov, Alex Cloud, Aryo Pradipta Gema, Jacob Goldman-Wetzler, Nina Panickssery, Henry Sleight, Erik Jones, Cem Anil
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Models increasingly possess capabilities that carry dual-use risks. While data filtering has emerged as a pretraining-time mitigation, it faces significant challenges: labeling whether data is harmful is expensive at scale, and given improving sample efficiency with larger models, even small amounts of mislabeled content could give rise to dangerous capabilities. To address risks associated with mislabeled harmful content, prior work proposed Gradient Routing (Cloud et al., 2024) &ndash; a technique that localizes target knowledge into a dedicated subset of model parameters so they can later be removed. We explore an improved variant of Gradient Routing, which we call Selective GradienT Masking (SGTM), with particular focus on evaluating its robustness to label noise. SGTM zero-masks selected gradients such that target domain examples only update their dedicated parameters. We test SGTM&rsquo;s effectiveness in two applications: removing knowledge of one language from a model trained on a bilingual synthetic dataset, and removing biology knowledge from a model trained on English Wikipedia. In both cases SGTM provides better retain/forget trade-off in the presence of labeling errors compared to both data filtering and a previously proposed instantiation of Gradient Routing. Unlike shallow unlearning approaches that can be quickly undone through fine-tuning, SGTM exhibits strong robustness to adversarial fine-tuning, requiring seven times more fine-tuning steps to reach baseline performance on the forget set compared to a finetuning-based unlearning method (RMU). Our results suggest SGTM provides a promising pretraining-time complement to existing safety mitigations, particularly in settings where label noise is unavoidable.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05648v1">üìÑ Download PDF</a></p><hr><h3 id=decoding-the-black-box-discerning-ai-rhetorics-about-and-through-poetic-promptinghttpsarxivorgabs251205243v1><a href=https://arxiv.org/abs/2512.05243v1>Decoding the Black Box: Discerning AI Rhetorics About and Through Poetic Prompting</a><a hidden class=anchor aria-hidden=true href=#decoding-the-black-box-discerning-ai-rhetorics-about-and-through-poetic-promptinghttpsarxivorgabs251205243v1>#</a></h3><p><strong>Authors:</strong> P. D. Edgar, Alia Hall
<strong>Venue:</strong> arXiv (2025)</p><p>Prompt engineering has emerged as a useful way studying the algorithmic tendencies and biases of large language models. Meanwhile creatives and academics have leveraged LLMs to develop creative works and explore the boundaries of their writing capabilities through text generation and code. This study suggests that creative text prompting, specifically Poetry Prompt Patterns, may be a useful addition to the toolbox of the prompt engineer, and outlines the process by which this approach may be taken. Then, the paper uses poetic prompts to assess descriptions and evaluations of three models of a renowned poet and test the consequences of the willingness of models to adapt or rewrite original creative works for presumed audiences.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05243v1">üìÑ Download PDF</a></p><hr><h3 id=fine-tuning-bert-for-domain-specific-question-answering-toward-educational-nlp-resources-at-university-scalehttpsarxivorgabs251205179v1><a href=https://arxiv.org/abs/2512.05179v1>Fine-Tuning BERT for Domain-Specific Question Answering: Toward Educational NLP Resources at University Scale</a><a hidden class=anchor aria-hidden=true href=#fine-tuning-bert-for-domain-specific-question-answering-toward-educational-nlp-resources-at-university-scalehttpsarxivorgabs251205179v1>#</a></h3><p><strong>Authors:</strong> Aur√©lie Montfrond
<strong>Venue:</strong> arXiv (2025)</p><p>Prior work on scientific question answering has largely emphasized chatbot-style systems, with limited exploration of fine-tuning foundation models for domain-specific reasoning. In this study, we developed a chatbot for the University of Limerick&rsquo;s Department of Electronic and Computer Engineering to provide course information to students. A custom dataset of 1,203 question-answer pairs in SQuAD format was constructed using the university book of modules, supplemented with manually and synthetically generated entries. We fine-tuned BERT (Devlin et al., 2019) using PyTorch and evaluated performance with Exact Match and F1 scores. Results show that even modest fine-tuning improves hypothesis framing and knowledge extraction, demonstrating the feasibility of adapting foundation models to educational domains. While domain-specific BERT variants such as BioBERT and SciBERT exist for biomedical and scientific literature, no foundation model has yet been tailored to university course materials. Our work addresses this gap by showing that fine-tuning BERT with academic QA pairs yields effective results, highlighting the potential to scale towards the first domain-specific QA model for universities and enabling autonomous educational knowledge systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05179v1">üìÑ Download PDF</a></p><hr><h3 id=exploiting-spatial-multiplexing-based-on-pixel-antennas-an-antenna-coding-approachhttpsarxivorgabs251205706v1><a href=https://arxiv.org/abs/2512.05706v1>Exploiting Spatial Multiplexing Based on Pixel Antennas: An Antenna Coding Approach</a><a hidden class=anchor aria-hidden=true href=#exploiting-spatial-multiplexing-based-on-pixel-antennas-an-antenna-coding-approachhttpsarxivorgabs251205706v1>#</a></h3><p><strong>Authors:</strong> Zixiang Han, Shanpu Shen, Ross Murch
<strong>Venue:</strong> arXiv (2025)</p><p>An antenna coding approach for exploiting the spatial multiplexing capability of pixel antennas is proposed. This approach can leverage additional degrees of freedom in the beamspace domain to transmit more information streams. Pixel antennas are a general reconfigurable antenna design where a radiating structure with arbitrary shape and size can be discretized into sub-wavelength elements called pixels which are connected by radio frequency switches. By controlling the switch states, the pixel antenna topology can be flexibly adjusted so that the resulting radiation pattern can be reconfigured for beamspace spatial multiplexing. In this work, we introduce the antenna coder and pattern coder for pixel antennas, provide a multiple-input multiple-output (MIMO) communication system model with antenna coding in the beamspace domain, and derive the spectral efficiency. Utilizing the antenna coder, the radiation pattern of the pixel antenna is analyzed and efficient optimization algorithms are provided for antenna coding design. Numerical simulation results show that the proposed technique using pixel antennas can enhance spectral efficiency of 4-by-4 MIMO by up to 12 bits/s/Hz or equivalently reduce the required transmit power by up to 90% when compared to conventional MIMO, demonstrating the effectiveness of the antenna coding technique in spectral efficiency enhancement and its promise for future sixth generation (6G) wireless communication.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05706v1">üìÑ Download PDF</a></p><hr><h3 id=the-decision-path-to-control-ai-risks-completely-fundamental-control-mechanisms-for-ai-governancehttpsarxivorgabs251204489v1><a href=https://arxiv.org/abs/2512.04489v1>The Decision Path to Control AI Risks Completely: Fundamental Control Mechanisms for AI Governance</a><a hidden class=anchor aria-hidden=true href=#the-decision-path-to-control-ai-risks-completely-fundamental-control-mechanisms-for-ai-governancehttpsarxivorgabs251204489v1>#</a></h3><p><strong>Authors:</strong> Yong Tao
<strong>Venue:</strong> arXiv (2025)</p><p>Artificial intelligence (AI) advances rapidly but achieving complete human control over AI risks remains an unsolved problem, akin to driving the fast AI &ldquo;train&rdquo; without a &ldquo;brake system.&rdquo; By exploring fundamental control mechanisms at key elements of AI decisions, this paper develops a systematic solution to thoroughly control AI risks, providing an architecture for AI governance and legislation with five pillars supported by six control mechanisms, illustrated through a minimum set of AI Mandates (AIMs). Three of the AIMs must be built inside AI systems and three in society to address major areas of AI risks: 1) align AI values with human users; 2) constrain AI decision-actions by societal ethics, laws, and regulations; 3) build in human intervention options for emergencies and shut-off switches for existential threats; 4) limit AI access to resources to reinforce controls inside AI; 5) mitigate spillover risks like job loss from AI. We also highlight the differences in AI governance on physical AI systems versus generative AI. We discuss how to strengthen analog physical safeguards to prevent smarter AI/AGI/ASI from circumventing core safety controls by exploiting AI&rsquo;s intrinsic disconnect from the analog physical world: AI&rsquo;s nature as pure software code run on chips controlled by humans, and the prerequisite that all AI-driven physical actions must be digitized. These findings establish a theoretical foundation for AI governance and legislation as the basic structure of a &ldquo;brake system&rdquo; for AI decisions. If enacted, these controls can rein in AI dangers as completely as humanly possible, removing large chunks of currently wide-open AI risks, substantially reducing overall AI risks to residual human errors.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04489v1">üìÑ Download PDF</a></p><hr><h3 id=minimizing-the-number-of-code-switching-operations-in-fault-tolerant-quantum-circuitshttpsarxivorgabs251204170v1><a href=https://arxiv.org/abs/2512.04170v1>Minimizing the Number of Code Switching Operations in Fault-Tolerant Quantum Circuits</a><a hidden class=anchor aria-hidden=true href=#minimizing-the-number-of-code-switching-operations-in-fault-tolerant-quantum-circuitshttpsarxivorgabs251204170v1>#</a></h3><p><strong>Authors:</strong> Erik Weilandt, Tom Peham, Robert Wille
<strong>Venue:</strong> arXiv (2025)</p><p>Fault-tolerant quantum computers rely on Quantum Error-Correcting Codes (QECCs) to protect information from noise. However, no single error-correcting code supports a fully transversal and therefore fault-tolerant implementation of all gates required for universal quantum computation. Code switching addresses this limitation by moving quantum information between different codes that, together, support a universal gate set. Unfortunately, each switch is costly-adding time and space overhead and increasing the logical error rate. Minimizing the number of switching operations is, therefore, essential for quantum computations using code switching. In this work, we study the problem of minimizing the number of code switches required to run a given quantum circuit. We show that this problem can be solved efficiently in polynomial time by reducing it to a minimum-cut instance on a graph derived from the circuit. Our formulation is flexible and can incorporate additional considerations, such as reducing depth overhead by preferring switches during idle periods or biasing the compilation to favor one code over another. To the best of our knowledge, this is the first automated approach for compiling and optimizing code-switching-based quantum computations at the logical level.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04170v1">üìÑ Download PDF</a></p><hr><h3 id=encompass-enhancing-agent-programming-with-search-over-program-execution-pathshttpsarxivorgabs251203571v1><a href=https://arxiv.org/abs/2512.03571v1>EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths</a><a hidden class=anchor aria-hidden=true href=#encompass-enhancing-agent-programming-with-search-over-program-execution-pathshttpsarxivorgabs251203571v1>#</a></h3><p><strong>Authors:</strong> Zhening Li, Armando Solar-Lezama, Yisong Yue, Stephan Zheng
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce &ldquo;probabilistic angelic nondeterminism&rdquo; (&ldquo;PAN&rdquo;), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03571v1">üìÑ Download PDF</a></p><hr><h3 id=modeling-topics-and-sociolinguistic-variation-in-code-switched-discourse-insights-from-spanish-english-and-spanish-guaran√≠httpsarxivorgabs251203334v1><a href=https://arxiv.org/abs/2512.03334v1>Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaran√≠</a><a hidden class=anchor aria-hidden=true href=#modeling-topics-and-sociolinguistic-variation-in-code-switched-discourse-insights-from-spanish-english-and-spanish-guaran√≠httpsarxivorgabs251203334v1>#</a></h3><p><strong>Authors:</strong> Nemika Tyagi, Nelvin Licona Guevara, Olga Kellert
<strong>Venue:</strong> arXiv (2025)</p><p>This study presents an LLM-assisted annotation pipeline for the sociolinguistic and topical analysis of bilingual discourse in two typologically distinct contexts: Spanish-English and Spanish-Guaran√≠. Using large language models, we automatically labeled topic, genre, and discourse-pragmatic functions across a total of 3,691 code-switched sentences, integrated demographic metadata from the Miami Bilingual Corpus, and enriched the Spanish-Guaran√≠ dataset with new topic annotations. The resulting distributions reveal systematic links between gender, language dominance, and discourse function in the Miami data, and a clear diglossic division between formal Guaran√≠ and informal Spanish in Paraguayan texts. These findings replicate and extend earlier interactional and sociolinguistic observations with corpus-scale quantitative evidence. The study demonstrates that large language models can reliably recover interpretable sociolinguistic patterns traditionally accessible only through manual annotation, advancing computational methods for cross-linguistic and low-resource bilingual research.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03334v1">üìÑ Download PDF</a></p><hr><h3 id=knowing-your-uncertainty----on-the-application-of-llm-in-social-scienceshttpsarxivorgabs251205461v1><a href=https://arxiv.org/abs/2512.05461v1>Knowing Your Uncertainty &ndash; On the application of LLM in social sciences</a><a hidden class=anchor aria-hidden=true href=#knowing-your-uncertainty----on-the-application-of-llm-in-social-scienceshttpsarxivorgabs251205461v1>#</a></h3><p><strong>Authors:</strong> Bolun Zhang, Linzhuo Li, Yunqi Chen, Qinlin Zhao, Zihan Zhu, Xiaoyuan Yi, Xing Xie
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) are rapidly being integrated into computational social science research, yet their blackboxed training and designed stochastic elements in inference pose unique challenges for scientific inquiry. This article argues that applying LLMs to social scientific tasks requires explicit assessment of uncertainty-an expectation long established in both quantitative methodology in the social sciences and machine learning. We introduce a unified framework for evaluating LLM uncertainty along two dimensions: the task type (T), which distinguishes between classification, short-form, and long-form generation, and the validation type (V), which captures the availability of reference data or evaluative criteria. Drawing from both computer science and social science literature, we map existing uncertainty quantification (UQ) methods to this T-V typology and offer practical recommendations for researchers. Our framework provides both a methodological safeguard and a practical guide for integrating LLMs into rigorous social science research.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05461v1">üìÑ Download PDF</a></p><hr><h3 id=enhancing-retrieval-augmented-generation-with-entity-linking-for-educational-platformshttpsarxivorgabs251205967v1><a href=https://arxiv.org/abs/2512.05967v1>Enhancing Retrieval-Augmented Generation with Entity Linking for Educational Platforms</a><a hidden class=anchor aria-hidden=true href=#enhancing-retrieval-augmented-generation-with-entity-linking-for-educational-platformshttpsarxivorgabs251205967v1>#</a></h3><p><strong>Authors:</strong> Francesco Granata, Francesco Poggi, Misael Mongiov√¨
<strong>Venue:</strong> arXiv (2025)</p><p>In the era of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) architectures are gaining significant attention for their ability to ground language generation in reliable knowledge sources. Despite their impressive effectiveness in many areas, RAG systems based solely on semantic similarity often fail to ensure factual accuracy in specialized domains, where terminological ambiguity can affect retrieval relevance. This study proposes an enhanced RAG architecture that integrates a factual signal derived from Entity Linking to improve the accuracy of educational question-answering systems in Italian. The system includes a Wikidata-based Entity Linking module and implements three re-ranking strategies to combine semantic and entity-based information: a hybrid score weighting model, reciprocal rank fusion, and a cross-encoder re-ranker. Experiments were conducted on two benchmarks: a custom academic dataset and the standard SQuAD-it dataset. Results show that, in domain-specific contexts, the hybrid schema based on reciprocal rank fusion significantly outperforms both the baseline and the cross-encoder approach, while the cross-encoder achieves the best results on the general-domain dataset. These findings confirm the presence of an effect of domain mismatch and highlight the importance of domain adaptation and hybrid ranking strategies to enhance factual precision and reliability in retrieval-augmented generation. They also demonstrate the potential of entity-aware RAG systems in educational environments, fostering adaptive and reliable AI-based tutoring tools.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05967v1">üìÑ Download PDF</a></p><hr><h3 id=training-time-action-conditioning-for-efficient-real-time-chunkinghttpsarxivorgabs251205964v1><a href=https://arxiv.org/abs/2512.05964v1>Training-Time Action Conditioning for Efficient Real-Time Chunking</a><a hidden class=anchor aria-hidden=true href=#training-time-action-conditioning-for-efficient-real-time-chunkinghttpsarxivorgabs251205964v1>#</a></h3><p><strong>Authors:</strong> Kevin Black, Allen Z. Ren, Michael Equi, Sergey Levine
<strong>Venue:</strong> arXiv (2025)</p><p>Real-time chunking (RTC) enables vision-language-action models (VLAs) to generate smooth, reactive robot trajectories by asynchronously predicting action chunks and conditioning on previously committed actions via inference-time inpainting. However, this inpainting method introduces computational overhead that increases inference latency. In this work, we propose a simple alternative: simulating inference delay at training time and conditioning on action prefixes directly, eliminating any inference-time overhead. Our method requires no modifications to the model architecture or robot runtime, and can be implemented with only a few additional lines of code. In simulated experiments, we find that training-time RTC outperforms inference-time RTC at higher inference delays. In real-world experiments on box building and espresso making tasks with the $œÄ_{0.6}$ VLA, we demonstrate that training-time RTC maintains both task performance and speed parity with inference-time RTC while being computationally cheaper. Our results suggest that training-time action conditioning is a practical drop-in replacement for inference-time inpainting in real-time robot control.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05964v1">üìÑ Download PDF</a></p><hr><h3 id=maxshapley-towards-incentive-compatible-generative-search-with-fair-context-attributionhttpsarxivorgabs251205958v1><a href=https://arxiv.org/abs/2512.05958v1>MaxShapley: Towards Incentive-compatible Generative Search with Fair Context Attribution</a><a hidden class=anchor aria-hidden=true href=#maxshapley-towards-incentive-compatible-generative-search-with-fair-context-attributionhttpsarxivorgabs251205958v1>#</a></h3><p><strong>Authors:</strong> Sara Patel, Mingxun Zhou, Giulia Fanti
<strong>Venue:</strong> arXiv (2025)</p><p>Generative search engines based on large language models (LLMs) are replacing traditional search, fundamentally changing how information providers are compensated. To sustain this ecosystem, we need fair mechanisms to attribute and compensate content providers based on their contributions to generated answers. We introduce MaxShapley, an efficient algorithm for fair attribution in generative search pipelines that use retrieval-augmented generation (RAG). MaxShapley is a special case of the celebrated Shapley value; it leverages a decomposable max-sum utility function to compute attributions with linear computation in the number of documents, as opposed to the exponential cost of Shapley values. We evaluate MaxShapley on three multi-hop QA datasets (HotPotQA, MuSiQUE, MS MARCO); MaxShapley achieves comparable attribution quality to exact Shapley computation, while consuming a fraction of its tokens&ndash;for instance, it gives up to an 8x reduction in resource consumption over prior state-of-the-art methods at the same attribution accuracy.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05958v1">üìÑ Download PDF</a></p><hr><h3 id=simpact-simulation-enabled-action-planning-using-vision-language-modelshttpsarxivorgabs251205955v1><a href=https://arxiv.org/abs/2512.05955v1>SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models</a><a hidden class=anchor aria-hidden=true href=#simpact-simulation-enabled-action-planning-using-vision-language-modelshttpsarxivorgabs251205955v1>#</a></h3><p><strong>Authors:</strong> Haowen Liu, Shaoxiong Yao, Haonan Chen, Jiawei Gao, Jiayuan Mao, Jia-Bin Huang, Yilun Du
<strong>Venue:</strong> arXiv (2025)</p><p>Vision-Language Models (VLMs) exhibit remarkable common-sense and semantic reasoning capabilities. However, they lack a grounded understanding of physical dynamics. This limitation arises from training VLMs on static internet-scale visual-language data that contain no causal interactions or action-conditioned changes. Consequently, it remains challenging to leverage VLMs for fine-grained robotic manipulation tasks that require physical understanding, reasoning, and corresponding action planning. To overcome this, we present SIMPACT, a test-time, SIMulation-enabled ACTion Planning framework that equips VLMs with physical reasoning through simulation-in-the-loop world modeling, without requiring any additional training. From a single RGB-D observation, SIMPACT efficiently constructs physics simulations, enabling the VLM to propose informed actions, observe simulated rollouts, and iteratively refine its reasoning. By integrating language reasoning with physics prediction, our simulation-enabled VLM can understand contact dynamics and action outcomes in a physically grounded way. Our method demonstrates state-of-the-art performance on five challenging, real-world rigid-body and deformable manipulation tasks that require fine-grained physical reasoning, outperforming existing general-purpose robotic manipulation models. Our results demonstrate that embedding physics understanding via efficient simulation into VLM reasoning at test time offers a promising path towards generalizable embodied intelligence. Project webpage can be found at <a href=https://simpact-bot.github.io>https://simpact-bot.github.io</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05955v1">üìÑ Download PDF</a></p><hr><h3 id=sympybench-a-dynamic-benchmark-for-scientific-reasoning-with-executable-python-codehttpsarxivorgabs251205954v1><a href=https://arxiv.org/abs/2512.05954v1>SymPyBench: A Dynamic Benchmark for Scientific Reasoning with Executable Python Code</a><a hidden class=anchor aria-hidden=true href=#sympybench-a-dynamic-benchmark-for-scientific-reasoning-with-executable-python-codehttpsarxivorgabs251205954v1>#</a></h3><p><strong>Authors:</strong> Shima Imani, Seungwhan Moon, Adel Ahmadyan, Lu Zhang, Kirmani Ahmed, Babak Damavandi
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce, a large-scale synthetic benchmark of 15,045 university-level physics problems (90/10% train/test split). Each problem is fully parameterized, supporting an effectively infinite range of input configurations, and is accompanied by structured, step-by-step reasoning and executable Python code that produces the ground-truth solution for any parameter set. The benchmark contains three question types: MC-Symbolic (multiple-choice with symbolic options), MC-Numerical (multiple-choice with numerical options), and free-form (open-ended responses). These diverse formats test complementary reasoning skills. By leveraging the dynamic, code-driven nature of the benchmark, we introduce three novel evaluation metrics in addition to standard accuracy: Consistency Score, Failure Rate, and Confusion Rate, that quantify variability and uncertainty across problem variants. Experiments with state-of-the-art instruction-tuned language models reveal both strengths and limitations in scientific reasoning, positioning SymPyBench as a foundation for developing more robust and interpretable reasoning systems</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05954v1">üìÑ Download PDF</a></p><hr><h3 id=thermodynamics-of-shear-equilibration-during-magnetic-reconnection-onset-in-mixed-equilibrium-current-sheetshttpsarxivorgabs251205921v1><a href=https://arxiv.org/abs/2512.05921v1>Thermodynamics of Shear Equilibration During Magnetic Reconnection Onset in Mixed-Equilibrium Current Sheets</a><a hidden class=anchor aria-hidden=true href=#thermodynamics-of-shear-equilibration-during-magnetic-reconnection-onset-in-mixed-equilibrium-current-sheetshttpsarxivorgabs251205921v1>#</a></h3><p><strong>Authors:</strong> Dominic Payne, Marc Swisdak, James Drake, Tak Chu Li
<strong>Venue:</strong> arXiv (2025)</p><p>Magnetic shear across the polarity inversion line (PIL) plays an important role in the explosive nature of reconnection onset and in the equilibration of current sheets, acting as a source of free energy that can enhance or inhibit the onset process under certain conditions. In this study, we use a 2D PIC simulation to examine the local interaction between the reconnection guide field and thermodynamic variables during reconnection onset in a region of initially depleted thermal energy and enhanced magnetic energy in a large guide field background. We identify critical stages of the equilibration process, characterize intervals based on whether the pressure evolution is driven by changes in density or temperature, and discuss what these intervals imply about the evolution of local heat and work density. Finally, we examine power densities associated with electromagnetic field time evolution and electromagnetic energy transfer and compare to those related to thermodynamic changes.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05921v1">üìÑ Download PDF</a></p><hr><h3 id=scail-towards-studio-grade-character-animation-via-in-context-learning-of-3d-consistent-pose-representationshttpsarxivorgabs251205905v1><a href=https://arxiv.org/abs/2512.05905v1>SCAIL: Towards Studio-Grade Character Animation via In-Context Learning of 3D-Consistent Pose Representations</a><a hidden class=anchor aria-hidden=true href=#scail-towards-studio-grade-character-animation-via-in-context-learning-of-3d-consistent-pose-representationshttpsarxivorgabs251205905v1>#</a></h3><p><strong>Authors:</strong> Wenhao Yan, Sheng Ye, Zhuoyi Yang, Jiayan Teng, ZhenHui Dong, Kairui Wen, Xiaotao Gu, Yong-Jin Liu, Jie Tang
<strong>Venue:</strong> arXiv (2025)</p><p>Achieving character animation that meets studio-grade production standards remains challenging despite recent progress. Existing approaches can transfer motion from a driving video to a reference image, but often fail to preserve structural fidelity and temporal consistency in wild scenarios involving complex motion and cross-identity animations. In this work, we present \textbf{SCAIL} (\textbf{S}tudio-grade \textbf{C}haracter \textbf{A}nimation via \textbf{I}n-context \textbf{L}earning), a framework designed to address these challenges from two key innovations. First, we propose a novel 3D pose representation, providing a more robust and flexible motion signal. Second, we introduce a full-context pose injection mechanism within a diffusion-transformer architecture, enabling effective spatio-temporal reasoning over full motion sequences. To align with studio-level requirements, we develop a curated data pipeline ensuring both diversity and quality, and establish a comprehensive benchmark for systematic evaluation. Experiments show that \textbf{SCAIL} achieves state-of-the-art performance and advances character animation toward studio-grade reliability and realism.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05905v1">üìÑ Download PDF</a></p><hr><h3 id=interplay-of-ferroelectricity-and-interlayer-superconductivity-in-van-der-waals-bilayershttpsarxivorgabs251205871v1><a href=https://arxiv.org/abs/2512.05871v1>Interplay of ferroelectricity and interlayer superconductivity in van der Waals bilayers</a><a hidden class=anchor aria-hidden=true href=#interplay-of-ferroelectricity-and-interlayer-superconductivity-in-van-der-waals-bilayershttpsarxivorgabs251205871v1>#</a></h3><p><strong>Authors:</strong> D. S. Annenkov, A. A. Kopasov, A. S. Mel&rsquo;nikov
<strong>Venue:</strong> arXiv (2025)</p><p>We study the distinctive features of the interplay between the interlayer superconductivity and ferroelectricity in van der Waals heterostructures. Corresponding analysis is carried out within the framework of the quasiclassical Eilenberger equations for a tunnel coupled bilayer with inhomogeneous relative shift of the conduction bands between the layers, which describes the net charge transfer in sliding ferroelectrics. It is shown that the critical temperature of the interlayer superconductivity can be significantly enhanced for superconducting nuclei localized in the vicinity of ferroelectric domain walls. We demonstrate that the increase in the tunneling amplitude leads to the decrease (increase) in the difference between the critical temperatures for localized and homogeneous superconducting states for the spin-singlet (spin-triplet) interlayer superconductivity. We also perform an extensive analysis of the effects of the in-plane magnetic field on the interlayer superconductivity. It is shown that the orbital effect can result in the suppression of the spin-singlet interlayer superconductivity and to the enhancement of the spin-triplet one. We find that possible manifestations of the paramagnetic effect include the suppression of the interlayer superconductivity by rather weak Zeeman fields, the two-fold anisotropy of the critical magnetic field for the spin-triplet states as well as the appearance of the reentrant superconducting phases. It is shown that the joint influence of the orbital and paramagnetic mechanisms on the spin-triplet interlayer superconductivity can even lead to a nonmonotonic behavior of the superconducting critical temperature as a function of the external magnetic field. The obtained results are discussed in the context of recent experimental data on van der Waals structures with coexisting superconductivity and sliding ferroelectricity.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05871v1">üìÑ Download PDF</a></p><hr><h3 id=phase-otdr-event-detection-using-image-based-data-transformation-and-deep-learninghttpsarxivorgabs251205830v1><a href=https://arxiv.org/abs/2512.05830v1>Phase-OTDR Event Detection Using Image-Based Data Transformation and Deep Learning</a><a hidden class=anchor aria-hidden=true href=#phase-otdr-event-detection-using-image-based-data-transformation-and-deep-learninghttpsarxivorgabs251205830v1>#</a></h3><p><strong>Authors:</strong> Muhammet Cagri Yeke, Samil Sirin, Kivilcim Yuksel, Abdurrahman Gumus
<strong>Venue:</strong> arXiv (2025)</p><p>This study focuses on event detection in optical fibers, specifically classifying six events using the Phase-OTDR system. A novel approach is introduced to enhance Phase-OTDR data analysis by transforming 1D data into grayscale images through techniques such as Gramian Angular Difference Field, Gramian Angular Summation Field, and Recurrence Plot. These grayscale images are combined into a multi-channel RGB representation, enabling more robust and adaptable analysis using transfer learning models. The proposed methodology achieves high classification accuracies of 98.84% and 98.24% with the EfficientNetB0 and DenseNet121 models, respectively. A 5-fold cross-validation process confirms the reliability of these models, with test accuracy rates of 99.07% and 98.68%. Using a publicly available Phase-OTDR dataset, the study demonstrates an efficient approach to understanding optical fiber events while reducing dataset size and improving analysis efficiency. The results highlight the transformative potential of image-based analysis in interpreting complex fiber optic sensing data, offering significant advancements in the accuracy and reliability of fiber optic monitoring systems. The codes and the corresponding image-based dataset are made publicly available on GitHub to support further research: <a href=https://github.com/miralab-ai/Phase-OTDR-event-detection>https://github.com/miralab-ai/Phase-OTDR-event-detection</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05830v1">üìÑ Download PDF</a></p><hr><h3 id=higher-order-diffusion-and-cahn-hilliard-type-models-revisited-on-the-half-linehttpsarxivorgabs251205829v1><a href=https://arxiv.org/abs/2512.05829v1>Higher-order diffusion and Cahn-Hilliard-type models revisited on the half-line</a><a hidden class=anchor aria-hidden=true href=#higher-order-diffusion-and-cahn-hilliard-type-models-revisited-on-the-half-linehttpsarxivorgabs251205829v1>#</a></h3><p><strong>Authors:</strong> A. Chatziafratis, A. Miranville, G. Karali, A. S. Fokas, E. C. Aifantis
<strong>Venue:</strong> arXiv (2025)</p><p>In this paper, we solve explicitly and analyze rigorously inhomogeneous initial-boundary-value problems (IBVP) for several fourth-order variations of the traditional diffusion equation and the associated linearized Cahn-Hilliard (C-H) model (also Kuramoto-Sivashinsky equation), formulated in the spatiotemporal quarter-plane. Such models are of relevance to heat-mass transfer phenomena, solid-fluid dynamics and the applied sciences. In particular, we derive formally effective solution representations, justifying a posteriori their validity. This includes the reconstruction of the prescribed initial and boundary data, which requires careful analysis of the various integral terms appearing in the formulae, proving that they converge in a strictly defined sense. In each IBVP, the novel formula is utilized to rigorously deduce the solution&rsquo;s regularity and asymptotic properties near the boundaries of the domain, including uniform convergence, eventual (long-time) periodicity under (eventually) periodic boundary conditions, and null non-controllability. Importantly, this analysis is indispensable for exploring the (non)uniqueness of the problem&rsquo;s solution and a new counter-example is constructed. Our work is based on the synergy between: (i) the well-known Fokas unified transform method and (ii) a new approach recently introduced for the rigorous analysis of the Fokas method and for investigating qualitative properties of linear evolution partial differential equations (PDE) on semi-infinite strips. Since only up to third-order evolution PDE have been investigated within this novel framework to date, we present our analysis and results in an illustrative manner and in order of progressively greater complexity, for the convenience of readers. The solution formulae established herein are expected to find utility in well-posedness studies for nonlinear counterparts too.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05829v1">üìÑ Download PDF</a></p><hr><h3 id=himoe-vla-hierarchical-mixture-of-experts-for-generalist-vision-language-action-policieshttpsarxivorgabs251205693v1><a href=https://arxiv.org/abs/2512.05693v1>HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies</a><a hidden class=anchor aria-hidden=true href=#himoe-vla-hierarchical-mixture-of-experts-for-generalist-vision-language-action-policieshttpsarxivorgabs251205693v1>#</a></h3><p><strong>Authors:</strong> Zhiying Du, Bei Liu, Yaobo Liang, Yichao Shen, Haidong Cao, Xiangyu Zheng, Zhiyuan Feng, Zuxuan Wu, Jiaolong Yang, Yu-Gang Jiang
<strong>Venue:</strong> arXiv (2025)</p><p>The development of foundation models for embodied intelligence critically depends on access to large-scale, high-quality robot demonstration data. Recent approaches have sought to address this challenge by training on large collections of heterogeneous robotic datasets. However, unlike vision or language data, robotic demonstrations exhibit substantial heterogeneity across embodiments and action spaces as well as other prominent variations such as senor configurations and action control frequencies. The lack of explicit designs for handling such heterogeneity causes existing methods to struggle with integrating diverse factors, thereby limiting their generalization and leading to degraded performance when transferred to new settings. In this paper, we present HiMoE-VLA, a novel vision-language-action (VLA) framework tailored to effectively handle diverse robotic data with heterogeneity. Specifically, we introduce a Hierarchical Mixture-of-Experts (HiMoE) architecture for the action module which adaptively handles multiple sources of heterogeneity across layers and gradually abstracts them into shared knowledge representations. Through extensive experimentation with simulation benchmarks and real-world robotic platforms, HiMoE-VLA demonstrates a consistent performance boost over existing VLA baselines, achieving higher accuracy and robust generalization across diverse robots and action spaces. The code and models are publicly available at <a href=https://github.com/ZhiyingDu/HiMoE-VLA>https://github.com/ZhiyingDu/HiMoE-VLA</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05693v1">üìÑ Download PDF</a></p><hr><h3 id=editthinker-unlocking-iterative-reasoning-for-any-image-editorhttpsarxivorgabs251205965v1><a href=https://arxiv.org/abs/2512.05965v1>EditThinker: Unlocking Iterative Reasoning for Any Image Editor</a><a hidden class=anchor aria-hidden=true href=#editthinker-unlocking-iterative-reasoning-for-any-image-editorhttpsarxivorgabs251205965v1>#</a></h3><p><strong>Authors:</strong> Hongyu Li, Manyuan Zhang, Dian Zheng, Ziyu Guo, Yimeng Jia, Kaituo Feng, Hao Yu, Yexin Liu, Yan Feng, Peng Pei, Xunliang Cai, Linjiang Huang, Hongsheng Li, Si Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Instruction-based image editing has emerged as a prominent research area, which, benefiting from image generation foundation models, have achieved high aesthetic quality, making instruction-following capability the primary challenge. Existing approaches improve instruction adherence via supervised or reinforcement learning, yet single-turn success rates remain limited due to inherent stochasticity and a lack of deliberation. In this work, we propose a deliberative editing framework to &rsquo;think&rsquo; while they edit, which simulates the human cognitive loop by iteratively executing a Think-while-Edit cycle: Critiquing results and Refining instructions , followed by Repeating the generation until satisfactory. Specifically, we train a single MLLM, EditThinker, to act as the reasoning engine of this framework, which jointly produce the critique score, reasoning process, and refined instructions. We employ reinforcement learning to align the EditThinker&rsquo;s thinking with its editing, thereby generating more targeted instruction improvements. Extensive experiments on four benchmarks demonstrate that our approach significantly improves the instruction-following capability of any image editing model by a large margin. We will release our data construction framework, datasets, and models to benefit the community.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05965v1">üìÑ Download PDF</a></p><hr><h3 id=variational-quantum-rainbow-deep-q-network-for-optimizing-resource-allocation-problemhttpsarxivorgabs251205946v1><a href=https://arxiv.org/abs/2512.05946v1>Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem</a><a hidden class=anchor aria-hidden=true href=#variational-quantum-rainbow-deep-q-network-for-optimizing-resource-allocation-problemhttpsarxivorgabs251205946v1>#</a></h3><p><strong>Authors:</strong> Truong Thanh Hung Nguyen, Truong Thinh Nguyen, Hung Cao
<strong>Venue:</strong> arXiv (2025)</p><p>Resource allocation remains NP-hard due to combinatorial complexity. While deep reinforcement learning (DRL) methods, such as the Rainbow Deep Q-Network (DQN), improve scalability through prioritized replay and distributional heads, classical function approximators limit their representational power. We introduce Variational Quantum Rainbow DQN (VQR-DQN), which integrates ring-topology variational quantum circuits with Rainbow DQN to leverage quantum superposition and entanglement. We frame the human resource allocation problem (HRAP) as a Markov decision process (MDP) with combinatorial action spaces based on officer capabilities, event schedules, and transition times. On four HRAP benchmarks, VQR-DQN achieves 26.8% normalized makespan reduction versus random baselines and outperforms Double DQN and classical Rainbow DQN by 4.9-13.4%. These gains align with theoretical connections between circuit expressibility, entanglement, and policy quality, demonstrating the potential of quantum-enhanced DRL for large-scale resource allocation. Our implementation is available at: <a href=https://github.com/Analytics-Everywhere-Lab/qtrl/>https://github.com/Analytics-Everywhere-Lab/qtrl/</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05946v1">üìÑ Download PDF</a></p><hr><h3 id=qualitative-and-quantitative-analysis-of-riemannian-optimization-methods-for-ground-states-of-rotating-multicomponent-bose-einstein-condensateshttpsarxivorgabs251205939v1><a href=https://arxiv.org/abs/2512.05939v1>Qualitative and Quantitative Analysis of Riemannian Optimization Methods for Ground States of Rotating Multicomponent Bose-Einstein Condensates</a><a hidden class=anchor aria-hidden=true href=#qualitative-and-quantitative-analysis-of-riemannian-optimization-methods-for-ground-states-of-rotating-multicomponent-bose-einstein-condensateshttpsarxivorgabs251205939v1>#</a></h3><p><strong>Authors:</strong> Martin Hermann, Tatjana Stykel, Mahima Yadav
<strong>Venue:</strong> arXiv (2025)</p><p>We develop and analyze Riemannian optimization methods for computing ground states of rotating multicomponent Bose-Einstein condensates, defined as minimizers of the Gross-Pitaevskii energy functional. To resolve the non-uniqueness of ground states induced by phase invariance, we work on a quotient manifold endowed with a general Riemannian metric. By introducing an auxiliary phase-aligned iteration and employing fixed-point convergence theory, we establish a unified local convergence framework for Riemannian gradient descent methods and derive explicit convergence rates. Specializing this framework to two metrics tailored to the energy landscape, we study the energy-adaptive and Lagrangian-based Riemannian gradient descent methods. While monotone energy decay and global convergence are established only for the former, a quantified local convergence analysis is provided for both methods. Numerical experiments confirm the theoretical results and demonstrate that the Lagrangian-based method, which incorporates second-order information on the energy functional and mass constraints, achieves faster local convergence than the energy-adaptive scheme.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05939v1">üìÑ Download PDF</a></p><hr><h3 id=physically-based-simulation-of-automotive-lidarhttpsarxivorgabs251205932v1><a href=https://arxiv.org/abs/2512.05932v1>Physically-Based Simulation of Automotive LiDAR</a><a hidden class=anchor aria-hidden=true href=#physically-based-simulation-of-automotive-lidarhttpsarxivorgabs251205932v1>#</a></h3><p><strong>Authors:</strong> L. Dudzik, M. Roschani, A. Sielemann, K. Trampert, J. Ziehn, J. Beyerer, C. Neumann
<strong>Venue:</strong> arXiv (2025)</p><p>We present an analytic model for simulating automotive time-of-flight (ToF) LiDAR that includes blooming, echo pulse width, and ambient light, along with steps to determine model parameters systematically through optical laboratory measurements. The model uses physically based rendering (PBR) in the near-infrared domain. It assumes single-bounce reflections and retroreflections over rasterized rendered images from shading or ray tracing, including light emitted from the sensor as well as stray light from other, non-correlated sources such as sunlight. Beams from the sensor and sensitivity of the receiving diodes are modeled with flexible beam steering patterns and with non-vanishing diameter.
Different (all non-real time) computational approaches can be chosen based on system properties, computing capabilities, and desired output properties.
Model parameters include system-specific properties, namely the physical spread of the LiDAR beam, combined with the sensitivity of the receiving diode; the intensity of the emitted light; the conversion between the intensity of reflected light and the echo pulse width; and scenario parameters such as environment lighting, positioning, and surface properties of the target(s) in the relevant infrared domain. System-specific properties of the model are determined from laboratory measurements of the photometric luminance on different target surfaces aligned with a goniometer at 0.01¬∞ resolution, which marks the best available resolution for measuring the beam pattern.
The approach is calibrated for and tested on two automotive LiDAR systems, the Valeo Scala Gen. 2 and the Blickfeld Cube 1. Both systems differ notably in their properties and available interfaces, but the relevant model parameters could be extracted successfully.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05932v1">üìÑ Download PDF</a></p><hr><h3 id=natural-language-summarization-enables-multi-repository-bug-localization-by-llms-in-microservice-architectureshttpsarxivorgabs251205908v1><a href=https://arxiv.org/abs/2512.05908v1>Natural Language Summarization Enables Multi-Repository Bug Localization by LLMs in Microservice Architectures</a><a hidden class=anchor aria-hidden=true href=#natural-language-summarization-enables-multi-repository-bug-localization-by-llms-in-microservice-architectureshttpsarxivorgabs251205908v1>#</a></h3><p><strong>Authors:</strong> Amirkia Rafiei Oskooei, S. Selcan Yukcu, Mehmet Cevheri Bozoglan, Mehmet S. Aktas
<strong>Venue:</strong> arXiv (2025)</p><p>Bug localization in multi-repository microservice architectures is challenging due to the semantic gap between natural language bug reports and code, LLM context limitations, and the need to first identify the correct repository. We propose reframing this as a natural language reasoning task by transforming codebases into hierarchical NL summaries and performing NL-to-NL search instead of cross-modal retrieval. Our approach builds context-aware summaries at file, directory, and repository levels, then uses a two-phase search: first routing bug reports to relevant repositories, then performing top-down localization within those repositories. Evaluated on DNext, an industrial system with 46 repositories and 1.1M lines of code, our method achieves Pass@10 of 0.82 and MRR of 0.50, significantly outperforming retrieval baselines and agentic RAG systems like GitHub Copilot and Cursor. This work demonstrates that engineered natural language representations can be more effective than raw source code for scalable bug localization, providing an interpretable repository -> directory -> file search path, which is vital for building trust in enterprise AI tools by providing essential transparency.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05908v1">üìÑ Download PDF</a></p><hr><h3 id=from-text-to-returns-using-large-language-models-for-mutual-fund-portfolio-optimization-and-risk-adjusted-allocationhttpsarxivorgabs251205907v1><a href=https://arxiv.org/abs/2512.05907v1>From Text to Returns: Using Large Language Models for Mutual Fund Portfolio Optimization and Risk-Adjusted Allocation</a><a hidden class=anchor aria-hidden=true href=#from-text-to-returns-using-large-language-models-for-mutual-fund-portfolio-optimization-and-risk-adjusted-allocationhttpsarxivorgabs251205907v1>#</a></h3><p><strong>Authors:</strong> Abrar Hossain Mufakir Qamar Ansari Haziq Jeelani Monia Digra Fayeq Jeelani Syed
<strong>Venue:</strong> arXiv (2025)</p><p>Generative AI (GenAI) has enormous potential for improving two critical areas in investing, namely portfolio optimization (choosing the best combination of assets) and risk management (protecting those investments). Our study works at this intersection, using Large Language Models (LLMs) to upgrade how financial decisions are traditionally made. This research specifically tested how well advanced LLMs like Microsoft Phi 2, Mistral 7B, and Zypher 7B can create practical, risk-aware strategies for investing mutual funds in different sectors of the economy. Our method is sophisticated: it combines a Retrieval-Augmented Generation (RAG) pipeline, which enables the LLM to check external, real-time data with standard financial optimization methods. The model&rsquo;s advice is context-aware because we feed it large economic signals, like changes in the global economy. The Zypher 7B model was the clear winner. It consistently produced strategies that maximized investment returns while delivering better risk-adjusted results than the other models. Its ability to process complex relationships and contextual information makes it a highly powerful tool for financial allocation. In conclusion, our findings show that GenAI substantially improves performance over basic allocation methods. By connecting GenAI to real-world financial applications, this work lays the groundwork for creating smarter, more efficient, and more adaptable solutions for asset management professionals.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05907v1">üìÑ Download PDF</a></p><hr><h3 id=asteroseismology-of-spb-stars-a-comparison-of-forward-asteroseismic-modelling-results-from-kepler-and-tesshttpsarxivorgabs251205864v1><a href=https://arxiv.org/abs/2512.05864v1>Asteroseismology of SPB stars: a comparison of forward asteroseismic modelling results from Kepler and TESS</a><a hidden class=anchor aria-hidden=true href=#asteroseismology-of-spb-stars-a-comparison-of-forward-asteroseismic-modelling-results-from-kepler-and-tesshttpsarxivorgabs251205864v1>#</a></h3><p><strong>Authors:</strong> L. J. A. Scott, D. M. Bowman
<strong>Venue:</strong> arXiv (2025)</p><p>The slowly pulsating B (SPB) stars are a class of variable star with masses between about 3 and 8 M$_{\odot}$. Their gravity-mode pulsation frequencies are sensitive to the near-core structure, which makes them useful probes of rotation and mixing in the deep stellar interior. Time series photometry, such as from the Kepler and TESS space telescopes, allows the extraction of their pulsation frequencies and construction of period spacing patterns. Previously, samples of slowly pulsating B stars were observed by the Kepler mission and underwent forward asteroseismic modelling to retrieve stellar parameters such as mass, age and core mass. However, all of these stars have since been re-observed by the ongoing TESS mission with light curves that are usually shorter and non-continuous, resulting in more difficult frequency extraction and interpretation in terms of constructing period spacing patterns. In this paper we compare the results of forward asteroseismic modelling of a sample of SPB stars using intermittent TESS light curve data to those based on long-duration Kepler light curves. We show how in some cases that the masses and core masses derived from only a few sectors of TESS data agree well with the 4-yr Kepler mission results, despite the stars having far fewer significant pulsation frequencies in their TESS light curves. However, some stars yield incompatible results, emphasising the complexities in forward asteroseismic modelling of gravity-mode pulsators with sparsely sampled or short duration TESS light curves.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05864v1">üìÑ Download PDF</a></p><hr><h2 id=-linguistics>üîç linguistics<a hidden class=anchor aria-hidden=true href=#-linguistics>#</a></h2><h3 id=aqua-net-adaptive-frequency-fusion-and-illumination-aware-network-for-underwater-image-enhancementhttpsarxivorgabs251205960v1><a href=https://arxiv.org/abs/2512.05960v1>AQUA-Net: Adaptive Frequency Fusion and Illumination Aware Network for Underwater Image Enhancement</a><a hidden class=anchor aria-hidden=true href=#aqua-net-adaptive-frequency-fusion-and-illumination-aware-network-for-underwater-image-enhancementhttpsarxivorgabs251205960v1>#</a></h3><p><strong>Authors:</strong> Munsif Ali, Najmul Hassan, Lucia Ventura, Davide Di Bari, Simonepietro Canese
<strong>Venue:</strong> arXiv (2025)</p><p>Underwater images often suffer from severe color distortion, low contrast, and a hazy appearance due to wavelength-dependent light absorption and scattering. Simultaneously, existing deep learning models exhibit high computational complexity, which limits their practical deployment for real-time underwater applications. To address these challenges, this paper presents a novel underwater image enhancement model, called Adaptive Frequency Fusion and Illumination Aware Network (AQUA-Net). It integrates a residual encoder decoder with dual auxiliary branches, which operate in the frequency and illumination domains. The frequency fusion encoder enriches spatial representations with frequency cues from the Fourier domain and preserves fine textures and structural details. Inspired by Retinex, the illumination-aware decoder performs adaptive exposure correction through a learned illumination map that separates reflectance from lighting effects. This joint spatial, frequency, and illumination design enables the model to restore color balance, visual contrast, and perceptual realism under diverse underwater conditions. Additionally, we present a high-resolution, real-world underwater video-derived dataset from the Mediterranean Sea, which captures challenging deep-sea conditions with realistic visual degradations to enable robust evaluation and development of deep learning models. Extensive experiments on multiple benchmark datasets show that AQUA-Net performs on par with SOTA in both qualitative and quantitative evaluations while using less number of parameters. Ablation studies further confirm that the frequency and illumination branches provide complementary contributions that improve visibility and color representation. Overall, the proposed model shows strong generalization capability and robustness, and it provides an effective solution for real-world underwater imaging applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05960v1">üìÑ Download PDF</a></p><hr><h3 id=spectroscopy-and-coherent-control-of-two-level-system-defect-ensembles-using-a-broadband-3d-waveguidehttpsarxivorgabs251205934v1><a href=https://arxiv.org/abs/2512.05934v1>Spectroscopy and Coherent Control of Two-Level System Defect Ensembles Using a Broadband 3D Waveguide</a><a hidden class=anchor aria-hidden=true href=#spectroscopy-and-coherent-control-of-two-level-system-defect-ensembles-using-a-broadband-3d-waveguidehttpsarxivorgabs251205934v1>#</a></h3><p><strong>Authors:</strong> Qianxu Wang, Juan S. Salcedo-Gallo, Salil Bedkihal, Tian Xia, Maciej W. Olszewski, Valla Fatemi, Mattias Fitzpatrick
<strong>Venue:</strong> arXiv (2025)</p><p>Defects in solid-state materials play a central role in determining coherence, stability, and performance in quantum technologies. Although narrowband techniques can probe specific resonances with high precision, a broadband spectroscopic approach captures the full spectrum of defect properties and dynamics. Two-level system (TLS) defects in amorphous dielectrics are a particularly important example because they are major sources of decoherence and energy loss in superconducting quantum devices. However, accessing and characterizing their collective dynamics remains far more challenging than probing individual TLS defects. Building on our previously developed Broadband Cryogenic Transient Dielectric Spectroscopy (BCTDS) technique, we study the coherent control and time-resolved dynamics of TLS defect ensembles over a wide frequency range of 3-5 GHz without requiring full device fabrication, revealing quantum interference effects, memory-dependent dynamics, and dressed-state evolution within the TLS defect bath. The spectral response reveals distinct V-shaped structures corresponding to the bare eigenmode frequencies. Using these features, we extract a TLS defect spectral density of 84 GHz^-1 for a silicon sample, across a 4.1-4.6 GHz span. Furthermore, we systematically investigate amplitude- and phase-controlled interference fringes for multiple temperatures and inter-pulse delays, providing direct evidence of coherent dynamics and control. A driven minimal spin model with dipole-dipole interactions that qualitatively capture the observed behavior is presented. Our results establish BCTDS as a versatile platform for broadband defect spectroscopy, offering new capabilities for diagnosing and mitigating sources of decoherence, engineering many-body dynamics, and exploring non-equilibrium phenomena in disordered quantum systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05934v1">üìÑ Download PDF</a></p><hr><h3 id=prism-an-agentic-multimodal-benchmark-for-scientific-reasoning-via-python-grounded-evaluationhttpsarxivorgabs251205930v1><a href=https://arxiv.org/abs/2512.05930v1>PRiSM: An Agentic Multimodal Benchmark for Scientific Reasoning via Python-Grounded Evaluation</a><a hidden class=anchor aria-hidden=true href=#prism-an-agentic-multimodal-benchmark-for-scientific-reasoning-via-python-grounded-evaluationhttpsarxivorgabs251205930v1>#</a></h3><p><strong>Authors:</strong> Shima Imani, Seungwhan Moon, Adel Ahmadyan, Lu Zhang, Kirmani Ahmed, Babak Damavandi
<strong>Venue:</strong> arXiv (2025)</p><p>Evaluating vision-language models (VLMs) in scientific domains like mathematics and physics poses unique challenges that go far beyond predicting final answers. These domains demand conceptual understanding, symbolic reasoning, and adherence to formal laws, requirements that most existing benchmarks fail to address. In particular, current datasets tend to be static, lacking intermediate reasoning steps, robustness to variations, or mechanisms for verifying scientific correctness. To address these limitations, we introduce PRiSM, a synthetic, fully dynamic, and multimodal benchmark for evaluating scientific reasoning via grounded Python code. PRiSM includes over 24,750 university-level physics and math problems, and it leverages our scalable agent-based pipeline, PrismAgent, to generate well-structured problem instances. Each problem contains dynamic textual and visual input, a generated figure, alongside rich structured outputs: executable Python code for ground truth generation and verification, and detailed step-by-step reasoning. The dynamic nature and Python-powered automated ground truth generation of our benchmark allow for fine-grained experimental auditing of multimodal VLMs, revealing failure modes, uncertainty behaviors, and limitations in scientific reasoning. To this end, we propose five targeted evaluation tasks covering generalization, symbolic program synthesis, perturbation robustness, reasoning correction, and ambiguity resolution. Through comprehensive evaluation of existing VLMs, we highlight their limitations and showcase how PRiSM enables deeper insights into their scientific reasoning capabilities.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05930v1">üìÑ Download PDF</a></p><hr><h3 id=numerically-reliable-brunovsky-transformationshttpsarxivorgabs251205910v1><a href=https://arxiv.org/abs/2512.05910v1>Numerically Reliable Brunovsky Transformations</a><a hidden class=anchor aria-hidden=true href=#numerically-reliable-brunovsky-transformationshttpsarxivorgabs251205910v1>#</a></h3><p><strong>Authors:</strong> Shaohui Yang, Colin N. Jones
<strong>Venue:</strong> arXiv (2025)</p><p>The Brunovsky canonical form provides sparse structural representations that are beneficial for computational optimal control, yet existing methods fail to compute it reliably. We propose a technique that produces Brunovsky transformations with substantially lower construction errors and improved conditioning. A controllable linear system is first reduced to staircase form via an orthogonal similarity transformation. We then derive a simple linear parametrization of the transformations yielding the unique Brunovsky form. Numerical stability is further enhanced by applying a deadbeat gain before computing system matrix powers and by optimizing the linear parameters to minimize condition numbers.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05910v1">üìÑ Download PDF</a></p><hr><h3 id=learning-the-cosmic-web-graph-based-classification-of-simulated-galaxies-by-their-dark-matter-environmentshttpsarxivorgabs251205909v1><a href=https://arxiv.org/abs/2512.05909v1>Learning the Cosmic Web: Graph-based Classification of Simulated Galaxies by their Dark Matter Environments</a><a hidden class=anchor aria-hidden=true href=#learning-the-cosmic-web-graph-based-classification-of-simulated-galaxies-by-their-dark-matter-environmentshttpsarxivorgabs251205909v1>#</a></h3><p><strong>Authors:</strong> Dakshesh Kololgi, Krishna Naidoo, Amelie Saintonge, Ofer Lahav
<strong>Venue:</strong> arXiv (2025)</p><p>We present a novel graph-based machine learning classifier for identifying the dark matter cosmic web environments of galaxies. Large galaxy surveys offer comprehensive statistical views of how galaxy properties are shaped by large-scale structure, but this requires robust classifications of galaxies&rsquo; cosmic web environments. Using stellar mass-selected IllustrisTNG-300 galaxies, we apply a three-stage, simulation-based framework to link galaxies to the total (mainly dark) underlying matter distribution. Here, we apply the following three steps: First, we assign the positions of simulated galaxies to a void, wall, filament, or cluster environment using the T-Web classification of the underlying matter distribution. Second, we construct a Delaunay triangulation of the galaxy distribution to summarise the local geometric structure with ten graph metrics for each galaxy. Third, we train a graph attention network (GAT) on each galaxy&rsquo;s graph metrics to predict its cosmic web environment. For galaxies with stellar mass $\mathrm{>10^9 M_{\odot}}$, our GAT+ model achieves an accuracy of $85,%$, outperforming graph-agnostic multilayer perceptrons and graph convolutional networks. Our results demonstrate that graph-based representations of galaxy positions provide a powerful and physically meaningful way to infer dark matter environments. We plan to apply this simulation-based graph modelling to investigate how the properties of observed galaxies from the Dark Energy Spectroscopic Instrument (DESI) survey are influenced by their dark matter environments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05909v1">üìÑ Download PDF</a></p><hr><h3 id=lpd-learnable-prototypes-with-diversity-regularization-for-weakly-supervised-histopathology-segmentationhttpsarxivorgabs251205922v1><a href=https://arxiv.org/abs/2512.05922v1>LPD: Learnable Prototypes with Diversity Regularization for Weakly Supervised Histopathology Segmentation</a><a hidden class=anchor aria-hidden=true href=#lpd-learnable-prototypes-with-diversity-regularization-for-weakly-supervised-histopathology-segmentationhttpsarxivorgabs251205922v1>#</a></h3><p><strong>Authors:</strong> Khang Le, Anh Mai Vu, Thi Kim Trang Vo, Ha Thach, Ngoc Bui Lam Quang, Thanh-Huy Nguyen, Minh H. N. Le, Zhu Han, Chandra Mohan, Hien Van Nguyen
<strong>Venue:</strong> arXiv (2025)</p><p>Weakly supervised semantic segmentation (WSSS) in histopathology reduces pixel-level labeling by learning from image-level labels, but it is hindered by inter-class homogeneity, intra-class heterogeneity, and CAM-induced region shrinkage (global pooling-based class activation maps whose activations highlight only the most distinctive areas and miss nearby class regions). Recent works address these challenges by constructing a clustering prototype bank and then refining masks in a separate stage; however, such two-stage pipelines are costly, sensitive to hyperparameters, and decouple prototype discovery from segmentation learning, limiting their effectiveness and efficiency. We propose a cluster-free, one-stage learnable-prototype framework with diversity regularization to enhance morphological intra-class heterogeneity coverage. Our approach achieves state-of-the-art (SOTA) performance on BCSS-WSSS, outperforming prior methods in mIoU and mDice. Qualitative segmentation maps show sharper boundaries and fewer mislabels, and activation heatmaps further reveal that, compared with clustering-based prototypes, our learnable prototypes cover more diverse and complementary regions within each class, providing consistent qualitative evidence for their effectiveness.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05922v1">üìÑ Download PDF</a></p><hr><h3 id=a-redshift-independent-theoretical-halo-mass-function-validated-with-the-uchuu-simulationshttpsarxivorgabs251205847v1><a href=https://arxiv.org/abs/2512.05847v1>A redshift-independent theoretical halo mass function validated with the Uchuu simulations</a><a hidden class=anchor aria-hidden=true href=#a-redshift-independent-theoretical-halo-mass-function-validated-with-the-uchuu-simulationshttpsarxivorgabs251205847v1>#</a></h3><p><strong>Authors:</strong> Elena Fern√°ndez-Garc√≠a, Juan E. Betancort-Rijo, Francisco Prada, Tomoaki Ishiyama, Anatoly Klypin, Jos√© Ruedas
<strong>Venue:</strong> arXiv (2025)</p><p>We present a new theoretical framework for the halo mass function (HMF) that accurately predicts the abundance of dark matter haloes across an exceptionally wide range in mass and redshift. Building on a generalised Press & Schechter model and triaxial collapse (GPS+), we predict the HMF in terms of the variance of the linear density field, with only a weak explicit dependence on halo mass and no explicit dependence on redshift. The GPS+ model naturally provides the correct normalization and high-mass behaviour without requiring empirical fitting. We calibrate and validate the GPS+ model using the Uchuu N-body simulation suite, which combines large cosmological volume and high mass resolution under Planck cosmology. Using six simulations with up to 300 realizations, we obtain precision HMF measurements spanning halo masses in the range 6.5 &lt; log($M_{\rm 200m}$/[h$^{-1}$ $M_{\odot}$]) &lt;16 over 0 &lt; z &lt; 20, with reduced cosmic variance. Across this full domain, the GPS+ model reproduces the simulated HMF with deviations typically below 10-20%. Comparison with the Sheth-Tormen (ST) model shows similar performance at z &lt; 2, but markedly improved agreement at higher redshifts, where ST can deviate by 70-80% while our model remains within ~20%. Finally, we assess the impact of the halo mass definition: adopting the evolving virial overdensity of Bryan & Norman (1998) worsens agreement at low redshift and high masses, whereas M200m yields a more universal, nearly redshift-independent HMF.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05847v1">üìÑ Download PDF</a></p><hr><h3 id=twisting-the-hagedorn-temperature-in-planar-mathcaln4-super-yang-millshttpsarxivorgabs251205810v1><a href=https://arxiv.org/abs/2512.05810v1>Twisting the Hagedorn temperature in planar $\mathcal{N}=4$ super Yang-Mills</a><a hidden class=anchor aria-hidden=true href=#twisting-the-hagedorn-temperature-in-planar-mathcaln4-super-yang-millshttpsarxivorgabs251205810v1>#</a></h3><p><strong>Authors:</strong> Simon Ekhammar, Joseph A. Minahan, Charles Thull
<strong>Venue:</strong> arXiv (2025)</p><p>We consider planar $\mathcal{N}=4$ super Yang-Mills at finite temperature with chemical potentials that couple either to the $R$-charges or the spins of the operators. We find expressions for the Hagedorn temperatures at both zero coupling by explicitly counting states, and at strong coupling using the string theory dual. We then apply the quantum spectral curve (QSC) to this problem, which adds additional twists to the $Q$-functions. For a single chemical potential $Œº$ coupled to one of the $R$-charges, we find the analytic weak-coupling Hagedorn temperature to one-loop order for any value of $Œº$, and to two-loop order for $Œº=1/2$. We then solve the QSC numerically, showing that at strong coupling there is good agreement with the string theory prediction to order $1/Œª^{1/4}$. This provides further evidence for a recent conjecture of Harmark for the form of the world-sheet zero-point shift. We also use the QSC to find the analytic one-loop correction to the Hagedorn temperature with non-zero chemical potentials coupled to the spins.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05810v1">üìÑ Download PDF</a></p><hr><h3 id=size-effects-on-shift-current-in-layered-cuinp_2s_6httpsarxivorgabs251205796v1><a href=https://arxiv.org/abs/2512.05796v1>Size-effects on shift-current in layered CuInP$_2$S$_6$</a><a hidden class=anchor aria-hidden=true href=#size-effects-on-shift-current-in-layered-cuinp_2s_6httpsarxivorgabs251205796v1>#</a></h3><p><strong>Authors:</strong> Francesco Delodovici, Brahim Dkhil, Charles Paillard
<strong>Venue:</strong> arXiv (2025)</p><p>Two-dimensional ferroelectrics have recently emerged as a promising avenue for next-generation optoelectronic and photovoltaic devices. Due to the intrinsic absence of inversion symmetry, 2D ferroelectrics exhibit bulk photovoltaic effect (BPVE), which relies on hot, non-thermalized photo-excited carriers to generate a photo-induced current with enhanced performances thanks to efficient charge separation mechanisms. The absence of a required p-n junction architecture makes these materials particularly attractive for nanoscale energy harvesting. Recent studies have reported enhanced BPVE in nanometer-thick CuInP$_2$S$_6$ ferroelectric embedded between two graphene wafers, driven by relatively strong polarization and reduced dimensionality. Short circuit photocurrent density values have been observed to reach up to mA/cm$^2$. In this paper, we demonstrate that the shift-current mechanism alone cannot fully account for these high conductivity values, suggesting that additional mechanisms may play a significant role. Furthermore, our work confirms the existence of a strong size effect, which drastically reduces the shift-conductivity response in the bulk limit, in agreement with experimental observations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05796v1">üìÑ Download PDF</a></p><hr><h3 id=multi-band-alma-polarization-observations-of-bhb07-11-reveal-aligned-dust-grains-in-complex-spiral-arm-structureshttpsarxivorgabs251205768v1><a href=https://arxiv.org/abs/2512.05768v1>Multi-band ALMA Polarization Observations of BHB07-11 Reveal Aligned Dust Grains in Complex Spiral Arm Structures</a><a hidden class=anchor aria-hidden=true href=#multi-band-alma-polarization-observations-of-bhb07-11-reveal-aligned-dust-grains-in-complex-spiral-arm-structureshttpsarxivorgabs251205768v1>#</a></h3><p><strong>Authors:</strong> Austen Fourkas, Leslie W. Looney, Zhe-Yu Daniel Lin, Martin Radecki, Zhi-Yun Li, John J. Tobin, Ian W. Stephens, Manuel Fern√°ndez-L√≥pez, Haifeng Yang, Woojin Kwon, Rachel Harrison
<strong>Venue:</strong> arXiv (2025)</p><p>Polarization-mode observations from the Atacama Large Millimeter/submillimeter Array (ALMA) are powerful tools for studying the dust grain populations in circumstellar disks. Many sources exhibit polarization signatures consistent with aligned dust grains, yet the physical origin of this alignment remains uncertain. One such source is BHB07-11, a Class I protobinary object in the Pipe Nebula with complex spiral arm structures in its circumbinary disk. While magnetic fields are often invoked to explain grain alignment in the interstellar medium, the contrasting conditions in circumstellar disk environments demand further investigation into grain alignment mechanisms. To determine BHB07-11&rsquo;s dominant polarization mechanism, we leverage ALMA polarization-mode dust continuum observations in Bands 3 ($Œª$=3.1 mm), 6 ($Œª$=1.3 mm), and 7 ($Œª$=0.87 mm), in combination with high-resolution dust continuum and spectral line observations in Band 6. Observed polarization vectors in each band are consistent with emission from aligned grains and follow the structure of the spiral arms as shown in the high-resolution observations. Given the relationship between the observed polarization vector orientation and the spiral arms, we find that the polarization morphology is most consistent with grains aligned through a relative velocity flow between gas and dust in the spiral arms, as envisioned in the recently developed badminton birdie-like alignment mechanism, rather than alignment with a magnetic field or other known alignment mechanisms.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05768v1">üìÑ Download PDF</a></p><hr><h3 id=4d3d-reduction-of-dualities-with-o6httpsarxivorgabs251205724v1><a href=https://arxiv.org/abs/2512.05724v1>4d/3d reduction of dualities with O6</a><a hidden class=anchor aria-hidden=true href=#4d3d-reduction-of-dualities-with-o6httpsarxivorgabs251205724v1>#</a></h3><p><strong>Authors:</strong> Antonio Amariti, Pietro Glorioso, Chiara Mascherpa, Andrea Zanetti
<strong>Venue:</strong> arXiv (2025)</p><p>We consider $\mathrm{U}(N)$ gauge theories with a pair of two-index tensors interacting through a quartic superpotential, in addition to fundamentals and antifundamentals. The models have a brane engineering in terms of NS, D4, D6 branes and an O6 plane. Depending on the representation of the tensorial matter we have either an O6$^{+}$ plane, an O6$^{-}$ plane or a combined state of O6$^{+}$ and O6$^{-}$, with the addition of 8 semi-infinite half-D6 branes, where the last case realizes a chiral theory. The 4d IR duality is realized through an HW transition in the brane description. Here we study the circle reduction of these dualities from the brane perspective by T-dualizing along the compact direction. We then compare the results against the one obtained from field theoretical considerations and from localization, finding a precise agreement. When we consider the reduction of the 4d superconformal index to the 3d squashed three sphere partition function we observe that it is not always possible to obtain convergent 3d result with the standard reduction prescription, and that the double scaling limit is necessary.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05724v1">üìÑ Download PDF</a></p><hr><h3 id=whatever-remains-must-be-true-filtering-drives-reasoning-in-llms-shaping-diversityhttpsarxivorgabs251205962v1><a href=https://arxiv.org/abs/2512.05962v1>Whatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity</a><a hidden class=anchor aria-hidden=true href=#whatever-remains-must-be-true-filtering-drives-reasoning-in-llms-shaping-diversityhttpsarxivorgabs251205962v1>#</a></h3><p><strong>Authors:</strong> Germ√°n Kruszewski, Pierre Erbacher, Jos Rozen, Marc Dymetman
<strong>Venue:</strong> arXiv (2025)</p><p>Reinforcement Learning (RL) has become the de facto standard for tuning LLMs to solve tasks involving reasoning. However, growing evidence shows that models trained in such way often suffer from a significant loss in diversity. We argue that this arises because RL implicitly optimizes the &ldquo;mode-seeking&rdquo; or &ldquo;zero-forcing&rdquo; Reverse KL to a target distribution causing the model to concentrate mass on certain high-probability regions of the target while neglecting others. In this work, we instead begin from an explicit target distribution, obtained by filtering out incorrect answers while preserving the relative probabilities of correct ones. Starting from a pre-trained LLM, we approximate this target distribution using the $Œ±$-divergence family, which unifies prior approaches and enables direct control of the precision-diversity trade-off by interpolating between mode-seeking and mass-covering divergences. On a Lean theorem-proving benchmark, our method achieves state-of-the-art performance along the coverage-precision Pareto frontier, outperforming all prior methods on the coverage axis.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05962v1">üìÑ Download PDF</a></p><hr><h3 id=consequences-of-kernel-regularity-for-bandit-optimizationhttpsarxivorgabs251205957v1><a href=https://arxiv.org/abs/2512.05957v1>Consequences of Kernel Regularity for Bandit Optimization</a><a hidden class=anchor aria-hidden=true href=#consequences-of-kernel-regularity-for-bandit-optimizationhttpsarxivorgabs251205957v1>#</a></h3><p><strong>Authors:</strong> Madison Lee, Tara Javidi
<strong>Venue:</strong> arXiv (2025)</p><p>In this work we investigate the relationship between kernel regularity and algorithmic performance in the bandit optimization of RKHS functions. While reproducing kernel Hilbert space (RKHS) methods traditionally rely on global kernel regressors, it is also common to use a smoothness-based approach that exploits local approximations. We show that these perspectives are deeply connected through the spectral properties of isotropic kernels. In particular, we characterize the Fourier spectra of the Mat√©rn, square-exponential, rational-quadratic, $Œ≥$-exponential, piecewise-polynomial, and Dirichlet kernels, and show that the decay rate determines asymptotic regret from both viewpoints. For kernelized bandit algorithms, spectral decay yields upper bounds on the maximum information gain, governing worst-case regret, while for smoothness-based methods, the same decay rates establish H√∂lder space embeddings and Besov space norm-equivalences, enabling local continuity analysis. These connections show that kernel-based and locally adaptive algorithms can be analyzed within a unified framework. This allows us to derive explicit regret bounds for each kernel family, obtaining novel results in several cases and providing improved analysis for others. Furthermore, we analyze LP-GP-UCB, an algorithm that combines both approaches, augmenting global Gaussian process surrogates with local polynomial estimators. While the hybrid approach does not uniformly dominate specialized methods, it achieves order-optimality across multiple kernel families.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05957v1">üìÑ Download PDF</a></p><hr><h3 id=correspondence-oriented-imitation-learning-flexible-visuomotor-control-with-3d-conditioninghttpsarxivorgabs251205953v1><a href=https://arxiv.org/abs/2512.05953v1>Correspondence-Oriented Imitation Learning: Flexible Visuomotor Control with 3D Conditioning</a><a hidden class=anchor aria-hidden=true href=#correspondence-oriented-imitation-learning-flexible-visuomotor-control-with-3d-conditioninghttpsarxivorgabs251205953v1>#</a></h3><p><strong>Authors:</strong> Yunhao Cao, Zubin Bhaumik, Jessie Jia, Xingyi He, Kuan Fang
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce Correspondence-Oriented Imitation Learning (COIL), a conditional policy learning framework for visuomotor control with a flexible task representation in 3D. At the core of our approach, each task is defined by the intended motion of keypoints selected on objects in the scene. Instead of assuming a fixed number of keypoints or uniformly spaced time intervals, COIL supports task specifications with variable spatial and temporal granularity, adapting to different user intents and task requirements. To robustly ground this correspondence-oriented task representation into actions, we design a conditional policy with a spatio-temporal attention mechanism that effectively fuses information across multiple input modalities. The policy is trained via a scalable self-supervised pipeline using demonstrations collected in simulation, with correspondence labels automatically generated in hindsight. COIL generalizes across tasks, objects, and motion patterns, achieving superior performance compared to prior methods on real-world manipulation tasks under both sparse and dense specifications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05953v1">üìÑ Download PDF</a></p><hr><h3 id=heard-or-halted-gender-interruptions-and-emotional-tone-in-us-supreme-court-oral-argumentshttpsarxivorgabs251205832v1><a href=https://arxiv.org/abs/2512.05832v1>Heard or Halted? Gender, Interruptions, and Emotional Tone in U.S. Supreme Court Oral Arguments</a><a hidden class=anchor aria-hidden=true href=#heard-or-halted-gender-interruptions-and-emotional-tone-in-us-supreme-court-oral-argumentshttpsarxivorgabs251205832v1>#</a></h3><p><strong>Authors:</strong> Yifei Tong
<strong>Venue:</strong> arXiv (2025)</p><p>This study examines how interruptions during U.S. Supreme Court oral arguments shape both the semantic content and emotional tone of advocates&rsquo; speech, with a focus on gendered dynamics in judicial discourse. Using the ConvoKit Supreme Court Corpus (2010-2019), we analyze 12,663 speech chunks from advocate-justice interactions to assess whether interruptions alter the meaning of an advocate&rsquo;s argument and whether interruptions toward female advocates exhibit more negative emotional valence. Semantic shifts are quantified using GloVe-based sentence embeddings, while sentiment is measured through lexicon-based analysis. We find that semantic similarity between pre- and post-interruption speech remains consistently high, suggesting that interruptions do not substantially alter argumentative content. However, interruptions directed at female advocates contain significantly higher levels of negative sentiment. These results deepen empirical understanding of gendered communication in elite institutional settings and demonstrate the value of computational linguistic methods for studying power, discourse, and equity in judicial proceedings.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05832v1">üìÑ Download PDF</a></p><hr><h3 id=unveiling-affective-polarization-trends-in-parliamentary-proceedingshttpsarxivorgabs251205231v1><a href=https://arxiv.org/abs/2512.05231v1>Unveiling Affective Polarization Trends in Parliamentary Proceedings</a><a hidden class=anchor aria-hidden=true href=#unveiling-affective-polarization-trends-in-parliamentary-proceedingshttpsarxivorgabs251205231v1>#</a></h3><p><strong>Authors:</strong> Gili Goldin, Ella Rabinovich, Shuly Wintner
<strong>Venue:</strong> arXiv (2025)</p><p>Recent years have seen an increase in polarized discourse worldwide, on various platforms. We propose a novel method for quantifying polarization, based on the emotional style of the discourse rather than on differences in ideological stands. Using measures of Valence, Arousal and Dominance, we detect signals of emotional discourse and use them to operationalize the concept of affective polarization. Applying this method to a recently released corpus of proceedings of the Knesset, the Israeli parliament (in Hebrew), we find that the emotional style of members of government differs from that of opposition members; and that the level of affective polarization, as reflected by this style, is significantly increasing with time.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05231v1">üìÑ Download PDF</a></p><hr><h3 id=toward-continuous-neurocognitive-monitoring-integrating-speech-ai-with-relational-graph-transformers-for-rare-neurological-diseaseshttpsarxivorgabs251204938v1><a href=https://arxiv.org/abs/2512.04938v1>Toward Continuous Neurocognitive Monitoring: Integrating Speech AI with Relational Graph Transformers for Rare Neurological Diseases</a><a hidden class=anchor aria-hidden=true href=#toward-continuous-neurocognitive-monitoring-integrating-speech-ai-with-relational-graph-transformers-for-rare-neurological-diseaseshttpsarxivorgabs251204938v1>#</a></h3><p><strong>Authors:</strong> Raquel Norel, Michele Merler, Pavitra Modi
<strong>Venue:</strong> arXiv (2025)</p><p>Patients with rare neurological diseases report cognitive symptoms -&ldquo;brain fog&rdquo;- invisible to traditional tests. We propose continuous neurocognitive monitoring via smartphone speech analysis integrated with Relational Graph Transformer (RELGT) architectures. Proof-of-concept in phenylketonuria (PKU) shows speech-derived &ldquo;Proficiency in Verbal Discourse&rdquo; correlates with blood phenylalanine (p = -0.50, p &lt; 0.005) but not standard cognitive tests (all |r| &lt; 0.35). RELGT could overcome information bottlenecks in heterogeneous medical data (speech, labs, assessments), enabling predictive alerts weeks before decompensation. Key challenges: multi-disease validation, clinical workflow integration, equitable multilingual deployment. Success would transform episodic neurology into continuous personalized monitoring for millions globally.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04938v1">üìÑ Download PDF</a></p><hr><h3 id=seal-self-evolving-agentic-learning-for-conversational-question-answering-over-knowledge-graphshttpsarxivorgabs251204868v1><a href=https://arxiv.org/abs/2512.04868v1>SEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs</a><a hidden class=anchor aria-hidden=true href=#seal-self-evolving-agentic-learning-for-conversational-question-answering-over-knowledge-graphshttpsarxivorgabs251204868v1>#</a></h3><p><strong>Authors:</strong> Hao Wang, Jialun Zhong, Changcheng Wang, Zhujun Nie, Zheng Li, Shunyu Yao, Yanzeng Li, Xinchi Li
<strong>Venue:</strong> arXiv (2025)</p><p>Knowledge-based conversational question answering (KBCQA) confronts persistent challenges in resolving coreference, modeling contextual dependencies, and executing complex logical reasoning. Existing approaches, whether end-to-end semantic parsing or stepwise agent-based reasoning, often suffer from structural inaccuracies and prohibitive computational costs, particularly when processing intricate queries over large knowledge graphs. To address these limitations, we introduce SEAL, a novel two-stage semantic parsing framework grounded in self-evolving agentic learning. In the first stage, a large language model (LLM) extracts a minimal S-expression core that captures the essential semantics of the input query. This core is then refined by an agentic calibration module, which corrects syntactic inconsistencies and aligns entities and relations precisely with the underlying knowledge graph. The second stage employs template-based completion, guided by question-type prediction and placeholder instantiation, to construct a fully executable S-expression. This decomposition not only simplifies logical form generation but also significantly enhances structural fidelity and linking efficiency. Crucially, SEAL incorporates a self-evolving mechanism that integrates local and global memory with a reflection module, enabling continuous adaptation from dialog history and execution feedback without explicit retraining. Extensive experiments on the SPICE benchmark demonstrate that SEAL achieves state-of-the-art performance, especially in multi-hop reasoning, comparison, and aggregation tasks. The results validate notable gains in both structural accuracy and computational efficiency, underscoring the framework&rsquo;s capacity for robust and scalable conversational reasoning.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04868v1">üìÑ Download PDF</a></p><hr><h3 id=playing-the-player-a-heuristic-framework-for-adaptive-poker-aihttpsarxivorgabs251204714v1><a href=https://arxiv.org/abs/2512.04714v1>Playing the Player: A Heuristic Framework for Adaptive Poker AI</a><a hidden class=anchor aria-hidden=true href=#playing-the-player-a-heuristic-framework-for-adaptive-poker-aihttpsarxivorgabs251204714v1>#</a></h3><p><strong>Authors:</strong> Andrew Paterson, Carl Sanders
<strong>Venue:</strong> arXiv (2025)</p><p>For years, the discourse around poker AI has been dominated by the concept of solvers and the pursuit of unexploitable, machine-perfect play. This paper challenges that orthodoxy. It presents Patrick, an AI built on the contrary philosophy: that the path to victory lies not in being unexploitable, but in being maximally exploitative. Patrick&rsquo;s architecture is a purpose-built engine for understanding and attacking the flawed, psychological, and often irrational nature of human opponents. Through detailed analysis of its design, its novel prediction-anchored learning method, and its profitable performance in a 64,267-hand trial, this paper makes the case that the solved myth is a distraction from the real, far more interesting challenge: creating AI that can master the art of human imperfection.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04714v1">üìÑ Download PDF</a></p><hr><h3 id=llm-srclog-towards-proactive-and-unified-log-template-extraction-via-large-language-modelshttpsarxivorgabs251204474v1><a href=https://arxiv.org/abs/2512.04474v1>LLM-SrcLog: Towards Proactive and Unified Log Template Extraction via Large Language Models</a><a hidden class=anchor aria-hidden=true href=#llm-srclog-towards-proactive-and-unified-log-template-extraction-via-large-language-modelshttpsarxivorgabs251204474v1>#</a></h3><p><strong>Authors:</strong> Jiaqi Sun, Wei Li, Heng Zhang, Chutong Ding, Shiyou Qian, Jian Cao, Guangtao Xue
<strong>Venue:</strong> arXiv (2025)</p><p>Log parsing transforms raw logs into structured templates containing constants and variables. It underpins anomaly detection, failure diagnosis, and other AIOps tasks. Current parsers are mostly reactive and log-centric. They only infer templates from logs, mostly overlooking the source code. This restricts their capacity to grasp dynamic log structures or adjust to evolving systems. Moreover, per-log LLM inference is too costly for practical deployment. In this paper, we propose LLM-SrcLog, a proactive and unified framework for log template parsing. It extracts templates directly from source code prior to deployment and supplements them with data-driven parsing for logs without available code. LLM-SrcLog integrates a cross-function static code analyzer to reconstruct meaningful logging contexts, an LLM-based white-box template extractor with post-processing to distinguish constants from variables, and a black-box template extractor that incorporates data-driven clustering for remaining unmatched logs. Experiments on two public benchmarks (Hadoop and Zookeeper) and a large-scale industrial system (Sunfire-Compute) show that, compared to two LLM-based baselines, LLM-SrcLog improves average F1-score by 2-17% and 8-35%. Meanwhile, its online parsing latency is comparable to data-driven methods and about 1,000 times faster than per-log LLM parsing. LLM-SrcLog achieves a near-ideal balance between speed and accuracy. Finally, we further validate the effectiveness of LLM-SrcLog through practical case studies in a real-world production environment.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04474v1">üìÑ Download PDF</a></p><hr><h3 id=strongly-coupled-quantum-forceshttpsarxivorgabs251205968v1><a href=https://arxiv.org/abs/2512.05968v1>Strongly Coupled Quantum Forces</a><a hidden class=anchor aria-hidden=true href=#strongly-coupled-quantum-forceshttpsarxivorgabs251205968v1>#</a></h3><p><strong>Authors:</strong> Yuval Grossman, Chinhsan Sieng, Xun-Jie Xu, Bingrong Yu
<strong>Venue:</strong> arXiv (2025)</p><p>Quantum forces are long-range interactions originating from vacuum fluctuations of mediator fields. Such forces inevitably arise between ordinary matter particles whenever they couple to light mediator species. Conventional computations of quantum forces rely on evaluating one-loop Feynman diagrams of the relevant scattering processes. In this work, we introduce a novel framework to compute quantum forces. Instead of relying on perturbative scattering amplitudes, we directly evaluate the quantum fluctuations of the mediator field by solving its quantized equation of motion with appropriate boundary conditions. This approach remains valid beyond the Born approximation and thus applies to regimes of strong coupling between the mediator and matter fields. In the weak-coupling limit, our results reproduce the known expressions from the Feynman diagram approach. In the strong-coupling regime, the result is modified by a factor that can suppress or enhance the effect. In contrast to classical forces, quantum forces intrinsically violate the superposition principle. Our approach may therefore offer a useful tool for probing non-perturbative effects in the infrared regime.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05968v1">üìÑ Download PDF</a></p><hr><h3 id=entanglement-enhanced-quantum-nano-vibrometryhttpsarxivorgabs251205961v1><a href=https://arxiv.org/abs/2512.05961v1>Entanglement-Enhanced Quantum Nano-Vibrometry</a><a hidden class=anchor aria-hidden=true href=#entanglement-enhanced-quantum-nano-vibrometryhttpsarxivorgabs251205961v1>#</a></h3><p><strong>Authors:</strong> Colin P. Lualdi, Joshua Rapp, Spencer J. Johnson, Michael Vayninger, Paul G. Kwiat
<strong>Venue:</strong> arXiv (2025)</p><p>The study of dynamic systems at the nanometer scale can benefit from the loss and background resilience offered by quantum two-photon interference. However, fast measurements with the required resolution are difficult to realize. As a solution, we introduce extreme energy entanglement between the photons undergoing interference. Using a flux probing analysis technique, we recover vibrational signals with frequencies as high as 21 kHz. Along with validating nanometer-scale precision and accuracy, we observe a significant quantum advantage when measuring in the presence of loss and background.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05961v1">üìÑ Download PDF</a></p><hr><h3 id=topical-issue-on-the-intersection-of-low-energy-nuclear-structure-and-high-energy-nuclear-collisionshttpsarxivorgabs251205874v1><a href=https://arxiv.org/abs/2512.05874v1>Topical issue on the intersection of low-energy nuclear structure and high-energy nuclear collisions</a><a hidden class=anchor aria-hidden=true href=#topical-issue-on-the-intersection-of-low-energy-nuclear-structure-and-high-energy-nuclear-collisionshttpsarxivorgabs251205874v1>#</a></h3><p><strong>Authors:</strong> T. Duguet, G. Giacalone, V. Som√†, Y. Zhou
<strong>Venue:</strong> arXiv (2025)</p><p>High-energy heavy-ion physics and low-energy nuclear structure physics have historically been disconnected fields. The hydrodynamic description of the quark-gluon plasma (QGP) requires input from nuclear structure to model the initial states of the colliding nuclei. Advances in both theory and experiment now show that the hydrodynamic evolution of the QGP is sensitive to the detailed features of the colliding nuclei, with remarkable consequences for experimental observables.
The topical collection represents a joint effort between the low- and high-energy nuclear communities, reflecting the growing recognition that precision modeling of nuclear structure is essential for interpreting high-energy collision data. This new experimental approach opens outstanding opportunities to deepen our understanding of strong-interaction matter. Indeed, by probing many-body correlations of nucleons directly in the nuclear ground state, high-energy collisions provide a unique way to &ldquo;image&rdquo; nuclei, fully complementary to the techniques of low-energy experiments, where nuclear collectivity is usually inferred from spectroscopic information on excited states.
Do emergent many-body QCD phenomena in nuclei manifest consistently across experiments and energy scales? Addressing this question requires synergy between collider data and state-of-the-art nuclear structure calculations. In view of the rapid progress of ab initio methods based on low-energy effective field theories of QCD, the implications are far-reaching: heavy-ion collisions can probe nuclear forces, while nuclear structure insights refine our understanding of QGP dynamics.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05874v1">üìÑ Download PDF</a></p><hr><h3 id=resolving-abrikosov-vortex-entry-in-superconducting-nano-string-resonators-via-displacement-noise-spectroscopy-in-cavity-optomechanicshttpsarxivorgabs251205873v1><a href=https://arxiv.org/abs/2512.05873v1>Resolving Abrikosov vortex entry in superconducting nano-string resonators via displacement-noise spectroscopy in cavity-optomechanics</a><a hidden class=anchor aria-hidden=true href=#resolving-abrikosov-vortex-entry-in-superconducting-nano-string-resonators-via-displacement-noise-spectroscopy-in-cavity-optomechanicshttpsarxivorgabs251205873v1>#</a></h3><p><strong>Authors:</strong> Thomas Luschmann, Tahereh Sadat Parvini, Lukas Niekamp, Achim Marx, Rudolf Gross, Hans Huebl
<strong>Venue:</strong> arXiv (2025)</p><p>Abrikosov vortices in type-II superconductors critically influence current flow and coherence, thereby imposing fundamental limits on superconducting quantum technologies. Quantum circuits employ superconducting elements at micro- and mesoscopic scales, where individual vortices can significantly impact device performance, necessitating investigation of vortex entry, motion, and pinning in these constrained geometries. Cavity-optomechanical platforms combining flux-tunable microwave resonators with superconducting nanomechanical elements offer a promising route to the single-photon strong-coupling regime and enable highly sensitive probing of the mechanical degree of freedom under elevated magnetic fields. Here, we exploit this platform to investigate vortex entry processes at the single-event level. We observe discrete jumps of the mechanical resonance frequency attributable to individual vortex entry, corresponding to attonewton-scale forces and allowing quantitative extraction of single-vortex pinning energies. These signatures are superimposed on a smooth power-law background characteristic of the collective Campbell-regime of vortex elasticity. Our results establish optomechanics-inspired sensing as a powerful method for exploring fundamental superconducting properties and identifying decoherence pathways in quantum circuits. Beyond advancing vortex physics, this work opens new opportunities for integrating mechanical sensing into superconducting device architectures, bridging condensed matter physics and quantum information science.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05873v1">üìÑ Download PDF</a></p><hr><h3 id=categorifying-isomonodromic-deformations-via-lie-groupoids-i-logarithmic-singularitieshttpsarxivorgabs251205966v1><a href=https://arxiv.org/abs/2512.05966v1>Categorifying isomonodromic deformations via Lie groupoids I: Logarithmic singularities</a><a hidden class=anchor aria-hidden=true href=#categorifying-isomonodromic-deformations-via-lie-groupoids-i-logarithmic-singularitieshttpsarxivorgabs251205966v1>#</a></h3><p><strong>Authors:</strong> Waleed Qaisar
<strong>Venue:</strong> arXiv (2025)</p><p>We upgrade the classical operation of \textit{isomonodromic deformations} along a path $Œ≥$ to a functor $\mathbb{P}_Œ≥$ between categories of flat connections with logarithmic singularities along a divisor $D$, which itself depends functorially on $Œ≥$, using tools from the theory of Lie groupoids. As applications, (1) we get that isomonodromy gives a map of moduli \textit{stacks} of flat connections with logarithmic singularities, (2) we encode higher homotopical information at level 2, i.e. we get an action of the fundamental 2-groupoid of the base of our family on the categories of logarithmic flat connections on the fibres, and (3) our methods produce a geometric incarnation of the isomonodromy functors as Morita equivalences which are more primary than the isomonodromy functors themselves, and from which they can be formally extracted by passing to representation categories.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05966v1">üìÑ Download PDF</a></p><hr><h3 id=impugan-learning-conditional-generative-models-for-robust-data-imputationhttpsarxivorgabs251205950v1><a href=https://arxiv.org/abs/2512.05950v1>Impugan: Learning Conditional Generative Models for Robust Data Imputation</a><a hidden class=anchor aria-hidden=true href=#impugan-learning-conditional-generative-models-for-robust-data-imputationhttpsarxivorgabs251205950v1>#</a></h3><p><strong>Authors:</strong> Zalish Mahmud, Anantaa Kotal, Aritran Piplai
<strong>Venue:</strong> arXiv (2025)</p><p>Incomplete data are common in real-world applications. Sensors fail, records are inconsistent, and datasets collected from different sources often differ in scale, sampling rate, and quality. These differences create missing values that make it difficult to combine data and build reliable models. Standard imputation methods such as regression models, expectation-maximization, and multiple imputation rely on strong assumptions about linearity and independence. These assumptions rarely hold for complex or heterogeneous data, which can lead to biased or over-smoothed estimates. We propose Impugan, a conditional Generative Adversarial Network (cGAN) for imputing missing values and integrating heterogeneous datasets. The model is trained on complete samples to learn how missing variables depend on observed ones. During inference, the generator reconstructs missing entries from available features, and the discriminator enforces realism by distinguishing true from imputed data. This adversarial process allows Impugan to capture nonlinear and multimodal relationships that conventional methods cannot represent. In experiments on benchmark datasets and a multi-source integration task, Impugan achieves up to 82% lower Earth Mover&rsquo;s Distance (EMD) and 70% lower mutual-information deviation (MI) compared to leading baselines. These results show that adversarially trained generative models provide a scalable and principled approach for imputing and merging incomplete, heterogeneous data. Our model is available at: github.com/zalishmahmud/impuganBigData2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05950v1">üìÑ Download PDF</a></p><hr><h3 id=removing-correlated-noise-stripes-from-the-nancy-grace-roman-space-telescope-survey-imageshttpsarxivorgabs251205949v1><a href=https://arxiv.org/abs/2512.05949v1>Removing correlated noise stripes from the Nancy Grace Roman Space Telescope survey images</a><a hidden class=anchor aria-hidden=true href=#removing-correlated-noise-stripes-from-the-nancy-grace-roman-space-telescope-survey-imageshttpsarxivorgabs251205949v1>#</a></h3><p><strong>Authors:</strong> Katherine Laliotis, Christopher M. Hirata, Emily Macbeth, Kaili Cao
<strong>Venue:</strong> arXiv (2025)</p><p>Weak gravitational lensing has emerged as a powerful tool for investigating the matter distribution in the Universe and how it has evolved over cosmic time. The Wide Field Instrument (WFI) on the Nancy Grace Roman Space Telescope (Roman) will deliver some of the highest precision measurements of weak lensing ever made. Since weak lensing is based on statistics of faint sources, it can be biased by even tiny instrument systematics, including correlated read noise. Previous works have shown the infrared detectors used in the Roman WFI show correlations in their noise fields at a level significant for weak lensing measurements, even after application of standard reference pixel corrections; of particular concern is 1/f noise, which appears as horizontal banding in the detector frame. In this paper, we present imDestripe: a new Python module utilizing the multiple roll angles in Roman&rsquo;s observing strategy and linear algebra techniques to remove correlated noise stripes from observed images. We test imDestripe in a hybrid simulation by combining real noise realizations (from darks taken during ground testing) with simulated images of the astronomical scene, and find that the power spectrum of the banding can be suppressed by factors of 10&ndash;30 on large scales. We briefly discuss plans for further development of imDestripe in the context of the WFI pipeline.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05949v1">üìÑ Download PDF</a></p><hr><h3 id=on-cable-graph-percolation-between-dimensions-2-and-3httpsarxivorgabs251205947v1><a href=https://arxiv.org/abs/2512.05947v1>On cable-graph percolation between dimensions 2 and 3</a><a hidden class=anchor aria-hidden=true href=#on-cable-graph-percolation-between-dimensions-2-and-3httpsarxivorgabs251205947v1>#</a></h3><p><strong>Authors:</strong> Pierre-Fran√ßois Rodriguez, Wen Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>We consider the Gaussian free field on two-dimensional slabs with a thickness described by a height $h$ at spatial scale $N$. We investigate the radius of critical clusters for the associated cable-graph percolation problem, which depends sensitively on the parameter $h$. Our results unveil a whole family of new &ldquo;fixed points&rdquo;, which interpolate between recent results from arXiv:2303.03782 in two dimensions and from arXiv:2405.17417 and arXiv:2406.02397 in three dimensions, and describe critical behaviour beyond those regimes. In the delocalised phase, the one-arm decay exhibits a &ldquo;plateau&rdquo;, i.e. it doesn&rsquo;t depend on the speed at which the variance of the field diverges in the large-$N$ limit. Our methods rely on a careful analysis of the interplay between two- and three-dimensional effects for the underlying random walk, which manifest themselves in a corresponding decomposition of the field.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05947v1">üìÑ Download PDF</a></p><hr><h3 id=bootstrapping-fuzzers-for-compilers-of-low-resource-language-dialects-using-language-modelshttpsarxivorgabs251205887v1><a href=https://arxiv.org/abs/2512.05887v1>Bootstrapping Fuzzers for Compilers of Low-Resource Language Dialects Using Language Models</a><a hidden class=anchor aria-hidden=true href=#bootstrapping-fuzzers-for-compilers-of-low-resource-language-dialects-using-language-modelshttpsarxivorgabs251205887v1>#</a></h3><p><strong>Authors:</strong> Sairam Vaidya, Marcel B√∂hme, Loris D&rsquo;Antoni
<strong>Venue:</strong> arXiv (2025)</p><p>Modern extensible compiler frameworks-such as MLIR-enable rapid creation of domain-specific language dialects. This flexibility, however, makes correctness harder to ensure as the same extensibility that accelerates development also complicates maintaining the testing infrastructure. Extensible languages require automated test generation that is both dialect-agnostic (works across dialects without manual adaptation) and dialect-effective (targets dialect-specific features to find bugs). Existing approaches typically sacrifice one of these goals by either requiring manually constructed seed corpora for each dialect, or by failing to be effective. We present a dialect-agnostic and dialect-effective grammar-based and coverage-guided fuzzing approach for extensible compilers that combines two key insights from existing work: (i) the grammars of dialects, which already encode the structural and type constraints, can often be extracted automatically from the dialect specification; and (ii) these grammars can be used in combination with pre-trained large language models to automatically generate representative and diverse seed inputs from the full dialect space without requiring any manual input or training data. These seeds can then be used to bootstrap coverage-guided fuzzers. We built this approach into a tool, Germinator. When evaluated on six MLIR projects spanning 91 dialects, Germinator generated seeds improve line coverage by 10-120% over grammar-based baselines. We compare against grammar-based baselines because they are the only class of existing automatic seed generators that can be applied uniformly across MLIR&rsquo;s heterogeneous dialect ecosystem. Germinator discovers 88 previously unknown bugs (40 confirmed), including 23 in dialects with no prior automated test generators, demonstrating effective and controllable testing of low-resource dialects at scale.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05887v1">üìÑ Download PDF</a></p><hr><h3 id=model-selection-with-uncertainty-in-estimating-optimal-dynamic-treatment-regimeshttpsarxivorgabs251205695v1><a href=https://arxiv.org/abs/2512.05695v1>Model selection with uncertainty in estimating optimal dynamic treatment regimes</a><a hidden class=anchor aria-hidden=true href=#model-selection-with-uncertainty-in-estimating-optimal-dynamic-treatment-regimeshttpsarxivorgabs251205695v1>#</a></h3><p><strong>Authors:</strong> Chunyu Wang, Brian Tom
<strong>Venue:</strong> arXiv (2025)</p><p>Optimal dynamic treatment regimes (DTRs), as a key part of precision medicine, have progressively gained more attention recently. To inform clinical decision making, interpretable and parsimonious models for contrast functions are preferred, raising concerns about undue misspecification. It is therefore important to properly evaluate the performance of candidate interpretable models and select the one that best approximates the unknown contrast function. Moreover, since a DTR usually involves multiple decision points, an inaccurate approximation at a later decision point affects its estimation at an earlier decision point when a backward induction algorithm is applied. This paper aims to perform model selection for contrast functions in the context of learning optimal DTRs from observed data. Note that the relative performance of candidate models may heavily depend on the sample size when, for example, the comparison is made between parametric and tree-based models. Therefore, instead of investigating the limiting behavior of each candidate model and developing methods to select asymptotically the `correct&rsquo; one, we focus on the finite sample performance of each model and attempt to perform model selection under a given sample size. To this end, we adopt the counterfactual cross-validation metric and propose a novel method to estimate the variance of the metric. Supplementing the cross-validation metric with its estimated variance allows us to characterize the uncertainty in model selection under a given sample size and facilitates hypothesis testing associated with a preferred model structure.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05695v1">üìÑ Download PDF</a></p><hr><h3 id=conscious-gaze-adaptive-attention-mechanisms-for-hallucination-mitigation-in-vision-language-modelshttpsarxivorgabs251205546v1><a href=https://arxiv.org/abs/2512.05546v1>Conscious Gaze: Adaptive Attention Mechanisms for Hallucination Mitigation in Vision-Language Models</a><a hidden class=anchor aria-hidden=true href=#conscious-gaze-adaptive-attention-mechanisms-for-hallucination-mitigation-in-vision-language-modelshttpsarxivorgabs251205546v1>#</a></h3><p><strong>Authors:</strong> Weijue Bu, Guan Yuan, Guixian Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>Large Vision-Language Models (VLMs) often exhibit text inertia, where attention drifts from visual evidence toward linguistic priors, resulting in object hallucinations. Existing decoding strategies intervene only at the output logits and thus cannot correct internal reasoning drift, while recent internal-control methods based on heuristic head suppression or global steering vectors lack principled grounding. We introduce Conscious Gaze (CG-VLM), a training-free, inference-time framework that converts game-theoretic interpretability into actionable decoding control. A Cognitive Demand Sensor built on Harsanyi interactions estimates instantaneous vision-text synergy and identifies moments when visual grounding is necessary. Conditioned on this signal, a Focused Consensus Induction module selectively reorients mid-layer attention toward visual tokens before collapse into text priors. CG-VLM achieves state-of-the-art results on POPE and CHAIR across InstructBLIP, LLaVA, Qwen-VL, and mPLUG, while preserving general capabilities, demonstrating that token-level sensing enables precise, context-aware intervention without compromising foundational knowledge.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05546v1">üìÑ Download PDF</a></p><hr><h3 id=an-evaluation-of-a15-nb3al-superconducting-thin-films-for-application-in-quantum-circuitshttpsarxivorgabs251205396v1><a href=https://arxiv.org/abs/2512.05396v1>An evaluation of A15 Nb3Al superconducting thin films for application in quantum circuits</a><a hidden class=anchor aria-hidden=true href=#an-evaluation-of-a15-nb3al-superconducting-thin-films-for-application-in-quantum-circuitshttpsarxivorgabs251205396v1>#</a></h3><p><strong>Authors:</strong> Joseph Falvo, Brooke Henry, Bernardo Langa, Rohit Pant, Ashish Alexander, Jason Dong, Kasra Sardashti
<strong>Venue:</strong> arXiv (2025)</p><p>A15 superconductors are distinguished by their high critical temperatures, magnetic fields, and current-carrying capabilities. Among them, Nb$_3$Al is of particular interest for superconducting quantum circuits as a means to extend device operating temperatures, provided that its electrodynamic properties are well understood. Here, we report on the synthesis of Nb$_3$Al thin films by magnetron co-sputtering followed by rapid thermal processing, yielding superconducting transition temperatures above 16~K. Microwire devices patterned from these films exhibit a coherence length of $3.2,\mathrm{nm}$ and superfluid densities as low as $1.1\times 10^{26},\mathrm{m}^{-3}$, suggesting that Nb$_3$Al may enable high kinetic inductance in thinner films. Coplanar waveguide resonators fabricated on Nb$_3$Al demonstrate single-photon internal quality factors up to $2.26\times 10^{5}$. These results establish Nb$_3$Al as a promising material platform for the development of superconducting quantum circuits operating at elevated temperatures, contingent on appropriate control of interfacial chemistry and surface morphology.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05396v1">üìÑ Download PDF</a></p><hr><h3 id=comparative-analysis-of-barrier-like-function-methods-for-reach-avoid-verification-in-stochastic-discrete-time-systemshttpsarxivorgabs251205348v1><a href=https://arxiv.org/abs/2512.05348v1>Comparative Analysis of Barrier-like Function Methods for Reach-Avoid Verification in Stochastic Discrete-Time Systems</a><a hidden class=anchor aria-hidden=true href=#comparative-analysis-of-barrier-like-function-methods-for-reach-avoid-verification-in-stochastic-discrete-time-systemshttpsarxivorgabs251205348v1>#</a></h3><p><strong>Authors:</strong> Zhipeng Cao, Peixin Wang, Luke Ong, ƒêorƒëe ≈Ωikeliƒá, Dominik Wagner, Bai Xue
<strong>Venue:</strong> arXiv (2025)</p><p>In this paper, we compare several representative barrier-like conditions from the literature for infinite-horizon reach-avoid verification of stochastic discrete-time systems. Our comparison examines both their theoretical properties and computational tractability, highlighting each condition&rsquo;s strengths and limitations that affect applicability and conservativeness. Finally, we illustrate their practical performance through computational experiments using semidefinite programming (SDP) and counterexample-guided inductive synthesis (CEGIS).</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05348v1">üìÑ Download PDF</a></p><hr><h3 id=on-planar-straight-line-dominance-drawingshttpsarxivorgabs251205225v1><a href=https://arxiv.org/abs/2512.05225v1>On Planar Straight-Line Dominance Drawings</a><a hidden class=anchor aria-hidden=true href=#on-planar-straight-line-dominance-drawingshttpsarxivorgabs251205225v1>#</a></h3><p><strong>Authors:</strong> Patrizio Angelini, Michael A. Bekos, Giuseppe Di Battista, Fabrizio Frati, Luca Grilli, Giacomo Ortali
<strong>Venue:</strong> arXiv (2025)</p><p>We study the following question, which has been considered since the 90&rsquo;s: Does every $st$-planar graph admit a planar straight-line dominance drawing? We show concrete evidence for the difficulty of this question, by proving that, unlike upward planar straight-line drawings, planar straight-line dominance drawings with prescribed $y$-coordinates do not always exist and planar straight-line dominance drawings cannot always be constructed via a contract-draw-expand inductive approach. We also show several classes of $st$-planar graphs that always admit a planar straight-line dominance drawing. These include $st$-planar $3$-trees in which every stacking operation introduces two edges incoming into the new vertex, $st$-planar graphs in which every vertex is adjacent to the sink, $st$-planar graphs in which no face has the left boundary that is a single edge, and $st$-planar graphs that have a leveling with span at most two.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05225v1">üìÑ Download PDF</a></p><hr><h2 id=-psycholinguistics>üîç psycholinguistics<a hidden class=anchor aria-hidden=true href=#-psycholinguistics>#</a></h2><h3 id=constraining-r-process-nucleosynthesis-via-enhanced-accuracy-neutron-capture-experimentshttpsarxivorgabs251205944v1><a href=https://arxiv.org/abs/2512.05944v1>Constraining r-process nucleosynthesis via enhanced accuracy neutron-capture experiments</a><a hidden class=anchor aria-hidden=true href=#constraining-r-process-nucleosynthesis-via-enhanced-accuracy-neutron-capture-experimentshttpsarxivorgabs251205944v1>#</a></h3><p><strong>Authors:</strong> C. Domingo-Pardo, C. Lederer-Woods, A. Mengoni
<strong>Venue:</strong> arXiv (2025)</p><p>The isotopic abundances of r-process elements in the solar system are traditionally derived as residuals from the subtraction of s-process contributions from total solar abundances. However, the uncertainties in s-process nucleosynthesis &ndash; particularly those arising from Maxwellian Averaged Cross Sections (MACS) &ndash; propagate directly into the r-process residuals, affecting their reliability. Building upon the seminal work of Goriely (1999), who introduced a multi-event s-process model to quantify these uncertainties, we revisit the problem using a simplified yet effective approach. By assuming that the relative uncertainty in s-process isotopic abundances scales linearly with the MACS uncertainties from data libraries (KADoNiS), we identify a subset of isotopes for which the r-process residuals remain significantly uncertain. Using updated solar abundances (Lodders 2025) and s-process contributions from Bisterzo et al. (2014), we present a short list of isotopes that are prime candidates for improved (n,g) measurements at CERN n_TOF in the near future. Our analysis provides a practical framework for prioritizing future experimental efforts that will profit from upgrades and enhancements of the n_TOF facility. It also highlights the need to revisit key neutron-capture cross sections to refine our understanding of the r-process isotopic abundance pattern, commonly used as a benchmark in stellar models of explosive nucleosynthesis.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05944v1">üìÑ Download PDF</a></p><hr><h3 id=evolutionary-system-2-reasoning-an-empirical-proofhttpsarxivorgabs251205760v1><a href=https://arxiv.org/abs/2512.05760v1>Evolutionary System 2 Reasoning: An Empirical Proof</a><a hidden class=anchor aria-hidden=true href=#evolutionary-system-2-reasoning-an-empirical-proofhttpsarxivorgabs251205760v1>#</a></h3><p><strong>Authors:</strong> Zeyuan Ma, Wenqi Huang, Guo-Huan Song, Hongshu Guo, Sijie Ma, Zhiguang Cao, Yue-Jiao Gong
<strong>Venue:</strong> arXiv (2025)</p><p>Machine intelligence marks the ultimate dream of making machines&rsquo; intelligence comparable to human beings. While recent progress in Large Language Models (LLMs) show substantial specific skills for a wide array of downstream tasks, they more or less fall shorts in general intelligence. Following correlation between intelligence and system 2 reasoning (slow thinking), in this paper, we aim to answering a worthwhile research question: could machine intelligence such as LLMs be evolved to acquire reasoning ability (not specific skill) just like our human beings? To this end, we propose evolutionary reasoning optimization (ERO) framework which performs survival of the fittest over a population of LLMs to search for individual with strong reasoning ability. Given a reasoning task, ERO first initializes multiple LLMs as a population, after which an evolutionary strategy evolves the population to maximize quantified reasoning score of the best individual. Based on experiments on representative testsuites, we claim two surprising empirical discoveries: i) the latest LLMs such as GPT-5 still show limited system 2 reasoning ability; ii) with simple evolution-loop of ERO, a relatively weak model (Qwen-7B) could be enhanced to emerge powerful reasoning ability. Our project can be accessed at <a href=https://github.com/MetaEvo/ERO>https://github.com/MetaEvo/ERO</a> for reproduction needs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05760v1">üìÑ Download PDF</a></p><hr><h3 id=squeezing-classical-antiferromagnets-into-quantum-spin-liquids-via-global-cavity-fluctuationshttpsarxivorgabs251205630v1><a href=https://arxiv.org/abs/2512.05630v1>Squeezing Classical Antiferromagnets into Quantum Spin Liquids via Global Cavity Fluctuations</a><a hidden class=anchor aria-hidden=true href=#squeezing-classical-antiferromagnets-into-quantum-spin-liquids-via-global-cavity-fluctuationshttpsarxivorgabs251205630v1>#</a></h3><p><strong>Authors:</strong> Charlie-Ray Mann, Mark A. Oehlgrien, B≈Ça≈ºej Jaworowski, Giuseppe Calaj√≥, Jamir Marino, Kyung S. Choi, Darrick E. Chang
<strong>Venue:</strong> arXiv (2025)</p><p>Cavity quantum electrodynamics with atomic ensembles is typically associated with collective spin phenomena, such as superradiance and spin squeezing, in which the atoms evolve collectively as a macroscopic spin ($S\sim N/2$) on the Bloch sphere. Surprisingly, we show that the tendency toward a collective spin description need not imply collective spin phenomena; rather, it can be exploited to generate new forms of strongly correlated quantum matter. The key idea is to use uniform cavity-mediated interactions to energetically project the system into the total-spin singlet sector ($S=0$) - a highly entangled subspace where the physics is governed entirely by cavity fluctuations. Focusing on Rydberg atom arrays coupled to a single-mode cavity, we show that global cavity fluctuations can effectively squeeze classical antiferromagnets into quantum spin liquids, characterized by non-local entanglement, fractionalized excitations, and emergent gauge fields. This work suggests that cavity QED can be a surprising resource for inducing strongly correlated phenomena, which could be explored in the new generation of hybrid tweezer-cavity platforms.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05630v1">üìÑ Download PDF</a></p><hr><h3 id=anomaly-cancellation-and-one-loop-finiteness-of-6d-half-maximal-supergravitieshttpsarxivorgabs251205082v1><a href=https://arxiv.org/abs/2512.05082v1>Anomaly cancellation and one-loop finiteness of 6D half-maximal supergravities</a><a hidden class=anchor aria-hidden=true href=#anomaly-cancellation-and-one-loop-finiteness-of-6d-half-maximal-supergravitieshttpsarxivorgabs251205082v1>#</a></h3><p><strong>Authors:</strong> Renata Kallosh
<strong>Venue:</strong> arXiv (2025)</p><p>We explain why the surprising one-loop finiteness of 6D half-maximal supergravities recently discovered by Huang et al [1] is the result of the cancellation of the six-dimensional gravitational and gauge anomalies in (2,0) supergravity with 21 tensor multiplets and (1,1) supergravity with 20 vector multiplets.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05082v1">üìÑ Download PDF</a></p><hr><h3 id=an-elementary-approach-to-wehrl-type-entropy-bounds-in-quantitative-formhttpsarxivorgabs251204245v1><a href=https://arxiv.org/abs/2512.04245v1>An elementary approach to Wehrl-type entropy bounds in quantitative form</a><a hidden class=anchor aria-hidden=true href=#an-elementary-approach-to-wehrl-type-entropy-bounds-in-quantitative-formhttpsarxivorgabs251204245v1>#</a></h3><p><strong>Authors:</strong> Fabio Nicola, Federico Riccardi, Paolo Tilli
<strong>Venue:</strong> arXiv (2025)</p><p>We consider the problem of the stability (with sharp exponent) of the Lieb&ndash;Solovej inequality for symmetric $SU(N)$ coherent states, which was obtained only recently by the authors. Here, we propose an elementary proof of this result, based on reformulating the Wehrl-type entropy as a function defined on the unit sphere in $\mathbb{C}^d$, for some suitable $d$, and on some explicit (and somewhat surprising) computations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04245v1">üìÑ Download PDF</a></p><hr><h3 id=counting-ads-vacuahttpsarxivorgabs251204151v1><a href=https://arxiv.org/abs/2512.04151v1>Counting AdS Vacua</a><a hidden class=anchor aria-hidden=true href=#counting-ads-vacuahttpsarxivorgabs251204151v1>#</a></h3><p><strong>Authors:</strong> Zihni Kaan Baykara, Alessandro Tomasiello, Cumrun Vafa
<strong>Venue:</strong> arXiv (2025)</p><p>We study the &rsquo;number&rsquo; $\mathfrak{N}(Œº)$ of AdS vacua with a UV cut off $ Œº$. It has been proposed that this number is finite. We find evidence that $\mathfrak{N}(Œº)\lesssim a \ Œº^{-b}$ as $Œº\rightarrow 0$ for some constants $a$ and $b$ of $O(1)$ in Planck units that may depend on dimension and the number of supercharges. For this result to hold it is crucial to integrate over the volume of massless and tachyonic directions of AdS which corresponds to the volume of the space of marginal and relevant deformations of the dual CFT. We are led to the surprising prediction that theories with large number of light moduli contribute very little to the volume measure among all theories. We also speculate about the dS case leading to the number of quasi-dS vacua of the order of $Œõ^{-Œ±}$ for some $O(1)$ parameter $Œ±$.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04151v1">üìÑ Download PDF</a></p><hr><h3 id=structure-theorems-for-the-heart-of-lcahttpsarxivorgabs251203338v1><a href=https://arxiv.org/abs/2512.03338v1>Structure theorems for the heart of LCA</a><a hidden class=anchor aria-hidden=true href=#structure-theorems-for-the-heart-of-lcahttpsarxivorgabs251203338v1>#</a></h3><p><strong>Authors:</strong> Oliver Braunling, Fei Ren
<strong>Venue:</strong> arXiv (2025)</p><p>Cohomology theories with values in LCA (locally compact abelian) groups suffer from the problem that the latter do not form an abelian category. However, the category LCA has a canonical abelian category envelope, the heart of a suitable t-structure. It adds formal cokernel objects. We show the surprising result that these abstract cokernels can also be interpreted as Hausdorff topological abelian groups, at least up to lattice isogenies. These need not be locally compact.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03338v1">üìÑ Download PDF</a></p><hr><h3 id=group-classification-12-dimensional-linear-equation-of-asian-options-pricinghttpsarxivorgabs251205963v1><a href=https://arxiv.org/abs/2512.05963v1>Group Classification (1+2)-dimensional Linear Equation of Asian Options Pricing</a><a hidden class=anchor aria-hidden=true href=#group-classification-12-dimensional-linear-equation-of-asian-options-pricinghttpsarxivorgabs251205963v1>#</a></h3><p><strong>Authors:</strong> Stanislav V. Spichak, Valeriy I. Stogniy, Inna M. Kopas
<strong>Venue:</strong> arXiv (2025)</p><p>We consider a class of (1+2)-dimensional linear partial differential of Asian options pricing. Special cases have been used to models of financial mathematics. We carry out group classification of a class equations. In particular, the maximum dimension Lie invariance algebra within the above class is eight-dimensional. It is shown that an equation with such an algebra can be transformed into the linear Kolmogorov equation with the help of the point transformations of variables. Using the operators of invariance algebra symmetry reduction is carried out and invariant exact solutions are constructed for some equations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05963v1">üìÑ Download PDF</a></p><hr><h3 id=trusted-ai-agents-in-the-cloudhttpsarxivorgabs251205951v1><a href=https://arxiv.org/abs/2512.05951v1>Trusted AI Agents in the Cloud</a><a hidden class=anchor aria-hidden=true href=#trusted-ai-agents-in-the-cloudhttpsarxivorgabs251205951v1>#</a></h3><p><strong>Authors:</strong> Teofil Bodea, Masanori Misono, Julian Pritzi, Patrick Sabanic, Thore Sommer, Harshavardhan Unnibhavi, David Schall, Nuno Santos, Dimitrios Stavrakakis, Pramod Bhatotia
<strong>Venue:</strong> arXiv (2025)</p><p>AI agents powered by large language models are increasingly deployed as cloud services that autonomously access sensitive data, invoke external tools, and interact with other agents. However, these agents run within a complex multi-party ecosystem, where untrusted components can lead to data leakage, tampering, or unintended behavior. Existing Confidential Virtual Machines (CVMs) provide only per binary protection and offer no guarantees for cross-principal trust, accelerator-level isolation, or supervised agent behavior. We present Omega, a system that enables trusted AI agents by enforcing end-to-end isolation, establishing verifiable trust across all contributing principals, and supervising every external interaction with accountable provenance. Omega builds on Confidential VMs and Confidential GPUs to create a Trusted Agent Platform that hosts many agents within a single CVM using nested isolation. It also provides efficient multi-agent orchestration with cross-principal trust establishment via differential attestation, and a policy specification and enforcement framework that governs data access, tool usage, and inter-agent communication for data protection and regulatory compliance. Implemented on AMD SEV-SNP and NVIDIA H100, Omega fully secures agent state across CVM-GPU, and achieves high performance while enabling high-density, policy-compliant multi-agent deployments at cloud scale.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05951v1">üìÑ Download PDF</a></p><hr><h3 id=a-comparative-study-on-synthetic-facial-data-generation-techniques-for-face-recognitionhttpsarxivorgabs251205928v1><a href=https://arxiv.org/abs/2512.05928v1>A Comparative Study on Synthetic Facial Data Generation Techniques for Face Recognition</a><a hidden class=anchor aria-hidden=true href=#a-comparative-study-on-synthetic-facial-data-generation-techniques-for-face-recognitionhttpsarxivorgabs251205928v1>#</a></h3><p><strong>Authors:</strong> Pedro Vidal, Bernardo Biesseck, Luiz E. L. Coelho, Roger Granada, David Menotti
<strong>Venue:</strong> arXiv (2025)</p><p>Facial recognition has become a widely used method for authentication and identification, with applications for secure access and locating missing persons. Its success is largely attributed to deep learning, which leverages large datasets and effective loss functions to learn discriminative features. Despite these advances, facial recognition still faces challenges in explainability, demographic bias, privacy, and robustness to aging, pose variations, lighting changes, occlusions, and facial expressions. Privacy regulations have also led to the degradation of several datasets, raising legal, ethical, and privacy concerns. Synthetic facial data generation has been proposed as a promising solution. It mitigates privacy issues, enables experimentation with controlled facial attributes, alleviates demographic bias, and provides supplementary data to improve models trained on real data. This study compares the effectiveness of synthetic facial datasets generated using different techniques in facial recognition tasks. We evaluate accuracy, rank-1, rank-5, and the true positive rate at a false positive rate of 0.01% on eight leading datasets, offering a comparative analysis not extensively explored in the literature. Results demonstrate the ability of synthetic data to capture realistic variations while emphasizing the need for further research to close the performance gap with real data. Techniques such as diffusion models, GANs, and 3D models show substantial progress; however, challenges remain.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05928v1">üìÑ Download PDF</a></p><hr><h3 id=the-bayesian-way-uncertainty-learning-and-statistical-reasoninghttpsarxivorgabs251205883v1><a href=https://arxiv.org/abs/2512.05883v1>The Bayesian Way: Uncertainty, Learning, and Statistical Reasoning</a><a hidden class=anchor aria-hidden=true href=#the-bayesian-way-uncertainty-learning-and-statistical-reasoninghttpsarxivorgabs251205883v1>#</a></h3><p><strong>Authors:</strong> Juan Sosa, Carlos A. Mart√≠nez, Danna Cruz
<strong>Venue:</strong> arXiv (2025)</p><p>This paper offers a comprehensive introduction to Bayesian inference, combining historical context, theoretical foundations, and core analytical examples. Beginning with Bayes&rsquo; theorem and the philosophical distinctions between Bayesian and frequentist approaches, we develop the inferential framework for estimation, interval construction, hypothesis testing, and prediction. Through canonical models, we illustrate how prior information and observed data are formally integrated to yield posterior distributions. We also explore key concepts including loss functions, credible intervals, Bayes factors, identifiability, and asymptotic behavior. While emphasizing analytical tractability in classical settings, we outline modern extensions that rely on simulation-based methods and discuss challenges related to prior specification and model evaluation. Though focused on foundational ideas, this paper sets the stage for applying Bayesian methods in contemporary domains such as hierarchical modeling, nonparametrics, and structured applications in time series, spatial data, networks, and political science. The goal is to provide a rigorous yet accessible entry point for students and researchers seeking to adopt a Bayesian perspective in statistical practice.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05883v1">üìÑ Download PDF</a></p><hr><h3 id=ug-fedda-uncertainty-guided-federated-domain-adaptation-for-multi-center-alzheimers-disease-detectionhttpsarxivorgabs251205814v1><a href=https://arxiv.org/abs/2512.05814v1>UG-FedDA: Uncertainty-Guided Federated Domain Adaptation for Multi-Center Alzheimer&rsquo;s Disease Detection</a><a hidden class=anchor aria-hidden=true href=#ug-fedda-uncertainty-guided-federated-domain-adaptation-for-multi-center-alzheimers-disease-detectionhttpsarxivorgabs251205814v1>#</a></h3><p><strong>Authors:</strong> Fubao Zhu, Zhanyuan Jia, Zhiguo Wang, Huan Huang, Danyang Sun, Chuang Han, Yanting Li, Jiaofen Nan, Chen Zhao, Weihua Zhou
<strong>Venue:</strong> arXiv (2025)</p><p>Alzheimer&rsquo;s disease (AD) is an irreversible neurodegenerative disorder, and early diagnosis is critical for timely intervention. However, most existing classification frameworks face challenges in multicenter studies, as they often neglect inter-site heterogeneity and lack mechanisms to quantify uncertainty, which limits their robustness and clinical applicability. To address these issues, we proposed Uncertainty-Guided Federated Domain Adaptation (UG-FedDA), a novel multicenter AD classification framework that integrates uncertainty quantification (UQ) with federated domain adaptation to handle cross-site structure magnetic resonance imaging (MRI) heterogeneity under privacy constraints. Our approach extracts multi-template region-of-interest (RoI) features using a self-attention transformer, capturing both regional representations and their interactions. UQ is integrated to guide feature alignment, mitigating source-target distribution shifts by down-weighting uncertain samples. Experiments are conducted on three public datasets: the Alzheimer&rsquo;s Disease Neuroimaging Initiative (ADNI), the Australian Imaging, Biomarkers and Lifestyle study (AIBL), and the Open Access Series of Imaging Studies (OASIS). UG-FedDA achieved consistent cross-domain improvements in accuracy, sensitivity, and area under the ROC curve across three classification tasks: AD vs. normal controls (NC), mild cognitive impairment (MCI) vs. AD, and NC vs. MCI. For NC vs. AD, UG-FedDA achieves accuracies of 90.54%, 89.04%, and 77.78% on ADNI, AIBL and OASIS datasets, respectively. For MCI vs. AD, accuracies are 80.20% (ADNI), 71.91% (AIBL), and 79.73% (OASIS). For NC vs. MCI, results are 76.87% (ADNI), 73.91% (AIBL), and 83.73% (OASIS). These results demonstrate that the proposed framework not only adapts efficiently across multiple sites but also preserves strict privacy.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05814v1">üìÑ Download PDF</a></p><hr><h3 id=speech-world-model-causal-state-action-planning-with-explicit-reasoning-for-speechhttpsarxivorgabs251205933v1><a href=https://arxiv.org/abs/2512.05933v1>Speech World Model: Causal State-Action Planning with Explicit Reasoning for Speech</a><a hidden class=anchor aria-hidden=true href=#speech-world-model-causal-state-action-planning-with-explicit-reasoning-for-speechhttpsarxivorgabs251205933v1>#</a></h3><p><strong>Authors:</strong> Xuanru Zhou, Jiachen Lian, Henry Hong, Xinyi Yang, Gopala Anumanchipalli
<strong>Venue:</strong> arXiv (2025)</p><p>Current speech-language models (SLMs) typically use a cascade of speech encoder and large language model, treating speech understanding as a single black box. They analyze the content of speech well but reason weakly about other aspects, especially under sparse supervision. Thus, we argue for explicit reasoning over speech states and actions with modular and transparent decisions. Inspired by cognitive science we adopt a modular perspective and a world model view in which the system learns forward dynamics over latent states. We factorize speech understanding into four modules that communicate through a causal graph, establishing a cognitive state search space. Guided by posterior traces from this space, an instruction-tuned language model produces a concise causal analysis and a user-facing response, enabling counterfactual interventions and interpretability under partial supervision. We present the first graph based modular speech model for explicit reasoning and we will open source the model and data to promote the development of advanced speech understanding.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05933v1">üìÑ Download PDF</a></p><hr><h3 id=a-hybrid-dynamic-model-for-predicting-human-cognition-and-reliance-during-automated-drivinghttpsarxivorgabs251205845v1><a href=https://arxiv.org/abs/2512.05845v1>A Hybrid Dynamic Model for Predicting Human Cognition and Reliance during Automated Driving</a><a hidden class=anchor aria-hidden=true href=#a-hybrid-dynamic-model-for-predicting-human-cognition-and-reliance-during-automated-drivinghttpsarxivorgabs251205845v1>#</a></h3><p><strong>Authors:</strong> Sibibalan Jeevanandam, Neera Jain
<strong>Venue:</strong> arXiv (2025)</p><p>We propose a simple (12 parameter) hybrid dynamic model that simultaneously captures the continuous-valued dynamics of three human cognitive states-trust, perceived risk, and mental workload-as well as discrete transitions in reliance on the automation. The discrete-time dynamic evolution of each cognitive state is modeled using a first-order affine difference equation. Reliance is defined as a single discrete-valued state, whose evolution at each time step depends on the cognitive states satisfying certain threshold conditions. Using data collected from 16 participants, we estimate participant-specific model parameters based on their reliance on the automation and intermittently self-reported cognitive states during a continuous drive in a vehicle simulator. The model can be estimated using a single user&rsquo;s trajectory data (e.g. 8 minutes of driving), making it suitable for online parameter adaptation methods. Our results show that the model fits the observed trajectories well for several participants, with their reliance behavior primarily influenced by trust, perceived risk, or both. Importantly, the model is interpretable, such that the variations in model parameters across participants provide insights into differences in the time scales over which cognitive states evolve, and how these states are influenced by task complexity. Implications on the design of human-centric vehicle automation design are discussed.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05845v1">üìÑ Download PDF</a></p><hr><h3 id=a-fast-anti-jamming-cognitive-radar-deployment-algorithm-based-on-reinforcement-learninghttpsarxivorgabs251205753v1><a href=https://arxiv.org/abs/2512.05753v1>A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning</a><a hidden class=anchor aria-hidden=true href=#a-fast-anti-jamming-cognitive-radar-deployment-algorithm-based-on-reinforcement-learninghttpsarxivorgabs251205753v1>#</a></h3><p><strong>Authors:</strong> Wencheng Cai, Xuchao Gao, Congying Han, Mingqiang Li, Tiande Guo
<strong>Venue:</strong> arXiv (2025)</p><p>The fast deployment of cognitive radar to counter jamming remains a critical challenge in modern warfare, where more efficient deployment leads to quicker detection of targets. Existing methods are primarily based on evolutionary algorithms, which are time-consuming and prone to falling into local optima. We tackle these drawbacks via the efficient inference of neural networks and propose a brand new framework: Fast Anti-Jamming Radar Deployment Algorithm (FARDA). We first model the radar deployment problem as an end-to-end task and design deep reinforcement learning algorithms to solve it, where we develop integrated neural modules to perceive heatmap information and a brand new reward format. Empirical results demonstrate that our method achieves coverage comparable to evolutionary algorithms while deploying radars approximately 7,000 times faster. Further ablation experiments confirm the necessity of each component of FARDA.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05753v1">üìÑ Download PDF</a></p><hr><h3 id=emergence-of-language-in-the-developing-brainhttpsarxivorgabs251205718v1><a href=https://arxiv.org/abs/2512.05718v1>Emergence of Language in the Developing Brain</a><a hidden class=anchor aria-hidden=true href=#emergence-of-language-in-the-developing-brainhttpsarxivorgabs251205718v1>#</a></h3><p><strong>Authors:</strong> Linnea Evanson, Christine Bulteau, Mathilde Chipaux, Georg Dorfm√ºller, Sarah Ferrand-Sorbets, Emmanuel Raffo, Sarah Rosenberg, Pierre Bourdillon, Jean-R√©mi King
<strong>Venue:</strong> arXiv (2025)</p><p>A few million words suffice for children to acquire language. Yet, the brain mechanisms underlying this unique ability remain poorly understood. To address this issue, we investigate neural activity recorded from over 7,400 electrodes implanted in the brains of 46 children, teenagers, and adults for epilepsy monitoring, as they listened to an audiobook version of &ldquo;The Little Prince&rdquo;. We then train neural encoding and decoding models using representations, derived either from linguistic theory or from large language models, to map the location, dynamics and development of the language hierarchy in the brain. We find that a broad range of linguistic features is robustly represented across the cortex, even in 2-5-year-olds. Crucially, these representations evolve with age: while fast phonetic features are already present in the superior temporal gyrus of the youngest individuals, slower word-level representations only emerge in the associative cortices of older individuals. Remarkably, this neuro-developmental trajectory is spontaneously captured by large language models: with training, these AI models learned representations that can only be identified in the adult human brain. Together, these findings reveal the maturation of language representations in the developing brain and show that modern AI systems provide a promising tool to model the neural bases of language acquisition.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05718v1">üìÑ Download PDF</a></p><hr><h3 id=instructmpc-a-human-llm-in-the-loop-framework-for-context-aware-power-grid-controlhttpsarxivorgabs251205876v1><a href=https://arxiv.org/abs/2512.05876v1>InstructMPC: A Human-LLM-in-the-Loop Framework for Context-Aware Power Grid Control</a><a hidden class=anchor aria-hidden=true href=#instructmpc-a-human-llm-in-the-loop-framework-for-context-aware-power-grid-controlhttpsarxivorgabs251205876v1>#</a></h3><p><strong>Authors:</strong> Ruixiang Wu, Jiahao Ai, Tinko Sebastian Bartels
<strong>Venue:</strong> arXiv (2025)</p><p>The transition toward power grids with high renewable penetration demands context-aware decision making frameworks. Traditional operational paradigms, which rely on static optimization of history-based load forecasting, often fail to capture the complex nature of real-time operational conditions, such as operator-issued maintenance mandates, emergency topology changes, or event-driven load surges. To address this challenge, we introduce InstructMPC, a closed-loop framework that integrates Large Language Models~(LLMs) to generate context-aware predictions, enabling the controller to optimize power system operation. Our method employs a Contextual Disturbances Predictor~(CDP) module to translate contextual information into predictive disturbance trajectories, which are then incorporated into the Model Predictive Control~(MPC) optimization. Unlike conventional open-loop forecasting frameworks, InstructMPC features an online tuning mechanism where the predictor&rsquo;s parameters are continuously updated based on the realized control cost with a theoretical guarantee, achieving a regret bound of $O(\sqrt{T \log T})$ for linear dynamics when optimized via a tailored loss function, ensuring task-aware learning and adaption to non-stationary grid conditions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05876v1">üìÑ Download PDF</a></p><hr><h3 id=machine-learning-enabled-interpretation-of-tribological-deformation-patterns-in-large-scale-md-datahttpsarxivorgabs251205818v1><a href=https://arxiv.org/abs/2512.05818v1>Machine-learning-enabled interpretation of tribological deformation patterns in large-scale MD data</a><a hidden class=anchor aria-hidden=true href=#machine-learning-enabled-interpretation-of-tribological-deformation-patterns-in-large-scale-md-datahttpsarxivorgabs251205818v1>#</a></h3><p><strong>Authors:</strong> Hendrik J. Ehrich, Marvin C. May, Stefan J. Eder
<strong>Venue:</strong> arXiv (2025)</p><p>Molecular dynamics (MD) simulations have become indispensable for exploring tribological deformation patterns at the atomic scale. However, transforming the resulting high-dimensional data into interpretable deformation pattern maps remains a resource-intensive and largely manual process. In this work, we introduce a data-driven workflow that automates this interpretation step using unsupervised and supervised learning. Grain-orientation-colored computational tomograph pictures obtained from CuNi alloy simulations were first compressed through an autoencoder to a 32-dimensional global feature vector. Despite this strong compression, the reconstructed images retained the essential microstructural motifs: grain boundaries, stacking faults, twins, and partial lattice rotations, while omitting only the finest defects. The learned representations were then combined with simulation metadata (composition, load, time, temperature, and spatial position) to train a CNN-MLP model to predict the dominant deformation pattern. The resulting model achieves a prediction accuracy of approximately 96% on validation data. A refined evaluation strategy, in which an entire spatial region containing distinct grains was excluded from training, provides a more robust measure of generalization. The approach demonstrates that essential tribological deformation signatures can be automatically identified and classified from structural images using Machine Learning. This proof of concept constitutes a first step towards fully automated, data-driven construction of tribological mechanism maps and, ultimately, toward predictive modeling frameworks that may reduce the need for large-scale MD simulation campaigns.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05818v1">üìÑ Download PDF</a></p><hr><h2 id=-llm>üîç llm<a hidden class=anchor aria-hidden=true href=#-llm>#</a></h2><h3 id=transformation-of-orientation-and-rotation-angles-of-synchronous-satellites-application-to-the-galilean-moonshttpsarxivorgabs251205935v1><a href=https://arxiv.org/abs/2512.05935v1>Transformation of orientation and rotation angles of synchronous satellites: Application to the Galilean moons</a><a hidden class=anchor aria-hidden=true href=#transformation-of-orientation-and-rotation-angles-of-synchronous-satellites-application-to-the-galilean-moonshttpsarxivorgabs251205935v1>#</a></h3><p><strong>Authors:</strong> Marie Yseboodt, Rose-Marie Baland
<strong>Venue:</strong> arXiv (2025)</p><p>The orientation and rotation of a synchronous satellite can be referred to both its Laplace plane and the ICRF equatorial plane, in terms of Euler angles or spin axis Cartesian coordinates and Earth equatorial coordinates, respectively. We computed second-order analytical expressions to make the transformation between the two systems and applied them to the Galilean satellites (Io, Europa, Ganymede, and Callisto). If one term of the spin axis Cartesian coordinates series is dominant, trigonometric series can be generated for the inertial and orbital obliquities, node longitude and offset with respect to the Cassini plane. Since the transformation does not require any fit of amplitudes and frequencies on numerical series, the physical meaning of the frequencies is preserved from the input series and the amplitudes can be directly related to the geophysical parameters of interest. We provide tables for the coordinates and angles&rsquo; series assuming that the satellites are entirely solid, and considering two different orbital theories. The possible amplitude ranges for the main terms are also examined in the case where a liquid layer is assumed in the interior model. We use our transformation method to propose an updated IAU WG solution which would result in an improvement with respect to zero obliquity models used so far. This method will also be useful for the interpretation of future Earth-based radar observations or JUICE data.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05935v1">üìÑ Download PDF</a></p><hr><h3 id=kq-svd-compressing-the-kv-cache-with-provable-guarantees-on-attention-fidelityhttpsarxivorgabs251205916v1><a href=https://arxiv.org/abs/2512.05916v1>KQ-SVD: Compressing the KV Cache with Provable Guarantees on Attention Fidelity</a><a hidden class=anchor aria-hidden=true href=#kq-svd-compressing-the-kv-cache-with-provable-guarantees-on-attention-fidelityhttpsarxivorgabs251205916v1>#</a></h3><p><strong>Authors:</strong> Damien Lesens, Beheshteh T. Rakhshan, Guillaume Rabusseau
<strong>Venue:</strong> arXiv (2025)</p><p>The Key-Value (KV) cache is central to the efficiency of transformer-based large language models (LLMs), storing previously computed vectors to accelerate inference. Yet, as sequence length and batch size grow, the cache becomes a major memory bottleneck. Prior compression methods typically apply low-rank decomposition to keys alone or attempt to jointly embed queries and keys, but both approaches neglect that attention fundamentally depends on their inner products. In this work, we prove that such strategies are suboptimal for approximating the attention matrix. We introduce KQ-SVD, a simple and computationally efficient method that directly performs an optimal low-rank decomposition of the attention matrix via a closed-form solution. By targeting the true source of redundancy, KQ-SVD preserves attention outputs with higher fidelity under compression. Extensive evaluations on LLaMA and Mistral models demonstrate that our approach consistently delivers superior projection quality.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05916v1">üìÑ Download PDF</a></p><hr><h3 id=differentially-rotating-neutron-stars-with-dark-matter-coreshttpsarxivorgabs251205898v1><a href=https://arxiv.org/abs/2512.05898v1>Differentially rotating neutron stars with dark matter cores</a><a hidden class=anchor aria-hidden=true href=#differentially-rotating-neutron-stars-with-dark-matter-coreshttpsarxivorgabs251205898v1>#</a></h3><p><strong>Authors:</strong> Lorenzo Cipriani, Violetta Sagun, Kalin V. Staykov, Daniela D. Doneva, Stoytcho S. Yazadjiev
<strong>Venue:</strong> arXiv (2025)</p><p>Dark matter is expected to accumulate inside neutron stars, modifying the structure of isolated stars and influencing both the dynamics of binary mergers and the evolution of the resulting hypermassive remnants. Since differential rotation is the primary mechanism delaying the collapse of these remnants, understanding its behavior is crucial when assessing the impact of an embedded dark component. In this work, we extend the numerical code RNS to describe two gravitationally coupled fluids in differential rotation, with baryonic matter modeled by a realistic nuclear equation of state and dark matter represented as a self-interacting bosonic condensate. Within this framework, we construct equilibrium sequences for a representative differential rotation law, providing a basis to explore how dark matter may influence the global properties and rotational dynamics of binary neutron star remnants.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05898v1">üìÑ Download PDF</a></p><hr><h3 id=log-linear-dynamic-inversion-for-thrusting-spacecraft-on-se23httpsarxivorgabs251205888v1><a href=https://arxiv.org/abs/2512.05888v1>Log-linear Dynamic Inversion for Thrusting Spacecraft on SE2(3)</a><a hidden class=anchor aria-hidden=true href=#log-linear-dynamic-inversion-for-thrusting-spacecraft-on-se23httpsarxivorgabs251205888v1>#</a></h3><p><strong>Authors:</strong> Micah K. Condie, Abigaile E. Woodbury, Li-Yu Lin, Kartik A. Pant, Mike Walker, James Goppert
<strong>Venue:</strong> arXiv (2025)</p><p>We show that the dynamics of a thrusting spacecraft can be embedded in the Lie group SE2(3) in a form that is group-affine with application of a feed-forward control law. This structure implies that the configuration-tracking error evolves exactly linearly in the associated Lie algebra coordinates (log-linear dynamics), rather than arising from a local linearization of the nonlinear system. As a result, a broad class of linear analysis and synthesis tools becomes directly applicable to powered spacecraft motion on SE2(3). A simple numerical example confirms that the error predicted by the linear Lie-algebra dynamics matches the error computed from the full nonlinear system, illustrating the exact log-linear behavior. This foundational property opens a path toward rigorous tools for satellite docking, autonomous rendezvous and proximity operations, robust controller design, and convex safety certification-capabilities that are difficult to achieve with classical local linearizations such as Tschauner-Hempel/Yamanaka-Ankersen (TH/YA).</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05888v1">üìÑ Download PDF</a></p><hr><h2 id=-neuroscience>üîç neuroscience<a hidden class=anchor aria-hidden=true href=#-neuroscience>#</a></h2><h3 id=zoom-in-click-out-unlocking-and-evaluating-the-potential-of-zooming-for-gui-groundinghttpsarxivorgabs251205941v1><a href=https://arxiv.org/abs/2512.05941v1>Zoom in, Click out: Unlocking and Evaluating the Potential of Zooming for GUI Grounding</a><a hidden class=anchor aria-hidden=true href=#zoom-in-click-out-unlocking-and-evaluating-the-potential-of-zooming-for-gui-groundinghttpsarxivorgabs251205941v1>#</a></h3><p><strong>Authors:</strong> Zhiyuan Jiang, Shenghao Xie, Wenyi Li, Wenqiang Zu, Peihang Li, Jiahao Qiu, Siqi Pei, Lei Ma, Tiejun Huang, Mengdi Wang, Shilong Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Grounding is a fundamental capability for building graphical user interface (GUI) agents. Although existing approaches rely on large-scale bounding box supervision, they still face various challenges, such as cross-platform generalization, complex layout analysis, and fine-grained element localization. In this paper, we investigate zoom as a strong yet underexplored prior for GUI grounding, and propose a training-free method, ZoomClick. By characterizing four key properties of zoom (i.e., pre-zoom, depth, shrink size, minimal crop size), we unlock its full capabilities for dynamic spatial focusing and adaptive context switching. Experiments demonstrate that our method significantly boosts the performance of both general vision-language and specialized GUI grounding models, achieving state-of-the-art results on several mainstream benchmarks; for example, UI-Venus-72B attains a 73.1% success rate on ScreenSpot-Pro. Furthermore, we present GUIZoom-Bench, a benchmark for evaluating model adaptability to zoom, aiming to inspire future research on improving zoom for further training and test-time scaling in GUI grounding tasks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05941v1">üìÑ Download PDF</a></p><hr><h3 id=a-continuous-nonlinear-optimization-perspective-on-the-spin-glass-problemhttpsarxivorgabs251205852v1><a href=https://arxiv.org/abs/2512.05852v1>A Continuous Nonlinear Optimization Perspective on the Spin Glass Problem</a><a hidden class=anchor aria-hidden=true href=#a-continuous-nonlinear-optimization-perspective-on-the-spin-glass-problemhttpsarxivorgabs251205852v1>#</a></h3><p><strong>Authors:</strong> Phil Duxbury, Carlile Lavor, Luiz Leduino de Salles-Neto
<strong>Venue:</strong> arXiv (2025)</p><p>We present a continuous nonlinear optimization model for the Spin Glass Problem (SGP), building on a classical result by Rosenberg (1972), which shows that for a class of multilinear polynomial problems the optimal values of the continuous relaxation and the corresponding discrete model coincide. Using the SGP as a case study, we provide a simple, problem-specific argument showing how any optimal solution returned by a continuous solver can be converted into an optimal discrete spin configuration, even when the solver outputs non-integer values. The relaxed model remains nonconvex and does not alter the inherent computational hardness of the problem, but it offers a direct and conceptually transparent continuous formulation that can be handled by modern global optimization software. Computational experiments on standard benchmark instances indicate that this approach can match, and in several cases surpass, recent integer programming linearization techniques, making it a practical and complementary tool for researchers working at the interface between statistical physics and combinatorial optimization.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05852v1">üìÑ Download PDF</a></p><hr><h3 id=superconformal-interfaces-from-5d-n4-gauged-supergravityhttpsarxivorgabs251205805v1><a href=https://arxiv.org/abs/2512.05805v1>Superconformal interfaces from 5D N=4 gauged supergravity</a><a hidden class=anchor aria-hidden=true href=#superconformal-interfaces-from-5d-n4-gauged-supergravityhttpsarxivorgabs251205805v1>#</a></h3><p><strong>Authors:</strong> Parinya Karndumri
<strong>Venue:</strong> arXiv (2025)</p><p>We find a large class of new supersymmetric Janus solutions from five-dimensional $N=4$ gauged supergravity coupled to five vector multiplets with $SO(2)<em>D\times SO(3)\times SO(3)$ gauge group. The gauged supergravity admits four supersymmetric $AdS_5$ vacua, two $N=4$ with $SO(2)<em>D\times SO(3)\times SO(3)$ and $SO(2)<em>D\times SO(3)</em>{\textrm{diag}}$ symmetric $AdS_5$ vacua and two $N=2$ with $SO(2)</em>{\textrm{diag}}\times SO(3)$ and $SO(2)</em>{\textrm{diag}}$ symmetric ones. In a truncation to three vector multiplets, the gauge group is given by $SO(2)\times SO(3)\times SO(3)$, and the resulting gauged supergravity admits only two $N=4$ supersymmetric $AdS_5$ vacua with $SO(2)\times SO(3)\times SO(3)$ and $SO(2)\times SO(3)<em>{\textrm{diag}}$ residual symmetries. By considering the $SO(2)</em>{\textrm{diag}}$ invariant sector within this truncation, we find a number of supersymetric Janus interfaces between the two $N=4$ vacua on both sides as well as an RG-flow interface between $SO(2)\times SO(3)\times SO(3)$ and $SO(2)\times SO(3)_{\textrm{diag}}$ symmetric vacua on each side. By repeating the analysis in the full $SO(2)_D\times SO(3)\times SO(3)$ gauged supergravity, we find Janus solutions interpolating between the aforementioned four supersymmetric $AdS_5$ vacua as well as examples of multi-Janus interfaces between these vacua.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05805v1">üìÑ Download PDF</a></p><hr><h3 id=a-multi-channel-auditory-signal-encoder-with-adaptive-resolution-using-volatile-memristorshttpsarxivorgabs251205701v1><a href=https://arxiv.org/abs/2512.05701v1>A Multi-Channel Auditory Signal Encoder with Adaptive Resolution Using Volatile Memristors</a><a hidden class=anchor aria-hidden=true href=#a-multi-channel-auditory-signal-encoder-with-adaptive-resolution-using-volatile-memristorshttpsarxivorgabs251205701v1>#</a></h3><p><strong>Authors:</strong> Dongxu Guo, Deepika Yadav, Patrick Foster, Spyros Stathopoulos, Mingyi Chen, Themis Prodromakis, Shiwei Wang
<strong>Venue:</strong> arXiv (2025)</p><p>We demonstrate and experimentally validate an end-to-end hybrid CMOS-memristor auditory encoder that realises adaptive-threshold, asynchronous delta-modulation (ADM)-based spike encoding by exploiting the inherent volatility of HfTiOx devices. A spike-triggered programming pulse rapidly raises the ADM threshold Delta (desensitisation); the device&rsquo;s volatility then passively lowers Delta when activity subsides (resensitisation), emphasising onsets while restoring sensitivity without static control energy. Our prototype couples an 8-channel 130 nm encoder IC to off-chip HfTiOx devices via a switch interface and an off-chip controller that monitors spike activity and issues programming events. An on-chip current-mirror transimpedance amplifier (TIA) converts device current into symmetric thresholds, enabling both sensitive and conservative encoding regimes. Evaluated with gammatone-filtered speech, the adaptive loop-at matched spike budget-sharpens onsets and preserves fine temporal detail that a fixed-Delta baseline misses; multi-channel spike cochleagrams show the same trend. Together, these results establish a practical hybrid CMOS-memristor pathway to onset-salient, spike-efficient neuromorphic audio front-ends and motivate low-power single-chip integration.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05701v1">üìÑ Download PDF</a></p><hr><h2 id=-data_resources>üîç data_resources<a hidden class=anchor aria-hidden=true href=#-data_resources>#</a></h2><h3 id=designing-an-optimal-sensor-network-via-minimizing-information-losshttpsarxivorgabs251205940v1><a href=https://arxiv.org/abs/2512.05940v1>Designing an Optimal Sensor Network via Minimizing Information Loss</a><a hidden class=anchor aria-hidden=true href=#designing-an-optimal-sensor-network-via-minimizing-information-losshttpsarxivorgabs251205940v1>#</a></h3><p><strong>Authors:</strong> Daniel Waxman, Fernando Llorente, Katia Lamer, Petar M. Djuriƒá
<strong>Venue:</strong> arXiv (2025)</p><p>Optimal experimental design is a classic topic in statistics, with many well-studied problems, applications, and solutions. The design problem we study is the placement of sensors to monitor spatiotemporal processes, explicitly accounting for the temporal dimension in our modeling and optimization. We observe that recent advancements in computational sciences often yield large datasets based on physics-based simulations, which are rarely leveraged in experimental design. We introduce a novel model-based sensor placement criterion, along with a highly-efficient optimization algorithm, which integrates physics-based simulations and Bayesian experimental design principles to identify sensor networks that &ldquo;minimize information loss&rdquo; from simulated data. Our technique relies on sparse variational inference and (separable) Gauss-Markov priors, and thus may adapt many techniques from Bayesian experimental design. We validate our method through a case study monitoring air temperature in Phoenix, Arizona, using state-of-the-art physics-based simulations. Our results show our framework to be superior to random or quasi-random sampling, particularly with a limited number of sensors. We conclude by discussing practical considerations and implications of our framework, including more complex modeling tools and real-world deployments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05940v1">üìÑ Download PDF</a></p><hr><h3 id=a-greek-government-decisions-dataset-for-public-sector-analysis-and-insighthttpsarxivorgabs251205647v1><a href=https://arxiv.org/abs/2512.05647v1>A Greek Government Decisions Dataset for Public-Sector Analysis and Insight</a><a hidden class=anchor aria-hidden=true href=#a-greek-government-decisions-dataset-for-public-sector-analysis-and-insighthttpsarxivorgabs251205647v1>#</a></h3><p><strong>Authors:</strong> Giorgos Antoniou, Giorgos Filandrianos, Aggelos Vlachos, Giorgos Stamou, Lampros Kollimenos, Konstantinos Skianis, Michalis Vazirgiannis
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce an open, machine-readable corpus of Greek government decisions sourced from the national transparency platform Diavgeia. The resource comprises 1 million decisions, featuring and high-quality raw text extracted from PDFs. It is released with raw extracted text in Markdown format, alongside a fully reproducible extraction pipeline. Beyond the core dataset, we conduct qualitative analyses to explore boilerplate patterns and design a retrieval-augmented generation (RAG) task by formulating a set of representative questions, creating high-quality answers, and evaluating a baseline RAG system on its ability to retrieve and reason over public decisions. This evaluation demonstrates the potential of large-scale public-sector corpora to support advanced information access and transparency through structured retrieval and reasoning over governmental documents, and highlights how such a RAG pipeline could simulate a chat-based assistant capable of interactively answering questions about public decisions. Due to its scale, quality, and domain coverage, the corpus can also serve as high-value pre-training or fine-tuning material for new Language Models (LMs) and Large Language Models (LLMs) respectively, including specialized models for legal and governmental domains, and as a foundation for novel approaches in domain adaptation, knowledge-grounded generation, and explainable AI. Finally, we discuss limitations, outline future directions, and make both the data and the code accessible.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05647v1">üìÑ Download PDF</a></p><hr><h3 id=using-large-language-models-to-create-personalized-networks-from-therapy-sessionshttpsarxivorgabs251205836v1><a href=https://arxiv.org/abs/2512.05836v1>Using Large Language Models to Create Personalized Networks From Therapy Sessions</a><a hidden class=anchor aria-hidden=true href=#using-large-language-models-to-create-personalized-networks-from-therapy-sessionshttpsarxivorgabs251205836v1>#</a></h3><p><strong>Authors:</strong> Clarissa W. Ong, Hiba Arnaout, Kate Sheehan, Estella Fox, Eugen Owtscharow, Iryna Gurevych
<strong>Venue:</strong> arXiv (2025)</p><p>Recent advances in psychotherapy have focused on treatment personalization, such as by selecting treatment modules based on personalized networks. However, estimating personalized networks typically requires intensive longitudinal data, which is not always feasible. A solution to facilitate scalability of network-driven treatment personalization is leveraging LLMs. In this study, we present an end-to-end pipeline for automatically generating client networks from 77 therapy transcripts to support case conceptualization and treatment planning. We annotated 3364 psychological processes and their corresponding dimensions in therapy transcripts. Using these data, we applied in-context learning to jointly identify psychological processes and their dimensions. The method achieved high performance even with a few training examples. To organize the processes into networks, we introduced a two-step method that grouped them into clinically meaningful clusters. We then generated explanation-augmented relationships between clusters. Experts found that networks produced by our multi-step approach outperformed those built with direct prompting for clinical utility and interpretability, with up to 90% preferring our approach. In addition, the networks were rated favorably by experts, with scores for clinical relevance, novelty, and usefulness ranging from 72-75%. Our findings provide a proof of concept for using LLMs to create clinically relevant networks from therapy transcripts. Advantages of our approach include bottom-up case conceptualization from client utterances in therapy sessions and identification of latent themes. Networks generated from our pipeline may be used in clinical settings and supervision and training. Future research should examine whether these networks improve treatment outcomes relative to other methods of treatment personalization, including statistically estimated networks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05836v1">üìÑ Download PDF</a></p><hr><h3 id=label-efficient-point-cloud-segmentation-with-active-learninghttpsarxivorgabs251205759v1><a href=https://arxiv.org/abs/2512.05759v1>Label-Efficient Point Cloud Segmentation with Active Learning</a><a hidden class=anchor aria-hidden=true href=#label-efficient-point-cloud-segmentation-with-active-learninghttpsarxivorgabs251205759v1>#</a></h3><p><strong>Authors:</strong> Johannes Meyer, Jasper Hoffmann, Felix Schulz, Dominik Merkle, Daniel Buescher, Alexander Reiterer, Joschka Boedecker, Wolfram Burgard
<strong>Venue:</strong> arXiv (2025)</p><p>Semantic segmentation of 3D point cloud data often comes with high annotation costs. Active learning automates the process of selecting which data to annotate, reducing the total amount of annotation needed to achieve satisfactory performance. Recent approaches to active learning for 3D point clouds are often based on sophisticated heuristics for both, splitting point clouds into annotatable regions and selecting the most beneficial for further neural network training. In this work, we propose a novel and easy-to-implement strategy to separate the point cloud into annotatable regions. In our approach, we utilize a 2D grid to subdivide the point cloud into columns. To identify the next data to be annotated, we employ a network ensemble to estimate the uncertainty in the network output. We evaluate our method on the S3DIS dataset, the Toronto-3D dataset, and a large-scale urban 3D point cloud of the city of Freiburg, which we labeled in parts manually. The extensive evaluation shows that our method yields performance on par with, or even better than, complex state-of-the-art methods on all datasets. Furthermore, we provide results suggesting that in the context of point clouds the annotated area can be a more meaningful measure for active learning algorithms than the number of annotated points.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05759v1">üìÑ Download PDF</a></p><hr><h3 id=owl-unsupervised-3d-object-detection-by-occupancy-guided-warm-up-and-large-model-priors-reasoninghttpsarxivorgabs251205698v1><a href=https://arxiv.org/abs/2512.05698v1>OWL: Unsupervised 3D Object Detection by Occupancy Guided Warm-up and Large Model Priors Reasoning</a><a hidden class=anchor aria-hidden=true href=#owl-unsupervised-3d-object-detection-by-occupancy-guided-warm-up-and-large-model-priors-reasoninghttpsarxivorgabs251205698v1>#</a></h3><p><strong>Authors:</strong> Xusheng Guo, Wanfa Zhang, Shijia Zhao, Qiming Xia, Xiaolong Xie, Mingming Wang, Hai Wu, Chenglu Wen
<strong>Venue:</strong> arXiv (2025)</p><p>Unsupervised 3D object detection leverages heuristic algorithms to discover potential objects, offering a promising route to reduce annotation costs in autonomous driving. Existing approaches mainly generate pseudo labels and refine them through self-training iterations. However, these pseudo-labels are often incorrect at the beginning of training, resulting in misleading the optimization process. Moreover, effectively filtering and refining them remains a critical challenge. In this paper, we propose OWL for unsupervised 3D object detection by occupancy guided warm-up and large-model priors reasoning. OWL first employs an Occupancy Guided Warm-up (OGW) strategy to initialize the backbone weight with spatial perception capabilities, mitigating the interference of incorrect pseudo-labels on network convergence. Furthermore, OWL introduces an Instance-Cued Reasoning (ICR) module that leverages the prior knowledge of large models to assess pseudo-label quality, enabling precise filtering and refinement. Finally, we design a Weight-adapted Self-training (WAS) strategy to dynamically re-weight pseudo-labels, improving the performance through self-training. Extensive experiments on Waymo Open Dataset (WOD) and KITTI demonstrate that OWL outperforms state-of-the-art unsupervised methods by over 15.0% mAP, revealing the effectiveness of our method.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05698v1">üìÑ Download PDF</a></p><hr><h3 id=distillfss-synthesizing-few-shot-knowledge-into-a-lightweight-segmentation-modelhttpsarxivorgabs251205613v1><a href=https://arxiv.org/abs/2512.05613v1>DistillFSS: Synthesizing Few-Shot Knowledge into a Lightweight Segmentation Model</a><a hidden class=anchor aria-hidden=true href=#distillfss-synthesizing-few-shot-knowledge-into-a-lightweight-segmentation-modelhttpsarxivorgabs251205613v1>#</a></h3><p><strong>Authors:</strong> Pasquale De Marinis, Pieter M. Blok, Uzay Kaymak, Rogier Brussee, Gennaro Vessio, Giovanna Castellano
<strong>Venue:</strong> arXiv (2025)</p><p>Cross-Domain Few-Shot Semantic Segmentation (CD-FSS) seeks to segment unknown classes in unseen domains using only a few annotated examples. This setting is inherently challenging: source and target domains exhibit substantial distribution shifts, label spaces are disjoint, and support images are scarce&ndash;making standard episodic methods unreliable and computationally demanding at test time. To address these constraints, we propose DistillFSS, a framework that embeds support-set knowledge directly into a model&rsquo;s parameters through a teacher&ndash;student distillation process. By internalizing few-shot reasoning into a dedicated layer within the student network, DistillFSS eliminates the need for support images at test time, enabling fast, lightweight inference, while allowing efficient extension to novel classes in unseen domains through rapid teacher-driven specialization. Combined with fine-tuning, the approach scales efficiently to large support sets and significantly reduces computational overhead. To evaluate the framework under realistic conditions, we introduce a new CD-FSS benchmark spanning medical imaging, industrial inspection, and remote sensing, with disjoint label spaces and variable support sizes. Experiments show that DistillFSS matches or surpasses state-of-the-art baselines, particularly in multi-class and multi-shot scenarios, while offering substantial efficiency gains. The code is available at <a href=https://github.com/pasqualedem/DistillFSS>https://github.com/pasqualedem/DistillFSS</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05613v1">üìÑ Download PDF</a></p><hr><h2 id=-emotion_language>üîç emotion_language<a hidden class=anchor aria-hidden=true href=#-emotion_language>#</a></h2><h3 id=measuring-the-effect-of-background-on-classification-and-feature-importance-in-deep-learning-for-av-perceptionhttpsarxivorgabs251205937v1><a href=https://arxiv.org/abs/2512.05937v1>Measuring the Effect of Background on Classification and Feature Importance in Deep Learning for AV Perception</a><a hidden class=anchor aria-hidden=true href=#measuring-the-effect-of-background-on-classification-and-feature-importance-in-deep-learning-for-av-perceptionhttpsarxivorgabs251205937v1>#</a></h3><p><strong>Authors:</strong> Anne Sielemann, Valentin Barner, Stefan Wolf, Masoud Roschani, Jens Ziehn, Juergen Beyerer
<strong>Venue:</strong> arXiv (2025)</p><p>Common approaches to explainable AI (XAI) for deep learning focus on analyzing the importance of input features on the classification task in a given model: saliency methods like SHAP and GradCAM are used to measure the impact of spatial regions of the input image on the classification result. Combined with ground truth information about the location of the object in the input image (e.g., a binary mask), it is determined whether object pixels had a high impact on the classification result, or whether the classification focused on background pixels. The former is considered to be a sign of a healthy classifier, whereas the latter is assumed to suggest overfitting on spurious correlations. A major challenge, however, is that these intuitive interpretations are difficult to test quantitatively, and hence the output of such explanations lacks an explanation itself. One particular reason is that correlations in real-world data are difficult to avoid, and whether they are spurious or legitimate is debatable. Synthetic data in turn can facilitate to actively enable or disable correlations where desired but often lack a sufficient quantification of realism and stochastic properties. [&mldr;] Therefore, we systematically generate six synthetic datasets for the task of traffic sign recognition, which differ only in their degree of camera variation and background correlation [&mldr;] to quantify the isolated influence of background correlation, different levels of camera variation, and considered traffic sign shapes on the classification performance, as well as background feature importance. [&mldr;] Results include a quantification of when and how much background features gain importance to support the classification task based on changes in the training domain [&mldr;].
Download: synset.de/datasets/synset-signset-ger/background-effect</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05937v1">üìÑ Download PDF</a></p><hr><h3 id=most-rocky-sub-neptunes-are-molten-mapping-the-solidification-shoreline-for-gas-dwarf-exoplanetshttpsarxivorgabs251205816v1><a href=https://arxiv.org/abs/2512.05816v1>Most Rocky Sub-Neptunes are Molten: Mapping the Solidification Shoreline for Gas Dwarf Exoplanets</a><a hidden class=anchor aria-hidden=true href=#most-rocky-sub-neptunes-are-molten-mapping-the-solidification-shoreline-for-gas-dwarf-exoplanetshttpsarxivorgabs251205816v1>#</a></h3><p><strong>Authors:</strong> Robb Calder, Oliver Shorttle, Harrison Nicholls, Tim Lichtenberg, Claire-Marie Guimond
<strong>Venue:</strong> arXiv (2025)</p><p>Sub-Neptunes are the most common type of detected exoplanet, yet their observed masses and radii are degenerate with several interior structures. One possibility is that sub-Neptunes have silicate/iron interiors and H$<em>2$-dominated atmospheres, i.e., they are <code>gas dwarfs'. If gas dwarfs have molten interiors, interactions between their magma oceans and atmospheres will produce distinct observational signatures. These signatures may break the degeneracy in interior structure, while providing insight into their interior processes, history, and population trends. We expect all such planets are born molten, but under what conditions do they remain molten today? We use the coupled interior-climate evolution model, PROTEUS, to estimate the </code>solidification shoreline&rsquo;: the instellation flux boundary (as a function of stellar $T</em>{\rm eff}$) that separates molten gas dwarfs from solidified ones. Our results show that 98% of detected sub-Neptunes occupy a region of parameter space consistent with their having permanent magma oceans, if they are gas dwarfs. While mantle $f{\rm O}_2$ and bulk volatile C/H ratio both influence magma ocean lifetimes, planets with oxidising mantles and carbon-rich atmospheres are unlikely to have radii consistent with the sub-Neptune classification. Therefore, most detected sub-Neptunes (if they are gas dwarfs) have permanent magma oceans. This result motivates further research into the interactions between molten interiors and overlying atmospheres, and campaigns to identify unambiguous signatures of these interactions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05816v1">üìÑ Download PDF</a></p><hr><h3 id=developing-synthetic-microdata-through-machine-learning-for-firm-level-business-surveyshttpsarxivorgabs251205948v1><a href=https://arxiv.org/abs/2512.05948v1>Developing synthetic microdata through machine learning for firm-level business surveys</a><a hidden class=anchor aria-hidden=true href=#developing-synthetic-microdata-through-machine-learning-for-firm-level-business-surveyshttpsarxivorgabs251205948v1>#</a></h3><p><strong>Authors:</strong> Jorge Cisneros Paz, Timothy Wojan, Matthew Williams, Jennifer Ozawa, Robert Chew, Kimberly Janda, Timothy Navarro, Michael Floyd, Christine Task, Damon Streat
<strong>Venue:</strong> arXiv (2025)</p><p>Public-use microdata samples (PUMS) from the United States (US) Census Bureau on individuals have been available for decades. However, large increases in computing power and the greater availability of Big Data have dramatically increased the probability of re-identifying anonymized data, potentially violating the pledge of confidentiality given to survey respondents. Data science tools can be used to produce synthetic data that preserve critical moments of the empirical data but do not contain the records of any existing individual respondent or business. Developing public-use firm data from surveys presents unique challenges different from demographic data, because there is a lack of anonymity and certain industries can be easily identified in each geographic area. This paper briefly describes a machine learning model used to construct a synthetic PUMS based on the Annual Business Survey (ABS) and discusses various quality metrics. Although the ABS PUMS is currently being refined and results are confidential, we present two synthetic PUMS developed for the 2007 Survey of Business Owners, similar to the ABS business data. Econometric replication of a high impact analysis published in Small Business Economics demonstrates the verisimilitude of the synthetic data to the true data and motivates discussion of possible ABS use cases.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05948v1">üìÑ Download PDF</a></p><hr><h3 id=minimal-two-band-model-and-experimental-proposals-to-distinguish-pairing-mechanisms-of-the-high-t_c-superconductor-la_3ni_2o_7httpsarxivorgabs251205956v1><a href=https://arxiv.org/abs/2512.05956v1>Minimal two band model and experimental proposals to distinguish pairing mechanisms of the high-T$_c$ superconductor La$_3$Ni$_2$O$_7$</a><a hidden class=anchor aria-hidden=true href=#minimal-two-band-model-and-experimental-proposals-to-distinguish-pairing-mechanisms-of-the-high-t_c-superconductor-la_3ni_2o_7httpsarxivorgabs251205956v1>#</a></h3><p><strong>Authors:</strong> Zheng-Duo Fan, Ashvin Vishwanath
<strong>Venue:</strong> arXiv (2025)</p><p>The discovery of high-T$_c$ superconductivity in La$_3$Ni$_2$O$_7$ has opened the door to a new route to high temperature superconductivity, distinct from that in cuprates and iron-based materials. Yet, despite intense recent activity, we lack experimentally testable protocols for distinguishing between different pairing scenarios. In this Letter, we construct a minimal two-band model that reproduces the Fermi-surface topology observed in recent ARPES measurements and DFT calculations, and we analyze superconductivity arising from two distinct pairing mechanisms. We show that these mechanisms yield sharply different responses to an applied perpendicular electric field. Thus, La$_3$Ni$_2$O$_7$ offers the unique opportunity to cleanly distinguish between different pairing scenarios. Finally, we propose three concrete experimental proposals designed to distinguish these scenarios and thereby identify the pairing mechanism most relevant to the real material.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05956v1">üìÑ Download PDF</a></p><hr><h3 id=llm-harms-a-taxonomy-and-discussionhttpsarxivorgabs251205929v1><a href=https://arxiv.org/abs/2512.05929v1>LLM Harms: A Taxonomy and Discussion</a><a hidden class=anchor aria-hidden=true href=#llm-harms-a-taxonomy-and-discussionhttpsarxivorgabs251205929v1>#</a></h3><p><strong>Authors:</strong> Kevin Chen, Saleh Afroogh, Abhejay Murali, David Atkinson, Amit Dhurandhar, Junfeng Jiao
<strong>Venue:</strong> arXiv (2025)</p><p>This study addresses categories of harm surrounding Large Language Models (LLMs) in the field of artificial intelligence. It addresses five categories of harms addressed before, during, and after development of AI applications: pre-development, direct output, Misuse and Malicious Application, and downstream application. By underscoring the need to define risks of the current landscape to ensure accountability, transparency and navigating bias when adapting LLMs for practical applications. It proposes mitigation strategies and future directions for specific domains and a dynamic auditing system guiding responsible development and integration of LLMs in a standardized proposal.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05929v1">üìÑ Download PDF</a></p><hr><h3 id=nice-neural-implicit-craniofacial-model-for-orthognathic-surgery-predictionhttpsarxivorgabs251205920v1><a href=https://arxiv.org/abs/2512.05920v1>NICE: Neural Implicit Craniofacial Model for Orthognathic Surgery Prediction</a><a hidden class=anchor aria-hidden=true href=#nice-neural-implicit-craniofacial-model-for-orthognathic-surgery-predictionhttpsarxivorgabs251205920v1>#</a></h3><p><strong>Authors:</strong> Jiawen Yang, Yihui Cao, Xuanyu Tian, Yuyao Zhang, Hongjiang Wei
<strong>Venue:</strong> arXiv (2025)</p><p>Orthognathic surgery is a crucial intervention for correcting dentofacial skeletal deformities to enhance occlusal functionality and facial aesthetics. Accurate postoperative facial appearance prediction remains challenging due to the complex nonlinear interactions between skeletal movements and facial soft tissue. Existing biomechanical, parametric models and deep-learning approaches either lack computational efficiency or fail to fully capture these intricate interactions. To address these limitations, we propose Neural Implicit Craniofacial Model (NICE) which employs implicit neural representations for accurate anatomical reconstruction and surgical outcome prediction. NICE comprises a shape module, which employs region-specific implicit Signed Distance Function (SDF) decoders to reconstruct the facial surface, maxilla, and mandible, and a surgery module, which employs region-specific deformation decoders. These deformation decoders are driven by a shared surgical latent code to effectively model the complex, nonlinear biomechanical response of the facial surface to skeletal movements, incorporating anatomical prior knowledge. The deformation decoders output point-wise displacement fields, enabling precise modeling of surgical outcomes. Extensive experiments demonstrate that NICE outperforms current state-of-the-art methods, notably improving prediction accuracy in critical facial regions such as lips and chin, while robustly preserving anatomical integrity. This work provides a clinically viable tool for enhanced surgical planning and patient consultation in orthognathic procedures.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05920v1">üìÑ Download PDF</a></p><hr><h3 id=world-models-that-know-when-they-dont-know-controllable-video-generation-with-calibrated-uncertaintyhttpsarxivorgabs251205927v1><a href=https://arxiv.org/abs/2512.05927v1>World Models That Know When They Don&rsquo;t Know: Controllable Video Generation with Calibrated Uncertainty</a><a hidden class=anchor aria-hidden=true href=#world-models-that-know-when-they-dont-know-controllable-video-generation-with-calibrated-uncertaintyhttpsarxivorgabs251205927v1>#</a></h3><p><strong>Authors:</strong> Zhiting Mei, Tenny Yin, Micah Baker, Ola Shorinwa, Anirudha Majumdar
<strong>Venue:</strong> arXiv (2025)</p><p>Recent advances in generative video models have led to significant breakthroughs in high-fidelity video synthesis, specifically in controllable video generation where the generated video is conditioned on text and action inputs, e.g., in instruction-guided video editing and world modeling in robotics. Despite these exceptional capabilities, controllable video models often hallucinate - generating future video frames that are misaligned with physical reality - which raises serious concerns in many tasks such as robot policy evaluation and planning. However, state-of-the-art video models lack the ability to assess and express their confidence, impeding hallucination mitigation. To rigorously address this challenge, we propose C3, an uncertainty quantification (UQ) method for training continuous-scale calibrated controllable video models for dense confidence estimation at the subpatch level, precisely localizing the uncertainty in each generated video frame. Our UQ method introduces three core innovations to empower video models to estimate their uncertainty. First, our method develops a novel framework that trains video models for correctness and calibration via strictly proper scoring rules. Second, we estimate the video model&rsquo;s uncertainty in latent space, avoiding training instability and prohibitive training costs associated with pixel-space approaches. Third, we map the dense latent-space uncertainty to interpretable pixel-level uncertainty in the RGB space for intuitive visualization, providing high-resolution uncertainty heatmaps that identify untrustworthy regions. Through extensive experiments on large-scale robot learning datasets (Bridge and DROID) and real-world evaluations, we demonstrate that our method not only provides calibrated uncertainty estimates within the training distribution, but also enables effective out-of-distribution detection.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05927v1">üìÑ Download PDF</a></p><hr><h3 id=to-err-is-human-systematic-quantification-of-errors-in-published-ai-papers-via-llm-analysishttpsarxivorgabs251205925v1><a href=https://arxiv.org/abs/2512.05925v1>To Err Is Human: Systematic Quantification of Errors in Published AI Papers via LLM Analysis</a><a hidden class=anchor aria-hidden=true href=#to-err-is-human-systematic-quantification-of-errors-in-published-ai-papers-via-llm-analysishttpsarxivorgabs251205925v1>#</a></h3><p><strong>Authors:</strong> Federico Bianchi, Yongchan Kwon, Zachary Izzo, Linjun Zhang, James Zou
<strong>Venue:</strong> arXiv (2025)</p><p>How many mistakes do published AI papers contain? Peer-reviewed publications form the foundation upon which new research and knowledge are built. Errors that persist in the literature can propagate unnoticed, creating confusion in follow-up studies and complicating reproducibility. The accelerating pace of research and the increasing demands on the peer-review system make such mistakes harder to detect and avoid. To address this, we developed a Paper Correctness Checker based on GPT-5 to systematically identify mistakes in papers previously published at top AI conferences and journals. Our analysis focuses on objective mistakes-e.g., errors in formulas, derivations, calculations, figures, and tables-that have a clearly verifiable ground truth. We intentionally exclude subjective considerations such as novelty, importance, or writing quality. We find that published papers contain a non-negligible number of objective mistakes and that the average number of mistakes per paper has increased over time-from 3.8 in NeurIPS 2021 to 5.9 in NeurIPS 2025 (55.3% increase); from 4.1 in ICLR 2018 to 5.2 in ICLR 2025; and from 5.0 in TMLR 2022/23 to 5.5 in TMLR 2025. Human experts reviewed 316 potential mistakes identified by the AI Checker and confirmed that 263 were actual mistakes, corresponding to a precision of 83.2%. While most identified issues are relatively minor, correcting them would reduce confusion in the literature and strengthen reproducibility. The AI Checker also surfaced potentially more substantive mistakes that could affect the interpretation of results. Moreover, we show that the AI Checker can propose correct fixes for 75.8% of the identified mistakes. Overall, this study highlights the potential of frontier LLMs to detect and correct objective mistakes in published papers, helping to establish a firmer foundation of knowledge.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05925v1">üìÑ Download PDF</a></p><hr><h3 id=a-residual-variance-matching-recursive-least-squares-filter-for-real-time-uav-terrain-followinghttpsarxivorgabs251205918v1><a href=https://arxiv.org/abs/2512.05918v1>A Residual Variance Matching Recursive Least Squares Filter for Real-time UAV Terrain Following</a><a hidden class=anchor aria-hidden=true href=#a-residual-variance-matching-recursive-least-squares-filter-for-real-time-uav-terrain-followinghttpsarxivorgabs251205918v1>#</a></h3><p><strong>Authors:</strong> Xiaobo Wu, Youmin Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>Accurate real-time waypoints estimation for the UAV-based online Terrain Following during wildfire patrol missions is critical to ensuring flight safety and enabling wildfire detection. However, existing real-time filtering algorithms struggle to maintain accurate waypoints under measurement noise in nonlinear and time-varying systems, posing risks of flight instability and missed wildfire detections during UAV-based terrain following. To address this issue, a Residual Variance Matching Recursive Least Squares (RVM-RLS) filter, guided by a Residual Variance Matching Estimation (RVME) criterion, is proposed to adaptively estimate the real-time waypoints of nonlinear, time-varying UAV-based terrain following systems. The proposed method is validated using a UAV-based online terrain following system within a simulated terrain environment. Experimental results show that the RVM-RLS filter improves waypoints estimation accuracy by approximately 88$%$ compared with benchmark algorithms across multiple evaluation metrics. These findings demonstrate both the methodological advances in real-time filtering and the practical potential of the RVM-RLS filter for UAV-based online wildfire patrol.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05918v1">üìÑ Download PDF</a></p><hr><h3 id=unitarization-of-r--Œ±r2-gravityhttpsarxivorgabs251205911v1><a href=https://arxiv.org/abs/2512.05911v1>Unitarization of $R + Œ±R^2$ gravity</a><a hidden class=anchor aria-hidden=true href=#unitarization-of-r--Œ±r2-gravityhttpsarxivorgabs251205911v1>#</a></h3><p><strong>Authors:</strong> I√±igo Asi√°in, Antonio Dobado, Dom√®nec Espriu
<strong>Venue:</strong> arXiv (2025)</p><p>We make use of the improved K-matrix algorithm to obtain unitarized amplitudes in $R+Œ±R^2$ gravity (the so-called
Starobisnsky model, of cosmological relevance). The procedure is of some complexity because infrared divergences
are present and need to be properly regulated. We focus on the behaviour of a bona fide scalar resonance, known to
exist in this model, and compare it to an apparent resonance detected in previous studies, thus confirming
that the latter seems to be an artifact due to the introduction of the infrared regulator. We analyze the existence of other
dynamical resonances and dwell on the amplitudes made unitary by this procedure.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05911v1">üìÑ Download PDF</a></p><hr><h3 id=euclid-quick-data-release-q1-from-simulations-to-sky-advancing-machine-learning-lens-detection-with-real-euclid-datahttpsarxivorgabs251205899v1><a href=https://arxiv.org/abs/2512.05899v1>Euclid Quick Data Release (Q1). From simulations to sky: Advancing machine-learning lens detection with real Euclid data</a><a hidden class=anchor aria-hidden=true href=#euclid-quick-data-release-q1-from-simulations-to-sky-advancing-machine-learning-lens-detection-with-real-euclid-datahttpsarxivorgabs251205899v1>#</a></h3><p><strong>Authors:</strong> Euclid Collaboration, N. E. P. Lines, T. E. Collett, P. Holloway, K. Rojas, S. Schuldt, R. B. Metcalf, T. Li, A. Verma, G. Despali, F. Courbin, R. Gavazzi, C. Tortora, B. Cl√©ment, N. Aghanim, B. Altieri, L. Amendola, S. Andreon, N. Auricchio, C. Baccigalupi, M. Baldi, A. Balestra, S. Bardelli, P. Battaglia, A. Biviano, E. Branchini, M. Brescia, S. Camera, G. Ca√±as-Herrera, V. Capobianco, C. Carbone, J. Carretero, M. Castellano, G. Castignani, S. Cavuoti, A. Cimatti, C. Colodro-Conde, G. Congedo, C. J. Conselice, L. Conversi, Y. Copin, H. M. Courtois, M. Cropper, H. Degaudenzi, G. De Lucia, H. Dole, F. Dubath, X. Dupac, S. Dusini, A. Ealet, S. Escoffier, M. Farina, R. Farinelli, F. Faustini, S. Ferriol, F. Finelli, M. Frailis, E. Franceschi, M. Fumana, S. Galeotta, K. George, B. Gillis, C. Giocoli, P. G√≥mez-Alvarez, J. Gracia-Carpio, A. Grazian, F. Grupp, S. V. H. Haugan, W. Holmes, I. M. Hook, F. Hormuth, A. Hornstrup, K. Jahnke, M. Jhabvala, B. Joachimi, E. Keih√§nen, S. Kermiche, A. Kiessling, B. Kubik, M. K√ºmmel, M. Kunz, H. Kurki-Suonio, A. M. C. Le Brun, S. Ligori, P. B. Lilje, V. Lindholm, I. Lloro, G. Mainetti, D. Maino, E. Maiorano, O. Mansutti, S. Marcin, O. Marggraf, M. Martinelli, N. Martinet, F. Marulli, R. J. Massey, E. Medinaceli, S. Mei, M. Melchior, Y. Mellier, M. Meneghetti, E. Merlin, G. Meylan, A. Mora, M. Moresco, L. Moscardini, R. Nakajima, C. Neissner, S. -M. Niemi, J. W. Nightingale, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, W. J. Percival, V. Pettorino, S. Pires, G. Polenta, M. Poncet, L. A. Popa, L. Pozzetti, F. Raison, A. Renzi, J. Rhodes, G. Riccio, E. Romelli, M. Roncarelli, C. Rosset, R. Saglia, Z. Sakr, A. G. S√°nchez, D. Sapone, B. Sartoris, J. A. Schewtschenko, P. Schneider, T. Schrabback, A. Secroun, G. Seidel, S. Serrano, C. Sirignano, G. Sirri, L. Stanco, J. Steinwagner, P. Tallada-Cresp√≠, A. N. Taylor, I. Tereno, N. Tessore, S. Toft, R. Toledo-Moreo, F. Torradeflot, I. Tutusaus, J. Valiviita, T. Vassallo, A. Veropalumbo, Y. Wang, J. Weller, A. Zacchei, G. Zamorani, F. M. Zerbi, E. Zucca, M. Ballardini, M. Bolzonella, E. Bozzo, C. Burigana, R. Cabanac, M. Calabrese, A. Cappi, T. Castro, J. A. Escartin Vigo, L. Gabarra, J. Garc√≠a-Bellido, V. Gautard, S. Hemmati, M. Huertas-Company, J. Macias-Perez, R. Maoli, J. Mart√≠n-Fleitas, M. Maturi, N. Mauri, P. Monaco, M. P√∂ntinen, C. Porciani, I. Risso, V. Scottez, M. Sereno, M. Tenti, M. Tucci, M. Viel, M. Wiesmann, Y. Akrami, I. T. Andika, G. Angora, S. Anselmi, M. Archidiacono, F. Atrio-Barandela, E. Aubourg, L. Bazzanini, D. Bertacca, M. Bethermin, F. Beutler, A. Blanchard, L. Blot, M. Bonici, S. Borgani, M. L. Brown, S. Bruton, A. Calabro, B. Camacho Quevedo, F. Caro, C. S. Carvalho, F. Cogato, S. Conseil, A. R. Cooray, O. Cucciati, S. Davini, F. De Paolis, G. Desprez, A. D√≠az-S√°nchez, S. Di Domizio, J. M. Diego, P. -A. Duc, V. Duret, M. Y. Elkhashab, A. Enia, Y. Fang, P. G. Ferreira, A. Finoguenov, A. Fontana, A. Franco, K. Ganga, T. Gasparetto, E. Gaztanaga, F. Giacomini, F. Gianotti, G. Gozaliasl, A. Gruppuso, M. Guidi, C. M. Gutierrez, A. Hall, H. Hildebrandt, J. Hjorth, J. J. E. Kajava, Y. Kang, V. Kansal, D. Karagiannis, K. Kiiveri, J. Kim, C. C. Kirkpatrick, S. Kruk, M. Lattanzi, L. Legrand, F. Lepori, G. Leroy, G. F. Lesci, J. Lesgourgues, T. I. Liaudat, M. Magliocchetti, A. Manj√≥n-Garc√≠a, F. Mannucci, C. J. A. P. Martins, L. Maurin, M. Miluzio, A. Montoro, C. Moretti, G. Morgante, S. Nadathur, K. Naidoo, P. Natoli, S. Nesseris, D. Paoletti, F. Passalacqua, K. Paterson, L. Patrizii, A. Pisani, D. Potter, G. W. Pratt, S. Quai, M. Radovich, W. Roster, S. Sacquegna, M. Sahl√©n, D. B. Sanders, E. Sarpa, A. Schneider, D. Sciotti, E. Sellentin, L. C. Smith, J. G. Sorce, K. Tanidis, C. Tao, F. Tarsitano, G. Testera, R. Teyssier, S. Tosi, A. Troja, A. Venhola, D. Vergani, G. Vernardos, G. Verza, S. Vinciguerra, M. Walmsley, N. A. Walton, A. H. Wright
<strong>Venue:</strong> arXiv (2025)</p><p>In the era of large-scale surveys like Euclid, machine learning has become an essential tool for identifying rare yet scientifically valuable objects, such as strong gravitational lenses. However, supervised machine-learning approaches require large quantities of labelled examples to train on, and the limited number of known strong lenses has lead to a reliance on simulations for training. A well-known challenge is that machine-learning models trained on one data domain often underperform when applied to a different domain: in the context of lens finding, this means that strong performance on simulated lenses does not necessarily translate into equally good performance on real observations. In Euclid&rsquo;s Quick Data Release 1 (Q1), covering 63 deg2, 500 strong lens candidates were discovered through a synergy of machine learning, citizen science, and expert visual inspection. These discoveries now allow us to quantify this performance gap and investigate the impact of training on real data. We find that a network trained only on simulations recovers up to 92% of simulated lenses with 100% purity, but only achieves 50% completeness with 24% purity on real Euclid data. By augmenting training data with real Euclid lenses and non-lenses, completeness improves by 25-30% in terms of the expected yield of discoverable lenses in Euclid DR1 and the full Euclid Wide Survey. Roughly 20% of this improvement comes from the inclusion of real lenses in the training data, while 5-10% comes from exposure to a more diverse set of non-lenses and false-positives from Q1. We show that the most effective lens-finding strategy for real-world performance combines the diversity of simulations with the fidelity of real lenses. This hybrid approach establishes a clear methodology for maximising lens discoveries in future data releases from Euclid, and will likely also be applicable to other surveys such as LSST.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05899v1">üìÑ Download PDF</a></p><hr><h3 id=hadronic-emissions-from-the-microquasar-v4641-sgr-ss433-and-its-implications-in-the-diffuse-galactic-emissionhttpsarxivorgabs251205839v1><a href=https://arxiv.org/abs/2512.05839v1>Hadronic Emissions from the Microquasar V4641 Sgr, SS433, and its implications in the Diffuse Galactic Emission</a><a hidden class=anchor aria-hidden=true href=#hadronic-emissions-from-the-microquasar-v4641-sgr-ss433-and-its-implications-in-the-diffuse-galactic-emissionhttpsarxivorgabs251205839v1>#</a></h3><p><strong>Authors:</strong> Basanti Paul, Abhijit Roy, Jagdish C. Joshi, Debanjan Bose
<strong>Venue:</strong> arXiv (2025)</p><p>Microquasars (MQs) are Galactic binary systems, consisting of a star and a compact object, a neutron star or a stellar mass black hole, which accretes matter from its companion star and gives rise to relativistic jets. Recent detection of very-high-energy (VHE; $E \gtrsim 100,\text{GeV}$) and ultra-high-energy (UHE; $E \gtrsim 100,\text{TeV}$) gamma-rays by LHAASO, HAWC and HESS from the MQ V4641 Sgr and SS 433 suggests them as Galactic PeVatrons. In this work, we studied a hadronic origin of the observed TeV-PeV gamma-ray emission from these MQs. We considered the hadronic scenario where the gamma-rays are produced by the interaction of relativistic protons in the MQ jet with the stellar wind. We fitted our model with observed data and constrained physical parameters like the hadronic jet power fraction, the proton spectral index, the maximum proton energy and the jet bulk Lorentz factor. Our best-fit model shows hard proton spectra ($1.84-2.44$) and maximum proton energies between 1 and 5 PeV. We also estimated the all-flavor neutrino fluxes corresponding to the gamma-ray fluxes from the hadronic model and found that V4641 sgr can be detected by next-generation neutrino telescopes like KM3NeT-ARCA and TRIDENT. Furthermore, we modeled a synthetic population of Galactic MQs and estimated their contribution to the diffuse TeV-PeV gamma-ray flux. For the inner Galaxy PSR contribution dominates in the range 10-100 TeV, and above 100 TeV diffused cosmic ray interactions with the molecular clouds is most dominant. We find that a population $\sim 14$ MQs is required to explain the LHAASO data above 100 TeV. For the outer Galaxy, we show that MQs are the dominant class of sources, and we constrain their population $\sim$14. Our findings strongly suggest that MQs are efficient particle accelerators, contributing to Galactic PeVatrons and potential multimessenger sources in our Galaxy.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05839v1">üìÑ Download PDF</a></p><hr><h3 id=quantitatively-mapping-the-eady-model-onto-a-two-layer-quasi-geostrophic-modelhttpsarxivorgabs251205902v1><a href=https://arxiv.org/abs/2512.05902v1>Quantitatively mapping the Eady model onto a two-layer quasi-geostrophic model</a><a hidden class=anchor aria-hidden=true href=#quantitatively-mapping-the-eady-model-onto-a-two-layer-quasi-geostrophic-modelhttpsarxivorgabs251205902v1>#</a></h3><p><strong>Authors:</strong> Julie Meunier, Basile Gallet
<strong>Venue:</strong> arXiv (2025)</p><p>The two-layer quasigeostrophic model (2LQG) and the Eady model are two idealized systems illustrating the baroclinic instability of atmospheric jets and ocean currents. The two setups share many ingredients &ndash; background vertically sheared zonal flow of density-stratified fluid in a rapidly rotating frame &ndash; while differing in complexity and dimensionality. The Eady model has a continuous vertical direction, with baroclinic turbulence induced by boundary potential vorticity (PV) gradients at top and bottom. By contrast, the 2LQG sytem typically models baroclinic instability induced by interior PV gradients. This distinction challenges our ability to clearly identify a couple of &lsquo;modes&rsquo; through which the Eady dynamics could be inferred from a simpler 2LQG system. In the present study, we show that this difficulty can be circumvented in the turbulent regime arising for weak bottom drag. Namely, guided by the common organization of both systems into a gas of coherent vortices, we identify a quantitative mapping between the Eady and the 2LQG models. The mapping allows for parameter-free predictions of the eddy diffusivity of the Eady model based on the knowledge of the 2LQG diffusivity. We illustrate these results using numerical simulations of the Eady and 2LQG models with linear or quadratic bottom drag.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05902v1">üìÑ Download PDF</a></p><hr><h3 id=invariant-price-of-anarchy-a-metric-for-welfarist-traffic-controlhttpsarxivorgabs251205843v1><a href=https://arxiv.org/abs/2512.05843v1>Invariant Price of Anarchy: a Metric for Welfarist Traffic Control</a><a hidden class=anchor aria-hidden=true href=#invariant-price-of-anarchy-a-metric-for-welfarist-traffic-controlhttpsarxivorgabs251205843v1>#</a></h3><p><strong>Authors:</strong> Ilia Shilov, Mingjia He, Heinrich H. Nax, Emilio Frazzoli, Gioele Zardini, Saverio Bolognani
<strong>Venue:</strong> arXiv (2025)</p><p>The Price of Anarchy (PoA) is a standard metric for quantifying inefficiency in socio-technical systems, widely used to guide policies like traffic tolling. Conventional PoA analysis relies on exact numerical costs. However, in many settings, costs represent agents&rsquo; preferences and may be defined only up to possibly arbitrary scaling and shifting, representing informational and modeling ambiguities. We observe that while such transformations preserve equilibrium and optimal outcomes, they change the PoA value. To resolve this issue, we rely on results from Social Choice Theory and define the Invariant PoA. By connecting admissible transformations to degrees of comparability of agents&rsquo; costs, we derive the specific social welfare functions which ensure that efficiency evaluations do not depend on arbitrary rescalings or translations of individual costs. Case studies on a toy example and the Zurich network demonstrate that identical tolling strategies can lead to substantially different efficiency estimates depending on the assumed comparability. Our framework thus demonstrates that explicit axiomatic foundations are necessary in order to define efficiency metrics and to appropriately guide policy in large-scale infrastructure design robustly and effectively.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05843v1">üìÑ Download PDF</a></p><hr><h3 id=towards-agent-based-model-informed-neural-networkshttpsarxivorgabs251205764v1><a href=https://arxiv.org/abs/2512.05764v1>Towards agent-based-model informed neural networks</a><a hidden class=anchor aria-hidden=true href=#towards-agent-based-model-informed-neural-networkshttpsarxivorgabs251205764v1>#</a></h3><p><strong>Authors:</strong> Nino Antulov-Fantulin
<strong>Venue:</strong> arXiv (2025)</p><p>In this article, we present a framework for designing neural networks that remain consistent with the underlying principles of agent-based models. We begin by highlighting the limitations of standard neural differential equations in modeling complex systems, where physical invariants (like energy) are often absent but other constraints (like mass conservation, network locality, bounded rationality) must be enforced. To address this, we introduce Agent-Based-Model informed Neural Networks(ABM-NNs), which leverage restricted graph neural networks and hierarchical decomposition to learn interpretable, structure-preserving dynamics. We validate the framework across three case studies of increasing complexity: (i) a generalized Generalized Lotka&ndash;Volterra system, where we recover ground-truth parameters from short trajectories in presence of interventions; (ii) a graph-based SIR contagion model, where our method outperforms state-of-the-art graph learning baselines (GCN, GraphSAGE, Graph Transformer) in out-of-sample forecasting and noise robustness; and (iii) a real-world macroeconomic model of the ten largest economies, where we learn coupled GDP dynamics from empirical data and demonstrate gradient-based counterfactual analysis for policy interventions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05764v1">üìÑ Download PDF</a></p><hr><h3 id=open-data-privacy-and-fair-information-principles-towards-a-balancing-frameworkhttpsarxivorgabs251205728v1><a href=https://arxiv.org/abs/2512.05728v1>Open Data, Privacy, and Fair Information Principles: Towards a Balancing Framework</a><a hidden class=anchor aria-hidden=true href=#open-data-privacy-and-fair-information-principles-towards-a-balancing-frameworkhttpsarxivorgabs251205728v1>#</a></h3><p><strong>Authors:</strong> Frederik Zuiderveen Borgesius, Jonathan Gray, Mireille van Eechoud
<strong>Venue:</strong> arXiv (2025)</p><p>Open data are held to contribute to a wide variety of social and political goals, including strengthening transparency, public participation and democratic accountability, promoting economic growth and innovation, and enabling greater public sector efficiency and cost savings. However, releasing government data that contain personal information may threaten privacy and related rights and interests. In this Article we ask how these privacy interests can be respected, without unduly hampering benefits from disclosing public sector information. We propose a balancing framework to help public authorities address this question in different contexts. The framework takes into account different levels of privacy risks for different types of data. It also separates decisions about access and re-use, and highlights a range of different disclosure routes. A circumstance catalogue lists factors that might be considered when assessing whether, under which conditions, and how a dataset can be released. While open data remains an important route for the publication of government information, we conclude that it is not the only route, and there must be clear and robust public interest arguments in order to justify the disclosure of personal information as open data.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05728v1">üìÑ Download PDF</a></p><hr><h3 id=the-power-of-network-pluralism-multi-perspective-modeling-of-heterogeneous-legal-document-networkshttpsarxivorgabs251205679v1><a href=https://arxiv.org/abs/2512.05679v1>The Power of Network Pluralism: Multi-Perspective Modeling of Heterogeneous Legal Document Networks</a><a hidden class=anchor aria-hidden=true href=#the-power-of-network-pluralism-multi-perspective-modeling-of-heterogeneous-legal-document-networkshttpsarxivorgabs251205679v1>#</a></h3><p><strong>Authors:</strong> Titus P√ºnder, Corinna Coupette
<strong>Venue:</strong> arXiv (2025)</p><p>Insights are relative - influenced by a range of factors such as assumptions, scopes, or methods that together define a research perspective. In normative and empirical fields alike, this insight has led to the conclusion that no single perspective can generate complete knowledge. As a response, epistemological pluralism mandates that researchers consider multiple perspectives simultaneously to obtain a holistic understanding of their phenomenon under study. Translating this mandate to network science, our work introduces Network Pluralism as a conceptual framework that leverages multi-perspectivity to yield more complete, meaningful, and robust results. We develop and demonstrate the benefits of this approach via a hands-on analysis of complex legal systems, constructing a network space from references across documents from different branches of government as well as including organizational hierarchy above and fine-grained structure below the document level. Leveraging the resulting heterogeneity in a multi-network analysis, we show how complementing perspectives can help contextualize otherwise high-level findings, how contrasting several networks derived from the same data enables researchers to learn by difference, and how relating metrics to perspectives may increase the transparency and robustness of network-analytical results. To analyze a space of networks as perspectives, researchers need to map dimensions of variation in a given domain to network-modeling decisions and network-metric parameters. While this remains a challenging and inherently interdisciplinary task, our work acts as a blueprint to facilitate the broader adoption of Network Pluralism in domain-driven network research.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05679v1">üìÑ Download PDF</a></p><hr><h3 id=mind-multi-rationale-integrated-discriminative-reasoning-framework-for-multi-modal-large-modelshttpsarxivorgabs251205530v1><a href=https://arxiv.org/abs/2512.05530v1>MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models</a><a hidden class=anchor aria-hidden=true href=#mind-multi-rationale-integrated-discriminative-reasoning-framework-for-multi-modal-large-modelshttpsarxivorgabs251205530v1>#</a></h3><p><strong>Authors:</strong> Chuang Yu, Jinmiao Zhao, Mingxuan Zhao, Yunpeng Liu, Xiujun Shu, Yuanhao Feng, Bo Wang, Xiangyu Yue
<strong>Venue:</strong> arXiv (2025)</p><p>Recently, multimodal large language models (MLLMs) have been widely applied to reasoning tasks. However, they suffer from limited multi-rationale semantic modeling, insufficient logical robustness, and are susceptible to misleading interpretations in complex scenarios. Therefore, we propose a Multi-rationale INtegrated Discriminative (MIND) reasoning framework, which is designed to endow MLLMs with human-like cognitive abilities of &ldquo;Understand -> Rethink -> Correct&rdquo;, and achieves a paradigm evolution from passive imitation-based reasoning to active discriminative reasoning. Specifically, we introduce a Rationale Augmentation and Discrimination (RAD) paradigm, which automatically and efficiently expands existing datasets by generating diverse rationales, providing a unified and extensible data foundation. Meanwhile, we design a Progressive Two-stage Correction Learning (P2CL) strategy. The first phase enhances multi-rationale positive learning, while the second phase enables active logic discrimination and correction. In addition, to mitigate representation entanglement in the multi-rationale semantic space, we propose a Multi-rationale Contrastive Alignment (MCA) optimization strategy, which achieves semantic aggregation of correct reasoning and boundary separation of incorrect reasoning. Extensive experiments demonstrate that the proposed MIND reasoning framework achieves state-of-the-art (SOTA) performance on multiple public datasets covering scientific, commonsense, and mathematical scenarios. It provides a new perspective for advancing MLLMs towards higher levels of cognitive intelligence. Our code is available at <a href=https://github.com/YuChuang1205/MIND>https://github.com/YuChuang1205/MIND</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05530v1">üìÑ Download PDF</a></p><hr><h3 id=lyrics-matter-exploiting-the-power-of-learnt-representations-for-music-popularity-predictionhttpsarxivorgabs251205508v1><a href=https://arxiv.org/abs/2512.05508v1>Lyrics Matter: Exploiting the Power of Learnt Representations for Music Popularity Prediction</a><a hidden class=anchor aria-hidden=true href=#lyrics-matter-exploiting-the-power-of-learnt-representations-for-music-popularity-predictionhttpsarxivorgabs251205508v1>#</a></h3><p><strong>Authors:</strong> Yash Choudhary, Preeti Rao, Pushpak Bhattacharyya
<strong>Venue:</strong> arXiv (2025)</p><p>Accurately predicting music popularity is a critical challenge in the music industry, offering benefits to artists, producers, and streaming platforms. Prior research has largely focused on audio features, social metadata, or model architectures. This work addresses the under-explored role of lyrics in predicting popularity. We present an automated pipeline that uses LLM to extract high-dimensional lyric embeddings, capturing semantic, syntactic, and sequential information. These features are integrated into HitMusicLyricNet, a multimodal architecture that combines audio, lyrics, and social metadata for popularity score prediction in the range 0-100. Our method outperforms existing baselines on the SpotGenTrack dataset, which contains over 100,000 tracks, achieving 9% and 20% improvements in MAE and MSE, respectively. Ablation confirms that gains arise from our LLM-driven lyrics feature pipeline (LyricsAENet), underscoring the value of dense lyric representations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05508v1">üìÑ Download PDF</a></p><hr></div><footer class=post-footer><ul class=post-tags></ul></footer><div><div class=pagination__title><span class=pagination__title-h style=font-size:20px>Comments</span><hr></div><div id=tcomment></div><script src=https://cdn.staticfile.org/twikoo/1.6.39/twikoo.all.min.js></script><script>twikoo.init({envId:"https://mangodb-theta.vercel.app/",el:"#tcomment",lang:"en-US",path:window.TWIKOO_MAGIC_PATH||window.location.pathname})</script></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://garyforreal.me/zh/>Gary's House</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span><div class=busuanzi-footer><span id=busuanzi_container_site_pv>Views: <span id=busuanzi_value_site_pv></span>
</span><span id=busuanzi_container_site_uv>Visitors: <span id=busuanzi_value_site_uv></span></span></div></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="Â§çÂà∂";function s(){t.innerHTML="Â∑≤Â§çÂà∂ÔºÅ",setTimeout(()=>{t.innerHTML="Â§çÂà∂"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>