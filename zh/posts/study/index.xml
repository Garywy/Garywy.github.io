<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>å­¦ä¹  on Gary&#39;s House</title>
    <link>https://garyforreal.me/zh/posts/study/</link>
    <description>Recent content in å­¦ä¹  on Gary&#39;s House</description>
    <generator>Hugo -- 0.141.0</generator>
    <language>zh</language>
    <lastBuildDate>Tue, 09 Dec 2025 00:32:16 +0000</lastBuildDate>
    <atom:link href="https://garyforreal.me/zh/posts/study/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Weekly Paper Notes - 2025-12-09</title>
      <link>https://garyforreal.me/zh/posts/study/paper-2025-12-09-weekly/</link>
      <pubDate>Tue, 09 Dec 2025 00:32:16 +0000</pubDate>
      <guid>https://garyforreal.me/zh/posts/study/paper-2025-12-09-weekly/</guid>
      <description>&lt;h1 id=&#34;weekly-paper-notes&#34;&gt;Weekly Paper Notes&lt;/h1&gt;
&lt;h2 id=&#34;-multilingual&#34;&gt;ğŸ” multilingual&lt;/h2&gt;
&lt;h3 id=&#34;m4-rag-a-massive-scale-multilingual-multi-cultural-multimodal-raghttpsarxivorgabs251205959v1&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2512.05959v1&#34;&gt;M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; David Anugraha, Patrick Amadeus Irawan, Anshul Singh, En-Shiun Annie Lee, Genta Indra Winata
&lt;strong&gt;Venue:&lt;/strong&gt; arXiv (2025)&lt;/p&gt;
&lt;p&gt;Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Weekly Paper Notes - 2025-12-08</title>
      <link>https://garyforreal.me/zh/posts/study/paper-2025-12-08-weekly/</link>
      <pubDate>Mon, 08 Dec 2025 04:07:26 +0000</pubDate>
      <guid>https://garyforreal.me/zh/posts/study/paper-2025-12-08-weekly/</guid>
      <description>&lt;h1 id=&#34;weekly-paper-notes&#34;&gt;Weekly Paper Notes&lt;/h1&gt;
&lt;h2 id=&#34;-multilingual&#34;&gt;ğŸ” multilingual&lt;/h2&gt;
&lt;h3 id=&#34;m4-rag-a-massive-scale-multilingual-multi-cultural-multimodal-raghttpsarxivorgabs251205959v1&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2512.05959v1&#34;&gt;M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; David Anugraha, Patrick Amadeus Irawan, Anshul Singh, En-Shiun Annie Lee, Genta Indra Winata
&lt;strong&gt;Venue:&lt;/strong&gt; arXiv (2025)&lt;/p&gt;
&lt;p&gt;Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Weekly Paper Notes - 2025-12-07</title>
      <link>https://garyforreal.me/zh/posts/study/paper-2025-12-07-weekly/</link>
      <pubDate>Sun, 07 Dec 2025 07:18:42 +0000</pubDate>
      <guid>https://garyforreal.me/zh/posts/study/paper-2025-12-07-weekly/</guid>
      <description>&lt;h1 id=&#34;weekly-paper-notes&#34;&gt;Weekly Paper Notes&lt;/h1&gt;
&lt;h2 id=&#34;-cross-lingual&#34;&gt;ğŸ” cross-lingual&lt;/h2&gt;
&lt;h3 id=&#34;kda-knowledge-distillation-adapter-for-cross-lingual-transferhttpsaclanthologyorg2025inlg-main8&#34;&gt;&lt;a href=&#34;https://aclanthology.org/2025.inlg-main.8/&#34;&gt;KDA: Knowledge Distillation Adapter for Cross-Lingual Transfer&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt;
&lt;strong&gt;Venue:&lt;/strong&gt;  (Tue,)&lt;/p&gt;
&lt;p&gt;Ta-Bao Nguyen, Nguyen-Phuong Phan, Tung Le and Huy Tien Nguyen in Proceedings of the 18th International Natural Language Generation Conference&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.inlg-main.8&#34;&gt;ğŸ“¥ Save to Zotero&lt;/a&gt; Â Â  &lt;a href=&#34;https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.inlg-main.8&#34;&gt;ğŸ“„ Download PDF&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;are-knowledge-and-reference-in-multilingual-language-models-cross-lingually-consistenthttpsaclanthologyorg2025findings-emnlp267&#34;&gt;&lt;a href=&#34;https://aclanthology.org/2025.findings-emnlp.267/&#34;&gt;Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent?&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt;
&lt;strong&gt;Venue:&lt;/strong&gt;  (Fri,)&lt;/p&gt;
&lt;p&gt;Xi Ai, Mahardika Krisna Ihsani and Min-Yen Kan in Findings of the Association for Computational Linguistics: EMNLP 2025&lt;/p&gt;</description>
    </item>
    <item>
      <title>Weekly Paper Notes - 2025-12-06</title>
      <link>https://garyforreal.me/zh/posts/study/paper-2025-12-06-weekly/</link>
      <pubDate>Sat, 06 Dec 2025 11:29:05 +0000</pubDate>
      <guid>https://garyforreal.me/zh/posts/study/paper-2025-12-06-weekly/</guid>
      <description>&lt;h1 id=&#34;weekly-paper-notes&#34;&gt;Weekly Paper Notes&lt;/h1&gt;
&lt;h2 id=&#34;-multilingual&#34;&gt;ğŸ” multilingual&lt;/h2&gt;
&lt;h3 id=&#34;llms-know-more-than-words-a-genre-study-with-syntax-metaphor--phoneticshttpsarxivorgabs251204957v1&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2512.04957v1&#34;&gt;LLMs Know More Than Words: A Genre Study with Syntax, Metaphor &amp;amp; Phonetics&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Weiye Shi, Zhaowei Zhang, Shaoheng Yan, Yaodong Yang
&lt;strong&gt;Venue:&lt;/strong&gt; arXiv (2025)&lt;/p&gt;
&lt;p&gt;Large language models (LLMs) demonstrate remarkable potential across diverse language related tasks, yet whether they capture deeper linguistic properties, such as syntactic structure, phonetic cues, and metrical patterns from raw text remains unclear. To analysis whether LLMs can learn these features effectively and apply them to important nature language related tasks, we introduce a novel multilingual genre classification dataset derived from Project Gutenberg, a large-scale digital library offering free access to thousands of public domain literary works, comprising thousands of sentences per binary task (poetry vs. novel;drama vs. poetry;drama vs. novel) in six languages (English, French, German, Italian, Spanish, and Portuguese). We augment each with three explicit linguistic feature sets (syntactic tree structures, metaphor counts, and phonetic metrics) to evaluate their impact on classification performance. Experiments demonstrate that although LLM classifiers can learn latent linguistic structures either from raw text or from explicitly provided features, different features contribute unevenly across tasks, which underscores the importance of incorporating more complex linguistic signals during model training.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Weekly Paper Notes - 2025-12-05</title>
      <link>https://garyforreal.me/zh/posts/study/paper-2025-12-05-weekly/</link>
      <pubDate>Fri, 05 Dec 2025 15:29:10 +0000</pubDate>
      <guid>https://garyforreal.me/zh/posts/study/paper-2025-12-05-weekly/</guid>
      <description>&lt;h1 id=&#34;weekly-paper-notes&#34;&gt;Weekly Paper Notes&lt;/h1&gt;
&lt;h2 id=&#34;-multilingual&#34;&gt;ğŸ” multilingual&lt;/h2&gt;
&lt;h3 id=&#34;llms-know-more-than-words-a-genre-study-with-syntax-metaphor--phoneticshttpsarxivorgabs251204957v1&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/2512.04957v1&#34;&gt;LLMs Know More Than Words: A Genre Study with Syntax, Metaphor &amp;amp; Phonetics&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Weiye Shi, Zhaowei Zhang, Shaoheng Yan, Yaodong Yang
&lt;strong&gt;Venue:&lt;/strong&gt; arXiv (2025)&lt;/p&gt;
&lt;p&gt;Large language models (LLMs) demonstrate remarkable potential across diverse language related tasks, yet whether they capture deeper linguistic properties, such as syntactic structure, phonetic cues, and metrical patterns from raw text remains unclear. To analysis whether LLMs can learn these features effectively and apply them to important nature language related tasks, we introduce a novel multilingual genre classification dataset derived from Project Gutenberg, a large-scale digital library offering free access to thousands of public domain literary works, comprising thousands of sentences per binary task (poetry vs. novel;drama vs. poetry;drama vs. novel) in six languages (English, French, German, Italian, Spanish, and Portuguese). We augment each with three explicit linguistic feature sets (syntactic tree structures, metaphor counts, and phonetic metrics) to evaluate their impact on classification performance. Experiments demonstrate that although LLM classifiers can learn latent linguistic structures either from raw text or from explicitly provided features, different features contribute unevenly across tasks, which underscores the importance of incorporating more complex linguistic signals during model training.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Weekly Paper Notes - 2025-12-04</title>
      <link>https://garyforreal.me/zh/posts/study/paper-2025-12-04-weekly/</link>
      <pubDate>Thu, 04 Dec 2025 08:53:15 +0000</pubDate>
      <guid>https://garyforreal.me/zh/posts/study/paper-2025-12-04-weekly/</guid>
      <description>&lt;h1 id=&#34;weekly-paper-notes&#34;&gt;Weekly Paper Notes&lt;/h1&gt;
&lt;h2 id=&#34;-cross-lingual&#34;&gt;ğŸ” cross-lingual&lt;/h2&gt;
&lt;h3 id=&#34;kda-knowledge-distillation-adapter-for-cross-lingual-transferhttpsaclanthologyorg2025inlg-main8&#34;&gt;&lt;a href=&#34;https://aclanthology.org/2025.inlg-main.8/&#34;&gt;KDA: Knowledge Distillation Adapter for Cross-Lingual Transfer&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt;
&lt;strong&gt;Venue:&lt;/strong&gt;  (Tue,)&lt;/p&gt;
&lt;p&gt;Ta-Bao Nguyen, Nguyen-Phuong Phan, Tung Le and Huy Tien Nguyen in Proceedings of the 18th International Natural Language Generation Conference&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-code-switching&#34;&gt;ğŸ” code-switching&lt;/h2&gt;
&lt;h3 id=&#34;can-code-switched-texts-activate-a-knowledge-switch-in-llms-a-case-study-on-english-korean-code-switchinghttpsaclanthologyorg2025findings-emnlp1215&#34;&gt;&lt;a href=&#34;https://aclanthology.org/2025.findings-emnlp.1215/&#34;&gt;Can Code-Switched Texts Activate a Knowledge Switch in LLMs? A Case Study on English-Korean Code-Switching&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt;
&lt;strong&gt;Venue:&lt;/strong&gt;  (Fri,)&lt;/p&gt;
&lt;p&gt;Seoyeon Kim, Huiseo Kim, Chanjun Park, Jinyoung Yeo and Dongha Lee in Findings of the Association for Computational Linguistics: EMNLP 2025&lt;/p&gt;</description>
    </item>
    <item>
      <title>æ—¥è¯­æœ€å°å‘éŸ³ï¼ˆMoraï¼‰çš„æ€»ç»“</title>
      <link>https://garyforreal.me/zh/posts/study/mora/</link>
      <pubDate>Fri, 20 Jun 2025 15:55:51 +0900</pubDate>
      <guid>https://garyforreal.me/zh/posts/study/mora/</guid>
      <description>&lt;p&gt;å› ä¸ºä½œè€…æ­£åœ¨è¿›è¡Œæ—¥è¯­Dajareçš„ç›¸å…³ç ”ç©¶ï¼Œå…¶ä¸­æ¶‰åŠäº†å…³äºæ—¥è¯­æ–‡æœ¬åœ¨å‘éŸ³ç›¸ä¼¼åº¦æ–¹é¢çš„è®¡ç®—ï¼Œå› æ­¤æœ¬æ–‡æ—¨åœ¨æ€»ç»“äº†æ—¥è¯­ä¸­çš„å‘éŸ³å•å…ƒï¼ˆmoraï¼‰ä»¥åŠå•è¯çš„å‘éŸ³è¡¨è¾¾å½¢å¼ï¼Œä»¥ä¾¿äºåç»­å¯¹æœ¬æ–‡å‘éŸ³ç›¸ä¼¼æ€§çš„è®¡ç®—ã€‚&lt;/p&gt;</description>
    </item>
    <item>
      <title>DP_Question</title>
      <link>https://garyforreal.me/zh/posts/study/dp_question/</link>
      <pubDate>Sun, 29 Sep 2024 18:20:59 +0900</pubDate>
      <guid>https://garyforreal.me/zh/posts/study/dp_question/</guid>
      <description>&lt;h1 id=&#34;å‰è¨€&#34;&gt;å‰è¨€&lt;/h1&gt;
&lt;p&gt;å› ä¸ºæ€»æ˜¯åœ¨åŠ¨æ€è§„åˆ’é—®é¢˜ä¸Šç¢°å£ï¼Œæ‰€ä»¥æƒ³æ€»ç»“ä¸€ä¸‹åŠ¨æ€è§„åˆ’é—®é¢˜çš„è§£å†³åŠæ³•ã€‚&lt;br&gt;
DPé—®é¢˜åŸºæœ¬è§£é¢˜æ€è·¯ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;åˆå§‹çŠ¶æ€&lt;/li&gt;
&lt;li&gt;çŠ¶æ€è½¬ç§»æ–¹ç¨‹&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;1-çº¿æ€§dp&#34;&gt;1. çº¿æ€§DP&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;1.1 ä¾‹é¢˜ï¼šLeetcode 300. Longest Increasing Subsequence&lt;/strong&gt; &lt;br&gt;
Given an integer array nums, return the length of the longest strictly increasing subsequence.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Markdownå­¦ä¹ ç¬”è®°</title>
      <link>https://garyforreal.me/zh/posts/study/markdown%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Thu, 26 Sep 2024 17:31:12 +0900</pubDate>
      <guid>https://garyforreal.me/zh/posts/study/markdown%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>&lt;h1 id=&#34;å‰è¨€&#34;&gt;å‰è¨€&lt;/h1&gt;
&lt;p&gt;æœ¬æ–‡ä¸»è¦ä¸ºæ€»ç»“Markdownå¸¸ç”¨è¯­æ³•ï¼Œä»¥ä¾¿äºè‡ªå·²èƒ½å¤Ÿæ›´å¥½çš„ä¹¦å†™Markdownæ–‡ä»¶ã€‚&lt;/p&gt;
&lt;h1 id=&#34;1-åŸºæœ¬è¯­æ³•&#34;&gt;1. åŸºæœ¬è¯­æ³•&lt;/h1&gt;
&lt;h2 id=&#34;11-æ ‡é¢˜&#34;&gt;1.1 æ ‡é¢˜&lt;/h2&gt;
&lt;p&gt;åˆ©ç”¨&lt;code&gt;#&lt;/code&gt;ç¬¦å·åˆ›å»ºæ ‡é¢˜ï¼Œæœ‰å‡ ä¸ª&lt;code&gt;#&lt;/code&gt;å°±æ˜¯å‡ çº§æ ‡é¢˜ã€‚&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hugo&#43;GitHubpageså»ºç«‹ä¸ªäººåšå®¢</title>
      <link>https://garyforreal.me/zh/posts/study/hugo&#43;githubpages%E5%BB%BA%E7%AB%8B%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</link>
      <pubDate>Mon, 23 Sep 2024 17:33:57 +0900</pubDate>
      <guid>https://garyforreal.me/zh/posts/study/hugo&#43;githubpages%E5%BB%BA%E7%AB%8B%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</guid>
      <description>&lt;h1 id=&#34;1-å‰è¨€&#34;&gt;1. å‰è¨€&lt;/h1&gt;
&lt;p&gt;åŸæœ¬æ˜¯å› ä¸ºå­¦ä¹ ä»»åŠ¡è¦æ±‚éœ€è¦åšä¸€ä¸ªWeb Serviceï¼Œç»“æœé˜´å·®é˜³é”™çš„å‘ç°äº†hugoè¿™ä¸ªå·¥å…·ã€‚æ‰€ä»¥å€Ÿæ­¤æœºä¼šåˆ©ç”¨hugoåˆ¶ä½œäº†è‡ªå·±çš„ä¸ªäººåšå®¢ã€‚æ­¤ç¯‡æ–‡ç« å†…å®¹ä¸»è¦åŒ…æ‹¬äº†æ­å»ºä¸ªäººç½‘ç«™çš„æµç¨‹ï¼Œæˆ‘åœ¨å…¶ä¸­é‡åˆ°çš„ä¸€äº›é—®é¢˜ä»¥åŠè§£å†³æ–¹æ¡ˆï¼Œå¸Œæœ›èƒ½å¯¹ä½ æœ‰å¸®åŠ©ã€‚&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
