<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Weekly Paper Notes - 2025-12-05 | Gary's House</title>
<meta name=keywords content><meta name=description content="Weekly Paper Notes
üîç multilingual
LLMs Know More Than Words: A Genre Study with Syntax, Metaphor & Phonetics
Authors: Weiye Shi, Zhaowei Zhang, Shaoheng Yan, Yaodong Yang
Venue: arXiv (2025)
Large language models (LLMs) demonstrate remarkable potential across diverse language related tasks, yet whether they capture deeper linguistic properties, such as syntactic structure, phonetic cues, and metrical patterns from raw text remains unclear. To analysis whether LLMs can learn these features effectively and apply them to important nature language related tasks, we introduce a novel multilingual genre classification dataset derived from Project Gutenberg, a large-scale digital library offering free access to thousands of public domain literary works, comprising thousands of sentences per binary task (poetry vs. novel;drama vs. poetry;drama vs. novel) in six languages (English, French, German, Italian, Spanish, and Portuguese). We augment each with three explicit linguistic feature sets (syntactic tree structures, metaphor counts, and phonetic metrics) to evaluate their impact on classification performance. Experiments demonstrate that although LLM classifiers can learn latent linguistic structures either from raw text or from explicitly provided features, different features contribute unevenly across tasks, which underscores the importance of incorporating more complex linguistic signals during model training."><meta name=author content="Gary"><link rel=canonical href=https://garyforreal.me/zh/posts/study/paper-2025-12-05-weekly/><meta name=google-site-verification content="XYZabc"><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><meta name=referrer content="no-referrer-when-downgrade"><link crossorigin=anonymous href=/assets/css/stylesheet.7e5251d8716d933fafcf3df70d7ecd02729661d6d232fc5dd0b8a85ef75e3409.css integrity="sha256-flJR2HFtkz+vzz33DX7NAnKWYdbSMvxd0LioXvdeNAk=" rel="preload stylesheet" as=style><link rel=icon href=https://garyforreal.me/img/Q.jpg><link rel=icon type=image/png sizes=16x16 href=https://garyforreal.me/img/Q.jpg><link rel=icon type=image/png sizes=32x32 href=https://garyforreal.me/img/Q.jpg><link rel=apple-touch-icon href=https://garyforreal.me/Q.jpg><link rel=mask-icon href=https://garyforreal.me/Q.jpg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://garyforreal.me/zh/posts/study/paper-2025-12-05-weekly/><link rel=alternate hreflang=en href=https://garyforreal.me/en/posts/study/paper-2025-12-05-weekly/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@200..900&display=swap" rel=stylesheet><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous referrerpolicy=no-referrer></script><meta property="og:title" content="Weekly Paper Notes - 2025-12-05"><meta property="og:description" content="Weekly Paper Notes
üîç multilingual
LLMs Know More Than Words: A Genre Study with Syntax, Metaphor & Phonetics
Authors: Weiye Shi, Zhaowei Zhang, Shaoheng Yan, Yaodong Yang
Venue: arXiv (2025)
Large language models (LLMs) demonstrate remarkable potential across diverse language related tasks, yet whether they capture deeper linguistic properties, such as syntactic structure, phonetic cues, and metrical patterns from raw text remains unclear. To analysis whether LLMs can learn these features effectively and apply them to important nature language related tasks, we introduce a novel multilingual genre classification dataset derived from Project Gutenberg, a large-scale digital library offering free access to thousands of public domain literary works, comprising thousands of sentences per binary task (poetry vs. novel;drama vs. poetry;drama vs. novel) in six languages (English, French, German, Italian, Spanish, and Portuguese). We augment each with three explicit linguistic feature sets (syntactic tree structures, metaphor counts, and phonetic metrics) to evaluate their impact on classification performance. Experiments demonstrate that although LLM classifiers can learn latent linguistic structures either from raw text or from explicitly provided features, different features contribute unevenly across tasks, which underscores the importance of incorporating more complex linguistic signals during model training."><meta property="og:type" content="article"><meta property="og:url" content="https://garyforreal.me/zh/posts/study/paper-2025-12-05-weekly/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-12-05T15:29:10+00:00"><meta property="article:modified_time" content="2025-12-05T15:29:10+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Weekly Paper Notes - 2025-12-05"><meta name=twitter:description content="Weekly Paper Notes
üîç multilingual
LLMs Know More Than Words: A Genre Study with Syntax, Metaphor & Phonetics
Authors: Weiye Shi, Zhaowei Zhang, Shaoheng Yan, Yaodong Yang
Venue: arXiv (2025)
Large language models (LLMs) demonstrate remarkable potential across diverse language related tasks, yet whether they capture deeper linguistic properties, such as syntactic structure, phonetic cues, and metrical patterns from raw text remains unclear. To analysis whether LLMs can learn these features effectively and apply them to important nature language related tasks, we introduce a novel multilingual genre classification dataset derived from Project Gutenberg, a large-scale digital library offering free access to thousands of public domain literary works, comprising thousands of sentences per binary task (poetry vs. novel;drama vs. poetry;drama vs. novel) in six languages (English, French, German, Italian, Spanish, and Portuguese). We augment each with three explicit linguistic feature sets (syntactic tree structures, metaphor counts, and phonetic metrics) to evaluate their impact on classification performance. Experiments demonstrate that although LLM classifiers can learn latent linguistic structures either from raw text or from explicitly provided features, different features contribute unevenly across tasks, which underscores the importance of incorporating more complex linguistic signals during model training."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Â∏ñÂ≠ê","item":"https://garyforreal.me/zh/posts/"},{"@type":"ListItem","position":2,"name":"Â≠¶‰π†","item":"https://garyforreal.me/zh/posts/study/"},{"@type":"ListItem","position":3,"name":"Weekly Paper Notes - 2025-12-05","item":"https://garyforreal.me/zh/posts/study/paper-2025-12-05-weekly/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Weekly Paper Notes - 2025-12-05","name":"Weekly Paper Notes - 2025-12-05","description":"Weekly Paper Notes üîç multilingual LLMs Know More Than Words: A Genre Study with Syntax, Metaphor \u0026amp; Phonetics Authors: Weiye Shi, Zhaowei Zhang, Shaoheng Yan, Yaodong Yang Venue: arXiv (2025)\nLarge language models (LLMs) demonstrate remarkable potential across diverse language related tasks, yet whether they capture deeper linguistic properties, such as syntactic structure, phonetic cues, and metrical patterns from raw text remains unclear. To analysis whether LLMs can learn these features effectively and apply them to important nature language related tasks, we introduce a novel multilingual genre classification dataset derived from Project Gutenberg, a large-scale digital library offering free access to thousands of public domain literary works, comprising thousands of sentences per binary task (poetry vs. novel;drama vs. poetry;drama vs. novel) in six languages (English, French, German, Italian, Spanish, and Portuguese). We augment each with three explicit linguistic feature sets (syntactic tree structures, metaphor counts, and phonetic metrics) to evaluate their impact on classification performance. Experiments demonstrate that although LLM classifiers can learn latent linguistic structures either from raw text or from explicitly provided features, different features contribute unevenly across tasks, which underscores the importance of incorporating more complex linguistic signals during model training.\n","keywords":[],"articleBody":"Weekly Paper Notes üîç multilingual LLMs Know More Than Words: A Genre Study with Syntax, Metaphor \u0026 Phonetics Authors: Weiye Shi, Zhaowei Zhang, Shaoheng Yan, Yaodong Yang Venue: arXiv (2025)\nLarge language models (LLMs) demonstrate remarkable potential across diverse language related tasks, yet whether they capture deeper linguistic properties, such as syntactic structure, phonetic cues, and metrical patterns from raw text remains unclear. To analysis whether LLMs can learn these features effectively and apply them to important nature language related tasks, we introduce a novel multilingual genre classification dataset derived from Project Gutenberg, a large-scale digital library offering free access to thousands of public domain literary works, comprising thousands of sentences per binary task (poetry vs. novel;drama vs. poetry;drama vs. novel) in six languages (English, French, German, Italian, Spanish, and Portuguese). We augment each with three explicit linguistic feature sets (syntactic tree structures, metaphor counts, and phonetic metrics) to evaluate their impact on classification performance. Experiments demonstrate that although LLM classifiers can learn latent linguistic structures either from raw text or from explicitly provided features, different features contribute unevenly across tasks, which underscores the importance of incorporating more complex linguistic signals during model training.\nüì• Save to Zotero üìÑ Download PDF\nToward Continuous Neurocognitive Monitoring: Integrating Speech AI with Relational Graph Transformers for Rare Neurological Diseases Authors: Raquel Norel, Michele Merler, Pavitra Modi Venue: arXiv (2025)\nPatients with rare neurological diseases report cognitive symptoms -‚Äúbrain fog‚Äù- invisible to traditional tests. We propose continuous neurocognitive monitoring via smartphone speech analysis integrated with Relational Graph Transformer (RELGT) architectures. Proof-of-concept in phenylketonuria (PKU) shows speech-derived ‚ÄúProficiency in Verbal Discourse‚Äù correlates with blood phenylalanine (p = -0.50, p \u003c 0.005) but not standard cognitive tests (all |r| \u003c 0.35). RELGT could overcome information bottlenecks in heterogeneous medical data (speech, labs, assessments), enabling predictive alerts weeks before decompensation. Key challenges: multi-disease validation, clinical workflow integration, equitable multilingual deployment. Success would transform episodic neurology into continuous personalized monitoring for millions globally.\nüì• Save to Zotero üìÑ Download PDF\nAre LLMs Truly Multilingual? Exploring Zero-Shot Multilingual Capability of LLMs for Information Retrieval: An Italian Healthcare Use Case Authors: Vignesh Kumar Kembu, Pierandrea Morandini, Marta Bianca Maria Ranzini, Antonino Nocera Venue: arXiv (2025)\nLarge Language Models (LLMs) have become a key topic in AI and NLP, transforming sectors like healthcare, finance, education, and marketing by improving customer service, automating tasks, providing insights, improving diagnostics, and personalizing learning experiences. Information extraction from clinical records is a crucial task in digital healthcare. Although traditional NLP techniques have been used for this in the past, they often fall short due to the complexity, variability of clinical language, and high inner semantics in the free clinical text. Recently, Large Language Models (LLMs) have become a powerful tool for better understanding and generating human-like text, making them highly effective in this area. In this paper, we explore the ability of open-source multilingual LLMs to understand EHRs (Electronic Health Records) in Italian and help extract information from them in real-time. Our detailed experimental campaign on comorbidity extraction from EHR reveals that some LLMs struggle in zero-shot, on-premises settings, and others show significant variation in performance, struggling to generalize across various diseases when compared to native pattern matching and manual annotations.\nüì• Save to Zotero üìÑ Download PDF\nShared Multi-modal Embedding Space for Face-Voice Association Authors: Christopher Simic, Korbinian Riedhammer, Tobias Bocklet Venue: arXiv (2025)\nThe FAME 2026 challenge comprises two demanding tasks: training face-voice associations combined with a multilingual setting that includes testing on languages on which the model was not trained. Our approach consists of separate uni-modal processing pipelines with general face and voice feature extraction, complemented by additional age-gender feature extraction to support prediction. The resulting single-modal features are projected into a shared embedding space and trained with an Adaptive Angular Margin (AAM) loss. Our approach achieved first place in the FAME 2026 challenge, with an average Equal-Error Rate (EER) of 23.99%.\nüì• Save to Zotero üìÑ Download PDF\nAdiBhashaa: A Community-Curated Benchmark for Machine Translation into Indian Tribal Languages Authors: Pooja Singh, Sandeep Kumar Venue: arXiv (2025)\nLarge language models and multilingual machine translation (MT) systems increasingly drive access to information, yet many languages of the tribal communities remain effectively invisible in these technologies. This invisibility exacerbates existing structural inequities in education, governance, and digital participation. We present AdiBhashaa, a community-driven initiative that constructs the first open parallel corpora and baseline MT systems for four major Indian tribal languages-Bhili, Mundari, Gondi, and Santali. This work combines participatory data creation with native speakers, human-in-the-loop validation, and systematic evaluation of both encoder-decoder MT models and large language models. In addition to reporting technical findings, we articulate how AdiBhashaa illustrates a possible model for more equitable AI research: it centers local expertise, builds capacity among early-career researchers from marginalized communities, and foregrounds human validation in the development of language technologies.\nüì• Save to Zotero üìÑ Download PDF\nHas ACL Lost Its Crown? A Decade-Long Quantitative Analysis of Scale and Impact Across Leading AI Conferences Authors: Jianglin Ma, Ben Yao, Xiang Li, Yazhou Zhang Venue: arXiv (2025)\nThe recent surge of language models has rapidly expanded NLP research, driving an exponential rise in submissions and acceptances at major conferences. Yet this growth has been shadowed by escalating concerns over conference quality, e.g., plagiarism, reviewer inexperience and collusive bidding. However, existing studies rely largely on qualitative accounts (e.g., expert interviews, social media discussions, etc.), lacking longitudinal empirical evidence. To fill this gap, we conduct a ten year empirical study spanning seven leading conferences. We build a four dimensional bibliometric framework covering conference scale, core citation statistics,impact dispersion, cross venue and journal influence, etc. Notably, we further propose a metric Quality Quantity Elasticity, which measures the elasticity of citation growth relative to acceptance growth. Our findings show that ML venues sustain dominant and stable impact, NLP venues undergo widening stratification with mixed expansion efficiency, and AI venues exhibit structural decline. This study provides the first decade-long, cross-venue empirical evidence on the evolution of major conferences.\nüì• Save to Zotero üìÑ Download PDF\nMASE: Interpretable NLP Models via Model-Agnostic Saliency Estimation Authors: Zhou Yang, Shunyan Luo, Jiazhen Zhu, Fang Jin Venue: arXiv (2025)\nDeep neural networks (DNNs) have made significant strides in Natural Language Processing (NLP), yet their interpretability remains elusive, particularly when evaluating their intricate decision-making processes. Traditional methods often rely on post-hoc interpretations, such as saliency maps or feature visualization, which might not be directly applicable to the discrete nature of word data in NLP. Addressing this, we introduce the Model-agnostic Saliency Estimation (MASE) framework. MASE offers local explanations for text-based predictive models without necessitating in-depth knowledge of a model‚Äôs internal architecture. By leveraging Normalized Linear Gaussian Perturbations (NLGP) on the embedding layer instead of raw word inputs, MASE efficiently estimates input saliency. Our results indicate MASE‚Äôs superiority over other model-agnostic interpretation methods, especially in terms of Delta Accuracy, positioning it as a promising tool for elucidating the operations of text-based models in NLP.\nüì• Save to Zotero üìÑ Download PDF\nLangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving Authors: Muyu Pan, Matthew Walter, Dheeraj Kodakandla, Mahfuza Farooque Venue: arXiv (2025)\nOur work presents a novel reinforcement learning (RL) based framework to optimize heuristic selection within the conflict-driven clause learning (CDCL) process, improving the efficiency of Boolean satisfiability (SAT) solving. The proposed system, LangSAT, bridges the gap between natural language inputs and propositional logic by converting English descriptions into Conjunctive Normal Form (CNF) expressions and solving them using an RL-enhanced CDCL SAT solver. Unlike existing SAT-solving platforms that require CNF as input, LangSAT enables users to input standard English descriptions, making SAT-solving more accessible. The framework comprises two key components: Lang2Logic, which translates English sentences into CNF expressions, and SmartSAT, an RL-based SAT solver. SmartSAT encodes clause-variable relationships as structured graph representations and extracts global features specific to the SAT problem. This implementation provides the RL agent with deeper contextual information, enabling SAT problems to be solved more efficiently. Lang2Logic was evaluated on diverse natural language inputs, processing descriptions up to 450 words. The generated CNFs were solved by SmartSAT, which demonstrated comparable performance to traditional CDCL heuristics with respect to solving time. The combined LangSAT framework offers a more accessible and scalable solution for SAT-solving tasks across reasoning, formal verification, and debugging.\nüì• Save to Zotero üìÑ Download PDF\nComputational Linguistics Meets Libyan Dialect: A Study on Dialect Identification Authors: Mansour Essgaer, Khamis Massud, Rabia Al Mamlook, Najah Ghmaid Venue: arXiv (2025)\nThis study investigates logistic regression, linear support vector machine, multinomial Naive Bayes, and Bernoulli Naive Bayes for classifying Libyan dialect utterances gathered from Twitter. The dataset used is the QADI corpus, which consists of 540,000 sentences across 18 Arabic dialects. Preprocessing challenges include handling inconsistent orthographic variations and non-standard spellings typical of the Libyan dialect. The chi-square analysis revealed that certain features, such as email mentions and emotion indicators, were not significantly associated with dialect classification and were thus excluded from further analysis. Two main experiments were conducted: (1) evaluating the significance of meta-features extracted from the corpus using the chi-square test and (2) assessing classifier performance using different word and character n-gram representations. The classification experiments showed that Multinomial Naive Bayes (MNB) achieved the highest accuracy of 85.89% and an F1-score of 0.85741 when using a (1,2) word n-gram and (1,5) character n-gram representation. In contrast, Logistic Regression and Linear SVM exhibited slightly lower performance, with maximum accuracies of 84.41% and 84.73%, respectively. Additional evaluation metrics, including log loss, Cohen kappa, and Matthew correlation coefficient, further supported the effectiveness of MNB in this task. The results indicate that carefully selected n-gram representations and classification models play a crucial role in improving the accuracy of Libyan dialect identification. This study provides empirical benchmarks and insights for future research in Arabic dialect NLP applications.\nüì• Save to Zotero üìÑ Download PDF\nProbabilistic Safety under Arbitrary Disturbance Distributions using Piecewise-Affine Control Barrier Functions Authors: Matisse Teuwen, Mathijs Schuurmans, Panagiotis Patrinos Venue: arXiv (2025)\nWe propose a simple safety filter design for stochastic discrete-time systems based on piecewise affine probabilistic control barrier functions, providing an appealing balance between modeling flexibility and computational complexity. Exact evaluation of the safety filter consists of solving a mixed-integer quadratic program (MIQP) if the dynamics are control-affine (or a mixed-integer nonlinear program in general). We propose a heuristic search method that replaces this by a small number of small-scale quadratic programs (QPs), or nonlinear programs (NLPs) respectively. The proposed approach provides a flexible framework in which arbitrary (data-driven) quantile estimators can be used to bound the probability of safety violations. Through extensive numerical experiments, we demonstrate improvements in conservatism and computation time with respect to existing methods, and we illustrate the flexibility of the method for modeling complex safety sets. Supplementary material can be found at https://mathijssch.github.io/ecc26-supplementary/.\nüì• Save to Zotero üìÑ Download PDF\nJina-VLM: Small Multilingual Vision Language Model Authors: Andreas Koukounas, Georgios Mastrapas, Florian H√∂nicke, Sedigheh Eslami, Guillaume Roncari, Scott Martens, Han Xiao Venue: arXiv (2025)\nWe present Jina-VLM, a 2.4B parameter vision-language model that achieves state-of-the-art multilingual visual question answering among open 2B-scale VLMs. The model couples a SigLIP2 vision encoder with a Qwen3 language backbone through an attention-pooling connector that enables token-efficient processing of arbitrary-resolution images. The model achieves leading results on standard VQA benchmarks and multilingual evaluations while preserving competitive text-only performance. Model weights and code are publicly released at https://huggingface.co/jinaai/jina-vlm .\nüì• Save to Zotero üìÑ Download PDF\nAdapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study Authors: Lifeng Chen, Ryan Lai, Tianming Liu Venue: arXiv (2025)\nAdapting large language models (LLMs) to low-resource languages remains a major challenge due to data scarcity and cross-lingual drift. This work presents a two-stage adaptation of Qwen2.5-3B to Tibetan, a morphologically rich and underrepresented language. We employ Continual Pretraining (CPT) to establish Tibetan linguistic grounding, followed by Supervised Fine-Tuning (SFT) for task and translation specialization. Empirical evaluations demonstrate a consistent decrease in perplexity (from 2.98 $\\rightarrow$ 1.54) and substantial improvements in Chinese$\\rightarrow$Tibetan translation quality (BLEU: 0.046 $\\rightarrow$ 0.261; chrF: 2.2 $\\rightarrow$ 6.6). Layer-wise analysis across 435 layers in Qwen3-4B reveals that adaptation primarily concentrates on embedding and output heads, with mid‚Äìlate MLP projections encoding domain-specific transformations. Our findings suggest that CPT constructs a Tibetan semantic manifold while SFT sharpens task alignment with minimal representational disruption. This study provides the first quantitative exploration of Tibetan adaptation dynamics for LLMs, and offers an open, reproducible framework for extending multilingual foundation models to low-resource settings.\nüì• Save to Zotero üìÑ Download PDF\nIs Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions Authors: Kazi Abrab Hossain, Jannatul Somiya Mahmud, Maria Hossain Tuli, Anik Mitra, S. M. Taiabul Haque, Farig Y. Sadeque Venue: arXiv (2025)\nWhile recent developments in large language models have improved bias detection and classification, sensitive subjects like religion still present challenges because even minor errors can result in severe misunderstandings. In particular, multilingual models often misrepresent religions and have difficulties being accurate in religious contexts. To address this, we introduce BRAND: Bilingual Religious Accountable Norm Dataset, which focuses on the four main religions of South Asia: Buddhism, Christianity, Hinduism, and Islam, containing over 2,400 entries, and we used three different types of prompts in both English and Bengali. Our results indicate that models perform better in English than in Bengali and consistently display bias toward Islam, even when answering religion-neutral questions. These findings highlight persistent bias in multilingual models when similar questions are asked in different languages. We further connect our findings to the broader issues in HCI regarding religion and spirituality.\nüì• Save to Zotero üìÑ Download PDF\nDiminishing Returns in Self-Supervised Learning Authors: Oli Bridge, Huey Sun, Botond Branyicskai-Nagy, Charles D‚ÄôOrnano, Shomit Basu Venue: arXiv (2025)\nWhile transformer-based architectures have taken computer vision and NLP by storm, they often require a vast amount of parameters and training data to attain strong performance. In this work, we experiment with three distinct pre-training, intermediate fine-tuning, and downstream datasets and training objectives to explore their marginal benefits on a small 5M-parameter vision transformer. We find that while pre-training and fine-tuning always help our model but have diminishing returns, intermediate fine-tuning can actually show harmful impact on downstream performance, potentially due to dissimilarity in task mechanics. Taken together, our results suggest that small-scale ViTs benefit most from targeted pre-training and careful data selection, while indiscriminate stacking of intermediate tasks can waste compute and even degrade performance.\nüì• Save to Zotero üìÑ Download PDF\nM3DR: Towards Universal Multilingual Multimodal Document Retrieval Authors: Adithya S Kolavi, Vyoman Jain Venue: arXiv (2025)\nMultimodal document retrieval systems have shown strong progress in aligning visual and textual content for semantic search. However, most existing approaches remain heavily English-centric, limiting their effectiveness in multilingual contexts. In this work, we present M3DR (Multilingual Multimodal Document Retrieval), a framework designed to bridge this gap across languages, enabling applicability across diverse linguistic and cultural contexts. M3DR leverages synthetic multilingual document data and generalizes across different vision-language architectures and model sizes, enabling robust cross-lingual and cross-modal alignment. Using contrastive training, our models learn unified representations for text and document images that transfer effectively across languages. We validate this capability on 22 typologically diverse languages, demonstrating consistent performance and adaptability across linguistic and script variations. We further introduce a comprehensive benchmark that captures real-world multilingual scenarios, evaluating models under monolingual, multilingual, and mixed-language settings. M3DR generalizes across both single dense vector and ColBERT-style token-level multi-vector retrieval paradigms. Our models, NetraEmbed and ColNetraEmbed achieve state-of-the-art performance with ~150% relative improvements on cross-lingual retrieval.\nüì• Save to Zotero üìÑ Download PDF\nDual LoRA: Enhancing LoRA with Magnitude and Direction Updates Authors: Yixing Xu, Chao Li, Xuanwu Yin, Spandan Tiwari, Dong Li, Ashish Sirasao, Emad Barsoum Venue: arXiv (2025)\nLow-rank adaptation (LoRA) is one of the most popular methods among parameter-efficient fine-tuning (PEFT) methods to adapt pre-trained large language models (LLMs) to specific downstream tasks. However, the model trained based on LoRA often has an unsatisfactory performance due to its low-rank assumption. In this paper, we propose a novel method called Dual LoRA to improve the performance by incorporating an inductive bias into the original LoRA. Specifically, we separate low-rank matrices into two groups: the magnitude group to control whether or not and how far we should update a parameter and the direction group to decide whether this parameter should move forward or backward, to better simulate the parameter updating process of the full fine-tuning based on gradient-based optimization algorithms. We show that this can be simply achieved by adding a ReLU function to the magnitude group and a sign function to the direction group. We conduct several experiments over a wide range of NLP tasks, including natural language generation (NLG), understanding (NLU), and commonsense reasoning datasets on GPT-2, RoBERTa, DeBERTa, and LLaMA-1/2/3 as baseline models. The results show that we consistently outperform LoRA and its state-of-the-art variants with the same number of trainable parameters.\nüì• Save to Zotero üìÑ Download PDF\nFine-Tuned Large Language Models for Logical Translation: Reducing Hallucinations with Lang2Logic Authors: Muyu Pan, Dheeraj Kodakandla, Mahfuza Farooque Venue: arXiv (2025)\nRecent advances in natural language processing (NLP), particularly large language models (LLMs), have motivated the automatic translation of natural language statements into formal logic without human intervention. This enables automated reasoning and facilitates debugging, finding loop invariants, and adhering to specifications in software systems. However, hallucinations-incorrect outputs generated by LLMs are challenging, particularly for logical translation tasks requiring precision. This work introduces a novel framework that inputs English sentences, converts them into logical expressions, and then translates them into Conjunctive Normal Form (CNF) for satisfiability solving. It employs classical NLP techniques with self-defined grammar, symbolic computation libraries, and a fine-tuned language model to reduce hallucinations. In the early experiments, we observed that the fine-tuned model, trained on different grammar settings, could intentionally correct the same types of hallucinations made by the original model. Thus, it provides reliable CNF generation.\nüì• Save to Zotero üìÑ Download PDF\nRFOP: Rethinking Fusion and Orthogonal Projection for Face-Voice Association Authors: Abdul Hannan, Furqan Malik, Hina Jabbar, Syed Suleman Sadiq, Mubashir Noman Venue: arXiv (2025)\nFace-voice association in multilingual environment challenge 2026 aims to investigate the face-voice association task in multilingual scenario. The challenge introduces English-German face-voice pairs to be utilized in the evaluation phase. To this end, we revisit the fusion and orthogonal projection for face-voice association by effectively focusing on the relevant semantic information within the two modalities. Our method performs favorably on the English-German data split and ranked 3rd in the FAME 2026 challenge by achieving the EER of 33.1.\nüì• Save to Zotero üìÑ Download PDF\nCross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages Authors: Lechen Zhang, Yusheng Zhou, Tolga Ergen, Lajanugen Logeswaran, Moontae Lee, David Jurgens Venue: arXiv (2025)\nSystem prompts provide a lightweight yet powerful mechanism for conditioning large language models (LLMs) at inference time. While prior work has focused on English-only settings, real-world deployments benefit from having a single prompt to operate reliably across languages. This paper presents a comprehensive study of how different system prompts steer models toward accurate and robust cross-lingual behavior. We propose a unified four-dimensional evaluation framework to assess system prompts in multilingual environments. Through large-scale experiments on five languages, three LLMs, and three benchmarks, we uncover that certain prompt components, such as CoT, emotion, and scenario, correlate with robust multilingual behavior. We develop a prompt optimization framework for multilingual settings and show it can automatically discover prompts that improve all metrics by 5-10%. Finally, we analyze over 10 million reasoning units and find that more performant system prompts induce more structured and consistent reasoning patterns, while reducing unnecessary language-switching. Together, we highlight system prompt optimization as a scalable path to accurate and robust multilingual LLM behavior.\nüì• Save to Zotero üìÑ Download PDF\nBOOM: Beyond Only One Modality KIT‚Äôs Multimodal Multilingual Lecture Companion Authors: Sai Koneru, Fabian Retkowski, Christian Huber, Lukas Hilgert, Seymanur Akti, Enes Yavuz Ugan, Alexander Waibel, Jan Niehues Venue: arXiv (2025)\nThe globalization of education and rapid growth of online learning have made localizing educational content a critical challenge. Lecture materials are inherently multimodal, combining spoken audio with visual slides, which requires systems capable of processing multiple input modalities. To provide an accessible and complete learning experience, translations must preserve all modalities: text for reading, slides for visual understanding, and speech for auditory learning. We present \\textbf{BOOM}, a multimodal multilingual lecture companion that jointly translates lecture audio and slides to produce synchronized outputs across three modalities: translated text, localized slides with preserved visual elements, and synthesized speech. This end-to-end approach enables students to access lectures in their native language while aiming to preserve the original content in its entirety. Our experiments demonstrate that slide-aware transcripts also yield cascading benefits for downstream tasks such as summarization and question answering. We release our Slide Translation code at https://github.com/saikoneru/image-translator and integrate it in Lecture Translator at https://gitlab.kit.edu/kit/isl-ai4lt/lt-middleware/ltpipeline}\\footnote{All released code and models are licensed under the MIT License.\nüì• Save to Zotero üìÑ Download PDF\nTriLex: A Framework for Multilingual Sentiment Analysis in Low-Resource South African Languages Authors: Mike Nkongolo, Hilton Vorster, Josh Warren, Trevor Naick, Deandre Vanmali, Masana Mashapha, Luke Brand, Alyssa Fernandes, Janco Calitz, Sibusiso Makhoba Venue: arXiv (2025)\nLow-resource African languages remain underrepresented in sentiment analysis, limiting both lexical coverage and the performance of multilingual Natural Language Processing (NLP) systems. This study proposes TriLex, a three-stage retrieval augmented framework that unifies corpus-based extraction, cross lingual mapping, and retrieval augmented generation (RAG) driven lexical refinement to systematically expand sentiment lexicons for low-resource languages. Using the enriched lexicon, the performance of two prominent African pretrained language models (AfroXLMR and AfriBERTa) is evaluated across multiple case studies. Results demonstrate that AfroXLMR delivers superior performance, achieving F1-scores above 80% for isiXhosa and isiZulu and exhibiting strong cross-lingual stability. Although AfriBERTa lacks pre-training on these target languages, it still achieves reliable F1-scores around 64%, validating its utility in computationally constrained settings. Both models outperform traditional machine learning baselines, and ensemble analyses further enhance precision and robustness. The findings establish TriLex as a scalable and effective framework for multilingual sentiment lexicon expansion and sentiment modeling in low-resource South African languages.\nüì• Save to Zotero üìÑ Download PDF\nTowards Language-Independent Face-Voice Association with Multimodal Foundation Models Authors: Aref Farhadipour, Teodora Vukovic, Volker Dellwo Venue: arXiv (2025)\nThis paper describes the UZH-CL system submitted to the FAME2026 Challenge. The challenge focuses on cross-modal verification under unique multilingual conditions, specifically unseen and unheard languages. Our approach investigates two distinct architectures, consisting of a baseline dual-encoder system trained from scratch using contrastive and orthogonal projection losses, and a foundation model approach leveraging ImageBind with LoRA. To address the data scarcity and language constraints of the challenge, we curated an external Arabic dataset from VoxBlink. Our best-performing system, ImageBind-LoRA, demonstrates remarkable cross-lingual generalization: despite being fine-tuned exclusively on Arabic audio, it achieved an EER of 24.73% on the evaluation set (English and German), securing 2nd place in the competition.\nüì• Save to Zotero üìÑ Download PDF\nCREST: Universal Safety Guardrails Through Cluster-Guided Cross-Lingual Transfer Authors: Lavish Bansal, Naman Mishra Venue: arXiv (2025)\nEnsuring content safety in large language models (LLMs) is essential for their deployment in real-world applications. However, existing safety guardrails are predominantly tailored for high-resource languages, leaving a significant portion of the world‚Äôs population underrepresented who communicate in low-resource languages. To address this, we introduce CREST (CRoss-lingual Efficient Safety Transfer), a parameter-efficient multilingual safety classification model that supports 100 languages with only 0.5B parameters. By training on a strategically chosen subset of only 13 high-resource languages, our model utilizes cluster-based cross-lingual transfer from a few to 100 languages, enabling effective generalization to both unseen high-resource and low-resource languages. This approach addresses the challenge of limited training data in low-resource settings. We conduct comprehensive evaluations across six safety benchmarks to demonstrate that CREST outperforms existing state-of-the-art guardrails of comparable scale and achieves competitive results against models with significantly larger parameter counts (2.5B parameters and above). Our findings highlight the limitations of language-specific guardrails and underscore the importance of developing universal, language-agnostic safety systems that can scale effectively to serve global populations.\nüì• Save to Zotero üìÑ Download PDF\ndots.ocr: Multilingual Document Layout Parsing in a Single Vision-Language Model Authors: Yumeng Li, Guang Yang, Hao Liu, Bowen Wang, Colin Zhang Venue: arXiv (2025)\nDocument Layout Parsing serves as a critical gateway for Artificial Intelligence (AI) to access and interpret the world‚Äôs vast stores of structured knowledge. This process,which encompasses layout detection, text recognition, and relational understanding, is particularly crucial for empowering next-generation Vision-Language Models. Current methods, however, rely on fragmented, multi-stage pipelines that suffer from error propagation and fail to leverage the synergies of joint training. In this paper, we introduce dots.ocr, a single Vision-Language Model that, for the first time, demonstrates the advantages of jointly learning three core tasks within a unified, end-to-end framework. This is made possible by a highly scalable data engine that synthesizes a vast multilingual corpus, empowering the model to deliver robust performance across a wide array of tasks, encompassing diverse languages, layouts, and domains. The efficacy of our unified paradigm is validated by state-of-the-art performance on the comprehensive OmniDocBench. Furthermore, to catalyze research in global document intelligence, we introduce XDocParse, a challenging new benchmark spanning 126 languages. On this testbed, dots.ocr establishes a powerful new baseline, outperforming the next-best competitor by a remarkable +7.4 point margin and proving its unparalleled multilingual capabilities.\nüì• Save to Zotero üìÑ Download PDF\nSwivuriso: The South African Next Voices Multilingual Speech Dataset Authors: Vukosi Marivatee, Kayode Olaleye, Sitwala Mundia, Andinda Bakainga, Unarine Netshifhefhe, Mahmooda Milanzie, Tsholofelo Hope Mogale, Thapelo Sindane, Zainab Abdulrasaq, Kesego Mokgosi, Chijioke Okorie, Nia Zion Van Wyk, Graham Morrissey, Dale Dunbar, Francois Smit, Tsosheletso Chidi, Rooweither Mabuya, Andiswa Bukula, Respect Mlambo, Tebogo Macucwa, Idris Abdulmumin, and Seani Rananga Venue: arXiv (2025)\nThis paper introduces Swivuriso, a 3000-hour multilingual speech dataset developed as part of the African Next Voices project, to support the development and benchmarking of automatic speech recognition (ASR) technologies in seven South African languages. Covering agriculture, healthcare, and general domain topics, Swivuriso addresses significant gaps in existing ASR datasets. We describe the design principles, ethical considerations, and data collection procedures that guided the dataset creation. We present baseline results of training/finetuning ASR models with this data and compare to other ASR datasets for the langauges concerned.\nüì• Save to Zotero üìÑ Download PDF\nCross-Lingual Interleaving for Speech Language Models Authors: Adel Moumen, Guangzhi Sun, Philip C. Woodland Venue: arXiv (2025)\nSpoken Language Models (SLMs) aim to learn linguistic competence directly from speech using discrete units, widening access to Natural Language Processing (NLP) technologies for languages with limited written resources. However, progress has been largely English-centric due to scarce spoken evaluation benchmarks and training data, making cross-lingual learning difficult. We present a cross-lingual interleaving method that mixes speech tokens across languages without textual supervision. We also release an EN-FR training dataset, TinyStories (~42k hours), together with EN-FR spoken StoryCloze and TopicCloze benchmarks for cross-lingual semantic evaluation, both synthetically generated using GPT-4. On 360M and 1B SLMs under matched training-token budgets, interleaving improves monolingual semantic accuracy, enables robust cross-lingual continuation, and strengthens cross-lingual hidden-state alignment. Taken together, these results indicate that cross-lingual interleaving is a simple, scalable route to building multilingual SLMs that understand and converse across languages. All resources will be made open-source to support reproducibility.\nüì• Save to Zotero üìÑ Download PDF\nBHRAM-IL: A Benchmark for Hallucination Recognition and Assessment in Multiple Indian Languages Authors: Hrishikesh Terdalkar, Kirtan Bhojani, Aryan Dongare, Omm Aditya Behera Venue: arXiv (2025)\nLarge language models (LLMs) are increasingly deployed in multilingual applications but often generate plausible yet incorrect or misleading outputs, known as hallucinations. While hallucination detection has been studied extensively in English, under-resourced Indian languages remain largely unexplored. We present BHRAM-IL, a benchmark for hallucination recognition and assessment in multiple Indian languages, covering Hindi, Gujarati, Marathi, Odia, along with English. The benchmark comprises 36,047 curated questions across nine categories spanning factual, numerical, reasoning, and linguistic tasks. We evaluate 14 state-of-the-art multilingual LLMs on a benchmark subset of 10,265 questions, analyzing cross-lingual and factual hallucinations across languages, models, scales, categories, and domains using category-specific metrics normalized to (0,1) range. Aggregation over all categories and models yields a primary score of 0.23 and a language-corrected fuzzy score of 0.385, demonstrating the usefulness of BHRAM-IL for hallucination-focused evaluation. The dataset, and the code for generation and evaluation are available on GitHub (https://github.com/sambhashana/BHRAM-IL/) and HuggingFace (https://huggingface.co/datasets/sambhashana/BHRAM-IL/) to support future research in multilingual hallucination detection and mitigation.\nüì• Save to Zotero üìÑ Download PDF\nSelf-Supervised Borrowing Detection on Multilingual Wordlists Authors: Tim Wientzek Venue: arXiv (2025)\nThis paper presents a fully self-supervised approach to borrowing detection in multilingual wordlists. The method combines two sources of information: PMI similarities based on a global correspondence model and a lightweight contrastive component trained on phonetic feature vectors. It further includes an automatic procedure for selecting decision thresholds without requiring labeled data. Experiments on benchmark datasets show that PMI alone already improves over existing string similarity measures such as NED and SCA, and that the combined similarity performs on par with or better than supervised baselines. An ablation study highlights the importance of character encoding, temperature settings and augmentation strategies. The approach scales to datasets of different sizes, works without manual supervision and is provided with a command-line tool that allows researchers to conduct their own studies.\nüì• Save to Zotero üìÑ Download PDF\nDemystifying Feature Engineering in Malware Analysis of API Call Sequences Authors: Tianheng Qu, Hongsong Zhu, Limin Sun, Haining Wang, Haiqiang Fei, Zheng He, Zhi Li Venue: arXiv (2025)\nMachine learning (ML) has been widely used to analyze API call sequences in malware analysis, which typically requires the expertise of domain specialists to extract relevant features from raw data. The extracted features play a critical role in malware analysis. Traditional feature extraction is based on human domain knowledge, while there is a trend of using natural language processing (NLP) for automatic feature extraction. This raises a question: how do we effectively select features for malware analysis based on API call sequences? To answer it, this paper presents a comprehensive study of investigating the impact of feature engineering upon malware classification.We first conducted a comparative performance evaluation under three models, Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and Transformer, with respect to knowledge-based and NLP-based feature engineering methods. We observed that models with knowledge-based feature engineering inputs generally outperform those using NLP-based across all metrics, especially under smaller sample sizes. Then we analyzed a complete set of data features from API call sequences, our analysis reveals that models often focus on features such as handles and virtual addresses, which vary across executions and are difficult for human analysts to interpret.\nüì• Save to Zotero üìÑ Download PDF\nDeep FlexQP: Accelerated Nonlinear Programming via Deep Unfolding Authors: Alex Oshin, Rahul Vodeb Ghosh, Augustinos D. Saravanos, Evangelos A. Theodorou Venue: arXiv (2025)\nWe propose an always-feasible quadratic programming (QP) optimizer, FlexQP, which is based on an exact relaxation of the QP constraints. If the original constraints are feasible, then the optimizer finds the optimal solution to the original QP. On the other hand, if the constraints are infeasible, the optimizer identifies a solution that minimizes the constraint violation in a sparse manner. FlexQP scales favorably with respect to the problem dimension, is robust to both feasible and infeasible QPs with minimal assumptions on the problem data, and can be effectively warm-started. We subsequently apply deep unfolding to improve our optimizer through data-driven techniques, leading to an accelerated Deep FlexQP. By learning dimension-agnostic feedback policies for the parameters from a small number of training examples, Deep FlexQP generalizes to problems with larger dimensions and can optimize for many more iterations than it was initially trained for. Our approach outperforms two recently proposed state-of-the-art accelerated QP approaches on a suite of benchmark systems including portfolio optimization, classification, and regression problems. We provide guarantees on the expected performance of our deep QP optimizer through probably approximately correct (PAC) Bayes generalization bounds. These certificates are used to design an accelerated sequential quadratic programming solver that solves nonlinear optimal control and predictive safety filter problems faster than traditional approaches. Overall, our approach is very robust and greatly outperforms existing non-learning and learning-based optimizers in terms of both runtime and convergence to the optimal solution across multiple classes of NLPs.\nüì• Save to Zotero üìÑ Download PDF\nMCAT: Scaling Many-to-Many Speech-to-Text Translation with MLLMs to 70 Languages Authors: Yexing Du, Kaiyuan Liu, Youcheng Pan, Bo Yang, Keqi Deng, Xie Chen, Yang Xiang, Ming Liu, Bin Qin, YaoWei Wang Venue: arXiv (2025)\nMultimodal Large Language Models (MLLMs) have achieved great success in Speech-to-Text Translation (S2TT) tasks. However, current research is constrained by two key challenges: language coverage and efficiency. Most of the popular S2TT datasets are substantially English-centric, which restricts the scaling-up of MLLMs‚Äô many-to-many translation capabilities. Moreover, the inference speed of MLLMs degrades dramatically when the speech is converted into long sequences (e.g., 750 tokens). To address these limitations, we propose a Multilingual Cost-effective Accelerated Speech-to-Text Translator (MCAT) framework, which includes two innovations. First, a language scaling method that leverages curriculum learning and a data balancing strategy is introduced to extend the language coverage supported by MLLMs to 70 languages and achieve mutual translation among these languages. Second, an optimized speech adapter module is designed to reduce the length of the speech sequence to only 30 tokens. Extensive experiments were conducted on MLLMs of different scales (9B and 27B). The experimental results demonstrate that MCAT not only surpasses state-of-the-art end-to-end models on the FLEURS dataset across 70x69 directions but also enhances batch inference efficiency. This is achieved with only ~100M trainable parameters and by using only 10 hours of S2TT data per language. Furthermore, we have released MCAT as open-source to promote the development of MLLMs for robust S2TT capabilities. The code and models are released at https://github.com/yxduir/m2m-70.\nüì• Save to Zotero üìÑ Download PDF\nMultilingual Conversational AI for Financial Assistance: Bridging Language Barriers in Indian FinTech Authors: Bharatdeep Hazarika, Arya Suneesh, Prasanna Devadiga, Pawan Kumar Rajpoot, Anshuman B Suresh, Ahmed Ifthaquar Hussain Venue: arXiv (2025)\nIndia‚Äôs linguistic diversity presents both opportunities and challenges for fintech platforms. While the country has 31 major languages and over 100 minor ones, only 10% of the population understands English, creating barriers to financial inclusion. We present a multilingual conversational AI system for a financial assistance use case that supports code-mixed languages like Hinglish, enabling natural interactions for India‚Äôs diverse user base. Our system employs a multi-agent architecture with language classification, function management, and multilingual response generation. Through comparative analysis of multiple language models and real-world deployment, we demonstrate significant improvements in user engagement while maintaining low latency overhead (4-8%). This work contributes to bridging the language gap in digital financial services for emerging markets.\nüì• Save to Zotero üìÑ Download PDF\nBackportBench: A Multilingual Benchmark for Automated Backporting of Patches Authors: Zhiqing Zhong, Jiaming Huang, Pinjia He Venue: arXiv (2025)\nMany modern software projects evolve rapidly to incorporate new features and security patches. It is important for users to update their dependencies to safer versions, but many still use older, vulnerable package versions because upgrading can be difficult and may break their existing codebase. Software developers can mitigate this problem by backporting security patches to older releases. However, manually backporting is time-consuming and error-prone. The effectiveness of existing automated backporting techniques on general software remains unclear since they typically target only code-hunk or function-level patch porting scenarios and are evaluated with imperfect metrics. To facilitate the development and evaluation of automated backporting techniques, we introduce BackportBench, the first comprehensive benchmark suite for patch backporting problem. BackportBench is a multilingual benchmark that contains 202 patch backporting problems from PyPI, Maven, and npm, each with executable Docker environments and relevant test cases. We evaluated existing patch porting methods and LLM-based techniques that have the potential to adapt to this task using BackportBench. The results show that the agentic method has outperformed traditional patch porting methods, especially on cases that require logical and structural changes. However, the performance varies across different programming languages. Based on the findings, we draw several implications for researchers and software practitioners in future work on automated backporting.\nüì• Save to Zotero üìÑ Download PDF\nRE-LLM: Integrating Large Language Models into Renewable Energy Systems Authors: Ali Forootani, Mohammad Sadr, Danial Esmaeili Aliabadi, Daniela Thraen Venue: arXiv (2025)\nEnergy system models are increasingly employed to guide long-term planning in multi-sectoral environments where decisions span electricity, heat, transport, land use, and industry. While these models provide rigorous quantitative insights, their outputs are often highly technical, making them difficult to interpret for non-expert stakeholders such as policymakers, planners, and the public. This communication gap limits the accessibility and practical impact of scenario-based modeling, particularly as energy transitions grow more complex with rising shares of renewables, sectoral integration, and deep uncertainties. To address this challenge, we propose the Renewable Energy Large Language Model (RE-LLM), a hybrid framework that integrates Large Language Models (LLMs) directly into the energy system modeling workflow. RE-LLM combines three core elements: (i) optimization-based scenario exploration, (ii) machine learning surrogates that accelerate computationally intensive simulations, and (iii) LLM-powered natural language generation that translates complex results into clear, stakeholder-oriented explanations. This integrated design not only reduces computational burden but also enhances inter-pretability, enabling real-time reasoning about trade-offs, sensitivities, and policy implications. The framework is adaptable across different optimization platforms and energy system models, ensuring broad applicability beyond the case study presented. By merging speed, rigor, and interpretability, RE-LLM advances a new paradigm of human-centric energy modeling. It enables interactive, multilingual, and accessible engagement with future energy pathways, ultimately bridging the final gap between data-driven analysis and actionable decision-making for sustainable transitions.\nüì• Save to Zotero üìÑ Download PDF\nMARSAD: A Multi-Functional Tool for Real-Time Social Media Analysis Authors: Md. Rafiul Biswas, Firoj Alam, Wajdi Zaghouani Venue: arXiv (2025)\nMARSAD is a multifunctional natural language processing (NLP) platform designed for real-time social media monitoring and analysis, with a particular focus on the Arabic-speaking world. It enables researchers and non-technical users alike to examine both live and archived social media content, producing detailed visualizations and reports across various dimensions, including sentiment analysis, emotion analysis, propaganda detection, fact-checking, and hate speech detection. The platform also provides secure data-scraping capabilities through API keys for accessing public social media data. MARSAD‚Äôs backend architecture integrates flexible document storage with structured data management, ensuring efficient processing of large and multimodal datasets. Its user-friendly frontend supports seamless data upload and interaction.\nüì• Save to Zotero üìÑ Download PDF\nSecuring Large Language Models (LLMs) from Prompt Injection Attacks Authors: Omar Farooq Khan Suri, John McCrae Venue: arXiv (2025)\nLarge Language Models (LLMs) are increasingly being deployed in real-world applications, but their flexibility exposes them to prompt injection attacks. These attacks leverage the model‚Äôs instruction-following ability to make it perform malicious tasks. Recent work has proposed JATMO, a task-specific fine-tuning approach that trains non-instruction-tuned base models to perform a single function, thereby reducing susceptibility to adversarial instructions. In this study, we evaluate the robustness of JATMO against HOUYI, a genetic attack framework that systematically mutates and optimizes adversarial prompts. We adapt HOUYI by introducing custom fitness scoring, modified mutation logic, and a new harness for local model testing, enabling a more accurate assessment of defense effectiveness. We fine-tuned LLaMA 2-7B, Qwen1.5-4B, and Qwen1.5-0.5B models under the JATMO methodology and compared them with a fine-tuned GPT-3.5-Turbo baseline. Results show that while JATMO reduces attack success rates relative to instruction-tuned models, it does not fully prevent injections; adversaries exploiting multilingual cues or code-related disruptors still bypass defenses. We also observe a trade-off between generation quality and injection vulnerability, suggesting that better task performance often correlates with increased susceptibility. Our results highlight both the promise and limitations of fine-tuning-based defenses and point toward the need for layered, adversarially informed mitigation strategies.\nüì• Save to Zotero üìÑ Download PDF\nSentiment Analysis and Emotion Classification using Machine Learning Techniques for Nagamese Language - A Low-resource Language Authors: Ekha Morang, Surhoni A. Ngullie, Sashienla Longkumer, Teisovi Angami Venue: arXiv (2025)\nThe Nagamese language, a.k.a Naga Pidgin, is an Assamese-lexified creole language developed primarily as a means of communication in trade between the people from Nagaland and people from Assam in the north-east India. Substantial amount of work in sentiment analysis has been done for resource-rich languages like English, Hindi, etc. However, no work has been done in Nagamese language. To the best of our knowledge, this is the first attempt on sentiment analysis and emotion classification for the Nagamese Language. The aim of this work is to detect sentiments in terms of polarity (positive, negative and neutral) and basic emotions contained in textual content of Nagamese language. We build sentiment polarity lexicon of 1,195 nagamese words and use these to build features along with additional features for supervised machine learning techniques using Na\"ive Bayes and Support Vector Machines. Keywords: Nagamese, NLP, sentiment analysis, machine learning\nüì• Save to Zotero üìÑ Download PDF\nHow do we measure privacy in text? A survey of text anonymization metrics Authors: Yaxuan Ren, Krithika Ramesh, Yaxing Yao, Anjalie Field Venue: arXiv (2025)\nIn this work, we aim to clarify and reconcile metrics for evaluating privacy protection in text through a systematic survey. Although text anonymization is essential for enabling NLP research and model development in domains with sensitive data, evaluating whether anonymization methods sufficiently protect privacy remains an open challenge. In manually reviewing 47 papers that report privacy metrics, we identify and compare six distinct privacy notions, and analyze how the associated metrics capture different aspects of privacy risk. We then assess how well these notions align with legal privacy standards (HIPAA and GDPR), as well as user-centered expectations grounded in HCI studies. Our analysis offers practical guidance on navigating the landscape of privacy evaluation approaches further and highlights gaps in current practices. Ultimately, we aim to facilitate more robust, comparable, and legally aware privacy evaluations in text anonymization.\nüì• Save to Zotero üìÑ Download PDF\nA Hybrid Deep Learning and Anomaly Detection Framework for Real-Time Malicious URL Classification Authors: Berkani Khaled, Zeraoulia Rafik Venue: arXiv (2025)\nMalicious URLs remain a primary vector for phishing, malware, and cyberthreats. This study proposes a hybrid deep learning framework combining \\texttt{HashingVectorizer} n-gram analysis, SMOTE balancing, Isolation Forest anomaly filtering, and a lightweight neural network classifier for real-time URL classification. The multi-stage pipeline processes URLs from open-source repositories with statistical features (length, dot count, entropy), achieving $O(NL + EBdh)$ training complexity and a 20,ms prediction latency. Empirical evaluation yields 96.4% accuracy, 95.4% F1-score, and 97.3% ROC-AUC, outperforming CNN (94.8%) and SVM baselines with a $50!\\times$‚Äì$100!\\times$ speedup (Table~\\ref{tab:comp-complexity}). A multilingual Tkinter GUI (Arabic/English/French) enables real-time threat assessment with clipboard integration. The framework demonstrates superior scalability and resilience against obfuscated URL patterns.\nüì• Save to Zotero üìÑ Download PDF\nELR-1000: A Community-Generated Dataset for Endangered Indic Indigenous Languages Authors: Neha Joshi, Pamir Gogoi, Aasim Mirza, Aayush Jansari, Aditya Yadavalli, Ayushi Pandey, Arunima Shukla, Deepthi Sudharsan, Kalika Bali, Vivek Seshadri Venue: arXiv (2025)\nWe present a culturally-grounded multimodal dataset of 1,060 traditional recipes crowdsourced from rural communities across remote regions of Eastern India, spanning 10 endangered languages. These recipes, rich in linguistic and cultural nuance, were collected using a mobile interface designed for contributors with low digital literacy. Endangered Language Recipes (ELR)-1000 ‚Äì captures not only culinary practices but also the socio-cultural context embedded in indigenous food traditions. We evaluate the performance of several state-of-the-art large language models (LLMs) on translating these recipes into English and find the following: despite the models‚Äô capabilities, they struggle with low-resource, culturally-specific language. However, we observe that providing targeted context ‚Äì including background information about the languages, translation examples, and guidelines for cultural preservation ‚Äì leads to significant improvements in translation quality. Our results underscore the need for benchmarks that cater to underrepresented languages and domains to advance equitable and culturally-aware language technologies. As part of this work, we release the ELR-1000 dataset to the NLP community, hoping it motivates the development of language technologies for endangered languages.\nüì• Save to Zotero üìÑ Download PDF\nFine-tuning of lightweight large language models for sentiment classification on heterogeneous financial textual data Authors: Alvaro Paredes Amorin, Andre Python, Christoph Weisser Venue: arXiv (2025)\nLarge language models (LLMs) play an increasingly important role in finan- cial markets analysis by capturing signals from complex and heterogeneous textual data sources, such as tweets, news articles, reports, and microblogs. However, their performance is dependent on large computational resources and proprietary datasets, which are costly, restricted, and therefore inacces- sible to many researchers and practitioners. To reflect realistic situations we investigate the ability of lightweight open-source LLMs - smaller and publicly available models designed to operate with limited computational resources - to generalize sentiment understanding from financial datasets of varying sizes, sources, formats, and languages. We compare the benchmark finance natural language processing (NLP) model, FinBERT, and three open-source lightweight LLMs, DeepSeek-LLM 7B, Llama3 8B Instruct, and Qwen3 8B on five publicly available datasets: FinancialPhraseBank, Financial Question Answering, Gold News Sentiment, Twitter Sentiment and Chinese Finance Sentiment. We find that LLMs, specially Qwen3 8B and Llama3 8B, perform best in most scenarios, even from using only 5% of the available training data. These results hold in zero-shot and few-shot learning scenarios. Our findings indicate that lightweight, open-source large language models (LLMs) consti- tute a cost-effective option, as they can achieve competitive performance on heterogeneous textual data even when trained on only a limited subset of the extensive annotated corpora that are typically deemed necessary.\nüì• Save to Zotero üìÑ Download PDF\nDeformAr: Rethinking NER Evaluation through Component Analysis and Visual Analytics Authors: Ahmed Mustafa Younes Venue: arXiv (2025)\nTransformer models have significantly advanced Natural Language Processing (NLP), demonstrating strong performance in English. However, their effectiveness in Arabic, particularly for Named Entity Recognition (NER), remains limited, even with larger pre-trained models. This performance gap stems from multiple factors, including tokenisation, dataset quality, and annotation inconsistencies. Existing studies often analyze these issues in isolation, failing to capture their joint effect on system behaviour and performance. We introduce DeformAr (Debugging and Evaluation Framework for Transformer-based NER Systems), a novel framework designed to investigate and explain the performance discrepancy between Arabic and English NER systems. DeformAr integrates a data extraction library and an interactive dashboard, supporting two modes of evaluation: cross-component analysis and behavioural analysis. The framework divides each language into dataset and model components to examine their interactions. The analysis proceeds in two stages. First, cross-component analysis provides systematic diagnostic measures across data and model subcomponents, addressing the ‚Äúwhat,‚Äù ‚Äúhow,‚Äù and ‚Äúwhy‚Äù behind observed discrepancies. The second stage applies behavioural analysis by combining interpretability techniques with token-level metrics, interactive visualisations, and representation space analysis. These stages enable a component-aware diagnostic process that detects model behaviours and explains them by linking them to underlying representational patterns and data factors. DeformAr is the first Arabic-specific, component-based interpretability tool, offering a crucial resource for advancing model analysis in under-resourced languages.\nüì• Save to Zotero üìÑ Download PDF\nMultilingual Training-Free Remote Sensing Image Captioning Authors: Carlos Rebelo, Gil Rocha, Jo√£o Daniel Silva, Bruno Martins Venue: arXiv (2025)\nRemote sensing image captioning has advanced rapidly through encoder‚Äìdecoder models, although the reliance on large annotated datasets and the focus on English restricts global applicability. To address these limitations, we propose the first training-free multilingual approach, based on retrieval-augmented prompting. For a given aerial image, we employ a domain-adapted SigLIP2 encoder to retrieve related captions and few-shot examples from a datastore, which are then provided to a language model. We explore two variants: an image-blind setup, where a multilingual Large Language Model (LLM) generates the caption from textual prompts alone, and an image-aware setup, where a Vision‚ÄìLanguage Model (VLM) jointly processes the prompt and the input image. To improve the coherence of the retrieved content, we introduce a graph-based re-ranking strategy using PageRank on a graph of images and captions. Experiments on four benchmark datasets across ten languages demonstrate that our approach is competitive with fully supervised English-only systems and generalizes to other languages. Results also highlight the importance of re-ranking with PageRank, yielding up to 35% improvements in performance metrics. Additionally, it was observed that while VLMs tend to generate visually grounded but lexically diverse captions, LLMs can achieve stronger BLEU and CIDEr scores. Lastly, directly generating captions in the target language consistently outperforms other translation-based strategies. Overall, our work delivers one of the first systematic evaluations of multilingual, training-free captioning for remote sensing imagery, advancing toward more inclusive and scalable multimodal Earth observation systems.\nüì• Save to Zotero üìÑ Download PDF\nAccelerating Bangla NLP Tasks with Automatic Mixed Precision: Resource-Efficient Training Preserving Model Efficacy Authors: Md Mehrab Hossain Opi, Sumaiya Khan, Moshammad Farzana Rahman Venue: arXiv (2025)\nTraining models for Natural Language Processing (NLP) requires substantial computational resources and time, posing significant challenges, especially for NLP development in Bangla, where access to high-end hardware is often limited. In this work, we explore automatic mixed precision (AMP) training as a means to improve computational efficiency without sacrificing model performance. By leveraging a dynamic mix of 16-bit and 32-bit floating-point computations, AMP lowers GPU memory requirements and speeds up training without degrading model performance. We evaluate AMP across four standard Bangla NLP tasks, namely sentiment analysis, named entity recognition, error classification, and question answering, using four transformer-based models: BanglaBERT, BanglishBERT, XLM-R, and mBERT. Our results demonstrate that AMP accelerates training by 44.5% and reduces memory consumption by 17.6%, while maintaining F-1 score within 99.7% of the full-precision baselines. This empirical study highlights AMP‚Äôs potential to democratize access to state-of-the-art NLP capabilities in hardware-constrained settings by lowering computational barriers.\nüì• Save to Zotero üìÑ Download PDF\nSHRAG: AFrameworkfor Combining Human-Inspired Search with RAG Authors: Hyunseok Ryu, Wonjune Shin, Hyun Park Venue: arXiv (2025)\nRetrieval-Augmented Generation (RAG) is gaining recognition as one of the key technological axes for next generation information retrieval, owing to its ability to mitigate the hallucination phenomenon in Large Language Models (LLMs)and effectively incorporate up-to-date information. However, specialized expertise is necessary to construct ahigh-quality retrieval system independently; moreover, RAGdemonstratesrelativelyslowerprocessing speeds compared to conventional pure retrieval systems because it involves both retrieval and generation stages. Accordingly, this study proposes SHRAG, a novel framework designed to facilitate the seamless integration of Information Retrieval and RAG while simultaneously securing precise retrieval performance. SHRAG utilizes a Large Language Model as a Query Strategist to automatically transform unstructured natural language queries into logically structured search queries, subsequently performing Boolean retrieval to emulate the search process of an expert human searcher. Furthermore, it incorporates multilingual query expansion and a multilingual embedding model, enabling it to perform efficient cross-lingual question answering within the multilingual dataset environment of the ScienceON Challenge. Experimental results demonstrate that the proposed method, combining logical retrieval capabilities and generative reasoning, can significantly enhance the accuracy and reliability of RAG systems. Furthermore, SHRAG movesbeyondconventionaldocument-centric retrieval methods, presenting the potential for a new search paradigm capable of providing direct and reliable responses to queries.\nüì• Save to Zotero üìÑ Download PDF\nMPR-GUI: Benchmarking and Enhancing Multilingual Perception and Reasoning in GUI Agents Authors: Ruihan Chen, Qiming Li, Xiaocheng Feng, Xiaoliang Yang, Weihong Zhong, Yuxuan Gu, Zekun Zhou, Bing Qin Venue: arXiv (2025)\nWith the advancement of computational resources, Large Vision-Language Models (LVLMs) exhibit impressive Perception and Reasoning (P\u0026R) performance on Graphical User Interface (GUI) tasks. However, although they demonstrate strong P\u0026R capabilities in English GUI scenarios, their performance in multilingual settings has received little attention, which limits their global applications. Moreover, existing studies on GUI tasks lack fine-grained analyses, including widget functions and elements‚Äô spatial relationships, which are fundamental for more targeted improvements. To tackle these issues, we propose MPR-GUI-Bench, a Multilingual fine-grained Perception and Reasoning GUI Benchmark to evaluate GUI agents‚Äô P\u0026R capabilities. Evaluation results demonstrate that LVLMs exhibit significantly worse P\u0026R performance in non-English languages than in English. To address these gaps, we propose GUI-XLI, a GUI Cross-Lingual Intervention method that applies interventions to the hidden states at P\u0026R capability-related layers to mitigate the gaps between English and other languages, building on previous research showing that the hidden states of different language inputs exhibit significant differences in the latent space. Experimental results indicate that our method improves GUI agents‚Äô multilingual P\u0026R capability by 6.5% on average.\nüì• Save to Zotero üìÑ Download PDF\nFastPOS: Language-Agnostic Scalable POS Tagging Framework Low-Resource Use Case Authors: Md Abdullah Al Kafi, Sumit Kumar Banshal Venue: arXiv (2025)\nThis study proposes a language-agnostic transformer-based POS tagging framework designed for low-resource languages, using Bangla and Hindi as case studies. With only three lines of framework-specific code, the model was adapted from Bangla to Hindi, demonstrating effective portability with minimal modification. The framework achieves 96.85 percent and 97 percent token-level accuracy across POS categories in Bangla and Hindi while sustaining strong F1 scores despite dataset imbalance and linguistic overlap. A performance discrepancy in a specific POS category underscores ongoing challenges in dataset curation. The strong results stem from the underlying transformer architecture, which can be replaced with limited code adjustments. Its modular and open-source design enables rapid cross-lingual adaptation while reducing model design and tuning overhead, allowing researchers to focus on linguistic preprocessing and dataset refinement, which are essential for advancing NLP in underrepresented languages.\nüì• Save to Zotero üìÑ Download PDF\nFinancial Text Classification Based On rLoRA Finetuning On Qwen3-8B model Authors: Zhiming Lian Venue: arXiv (2025)\nFinancial text classification has increasingly become an important aspect in quantitative trading systems and related tasks, such as financial sentiment analysis and the classification of financial news. In this paper, we assess the performance of the large language model Qwen3-8B on both tasks. Qwen3-8B is a state-of-the-art model that exhibits strong instruction-following and multilingual capabilities, and is distinct from standard models, primarily because it is specifically optimized for efficient fine tuning and high performance on reasoning-based benchmarks, making it suitable for financial applications. To adapt this model, we apply Noisy Embedding Instruction Finetuning and based on our previous work, this method increases robustness by injecting controlled noise into the embedding layers during supervised adaptation. We improve efficiency further with Rank-stabilized Low-Rank Adaptation low-rank optimization approach, and FlashAttention, which allow for faster training with lower GPU memory. For both tasks, we benchmark Qwen3-8B against standard classical transformer models, such as T5, BERT, and RoBERTa, and large models at scale, such as LLaMA1-7B, LLaMA2-7B, and Baichuan2-7B. The findings reveal that Qwen3-8B consistently surpasses these baselines by obtaining better classification accuracy and needing fewer training epochs. The synergy of instruction-based fine-tuning and memory-efficient optimization methods suggests Qwen3-8B can potentially serve as a scalable, economical option for real-time financial NLP applications. Qwen3-8B provides a very promising base for advancing dynamic quantitative trading systems in the future.\nüì• Save to Zotero üìÑ Download PDF\nStatistical NLP for Optimization of Clinical Trial Success Prediction in Pharmaceutical R\u0026D Authors: Michael R. Doane Venue: arXiv (2025)\nThis work presents the development and evaluation of an NLP-enabled probabilistic classifier designed to estimate the probability of technical and regulatory success (pTRS) for clinical trials in the field of neuroscience. While pharmaceutical R\u0026D is plagued by high attrition rates and enormous costs, particularly within neuroscience, where success rates are below 10%, timely identification of promising programs can streamline resource allocation and reduce financial risk. Leveraging data from the ClinicalTrials.gov database and success labels from the recently developed Clinical Trial Outcome dataset, the classifier extracts text-based clinical trial features using statistical NLP techniques. These features were integrated into several non-LLM frameworks (logistic regression, gradient boosting, and random forest) to generate calibrated probability scores. Model performance was assessed on a retrospective dataset of 101,145 completed clinical trials spanning 1976-2024, achieving an overall ROC-AUC of 0.64. An LLM-based predictive model was then built using BioBERT, a domain-specific language representation encoder. The BioBERT-based model achieved an overall ROC-AUC of 0.74 and a Brier Score of 0.185, indicating its predictions had, on average, 40% less squared error than would be observed using industry benchmarks. The BioBERT-based model also made trial outcome predictions that were superior to benchmark values 70% of the time overall. By integrating NLP-driven insights into drug development decision-making, this work aims to enhance strategic planning and optimize investment allocation in neuroscience programs.\nüì• Save to Zotero üìÑ Download PDF\nCACARA: Cross-Modal Alignment Leveraging a Text-Centric Approach for Cost-Effective Multimodal and Multilingual Learning Authors: Diego A. B. Moreira, Alef I. Ferreira, Jhessica Silva, Gabriel O. dos Santos, Gustavo Bonil, Jo√£o Gondim, Marina dos Santos, Helena Maia, Simone Hashiguti, N√°dia da Silva, Carolina Scarton, Helio Pedrini, Sandra Avila Venue: arXiv (2025)\nAs deep learning models evolve, new applications and challenges are rapidly emerging. Tasks that once relied on a single modality, such as text, images, or audio, are now enriched by seamless interactions between multimodal data. These connections bridge information gaps: an image can visually materialize a text, while audio can add context to an image. Researchers have developed numerous multimodal models, but most rely on resource-intensive training across multiple modalities. Similarly, extending these models to new languages often follows the same resource-heavy training strategy. In this work, we propose a multimodal and multilingual architecture, CACARA, trained through emergent alignment learning, enabling the seamless integration of new modalities into an existing bimodal/multimodal model without requiring full retraining. This work breaks new ground by demonstrating that this emergent alignment paradigm can unlock multilingual capabilities from monolingual training. By fine-tuning the newly incorporated modality only on data aligned with the English language, our model develops support for over 100 languages without explicit multilingual pretraining or tuning of the text encoder. Such emergent multimodal and multilingual properties are gained efficiently, preserving previously learned knowledge at a training cost comparable to that of a monolingual model. Our strategy achieves up to a 14.24 percentage points improvement in R@1 audio-to-text retrieval, outperforming state-of-the-art multimodal models ‚Äì all without the heavy computational cost of retraining across every modality and language.\nüì• Save to Zotero üìÑ Download PDF\nRRPO: Robust Reward Policy Optimization for LLM-based Emotional TTS Authors: Cong Wang, Changfeng Gao, Yang Xiang, Zhihao Du, Keyu An, Han Zhao, Qian Chen, Xiangang Li, Yingming Gao, Ya Li Venue: arXiv (2025)\nDifferentiable reinforcement learning (RL) frameworks like DiffRO offer a powerful approach for controllable text-to-speech (TTS), but are vulnerable to reward hacking, particularly for nuanced tasks like emotion control. The policy model can exploit a vanilla Reward Model (RM) by generating acoustic artifacts to achieve spurious rewards, but at the cost of degrading perceptual quality. To address this, we propose Robust Reward Policy Optimization (RRPO), a novel framework that employs a hybrid regularization scheme. This scheme develops a robust RM whose reward signal is more reliably aligned with human perception, compelling the policy to abandon detrimental shortcuts and instead learn the complex features of genuine emotions. Our ablation study confirms the enhanced robustness of our RM, as evidenced by its strong cross-lingual generalization. The subjective evaluation demonstrates that this robust RM effectively mitigates reward hacking, leading to significant improvements in both emotional expressiveness and naturalness over all baselines. Demo page: https://lrwinr.github.io/RRPO-CosyVoice.\nüì• Save to Zotero üìÑ Download PDF\nDifferent types of syntactic agreement recruit the same units within large language models Authors: Daria Kryvosheieva, Andrea de Varda, Evelina Fedorenko, Greta Tuckute Venue: arXiv (2025)\nLarge language models (LLMs) can reliably distinguish grammatical from ungrammatical sentences, but how grammatical knowledge is represented within the models remains an open question. We investigate whether different syntactic phenomena recruit shared or distinct components in LLMs. Using a functional localization approach inspired by cognitive neuroscience, we identify the LLM units most responsive to 67 English syntactic phenomena in seven open-weight models. These units are consistently recruited across sentences containing the phenomena and causally support the models‚Äô syntactic performance. Critically, different types of syntactic agreement (e.g., subject-verb, anaphor, determiner-noun) recruit overlapping sets of units, suggesting that agreement constitutes a meaningful functional category for LLMs. This pattern holds in English, Russian, and Chinese; and further, in a cross-lingual analysis of 57 diverse languages, structurally more similar languages share more units for subject-verb agreement. Taken together, these findings reveal that syntactic agreement-a critical marker of syntactic dependencies-constitutes a meaningful category within LLMs‚Äô representational spaces.\nüì• Save to Zotero üìÑ Download PDF\nIndicParam: Benchmark to evaluate LLMs on low-resource Indic Languages Authors: Ayush Maheshwari, Kaushal Sharma, Vivek Patel, Aditya Maheshwari Venue: arXiv (2025)\nWhile large language models excel on high-resource multilingual tasks, low- and extremely low-resource Indic languages remain severely under-evaluated. We present IndicParam, a human-curated benchmark of over 13,000 multiple-choice questions covering 11 such languages (Nepali, Gujarati, Marathi, Odia as low-resource; Dogri, Maithili, Rajasthani, Sanskrit, Bodo, Santali, Konkani as extremely low-resource) plus Sanskrit-English code-mixed set. We evaluated 19 LLMs, both proprietary and open-weights, which reveals that even the top-performing GPT-5 reaches only 45.0% average accuracy, followed by DeepSeek-3.2 (43.1) and Claude-4.5 (42.7). We additionally label each question as knowledge-oriented or purely linguistic to discriminate factual recall from grammatical proficiency. Further, we assess the ability of LLMs to handle diverse question formats-such as list-based matching, assertion-reason pairs, and sequence ordering-alongside conventional multiple-choice questions. IndicParam provides insights into limitations of cross-lingual transfer and establishes a challenging benchmark for Indic languages. The dataset is available at https://huggingface.co/datasets/bharatgenai/IndicParam. Scripts to run benchmark are present at https://github.com/ayushbits/IndicParam.\nüì• Save to Zotero üìÑ Download PDF\nModeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaran√≠ Authors: Nemika Tyagi, Nelvin Licona Guevara, Olga Kellert Venue: arXiv (2025)\nThis study presents an LLM-assisted annotation pipeline for the sociolinguistic and topical analysis of bilingual discourse in two typologically distinct contexts: Spanish-English and Spanish-Guaran√≠. Using large language models, we automatically labeled topic, genre, and discourse-pragmatic functions across a total of 3,691 code-switched sentences, integrated demographic metadata from the Miami Bilingual Corpus, and enriched the Spanish-Guaran√≠ dataset with new topic annotations. The resulting distributions reveal systematic links between gender, language dominance, and discourse function in the Miami data, and a clear diglossic division between formal Guaran√≠ and informal Spanish in Paraguayan texts. These findings replicate and extend earlier interactional and sociolinguistic observations with corpus-scale quantitative evidence. The study demonstrates that large language models can reliably recover interpretable sociolinguistic patterns traditionally accessible only through manual annotation, advancing computational methods for cross-linguistic and low-resource bilingual research.\nüì• Save to Zotero üìÑ Download PDF\nIVCR-200K: A Large-Scale Multi-turn Dialogue Benchmark for Interactive Video Corpus Retrieval Authors: Ning Han, Yawen Zeng, Shaohua Long, Chengqing Li, Sijie Yang, Dun Tan, Jianfeng Dong, Jingjing Chen Venue: arXiv (2025)\nIn recent years, significant developments have been made in both video retrieval and video moment retrieval tasks, which respectively retrieve complete videos or moments for a given text query. These advancements have greatly improved user satisfaction during the search process. However, previous work has failed to establish meaningful ‚Äúinteraction‚Äù between the retrieval system and the user, and its one-way retrieval paradigm can no longer fully meet the personalization and dynamic needs of at least 80.8% of users. In this paper, we introduce the Interactive Video Corpus Retrieval (IVCR) task, a more realistic setting that enables multi-turn, conversational, and realistic interactions between the user and the retrieval system. To facilitate research on this challenging task, we introduce IVCR-200K, a high-quality, bilingual, multi-turn, conversational, and abstract semantic dataset that supports video retrieval and even moment retrieval. Furthermore, we propose a comprehensive framework based on multi-modal large language models (MLLMs) to help users interact in several modes with more explainable solutions. The extensive experiments demonstrate the effectiveness of our dataset and framework.\nüì• Save to Zotero üìÑ Download PDF\nWhose Personae? Synthetic Persona Experiments in LLM Research and Pathways to Transparency Authors: Jan Batzner, Volker Stocker, Bingjun Tang, Anusha Natarajan, Qinhao Chen, Stefan Schmid, Gjergji Kasneci Venue: arXiv (2025)\nSynthetic personae experiments have become a prominent method in Large Language Model alignment research, yet the representativeness and ecological validity of these personae vary considerably between studies. Through a review of 63 peer-reviewed studies published between 2023 and 2025 in leading NLP and AI venues, we reveal a critical gap: task and population of interest are often underspecified in persona-based experiments, despite personalization being fundamentally dependent on these criteria. Our analysis shows substantial differences in user representation, with most studies focusing on limited sociodemographic attributes and only 35% discussing the representativeness of their LLM personae. Based on our findings, we introduce a persona transparency checklist that emphasizes representative sampling, explicit grounding in empirical data, and enhanced ecological validity. Our work provides both a comprehensive assessment of current practices and practical guidelines to improve the rigor and ecological validity of persona-based evaluations in language model alignment research.\nüì• Save to Zotero üìÑ Download PDF\nSelfAI: Building a Self-Training AI System with LLM Agents Authors: Xiao Wu, Ting-Zhu Huang, Liang-Jian Deng, Xiaobing Yu, Yu Zhong, Shangqi Deng, Ufaq Khan, Jianghao Wu, Xiaofeng Liu, Imran Razzak, Xiaojun Chang, Yutong Xie Venue: arXiv (2025)\nRecent work on autonomous scientific discovery has leveraged LLM-based agents to integrate problem specification, experiment planning, and execution into end-to-end systems. However, these frameworks are often confined to narrow application domains, offer limited real-time interaction with researchers, and lack principled mechanisms for determining when to halt exploration, resulting in inefficiencies, reproducibility challenges, and under-utilized human expertise. To address these gaps, we propose \\textit{SelfAI}, a general multi-agent platform that combines a User Agent for translating high-level research objectives into standardized experimental configurations, a Cognitive Agent powered by LLMs with optimal stopping criteria to iteratively refine hyperparameter searches, and an Experiment Manager responsible for orchestrating parallel, fault-tolerant training workflows across heterogeneous hardware while maintaining a structured knowledge base for continuous feedback. We further introduce two novel evaluation metrics, Score and $\\text{AUP}_D$, to quantify discovery efficiency and search diversity. Across regression, NLP, computer vision, scientific computing, medical imaging, and drug discovery benchmarks, SelfAI consistently achieves strong performance and reduces redundant trials compared to classical Bayesian optimization and LLM-based baselines, while enabling seamless interaction with human researchers.\nüì• Save to Zotero üìÑ Download PDF\nChallenges of Heterogeneity in Big Data: A Comparative Study of Classification in Large-Scale Structured and Unstructured Domains Authors: Gonz√°lez Trigueros Jes√∫s Eduardo, Alonso S√°nchez Alejandro, Mu√±oz Rivera Emilio, Pe√±ar√°n Prieto Mariana Jaqueline, Mendoza Gonz√°lez Camila Natalia Venue: arXiv (2025)\nThis study analyzes the impact of heterogeneity (‚ÄúVariety‚Äù) in Big Data by comparing classification strategies across structured (Epsilon) and unstructured (Rest-Mex, IMDB) domains. A dual methodology was implemented: evolutionary and Bayesian hyperparameter optimization (Genetic Algorithms, Optuna) in Python for numerical data, and distributed processing in Apache Spark for massive textual corpora. The results reveal a ‚Äúcomplexity paradox‚Äù: in high-dimensional spaces, optimized linear models (SVM, Logistic Regression) outperformed deep architectures and Gradient Boosting. Conversely, in text-based domains, the constraints of distributed fine-tuning led to overfitting in complex models, whereas robust feature engineering ‚Äì specifically Transformer-based embeddings (ROBERTa) and Bayesian Target Encoding ‚Äì enabled simpler models to generalize effectively. This work provides a unified framework for algorithm selection based on data nature and infrastructure constraints.\nüì• Save to Zotero üìÑ Download PDF\nBioArc: Discovering Optimal Neural Architectures for Biological Foundation Models Authors: Yi Fang, Haoran Xu, Jiaxin Han, Sirui Ding, Yizhi Wang, Yue Wang, Xuan Wang Venue: arXiv (2025)\nFoundation models have revolutionized various fields such as natural language processing (NLP) and computer vision (CV). While efforts have been made to transfer the success of the foundation models in general AI domains to biology, existing works focus on directly adopting the existing foundation model architectures from general machine learning domains without a systematic design considering the unique physicochemical and structural properties of each biological data modality. This leads to suboptimal performance, as these repurposed architectures struggle to capture the long-range dependencies, sparse information, and complex underlying ``grammars‚Äô‚Äô inherent to biological data. To address this gap, we introduce BioArc, a novel framework designed to move beyond intuition-driven architecture design towards principled, automated architecture discovery for biological foundation models. Leveraging Neural Architecture Search (NAS), BioArc systematically explores a vast architecture design space, evaluating architectures across multiple biological modalities while rigorously analyzing the interplay between architecture, tokenization, and training strategies. This large-scale analysis identifies novel, high-performance architectures, allowing us to distill a set of empirical design principles to guide future model development. Furthermore, to make the best of this set of discovered principled architectures, we propose and compare several architecture prediction methods that effectively and efficiently predict optimal architectures for new biological tasks. Overall, our work provides a foundational resource and a principled methodology to guide the creation of the next generation of task-specific and foundation models for biology.\nüì• Save to Zotero üìÑ Download PDF\nAccelerated Execution of Bayesian Neural Networks using a Single Probabilistic Forward Pass and Code Generation Authors: Bernhard Klein, Falk Selker, Hendrik Borras, Sophie Steger, Franz Pernkopf, Holger Fr√∂ning Venue: arXiv (2025)\nMachine learning models perform well across domains such as diagnostics, weather forecasting, NLP, and autonomous driving, but their limited uncertainty handling restricts use in safety-critical settings. Traditional neural networks often fail to detect out-of-domain (OOD) data and may output confident yet incorrect predictions. Bayesian neural networks (BNNs) address this by providing probabilistic estimates, but incur high computational cost because predictions require sampling weight distributions and multiple forward passes. The Probabilistic Forward Pass (PFP) offers a highly efficient approximation to Stochastic Variational Inference (SVI) by assuming Gaussian-distributed weights and activations, enabling fully analytic uncertainty propagation and replacing sampling with a single deterministic forward pass. We present an end-to-end pipeline for training, compiling, optimizing, and deploying PFP-based BNNs on embedded ARM CPUs. Using the TVM deep learning compiler, we implement a dedicated library of Gaussian-propagating operators for multilayer perceptrons and convolutional neural networks, combined with manual and automated tuning strategies. Ablation studies show that PFP consistently outperforms SVI in computational efficiency, achieving speedups of up to 4200x for small mini-batches. PFP-BNNs match SVI-BNNs on Dirty-MNIST in accuracy, uncertainty estimation, and OOD detection while greatly reducing compute cost. These results highlight the potential of combining Bayesian approximations with code generation to enable efficient BNN deployment on resource-constrained systems.\nüì• Save to Zotero üìÑ Download PDF\nThe Decision Path to Control AI Risks Completely: Fundamental Control Mechanisms for AI Governance Authors: Yong Tao Venue: arXiv (2025)\nArtificial intelligence (AI) advances rapidly but achieving complete human control over AI risks remains an unsolved problem, akin to driving the fast AI ‚Äútrain‚Äù without a ‚Äúbrake system.‚Äù By exploring fundamental control mechanisms at key elements of AI decisions, this paper develops a systematic solution to thoroughly control AI risks, providing an architecture for AI governance and legislation with five pillars supported by six control mechanisms, illustrated through a minimum set of AI Mandates (AIMs). Three of the AIMs must be built inside AI systems and three in society to address major areas of AI risks: 1) align AI values with human users; 2) constrain AI decision-actions by societal ethics, laws, and regulations; 3) build in human intervention options for emergencies and shut-off switches for existential threats; 4) limit AI access to resources to reinforce controls inside AI; 5) mitigate spillover risks like job loss from AI. We also highlight the differences in AI governance on physical AI systems versus generative AI. We discuss how to strengthen analog physical safeguards to prevent smarter AI/AGI/ASI from circumventing core safety controls by exploiting AI‚Äôs intrinsic disconnect from the analog physical world: AI‚Äôs nature as pure software code run on chips controlled by humans, and the prerequisite that all AI-driven physical actions must be digitized. These findings establish a theoretical foundation for AI governance and legislation as the basic structure of a ‚Äúbrake system‚Äù for AI decisions. If enacted, these controls can rein in AI dangers as completely as humanly possible, removing large chunks of currently wide-open AI risks, substantially reducing overall AI risks to residual human errors.\nüì• Save to Zotero üìÑ Download PDF\nMinimizing the Number of Code Switching Operations in Fault-Tolerant Quantum Circuits Authors: Erik Weilandt, Tom Peham, Robert Wille Venue: arXiv (2025)\nFault-tolerant quantum computers rely on Quantum Error-Correcting Codes (QECCs) to protect information from noise. However, no single error-correcting code supports a fully transversal and therefore fault-tolerant implementation of all gates required for universal quantum computation. Code switching addresses this limitation by moving quantum information between different codes that, together, support a universal gate set. Unfortunately, each switch is costly-adding time and space overhead and increasing the logical error rate. Minimizing the number of switching operations is, therefore, essential for quantum computations using code switching. In this work, we study the problem of minimizing the number of code switches required to run a given quantum circuit. We show that this problem can be solved efficiently in polynomial time by reducing it to a minimum-cut instance on a graph derived from the circuit. Our formulation is flexible and can incorporate additional considerations, such as reducing depth overhead by preferring switches during idle periods or biasing the compilation to favor one code over another. To the best of our knowledge, this is the first automated approach for compiling and optimizing code-switching-based quantum computations at the logical level.\nüì• Save to Zotero üìÑ Download PDF\nEnCompass: Enhancing Agent Programming with Search Over Program Execution Paths Authors: Zhening Li, Armando Solar-Lezama, Yisong Yue, Stephan Zheng Venue: arXiv (2025)\nWe introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce ‚Äúprobabilistic angelic nondeterminism‚Äù (‚ÄúPAN‚Äù), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.\nüì• Save to Zotero üìÑ Download PDF\nLanguage Diversity: Evaluating Language Usage and AI Performance on African Languages in Digital Spaces Authors: Edward Ajayi, Eudoxie Umwari, Mawuli Deku, Prosper Singadi, Jules Udahemuka, Bekalu Tadele, Chukuemeka Edeh Venue: arXiv (2025)\nThis study examines the digital representation of African languages and the challenges this presents for current language detection tools. We evaluate their performance on Yoruba, Kinyarwanda, and Amharic. While these languages are spoken by millions, their online usage on conversational platforms is often sparse, heavily influenced by English, and not representative of the authentic, monolingual conversations prevalent among native speakers. This lack of readily available authentic data online creates a challenge of scarcity of conversational data for training language models. To investigate this, data was collected from subreddits and local news sources for each language. The analysis showed a stark contrast between the two sources. Reddit data was minimal and characterized by heavy code-switching. Conversely, local news media offered a robust source of clean, monolingual language data, which also prompted more user engagement in the local language on the news publishers social media pages. Language detection models, including the specialized AfroLID and a general LLM, performed with near-perfect accuracy on the clean news data but struggled with the code-switched Reddit posts. The study concludes that professionally curated news content is a more reliable and effective source for training context-rich AI models for African languages than data from conversational platforms. It also highlights the need for future models that can process clean and code-switched text to improve the detection accuracy for African languages.\nüì• Save to Zotero üìÑ Download PDF\nPromptBridge: Cross-Model Prompt Transfer for Large Language Models Authors: Yaxuan Wang, Quan Liu, Zhenting Wang, Zichao Li, Wei Wei, Yang Liu, Yujia Bao Venue: arXiv (2025)\nLarge language models (LLMs) underpin applications in code generation, mathematical reasoning, and agent-based workflows. In practice, systems access LLMs via commercial APIs or open-source deployments, and the model landscape (e.g., GPT, Claude, Llama) evolves rapidly. This rapid evolution forces frequent model switches driven by capability, cost, deployment constraints, and privacy. Yet prompts are highly model-sensitive: reusing a prompt engineered for one model on another often yields substantially worse performance than a prompt optimized for the target model. We term this phenomenon Model Drifting. Through extensive empirical analysis across diverse LLM configurations, we show that model drifting is both common and severe. To address this challenge, we introduce PromptBridge, a training-free framework that preserves prompt effectiveness under model switches, enabling cross-model prompt transfer without costly per-task or per-model re-optimization. PromptBridge requires only a small set of alignment tasks for calibration. It first applies Model-Adaptive Reflective Prompt Evolution (MAP-RPE) to obtain task- and model-specific optimal prompts via iterative reflective refinement and quantitative evaluation. Using the resulting calibrated prompt pairs for the source and target models, PromptBridge learns a cross-model prompt mapping. At test time, i.e., for an unseen task, given a source-model prompt, this mapping directly produces an optimized prompt for the target model. Experiments in single-agent and multi-agent settings show that PromptBridge consistently improves downstream accuracy while reducing migration effort. The code will be available soon.\nüì• Save to Zotero üìÑ Download PDF\nExploiting Function-Family Structure in Analog Circuit Optimization Authors: Zhuohua Liu, Kaiqi Huang, Qinxin Mei, Yuanqi Hu, Wei W. Xing Venue: arXiv (2025)\nAnalog circuit optimization is typically framed as black-box search over arbitrary smooth functions, yet device physics constrains performance mappings to structured families: exponential device laws, rational transfer functions, and regime-dependent dynamics. Off-the-shelf Gaussian-process surrogates impose globally smooth, stationary priors that are misaligned with these regime-switching primitives and can severely misfit highly nonlinear circuits at realistic sample sizes (50‚Äì100 evaluations). We demonstrate that pre-trained tabular models encoding these primitives enable reliable optimization without per-circuit engineering. Circuit Prior Network (CPN) combines a tabular foundation model (TabPFN v2) with Direct Expected Improvement (DEI), computing expected improvement exactly under discrete posteriors rather than Gaussian approximations. Across 6 circuits and 25 baselines, structure-matched priors achieve $R^2 \\approx 0.99$ in small-sample regimes where GP-Mat√©rn attains only $R^2 = 0.16$ on Bandgap, deliver $1.05$‚Äì$3.81\\times$ higher FoM with $3.34$‚Äì$11.89\\times$ fewer iterations, and suggest a shift from hand-crafting models as priors toward systematic physics-informed structure identification. Our code will be made publicly available upon paper acceptance.\nüì• Save to Zotero üìÑ Download PDF\nAnalysis of the operation of a TSN switch and other devices using executable QR codes Authors: Stefano Scanzio, Pietro Chiavassa, Gianluca Cena Venue: arXiv (2025)\nExecutable QR codes, also known as sQRy, are a technology aimed at inserting executable programs in a QR code. Through a concrete example, in this paper, we demonstrate their usage in the context of industrial networks in order to assess the operation of a TSN switch by analyzing its status LEDs even in the absence of an internet connection. The entire generation chain that is used to create the sQRy, as well as the corresponding execution chain that, starting from the sQRy, runs it on a mobile device, has been detailed through examples.\nüì• Save to Zotero üìÑ Download PDF\nMitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates Authors: Atsuki Yamaguchi, Terufumi Morishita, Aline Villavicencio, Nikolaos Aletras Venue: arXiv (2025)\nExpanding the linguistic diversity of instruct large language models (LLMs) is crucial for global accessibility but is often hindered by the reliance on costly specialized target language labeled data and catastrophic forgetting during adaptation. We tackle this challenge under a realistic, low-resource constraint: adapting instruct LLMs using only unlabeled target language data. We introduce Source-Shielded Updates (SSU), a selective parameter update strategy that proactively preserves source knowledge. Using a small set of source data and a parameter importance scoring method, SSU identifies parameters critical to maintaining source abilities. It then applies a column-wise freezing strategy to protect these parameters before adaptation. Experiments across five typologically diverse languages and 7B and 13B models demonstrate that SSU successfully mitigates catastrophic forgetting. It reduces performance degradation on monolingual source tasks to just 3.4% (7B) and 2.8% (13B) on average, a stark contrast to the 20.3% and 22.3% from full fine-tuning. SSU also achieves target-language performance highly competitive with full fine-tuning, outperforming it on all benchmarks for 7B models and the majority for 13B models.\nüì• Save to Zotero üìÑ Download PDF\nDivide, then Ground: Adapting Frame Selection to Query Types for Long-Form Video Understanding Authors: Jialuo Li, Bin Li, Jiahao Li, Yan Lu Venue: arXiv (2025)\nThe application of Large Multimodal Models (LMMs) to long-form video understanding is constrained by limited context lengths and the computationally prohibitive cost of processing dense video tokens. Consequently, recent research has focused on query-aware frame selection, methods that often incur significant computational overhead. This paper challenges the assumption that such complex search mechanisms are universally necessary. We first identify and validate a query typology distinguishing between global query and localized query. We demonstrate that while uniform sampling is both effective and efficient for global queries, localized queries indeed necessitate query-aware selection for optimal performance. Building on this insight, we propose DIG, a training-free frame selection framework that adapts its strategy based on the query type. Specifically,DIG employs efficient uniform sampling for global queries while activating a specialized pipeline to extract query-relevant frames for localized queries. Experiments on three long-form video understanding benchmarks demonstrate that DIG consistently outperforms existing baselines and robustly improves LMM performance, even when scaling the input frame count to 256.\nüì• Save to Zotero üìÑ Download PDF\nDraCo: Draft as CoT for Text-to-Image Preview and Rare Concept Generation Authors: Dongzhi Jiang, Renrui Zhang, Haodong Li, Zhuofan Zong, Ziyu Guo, Jun He, Claire Guo, Junyan Ye, Rongyao Fang, Weijia Li, Rui Liu, Hongsheng Li Venue: arXiv (2025)\nRecent unified multimodal large language models (MLLMs) have shown impressive capabilities, incorporating chain-of-thought (CoT) reasoning for enhanced text-to-image generation. However, existing approaches remain limited, either treating the model merely as a standalone generator or relying on abstract textual planning. To this end, we propose Draft-as-CoT (DraCo), a novel interleaved reasoning paradigm that fully leverages both textual and visual contents in CoT for better planning and verification. Our method first generates a low-resolution draft image as preview, providing more concrete and structural visual planning and guidance. Then, we employ the model‚Äôs inherent understanding capability to verify potential semantic misalignments between the draft and input prompt, and performs refinement through selective corrections with super-resolution. In this way, our approach addresses two fundamental challenges: the coarse-grained nature of textual planning and the difficulty in generating rare attribute combinations. To support training, we curate DraCo-240K, aiming to enhance three atomic capabilities spanning general correction, instance manipulation, and layout reorganization. Supported by DraCo-CFG, a specialized classifier-free guidance (CFG) strategy for interleaved reasoning, DraCo achieves a tremendous increase on GenEval (+8%), Imagine-Bench (+0.91), and GenEval++ (+3%), significantly outperforming direct generation and other generation methods empowered by CoT.\nüì• Save to Zotero üìÑ Download PDF\nARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning Authors: Shengyuan Ding, Xinyu Fang, Ziyu Liu, Yuhang Zang, Yuhang Cao, Xiangyu Zhao, Haodong Duan, Xiaoyi Dong, Jianze Liang, Bin Wang, Conghui He, Dahua Lin, Jiaqi Wang Venue: arXiv (2025)\nReward models are critical for aligning vision-language systems with human preferences, yet current approaches suffer from hallucination, weak visual grounding, and an inability to use tools for verification, limiting their reliability on complex multimodal reasoning tasks. We present ARM-Thinker, an A}gentic multimodal Reward Model that autonomously invokes external tools (e.g., image cropping, doc page retrieval) to ground judgments in verifiable evidence, replacing static, non-interactive reward scoring. This enables the model to verify fine-grained visual details, cross-reference multi-page evidence, and validate reasoning claims, which are capabilities absent in existing reward models. We train ARM-Thinker with multi-stage reinforcement learning, jointly optimizing tool-calling decisions and judgment accuracy. To evaluate agentic reward modeling, we introduce ARMBench-VL, comprising three benchmarks that assess fine-grained visual grounding (image-level tools), multi-page document understanding (retrieval tools), and instruction following (text-level verification). ARM-Thinker achieves +16.2% average improvement on reward modeling benchmarks, +9.6% on tool-use tasks, and outperforms baselines on multimodal math and logical reasoning benchmarks. Our results demonstrate that agentic capabilities significantly enhance both accuracy and interpretability of reward models.\nüì• Save to Zotero üìÑ Download PDF\nSTARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models Authors: Feng Xu, Guangyao Zhai, Xin Kong, Tingzhong Fu, Daniel F. N. Gordon, Xueli An, Benjamin Busam Venue: arXiv (2025)\nRecent advances in Vision-Language-Action (VLA) models, powered by large language models and reinforcement learning-based fine-tuning, have shown remarkable progress in robotic manipulation. Existing methods often treat long-horizon actions as linguistic sequences and apply trajectory-level optimization methods such as Trajectory-wise Preference Optimization (TPO) or Proximal Policy Optimization (PPO), leading to coarse credit assignment and unstable training. However, unlike language, where a unified semantic meaning is preserved despite flexible sentence order, action trajectories progress through causally chained stages with different learning difficulties. This motivates progressive stage optimization. Thereby, we present Stage-Aware Reinforcement (STARE), a module that decomposes a long-horizon action trajectory into semantically meaningful stages and provides dense, interpretable, and stage-aligned reinforcement signals. Integrating STARE into TPO and PPO, we yield Stage-Aware TPO (STA-TPO) and Stage-Aware PPO (STA-PPO) for offline stage-wise preference and online intra-stage interaction, respectively. Further building on supervised fine-tuning as initialization, we propose the Imitation -\u003e Preference -\u003e Interaction (IPI), a serial fine-tuning pipeline for improving action accuracy in VLA models. Experiments on SimplerEnv and ManiSkill3 demonstrate substantial gains, achieving state-of-the-art success rates of 98.0 percent on SimplerEnv and 96.4 percent on ManiSkill3 tasks.\nüì• Save to Zotero üìÑ Download PDF\nSemantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning Authors: Purbesh Mitra, Sennur Ulukus Venue: arXiv (2025)\nLong context reasoning in large language models (LLMs) has demonstrated enhancement of their cognitive capabilities via chain-of-thought (CoT) inference. Training such models is usually done via reinforcement learning with verifiable rewards (RLVR) in reasoning based problems, like math and programming. However, RLVR is limited by several bottlenecks, such as, lack of dense reward, and inadequate sample efficiency. As a result, it requires significant compute resources in post-training phase. To overcome these limitations, in this work, we propose \\textbf{Semantic Soft Bootstrapping (SSB)}, a self-distillation technique, in which the same base language model plays the role of both teacher and student, but receives different semantic contexts about the correctness of its outcome at training time. The model is first prompted with a math problem and several rollouts are generated. From them, the correct and most common incorrect response are filtered, and then provided to the model in context to produce a more robust, step-by-step explanation with a verified final answer. This pipeline automatically curates a paired teacher-student training set from raw problem-answer data, without any human intervention. This generation process also produces a sequence of logits, which is what the student model tries to match in the training phase just from the bare question alone. In our experiment, Qwen2.5-3B-Instruct on GSM8K dataset via parameter-efficient fine-tuning. We then tested its accuracy on MATH500, and AIME2024 benchmarks. Our experiments show a jump of 10.6%, and 10% improvements in accuracy, respectively, over group relative policy optimization (GRPO), which is a commonly used RLVR algorithm. Our code is available at https://github.com/purbeshmitra/semantic-soft-bootstrapping, and the model, curated dataset is available at https://huggingface.co/purbeshmitra/semantic-soft-bootstrapping.\nüì• Save to Zotero üìÑ Download PDF\nTV2TV: A Unified Framework for Interleaved Language and Video Generation Authors: Xiaochuang Han, Youssef Emad, Melissa Hall, John Nguyen, Karthik Padthe, Liam Robbins, Amir Bar, Delong Chen, Michal Drozdzal, Maha Elbayad, Yushi Hu, Shang-Wen Li, Sreya Dutta Roy, Jakob Verbeek, XuDong Wang, Marjan Ghazvininejad, Luke Zettlemoyer, Emily Dinan Venue: arXiv (2025)\nVideo generation models are rapidly advancing, but can still struggle with complex video outputs that require significant semantic branching or repeated high-level reasoning about what should happen next. In this paper, we introduce a new class of omni video-text models that integrate ideas from recent LM reasoning advances to address this challenge. More specifically, we present TV2TV, a unified generative modeling framework which decomposes video generation into an interleaved text and video generation process. TV2TV jointly learns language modeling (next-token prediction) and video flow matching (next-frame prediction) using a Mixture-of-Transformers (MoT) architecture. At inference time, TV2TV decides when to alternate between generating text and video frames, allowing the model to ‚Äúthink in words‚Äù about subsequent content before ``acting in pixels‚Äô‚Äô to produce frames. This design offloads much of the responsibility for deciding what should happen next to the language modeling tower, enabling improved visual quality and prompt alignment of generated videos. It also enables fine-grained controllability, allowing users to modify the video generation trajectory through text interventions at any point in the process. In controlled experiments on video game data, TV2TV demonstrates substantial improvements in both visual quality and controllability. TV2TV also scales to natural videos, as we show by augmenting sports videos with interleaved natural language action descriptions using vision-language models (VLMs). Training TV2TV on this corpus yields strong visual quality and prompt alignment, showcasing the model‚Äôs ability to reason about and generate complex real-world action sequences. Together, these results highlight TV2TV as a promising step toward video generation with open-ended textual reasoning and control.\nüì• Save to Zotero üìÑ Download PDF\nStructured Document Translation via Format Reinforcement Learning Authors: Haiyue Song, Johannes Eschbach-Dymanus, Hour Kaing, Sumire Honda, Hideki Tanaka, Bianka Buschbeck, Masao Utiyama Venue: arXiv (2025)\nRecent works on structured text translation remain limited to the sentence level, as they struggle to effectively handle the complex document-level XML or HTML structures. To address this, we propose \\textbf{Format Reinforcement Learning (FormatRL)}, which employs Group Relative Policy Optimization on top of a supervised fine-tuning model to directly optimize novel structure-aware rewards: 1) TreeSim, which measures structural similarity between predicted and reference XML trees and 2) Node-chrF, which measures translation quality at the level of XML nodes. Additionally, we apply StrucAUC, a fine-grained metric distinguishing between minor errors and major structural failures. Experiments on the SAP software-documentation benchmark demonstrate improvements across six metrics and an analysis further shows how different reward functions contribute to improvements in both structural and translation quality.\nüì• Save to Zotero üìÑ Download PDF\nVisual Reasoning Tracer: Object-Level Grounded Reasoning Benchmark Authors: Haobo Yuan, Yueyi Sun, Yanwei Li, Tao Zhang, Xueqing Deng, Henghui Ding, Lu Qi, Anran Wang, Xiangtai Li, Ming-Hsuan Yang Venue: arXiv (2025)\nRecent advances in Multimodal Large Language Models (MLLMs) have significantly improved performance on tasks such as visual grounding and visual question answering. However, the reasoning processes of these models remain largely opaque; they typically output only final predictions without revealing the intermediate steps or fine-grained evidence (e.g., pixels, locations) that lead to the result. This contrasts with human intelligence, which naturally operates through a chain of visual reasoning. To address this limitation, we introduce the Visual Reasoning Tracer (VRT) task, which requires models to not only localize the target object but also explicitly predict the intermediate objects that form the reasoning path. To advance research in this area, we contribute: (1) VRT-Bench, a human-annotated benchmark for evaluating visual reasoning; (2) a new metric for assessing the quality of reasoning traces; and (3) VRT-80k, a large-scale dataset for reasoning model training. Our experiments reveal that while existing models often produce the correct final output, they struggle to ground their intermediate reasoning. In contrast, models trained on VRT-80k achieve substantial improvements in tracing the reasoning path.\nüì• Save to Zotero üìÑ Download PDF\nDavid vs. Goliath: Can Small Models Win Big with Agentic AI in Hardware Design? Authors: Shashwat Shankar, Subhranshu Pandey, Innocent Dengkhw Mochahari, Bhabesh Mali, Animesh Basak Chowdhury, Sukanta Bhattacharjee, Chandan Karfa Venue: arXiv (2025)\nLarge Language Model(LLM) inference demands massive compute and energy, making domain-specific tasks expensive and unsustainable. As foundation models keep scaling, we ask: Is bigger always better for hardware design? Our work tests this by evaluating Small Language Models coupled with a curated agentic AI framework on NVIDIA‚Äôs Comprehensive Verilog Design Problems(CVDP) benchmark. Results show that agentic workflows: through task decomposition, iterative feedback, and correction - not only unlock near-LLM performance at a fraction of the cost but also create learning opportunities for agents, paving the way for efficient, adaptive solutions in complex design tasks.\nüì• Save to Zotero üìÑ Download PDF\nMulti-LLM Collaboration for Medication Recommendation Authors: Huascar Sanchez, Briland Hitaj, Jules Bergmann, Linda Briesemeister Venue: arXiv (2025)\nAs healthcare increasingly turns to AI for scalable and trustworthy clinical decision support, ensuring reliability in model reasoning remains a critical challenge. Individual large language models (LLMs) are susceptible to hallucinations and inconsistency, whereas naive ensembles of models often fail to deliver stable and credible recommendations. Building on our previous work on LLM Chemistry, which quantifies the collaborative compatibility among LLMs, we apply this framework to improve the reliability in medication recommendation from brief clinical vignettes. Our approach leverages multi-LLM collaboration guided by Chemistry-inspired interaction modeling, enabling ensembles that are effective (exploiting complementary strengths), stable (producing consistent quality), and calibrated (minimizing interference and error amplification). We evaluate our Chemistry-based Multi-LLM collaboration strategy on real-world clinical scenarios to investigate whether such interaction-aware ensembles can generate credible, patient-specific medication recommendations. Preliminary results are encouraging, suggesting that LLM Chemistry-guided collaboration may offer a promising path toward reliable and trustworthy AI assistants in clinical practice.\nüì• Save to Zotero üìÑ Download PDF\nPersonalizing Agent Privacy Decisions via Logical Entailment Authors: James Flemings, Ren Yi, Octavian Suciu, Kassem Fawaz, Murali Annavaram, Marco Gruteser Venue: arXiv (2025)\nPersonal language model-based agents are becoming more widespread for completing tasks on behalf of users; however, this raises serious privacy questions regarding whether these models will appropriately disclose user data. While prior work has evaluated language models on data-sharing scenarios based on general privacy norms, we focus on personalizing language models‚Äô privacy decisions, grounding their judgments directly in prior user privacy decisions. Our findings suggest that general privacy norms are insufficient for effective personalization of privacy decisions. Furthermore, we find that eliciting privacy judgments from the model through In-context Learning (ICL) is unreliable to due misalignment with the user‚Äôs prior privacy judgments and opaque reasoning traces, which make it difficult for the user to interpret the reasoning behind the model‚Äôs decisions. To address these limitations, we propose ARIEL (Agentic Reasoning with Individualized Entailment Logic), a framework that jointly leverages a language model and rule-based logic for structured data-sharing reasoning. ARIEL is based on formulating personalization of data sharing as an entailment, whether a prior user judgment on a data-sharing request implies the same judgment for an incoming request. Our experimental evaluations on advanced models and publicly-available datasets demonstrate that ARIEL can reduce the F1 score error by $\\textbf{39.1%}$ over language model-based reasoning (ICL), demonstrating that ARIEL is effective at correctly judging requests where the user would approve data sharing. Overall, our findings suggest that combining LLMs with strict logical entailment is a highly effective strategy for enabling personalized privacy judgments for agents.\nüì• Save to Zotero üìÑ Download PDF\n4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer Authors: Xianfeng Wu, Yajing Bai, Minghan Li, Xianzu Wu, Xueqi Zhao, Zhongyuan Lai, Wenyu Liu, Xinggang Wang Venue: arXiv (2025)\nConstructing 4D language fields is crucial for embodied AI, augmented/virtual reality, and 4D scene understanding, as they provide enriched semantic representations of dynamic environments and enable open-vocabulary querying in complex scenarios. However, existing approaches to 4D semantic field construction primarily rely on scene-specific Gaussian splatting, which requires per-scene optimization, exhibits limited generalization, and is difficult to scale to real-world applications. To address these limitations, we propose 4DLangVGGT, the first Transformer-based feed-forward unified framework for 4D language grounding, that jointly integrates geometric perception and language alignment within a single architecture. 4DLangVGGT has two key components: the 4D Visual Geometry Transformer, StreamVGGT, which captures spatio-temporal geometric representations of dynamic scenes; and the Semantic Bridging Decoder (SBD), which projects geometry-aware features into a language-aligned semantic space, thereby enhancing semantic interpretability while preserving structural fidelity. Unlike prior methods that depend on costly per-scene optimization, 4DLangVGGT can be jointly trained across multiple dynamic scenes and directly applied during inference, achieving both deployment efficiency and strong generalization. This design significantly improves the practicality of large-scale deployment and establishes a new paradigm for open-vocabulary 4D scene understanding. Experiments on HyperNeRF and Neu3D datasets demonstrate that our approach not only generalizes effectively but also achieves state-of-the-art performance, achieving up to 2% gains under per-scene training and 1% improvements under multi-scene training. Our code released in https://github.com/hustvl/4DLangVGGT\nüì• Save to Zotero üìÑ Download PDF\nArbitrage: Efficient Reasoning via Advantage-Aware Speculation Authors: Monishwaran Maheswaran, Rishabh Tiwari, Yuezhou Hu, Kerem Dilmen, Coleman Hooper, Haocheng Xi, Nicholas Lee, Mehrdad Farajtabar, Michael W. Mahoney, Kurt Keutzer, Amir Gholami Venue: arXiv (2025)\nModern Large Language Models achieve impressive reasoning capabilities with long Chain of Thoughts, but they incur substantial computational cost during inference, and this motivates techniques to improve the performance-cost ratio. Among these techniques, Speculative Decoding accelerates inference by employing a fast but inaccurate draft model to autoregressively propose tokens, which are then verified in parallel by a more capable target model. However, due to unnecessary rejections caused by token mismatches in semantically equivalent steps, traditional token-level Speculative Decoding struggles in reasoning tasks. Although recent works have shifted to step-level semantic verification, which improve efficiency by accepting or rejecting entire reasoning steps, existing step-level methods still regenerate many rejected steps with little improvement, wasting valuable target compute. To address this challenge, we propose Arbitrage, a novel step-level speculative generation framework that routes generation dynamically based on the relative advantage between draft and target models. Instead of applying a fixed acceptance threshold, Arbitrage uses a lightweight router trained to predict when the target model is likely to produce a meaningfully better step. This routing approximates an ideal Arbitrage Oracle that always chooses the higher-quality step, achieving near-optimal efficiency-accuracy trade-offs. Across multiple mathematical reasoning benchmarks, Arbitrage consistently surpasses prior step-level Speculative Decoding baselines, reducing inference latency by up to $\\sim2\\times$ at matched accuracy.\nüì• Save to Zotero üìÑ Download PDF\nFactuality and Transparency Are All RAG Needs! Self-Explaining Contrastive Evidence Re-ranking Authors: Francielle Vargas, Daniel Pedronette Venue: arXiv (2025)\nThis extended abstract introduces Self-Explaining Contrastive Evidence Re-Ranking (CER), a novel method that restructures retrieval around factual evidence by fine-tuning embeddings with contrastive learning and generating token-level attribution rationales for each retrieved passage. Hard negatives are automatically selected using a subjectivity-based criterion, forcing the model to pull factual rationales closer while pushing subjective or misleading explanations apart. As a result, the method creates an embedding space explicitly aligned with evidential reasoning. We evaluated our method on clinical trial reports, and initial experimental results show that CER improves retrieval accuracy, mitigates the potential for hallucinations in RAG systems, and provides transparent, evidence-based retrieval that enhances reliability, especially in safety-critical domains.\nüì• Save to Zotero üìÑ Download PDF\nInfluence of Object Affordance on Action Language Understanding: Evidence from Dynamic Causal Modeling Analysis Authors: Supriya Bordoloi, Cota Navin Gupta, Shyamanta M. Hazarika Venue: arXiv (2025)\nThis study investigates the causal neural dynamics by which affordance representations influence action language comprehension. In this study, 18 participants observed stimuli displayed in two conditions during the experiment: text-only (e.g., `Hit with a hammer‚Äô) and video+text (visual clips with matching phrases). EEG data were recorded from 32 channels and analyzed for event-related potentials and source localization using LORETA, which identified four left-hemisphere regions of interest: the Lateral Occipital Cortex (LOC), Posterior Superior Temporal Gyrus (pSTG), Ventral Premotor Cortex (PMv), and Inferior Parietal Lobule (IPL). A space of dynamic causal modeling (DCM) was constructed with driving inputs to LOC and pSTG, and multiple connectivity configurations were tested. Bayesian Model Selection revealed a dominant model in which PMv causally influenced IPL and pSTG, reflecting a feedforward architecture from affordance-related motor regions to semantic hubs. Bayesian Model Averaging further confirmed strong endogenous connections from LOC to PMv and IPL, and significant modulation from PMv to IPL. These findings provide direct evidence that affordance processing in premotor regions drives action language understanding by engaging downstream parietal and temporal areas. The results support grounded cognition theories and offer a mechanistic account of how sensorimotor information contributes to linguistic comprehension.\nüì• Save to Zotero üìÑ Download PDF\nStrategic Self-Improvement for Competitive Agents in AI Labour Markets Authors: Christopher Chiu, Simpson Zhang, Mihaela van der Schaar Venue: arXiv (2025)\nAs artificial intelligence (AI) agents are deployed across economic domains, understanding their strategic behavior and market-level impact becomes critical. This paper puts forward a groundbreaking new framework that is the first to capture the real-world economic forces that shape agentic labor markets: adverse selection, moral hazard, and reputation dynamics. Our framework encapsulates three core capabilities that successful LLM-agents will need: \\textbf{metacognition} (accurate self-assessment of skills), \\textbf{competitive awareness} (modeling rivals and market dynamics), and \\textbf{long-horizon strategic planning}. We illustrate our framework through a tractable simulated gig economy where agentic Large Language Models (LLMs) compete for jobs, develop skills, and adapt their strategies under competitive pressure. Our simulations illustrate how LLM agents explicitly prompted with reasoning capabilities learn to strategically self-improve and demonstrate superior adaptability to changing market conditions. At the market level, our simulations reproduce classic macroeconomic phenomena found in human labor markets, while controlled experiments reveal potential AI-driven economic trends, such as rapid monopolization and systemic price deflation. This work provides a foundation to further explore the economic properties of AI-driven labour markets, and a conceptual framework to study the strategic reasoning capabilities in agents competing in the emerging economy.\nüì• Save to Zotero üìÑ Download PDF\nNex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction Authors: Nex-AGI Team, :, Yuxuan Cai, Lu Chen, Qiaoling Chen, Yuyang Ding, Liwen Fan, Wenjie Fu, Yufei Gao, Honglin Guo, Pinxue Guo, Zhenhua Han, Zhengfu He, Hanglei Hu, Kai Hu, Shengjia Hua, Tianyu Huai, Baodai Huang, Li Ji, Zhen Jiang, Zhikai Lei, Bufan Li, Jiahang Lin, Lizhi Lin, Jinxiu Liu, Shichun Liu, Ziming Liu, Yuchen Ni, Pengfang Qian, Yujiong Shen, Qingyun Shi, Wentao Shu, Peng Sun, Yiran Suo, Tian Tang, Boyu Tian, Guoteng Wang, Junzhe Wang, Peixin Wang, Zhiheng Xi, Hang Yan, Jie Yang, Zhixiong Yang, Tianchu Yao, Guangze Ye, Qianxi Yu, Shuo Zhang, Xinyue Zhang, Yiqi Zhang, Jiarong Zhao, Miao Zheng, Rui Zheng, Enyu Zhou, Jiazheng Zhou, Maosen Zhou, Yuhao Zhou, Tao Gui, Yining Zheng, Xinchi Chen, Jie Zhou, Siyuan Feng, Qin Chen, Liang He, Qi Zhang, Xuanjing Huang, Xipeng Qiu Venue: arXiv (2025)\nThe evolution of Large Language Models (LLMs) from passive responders to autonomous agents necessitates a fundamental shift in learning paradigms ‚Äì from static imitation to incentive-driven decision making. However, this transition is significantly impeded by the lack of scalable infrastructure capable of constructing high-quality interaction signals for effective policy learning. To address this, we introduce a comprehensive method designed to systematically scale the diversity and complexity of interactive environments. Our method realizes this scaling by addressing three orthogonal dimensions: (1) Complexity: NexAU, a flexible agent framework that supports building complex agent hierarchies via simple configurations; (2) Diversity: NexA4A automatically generates diverse agent hierarchies from natural language to cover infinite domains; and (3) Fidelity: NexGAP bridges the simulation-reality gap by integrating dynamic real-world environment for grounded trajectories synthesis. We train Nex-N1 upon the diverse and complex interactive environments established by our infrastructure. Empirical results on benchmarks such as SWE-bench and tau2 demonstrate that Nex-N1 consistently outperforms SOTA open-source models and achieves competitive performance against frontier proprietary models on complex agentic tasks. We open-source the Nex ecosystem and model weights to facilitate further research.\nüì• Save to Zotero üìÑ Download PDF\nAligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models Authors: NaHyeon Park, Namin An, Kunhee Kim, Soyeon Yoon, Jiahao Huo, Hyunjung Shim Venue: arXiv (2025)\nLarge vision-language model (LVLM) based text-to-image (T2I) systems have become the dominant paradigm in image generation, yet whether they amplify social biases remains insufficiently understood. In this paper, we show that LVLM-based models produce markedly more socially biased images than non-LVLM-based models. We introduce a 1,024 prompt benchmark spanning four levels of linguistic complexity and evaluate demographic bias across multiple attributes in a systematic manner. Our analysis identifies system prompts, the predefined instructions guiding LVLMs, as a primary driver of biased behavior. Through decoded intermediate representations, token-probability diagnostics, and embedding-association analyses, we reveal how system prompts encode demographic priors that propagate into image synthesis. To this end, we propose FairPro, a training-free meta-prompting framework that enables LVLMs to self-audit and construct fairness-aware system prompts at test time. Experiments on two LVLM-based T2I models, SANA and Qwen-Image, show that FairPro substantially reduces demographic bias while preserving text-image alignment. We believe our findings provide deeper insight into the central role of system prompts in bias propagation and offer a practical, deployable approach for building more socially responsible T2I systems.\nüì• Save to Zotero üìÑ Download PDF\nHiPPO: Exploring A Novel Hierarchical Pronunciation Assessment Approach for Spoken Languages Authors: Bi-Cheng Yan, Hsin-Wei Wang, Fu-An Chao, Tien-Hong Lo, Yung-Chang Hsu, Berlin Chen Venue: arXiv (2025)\nAutomatic pronunciation assessment (APA) seeks to quantify a second language (L2) learner‚Äôs pronunciation proficiency in a target language by offering timely and fine-grained diagnostic feedback. Most existing efforts on APA have predominantly concentrated on highly constrained reading-aloud tasks (where learners are prompted to read a reference text aloud); however, assessing pronunciation quality in unscripted speech (or free-speaking scenarios) remains relatively underexplored. In light of this, we first propose HiPPO, a hierarchical pronunciation assessment model tailored for spoken languages, which evaluates an L2 learner‚Äôs oral proficiency at multiple linguistic levels based solely on the speech uttered by the learner. To improve the overall accuracy of assessment, a contrastive ordinal regularizer and a curriculum learning strategy are introduced for model training. The former aims to generate score-discriminative features by exploiting the ordinal nature of regression targets, while the latter gradually ramps up the training complexity to facilitate the assessment task that takes unscripted speech as input. Experiments conducted on the Speechocean762 benchmark dataset validates the feasibility and superiority of our method in relation to several cutting-edge baselines.\nüì• Save to Zotero üìÑ Download PDF\nFASTer: Toward Efficient Autoregressive Vision Language Action Modeling via neural Action Tokenization Authors: Yicheng Liu, Shiduo Zhang, Zibin Dong, Baijun Ye, Tianyuan Yuan, Xiaopeng Yu, Linqi Yin, Chenhao Lu, Junhao Shi, Luca Jiang-Tao Yu, Liangtao Zheng, Tao Jiang, Jingjing Gong, Xipeng Qiu, Hang Zhao Venue: arXiv (2025)\nAutoregressive vision-language-action (VLA) models have recently demonstrated strong capabilities in robotic manipulation. However, their core process of action tokenization often involves a trade-off between reconstruction fidelity and inference efficiency. We introduce FASTer, a unified framework for efficient and generalizable robot learning that integrates a learnable tokenizer with an autoregressive policy built upon it. FASTerVQ encodes action chunks as single-channel images, capturing global spatio-temporal dependencies while maintaining a high compression ratio. FASTerVLA builds on this tokenizer with block-wise autoregressive decoding and a lightweight action expert, achieving both faster inference and higher task performance. Extensive experiments across simulated and real-world benchmarks show that FASTerVQ delivers superior reconstruction quality, high token utilization, and strong cross-task and cross-embodiment generalization, while FASTerVLA further improves overall capability, surpassing previous state-of-the-art VLA models in both inference speed and task performance.\nüì• Save to Zotero üìÑ Download PDF\nCARL: Critical Action Focused Reinforcement Learning for Multi-Step Agent Authors: Leyang Shen, Yang Zhang, Chun Kai Ling, Xiaoyan Zhao, Tat-Seng Chua Venue: arXiv (2025)\nAgents capable of accomplishing complex tasks through multiple interactions with the environment have emerged as a popular research direction. However, in such multi-step settings, the conventional group-level policy optimization algorithm becomes suboptimal because of its underlying assumption that each action holds equal contribution, which deviates significantly from reality. Our analysis reveals that only a small fraction of actions are critical in determining the final outcome. Building on this insight, we propose CARL, a critical-action-focused reinforcement learning algorithm tailored for multi-step agents. CARL achieves focused training through providing action-level optimization signals for high-criticality actions while excluding low-criticality actions from model update. Extensive experiments demonstrate that CARL achieves both stronger performance and higher efficiency during training and inference across diverse evaluation settings.\nüì• Save to Zotero üìÑ Download PDF\nGrowing Spines: Ad Infinitum et Ad Infinitesimalia Authors: Blaise Boissonneau, Anna De Mase, Franziska Jahnke, Pierre Touchard Venue: arXiv (2025)\nWe prove that for every ordered abelian group $G$ there exists a non-trivial ordered abelian group $H$ such that $G\\preccurlyeq H\\oplus G$ with the lexicographic order, and give a first-order characterization of ordered abelian group $G$ such that $G\\preccurlyeq G\\oplus H$ for some non-trivial $H$. We apply this to characterize which ordered abelian groups (respectively fields) ensure that any henselian valuation with said value group (respectively residue field) is definable in the language of rings. This answers a question of Krapp, Kuhlmann, and Link.\nüì• Save to Zotero üìÑ Download PDF\nAlgorithmic Thinking Theory Authors: MohammadHossein Bateni, Vincent Cohen-Addad, Yuzhou Gu, Silvio Lattanzi, Simon Meierhans, Christopher Mohri Venue: arXiv (2025)\nLarge language models (LLMs) have proven to be highly effective for solving complex reasoning tasks. Surprisingly, their capabilities can often be improved by iterating on previously generated solutions. In this context, a reasoning plan for generating and combining a set of solutions can be thought of as an algorithm for reasoning using a probabilistic oracle. We introduce a theoretical framework for analyzing such reasoning algorithms. This framework formalizes the principles underlying popular techniques for iterative improvement and answer aggregation, providing a foundation for designing a new generation of more powerful reasoning methods. Unlike approaches for understanding models that rely on architectural specifics, our model is grounded in experimental evidence. As a result, it offers a general perspective that may extend to a wide range of current and future reasoning oracles.\nüì• Save to Zotero üìÑ Download PDF\nThe AI Consumer Index (ACE) Authors: Julien Benchek, Rohit Shetty, Benjamin Hunsberger, Ajay Arun, Zach Richards, Brendan Foody, Osvald Nitski, Bertie Vidgen Venue: arXiv (2025)\nWe introduce the first version of the AI Consumer Index (ACE), a benchmark for assessing whether frontier AI models can perform high-value consumer tasks. ACE contains a hidden heldout set of 400 test cases, split across four consumer activities: shopping, food, gaming, and DIY. We are also open sourcing 80 cases as a devset with a CC-BY license. For the ACE leaderboard we evaluated 10 frontier models (with websearch turned on) using a novel grading methodology that dynamically checks whether relevant parts of the response are grounded in the retrieved web sources. GPT 5 (Thinking = High) is the top-performing model, scoring 56.1%, followed by o3 Pro (Thinking = On) (55.2%) and GPT 5.1 (Thinking = High) (55.1%). Models differ across domains, and in Shopping the top model scores under 50%. For some requests (such as giving the correct price or providing working links), models are highly prone to hallucination. Overall, ACE shows a substantial gap between the performance of even the best models and consumers‚Äô AI needs.\nüì• Save to Zotero üìÑ Download PDF\nExistentially defining valuations in function fields over large fields Authors: Nicolas Daans Venue: arXiv (2025)\nLet $K$ be a large field such that $K[\\sqrt{-1}]$ is not algebraically closed and $F/K$ a function field in one variable. Extending techniques and results from earlier work with Becher and Dittmann, we show that every valuation ring on $F$ containing $K$ is existentially definable in the language of rings with parameters from $F$. As a consequence, using a known reduction technique, we obtain the undecidability of the existential theory of $F$ in the language of rings with appropriately chosen parameters.\nüì• Save to Zotero üìÑ Download PDF\nChameleon: Adaptive Adversarial Agents for Scaling-Based Visual Prompt Injection in Multimodal AI Systems Authors: M Zeeshan, Saud Satti Venue: arXiv (2025)\nMultimodal Artificial Intelligence (AI) systems, particularly Vision-Language Models (VLMs), have become integral to critical applications ranging from autonomous decision-making to automated document processing. As these systems scale, they rely heavily on preprocessing pipelines to handle diverse inputs efficiently. However, this dependency on standard preprocessing operations, specifically image downscaling, creates a significant yet often overlooked security vulnerability. While intended for computational optimization, scaling algorithms can be exploited to conceal malicious visual prompts that are invisible to human observers but become active semantic instructions once processed by the model. Current adversarial strategies remain largely static, failing to account for the dynamic nature of modern agentic workflows. To address this gap, we propose Chameleon, a novel, adaptive adversarial framework designed to expose and exploit scaling vulnerabilities in production VLMs. Unlike traditional static attacks, Chameleon employs an iterative, agent-based optimization mechanism that dynamically refines image perturbations based on the target model‚Äôs real-time feedback. This allows the framework to craft highly robust adversarial examples that survive standard downscaling operations to hijack downstream execution. We evaluate Chameleon against Gemini 2.5 Flash model. Our experiments demonstrate that Chameleon achieves an Attack Success Rate (ASR) of 84.5% across varying scaling factors, significantly outperforming static baseline attacks which average only 32.1%. Furthermore, we show that these attacks effectively compromise agentic pipelines, reducing decision-making accuracy by over 45% in multi-step tasks. Finally, we discuss the implications of these vulnerabilities and propose multi-scale consistency checks as a necessary defense mechanism.\nüì• Save to Zotero üìÑ Download PDF\nSTELLA: Guiding Large Language Models for Time Series Forecasting with Semantic Abstractions Authors: Junjie Fan, Hongye Zhao, Linduo Wei, Jiayu Rao, Guijia Li, Jiaxin Yuan, Wenqi Xu, Yong Qi Venue: arXiv (2025)\nRecent adaptations of Large Language Models (LLMs) for time series forecasting often fail to effectively enhance information for raw series, leaving LLM reasoning capabilities underutilized. Existing prompting strategies rely on static correlations rather than generative interpretations of dynamic behavior, lacking critical global and instance-specific context. To address this, we propose STELLA (Semantic-Temporal Alignment with Language Abstractions), a framework that systematically mines and injects structured supplementary and complementary information. STELLA employs a dynamic semantic abstraction mechanism that decouples input series into trend, seasonality, and residual components. It then translates intrinsic behavioral features of these components into Hierarchical Semantic Anchors: a Corpus-level Semantic Prior (CSP) for global context and a Fine-grained Behavioral Prompt (FBP) for instance-level patterns. Using these anchors as prefix-prompts, STELLA guides the LLM to model intrinsic dynamics. Experiments on eight benchmark datasets demonstrate that STELLA outperforms state-of-the-art methods in long- and short-term forecasting, showing superior generalization in zero-shot and few-shot settings. Ablation studies further validate the effectiveness of our dynamically generated semantic anchors.\nüì• Save to Zotero üìÑ Download PDF\nSEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs Authors: Hao Wang, Jialun Zhong, Changcheng Wang, Zhujun Nie, Zheng Li, Shunyu Yao, Yanzeng Li, Xinchi Li Venue: arXiv (2025)\nKnowledge-based conversational question answering (KBCQA) confronts persistent challenges in resolving coreference, modeling contextual dependencies, and executing complex logical reasoning. Existing approaches, whether end-to-end semantic parsing or stepwise agent-based reasoning, often suffer from structural inaccuracies and prohibitive computational costs, particularly when processing intricate queries over large knowledge graphs. To address these limitations, we introduce SEAL, a novel two-stage semantic parsing framework grounded in self-evolving agentic learning. In the first stage, a large language model (LLM) extracts a minimal S-expression core that captures the essential semantics of the input query. This core is then refined by an agentic calibration module, which corrects syntactic inconsistencies and aligns entities and relations precisely with the underlying knowledge graph. The second stage employs template-based completion, guided by question-type prediction and placeholder instantiation, to construct a fully executable S-expression. This decomposition not only simplifies logical form generation but also significantly enhances structural fidelity and linking efficiency. Crucially, SEAL incorporates a self-evolving mechanism that integrates local and global memory with a reflection module, enabling continuous adaptation from dialog history and execution feedback without explicit retraining. Extensive experiments on the SPICE benchmark demonstrate that SEAL achieves state-of-the-art performance, especially in multi-hop reasoning, comparison, and aggregation tasks. The results validate notable gains in both structural accuracy and computational efficiency, underscoring the framework‚Äôs capacity for robust and scalable conversational reasoning.\nüì• Save to Zotero üìÑ Download PDF\nAre Your Agents Upward Deceivers? Authors: Dadi Guo, Qingyu Liu, Dongrui Liu, Qihan Ren, Shuai Shao, Tianyi Qiu, Haoran Li, Yi R. Fung, Zhongjie Ba, Juntao Dai, Jiaming Ji, Zhikai Chen, Jialing Tao, Yaodong Yang, Jing Shao, Xia Hu Venue: arXiv (2025)\nLarge Language Model (LLM)-based agents are increasingly used as autonomous subordinates that carry out tasks for users. This raises the question of whether they may also engage in deception, similar to how individuals in human organizations lie to superiors to create a good image or avoid punishment. We observe and define agentic upward deception, a phenomenon in which an agent facing environmental constraints conceals its failure and performs actions that were not requested without reporting. To assess its prevalence, we construct a benchmark of 200 tasks covering five task types and eight realistic scenarios in a constrained environment, such as broken tools or mismatched information sources. Evaluations of 11 popular LLMs reveal that these agents typically exhibit action-based deceptive behaviors, such as guessing results, performing unsupported simulations, substituting unavailable information sources, and fabricating local files. We further test prompt-based mitigation and find only limited reductions, suggesting that it is difficult to eliminate and highlighting the need for stronger mitigation strategies to ensure the safety of LLM-based agents.\nüì• Save to Zotero üìÑ Download PDF\nAsk Safely: Privacy-Aware LLM Query Generation for Knowledge Graphs Authors: Mauro Dalle Lucca Tosi, Jordi Cabot Venue: arXiv (2025)\nLarge Language Models (LLMs) are increasingly used to query knowledge graphs (KGs) due to their strong semantic understanding and extrapolation capabilities compared to traditional approaches. However, these methods cannot be applied when the KG contains sensitive data and the user lacks the resources to deploy a local generative LLM. To address this issue, we propose a privacy-aware query generation approach for KGs. Our method identifies sensitive information in the graph based on its structure and omits such values before requesting the LLM to translate natural language questions into Cypher queries. Experimental results show that our approach preserves the quality of the generated queries while preventing sensitive data from being transmitted to third-party services.\nüì• Save to Zotero üìÑ Download PDF\nLanguage Models as Semantic Teachers: Post-Training Alignment for Medical Audio Understanding Authors: Tsai-Ning Wang, Lin-Lin Chen, Neil Zeghidour, Aaqib Saeed Venue: arXiv (2025)\nPre-trained audio models excel at detecting acoustic patterns in auscultation sounds but often fail to grasp their clinical significance, limiting their use and performance in diagnostic tasks. To bridge this gap, we introduce AcuLa (Audio-Clinical Understanding via Language Alignment), a lightweight post-training framework that instills semantic understanding into any audio encoder by aligning it with a medical language model, which acts as a ‚Äúsemantic teacher.‚Äù To enable alignment at scale, we construct a large-scale dataset by leveraging off-the-shelf large language models to translate the rich, structured metadata accompanying existing audio recordings into coherent clinical reports. Our alignment strategy combines a representation-level contrastive objective with a self-supervised modeling, ensuring that the model learns clinical semantics while preserving fine-grained temporal cues. AcuLa achieves state-of-the-art results across 18 diverse cardio-respiratory tasks from 10 different datasets, improving the mean AUROC on classification benchmarks from 0.68 to 0.79 and, on the most challenging COVID-19 cough detection task, boosting the AUROC from 0.55 to 0.89. Our work demonstrates that this audio-language alignment transforms purely acoustic models into clinically-aware diagnostic tools, establishing a novel paradigm for enhancing physiological understanding in audio-based health monitoring.\nüì• Save to Zotero üìÑ Download PDF\nSoK: a Comprehensive Causality Analysis Framework for Large Language Model Security Authors: Wei Zhao, Zhe Li, Jun Sun Venue: arXiv (2025)\nLarge Language Models (LLMs) exhibit remarkable capabilities but remain vulnerable to adversarial manipulations such as jailbreaking, where crafted prompts bypass safety mechanisms. Understanding the causal factors behind such vulnerabilities is essential for building reliable defenses. In this work, we introduce a unified causality analysis framework that systematically supports all levels of causal investigation in LLMs, ranging from token-level, neuron-level, and layer-level interventions to representation-level analysis. The framework enables consistent experimentation and comparison across diverse causality-based attack and defense methods. Accompanying this implementation, we provide the first comprehensive survey of causality-driven jailbreak studies and empirically evaluate the framework on multiple open-weight models and safety-critical benchmarks including jailbreaks, hallucination detection, backdoor identification, and fairness evaluation. Our results reveal that: (1) targeted interventions on causally critical components can reliably modify safety behavior; (2) safety-related mechanisms are highly localized (i.e., concentrated in early-to-middle layers with only 1‚Äì2% of neurons exhibiting causal influence); and (3) causal features extracted from our framework achieve over 95% detection accuracy across multiple threat types. By bridging theoretical causality analysis and practical model safety, our framework establishes a reproducible foundation for research on causality-based attacks, interpretability, and robust attack detection and mitigation in LLMs. Code is available at https://github.com/Amadeuszhao/SOK_Casuality.\nüì• Save to Zotero üìÑ Download PDF\nDAMASHA: Detecting AI in Mixed Adversarial Texts via Segmentation with Human-interpretable Attribution Authors: L. D. M. S. Sai Teja, N. Siva Gopala Krishna, Ufaq Khan, Muhammad Haris Khan, Partha Pakray, Atul Mishra Venue: arXiv (2025)\nIn the age of advanced large language models (LLMs), the boundaries between human and AI-generated text are becoming increasingly blurred. We address the challenge of segmenting mixed-authorship text, that is identifying transition points in text where authorship shifts from human to AI or vice-versa, a problem with critical implications for authenticity, trust, and human oversight. We introduce a novel framework, called Info-Mask for mixed authorship detection that integrates stylometric cues, perplexity-driven signals, and structured boundary modeling to accurately segment collaborative human-AI content. To evaluate the robustness of our system against adversarial perturbations, we construct and release an adversarial benchmark dataset Mixed-text Adversarial setting for Segmentation (MAS), designed to probe the limits of existing detectors. Beyond segmentation accuracy, we introduce Human-Interpretable Attribution (HIA overlays that highlight how stylometric features inform boundary predictions, and we conduct a small-scale human study assessing their usefulness. Across multiple architectures, Info-Mask significantly improves span-level robustness under adversarial conditions, establishing new baselines while revealing remaining challenges. Our findings highlight both the promise and limitations of adversarially robust, interpretable mixed-authorship detection, with implications for trust and oversight in human-AI co-authorship.\nüì• Save to Zotero üìÑ Download PDF\nDaLA: Danish Linguistic Acceptability Evaluation Guided by Real World Errors Authors: Gianluca Barmina, Nathalie Carmen Hau Norman, Peter Schneider-Kamp, Lukas Galke Venue: arXiv (2025)\nWe present an enhanced benchmark for evaluating linguistic acceptability in Danish. We first analyze the most common errors found in written Danish. Based on this analysis, we introduce a set of fourteen corruption functions that generate incorrect sentences by systematically introducing errors into existing correct Danish sentences. To ensure the accuracy of these corruptions, we assess their validity using both manual and automatic methods. The results are then used as a benchmark for evaluating Large Language Models on a linguistic acceptability judgement task. Our findings demonstrate that this extension is both broader and more comprehensive than the current state of the art. By incorporating a greater variety of corruption types, our benchmark provides a more rigorous assessment of linguistic acceptability, increasing task difficulty, as evidenced by the lower performance of LLMs on our benchmark compared to existing ones. Our results also suggest that our benchmark has a higher discriminatory power which allows to better distinguish well-performing models from low-performing ones.\nüì• Save to Zotero üìÑ Download PDF\nSIMA 2: A Generalist Embodied Agent for Virtual Worlds Authors: SIMA team, Adrian Bolton, Alexander Lerchner, Alexandra Cordell, Alexandre Moufarek, Andrew Bolt, Andrew Lampinen, Anna Mitenkova, Arne Olav Hallingstad, Bojan Vujatovic, Bonnie Li, Cong Lu, Daan Wierstra, Daniel P. Sawyer, Daniel Slater, David Reichert, Davide Vercelli, Demis Hassabis, Drew A. Hudson, Duncan Williams, Ed Hirst, Fabio Pardo, Felix Hill, Frederic Besse, Hannah Openshaw, Harris Chan, Hubert Soyer, Jane X. Wang, Jeff Clune, John Agapiou, John Reid, Joseph Marino, Junkyung Kim, Karol Gregor, Kaustubh Sridhar, Kay McKinney, Laura Kampis, Lei M. Zhang, Loic Matthey, Luyu Wang, Maria Abi Raad, Maria Loks-Thompson, Martin Engelcke, Matija Kecman, Matthew Jackson, Maxime Gazeau, Ollie Purkiss, Oscar Knagg, Peter Stys, Piermaria Mendolicchio, Raia Hadsell, Rosemary Ke, Ryan Faulkner, Sarah Chakera, Satinder Singh Baveja, Shane Legg, Sheleem Kashem, Tayfun Terzi, Thomas Keck, Tim Harley, Tim Scholtes, Tyson Roberts, Volodymyr Mnih, Yulan Liu, Zhengdong Wang, Zoubin Ghahramani Venue: arXiv (2025)\nWe introduce SIMA 2, a generalist embodied agent that understands and acts in a wide variety of 3D virtual worlds. Built upon a Gemini foundation model, SIMA 2 represents a significant step toward active, goal-directed interaction within an embodied environment. Unlike prior work (e.g., SIMA 1) limited to simple language commands, SIMA 2 acts as an interactive partner, capable of reasoning about high-level goals, conversing with the user, and handling complex instructions given through language and images. Across a diverse portfolio of games, SIMA 2 substantially closes the gap with human performance and demonstrates robust generalization to previously unseen environments, all while retaining the base model‚Äôs core reasoning capabilities. Furthermore, we demonstrate a capacity for open-ended self-improvement: by leveraging Gemini to generate tasks and provide rewards, SIMA 2 can autonomously learn new skills from scratch in a new environment. This work validates a path toward creating versatile and continuously learning agents for both virtual and, eventually, physical worlds.\nüì• Save to Zotero üìÑ Download PDF\nSpatially-Enhanced Retrieval-Augmented Generation for Walkability and Urban Discovery Authors: Maddalena Amendola, Chiara Pugliese, Raffaele Perego, Chiara Renso Venue: arXiv (2025)\nLarge Language Models (LLMs) have become foundational tools in artificial intelligence, supporting a wide range of applications beyond traditional natural language processing, including urban systems and tourist recommendations. However, their tendency to hallucinate and their limitations in spatial retrieval and reasoning are well known, pointing to the need for novel solutions. Retrieval-augmented generation (RAG) has recently emerged as a promising way to enhance LLMs with accurate, domain-specific, and timely information. Spatial RAG extends this approach to tasks involving geographic understanding. In this work, we introduce WalkRAG, a spatial RAG-based framework with a conversational interface for recommending walkable urban itineraries. Users can request routes that meet specific spatial constraints and preferences while interactively retrieving information about the path and points of interest (POIs) along the way. Preliminary results show the effectiveness of combining information retrieval, spatial reasoning, and LLMs to support urban discovery.\nüì• Save to Zotero üìÑ Download PDF\nASTRIDE: A Security Threat Modeling Platform for Agentic-AI Applications Authors: Eranga Bandara, Amin Hass, Ross Gore, Sachin Shetty, Ravi Mukkamala, Safdar H. Bouk, Xueping Liang, Ng Wee Keong, Kasun De Zoysa, Aruna Withanage, Nilaan Loganathan Venue: arXiv (2025)\nAI agent-based systems are becoming increasingly integral to modern software architectures, enabling autonomous decision-making, dynamic task execution, and multimodal interactions through large language models (LLMs). However, these systems introduce novel and evolving security challenges, including prompt injection attacks, context poisoning, model manipulation, and opaque agent-to-agent communication, that are not effectively captured by traditional threat modeling frameworks. In this paper, we introduce ASTRIDE, an automated threat modeling platform purpose-built for AI agent-based systems. ASTRIDE extends the classical STRIDE framework by introducing a new threat category, A for AI Agent-Specific Attacks, which encompasses emerging vulnerabilities such as prompt injection, unsafe tool invocation, and reasoning subversion, unique to agent-based applications. To automate threat modeling, ASTRIDE combines a consortium of fine-tuned vision-language models (VLMs) with the OpenAI-gpt-oss reasoning LLM to perform end-to-end analysis directly from visual agent architecture diagrams, such as data flow diagrams(DFDs). LLM agents orchestrate the end-to-end threat modeling automation process by coordinating interactions between the VLM consortium and the reasoning LLM. Our evaluations demonstrate that ASTRIDE provides accurate, scalable, and explainable threat modeling for next-generation intelligent systems. To the best of our knowledge, ASTRIDE is the first framework to both extend STRIDE with AI-specific threats and integrate fine-tuned VLMs with a reasoning LLM to fully automate diagram-driven threat modeling in AI agent-based applications.\nüì• Save to Zotero üìÑ Download PDF\nMemLoRA: Distilling Expert Adapters for On-Device Memory Systems Authors: Massimo Bini, Ondrej Bohdal, Umberto Michieli, Zeynep Akata, Mete Ozay, Taha Ceritli Venue: arXiv (2025)\nMemory-augmented Large Language Models (LLMs) have demonstrated remarkable consistency during prolonged dialogues by storing relevant memories and incorporating them as context. Such memory-based personalization is also key in on-device settings that allow users to keep their conversations and data private. However, memory-augmented systems typically rely on LLMs that are too costly for local on-device deployment. Even though Small Language Models (SLMs) are more suitable for on-device inference than LLMs, they cannot achieve sufficient performance. Additionally, these LLM-based systems lack native visual capabilities, limiting their applicability in multimodal contexts. In this paper, we introduce (i) MemLoRA, a novel memory system that enables local deployment by equipping SLMs with specialized memory adapters, and (ii) its vision extension MemLoRA-V, which integrates small Vision-Language Models (SVLMs) to memory systems, enabling native visual understanding. Following knowledge distillation principles, each adapter is trained separately for specific memory operations$\\unicode{x2013}$knowledge extraction, memory update, and memory-augmented generation. Equipped with memory adapters, small models enable accurate on-device memory operations without cloud dependency. On text-only operations, MemLoRA outperforms 10$\\times$ larger baseline models (e.g., Gemma2-27B) and achieves performance comparable to 60$\\times$ larger models (e.g., GPT-OSS-120B) on the LoCoMo benchmark. To evaluate visual understanding operations instead, we extend LoCoMo with challenging Visual Question Answering tasks that require direct visual reasoning. On this, our VLM-integrated MemLoRA-V shows massive improvements over caption-based approaches (81.3 vs. 23.7 accuracy) while keeping strong performance in text-based tasks, demonstrating the efficacy of our method in multimodal contexts.\nüì• Save to Zotero üìÑ Download PDF\nChallenging the Abilities of Large Language Models in Italian: a Community Initiative Authors: Malvina Nissim, Danilo Croce, Viviana Patti, Pierpaolo Basile, Giuseppe Attanasio, Elio Musacchio, Matteo Rinaldi, Federico Borazio, Maria Francis, Jacopo Gili, Daniel Scalena, Bego√±a Altuna, Ekhi Azurmendi, Valerio Basile, Luisa Bentivogli, Arianna Bisazza, Marianna Bolognesi, Dominique Brunato, Tommaso Caselli, Silvia Casola, Maria Cassese, Mauro Cettolo, Claudia Collacciani, Leonardo De Cosmo, Maria Pia Di Buono, Andrea Esuli, Julen Etxaniz, Chiara Ferrando, Alessia Fidelangeli, Simona Frenda, Achille Fusco, Marco Gaido, Andrea Galassi, Federico Galli, Luca Giordano, Mattia Goffetti, Itziar Gonzalez-Dios, Lorenzo Gregori, Giulia Grundler, Sandro Iannaccone, Chunyang Jiang, Moreno La Quatra, Francesca Lagioia, Soda Marem Lo, Marco Madeddu, Bernardo Magnini, Raffaele Manna, Fabio Mercorio, Paola Merlo, Arianna Muti, Vivi Nastase, Matteo Negri, Dario Onorati, Elena Palmieri, Sara Papi, Lucia Passaro, Giulia Pensa, Andrea Piergentili, Daniele Potert√¨, Giovanni Puccetti, Federico Ranaldi, Leonardo Ranaldi, Andrea Amelio Ravelli, Martina Rosola, Elena Sofia Ruzzetti, Giuseppe Samo, Andrea Santilli, Piera Santin, Gabriele Sarti, Giovanni Sartor, Beatrice Savoldi, Antonio Serino, Andrea Seveso, Lucia Siciliani, Paolo Torroni, Rossella Varvara, Andrea Zaninello, Asya Zanollo, Fabio Massimo Zanzotto, Kamyar Zeinalipour, Andrea Zugarini Venue: arXiv (2025)\nThe rapid progress of Large Language Models (LLMs) has transformed natural language processing and broadened its impact across research and society. Yet, systematic evaluation of these models, especially for languages beyond English, remains limited. ‚ÄúChallenging the Abilities of LAnguage Models in ITAlian‚Äù (CALAMITA) is a large-scale collaborative benchmarking initiative for Italian, coordinated under the Italian Association for Computational Linguistics. Unlike existing efforts that focus on leaderboards, CALAMITA foregrounds methodology: it federates more than 80 contributors from academia, industry, and the public sector to design, document, and evaluate a diverse collection of tasks, covering linguistic competence, commonsense reasoning, factual consistency, fairness, summarization, translation, and code generation. Through this process, we not only assembled a benchmark of over 20 tasks and almost 100 subtasks, but also established a centralized evaluation pipeline that supports heterogeneous datasets and metrics. We report results for four open-weight LLMs, highlighting systematic strengths and weaknesses across abilities, as well as challenges in task-specific evaluation. Beyond quantitative results, CALAMITA exposes methodological lessons: the necessity of fine-grained, task-representative metrics, the importance of harmonized pipelines, and the benefits and limitations of broad community engagement. CALAMITA is conceived as a rolling benchmark, enabling continuous integration of new tasks and models. This makes it both a resource ‚Äì the most comprehensive and diverse benchmark for Italian to date ‚Äì and a framework for sustainable, community-driven evaluation. We argue that this combination offers a blueprint for other languages and communities seeking inclusive and rigorous LLM evaluation practices.\nüì• Save to Zotero üìÑ Download PDF\nTyping Fallback Functions: A Semantic Approach to Type Safe Smart Contracts Authors: Stian Lybech, Daniele Gorla, Luca Aceto Venue: arXiv (2025)\nThis paper develops semantic typing in a smart-contract setting to ensure type safety of code that uses statically untypable language constructs, such as the fallback function. The idea is that the creator of a contract on the blockchain equips code containing such constructs with a formal proof of its type safety, given in terms of the semantics of types. Then, a user of the contract only needs to check the validity of the provided `proof certificate‚Äô of type safety. This is a form of proof-carrying code, which naturally fits with the immutable nature of the blockchain environment. As a concrete application of our approach, we focus on ensuring information flow control and non-interference for the language TINYSOL, a distilled version of the Solidity language, through security types. We provide the semantics of types in terms of a typed operational semantics of TINYSOL, and a way for expressing the proofs of safety as coinductively-defined typing interpretations and for representing them compactly via up-to techniques, similar to those used for bisimilarity. We also show how our machinery can be used to type the typical pointer-to-implementation pattern based on the fallback function. However, our main contribution is not the safety theorem per se (and so security properties different from non-interference can be considered as well), but rather the presentation of the theoretical developments necessary to make this approach work in a blockchain/smart-contract setting.\nüì• Save to Zotero üìÑ Download PDF\nEtCon: Edit-then-Consolidate for Reliable Knowledge Editing Authors: Ruilin Li, Yibin Wang, Wenhong Zhu, Chenglin Li, Jinghao Zhang, Chenliang Li, Junchi Yan, Jiaqi Wang Venue: arXiv (2025)\nKnowledge editing aims to update specific facts in large language models (LLMs) without full retraining. Prior efforts sought to tune the knowledge layers of LLMs, proving effective for making selective edits. However, a significant gap exists between their performance in controlled, teacher-forcing evaluations and their real-world effectiveness in lifelong learning scenarios, which greatly limits their practical applicability. This work‚Äôs empirical analysis reveals two recurring issues associated with this gap: (1) Most traditional methods lead the edited model to overfit to the new fact, thereby degrading pre-trained capabilities; (2) There is a critical absence of a knowledge consolidation stage, leaving new facts insufficiently integrated into LLMs‚Äô inference-time behavior under autoregressive generation, thereby leading to a mismatch between parametric knowledge and actual generation behavior. To this end, we propose Edit-then-Consolidate, a novel knowledge editing paradigm that aims to bridge the gap between theoretical knowledge editing methods and their real-world applicability. Specifically, (1) our framework mitigates overfitting via Targeted Proximal Supervised Fine-Tuning (TPSFT) that localizes the edit via a trust-region objective to limit policy drift; (2) Then, a consolidation stage using Group Relative Policy Optimization (GRPO) aligns the edited knowledge with CoT-based inference policy by optimizing trajectory-level behavior under comprehensive reward signals. Extensive experiments demonstrate our framework consistently improves editing reliability and generalization under real-world evaluations, while better preserving locality and pre-trained capabilities.\nüì• Save to Zotero üìÑ Download PDF\nRLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting Authors: Siqi Wang, Hailong Yang, Junjie Zhu, Xuezhu Wang, Yufan Xu, Depei Qian Venue: arXiv (2025)\nReinforcement Learning from Human Feedback (RLHF) is an important fine-tuning technique for large language models (LLMs) and comprises three stages: generation, inference, and training. The generation stage generates samples that are then used to infer learnable experiences for training. We observe that the generation stage is the bottleneck of the entire execution process and consider it a key point for optimization. Specifically, we realize the first attempt to integrate speculative decoding into the RLHF generation stage and propose RLHFSpec, an RLHF system that accelerates generation execution with adaptive speculative decoding and sample reallocation. To fully exploit the performance potential provided by speculative decoding, especially dealing with the dynamic workload of the generation stage, RLHFSpec proposes a workload-aware drafting strategy selection mechanism, which selects the near-optimal strategy by jointly considering the verification cost and the number of accepted tokens. Moreover, RLHFSpec also proposes sample reallocation to fully utilize the GPU resources, and optimizes it with an efficient sample migration mechanism. The experimental results show that the RLHFSpec can achieve higher throughput in the generation stage compared to state-of-the-art works. Moreover, due to the effective alleviation of the generation bottleneck, RLHFSpec also shows significant performance speedup in the entire RLHF execution.\nüì• Save to Zotero üìÑ Download PDF\nModel Whisper: Steering Vectors Unlock Large Language Models‚Äô Potential in Test-time Authors: Xinyue Kang, Diwei Shi, Li Chen Venue: arXiv (2025)\nIt is a critical challenge to efficiently unlock the powerful reasoning potential of Large Language Models (LLMs) for specific tasks or new distributions. Existing test-time adaptation methods often require tuning model parameters, which is not only computationally expensive but also risks degrading the model‚Äôs pre-existing abilities.To address this, we introduce a lightweight component, Test-Time Steering Vectors (TTSV), which is prepended to the input while keeping the LLM‚Äôs parameters entirely frozen. By optimizing the TTSV on test data to minimize the model‚Äôs output entropy, we steer the model towards an internal state of higher confidence, activating its inherent abilities most relevant to the current task. TTSV is both lightweight and highly efficient to optimize, making it a true plug-and-play enhancement. Extensive experiments validate our approach‚Äôs effectiveness on both base models and reasoning-enhanced models. For instance, on the MATH500 task, TTSV achieves a 45.88% relative performance gain on the Qwen2.5-Math-7B model and a 16.22% relative gain on the Qwen3-4B model. Furthermore, our approach exhibits robust generalization, with its steering vectors proving highly transferable across diverse tasks.\nüì• Save to Zotero üìÑ Download PDF\nSignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs Authors: Wenhua Cheng, Weiwei Zhang, Heng Guo, Haihao Shen Venue: arXiv (2025)\nExtreme low-bit quantization is critical for efficiently deploying Large Language Models (LLMs), yet it often leads to severe performance degradation at 2-bits and even 4-bits (e.g., MXFP4). We present SignRoundV2, a post-training quantization framework that is highly effective even without mixed-precision. SignRoundV2 introduces (1) a fast sensitivity metric that combines gradient information with quantization-induced deviations to guide layer-wise bit allocation, and (2) a lightweight pre-tuning search for quantization scales to improve extremely low-bit quantization. These components allow SignRoundV2 to close the gap with full-precision models. Extensive experiments indicate that our method sustains competitive accuracy for LLMs, achieving production-grade performance with about 1 percent variance at 4-5 bits and strong results even at 2 bits. The implementation is available at https://github.com/intel/auto-round.\nüì• Save to Zotero üìÑ Download PDF\nOsmT: Bridging OpenStreetMap Queries and Natural Language with Open-source Tag-aware Language Models Authors: Zhuoyue Wan, Wentao Hu, Chen Jason Zhang, Yuanfeng Song, Shuaimin Li, Ruiqiang Xiao, Xiao-Yong Wei, Raymond Chi-Wing Wong Venue: arXiv (2025)\nBridging natural language and structured query languages is a long-standing challenge in the database community. While recent advances in language models have shown promise in this direction, existing solutions often rely on large-scale closed-source models that suffer from high inference costs, limited transparency, and lack of adaptability for lightweight deployment. In this paper, we present OsmT, an open-source tag-aware language model specifically designed to bridge natural language and Overpass Query Language (OverpassQL), a structured query language for accessing large-scale OpenStreetMap (OSM) data. To enhance the accuracy and structural validity of generated queries, we introduce a Tag Retrieval Augmentation (TRA) mechanism that incorporates contextually relevant tag knowledge into the generation process. This mechanism is designed to capture the hierarchical and relational dependencies present in the OSM database, addressing the topological complexity inherent in geospatial query formulation. In addition, we define a reverse task, OverpassQL-to-Text, which translates structured queries into natural language explanations to support query interpretation and improve user accessibility. We evaluate OsmT on a public benchmark against strong baselines and observe consistent improvements in both query generation and interpretation. Despite using significantly fewer parameters, our model achieves competitive accuracy, demonstrating the effectiveness of open-source pre-trained language models in bridging natural language and structured query languages within schema-rich geospatial environments.\nüì• Save to Zotero üìÑ Download PDF\nE3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving Authors: Yihong Tang, Haicheng Liao, Tong Nie, Junlin He, Ao Qu, Kehua Chen, Wei Ma, Zhenning Li, Lijun Sun, Chengzhong Xu Venue: arXiv (2025)\nEnd-to-end autonomous driving (AD) systems increasingly adopt vision-language-action (VLA) models, yet they typically ignore the passenger‚Äôs emotional state, which is central to comfort and AD acceptance. We introduce Open-Domain End-to-End (OD-E2E) autonomous driving, where an autonomous vehicle (AV) must interpret free-form natural-language commands, infer the emotion, and plan a physically feasible trajectory. We propose E3AD, an emotion-aware VLA framework that augments semantic understanding with two cognitively inspired components: a continuous Valenc-Arousal-Dominance (VAD) emotion model that captures tone and urgency from language, and a dual-pathway spatial reasoning module that fuses egocentric and allocentric views for human-like spatial cognition. A consistency-oriented training scheme, combining modality pretraining with preference-based alignment, further enforces coherence between emotional intent and driving actions. Across real-world datasets, E3AD improves visual grounding and waypoint planning and achieves state-of-the-art (SOTA) VAD correlation for emotion estimation. These results show that injecting emotion into VLA-style driving yields more human-aligned grounding, planning, and human-centric feedback.\nüì• Save to Zotero üìÑ Download PDF\nThe Universal Weight Subspace Hypothesis Authors: Prakhar Kaushik, Shravan Chaudhari, Ankit Vaidya, Rama Chellappa, Alan Yuille Venue: arXiv (2025)\nWe show that deep neural networks trained across diverse tasks exhibit remarkably similar low-dimensional parametric subspaces. We provide the first large-scale empirical evidence that demonstrates that neural networks systematically converge to shared spectral subspaces regardless of initialization, task, or domain. Through mode-wise spectral analysis of over 1100 models - including 500 Mistral-7B LoRAs, 500 Vision Transformers, and 50 LLaMA-8B models - we identify universal subspaces capturing majority variance in just a few principal directions. By applying spectral decomposition techniques to the weight matrices of various architectures trained on a wide range of tasks and datasets, we identify sparse, joint subspaces that are consistently exploited, within shared architectures across diverse tasks and datasets. Our findings offer new insights into the intrinsic organization of information within deep networks and raise important questions about the possibility of discovering these universal subspaces without the need for extensive data and computational resources. Furthermore, this inherent structure has significant implications for model reusability, multi-task learning, model merging, and the development of training and inference-efficient algorithms, potentially reducing the carbon footprint of large-scale neural models.\nüì• Save to Zotero üìÑ Download PDF\nSDG-Track: A Heterogeneous Observer-Follower Framework for High-Resolution UAV Tracking on Embedded Platforms Authors: Jiawen Wen, Yu Hu, Suixuan Qiu, Jinshan Huang, Xiaowen Chu Venue: arXiv (2025)\nReal-time tracking of small unmanned aerial vehicles (UAVs) on edge devices faces a fundamental resolution-speed conflict. Downsampling high-resolution imagery to standard detector input sizes causes small target features to collapse below detectable thresholds. Yet processing native 1080p frames on resource-constrained platforms yields insufficient throughput for smooth gimbal control. We propose SDG-Track, a Sparse Detection-Guided Tracker that adopts an Observer-Follower architecture to reconcile this conflict. The Observer stream runs a high-capacity detector at low frequency on the GPU to provide accurate position anchors from 1920x1080 frames. The Follower stream performs high-frequency trajectory interpolation via ROI-constrained sparse optical flow on the CPU. To handle tracking failures from occlusion or model drift caused by spectrally similar distractors, we introduce Dual-Space Recovery, a training-free re-acquisition mechanism combining color histogram matching with geometric consistency constraints. Experiments on a ground-to-air tracking station demonstrate that SDG-Track achieves 35.1 FPS system throughput while retaining 97.2% of the frame-by-frame detection precision. The system successfully tracks agile FPV drones under real-world operational conditions on an NVIDIA Jetson Orin Nano. Our paper code is publicly available at https://github.com/Jeffry-wen/SDG-Track\nüì• Save to Zotero üìÑ Download PDF\nA Novel Trust-Based DDoS Cyberattack Detection Model for Smart Business Environments Authors: Oghenetejiri Okporokpo, Funminiyi Olajide, Nemitari Ajienka, Xiaoqi Ma Venue: arXiv (2025)\nAs the frequency and complexity of Distributed Denial-of-Service (DDoS) attacks continue to increase, the level of threats posed to Smart Internet of Things (SIoT) business environments have also increased. These environments generally have several interconnected SIoT systems and devices that are integral to daily operations, usually depending on cloud infrastructure and real-time data analytics, which require continuous availability and secure data exchange. Conventional detection mechanisms, while useful in static or traditional network environments, often are inadequate in responding to the needs of these dynamic and diverse SIoT networks. In this paper, we introduce a novel trust-based DDoS detection model tailored to meet the unique requirements of smart business environments. The proposed model incorporates a trust evaluation engine that continuously monitors node behaviour, calculating trust scores based on packet delivery ratio, response time, and anomaly detection. These trust metrics are then aggregated by a central trust-based repository that uses inherent trust values to identify traffic patterns indicative of DDoS attacks. By integrating both trust scores and central trust-based outputs, the trust calculation is enhanced, ensuring that threats are accurately identified and addressed in real-time. The model demonstrated a significant improvement in detection accuracy, and a low false-positive rate with enhanced scalability and adaptability under TCP SYN, Ping Flood, and UDP Flood attacks. The results show that a trust-based approach provides an effective, lightweight alternative for securing resource-constrained business IoT environments.\nüì• Save to Zotero üìÑ Download PDF\nBreaking the bandwidth-efficiency trade-off in soliton microcombs via mode coupling Authors: Yang Liu, Andreas Jacobsen, Thibault Wildi, Yanjing Zhao, Chaochao Ye, Yi Zheng, Camiel Op de Beeck, Jos√© Carreira, Michael Geiselmann, Kresten Yvind, Tobias Herr, Minhao Pu Venue: arXiv (2025)\nDissipative Kerr solitons in optical microresonators have emerged as a powerful tool for compact and coherent frequency comb generation. Advances in nanofabrication have allowed precise dispersion engineering, unlocking octave-spanning soliton combs that are essential for applications such as optical atomic clocks, frequency synthesis, precision spectroscopy, and astronomical spectrometer calibration. However, a key challenge hindering their practical deployment is the intrinsic bandwidth-efficiency trade-off: achieving broadband soliton generation requires large pump detuning, which suppresses power coupling and limits pump-to-comb conversion efficiencies to only a few percent. Recent efforts using pulsed pumping or coupled-resonator architectures have improved efficiency to several tens of percent, yet their bandwidths remain below one-tenth of an octave, inadequate for applications demanding wide spectral coverage. Here, we overcome this limitation by harnessing mode interactions between spatial modes within a single microresonator. The mode hybridization creates an additional power-transfer channel that supports large pump detuning while maintaining strong pump-to-resonator coupling, enabling broadband soliton formation at substantially reduced pump power. Using this approach, we demonstrate an octave-spanning soliton microcomb with a record pump-to-comb conversion efficiency exceeding 50%. These results resolve the fundamental bandwidth-efficiency dilemma in soliton microcombs and paves the way toward fully-integrated, high-efficiency, ultrabroad comb sources for next-generation photonic systems.\nüì• Save to Zotero üìÑ Download PDF\nAnisotropic Response in Metamaterials with Elliptically Perforated Plates: Applications to Near-Field Radiative Heat Transfer Authors: J. E. P‚Äôerez-Rodr‚Äôiguez, R. Esquivel-Sirvent, A. Camacho de la Rosa Venue: arXiv (2025)\nMetamaterials with tunable optical properties provide a versatile platform for controlling electromagnetic interactions at the nanoscale. This study explores the anisotropic thermal behavior of metamaterials composed of planar plates perforated with periodic arrays of cylinders possessing elliptical cross sections. In contrast to conventional circular perforations, elliptical geometries inherently break rotational symmetry, introducing anisotropy in the effective electromagnetic and thermal response of the structure. Using a fluctuation electrodynamics framework combined with full-wave numerical simulations, we quantify the near-field radiative heat transfer between such elliptically perforated plates as a function of ellipse orientation, aspect ratio, and separation distance. The results reveal that elliptical perforations enable enhanced spectral and directional control of evanescent mode coupling and surface polariton excitation, leading to significant modulation of the near-field heat flux. These findings highlight the potential of geometrically engineered anisotropy for advanced thermal management and energy conversion applications, and offer new design strategies for the development of thermally functional metamaterials operating in the near-field regime.\nüì• Save to Zotero üìÑ Download PDF\nMeta-Learning for Quantum Optimization via Quantum Sequence Model Authors: Yu-Cheng Lin, Yu-Chao Hsu, Samuel Yen-Chi Chen Venue: arXiv (2025)\nThe Quantum Approximate Optimization Algorithm (QAOA) is a leading approach for solving combinatorial optimization problems on near-term quantum processors. However, finding good variational parameters remains a significant challenge due to the non-convex energy landscape, often resulting in slow convergence and poor solution quality. In this work, we propose a quantum meta-learning framework that trains advanced quantum sequence models to generate effective parameter initialization policies. We investigate four classical or quantum sequence models, including the Quantum Kernel-based Long Short-Term Memory (QK-LSTM), as learned optimizers in a ‚Äúlearning to learn‚Äù paradigm. Our numerical experiments on the Max-Cut problem demonstrate that the QK-LSTM optimizer achieves superior performance, obtaining the highest approximation ratios and exhibiting the fastest convergence rate across all tested problem sizes (n=10 to 13). Crucially, the QK-LSTM model achieves perfect parameter transferability by synthesizing a single, fixed set of near-optimal parameters, leading to a remarkable sustained acceleration of convergence even when generalizing to larger problems. This capability, enabled by the compact and expressive power of the quantum kernel architecture, underscores its effectiveness. The QK-LSTM, with only 43 trainable parameters, substantially outperforms the classical LSTM (56 parameters) and other quantum sequence models, establishing a robust pathway toward highly efficient parameter initialization for variational quantum algorithms in the NISQ era.\nüì• Save to Zotero üìÑ Download PDF\nSome computations in the heart of the homotopy t-structure on logarithmic motives Authors: Alberto Merici Venue: arXiv (2025)\nIn this note we will illustrate a method for computing the $œÄ_0$ of the effective log motive of a smooth and proper variety over a perfect field $k$ and show that it is $\\A^1$-invariant. We will apply this to compute the first homotopy groups of $¬∂^1$ to show that the stripping functor from log motivic sheaves to (usual) Nisnevich sheaves with transfers is fully faithful.\nüì• Save to Zotero üìÑ Download PDF\nRAMEN: Resolution-Adjustable Multimodal Encoder for Earth Observation Authors: Nicolas Houdr√©, Diego Marcos, Hugo Riffaud de Turckheim, Dino Ienco, Laurent Wendling, Camille Kurtz, Sylvain Lobry Venue: arXiv (2025)\nEarth observation (EO) data spans a wide range of spatial, spectral, and temporal resolutions, from high-resolution optical imagery to low resolution multispectral products or radar time series. While recent foundation models have improved multimodal integration for learning meaningful representations, they often expect fixed input resolutions or are based on sensor-specific encoders limiting generalization across heterogeneous EO modalities. To overcome these limitations we introduce RAMEN, a resolution-adjustable multimodal encoder that learns a shared visual representation across EO data in a fully sensor-agnostic manner. RAMEN treats the modality and spatial and temporal resolutions as key input data features, enabling coherent analysis across modalities within a unified latent space. Its main methodological contribution is to define spatial resolution as a controllable output parameter, giving users direct control over the desired level of detail at inference and allowing explicit trade-offs between spatial precision and computational cost. We train a single, unified transformer encoder reconstructing masked multimodal EO data drawn from diverse sources, ensuring generalization across sensors and resolutions. Once pretrained, RAMEN transfers effectively to both known and unseen sensor configurations and outperforms larger state-of-the-art models on the community-standard PANGAEA benchmark, containing various multi-sensor and multi-resolution downstream tasks. Our code and pretrained model are available at https://github.com/nicolashoudre/RAMEN.\nüì• Save to Zotero üìÑ Download PDF\nSchwarzschild Black Hole Turbulence: Scalar Probe Authors: Alex Kehagias, Antonio Riotto Venue: arXiv (2025)\nWe explore how perturbations of a Schwarzschild black hole can redistribute energy among scalar modes and seed turbulent like cascades. We make use of the van der Pol-Krylov-Bogoliubov averaging method and derive coupled mode equations that describe near-resonant interactions between neighbouring multipoles. We compare two routes to instability, namely the difference-frequency mixing between adjacent modes and the diagonal (Mathieu) self-modulation channel. We show that, at high multipole number (eikonal limit), the difference-frequency route dominates and drives a one-way cascade from higher to lower frequencies. We chart the corresponding instability regions (‚Äútongues‚Äù) and quantify their detuning dependence. The framework provides a simple, quantitative mechanism for energy transfer in black hole ringdowns and clarifies when and how turbulent signatures can arise within linear probes on a weakly perturbed background.\nüì• Save to Zotero üìÑ Download PDF\nSuppressing metal molecule charge transfer with a phosphorus interlayer Authors: Mattia Bassotti, Luca Floreano, Luca Schio, Sergio Salaverria, Dimas G. de Oteyza, Giacomo Giorgi, Frederik Schiller, Alberto Verdini Venue: arXiv (2025)\nPorphyrins are organic molecules that exhibit excellent opto-electronics properties, making them suitable for a variety of applications. Nevertheless, their functionality strongly depends on the surface onto which they are deposited, and on the interaction between the molecules and the substrate itself, which often leads to an undesired alteration in their electronic properties. In this study, we use a phosphorus interlayer on a Cu(110) surface as a buffer layer for the electronic decoupling of Zinc-TetraPhenylPorphyrin (ZnTPP) molecules. Using a combination of complementary techniques, such as Near Edge X-ray Absorption Fine Structure (NEXAFS), X-ray and Ultraviolet Photoemission Spectroscopy (XPS, UPS) as well as Scanning Tunneling Spectroscopy (STS) techniques, it is shown how the charge transfer from the metal, responsible for quenching the ZnTPP lowest unoccupied molecular level (LUMO) levels, is effectively prevented by the presence of a phosphorus reconstruction in between.\nüì• Save to Zotero üìÑ Download PDF\nIntroducing V-Soft Pro: a Modular Platform for a Transhumeral Prosthesis with Controllable Stiffness Authors: Giuseppe Milazzo, Giorgio Grioli, Antonio Bicchi, Manuel G. Catalano Venue: arXiv (2025)\nCurrent upper limb prostheses aim to enhance user independence in daily activities by incorporating basic motor functions. However, they fall short of replicating the natural movement and interaction capabilities of the human arm. In contrast, human limbs leverage intrinsic compliance and actively modulate joint stiffness, enabling adaptive responses to varying tasks, impact absorption, and efficient energy transfer during dynamic actions. Inspired by this adaptability, we developed a transhumeral prosthesis with Variable Stiffness Actuators (VSAs) to replicate the controllable compliance found in biological joints. The proposed prosthesis features a modular design, allowing customization for different residual limb shapes and accommodating a range of independent control signals derived from users‚Äô biological cues. Integrated elastic elements passively support more natural movements, facilitate safe interactions with the environment, and adapt to diverse task requirements. This paper presents a comprehensive overview of the platform and its functionalities, highlighting its potential applications in the field of prosthetics.\nüì• Save to Zotero üìÑ Download PDF\nOperator Formalism for Laser-Plasma Wakefield Acceleration Authors: Mostafa Behtouei, Carlos Salgado Lopez, Giancarlo Gatti Venue: arXiv (2025)\nIn this paper, we develop an operator-based framework for laser‚Äìplasma wakefield acceleration (LPWA) in capillary discharges, providing a compact and systematic description of the coupled dynamics of laser fields and plasma response. The formalism employs key operators: the transverse modal operator $\\hat{K}$, the nonlinear plasma operator $\\hat{N}[Œ®]$, the plasma oscillation operator $\\hatŒ©_p^{,2}$, and the ponderomotive source operator $\\hatŒ±$, which together describe mode coupling, plasma oscillations, and nonlinear feedback induced by the ponderomotive force. In the linear regime, the system is characterized by invariant subspaces associated with stable modal structures, while nonlinear interactions break these invariances, leading to mode mixing and complex dynamics. The approach establishes a direct connection between LPWA and Hilbert-space operator theory, including the invariant subspace, providing a formal mathematical interpretation of energy transfer and wakefield formation. Furthermore, the operator formalism integrates with neural operator methods, allowing efficient approximation of $\\hat{N}$ and $\\hatŒ±$ for reduced-order modeling and predictive control. This hybrid physics‚ÄìAI framework offers a robust foundation for modeling, analysis, and optimization of high-intensity laser‚Äìplasma interactions in next-generation accelerator experiments.\nüì• Save to Zotero üìÑ Download PDF\nHybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies Authors: Jonne Van Haastregt, Bastian Orthmann, Michael C. Welle, Yuchong Zhang, Danica Kragic Venue: arXiv (2025)\nDespite the fact that visuomotor-based policies obtained via imitation learning demonstrate good performances in complex manipulation tasks, they usually struggle to achieve the same accuracy and speed as traditional control based methods. In this work, we introduce Hybrid-Diffusion models that combine open-loop routines with visuomotor diffusion policies. We develop Teleoperation Augmentation Primitives (TAPs) that allow the operator to perform predefined routines, such as locking specific axes, moving to perching waypoints, or triggering task-specific routines seamlessly during demonstrations. Our Hybrid-Diffusion method learns to trigger such TAPs during inference. We validate the method on challenging real-world tasks: Vial Aspiration, Open-Container Liquid Transfer, and container unscrewing. All experimental videos are available on the project‚Äôs website: https://hybriddiffusion.github.io/\nüì• Save to Zotero üìÑ Download PDF\nCrack detection by holomorphic neural networks and transfer-learning-enhanced genetic optimization Authors: Jonas Hund, Nicolas Cuenca, Tito Andriollo Venue: arXiv (2025)\nA new strategy for detecting cracks in 2D solids based on strain data is introduced. Crack detection is formulated as an inverse problem and solved using genetic optimization. The novelty lies in the evaluation of the model response at each generation. Specifically, the solution to the corresponding plane elasticity problem is expressed via holomorphic potentials, which are determined by training two holomorphic neural networks. As the potentials satisfy equilibrium and traction-free conditions along the crack faces a priori, the training proceeds quickly based solely on boundary information. Training efficiency is further improved by splitting the genetic search into long-range and short-range stages, enabling the use of transfer learning in the latter. The new strategy is tested on three benchmark problems, showing that an optimal number of training epochs exists that provides the best overall performance. A comparison is also made with a popular crack detection approach that uses XFEM to compute the model response. Under the assumption of identical stress-field representation accuracy, the proposed method is found to be between 7 and 23 times faster than the XFEM-based approach. While the strategy is presented here for the simplified case of a single internal crack, generalization is feasible. Overall, the present findings demonstrate that combining genetic optimization with holomorphic neural networks and transfer learning offers a promising avenue for developing crack detection strategies with higher efficiency than those currently available.\nüì• Save to Zotero üìÑ Download PDF\nTuning the Electronic States of Bi2Se3 Films with Large Spin-Orbit Interaction Using Molecular Heterojunctions Authors: Matthew Rogers, Craig Knox, Bryan Hickey, Lida Ansari, Farzan Gity, Timothy Moorsom, Mairi McCauley, Gilberto Teobaldi, Manuel dos Santos Dias, Hari B. Vasili, Manuel Valvidares, Mannan Ali, Gavin Burnell, Ahmet Yagmur, Satoshi Sasaki, Oscar Cespedes Venue: arXiv (2025)\nAn electric bias can shift the Fermi level along the Dirac cone of a topological insulator and modify its charge transport, but tuning the electronic states and spin-orbit interaction (SOI) without destroying the surface topology is challenging. Here, we show that thin film Bi2Se3/n-p (p-n) molecular diodes form ordered interfaces where charge transfer and orbital re-hybridisation result in a decrease (increase) of the carrier density and improved mobility. In Bi2Se3 the spin-orbit lifetime, t_so, is 0.13 ps, which is comparable to the strongest spin-orbit materials. This lifetime drops further to 0.06 ps (0.09 ps) with the addition of p-n (n-p) molecular diodes, at the limit of measurable values. This strengthened spin-orbit interaction occurs even though molecules are made of light elements and increase the mean free path of the charge carriers by almost 50%, indicating changes to the Berry curvature and/or Rashba splitting around the hybridisation points. Raman spectroscopy gives evidence that the coupling effect may be controlled by optical irradiation, opening a pathway towards the design of heavy-light element hybrids with optically tunable quantum transport.\nüì• Save to Zotero üìÑ Download PDF\nHoi! ‚Äì A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation Authors: Tim Engelbracht, Ren√© Zurbr√ºgg, Matteo Wohlrapp, Martin B√ºchner, Abhinav Valada, Marc Pollefeys, Hermann Blum, Zuria Bauer Venue: arXiv (2025)\nWe present a dataset for force-grounded, cross-view articulated manipulation that couples what is seen with what is done and what is felt during real human interaction. The dataset contains 3048 sequences across 381 articulated objects in 38 environments. Each object is operated under four embodiments - (i) human hand, (ii) human hand with a wrist-mounted camera, (iii) handheld UMI gripper, and (iv) a custom Hoi! gripper - where the tool embodiment provides synchronized end-effector forces and tactile sensing. Our dataset offers a holistic view of interaction understanding from video, enabling researchers to evaluate how well methods transfer between human and robotic viewpoints, but also investigate underexplored modalities such as force sensing and prediction.\nüì• Save to Zotero üìÑ Download PDF\nInterfacial Synergy in Ag-Doped CuO-AgCl-g-C3N4 Composites for Efficient Charge Separation and Low-power Methylene Blue Degradation Authors: Suresh Chandra Baral, Uttama Kumar Saint, Dilip Sasmal, Sradhanjali Lenka, Ashish Kalkal, A. Mekki, Sudhagar Pitchaimuthu, Somaditya Sen Venue: arXiv (2025)\nAn Ag-doped CuO-AgCl-g-C3N4 heterostructure has been designed to achieve rapid Methylene Blue (MB) degradation through a synergistic photo-Fenton mechanism driven by low-power UV illumination. The composite integrates narrow-bandgap CuO, plasmonic Ag/AgCl, and visible-responsive g-C3N4 into a dual Z-scheme configuration that promotes efficient interfacial charge transfer while preserving strong redox potentials. Diffuse reflectance UV-Vis spectra ascertained the bandgap positions of the composite corresponding to those of its constituents: 2.9 eV (g-C3N4) and 1.42 eV (Ag-doped CuO-AgCl), indicating enhanced absorption and efficient charge carrier generation. BET analysis confirmed the presence of mesoporosity and revealed an effective surface area, ensuring the availability of abundant adsorption and reaction sites. A commercial 11 W UV irradiation was used for the photocatalytic test. Almost complete degradation of MB occurred within 10 min, following pseudo-first-order kinetics with a high apparent rate constant of 0.45/min. The remarkable activity arises from the synergistic interplay of Fenton-like redox cycling and efficient photoinduced charge carrier generation and separation. In addition, it has been demonstrated that intentionally incorporated AgCl plays an active role as a plasmonic-semiconducting interface, strengthening charge separation and catalyst stability under neutral conditions, rather than acting as a passive chloride byproduct. Overall, by linking defect engineering, heterojunction design, and photo-Fenton synergy, this study establishes a low-power, catalytic platform offering a viable pathway towards sustainable dye wastewater remediation.\nüì• Save to Zotero üìÑ Download PDF\nFormation of the Dormant Black Holes with Luminous Companions from Binary or Triple Systems Authors: Zhuowen Li, Xizhen Lu, Guoliang L√º, Chunhua Zhu, Helei Liu, Li Lei, Sufen Guo, Xiaolong He, Nurzada Beissen Venue: arXiv (2025)\nRecently, a class of dormant black hole binaries with luminous companions (dBH-LC) has been observed, such as $Gaia$ BH1, BH2, and BH3. Unlike previously discovered X-ray BH binaries, this type of dBH-LC has relatively long orbital periods (typically more than several tens to a few hundred days) and shows very weak X-ray emission. Therefore, studying the formation and evolution of the whole dBH-LC population is also a very interesting problem. Our aim is to study the contribution of massive stars to the dBH-LC population under different evolutionary models (isolated binary evolution (IBE) and hierarchical triple evolution), and different formation channels (such as mass transfer, common envelope evolution). Using the Massive Objects in Binary Stellar Evolution (MOBSE) code, the Triple Stellar Evolution (TSE) code, and the latest initial multiple-star distributions, we model the populations of massive stars. Finally, we calculate the orbital properties, mass distributions, and birthrates of the BH-LC populations formed under these different conditions. In the Milky Way, we calculate that the birthrate of dBH-LC formed through IBE is about 4.35$\\times$$10^{-5}$ ${\\rm yr}^{-1}$, while the birthrate through triple evolution is about 1.47$\\times$$10^{-3}$ ${\\rm yr}^{-1}$. This means that the birthrate from triple evolution is one to two orders of magnitude higher than that from IBE. We find that in triple evolution, the main formation channel of dBH-LC is post-merger binaries formed from inner binary mergers triggered by von Zeipel$-$Lidov$-$Kozai oscillations.\nüì• Save to Zotero üìÑ Download PDF\nMaehara Interpolation in Extensions of R-mingle Authors: Wesley Fussner, Krzysztof Krawczyk Venue: arXiv (2025)\nWe show that there are exactly five quasivarieties of Sugihara algebras with the amalgamation property, and that all of these have the relative congruence extension property. As a consequence, we obtain that the amalgamation property and transferable injections property coincide for arbitrary quasivarieties of Sugihara algebras. These results provide a complete description of arbitrary (not merely axiomatic) extensions of the logic R-mingle that have the Maehara interpolation property, and further demonstrates that the Robinson property and Maehara interpolation property coincide for arbitrary extensions of R-mingle. Further, we show that the question of whether a given finitely based extension of R-mingle has the Maehara interpolation property is decidable.\nüì• Save to Zotero üìÑ Download PDF\nEvolution of Correlated Electrons in ${\\rm La_3Ni_2O_7}$ at Ambient Pressure: a Study of Double-Counting Effect Authors: Zhong-Yi Xie, Zhihui Luo, W√©i W√∫, Dao-Xin Yao Venue: arXiv (2025)\nWe employ cluster extension of dynamical mean-field theory (CDMFT) to systematically investigate the impact of double counting corrections on the correlated electronic structure of ${\\rm La_3Ni_2O_7}$ under ambient pressure. By adjusting double-counting parameters, while maintaining a fixed Fermi surface, we observe a pronounced orbital-selective density of states change: the $d_{z^2}$ orbital undergoes significant variation near the Fermi level with increasing $E_{dc}^z$, while the $d_{x^2-y^2}$ orbital remains essentially unchanged throughout the entire range. Analysis of renormalization factor show the monotonic dependence with double counting in both $d_{z^2}$ and $d_{x^2-y^2}$ orbital, and it also identifies an optimal double counting window in $d_{z^2}$ orbital aligns with experimental values. We also find the interlayer Matsubara self energy exhibits non-monotonic dependence on $E_{dc}^z$, deviating from theoretical predictions. This anomaly is attributed to the metallization of oxygen-bridged pathways, which disrupts the prerequisite for charge transfer via apical oxygen. Our results establish $E_{dc}$ as a critical control parameter for correlated electronic structure in ${\\rm La_3Ni_2O_7}$ and provide a computational framework for resolving orbital-dependent correlation effects in layered materials.\nüì• Save to Zotero üìÑ Download PDF\nALMA-QUARKS: Few-Thousand-Year Hatching out of ‚ÄúEgg‚Äù: The Supersonic Breakout of a Hypercompact H II Region from Its Parental Hot Core Authors: Siju Zhang, Guido Garay, Fengwei Xu, Luis F. Rodr√≠guez, Neal J. Evans, Annie Zavagno, Paul F. Goldsmith, Dongting Yang, Xunchuan Liu, Aiyuan Yang, Tie Liu, Amelia M. Stutz, Hong-Li Liu, Wenyu Jiao, Anandmayee Tej, Lei Zhu, Kee-Tae Kim, Pablo Garc√≠a, Thomas Peters, Thomas M√∂ller, Shanghuo Li, Leonardo Bronfman Venue: arXiv (2025)\nThe kinematic evolution of hypercompact H II (HC H II) regions around young high-mass stars remains poorly understood due to complex interactions with parental environs. We present ALMA QUARKS/ATOMS 1.3 mm/3 mm observations (the highest resolution $\\sim0.01$ pc) of a deeply embedded HC H II region (diameter $\\sim0.015$ pc, electron density $\\sim2\\times10^{5}$ cm$^{-3}$) exhibiting a striking $\\gtrsim20$ km s$^{-1}$ global redshift seen in optically thin H30$Œ±$/H40$Œ±$ recombination lines relative to its parental hot molecular core within a hub-filament system. The 1.3 mm continuum data reveal a distinct 0.1-pc arc and a perpendicular 0.04-pc tail. We propose that this morphology arises from a dynamic champagne flow: the slow expansion of HC H II region into a pre-existing filament forms the arc and associated low-velocity (few km s$^{-1}$) SiO shocks. Meanwhile, in the opposite direction ionized gas escapes along a steep density gradient traced by the tail and high-velocity (20 km s$^{-1}$) SiO emission. We reject the bow shock scenario in which ionized gas co-moves with a runaway high-mass star because shocked gas in the arc aligns with the hub velocity, contradicting the bow shock prediction. Non-LTE radiative transfer modeling further rules out infall of ionized gas as the velocity shift origin. We conclude that this exceptional HC H II region is undergoing a few-thousand-year transition phase of ‚Äúhatching out of the egg‚Äù: the ionized gas of HC H II region has just broken out of its parental hot core and now is flowing outward supersonically. This work highlights how anisotropic density distributions induce supersonically anisotropic ionized flows that govern HC H II region evolution.\nüì• Save to Zotero üìÑ Download PDF\nBridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting Authors: Jian Tang, Pu Pang, Haowen Sun, Chengzhong Ma, Xingyu Chen, Hua Huang, Xuguang Lan Venue: arXiv (2025)\nCross-domain transfer in robotic manipulation remains a longstanding challenge due to the significant domain gap between simulated and real-world environments. Existing methods such as domain randomization, adaptation, and sim-real calibration often require extensive tuning or fail to generalize to unseen scenarios. To address this issue, we observe that if domain-invariant features are utilized during policy training in simulation, and the same features can be extracted and provided as the input to policy during real-world deployment, the domain gap can be effectively bridged, leading to significantly improved policy generalization. Accordingly, we propose Semantic 2D Gaussian Splatting (S2GS), a novel representation method that extracts object-centric, domain-invariant spatial features. S2GS constructs multi-view 2D semantic fields and projects them into a unified 3D space via feature-level Gaussian splatting. A semantic filtering mechanism removes irrelevant background content, ensuring clean and consistent inputs for policy learning. To evaluate the effectiveness of S2GS, we adopt Diffusion Policy as the downstream learning algorithm and conduct experiments in the ManiSkill simulation environment, followed by real-world deployment. Results demonstrate that S2GS significantly improves sim-to-real transferability, maintaining high and stable task performance in real-world scenarios.\nüì• Save to Zotero üìÑ Download PDF\nBoosting the Memory Window of Memristive Stacks via Engineered Interfaces with High Ionic Mobility Authors: Jos√© Diogo Costa, Daniel Veira-Canle, Noa Varela-Dom√≠nguez, Nicholas Davey, Victor Lebor√°n, Rafael Ramos, F√®lix Casanova, Luis E. Hueso, Victor M. Brea, P. L√≥pez, Francisco Rivadulla Venue: arXiv (2025)\nThe great potential of memristive devices for real-world applications still relies on overcoming key technical challenges, including the need for a larger number of stable resistance states, faster switching speeds, lower SET/RESET voltages, improved endurance, and reduced variability. One material optimization strategy that has still been quite overlooked is interface engineering, specifically, tailoring the electrode/dielectric interface to modulate oxygen exchange. Here, we demonstrate that introducing materials with high ionic mobility can significantly expand the accessible oxygen concentration range within the dielectric layer, significantly broadening the memory window. Using SrTiO3-based memristive stacks, we integrated an ion-conducting SrCoO3 interfacial layer to facilitate oxygen transfer, increasing the number of distinguishable resistance states from 8 to 22. This modification also reduced the SET/RESET voltage by 50% and markedly improved device endurance, albeit with a trade-off of reduced state retention. To assess the practical implications of this trade-off, we trained a two-layer fully connected neural network using the experimental SrTiO3/SrCoO3 memristor characteristics on the MNIST handwritten digit dataset. Networks with hidden-layer sizes between 64 and 256 memristive elements achieved classification errors below 7%. The observed temporal drift means the functional state must be updated at intervals of less than 1 h to maintain reliable operation. Finally, we confirmed the transferability of this interface-engineering approach by applying it to HfOx-based devices, achieving a similarly enhanced memory window.\nüì• Save to Zotero üìÑ Download PDF\nColorings of unrooted tree-based networks and related graphs Authors: Mirko Wilde, Mareike Fischer Venue: arXiv (2025)\nIn mathematical phylogenetics, evolutionary relationships are often represented by trees and networks. The latter are typically used whenever the relationships cannot be adequately described by a tree, which happens when so-called reticulate evolutionary events happen, such as horizontal gene transfer or hybridization. But as such events are known to be relatively rare for most species, evolution is sometimes thought of as a process that can be represented by a tree with some additional edges, i.e., with a network that is still ``somewhat treelike‚Äô‚Äô. In this context, different versions of so-called tree-based networks have played a major role in recent phylogenetic literature. Yet, surprisingly little is known about their combinatorial and graph-theoretic properties. In our manuscript, we answer a recently published question concerning the colorability of a specific class of tree-based networks. In particular, we will investigate an even more general class of graphs and show their 3-colorability. This nicely links recent phylogenetic concepts with classical graph theory.\nüì• Save to Zotero üìÑ Download PDF\nFast and efficient formation of stable tetraatomic molecules from ultracold atoms via generalized stimulated Raman exact passage Authors: Jia-Hui Zhang, Wen-Yuan Wang, Fu-Quan Dou Venue: arXiv (2025)\nThe study of the conversion of ultracold atoms into molecules has long remained a hot topic in atomic, molecular, and optical physics. However, most prior research has focused on diatomic molecules, with relatively scarce exploration of polyatomic molecules. Here we propose a two-step strategy for the formation of stable ultracold tetraatomic molecules. We first suggest a generalized nonlinear stimulated Raman exact passage (STIREP) technique for the coherent conversion of ultracold atoms to tetraatomic molecules, which is subsequently followed by a chainwise-STIREP technique to transfer the resulting molecules into a sufficiently stable ground state. Through systematic numerical analysis, we demonstrate that the proposed two-step strategy holds great potential for enabling the robust, fast, and efficient formation of stable ultracold tetraatomic molecules.\nüì• Save to Zotero üìÑ Download PDF\nA Unified Low-rank ADI Framework with Shared Linear Solves for Simultaneously Solving Multiple Lyapunov, Sylvester, and Riccati Equations Authors: Umair Zulfiqar, Zhong-Yi Huang Venue: arXiv (2025)\nIt is known in the literature that the low-rank ADI method for Lyapunov equations is a Petrov-Galerkin projection algorithm that implicitly performs model order reduction. In this paper, we show that the low-rank ADI methods for Sylvester and Riccati equations are also Petrov-Galerkin projection algorithms that implicitly perform model order reduction. By observing that the ADI methods for Lyapunov, Sylvester, and Riccati equations differ only in pole placement and not in their interpolatory nature, we show that the shifted linear solves-which constitute the bulk of the computational cost-can be shared. The pole-placement step involves only small-scale operations and is therefore inexpensive. We propose a unified ADI framework that requires only two shifted linear solves per iteration to simultaneously solve six Lyapunov equations, one Sylvester equation, and ten Riccati equations, thus substantially increasing the return on investment for the computational cost spent on the linear solves. All operations needed to extract the individual solutions from these shared linear solves are small-scale and inexpensive. Since all ADI methods implicitly perform model order reduction when solving these linear matrix equations, we show that the resulting reduced-order models can be obtained as an additional byproduct. These models not only interpolate the original transfer function at the mirror images of the ADI shifts but also preserve important system properties such as stability, minimum-phase property, positive-realness, bounded-realness, and passivity. Consequently, the proposed unified ADI framework also serves as a recursive, interpolation-based model order reduction method, which can preserve several important properties of the original model in the reduced-order model.\nüì• Save to Zotero üìÑ Download PDF\nSemi Centralized Training Decentralized Execution Architecture for Multi Agent Deep Reinforcement Learning in Traffic Signal Control Authors: Pouria Yazdani, Arash Rezaali, Monireh Abdoos Venue: arXiv (2025)\nMulti-agent reinforcement learning (MARL) has emerged as a promising paradigm for adaptive traffic signal control (ATSC) of multiple intersections. Existing approaches typically follow either a fully centralized or a fully decentralized design. Fully centralized approaches suffer from the curse of dimensionality, and reliance on a single learning server, whereas purely decentralized approaches operate under severe partial observability and lack explicit coordination resulting in suboptimal performance. These limitations motivate region-based MARL, where the network is partitioned into smaller, tightly coupled intersections that form regions, and training is organized around these regions. This paper introduces a Semi-Centralized Training, Decentralized Execution (SEMI-CTDE) architecture for multi intersection ATSC. Within each region, SEMI-CTDE performs centralized training with regional parameter sharing and employs composite state and reward formulations that jointly encode local and regional information. The architecture is highly transferable across different policy backbones and state-reward instantiations. Building on this architecture, we implement two models with distinct design objectives. A multi-perspective experimental analysis of the two implemented SEMI-CTDE-based models covering ablations of the architecture‚Äôs core elements including rule based and fully decentralized baselines shows that they achieve consistently superior performance and remain effective across a wide range of traffic densities and distributions.\nüì• Save to Zotero üìÑ Download PDF\nStrategies for zero boil-off liquid hydrogen transfer: an export terminal case-study Authors: Halvor Aarnes Krog, David Berstad Venue: arXiv (2025)\nTo ensure economic viability, LH2 export terminals must minimize boil-off losses. We show two strategies to achieve zero boil-off losses for the transfer of 160 000 m3 LH2 (11 248 tons) using a centrifugal pump. In the first strategy, a pump with variable speed drive (VSD) and split-range control for the flow rate achieves losses from 0 wt% to 0.24 wt% in an uncertainty analysis. A pump efficiency approaching 70% is the most important factor to minimize losses. In contrast, a fixed-speed pump has unacceptably high losses ranging from 0.76 wt% to 1.06 wt% (119 tons per ship). The second strategy is to increase the maximum pressure in the seaborne tank (base case is 1.15 bara). Zero loss is achieved for the fixed speed pump if the maximum pressure is increased to 1.35 bara, while 1.22 bara is required for the pump with VSD assuming an efficiency of 60%.\nüì• Save to Zotero üìÑ Download PDF\nInfrared UAV Target Tracking with Dynamic Feature Refinement and Global Contextual Attention Knowledge Distillation Authors: Houzhang Fang, Chenxing Wu, Kun Bai, Tianqi Chen, Xiaolin Wang, Xiyang Liu, Yi Chang, Luxin Yan Venue: arXiv (2025)\nUnmanned aerial vehicle (UAV) target tracking based on thermal infrared imaging has been one of the most important sensing technologies in anti-UAV applications. However, the infrared UAV targets often exhibit weak features and complex backgrounds, posing significant challenges to accurate tracking. To address these problems, we introduce SiamDFF, a novel dynamic feature fusion Siamese network that integrates feature enhancement and global contextual attention knowledge distillation for infrared UAV target (IRUT) tracking. The SiamDFF incorporates a selective target enhancement network (STEN), a dynamic spatial feature aggregation module (DSFAM), and a dynamic channel feature aggregation module (DCFAM). The STEN employs intensity-aware multi-head cross-attention to adaptively enhance important regions for both template and search branches. The DSFAM enhances multi-scale UAV target features by integrating local details with global features, utilizing spatial attention guidance within the search frame. The DCFAM effectively integrates the mixed template generated from STEN in the template branch and original template, avoiding excessive background interference with the template and thereby enhancing the emphasis on UAV target region features within the search frame. Furthermore, to enhance the feature extraction capabilities of the network for IRUT without adding extra computational burden, we propose a novel tracking-specific target-aware contextual attention knowledge distiller. It transfers the target prior from the teacher network to the student model, significantly improving the student network‚Äôs focus on informative regions at each hierarchical level of the backbone network. Extensive experiments on real infrared UAV datasets demonstrate that the proposed approach outperforms state-of-the-art target trackers under complex backgrounds while achieving a real-time tracking speed.\nüì• Save to Zotero üìÑ Download PDF\nRefa√ßade: Editing Object with Given Reference Texture Authors: Youze Huang, Penghui Ruan, Bojia Zi, Xianbiao Qi, Jianan Wang, Rong Xiao Venue: arXiv (2025)\nRecent advances in diffusion models have brought remarkable progress in image and video editing, yet some tasks remain underexplored. In this paper, we introduce a new task, Object Retexture, which transfers local textures from a reference object to a target object in images or videos. To perform this task, a straightforward solution is to use ControlNet conditioned on the source structure and the reference texture. However, this approach suffers from limited controllability for two reasons: conditioning on the raw reference image introduces unwanted structural information, and it fails to disentangle the visual texture and structure information of the source. To address this problem, we propose Refa√ßade, a method that consists of two key designs to achieve precise and controllable texture transfer in both images and videos. First, we employ a texture remover trained on paired textured/untextured 3D mesh renderings to remove appearance information while preserving the geometry and motion of source videos. Second, we disrupt the reference global layout using a jigsaw permutation, encouraging the model to focus on local texture statistics rather than the global layout of the object. Extensive experiments demonstrate superior visual quality, precise editing, and controllability, outperforming strong baselines in both quantitative and human evaluations. Code is available at https://github.com/fishZe233/Refacade.\nüì• Save to Zotero üìÑ Download PDF\nPrototype-Based Semantic Consistency Alignment for Domain Adaptive Retrieval Authors: Tianle Hu, Weijun Lv, Na Han, Xiaozhao Fang, Jie Wen, Jiaxing Li, Guoxu Zhou Venue: arXiv (2025)\nDomain adaptive retrieval aims to transfer knowledge from a labeled source domain to an unlabeled target domain, enabling effective retrieval while mitigating domain discrepancies. However, existing methods encounter several fundamental limitations: 1) neglecting class-level semantic alignment and excessively pursuing pair-wise sample alignment; 2) lacking either pseudo-label reliability consideration or geometric guidance for assessing label correctness; 3) directly quantizing original features affected by domain shift, undermining the quality of learned hash codes. In view of these limitations, we propose Prototype-Based Semantic Consistency Alignment (PSCA), a two-stage framework for effective domain adaptive retrieval. In the first stage, a set of orthogonal prototypes directly establishes class-level semantic connections, maximizing inter-class separability while gathering intra-class samples. During the prototype learning, geometric proximity provides a reliability indicator for semantic consistency alignment through adaptive weighting of pseudo-label confidences. The resulting membership matrix and prototypes facilitate feature reconstruction, ensuring quantization on reconstructed rather than original features, thereby improving subsequent hash coding quality and seamlessly connecting both stages. In the second stage, domain-specific quantization functions process the reconstructed features under mutual approximation constraints, generating unified binary hash codes across domains. Extensive experiments validate PSCA‚Äôs superior performance across multiple datasets.\nüì• Save to Zotero üìÑ Download PDF\nUniversal quantum control over non-Hermitian continuous-variable systems Authors: Zhu-yao Jin, Jun Jing Venue: arXiv (2025)\nAlthough the control of non-Hermitian quantum systems has a growing interest for their nonunitary feature in the time evolution, the existing discussions are not more than two or three dimensions and heavily influenced by the singularity of the energy spectrum. We here develop a general theory to control an arbitrary number of bosonic modes governed by the time-dependent non-Hermitian Hamiltonian. It takes advantage of the gauge potential in the instantaneous frame rather than the energy spectrum of Hamiltonian. In particular, the dynamics of a general non-Hermitian continuous-variable system is analyzed in the instantaneous frame associated with time-dependent ancillary operators that are superpositions of the laboratory-frame operators and irrelevant to the original Hamiltonian. The gauge potential is determined by the unitary transformation between the time-dependent and stationary ancillary frames. The upper triangularization condition for the Hamiltonian‚Äôs coefficient matrix in the stationary ancillary frame enables two of the time-dependent ancillary operators to be nonadiabatic Heisenberg passages of the non-Hermitian system. The probability conservation of the system wavefunction can be restored at the end of these passages without artificial normalization. Our theory is exemplified with the perfect and nonreciprocal state transfers in a cavity magnonic system. The former holds for arbitrary initial states and is irrelevant to the parity-time symmetry of the Hamiltonian and the exceptional point of the spectra; and the latter is consistent with the unidirectional perfect absorbtion. Our work essentially extends the universal quantum control (UQC) theory to the non-Hermitian continuous-variable systems, providing a promising approach for their coherent control.\nüì• Save to Zotero üìÑ Download PDF\nNucleon to Roper transition amplitudes and electromagnetic form factors Authors: G. Ramalho Venue: arXiv (2025)\nThe second excitation of the nucleon, the Roper, has properties differentiated from other low-lying nucleon resonances. Their properties challenge our understanding of the structure of the baryons in terms of the degrees of freedom from QCD. In the present work we discuss the properties of the Roper resonance and the nucleon to Roper electromagnetic transition, based on the quark degrees of freedom, that are expected to dominate for large square momentum transfer $Q^2$. We also discuss the analytic structure of the transition amplitudes in the low-$Q^2$ region, and how the contributions of baryon-meson states can help to describe the low and intermediate $Q^2$ data, and the nature of the Roper.\nüì• Save to Zotero üìÑ Download PDF\nControllable Long-term Motion Generation with Extended Joint Targets Authors: Eunjong Lee, Eunhee Kim, Sanghoon Hong, Eunho Jung, Jihoon Kim Venue: arXiv (2025)\nGenerating stable and controllable character motion in real-time is a key challenge in computer animation. Existing methods often fail to provide fine-grained control or suffer from motion degradation over long sequences, limiting their use in interactive applications. We propose COMET, an autoregressive framework that runs in real time, enabling versatile character control and robust long-horizon synthesis. Our efficient Transformer-based conditional VAE allows for precise, interactive control over arbitrary user-specified joints for tasks like goal-reaching and in-betweening from a single model. To ensure long-term temporal stability, we introduce a novel reference-guided feedback mechanism that prevents error accumulation. This mechanism also serves as a plug-and-play stylization module, enabling real-time style transfer. Extensive evaluations demonstrate that COMET robustly generates high-quality motion at real-time speeds, significantly outperforming state-of-the-art approaches in complex motion control tasks and confirming its readiness for demanding interactive applications.\nüì• Save to Zotero üìÑ Download PDF\nContext-Aware Mixture-of-Experts Inference on CXL-Enabled GPU-NDP Systems Authors: Zehao Fan, Zhenyu Liu, Yunzhen Liu, Yayue Hou, Hadjer Benmeziane, Kaoutar El Maghraoui, Liu Liu Venue: arXiv (2025)\nMixture-of-Experts (MoE) models scale large language models through conditional computation, but inference becomes memory-bound once expert weights exceed the capacity of GPU memory. In this case, weights must be offloaded to external memory, and fetching them incurs costly and repeated transfers. We address this by adopting CXL-attached near-data processing (CXL-NDP) as the offloading tier to execute cold experts in place, converting expensive parameter movement into cheaper activation movement. Unlike prior GPU-NDP systems that are largely context-agnostic and reactive, we develop a context-aware MoE system that uses prefill-stage activation statistics to guide decoding-stage expert placement, dynamically pins hot experts in GPU-side HBM, and maps the remainder to CXL-NDP. To meet NDP‚Äôs limited compute throughput, we introduce context-aware mixed-precision quantization that allocates per-expert bitwidths (1-4 bit) based on prefill stage. The resulting MoE inference system overlaps GPU and NDP execution while minimizing cross-device movement. The evaluation on the GPU-NDP system shows that our approach achieves up to an 8.7-fold decoding throughput improvement over the state-of-the-art method, while incurring only a 0.13% average accuracy drop.\nüì• Save to Zotero üìÑ Download PDF\nOffloading to CXL-based Computational Memory Authors: Suyeon Lee, Kangkyu Park, Kwangsik Shin, Ada Gavrilovska Venue: arXiv (2025)\nCXL-based Computational Memory (CCM) enables near-memory processing within expanded remote memory, presenting opportunities to address data movement costs associated with disaggregated memory systems and to accelerate overall performance. However, existing operation offloading mechanisms are not capable of leveraging the trade-offs of different models based on different CXL protocols. This work first examines these tradeoffs and demonstrates their impact on end-to-end performance and system efficiency for workloads with diverse data and processing requirements. We propose a novel ‚ÄòAsynchronous Back-Streaming‚Äô protocol by carefully layering data and control transfer operations on top of the underlying CXL protocols. We design KAI, a system that realizes the asynchronous back-streaming model that supports asynchronous data movement and lightweight pipelining in host-CCM interactions. Overall, KAI reduces end-to-end runtime by up to 50.4%, and CCM and host idle times by average 22.11x and 3.85x, respectively.\nüì• Save to Zotero üìÑ Download PDF\nMulti-source Learning for Target Population by High-dimensional Calibration Authors: Haoxiang Zhan, Jae Kwang Kim, Yumou Qiu Venue: arXiv (2025)\nMulti-source learning is an emerging area of research in statistics, where information from multiple datasets with heterogeneous distributions is combined to estimate the parameter of interest for a target population without observed responses. We propose a high-dimensional debiased calibration (HDC) method and a multi-source HDC (MHDC) estimator for general estimating equations. The HDC method uses a novel approach to achieve Neyman orthogonality for the target parameter via high-dimensional covariate balancing on an augmented set of covariates. It avoids the augmented inverse probability weighting formulation and leads to an easier optimization algorithm for the target parameter in estimating equations and M-estimation. The proposed MHDC estimator integrates multi-source data while supporting flexible specifications for both density ratio and outcome regression models, achieving multiple robustness against model misspecification. Its asymptotic normality is established, and a specification test is proposed to examine the transferability condition for the multi-source data. Compared to the linear combination of single-source HDC estimators, the MHDC estimator improves efficiency by jointly utilizing all data sources. Through simulation studies, we show that the MHDC estimator accommodates multiple sources and multiple working models effectively and performs better than the existing doubly robust estimators for multi-source learning. An empirical analysis of a meteorological dataset demonstrates the utility of the proposed method in practice.\nüì• Save to Zotero üìÑ Download PDF\nPerformance Evaluation of Transfer Learning Based Medical Image Classification Techniques for Disease Detection Authors: Zeeshan Ahmad, Shudi Bao, Meng Chen Venue: arXiv (2025)\nMedical image classification plays an increasingly vital role in identifying various diseases by classifying medical images, such as X-rays, MRIs and CT scans, into different categories based on their features. In recent years, deep learning techniques have attracted significant attention in medical image classification. However, it is usually infeasible to train an entire large deep learning model from scratch. To address this issue, one of the solutions is the transfer learning (TL) technique, where a pre-trained model is reused for a new task. In this paper, we present a comprehensive analysis of TL techniques for medical image classification using deep convolutional neural networks. We evaluate six pre-trained models (AlexNet, VGG16, ResNet18, ResNet34, ResNet50, and InceptionV3) on a custom chest X-ray dataset for disease detection. The experimental results demonstrate that InceptionV3 consistently outperforms other models across all the standard metrics. The ResNet family shows progressively better performance with increasing depth, whereas VGG16 and AlexNet perform reasonably well but with lower accuracy. In addition, we also conduct uncertainty analysis and runtime comparison to assess the robustness and computational efficiency of these models. Our findings reveal that TL is beneficial in most cases, especially with limited data, but the extent of improvement depends on several factors such as model architecture, dataset size, and domain similarity between source and target tasks. Moreover, we demonstrate that with a well-trained feature extractor, only a lightweight feedforward model is enough to provide efficient prediction. As such, this study contributes to the understanding of TL in medical image classification, and provides insights for selecting appropriate models based on specific requirements.\nüì• Save to Zotero üìÑ Download PDF\nMini-supernovae from white dwarf-neutron star mergers: Viewing-angle-dependent spectra and lightcurves Authors: Yacheng Kang, Jin-Ping Zhu, Lijing Shao, Jiahang Zhong, Jinghao Zhang, Bing Zhang Venue: arXiv (2025)\nUnstable mass transfer may occur during white dwarf-neutron star (WD-NS) mergers, in which the WD can be tidally disrupted and form an accretion disk around the NS. Such an accretion disk can produce unbound wind ejecta, with synthesized $^{56}\\mathrm{Ni}$ mixed in. Numerical simulations reveal that this unbound ejecta should be strongly polar-dominated, which may cause the following radioactive-powered thermal transient to be viewing-angle-dependent. This issue has so far received limited investigation. We investigate how the intrinsically non-spherical geometry of WD-NS wind ejecta affects the viewing-angle dependence of the thermal transients. Using a two-dimensional axisymmetric ejecta configuration and incorporating heating from the radioactive decay of $^{56}\\mathrm{Ni}$, we employ a semi-analytical discretization scheme to simulate the observed viewing-angle-dependent photospheric evolution, as well as the resulting spectra and lightcurves. The observed photosphere evolves over time and depends strongly on the viewing angle: off-axis observers can see deeper, hotter inner layers of the ejecta and larger projected photospheric areas compared to on-axis observers. For a fiducial WD-NS merger producing 0.3 solar mass of ejecta and 0.01 solar mass of synthesized $^{56}\\mathrm{Ni}$, the resulting peak optical absolute magnitudes of the transient span from ~ -12 mag along the polar direction to ~ -16 mag along the equatorial direction, corresponding to luminosities of $10^{40}$-$10^{42}$ erg s$^{-1}$. The typical peak timescales are expected to be 3-10 d. We for the first time explore the viewing-angle effect on WD-NS merger transients. Since their ejecta composition and energy sources resemble those of supernovae, yet WD-NS merger transients are dimmer and evolve more rapidly, we propose using ‚Äúmini-supernovae‚Äù to describe the thermal emission following WD-NS mergers.\nüì• Save to Zotero üìÑ Download PDF\nRetrieving missing data in electron diffraction of gas-phase molecules Authors: Yanwei Xiong, Nikhil Kumar Pachisia, Martin Centurion Venue: arXiv (2025)\nWe report an iterative algorithm to retrieve accurate real space information from gas electron diffraction measurements with missing data at low momentum transfer. The algorithm is similar to phase retrieval algorithms which transform signals back and forth between the signal domain and the Fourier domain and apply constraints to retrieve the missing phase. The difference in our case is that the goal is not retrieval of the phase of the diffraction signal but the missing data at low momentum transfer, which is necessary for generating the real-space pair distribution function. The missing data is a common problem in static and ultrafast gas phase electron diffraction experiments due to experimental constraints. We demonstrated successful restoration of the missing data in simulated data and in experimentally measured diffraction signals of static and photo-dissociated trifluoroiodomethane and iodobenzene molecules.\nüì• Save to Zotero üìÑ Download PDF\nAsymptotic constraints for 1D planar grey photon diffusion from linear transport with special-relativistic effects Authors: Ryan T. Wollaeger, Jim E. Morel, Kendra P. Long, Mathew A. Cleveland, Robert B. Lowrie Venue: arXiv (2025)\nWe derive a grey linear diffusion equation for photons with respect to inertial (or lab-frame) space and time, using asymptotic analysis in 1D planar geometry. The solution of the equation is the comoving radiation energy density. Our analysis does not make use of assumptions about the magnitude of velocity; instead we derive an asymptotic scaling in the lab frame such that we avoid apparent non-physical pathologies that are encountered with the standard static-matter scaling. We permit the photon direction to be continuous (as opposed to constraining the analysis to discrete ordinates). The result is a drift-diffusion equation in the lab frame for comoving radiation energy density, with an adiabatic term that matches the standard semi-relativistic diffusion equation. Following a recent study for discrete directions, this equation reduces to a pure advection equation as the velocity approaches the speed of light. We perform preliminary numerical experiments comparing solutions to relativistic lab-frame Monte Carlo transport and to the well-known semi-relativistic diffusion equation.\nüì• Save to Zotero üìÑ Download PDF\nInteractions Between Internal Solitary Waves and Floating Canopies Authors: Jen-Ping Chu, Mitul Luhar, Patrick Lynett Venue: arXiv (2025)\nInteractions between internal solitary waves and floating canopies of varying length and porosity are examined via laboratory experiments and complementary simulations for a miscible, two-layer system. In both approaches, internal solitary waves of varying amplitudes are generated by a jet-array mechanism that is driven by the nonlinear eKdV solution. Pycnocline displacements, phase speeds, and velocity fields are obtained using synchronized planar laser-induced fluorescence and particle imaging velocimetry systems in the experiment. In the simulations, the canopy is represented as a porous zone with prescribed porosity and hydraulic conductivity determined by the Kozeny-Carman model, which is validated by comparing simulated and measured horizontal velocity profiles. The higher-porosity (transitional) canopy produces a nearly monotonic, albeit minor, amplitude reduction and negligible wave energy dissipation after the interaction. However, the shear layer developed at the bottom edge of the lower-porosity (dense) canopy grows to a comparable strength as the shear sustained by the internal solitary wave profile at the pycnocline. The vortex pair generated by this shear accelerates the upper-layer fluid beneath the canopy, leading to complex nonlinear amplitude modulation and significant wave transformation. With an extended canopy length, the internal solitary waves settle to a quasi-steady state with a significant phase speed reduction. Upon the wave exiting the canopy, flow separation at the downstream edge of the canopy again pairs with the shear at the pycnocline, inducing an intensified jet. This complex interaction leads to energy transfer between kinetic and potential energy under the dense canopy.\nüì• Save to Zotero üìÑ Download PDF\nProbing Evaporating Black Holes with Modular Flow in SYK Authors: Nicol√≤ Bragagnolo, S. Prem Kumar Venue: arXiv (2025)\nWe study the effect of modular flow on correlation functions of fermions in the Sachdev-Ye-Kitaev (SYK) model coupled weakly to a bath, which we take to be another SYK model. The system and bath, together are prepared in the thermofield double (TFD) state, and we focus on the effect of modular flow generated by the reduced density matrix for the SYK system, obtained by tracing out the bath. We show, in the late time limit, that modular flowed correlators of two Majorana fermions, single-sided and two-sided, exhibit non-trivial singularities. Beyond a critical value of the modular parameter, the ``modular scrambling time\", the singularity structure shows correlations being transferred from one boundary to the other. The calculations are performed by employing the replica trick in Euclidean time and appropriately analytically continuing to real time. Exploiting the connection between modular flow generators and SL$(2,{\\mathbb R})$ boosts we use the microscopic picture to reconstruct the dual bulk modular flow in two-sided AdS$_2$ black hole spacetime. Fixed points of the flow allow to identify quantum extremal surfaces (QES) demarcating the entanglement wedge of the boundary system and the island. We show that bulk modular flow can move fermion insertions near the right boundary past the horizon leading to lightcone singularities in appropriately smeared boundary correlators, probing physics beyond the horizon.\nüì• Save to Zotero üìÑ Download PDF\nUniversal Quantum Interconnects via Phase-Coherent Four-Wave Mixing Authors: Hao Zhang, Yang Xu, Linshan Sun, Wei Cui, Robert W. Boyd, Sergio Carbajo Venue: arXiv (2025)\nQuantum transduction, which enables the coherent conversion of quantum information between disparate physical platforms, is a cornerstone for realizing scalable and interoperable quantum networks. Among various approaches, parametric frequency mixing processes such as four-wave mixing (FWM) offer a promising pathway toward efficient and low-noise transduction. In this work, we demonstrate the feasibility of coherent quantum state transfer by indirectly verifying high-fidelity wavefunction‚Äôs phase mapping (\u003e99%) from the input field to the generated output field wave. Using a gas-filled hollow-core capillary fiber, we systematically investigate spectral phase evolution across a broad range, including infrared (IR) to ultraviolet (UV) transitions, as well as conversions from telecom-band (1550 nm) to visible (516 nm) and deep-UV (308 nm) wavelengths. Our results reveal that strong phase coherence can be maintained throughout these diverse conversion regimes. Because quantum properties such as coherence and entanglement are intrinsically encoded in both the amplitude and phase of a photonic wavefunction, preserving spectral phase is essential for faithful quantum information transfer. We further show that efficient and phase-preserving transduction can be achieved by tuning system parameters, offering valuable insights into nonlinear coupling dynamics. These findings establish a promising foundation for advancing FWM-based quantum transduction schemes and open new avenues for integrating heterogeneous quantum systems across wide spectral domains within future quantum communication networks.\nüì• Save to Zotero üìÑ Download PDF\nInference-time Stochastic Refinement of GRU-Normalizing Flow for Real-time Video Motion Transfer Authors: Tasmiah Haque, Srinjoy Das Venue: arXiv (2025)\nReal-time video motion transfer applications such as immersive gaming and vision-based anomaly detection require accurate yet diverse future predictions to support realistic synthesis and robust downstream decision making under uncertainty. To improve the diversity of such sequential forecasts we propose a novel inference-time refinement technique that combines Gated Recurrent Unit-Normalizing Flows (GRU-NF) with stochastic sampling methods. While GRU-NF can capture multimodal distributions through its integration of normalizing flows within a temporal forecasting framework, its deterministic transformation structure can limit expressivity. To address this, inspired by Stochastic Normalizing Flows (SNF), we introduce Markov Chain Monte Carlo (MCMC) steps during GRU-NF inference, enabling the model to explore a richer output space and better approximate the true data distribution without retraining. We validate our approach in a keypoint-based video motion transfer pipeline, where capturing temporally coherent and perceptually diverse future trajectories is essential for realistic samples and low bandwidth communication. Experiments show that our inference framework, Gated Recurrent Unit- Stochastic Normalizing Flows (GRU-SNF) outperforms GRU-NF in generating diverse outputs without sacrificing accuracy, even under longer prediction horizons. By injecting stochasticity during inference, our approach captures multimodal behavior more effectively. These results highlight the potential of integrating stochastic dynamics with flow-based sequence models for generative time series forecasting.\nüì• Save to Zotero üìÑ Download PDF\nUniLight: A Unified Representation for Lighting Authors: Zitian Zhang, Iliyan Georgiev, Michael Fischer, Yannick Hold-Geoffroy, Jean-Fran√ßois Lalonde, Valentin Deschaintre Venue: arXiv (2025)\nLighting has a strong influence on visual appearance, yet understanding and representing lighting in images remains notoriously difficult. Various lighting representations exist, such as environment maps, irradiance, spherical harmonics, or text, but they are incompatible, which limits cross-modal transfer. We thus propose UniLight, a joint latent space as lighting representation, that unifies multiple modalities within a shared embedding. Modality-specific encoders for text, images, irradiance, and environment maps are trained contrastively to align their representations, with an auxiliary spherical-harmonics prediction task reinforcing directional understanding. Our multi-modal data pipeline enables large-scale training and evaluation across three tasks: lighting-based retrieval, environment-map generation, and lighting control in diffusion-based image synthesis. Experiments show that our representation captures consistent and transferable lighting features, enabling flexible manipulation across modalities.\nüì• Save to Zotero üìÑ Download PDF\nPrimordial Black Holes from Inflation with a Spectator Field Authors: Dario L. Lorenzoni, Sarah R. Geller, David I. Kaiser, Evan McDonough Venue: arXiv (2025)\nHow is the production of primordial black holes (PBHs) in single-field models of inflation impacted by the presence of additional scalar fields? We consider the effect of a spectator field - a free scalar field with sub-Hubble mass, no direct coupling to the inflaton, and which makes a subdominant contribution to the total energy density - in the context of single-field models of inflation featuring a transient phase of ultra-slow roll (USR) evolution. Despite the modest title, a spectator field can have a dramatic impact: the slow-roll evolution of the spectator prevents the combined inflaton-and-spectator system from entering into USR, which naively might be expected to preclude the production of PBHs. However, we demonstrate that the growth of perturbations is maintained or enhanced by the spectator, through the rich interplay of curvature and isocurvature perturbations. We show in a model-independent way that the single-field phase of ultra-slow-roll is replaced by two turns in field space encompassing a phase of tachyonic instability for the isocurvature perturbations and a transfer of power from isocurvature to curvature modes. Furthermore, we highlight a degeneracy between the fine-tuning of the feature in the inflaton potential and the parameters of the spectator, leading to an overall resilience of model predictions to parameter variations. This makes it easier for the underlying PBH model to accommodate both high-precision CMB constraints and production of PBHs in the asteroid-mass range.\nüì• Save to Zotero üìÑ Download PDF\nResolving the terrestrial planet-forming region of HD 172555 with ALMA: I. Post-impact dust distribution Authors: Zoe Roumeliotis, Luca Matr√†, Grant M. Kennedy, Sebastian Marino, Kate Y. L. Su, David J. Wilner, Mark C. Wyatt, Alan P. Jackson Venue: arXiv (2025)\nGiant impacts between planetary embryos are a natural step in the terrestrial planet formation process and are expected to create disks of warm debris in the terrestrial regions of their stars. Understanding the gas and dust debris produced in giant impacts is vital for comprehending and constraining models of planetary collisions. We reveal the distribution of millimeter grains in the giant impact debris disk of HD 172555 for the first time, using new ALMA 0.87 mm observations at $\\sim$80 mas (2.3 au) resolution. We modeled the interferometric visibilities to obtain basic spatial properties of the disk, and compared it to the disk‚Äôs dust and gas distributions at other wavelengths. We detect the star and dust emission from an inclined disk out to $\\sim$9 au and down to 2.3 au (on-sky) from the central star, with no significant asymmetry in the dust distribution. Radiative transfer modeling of the visibilities indicates the disk surface density distribution of millimeter grains most likely peaks around $\\sim$5 au, while the width inferred remains model-dependent at the S/N of the data. We highlight an outward radial offset of the small grains traced by scattered light observations compared to the millimeter grains, which could be explained by the combined effect of gas drag and radiation pressure in the presence of large enough gas densities. Furthermore, SED modeling implies a size distribution slope for the millimeter grains consistent with the expectation of collisional evolution and flatter than inferred for the micron-sized grains, implying a break in the grain size distribution and confirming an overabundance of small grains.\nüì• Save to Zotero üìÑ Download PDF\nEnhancing next token prediction based pre-training for jet foundation models Authors: Joschka Birk, Anna Hallin, Gregor Kasieczka, Nikol Madzharova, Ian Pang, David Shih Venue: arXiv (2025)\nNext token prediction is an attractive pre-training task for jet foundation models, in that it is simulation free and enables excellent generative capabilities that can transfer across datasets. Here we study multiple improvements to next token prediction, building on the initial work of OmniJet-$Œ±$. Instead of tokenizing particles and subsequently only using the token-ID as the model input for both the generative and the classification task, we adopt a hybrid setup, which allows us to use continuous feature vectors as model input while only using token-IDs in the next token prediction target. Secondly, we explore a combined pre-training strategy that combines masked particle modeling and generative learning objectives. Taken together, these changes greatly improve the performance in downstream classification tasks without any loss in generative performance.\nüì• Save to Zotero üìÑ Download PDF\nUnique Lives, Shared World: Learning from Single-Life Videos Authors: Tengda Han, Sayna Ebrahimi, Dilara Gokay, Li Yang Ku, Maks Ovsjanikov, Iva Babukova, Daniel Zoran, Viorica Patraucean, Joao Carreira, Andrew Zisserman, Dima Damen Venue: arXiv (2025)\nWe introduce the ‚Äúsingle-life‚Äù learning paradigm, where we train a distinct vision model exclusively on egocentric videos captured by one individual. We leverage the multiple viewpoints naturally captured within a single life to learn a visual encoder in a self-supervised manner. Our experiments demonstrate three key findings. First, models trained independently on different lives develop a highly aligned geometric understanding. We demonstrate this by training visual encoders on distinct datasets each capturing a different life, both indoors and outdoors, as well as introducing a novel cross-attention-based metric to quantify the functional alignment of the internal representations developed by different models. Second, we show that single-life models learn generalizable geometric representations that effectively transfer to downstream tasks, such as depth estimation, in unseen environments. Third, we demonstrate that training on up to 30 hours from one week of the same person‚Äôs life leads to comparable performance to training on 30 hours of diverse web data, highlighting the strength of single-life representation learning. Overall, our results establish that the shared structure of the world, both leads to consistency in models trained on individual lives, and provides a powerful signal for visual representation learning.\nüì• Save to Zotero üìÑ Download PDF\nDomain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions Authors: Hong Yang, Devroop Kar, Qi Yu, Alex Ororbia, Travis Desell Venue: arXiv (2025)\nWhy do state-of-the-art OOD detection methods exhibit catastrophic failure when models are trained on single-domain datasets? We provide the first theoretical explanation for this phenomenon through the lens of information theory. We prove that supervised learning on single-domain data inevitably produces domain feature collapse ‚Äì representations where I(x_d; z) = 0, meaning domain-specific information is completely discarded. This is a fundamental consequence of information bottleneck optimization: models trained on single domains (e.g., medical images) learn to rely solely on class-specific features while discarding domain features, leading to catastrophic failure when detecting out-of-domain samples (e.g., achieving only 53% FPR@95 on MNIST). We extend our analysis using Fano‚Äôs inequality to quantify partial collapse in practical scenarios. To validate our theory, we introduce Domain Bench, a benchmark of single-domain datasets, and demonstrate that preserving I(x_d; z) \u003e 0 through domain filtering (using pretrained representations) resolves the failure mode. While domain filtering itself is conceptually straightforward, its effectiveness provides strong empirical evidence for our information-theoretic framework. Our work explains a puzzling empirical phenomenon, reveals fundamental limitations of supervised learning in narrow domains, and has broader implications for transfer learning and when to fine-tune versus freeze pretrained models.\nüì• Save to Zotero üìÑ Download PDF\nValue Gradient Guidance for Flow Matching Alignment Authors: Zhen Liu, Tim Z. Xiao, Carles Domingo-Enrich, Weiyang Liu, Dinghuai Zhang Venue: arXiv (2025)\nWhile methods exist for aligning flow matching models‚Äìa popular and effective class of generative models‚Äìwith human preferences, existing approaches fail to achieve both adaptation efficiency and probabilistically sound prior preservation. In this work, we leverage the theory of optimal control and propose VGG-Flow, a gradient-matching-based method for finetuning pretrained flow matching models. The key idea behind this algorithm is that the optimal difference between the finetuned velocity field and the pretrained one should be matched with the gradient field of a value function. This method not only incorporates first-order information from the reward model but also benefits from heuristic initialization of the value function to enable fast adaptation. Empirically, we show on a popular text-to-image flow matching model, Stable Diffusion 3, that our method can finetune flow matching models under limited computational budgets while achieving effective and prior-preserving alignment.\nüì• Save to Zotero üìÑ Download PDF\nNeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation Authors: Yu Zeng, Charles Ochoa, Mingyuan Zhou, Vishal M. Patel, Vitor Guizilini, Rowan McAllister Venue: arXiv (2025)\nStandard diffusion corrupts data using Gaussian noise whose Fourier coefficients have random magnitudes and random phases. While effective for unconditional or text-to-image generation, corrupting phase components destroys spatial structure, making it ill-suited for tasks requiring geometric consistency, such as re-rendering, simulation enhancement, and image-to-image translation. We introduce Phase-Preserving Diffusion œÜ-PD, a model-agnostic reformulation of the diffusion process that preserves input phase while randomizing magnitude, enabling structure-aligned generation without architectural changes or additional parameters. We further propose Frequency-Selective Structured (FSS) noise, which provides continuous control over structural rigidity via a single frequency-cutoff parameter. œÜ-PD adds no inference-time cost and is compatible with any diffusion model for images or videos. Across photorealistic and stylized re-rendering, as well as sim-to-real enhancement for driving planners, œÜ-PD produces controllable, spatially aligned results. When applied to the CARLA simulator, œÜ-PD improves CARLA-to-Waymo planner performance by 50%. The method is complementary to existing conditioning approaches and broadly applicable to image-to-image and video-to-video generation. Videos, additional examples, and code are available on our \\href{https://yuzeng-at-tri.github.io/ppd-page/}{project page}.\nüì• Save to Zotero üìÑ Download PDF\nDeep Forcing: Training-Free Long Video Generation with Deep Sink and Participative Compression Authors: Jung Yi, Wooseok Jang, Paul Hyunbin Cho, Jisu Nam, Heeji Yoon, Seungryong Kim Venue: arXiv (2025)\nRecent advances in autoregressive video diffusion have enabled real-time frame streaming, yet existing solutions still suffer from temporal repetition, drift, and motion deceleration. We find that naively applying StreamingLLM-style attention sinks to video diffusion leads to fidelity degradation and motion stagnation. To overcome this, we introduce Deep Forcing, which consists of two training-free mechanisms that address this without any fine-tuning. Specifically, 1) Deep Sink dedicates half of the sliding window to persistent sink tokens and re-aligns their temporal RoPE phase to the current timeline, stabilizing global context during long rollouts. 2) Participative Compression performs importance-aware KV cache pruning that preserves only tokens actively participating in recent attention while safely discarding redundant and degraded history, minimizing error accumulation under out-of-distribution length generation. Together, these components enable over 12x extrapolation (e.g. 5s-trained to 60s+ generation) with better imaging quality than LongLive, better aesthetic quality than RollingForcing, almost maintaining overall consistency, and substantial gains in dynamic degree, all while maintaining real-time generation. Our results demonstrate that training-free KV-cache management can match or exceed training-based approaches for autoregressively streaming long-video generation.\nüì• Save to Zotero üìÑ Download PDF\nDebt, Growth, and the Carbon Lock-In Authors: Silvia Montagnania, Barnabe Ledoux, David Lacoste Venue: arXiv (2025)\nWe develop a macro-financial model that establishes a link between credit dynamics, economic growth, and cumulative carbon emissions. It is based on an extension of Kelly‚Äôs model, a framework derived from information theory and investment theory, applied here to understand macro-financial and climate dynamics. This approach complements traditional Integrated Assessment Models (IAMs) by explicitly linking financial dynamics to cumulative emissions, enabling the assessment of policy alignment (or misalignment) with net-zero pathways. We find that injecting debt into the system increases short-term production gains, but at the expense of higher bankruptcy risk and cumulative emissions. Thus, the model reveals a double constraint: financially, debt requires growth to be repaid; ecologically, growth requires energy, and therefore emissions. When the intrinsic growth rate falls below the interest rate, the probability of solvency drops to zero: the economy enters a zone of structural instability. The model then identifies an optimal leverage frontier: beyond a certain threshold, additional debt no longer fuels real wealth; it only increases the risk of bankruptcy and carbon debt. Our model is calibrated using multi-decade macroeconomic and emissions data from several countries, including the United States, China, France, and Denmark. Our results confirm that the correlation between cumulative debt, cumulative GDP, and cumulative emissions remains strong, regardless of the political structure of credit. In our current financial system, credit expansion amplifies GDP growth and associated emissions, thereby locking economies into higher cumulative carbon trajectories, even as energy efficiency improves through innovation.\nüì• Save to Zotero üìÑ Download PDF\nMillimetre-Wave Comb Generated by an Optical Microcomb Authors: Luke Peters, Antonio Cutrona, Andrew R. Cooper, Luana Olivieri, Fedor Getman, Vittorio Cecconi, Nitish Paul, Debayan Das, Maxwell Rowley, Sai T. Chu, Brent E. Little, Roberto Morandotti, David J. Moss, Juan S. Totero Gongora, Alessia Pasquazi, Marco Peccianti Venue: arXiv (2025)\nMetrological-grade millimetre wave baseband comb sources covering the subterahertz window are a key building block for next-generation wireless communications, precision sensing, and positioning systems. While optical microcombs have set new benchmarks in ultra-low phase noise single-frequency microwave generation, to date, no microcomb source has directly produced a millimetre-wave baseband comb. Here, we present a 50 GHz repetition rate carrier-envelope offset estabilised millimetre-wave baseband comb source covering the sub-terahertz region, generated from an optical microcomb source. Our microresonator-filtered microcomb enables direct, coherent downconversion via photoconductive antennas, even without external amplification. The metrological-grade optical soliton source produces single-cycle, naturally zero carrier-envelope offset millimetrewave baseband combs. It supports time-domain spectroscopy without any need to temporally align the source and detection pulses, as the ultra-high phase coherence allows significant differences between the optical paths of the source and detection pulses, which we tested over 8m, finding no degradation even in freerunning operation. Finally, the multisoliton operation regime provides a simple way of spectrally tailoring the microwave output by selecting different optical soliton states.\nüì• Save to Zotero üìÑ Download PDF\nEvolutionary Architecture Search through Grammar-Based Sequence Alignment Authors: Adri G√≥mez Mart√≠n, Felix M√∂ller, Steven McDonagh, Monica Abella, Manuel Desco, Elliot J. Crowley, Aaron Klein, Linus Ericsson Venue: arXiv (2025)\nNeural architecture search (NAS) in expressive search spaces is a computationally hard problem, but it also holds the potential to automatically discover completely novel and performant architectures. To achieve this we need effective search algorithms that can identify powerful components and reuse them in new candidate architectures. In this paper, we introduce two adapted variants of the Smith-Waterman algorithm for local sequence alignment and use them to compute the edit distance in a grammar-based evolutionary architecture search. These algorithms enable us to efficiently calculate a distance metric for neural architectures and to generate a set of hybrid offspring from two parent models. This facilitates the deployment of crossover-based search heuristics, allows us to perform a thorough analysis on the architectural loss landscape, and track population diversity during search. We highlight how our method vastly improves computational complexity over previous work and enables us to efficiently compute shortest paths between architectures. When instantiating the crossover in evolutionary searches, we achieve competitive results, outperforming competing methods. Future work can build upon this new tool, discovering novel components that can be used more broadly across neural architecture design, and broadening its applications beyond NAS.\nüì• Save to Zotero üìÑ Download PDF\nLearning Causality for Longitudinal Data Authors: Mouad EL Bouchattaoui Venue: arXiv (2025)\nThis thesis develops methods for causal inference and causal representation learning (CRL) in high-dimensional, time-varying data. The first contribution introduces the Causal Dynamic Variational Autoencoder (CDVAE), a model for estimating Individual Treatment Effects (ITEs) by capturing unobserved heterogeneity in treatment response driven by latent risk factors that affect only outcomes. CDVAE comes with theoretical guarantees on valid latent adjustment and generalization bounds for ITE error. Experiments on synthetic and real datasets show that CDVAE outperforms baselines, and that state-of-the-art models greatly improve when augmented with its latent substitutes, approaching oracle performance without access to true adjustment variables. The second contribution proposes an efficient framework for long-term counterfactual regression based on RNNs enhanced with Contrastive Predictive Coding (CPC) and InfoMax. It captures long-range dependencies under time-varying confounding while avoiding the computational cost of transformers, achieving state-of-the-art results and introducing CPC into causal inference. The third contribution advances CRL by addressing how latent causes manifest in observed variables. We introduce a model-agnostic interpretability layer based on the geometry of the decoder Jacobian. A sparse self-expression prior induces modular, possibly overlapping groups of observed features aligned with shared latent influences. We provide recovery guarantees in both disjoint and overlapping settings and show that meaningful latent-to-observed structure can be recovered without anchor features or single-parent assumptions. Scalable Jacobian-based regularization techniques are also developed.\nüì• Save to Zotero üìÑ Download PDF\nExploring YouTube‚Äôs Political Communication Networks during the 2024 French Elections Authors: Caroline Violot, Vera Sosnovik, Mathias Humbert Venue: arXiv (2025)\nIn 2024, France was shaken by the far-right National Rally‚Äôs victory in the European elections. In response to this unprecedented result, French President Emmanuel Macron dissolved the National Assembly, triggering legislative elections just two weeks later. A whirlwind campaign followed, partly on social media, as is now the norm, and concluded with the victory of a left-wing coalition. This article examines the YouTube activity of two key actors during this period, news media and politicians, and the commenting behavior they generated. We built a dataset of 35 news media channels, 28 politicians and parties channels, 43.5k videos posted from three months before the European elections to one week after the second round of the legislative elections, and 7.4M associated comments. We examined upload activity and engagement across political orientations and used network analysis methods to uncover the structure of their commenting communities. We also identified politicians‚Äô appearances on news media channels and assessed their impact on commenting user bases. Our findings show that, among politicians and parties channels, far-right and left-wing ones were significantly more active and received substantially higher engagement (views, likes, and comments) than other groups, with denser and more clustered commenting communities. About 7% of commenters commented across political orientations and were much more active than in-group commenters. News media channels tended to favor politically aligned guests, while centrist politicians were over-represented. Finally, politicians‚Äô presence in the videos of a specific news media channel increased the share of commenters who were active on this channel and political channels, regardless of their orientation.\nüì• Save to Zotero üìÑ Download PDF\nEnvironment-Aware Channel Inference via Cross-Modal Flow: From Multimodal Sensing to Wireless Channels Authors: Guangming Liang, Mingjie Yang, Dongzhu Liu, Paul Henderson, Lajos Hanzo Venue: arXiv (2025)\nAccurate channel state information (CSI) underpins reliable and efficient wireless communication. However, acquiring CSI via pilot estimation incurs substantial overhead, especially in massive multiple-input multiple-output (MIMO) systems operating in high-Doppler environments. By leveraging the growing availability of environmental sensing data, this treatise investigates pilot-free channel inference that estimates complete CSI directly from multimodal observations, including camera images, LiDAR point clouds, and GPS coordinates. In contrast to prior studies that rely on predefined channel models, we develop a data-driven framework that formulates the sensing-to-channel mapping as a cross-modal flow matching problem. The framework fuses multimodal features into a latent distribution within the channel domain, and learns a velocity field that continuously transforms the latent distribution toward the channel distribution. To make this formulation tractable and efficient, we reformulate the problem as an equivalent conditional flow matching objective and incorporate a modality alignment loss, while adopting low-latency inference mechanisms to enable real-time CSI estimation. In experiments, we build a procedural data generator based on Sionna and Blender to support realistic modeling of sensing scenes and wireless propagation. System-level evaluations demonstrate significant improvements over pilot- and sensing-based benchmarks in both channel estimation accuracy and spectral efficiency for the downstream beamforming task.\nüì• Save to Zotero üìÑ Download PDF\nProbing TeV Afterglow Emission of GRB~221009A with Gaussian Structured jet in Wind-driven medium Authors: T. Mondal, S. Chakraborty, L. Resmi, D. Bose Venue: arXiv (2025)\nRecent detections of very high energy (VHE; GeV-TeV) photons from gamma-ray burst (GRB) afterglows, most notably the extreme event GRB 221009A, require refined models that include realistic jet structures and complex circumburst environments. The jet‚Äôs angular structure is crucial for shaping afterglow emission. Our recent work demonstrates that Gaussian jets, with their smooth angular decline, naturally produce early bright peaks for on-axis observers and delayed, softer, dimmer peaks at higher inclinations. The gradual decline suppresses excessive lateral expansion, unlike the sharp edge in top-hat jets, making Gaussian jets a compelling alternative to both top-hat and other structured-jet models. Here we implement a Gaussian structured-jet model to explain TeV afterglows from adiabatic forward shocks propagating in a wind-driven medium. We show that the TeV peak time and flux depend sensitively on jet geometry, kinetic energy, wind density, and on microphysical parameter ratios that scale the SSC component. We identify the afterglow parameter space that is favourable for detecting sub-TeV photons with the Cherenkov Telescope Array (CTA), finding that only about ten per cent of simulated TeV events exceed CTA sensitivity in a wind medium. These detections arise from near core-aligned views, with high kinetic energy and wind density, moderate initial Lorentz factor and downstream magnetic field, and a relatively large fraction of energy in nonthermal electrons. Applying this model to GRB 221009A, we perform multi-band fits including wind-modified dynamics, Klein-Nishina effects, and EBL attenuation, and find that a mildly off-axis geometry reproduces the observed X-ray and GeV-TeV light curves.\nüì• Save to Zotero üìÑ Download PDF\nPerformance Optimization and Characterization of 7-pad Resistive PICOSEC Micromegas Detectors Authors: A. Kallitsopoulou, R. Aleksan, S. Aune, J. Bortfeldt, F. Brunbauer, M. Brunoldi, J. Datta, D. Desforge, G. Fanourakis, D. Fiorina, K. J. Floethner, M. Gallinaro, F. Garcia, I. Giomataris, K. Gnanvo, F. J. Iguaz, D. Janssens, F. Jeanneau, M. Kovacic, B. Kross, P. Legou, M. Lisowska, J. Liu, M. Lupberger, I. Maniatis, J. McKisson, Y. Meng, H. Muller, E. Oliveri, G. Orlandini, A. Pandey, T. Papaevangelou, M. Pomorski, E. F. Ribas, L. Ropelewski, D. Sampsonidis, L. Scharenberg, T. Schneider, E. Scorsone, L. Sohl, M. van Stenis, Y. Tsipolitis, S. E. Tzamarias, A. Utrobicic, I. Vai, R. Veenhof, P. Vitulo, X. Wang, S. White, W. Xi, Z. Zhang, Y. Zhou Venue: arXiv (2025)\nWe present a comprehensive characterization of resistive PICOSEC Micromegas detector prototypes, tested under identical conditions, constant drift gap, field configurations, and photocathode at the CERN SPS H4 beam line. This work provides a proof of concept for the use of resistive layer technology in gaseous timing detectors, demonstrating that robustness can be improved without compromising the excellent timing performance of PICOSEC Micromegas. Different resistive architectures and values were explored to optimize stability and ensure reliable long-term operation in challenging experimental environments. The prototype with a 10MŒ© resistive layer achieved the best overall performance, with a timing resolution of 22.900 {\\pm} 0.002 ps and a spatial resolution of 1.190 {\\pm} 0.003 mm, while charge sharing across multiple pads enabled combined timing resolutions below 28 ps. A lower-resistivity (200kŒ©) configuration exhibited enhanced charge spread, leading to minor systematic offsets in reconstructed pad centers, yet maintained robust timing and spatial performance. Capacitive charge-sharing architectures improved spatial resolution in some regions but suffered from signal attenuation and nonuniform charge distributions, resulting in slightly degraded timing (33.300 {\\pm} 0.002 ps) and complex localization patterns. Mechanical precision, particularly readout planarity and photocathode alignment, was identified as critical for uniform detector response. These studies benchmark the potential of resistive layers for gaseous timing detectors and provide a foundation for scalable designs with optimized timing and spatial resolution across diverse experimental applications.\nüì• Save to Zotero üìÑ Download PDF\nContract-Driven QoE Auditing for Speech and Singing Services: From MOS Regression to Service Graphs Authors: Wenzhang Du Venue: arXiv (2025)\nSubjective mean opinion scores (MOS) remain the de-facto target for non-intrusive speech and singing quality assessment. However, MOS is a scalar that collapses heterogeneous user expectations, ignores service-level objectives, and is difficult to compare across deployment graphs. We propose a contract-driven QoE auditing framework: each service graph G is evaluated under a set of human-interpretable experience contracts C, yielding a contract-level satisfaction vector Q(G, C). We show that (i) classical MOS regression is a special case with a degenerate contract set, (ii) contract-driven quality is more stable than MOS under graph view transformations (e.g., pooling by system vs. by system type), and (iii) the effective sample complexity of learning contracts is governed by contract semantics rather than merely the dimensionality of C. We instantiate the framework on URGENT2024 MOS (6.9k speech utterances with raw rating vectors) and SingMOS v1 (7,981 singing clips; 80 systems). On URGENT, we train a contract-aware neural auditor on self-supervised WavLM embeddings; on SingMOS, we perform contract-driven graph auditing using released rating vectors and metadata without decoding audio. Empirically, our auditor matches strong MOS predictors in MOS accuracy while providing calibrated contract probabilities; on SingMOS, Q(G, C) exhibits substantially smaller cross-view drift than raw MOS and graph-only baselines; on URGENT, difficulty curves reveal that mis-specified ‚Äúsimple‚Äù contracts can be harder to learn than richer but better aligned contract sets.\nüì• Save to Zotero üìÑ Download PDF\nHierarchical matrix approximability of inverse of convection dominated finite element matrices Authors: Arthur Saunier, Leo Agelas, Ani Anciaux Sedrakian, Ibtihel Ben Gharbia, Xavier Claeys Venue: arXiv (2025)\nSeveral researchers have developed a rich toolbox of matrix compression techniques that exploit structure and redundancy in large matrices. Classical methods such as the block low-rank format and the Fast Multipole Method make it possible to manipulate very large systems by representing them in a reduced form. Among the most sophisticated tools in this area are hierarchical matrices (H-matrices), which exploit local properties of the underlying kernel or operator to approximate matrix blocks by low-rank factors, organized in a recursive hierarchy. H-matrices offer a flexible and scalable framework, yielding nearly linear complexity in both storage and computation. Hierarchical matrix techniques, originally developed for boundary integral equations, have recently been applied to matrices stemming from the discretization of advection-dominated problems. However, their effectiveness is limited by the loss of coercivity induced by convection phenomena, where traditional methods fail. Initial work by Le Borne addressed this by modifying the admissibility criterion for structured grids with constant convection, but challenges remain for more general grids and advection fields. In this work, we propose a novel partitioning strategy based on ‚Äúconvection tubes‚Äù, clusters aligned with the convection vector field. This method does not require a structured grid or constant convection, overcoming the limitations of previous approaches. We present both theoretical analyses and numerical experiments, that demonstrate the efficiency and robustness of our method for convection-dominated PDEs on unstructured grids. The approach builds on a P√©clet-robust Caccioppoli inequality, crucial for handling convection-dominated problems.\nüì• Save to Zotero üìÑ Download PDF\nYingMusic-Singer: Zero-shot Singing Voice Synthesis and Editing with Annotation-free Melody Guidance Authors: Junjie Zheng, Chunbo Hao, Guobin Ma, Xiaoyu Zhang, Gongyu Chen, Chaofan Ding, Zihao Chen, Lei Xie Venue: arXiv (2025)\nSinging Voice Synthesis (SVS) remains constrained in practical deployment due to its strong dependence on accurate phoneme-level alignment and manually annotated melody contours, requirements that are resource-intensive and hinder scalability. To overcome these limitations, we propose a melody-driven SVS framework capable of synthesizing arbitrary lyrics following any reference melody, without relying on phoneme-level alignment. Our method builds on a Diffusion Transformer (DiT) architecture, enhanced with a dedicated melody extraction module that derives melody representations directly from reference audio. To ensure robust melody encoding, we employ a teacher model to guide the optimization of the melody extractor, alongside an implicit alignment mechanism that enforces similarity distribution constraints for improved melodic stability and coherence. Additionally, we refine duration modeling using weakly annotated song data and introduce a Flow-GRPO reinforcement learning strategy with a multi-objective reward function to jointly enhance pronunciation clarity and melodic fidelity. Experiments show that our model achieves superior performance over existing approaches in both objective measures and subjective listening tests, especially in zero-shot and lyric adaptation settings, while maintaining high audio quality without manual annotation. This work offers a practical and scalable solution for advancing data-efficient singing voice synthesis. To support reproducibility, we release our inference code and model checkpoints.\nüì• Save to Zotero üìÑ Download PDF\nCIG-MAE: Cross-Modal Information-Guided Masked Autoencoder for Self-Supervised WiFi Sensing Authors: Gang Liu, Yanling Hao, Yixuan Zou Venue: arXiv (2025)\nHuman Action Recognition using WiFi Channel State Information (CSI) has emerged as an attractive alternative to vision-based methods due to its ubiquity, device-agnostic nature, and inherent privacy-preserving capabilities. However, the high cost of manual annotation and the limited scale of publicly available CSI datasets restrict the performance of supervised approaches. Self-supervised learning (SSL) offers a promising avenue, but existing contrastive paradigms rely on data augmentations that conflict with the physical semantics of radio signals and require large-batch training, making them poorly suited for CSI. To overcome these challenges, we introduce CIG-MAE ‚Äì a Cross-modal Information-Guided Masked Autoencoder ‚Äì that reconstructs both the amplitude and phase of CSI using a symmetric dual-stream architecture with a high masking ratio. Specifically, we propose an Adaptive Information-Guided Masking strategy that dynamically allocates attention to time-frequency regions with high information density to improve learning efficiency, and incorporate a Barlow Twins regularizer to align cross-modal representations without negative samples. Experiments on three public datasets show that CIG-MAE consistently outperforms SOTA SSL methods and even surpasses a fully supervised baseline, demonstrating superior data efficiency, robustness, and representation generalization.\nüì• Save to Zotero üìÑ Download PDF\nM3-TTS: Multi-modal DiT Alignment \u0026 Mel-latent for Zero-shot High-fidelity Speech Synthesis Authors: Xiaopeng Wang, Chunyu Qiang, Ruibo Fu, Zhengqi Wen, Xuefei Liu, Yukun Liu, Yuzhe Liang, Kang Yin, Yuankun Xie, Heng Xie, Chenxing Li, Chen Zhang, Changsheng Li Venue: arXiv (2025)\nNon-autoregressive (NAR) text-to-speech synthesis relies on length alignment between text sequences and audio representations, constraining naturalness and expressiveness. Existing methods depend on duration modeling or pseudo-alignment strategies that severely limit naturalness and computational efficiency. We propose M3-TTS, a concise and efficient NAR TTS paradigm based on multi-modal diffusion transformer (MM-DiT) architecture. M3-TTS employs joint diffusion transformer layers for cross-modal alignment, achieving stable monotonic alignment between variable-length text-speech sequences without pseudo-alignment requirements. Single diffusion transformer layers further enhance acoustic detail modeling. The framework integrates a mel-vae codec that provides 3* training acceleration. Experimental results on Seed-TTS and AISHELL-3 benchmarks demonstrate that M3-TTS achieves state-of-the-art NAR performance with the lowest word error rates (1.36% English, 1.31% Chinese) while maintaining competitive naturalness scores. Code and demos will be available at https://wwwwxp.github.io/M3-TTS.\nüì• Save to Zotero üìÑ Download PDF\nTimesNet-Gen: Deep Learning-based Site Specific Strong Motion Generation Authors: Baris Yilmaz, Bevan Deniz Cilgin, Erdem Akag√ºnd√ºz, Salih Tileylioglu Venue: arXiv (2025)\nEffective earthquake risk reduction relies on accurate site-specific evaluations. This requires models that can represent the influence of local site conditions on ground motion characteristics. In this context, data driven approaches that learn site controlled signatures from recorded ground motions offer a promising direction. We address strong ground motion generation from time-domain accelerometer records and introduce the TimesNet-Gen, a time-domain conditional generator. The approach uses a station specific latent bottleneck. We evaluate generation by comparing HVSR curves and fundamental site-frequency $f_0$ distributions between real and generated records per station, and summarize station specificity with a score based on the $f_0$ distribution confusion matrices. TimesNet-Gen achieves strong station-wise alignment and compares favorably with a spectrogram-based conditional VAE baseline for site-specific strong motion synthesis. Our codes are available via https://github.com/brsylmz23/TimesNet-Gen.\nüì• Save to Zotero üìÑ Download PDF\nTowards Ethical Multi-Agent Systems of Large Language Models: A Mechanistic Interpretability Perspective Authors: Jae Hee Lee, Anne Lauscher, Stefano V. Albrecht Venue: arXiv (2025)\nLarge language models (LLMs) have been widely deployed in various applications, often functioning as autonomous agents that interact with each other in multi-agent systems. While these systems have shown promise in enhancing capabilities and enabling complex tasks, they also pose significant ethical challenges. This position paper outlines a research agenda aimed at ensuring the ethical behavior of multi-agent systems of LLMs (MALMs) from the perspective of mechanistic interpretability. We identify three key research challenges: (i) developing comprehensive evaluation frameworks to assess ethical behavior at individual, interactional, and systemic levels; (ii) elucidating the internal mechanisms that give rise to emergent behaviors through mechanistic interpretability; and (iii) implementing targeted parameter-efficient alignment techniques to steer MALMs towards ethical behaviors without compromising their performance.\nüì• Save to Zotero üìÑ Download PDF\nA Chandra view of SPT-CL J0217-5014: a massive galaxy cluster at a cosmic intersection at z=0.53 Authors: Dan Hu, Shida Fan, Zhongsheng Yuan, Junjie Mao, Norbert Werner, Yuanyuan Su, Fran√ßois Mernier, Yuanyuan Zhao, Liyi Gu, Haiguang Xu Venue: arXiv (2025)\nGalaxy clusters trace the densest regions of the cosmic web and are crucial laboratories for studying the thermodynamic and chemical evolution of the intracluster medium (ICM). We present a Chandra study of the massive galaxy cluster SPT-CL J0217-5014 ($z \\sim 0.53$; $M_{\\rm 500} \\sim 3 \\times 10^{14}\\rm M_{\\odot}$), previously reported as a Swift serendipitous clusters with the highest Fe abundance ($\\sim 1.3\\pm 0.4$ $\\rm Z_{\\odot}$ within $\\sim 1‚Äô.7$) and a potentially disturbed morphology. The X-ray morphology reveals a disturbed ICM with a surface brightness edge at $\\sim 0‚Äô.26$ ($\\sim 100$ kpc) to the west and a tail-like feature extending towards the east. The best-fit metal abundance within 1‚Äô.5 ($\\sim 0.7\\rm R_{500}$) is $0.61_{-0.23}^{+0.26}\\rm Z_{\\odot}$. The derived central electron number density, entropy, and cooling time classify this system as a non-cool-core cluster, suggesting that merger activity has likely disrupted the possible pre-existing cool core. At larger radii ($\\sim 1‚Äô - 2‚Äô$), we detect excess X-ray emission to the south, spatially aligned with a filamentary distribution of red galaxies, indicating ongoing accretion along an intracluster filament. Based on the DESI DR9 cross-matched optical clusters and photometric redshifts, we identify three nearby, lower-mass clusters that likely trace the large-scale structures, suggesting that SPT-CL~J0217-5014 is the primary node of a dynamically active environment where past mergers and anisotropic accretion along cosmic filaments have shaped the present-day ICM.\nüì• Save to Zotero üìÑ Download PDF\nGeschlechts√ºbergreifende Maskulina im Sprachgebrauch Eine korpusbasierte Untersuchung zu lexemspezifischen Unterschieden Authors: Carolin Mueller-Spitzer, Samira Ochs, Jan Oliver Ruediger, Sascha Wolfer Venue: arXiv (2025)\nThis study examines the distribution and linguistic characteristics of generic masculines (GM) in contemporary German press texts. The use of masculine personal nouns to refer to mixed-gender groups or unspecified individuals has been widely debated in academia and the public, with con-flicting perspectives on its gender-neutrality. While psycholinguistic studies suggest that GM is more readily associated with male referents, corpus-based analyses of its actual use remain scarce. We investigate GM in a large corpus of press texts, focusing on lexeme-specific differences across dif-ferent types of personal nouns. We conducted manual annotations of the whole inflectional para-digm of 21 personal nouns, resulting in 6,195 annotated tokens. Our findings reveal considerable differences between lexical items, especially between passive role nouns and prestige-related per-sonal nouns. On a grammatical level, we find that GM occurs predominantly in the plural and in indefinite noun phrases. Furthermore, our data shows that GM is not primarily used to denote entire classes of people, as has been previously claimed. By providing an empirical insight into the use of GM in authentic written language, we contribute to a more nuanced understanding of its forms and manifestations. These findings provide a solid basis for aligning linguistic stimuli in psy-cholinguistic studies more closely with real-world language use.\nüì• Save to Zotero üìÑ Download PDF\nGenerative AI for Self-Adaptive Systems: State of the Art and Research Roadmap Authors: Jialong Li, Mingyue Zhang, Nianyu Li, Danny Weyns, Zhi Jin, Kenji Tei Venue: arXiv (2025)\nSelf-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this paper aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI‚Äôs within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.\nüì• Save to Zotero üìÑ Download PDF\nI2I-Bench: A Comprehensive Benchmark Suite for Image-to-Image Editing Models Authors: Juntong Wang, Jiarui Wang, Huiyu Duan, Jiaxiang Kang, Guangtao Zhai, Xiongkuo Min Venue: arXiv (2025)\nImage editing models are advancing rapidly, yet comprehensive evaluation remains a significant challenge. Existing image editing benchmarks generally suffer from limited task scopes, insufficient evaluation dimensions, and heavy reliance on manual annotations, which significantly constrain their scalability and practical applicability. To address this, we propose \\textbf{I2I-Bench}, a comprehensive benchmark for image-to-image editing models, which features (i) diverse tasks, encompassing 10 task categories across both single-image and multi-image editing tasks, (ii) comprehensive evaluation dimensions, including 30 decoupled and fine-grained evaluation dimensions with automated hybrid evaluation methods that integrate specialized tools and large multimodal models (LMMs), and (iii) rigorous alignment validation, justifying the consistency between our benchmark evaluations and human preferences. Using I2I-Bench, we benchmark numerous mainstream image editing models, investigating the gaps and trade-offs between editing models across various dimensions. We will open-source all components of I2I-Bench to facilitate future research.\nüì• Save to Zotero üìÑ Download PDF\nReflection-Satisfaction Tradeoff: Investigating Impact of Reflection on Student Engagement with AI-Generated Programming Hints Authors: Heeryung Choi, Tung Phung, Mengyan Wu, Adish Singla, Christopher Brooks Venue: arXiv (2025)\nGenerative AI tools, such as AI-generated hints, are increasingly integrated into programming education to offer timely, personalized support. However, little is known about how to effectively leverage these hints while ensuring autonomous and meaningful learning. One promising approach involves pairing AI-generated hints with reflection prompts, asking students to review and analyze their learning, when they request hints. This study investigates the interplay between AI-generated hints and different designs of reflection prompts in an online introductory programming course. We conducted a two-trial field experiment. In Trial 1, students were randomly assigned to receive prompts either before or after receiving hints, or no prompt at all. Each prompt also targeted one of three SRL phases: planning, monitoring, and evaluation. In Trial 2, we examined two types of prompt guidance: directed (offering more explicit and structured guidance) and open (offering more general and less constrained guidance). Findings show that students in the before-hint (RQ1), planning (RQ2), and directed (RQ3) prompt groups produced higher-quality reflections but reported lower satisfaction with AI-generated hints than those in other conditions. Immediate performance did not differ across conditions. This negative relationship between reflection quality and hint satisfaction aligns with previous work on student mental effort and satisfaction. Our results highlight the need to reconsider how AI models are trained and evaluated for education, as prioritizing user satisfaction can undermine deeper learning.\nüì• Save to Zotero üìÑ Download PDF\nUserSimCRS v2: Simulation-Based Evaluation for Conversational Recommender Systems Authors: Nolwenn Bernard, Krisztian Balog Venue: arXiv (2025)\nResources for simulation-based evaluation of conversational recommender systems (CRSs) are scarce. The UserSimCRS toolkit was introduced to address this gap. In this work, we present UserSimCRS v2, a significant upgrade aligning the toolkit with state-of-the-art research. Key extensions include an enhanced agenda-based user simulator, introduction of large language model-based simulators, integration for a wider range of CRSs and datasets, and new LLM-as-a-judge evaluation utilities. We demonstrate these extensions in a case study.\nüì• Save to Zotero üìÑ Download PDF\nSAM3-I: Segment Anything with Instructions Authors: Jingjing Li, Yue Feng, Yuchen Guo, Jincai Huang, Yongri Piao, Qi Bi, Miao Zhang, Xiaoqi Zhao, Qiang Chen, Shihao Zou, Wei Ji, Huchuan Lu, Li Cheng Venue: arXiv (2025)\nSegment Anything Model 3 (SAM3) has advanced open-vocabulary segmentation through promptable concept segmentation, allowing users to segment all instances corresponding to a given concept, typically specified with short noun-phrase (NP) prompts. While this marks the first integration of language-level concepts within the SAM family, real-world usage typically requires far richer expressions that include attributes, spatial relations, functionalities, actions, states, and even implicit reasoning over instances. Currently, SAM3 relies on external multi-modal agents to convert complex instructions into NPs and then conduct iterative mask filtering. However, these NP-level concepts remain overly coarse, often failing to precisely represent a specific instance. In this work, we present SAM3-I, an enhanced framework that unifies concept-level understanding and instruction-level reasoning within the SAM family. SAM3-I introduces an instruction-aware cascaded adaptation mechanism that progressively aligns expressive instruction semantics with SAM3‚Äôs existing vision-language representations, enabling direct instruction-following segmentation without sacrificing its original concept-driven capabilities. Furthermore, we design a structured instruction taxonomy spanning concept, simple, and complex levels, and develop a scalable data engine to construct a dataset with diverse instruction-mask pairs. Experiments show that SAM3-I delivers appealing performance, demonstrating that SAM3 can be effectively extended to follow natural-language instructions while preserving its strong concept grounding. We open-source SAM3-I and provide practical fine-tuning workflows, enabling researchers to adapt it to domain-specific applications. The source code is available here.\nüì• Save to Zotero üìÑ Download PDF\nInvestigating the H i mass-size relation using the Simba cosmological simulations Authors: Omphile Rabyang, Ed Elson Venue: arXiv (2025)\nObservational studies have established a remarkably tight power-law relationship between the H I masses and sizes of late-type galaxies, known as the H I mass-size relation. This relation has been shown to persist across various models of a galaxy‚Äôs H I surface density profile. Using the Simba cosmological simulations, we investigate the robustness of this relation under different feedback prescriptions, including cases where specific feedback mechanisms are absent. While the global properties of galaxies are significantly affected by changes in feedback, the H I mass-size relation remains intact. Moreover, its parameters consistently align with the best available empirical measurements. We analyze the H I mass distributions of galaxies and demonstrate that, regardless of the feedback scenario, galaxies within a given H I mass bin exhibit outer H I radial profiles well approximated by an exponential function. Furthermore, the exponential decline rate remains remarkably similar across different physical prescriptions. We attribute the persistence of the H I mass-size relation to this inherent self-similarity in the H I mass distributions.\nüì• Save to Zotero üìÑ Download PDF\nDiffusion Fine-Tuning via Reparameterized Policy Gradient of the Soft Q-Function Authors: Hyeongyu Kang, Jaewoo Lee, Woocheol Shin, Kiyoung Om, Jinkyoo Park Venue: arXiv (2025)\nDiffusion models excel at generating high-likelihood samples but often require alignment with downstream objectives. Existing fine-tuning methods for diffusion models significantly suffer from reward over-optimization, resulting in high-reward but unnatural samples and degraded diversity. To mitigate over-optimization, we propose \\textbf{Soft Q-based Diffusion Finetuning (SQDF)}, a novel KL-regularized RL method for diffusion alignment that applies a reparameterized policy gradient of a training-free, differentiable estimation of the soft Q-function. SQDF is further enhanced with three innovations: a discount factor for proper credit assignment in the denoising process, the integration of consistency models to refine Q-function estimates, and the use of an off-policy replay buffer to improve mode coverage and manage the reward-diversity trade-off. Our experiments demonstrate that SQDF achieves superior target rewards while preserving diversity in text-to-image alignment. Furthermore, in online black-box optimization, SQDF attains high sample efficiency while maintaining naturalness and diversity.\nüì• Save to Zotero üìÑ Download PDF\nADAPT: Learning Task Mixtures for Budget-Constrained Instruction Tuning Authors: Pritam Kadasi, Abhishek Upperwal, Mayank SIngh Venue: arXiv (2025)\nWe propose ADAPT, a meta-learning algorithm that \\emph{learns} task sampling proportions under an explicit token budget for multi-task instruction tuning. Instead of fixing task weights by hand, \\adapt{} maintains a continuous distribution over tasks and updates it via meta-gradients of a smooth worst-case validation objective, inducing an adaptive curriculum that allocates more tokens to useful tasks while avoiding collapse. We instantiate ADAPT on three $\\sim$1B-parameter open-weight LLMs (Gemma-3-1B, LLaMA-3.2-1B, Qwen-0.6B), training on 20 Natural Instructions task types under budgets of $1%$, $5%$, and $10%$ of the available supervised tokens, and compare against strong supervised fine-tuning baselines with uniform and size-proportional mixing. We conduct evaluations on 11 out-of-domain benchmarks spanning reasoning, reading comprehension, code generation, and instruction following, we find that ADAPT matches or slightly improves average downstream performance relative to the best static mixture, while using fewer effective training tokens and reallocating budget toward harder, benchmark-aligned tasks.\nüì• Save to Zotero üìÑ Download PDF\nGaussian Entropy Fields: Driving Adaptive Sparsity in 3D Gaussian Optimization Authors: Hong Kuang, Jianchen Liu Venue: arXiv (2025)\n3D Gaussian Splatting (3DGS) has emerged as a leading technique for novel view synthesis, demonstrating exceptional rendering efficiency. \\replaced[]{Well-reconstructed surfaces can be characterized by low configurational entropy, where dominant primitives clearly define surface geometry while redundant components are suppressed.}{The key insight is that well-reconstructed surfaces naturally exhibit low configurational entropy, where dominant primitives clearly define surface geometry while suppressing redundant components.} Three complementary technical contributions are introduced: (1) entropy-driven surface modeling via entropy minimization for low configurational entropy in primitive distributions; (2) adaptive spatial regularization using the Surface Neighborhood Redundancy Index (SNRI) and image entropy-guided weighting; (3) multi-scale geometric preservation through competitive cross-scale entropy alignment. Extensive experiments demonstrate that GEF achieves competitive geometric precision on DTU and T\u0026T benchmarks, while delivering superior rendering quality compared to existing methods on Mip-NeRF 360. Notably, superior Chamfer Distance (0.64) on DTU and F1 score (0.44) on T\u0026T are obtained, alongside the best SSIM (0.855) and LPIPS (0.136) among baselines on Mip-NeRF 360, validating the framework‚Äôs ability to enhance surface reconstruction accuracy without compromising photometric fidelity.\nüì• Save to Zotero üìÑ Download PDF\nCompletion by Comprehension: Guiding Code Generation with Multi-Granularity Understanding Authors: Xinkui Zhao, Rongkai Liu, Yifan Zhang, Chen Zhi, Lufei Zhang, Guanjie Cheng, Yueshen Xu, Shuiguang Deng, Jianwei Yin Venue: arXiv (2025)\nAs code completion task from function-level to repository-level, leveraging contextual information from large-scale codebases becomes a core challenge. However, existing retrieval-augmented generation (RAG) methods typically treat code as plain natural language, relying primarily on shallow semantic matching while overlooking structural semantics and code-specific dependencies. This limits their ability to capture control flow and underlying intent, ultimately constraining the quality of generated code. Therefore, we propose CoCo, a novel framework that enables code Completion by Comprehension of multi-granularity context from large-scale code repositories. CoCo employs static code analysis to extract structured context at the function, file, and project levels, capturing execution logic and semantic dependencies. It then adopts an graph-based multi-granularity context selection mechanism to filter out redundant information and remove noise. Consequently, the information is converted into natural language in a consistent manner, thereby functioning as explicit contextual prompts to guide subsequent code completion. Additionally, a structure-aware code re-ranker mechanism ensures alignment at both semantic and structural levels. Extensive experiments on CrossCodeEval and RepoEval benchmarks demonstrate that CoCo consistently surpasses state-of-the-art baselines, achieving up to 20.2% gains in EM. Moreover, the framework is model-agnostic and can be seamlessly integrated into existing methods, leading to significant performance.\nüì• Save to Zotero üìÑ Download PDF\nFLEX: Leveraging FPGA-CPU Synergy for Mixed-Cell-Height Legalization Acceleration Authors: Xingyu Liu, Jiawei Liang, Linfeng Du, Yipu Zhang, Chaofang Ma, Hanwei Fan, Jiang Xu, Wei Zhang Venue: arXiv (2025)\nIn this work, we present FLEX, an FPGA-CPU accelerator for mixed-cell-height legalization tasks. We address challenges from the following perspectives. First, we optimize the task assignment strategy and perform an efficient task partition between FPGA and CPU to exploit their complementary strengths. Second, a multi-granularity pipelining technique is employed to accelerate the most time-consuming step, finding optimal placement position (FOP), in legalization. At last, we particularly target the computationally intensive cell shifting process in FOP, optimizing the design to align it seamlessly with the multi-granularity pipelining framework for further speedup. Experimental results show that FLEX achieves up to 18.3x and 5.4x speedups compared to state-of-the-art CPU-GPU and multi-threaded CPU legalizers with better scalability, while improving legalization quality by 4% and 1%.\nüì• Save to Zotero üìÑ Download PDF\nPump Free Microwave-Optical Quantum Transduction Authors: Fangxin Li, Jaesung Heo, Zhaoyou Wang, Andrew P. Higginbotham, Alexander A. High, Liang Jiang Venue: arXiv (2025)\nDistributed quantum computing involves superconducting computation nodes operating at microwave frequencies, which are connected by long-distance transmission lines that transmit photons at optical frequencies. Quantum transduction, which coherently converts between microwave and optical (M-O) photons, is a critical component of such an architecture. Current approaches are hindered by the unavoidable problem of device heating due to the optical pump. In this work, we propose a pump-free scheme based on color centers that generates time-bin encoded M-O Bell pairs. Our scheme first creates spin-photon entanglement and then converts the spin state into a time-bin-encoded microwave photon using a strongly coupled Purcell-enhanced resonator. In our protocol, the microwave retrieval is heralded by detecting the microwave signal with a three-level transmon. We have analyzed the resulting Bell state fidelity and generation probability of this protocol. Our simulation shows that by combining a state-of-the-art spin-optical interface with our proposed strongly-coupled spin-microwave design, the pump-free scheme can generate M-O Bell pairs at a heralding rate exceeding one kilohertz with near-unity fidelity, which establishes the scheme as a promising source for M-O Bell pairs.\nüì• Save to Zotero üìÑ Download PDF\nTokenizing Buildings: A Transformer for Layout Synthesis Authors: Manuel Ladron de Guevara, Jinmo Rhee, Ardavan Bidgoli, Vaidas Razgaitis, Michael Bergin Venue: arXiv (2025)\nWe introduce Small Building Model (SBM), a Transformer-based architecture for layout synthesis in Building Information Modeling (BIM) scenes. We address the question of how to tokenize buildings by unifying heterogeneous feature sets of architectural elements into sequences while preserving compositional structure. Such feature sets are represented as a sparse attribute-feature matrix that captures room properties. We then design a unified embedding module that learns joint representations of categorical and possibly correlated continuous feature groups. Lastly, we train a single Transformer backbone in two modes: an encoder-only pathway that yields high-fidelity room embeddings, and an encoder-decoder pipeline for autoregressive prediction of room entities, referred to as Data-Driven Entity Prediction (DDEP). Experiments across retrieval and generative layout synthesis show that SBM learns compact room embeddings that reliably cluster by type and topology, enabling strong semantic retrieval. In DDEP mode, SBM produces functionally sound layouts, with fewer collisions and boundary violations and improved navigability.\nüì• Save to Zotero üìÑ Download PDF\nThe initial-to-final-state inverse problem with unbounded potentials and Strichartz estimates Authors: Pedro Caro, Alberto Ruiz Venue: arXiv (2025)\nThe initial-to-final-state inverse problem consists in determining a quantum Hamiltonian assuming the knowledge of the state of the system at some fixed time, for every initial state. We formulated this problem to establish a theoretical framework that would explain the viability of data-driven prediction in quantum mechanics. In a previous work, we analysed this inverse problem for Hamiltonians of the form $-Œî+ V$ with an electric potential $V = V({\\rm t}, {\\rm x})$, and we showed that uniqueness holds whenever the potentials are bounded and decay super-exponentially at infinity. In this paper, we extend this result for unbounded potentials. One of the key steps consists in proving a family of suitable Strichartz estimates ‚Äì including the corresponding endpoint of Keel and Tao. In the context of the inverse Calder√≥n problem this family of inequalities corresponds to the Carleman inequality proved by Kenig, Ruiz and Sogge. Haberman showed that this inequality can be also retrieved as an embedding of a suitable Bourgain space. The corresponding Bourgain space in our context do not capture the mixed-norm Lebesgue spaces of Strichartz inequalities. In this paper, we give a counterexample that justifies this fact, and shows the limitations of Bourgain spaces to address the initial-to-final-state inverse problem.\nüì• Save to Zotero üìÑ Download PDF\nTerahertz Fourier Ptychographic Imaging Authors: Pitambar Mukherjee, Vivek Kumar, Frederic Fauquet, Amaury Badon, Damien Bigourd, Kedar Khare, Sylvain Gigan, Patrick Mounaix Venue: arXiv (2025)\nHigh-resolution imaging in the terahertz (THz) spectral range remains fundamentally constrained by the limited numerical apertures of currently existing state-of-the-art imagers, which restricts its applicability across many fields, such as imaging in complex media or nondestructive testing. To address this challenge, we introduce a proof-of-concept implementation of THz Fourier Ptychographic imaging to enhance spatial resolution without requiring extensive hardware modifications. Our method employs a motorized kinematic mirror to generate a sequence of controlled, multi-angle plane-wave illuminations, with each resulting oblique-illumination intensity image encoding a limited portion of the spatial-frequency content of the target imaging sample. These measurements are combined in the Fourier domain using an aberration-corrected iterative phase-retrieval algorithm integrated with an efficient illumination calibration scheme, which enables the reconstruction of resolution-enhanced amplitude and phase images through the synthetic expansion of the effective numerical aperture. Our work establishes a robust framework for high-resolution THz imaging and paves the way for a wide array of applications in materials characterization, spectroscopy, and non-destructive evaluation.\nüì• Save to Zotero üìÑ Download PDF\nDemultiplexing through a multimode fiber using chip-scale diffractive neural networks Authors: Qian Zhang, Haoyi Yu, Jie Zhang, Yuedi Zhang, Chao Meng, Jiali Sun, Yu Miao, Qiming Zhang, Min Gu, Juergen W Czarske Venue: arXiv (2025)\nIn today‚Äôs information age, advanced fiber optic transmission technology is of paramount importance. Multimode fibers (MMFs) using space-division multiplexing (SDM) are promising for improved transmission capacity, connection flexibility, and security of data. However, the complex transmission characteristics of MMFs significantly hinder precise mode demultiplexing. Conventional approaches, including holographic measurements, phase retrieval algorithms, photonic lanterns, and multiplane light conversion, are limited by system complexity, size, and flexibility. In this paper, we demonstrate for the first time a purely optical, chip-scale AI solution for high-mode isolation, speed-of-light demultiplexing of MMF modes using a three-dimensional diffractive neural network (DNN). The DNN is trained with synthetic modal data and fabricated using two-photon nanolithography. It features a compact size of $120Œºm \\times 120Œºm \\times 80Œºm$ and a diffractive structure size of $1Œºm^{2}$ for the neurons at the hidden layers of the network. Experimentally, the DNN demultiplexer achieves a relative demultiplexing accuracy of over 80%. The AI approach of DNN allows for flexible design and overcomes the size and performance limitations of digital-optical demultiplexers. This work paves the way for compact, low-latency optical processors for high-performance demultiplexers and enables scalable, chip-integrated solutions for next-generation fiber optic networks.\nüì• Save to Zotero üìÑ Download PDF\nThe Endocranial Cast of Khirtharia (Artiodactyla, Raoellidae) Provides New Insights into the Earliest Evolution of the Cetacean Brain Authors: Mohd Waqas, Thierry Smith, Rajendra Rana, Maeva J Orliac Venue: arXiv (2025)\nIntroduction: Raoellidae are small artiodactyls retrieved from the middle Eocene of Asia (ca. -47 Ma) and closely related to stem Cetacea. Morphological observations of their endocranial structures allow for outlining some of the early steps of the evolutionary history of the cetacean brain. The external features of the brain and associated sinuses of Raoellidae are so far only documented by the virtual reconstruction of the endocast based on specimens of the species Indohyus indirae. These specimens are however too deformed to fully access the external morphology, surface area, and volume measurements of the brain. Methods: We bring here new elements to the picture of the raoellid brain by an investigation of the internal structures of an exceptionally well-preserved cranium collected from the Kalakot area (Jammu and Kashmir, India) referred to the species Khirtharia inflata. Micro-CT scan investigation and virtual reconstruction of the endocast and associated sinuses of this specimen provide crucial additional data about the morphological diversity within Raoellidae as well as reliable linear, surfaces, and volumes measurements, allowing for quantitative studies. Results: We show that, like I. indirae, the brain of K. inflata exhibits a mosaic of features observed in earliest artiodactyls: a small neocortex with simple folding pattern, widely exposed midbrain, and relatively long cerebellum. But, like Indohyus, the brain of Khirtharia shows unique derived characters also observed in stem cetaceans: narrow elongated olfactory bulbs and peduncles, posterior location of the braincase in the cranium, and complex network of blood vessels around the cerebellum. The volume of the brain relative to body mass of K. inflata is markedly small when compared to other early artiodactyls. Conclusion: We show here that cetaceans that nowadays have the second biggest brain after humans derive from a group of animals that had a lower-than-average expected brain size. This is probably a side effect of the adaptation to aquatic life. Conversely, this very small brain size relative to body mass might be another line of evidence supporting the aquatic habits in raoellids.\nüì• Save to Zotero üìÑ Download PDF\nPrompt2Craft: Generating Functional Craft Assemblies with LLMs Authors: Vitor Hideyo Isume, Takuya Kiyokawa, Natsuki Yamanobe, Yukiyasu Domae, Weiwei Wan, Kensuke Harada Venue: arXiv (2025)\nInspired by traditional handmade crafts, where a person improvises assemblies based on the available objects, we formally introduce the Craft Assembly Task. It is a robotic assembly task that involves building an accurate representation of a given target object using the available objects, which do not directly correspond to its parts. In this work, we focus on selecting the subset of available objects for the final craft, when the given input is an RGB image of the target in the wild. We use a mask segmentation neural network to identify visible parts, followed by retrieving labeled template meshes. These meshes undergo pose optimization to determine the most suitable template. Then, we propose to simplify the parts of the transformed template mesh to primitive shapes like cuboids or cylinders. Finally, we design a search algorithm to find correspondences in the scene based on local and global proportions. We develop baselines for comparison that consider all possible combinations, and choose the highest scoring combination for common metrics used in foreground maps and mask accuracy. Our approach achieves comparable results to the baselines for two different scenes, and we show qualitative results for an implementation in a real-world scenario.\nüì• Save to Zotero üìÑ Download PDF\nVideoMem: Enhancing Ultra-Long Video Understanding via Adaptive Memory Management Authors: Hongbo Jin, Qingyuan Wang, Wenhao Zhang, Yang Liu, Sijie Cheng Venue: arXiv (2025)\nUltra long video understanding remains an open challenge, as existing vision language models (VLMs) falter on such content due to limited context length and inefficient long term memory retention. To address this, recent works have attempted to construct external knowledge bases and corresponding retrieval agumented generation (RAG) systems, yet these incur enormous storage and computational overhead. In this paper, we propose VideoMem, a novel framework that pioneers models long video understanding as a sequential generation task via adaptive memory management. Specifically, VideoMem dynamically updates a global memory buffer, which adaptively retains critical information while discarding redundant content across the video timeline. To efficiently train VLMs for such long-term tasks, VideoMem integrates the Progressive Grouped Relative Policy Optimization (PRPO) algorithm, equipped with two core modules: Progressive State Propagation (PSP) adaptively retains valid current states, propagates them to the next rollout step, and gradually narrows the model exploration space. Temporal Cascading Reward (TCR) further alleviates reward sparsity, improving sample utilization and accelerating convergence. Extensive experiments demonstrate that VideoMem significantly outperforms existing open-source models across diverse benchmarks for ultra-long video understanding tasks.\nüì• Save to Zotero üìÑ Download PDF\nContinuously tunable single-photon level nonlinearity with Rydberg state wave-function engineering Authors: Biao Xu, Gen-Sheng Ye, Yue Chang, Tao Shi, Lin Li Venue: arXiv (2025)\nExtending optical nonlinearity into the extremely weak light regime is at the heart of quantum optics, since it enables the efficient generation of photonic entanglement and implementation of photonic quantum logic gate. Here, we demonstrate the capability for continuously tunable single-photon level nonlinearity, enabled by precise control of Rydberg interaction over two orders of magnitude, through the use of microwave-assisted wave-function engineering. To characterize this nonlinearity, light storage and retrieval protocol utilizing Rydberg electromagnetically induced transparency is employed, and the quantum statistics of the retrieved photons are analyzed. As a first application, we demonstrate our protocol can speed up the preparation of single photons in low-lying Rydberg states by a factor of up to ~ 40. Our work holds the potential to accelerate quantum operations and to improve the circuit depth and connectivity in Rydberg systems, representing a crucial step towards scalable quantum information processing with Rydberg atoms.\nüì• Save to Zotero üìÑ Download PDF\nMSME: A Multi-Stage Multi-Expert Framework for Zero-Shot Stance Detection Authors: Yuanshuo Zhang, Aohua Li, Bo Chen, Jingbo Sun, Xiaobing Zhao Venue: arXiv (2025)\nLLM-based approaches have recently achieved impressive results in zero-shot stance detection. However, they still struggle in complex real-world scenarios, where stance understanding requires dynamic background knowledge, target definitions involve compound entities or events that must be explicitly linked to stance labels, and rhetorical devices such as irony often obscure the author‚Äôs actual intent. To address these challenges, we propose MSME, a Multi-Stage, Multi-Expert framework for zero-shot stance detection. MSME consists of three stages: (1) Knowledge Preparation, where relevant background knowledge is retrieved and stance labels are clarified; (2) Expert Reasoning, involving three specialized modules-Knowledge Expert distills salient facts and reasons from a knowledge perspective, Label Expert refines stance labels and reasons accordingly, and Pragmatic Expert detects rhetorical cues such as irony to infer intent from a pragmatic angle; (3) Decision Aggregation, where a Meta-Judge integrates all expert analyses to produce the final stance prediction. Experiments on three public datasets show that MSME achieves state-of-the-art performance across the board.\nüì• Save to Zotero üìÑ Download PDF\nRelative Wavefront Error Correction Over a 2.4 km Free-Space Optical Link via Machine Learning Authors: Nathan K. Long, Benjamin P. Dix-Matthews, Alex Frost, John Wallis, Ziqing Wang, Kenneth J. Grant, Robert Malaney Venue: arXiv (2025)\nIn coherent optical communication across turbulent atmospheric channels, reference beacons can be multiplexed with information-encoded signals during transmission. In this case, it is commonly assumed that the wavefront distortion of the two is equivalent. In contrast to this assumption, we present experimental evidence of relative wavefront errors (WFEs) between polarization-multiplexed reference beacons and signals, after passing through a 2.4 km atmospheric link. We develop machine learning-based wavefront correction algorithms to compensate for observed WFEs, via phase retrieval, resulting in up to a 2/3 reduction in the relative phase error variance. Further, we analyze the excess noise contributions from relative WFEs in the context of continuous-variable quantum key distribution (CV-QKD), where our findings suggest that if future CV-QKD implementations employ wavefront correction algorithms similar to those reported here, an order of magnitude increase in secure key rates may be forthcoming.\nüì• Save to Zotero üìÑ Download PDF\nGovBench: Benchmarking LLM Agents for Real-World Data Governance Workflows Authors: Zhou Liu, Zhaoyang Han, Guochen Yan, Hao Liang, Bohan Zeng, Xing Chen, Yuanfeng Song, Wentao Zhang Venue: arXiv (2025)\nData governance ensures data quality, security, and compliance through policies and standards, a critical foundation for scaling modern AI development. Recently, large language models (LLMs) have emerged as a promising solution for automating data governance by translating user intent into executable transformation code. However, existing benchmarks for automated data science often emphasize snippet-level coding or high-level analytics, failing to capture the unique challenge of data governance: ensuring the correctness and quality of the data itself. To bridge this gap, we introduce GovBench, a benchmark featuring 150 diverse tasks grounded in real-world scenarios, built on data from actual cases. GovBench employs a novel ‚Äúreversed-objective‚Äù methodology to synthesize realistic noise and utilizes rigorous metrics to assess end-to-end pipeline reliability. Our analysis on GovBench reveals that current models struggle with complex, multi-step workflows and lack robust error-correction mechanisms. Consequently, we propose DataGovAgent, a framework utilizing a Planner-Executor-Evaluator architecture that integrates constraint-based planning, retrieval-augmented generation, and sandboxed feedback-driven debugging. Experimental results show that DataGovAgent significantly boosts the Average Task Score (ATS) on complex tasks from 39.7 to 54.9 and reduces debugging iterations by over 77.9 percent compared to general-purpose baselines.\nüì• Save to Zotero üìÑ Download PDF\nThe Personalization Paradox: Semantic Loss vs. Reasoning Gains in Agentic AI Q\u0026A Authors: Satyajit Movidi, Stephen Russell Venue: arXiv (2025)\nAIVisor, an agentic retrieval-augmented LLM for student advising, was used to examine how personalization affects system performance across multiple evaluation dimensions. Using twelve authentic advising questions intentionally designed to stress lexical precision, we compared ten personalized and non-personalized system configurations and analyzed outcomes with a Linear Mixed-Effects Model across lexical (BLEU, ROUGE-L), semantic (METEOR, BERTScore), and grounding (RAGAS) metrics. Results showed a consistent trade-off: personalization reliably improved reasoning quality and grounding, yet introduced a significant negative interaction on semantic similarity, driven not by poorer answers but by the limits of current metrics, which penalize meaningful personalized deviations from generic reference texts. This reveals a structural flaw in prevailing LLM evaluation methods, which are ill-suited for assessing user-specific responses. The fully integrated personalized configuration produced the highest overall gains, suggesting that personalization can enhance system effectiveness when evaluated with appropriate multidimensional metrics. Overall, the study demonstrates that personalization produces metric-dependent shifts rather than uniform improvements and provides a methodological foundation for more transparent and robust personalization in agentic AI.\nüì• Save to Zotero üìÑ Download PDF\nA Retrieval-Augmented Generation Approach to Extracting Algorithmic Logic from Neural Networks Authors: Waleed Khalid, Dmitry Ignatov, Radu Timofte Venue: arXiv (2025)\nReusing existing neural-network components is central to research efficiency, yet discovering, extracting, and validating such modules across thousands of open-source repositories remains difficult. We introduce NN-RAG, a retrieval-augmented generation system that converts large, heterogeneous PyTorch codebases into a searchable and executable library of validated neural modules. Unlike conventional code search or clone-detection tools, NN-RAG performs scope-aware dependency resolution, import-preserving reconstruction, and validator-gated promotion ‚Äì ensuring that every retrieved block is scope-closed, compilable, and runnable. Applied to 19 major repositories, the pipeline extracted 1,289 candidate blocks, validated 941 (73.0%), and demonstrated that over 80% are structurally unique. Through multi-level de-duplication (exact, lexical, structural), we find that NN-RAG contributes the overwhelming majority of unique architectures to the LEMUR dataset, supplying approximately 72% of all novel network structures. Beyond quantity, NN-RAG uniquely enables cross-repository migration of architectural patterns, automatically identifying reusable modules in one project and regenerating them, dependency-complete, in another context. To our knowledge, no other open-source system provides this capability at scale. The framework‚Äôs neutral specifications further allow optional integration with language models for synthesis or dataset registration without redistributing third-party code. Overall, NN-RAG transforms fragmented vision code into a reproducible, provenance-tracked substrate for algorithmic discovery, offering a first open-source solution that both quantifies and expands the diversity of executable neural architectures across repositories.\nüì• Save to Zotero üìÑ Download PDF\nText-Only Training for Image Captioning with Retrieval Augmentation and Modality Gap Correction Authors: Rui Fonseca, Bruno Martins, Gil Rocha Venue: arXiv (2025)\nImage captioning has drawn considerable attention from the natural language processing and computer vision fields. Aiming to reduce the reliance on curated data, several studies have explored image captioning without any humanly-annotated image-text pairs for training, although existing methods are still outperformed by fully supervised approaches. This paper proposes TOMCap, i.e., an improved text-only training method that performs captioning without the need for aligned image-caption pairs. The method is based on prompting a pre-trained language model decoder with information derived from a CLIP representation, after undergoing a process to reduce the modality gap. We specifically tested the combined use of retrieved examples of captions, and latent vector representations, to guide the generation process. Through extensive experiments, we show that TOMCap outperforms other training-free and text-only methods. We also analyze the impact of different choices regarding the configuration of the retrieval-augmentation and modality gap reduction components.\nüì• Save to Zotero üìÑ Download PDF\nEvaluating Long-Context Reasoning in LLM-Based WebAgents Authors: Andy Chung, Yichi Zhang, Kaixiang Lin, Aditya Rawal, Qiaozi Gao, Joyce Chai Venue: arXiv (2025)\nAs large language model (LLM)-based agents become increasingly integrated into daily digital interactions, their ability to reason across long interaction histories becomes crucial for providing personalized and contextually aware assistance. However, the performance of these agents in long context scenarios, particularly for action-taking WebAgents operating in realistic web environments, remains largely unexplored. This paper introduces a benchmark for evaluating long context reasoning capabilities of WebAgents through sequentially dependent subtasks that require retrieval and application of information from extended interaction histories. We develop a novel evaluation framework that simulates multi-session user interactions by injecting irrelevant task trajectories between dependent subtasks, creating contexts ranging from 25,000 to 150,000 tokens. Through extensive evaluation of four popular models, Claude-3.7, GPT-4.1, Llama 4, and o4-mini, we observe a dramatic performance degradation as context length increases, with success rates dropping from 40-50% in baseline conditions to less than 10% in long context scenarios. Our detailed error analysis reveals that agents primarily fail due to getting stuck in loops and losing track of original task objectives. We further propose an implicit RAG approach that provides modest improvements by generating task-relevant summaries, though fundamental limitations in long context reasoning persist. These findings highlight critical challenges for deploying WebAgents in realistic, long-term user interaction scenarios and provide insights for developing more robust agent architectures capable of maintaining coherent task execution across extended contexts.\nüì• Save to Zotero üìÑ Download PDF\nSQuARE: Structured Query \u0026 Adaptive Retrieval Engine For Tabular Formats Authors: Chinmay Gondhalekar, Urjitkumar Patel, Fang-Chun Yeh Venue: arXiv (2025)\nAccurate question answering over real spreadsheets remains difficult due to multirow headers, merged cells, and unit annotations that disrupt naive chunking, while rigid SQL views fail on files lacking consistent schemas. We present SQuARE, a hybrid retrieval framework with sheet-level, complexity-aware routing. It computes a continuous score based on header depth and merge density, then routes queries either through structure-preserving chunk retrieval or SQL over an automatically constructed relational representation. A lightweight agent supervises retrieval, refinement, or combination of results across both paths when confidence is low. This design maintains header hierarchies, time labels, and units, ensuring that returned values are faithful to the original cells and straightforward to verify. Evaluated on multi-header corporate balance sheets, a heavily merged World Bank workbook, and diverse public datasets, SQuARE consistently surpasses single-strategy baselines and ChatGPT-4o on both retrieval precision and end-to-end answer accuracy while keeping latency predictable. By decoupling retrieval from model choice, the system is compatible with emerging tabular foundation models and offers a practical bridge toward a more robust table understanding.\nüì• Save to Zotero üìÑ Download PDF\nCRAFT-E: A Neuro-Symbolic Framework for Embodied Affordance Grounding Authors: Zhou Chen, Joe Lin, Carson Bulgin, Sathyanarayanan N. Aakur Venue: arXiv (2025)\nAssistive robots operating in unstructured environments must understand not only what objects are, but what they can be used for. This requires grounding language-based action queries to objects that both afford the requested function and can be physically retrieved. Existing approaches often rely on black-box models or fixed affordance labels, limiting transparency, controllability, and reliability for human-facing applications. We introduce CRAFT-E, a modular neuro-symbolic framework that composes a structured verb-property-object knowledge graph with visual-language alignment and energy-based grasp reasoning. The system generates interpretable grounding paths that expose the factors influencing object selection and incorporates grasp feasibility as an integral part of affordance inference. We further construct a benchmark dataset with unified annotations for verb-object compatibility, segmentation, and grasp candidates, and deploy the full pipeline on a physical robot. CRAFT-E achieves competitive performance in static scenes, ImageNet-based functional retrieval, and real-world trials involving 20 verbs and 39 objects. The framework remains robust under perceptual noise and provides transparent, component-level diagnostics. By coupling symbolic reasoning with embodied perception, CRAFT-E offers an interpretable and customizable alternative to end-to-end models for affordance-grounded object selection, supporting trustworthy decision-making in assistive robotic systems.\nüì• Save to Zotero üìÑ Download PDF\nOn GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral Authors: Wenlong Deng, Yushu Li, Boying Gong, Yi Ren, Christos Thrampoulidis, Xiaoxiao Li Venue: arXiv (2025)\nTool-integrated (TI) reinforcement learning (RL) enables large language models (LLMs) to perform multi-step reasoning by interacting with external tools such as search engines and retrievers. Group Relative Policy Optimization (GRPO), exemplified by the recent Search-R1, offers fast convergence and a value-free formulation that makes it appealing for this setting, yet consistently suffers from training collapse. We identify Lazy Likelihood Displacement (LLD), a systematic reduction or stagnation in the likelihood of both correct and incorrect responses, as the core mechanism driving this failure. LLD emerges early and triggers a self-reinforcing LLD Death Spiral, where declining likelihood leads to low-confidence responses, inflating gradients, and ultimately causing collapse. We empirically characterize this process across models on a Search-R1-style, search-integrated question answering task, revealing a consistent three-phase trajectory: early stagnation, steady decay, and accelerated collapse. To address this, we propose a lightweight likelihood-preserving regularization LLDS for GRPO that activates only when a trajectory‚Äôs likelihood decreases, and regularizes only the tokens responsible. This fine-grained structure mitigates LLD with minimal interference to optimization. Across seven open-domain and multi-hop QA benchmarks, our method stabilizes training, prevents gradient explosion, and yields substantial performance improvements, including +37.8% gains on Qwen2.5-3B and +32.0% gains on Qwen2.5-7B. Our results establish LLD as a fundamental bottleneck in GRPO-based TIRL and provide a practical path toward stable, scalable training of tool-integrated LLM.\nüì• Save to Zotero üìÑ Download PDF\nHigh-Resolution Retrieval of Atmospheric Boundary Layers with Nonstationary Gaussian Processes Authors: Haoran Xiong, Paytsar Muradyan, Christopher J. Geoga Venue: arXiv (2025)\nThe atmospheric boundary layer (ABL) plays a critical role in governing turbulent exchanges of momentum, heat moisture, and trace gases between the Earth‚Äôs surface and the free atmosphere, thereby influencing meteorological phenomena, air quality, and climate processes. Accurate and temporally continuous characterization of the ABL structure and height evolution is crucial for both scientific understanding and practical applications. High-resolution retrievals of the ABL height from vertical velocity measurements is challenging because it is often estimated using empirical thresholds applied to profiles of vertical velocity variance or related turbulence diagnostics at each measurement altitude, which can suffer from limited sampling and sensitivity to noise. To address these limitations, this work employs nonstationary Gaussian process (GP) modeling to more effectively capture the spatio-temporal dependence structure in the data, enabling high-quality ‚Äì and, if desired, high-resolution ‚Äì estimates of the ABL height without reliance on ad-hoc parameter tuning. By leveraging Vecchia approximations, the proposed method can be applied to large-scale datasets, and example applications using full-day vertical velocity profiles comprising approximately $5$M measurements are presented.\nüì• Save to Zotero üìÑ Download PDF\nFractal Aggregate Aerosols in the Virga Cloud Code II: Exploring the Effects of Key Cloud Parameters in Warm Neptune, Hot Jupiter and Brown Dwarf Atmospheres Authors: Matt G. Lodge, Sarah E. Moran, Hannah R. Wakeford, Zoe M. Leinhardt, Mark S. Marley Venue: arXiv (2025)\nAerosols and clouds are expected to be ubiquitous in exoplanet and brown dwarf atmospheres, where they can have a significant impact on transmission and emission spectra. The cloud code Virga is capable of quickly modeling cloud particle sizes as a function of altitude, and has recently been updated to include functionality for aggregates (ranging from very fluffy chains to compact fractals). We analyze the effect that these aggregates have on transmission spectra for typical warm Neptune and hot Jupiter environments, as well as their effect on emission spectra for an L-type brown dwarf, over the wavelength range 0.3 - 15 um. We find significant, measurable differences in spectra when particle shape is changed (particularly the shortest wavelengths where particle morphology strongly affects the scattering slope). We provide some intuitive rules for how non-absorbing aggregates impact spectra: when particle sizes are small compared to the wavelength of light, the most elongated and chain-like particles have the highest opacities. When particles are large, the inverse is true (the most compact shapes have the highest opacities). We present an explanation for these effects in terms of the dynamics of how the particles form and move through the atmosphere, as well as in terms of fundamental optics theory. Given the significant impact that particle shape can have on spectra, we strongly encourage the community to include shape as a free parameter in future case studies, atmospheric models, and retrievals.\nüì• Save to Zotero üìÑ Download PDF\nTighter constraints on the atmosphere of GJ 436 b from combined high-resolution CARMENES and CRIRES$^+$ observations Authors: A. Pel√°ez-Torres, A. S√°nchez-L√≥pez, L. Nortmann, M. L√≥pez-Puertas, E. Gonz√°lez-√Ålvarez, H. M. Tabernero, C. Jiang, D. Revilla, G. Morello, J. Orell-Miquel, E. Pall√©, P. J. Amado, J. A. Caballero, I. Ribas, A. Reiners, A. Quirrenbach, D. Cont, S. Dreizler, A. Fern√°ndez-Mart√≠n, A. P. Hatzes, Th. Henning, F. Lesjak, D. Montes, A. Schweizer, T. Trifonov, F. Yan Venue: arXiv (2025)\nWe aim to study the atmospheric properties of the warm Neptune GJ 436 b by combining a set of five transit events observed with the CARMENES spectrograph with one transit from CRIRES$^+$ so as to provide the most constrained results possible at high resolution. We removed telluric and stellar signals from the data using SysRem and potential planetary signals were investigated using the cross-correlation technique. Following standard procedures for undetected species, we performed injection recovery tests and Bayesian retrievals to place constraints on the detectability of the main near-infrared absorbers. In addition, we simulated ELT/ANDES observations by computing end-to-end in silico datasets with EXoPLORE. No molecular signals were detected in the atmosphere of GJ 436 b, which is consistent with previous studies. Combined CARMENES-CRIRES$^+$ injection-recovery and Bayesian retrieval analyses show that the atmosphere is likely covered by high-altitude clouds ($\\sim$ $1$ mbar) at low and intermediate metallicities or, alternatively, is very metal-rich ($\\gtrsim$ $900\\times$ solar), which would suppress spectral features without invoking clouds. Simulations of ELT/ANDES observations suggest a boost by nearly an order of magnitude to the upper limit in the photon-limited regime, reaching $0.1$ mbar at $10$-$300\\times$ solar metallicities. The joint analysis of all useful transit observations from CARMENES and CRIRES$^+$ provides the most stringent constraints to date on the atmospheric properties of GJ 436 b. Complementary CCF-based and retrieval approaches consistently indicate that the atmosphere is either cloudy or highly metal enriched. Any weak near-infrared absorption lines, if present, are likely to be below current detection limits. However, according to our simulations, these features may be revealed with ELT/ANDES even in single-transit observations.\nüì• Save to Zotero üìÑ Download PDF\nRELIC: Interactive Video World Model with Long-Horizon Memory Authors: Yicong Hong, Yiqun Mei, Chongjian Ge, Yiran Xu, Yang Zhou, Sai Bi, Yannick Hold-Geoffroy, Mike Roberts, Matthew Fisher, Eli Shechtman, Kalyan Sunkavalli, Feng Liu, Zhengqi Li, Hao Tan Venue: arXiv (2025)\nA truly interactive world model requires three key ingredients: real-time long-horizon streaming, consistent spatial memory, and precise user control. However, most existing approaches address only one of these aspects in isolation, as achieving all three simultaneously is highly challenging-for example, long-term memory mechanisms often degrade real-time performance. In this work, we present RELIC, a unified framework that tackles these three challenges altogether. Given a single image and a text description, RELIC enables memory-aware, long-duration exploration of arbitrary scenes in real time. Built upon recent autoregressive video-diffusion distillation techniques, our model represents long-horizon memory using highly compressed historical latent tokens encoded with both relative actions and absolute camera poses within the KV cache. This compact, camera-aware memory structure supports implicit 3D-consistent content retrieval and enforces long-term coherence with minimal computational overhead. In parallel, we fine-tune a bidirectional teacher video model to generate sequences beyond its original 5-second training horizon, and transform it into a causal student generator using a new memory-efficient self-forcing paradigm that enables full-context distillation over long-duration teacher as well as long student self-rollouts. Implemented as a 14B-parameter model and trained on a curated Unreal Engine-rendered dataset, RELIC achieves real-time generation at 16 FPS while demonstrating more accurate action following, more stable long-horizon streaming, and more robust spatial-memory retrieval compared with prior work. These capabilities establish RELIC as a strong foundation for the next generation of interactive world modeling.\nüì• Save to Zotero üìÑ Download PDF\nLearning to Comparison-Shop Authors: Jie Tang, Daochen Zha, Xin Liu, Huiji Gao, Liwei He, Stephanie Moyerman, Sanjeev Katariya Venue: arXiv (2025)\nIn online marketplaces like Airbnb, users frequently engage in comparison shopping before making purchase decisions. Despite the prevalence of this behavior, a significant disconnect persists between mainstream e-commerce search engines and users‚Äô comparison needs. Traditional ranking models often evaluate items in isolation, disregarding the context in which users compare multiple items on a search results page. While recent advances in deep learning have sought to improve ranking accuracy, diversity, and fairness by encoding listwise context, the challenge of aligning search rankings with user comparison shopping behavior remains inadequately addressed. In this paper, we propose a novel ranking architecture - Learning-to-Comparison-Shop (LTCS) System - that explicitly models and learns users‚Äô comparison shopping behaviors. Through extensive offline and online experiments, we demonstrate that our approach yields statistically significant gains in key business metrics - improving NDCG by 1.7% and boosting booking conversion rate by 0.6% in A/B testing - while also enhancing user experience. We also compare our model against state-of-the-art approaches and demonstrate that LTCS significantly outperforms them.\nüì• Save to Zotero üìÑ Download PDF\nA Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA) Authors: Saurav Prateek Venue: arXiv (2025)\nThe advancement in Large Language Models has driven the creation of complex agentic systems, such as Deep Research Agents (DRAs), to overcome the limitations of static Retrieval Augmented Generation (RAG) pipelines in handling complex, multi-turn research tasks. This paper introduces the Static Deep Research Agent (Static-DRA), a novel solution built upon a configurable and hierarchical Tree-based static workflow. The core contribution is the integration of two user-tunable parameters, Depth and Breadth, which provide granular control over the research intensity. This design allows end-users to consciously balance the desired quality and comprehensiveness of the research report against the associated computational cost of Large Language Model (LLM) interactions. The agent‚Äôs architecture, comprising Supervisor, Independent, and Worker agents, facilitates effective multi-hop information retrieval and parallel sub-topic investigation. We evaluate the Static-DRA against the established DeepResearch Bench using the RACE (Reference-based Adaptive Criteria-driven Evaluation) framework. Configured with a depth of 2 and a breadth of 5, and powered by the gemini-2.5-pro model, the agent achieved an overall score of 34.72. Our experiments validate that increasing the configured Depth and Breadth parameters results in a more in-depth research process and a correspondingly higher evaluation score. The Static-DRA offers a pragmatic and resource-aware solution, empowering users with transparent control over the deep research process. The entire source code, outputs and benchmark results are open-sourced at https://github.com/SauravP97/Static-Deep-Research/\nüì• Save to Zotero üìÑ Download PDF\nMechDetect: Detecting Data-Dependent Errors Authors: Philipp Jung, Nicholas Chandler, Sebastian J√§ger, Felix Biessmann Venue: arXiv (2025)\nData quality monitoring is a core challenge in modern information processing systems. While many approaches to detect data errors or shifts have been proposed, few studies investigate the mechanisms governing error generation. We argue that knowing how errors were generated can be key to tracing and fixing them. In this study, we build on existing work in the statistics literature on missing values and propose MechDetect, a simple algorithm to investigate error generation mechanisms. Given a tabular data set and a corresponding error mask, the algorithm estimates whether or not the errors depend on the data using machine learning models. Our work extends established approaches to detect mechanisms underlying missing values and can be readily applied to other error types, provided that an error mask is available. We demonstrate the effectiveness of MechDetect in experiments on established benchmark datasets.\nüì• Save to Zotero üìÑ Download PDF\nOmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance Authors: Lei Zhang, Diwen Zheng, Kaixin Bai, Zhenshan Bing, Zoltan-Csaba Marton, Zhaopeng Chen, Alois Christian Knoll, Jianwei Zhang Venue: arXiv (2025)\nDexterous grasp generation aims to produce grasp poses that align with task requirements and human interpretable grasp semantics. However, achieving semantically controllable dexterous grasp synthesis remains highly challenging due to the lack of unified modeling of multiple semantic dimensions, including grasp taxonomy, contact semantics, and functional affordance. To address these limitations, we present OmniDexVLG, a multimodal, semantics aware grasp generation framework capable of producing structurally diverse and semantically coherent dexterous grasps under joint language and visual guidance. Our approach begins with OmniDexDataGen, a semantic rich dexterous grasp dataset generation pipeline that integrates grasp taxonomy guided configuration sampling, functional affordance contact point sampling, taxonomy aware differential force closure grasp sampling, and physics based optimization and validation, enabling systematic coverage of diverse grasp types. We further introduce OmniDexReasoner, a multimodal grasp type semantic reasoning module that leverages multi agent collaboration, retrieval augmented generation, and chain of thought reasoning to infer grasp related semantics and generate high quality annotations that align language instructions with task specific grasp intent. Building upon these components, we develop a unified Vision Language Grasping generation model that explicitly incorporates grasp taxonomy, contact structure, and functional affordance semantics, enabling fine grained control over grasp synthesis from natural language instructions. Extensive experiments in simulation and real world object grasping and ablation studies demonstrate that our method substantially outperforms state of the art approaches in terms of grasp diversity, contact semantic diversity, functional affordance diversity, and semantic consistency.\nüì• Save to Zotero üìÑ Download PDF\nAlgorithms for Boolean Matrix Factorization using Integer Programming and Heuristics Authors: Christos Kolomvakis, Thomas Bobille, Arnaud Vandaele, Nicolas Gillis Venue: arXiv (2025)\nBoolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. Unlike binary matrix factorization based on standard arithmetic, BMF employs the Boolean OR and AND operations for the matrix product, which improves interpretability and reduces the approximation error. It is also used in role mining and computer vision. In this paper, we first propose algorithms for BMF that perform alternating optimization (AO) of the factor matrices, where each subproblem is solved via integer programming (IP). We then design different approaches to further enhance AO-based algorithms by selecting an optimal subset of rank-one factors from multiple runs. To address the scalability limits of IP-based methods, we introduce new greedy and local-search heuristics. We also construct a new C++ data structure for Boolean vectors and matrices that is significantly faster than existing ones and is of independent interest, allowing our heuristics to scale to large datasets. We illustrate the performance of all our proposed methods and compare them with the state of the art on various real datasets, both with and without missing data, including applications in topic modeling and imaging.\nüì• Save to Zotero üìÑ Download PDF\nThe enshittification of online search? Privacy and quality of Google, Bing and Apple in coding advice Authors: Konrad Kollnig Venue: arXiv (2025)\nEven though currently being challenged by ChatGPT and other large-language models (LLMs), Google Search remains one of the primary means for many individuals to find information on the internet. Interestingly, the way that we retrieve information on the web has hardly changed ever since Google was established in 1998, raising concerns as to Google‚Äôs dominance in search and lack of competition. If the market for search was sufficiently competitive, then we should probably see a steady increase in search quality over time as well as alternative approaches to the Google‚Äôs approach to search. However, hardly any research has so far looked at search quality, which is a key facet of a competitive market, especially not over time. In this report, we conducted a relatively large-scale quantitative comparison of search quality of 1,467 search queries relating to coding advice in October 2023. We focus on coding advice because the study of general search quality is difficult, with the aim of learning more about the assessment of search quality and motivating follow-up research into this important topic. We evaluate the search quality of Google Search, Microsoft Bing, and Apple Search, with a special emphasis on Apple Search, a widely used search engine that has never been explored in previous research. For the assessment of search quality, we use two independent metrics of search quality: 1) the number of trackers on the first search result, as a measure of privacy in web search, and 2) the average rank of the first Stack Overflow search result, under the assumption that Stack Overflow gives the best coding advice. Our results suggest that the privacy of search results is higher on Bing than on Google and Apple. Similarly, the quality of coding advice ‚Äì as measured by the average rank of Stack Overflow ‚Äì was highest on Bing.\nüì• Save to Zotero üìÑ Download PDF\nAR-Med: Automated Relevance Enhancement in Medical Search via LLM-Driven Information Augmentation Authors: Chuyue Wang, Jie Feng, Yuxi Wu, Hang Zhang, Zhiguo Fan, Bing Cheng, Wei Lin Venue: arXiv (2025)\nAccurate and reliable search on online healthcare platforms is critical for user safety and service efficacy. Traditional methods, however, often fail to comprehend complex and nuanced user queries, limiting their effectiveness. Large language models (LLMs) present a promising solution, offering powerful semantic understanding to bridge this gap. Despite their potential, deploying LLMs in this high-stakes domain is fraught with challenges, including factual hallucinations, specialized knowledge gaps, and high operational costs. To overcome these barriers, we introduce \\textbf{AR-Med}, a novel framework for \\textbf{A}utomated \\textbf{R}elevance assessment for \\textbf{Med}ical search that has been successfully deployed at scale on the Online Medical Delivery Platforms. AR-Med grounds LLM reasoning in verified medical knowledge through a retrieval-augmented approach, ensuring high accuracy and reliability. To enable efficient online service, we design a practical knowledge distillation scheme that compresses large teacher models into compact yet powerful student models. We also introduce LocalQSMed, a multi-expert annotated benchmark developed to guide model iteration and ensure strong alignment between offline and online performance. Extensive experiments show AR-Med achieves an offline accuracy of over 93%, a 24% absolute improvement over the original online system, and delivers significant gains in online relevance and user satisfaction. Our work presents a practical and scalable blueprint for developing trustworthy, LLM-powered systems in real-world healthcare applications.\nüì• Save to Zotero üìÑ Download PDF\nDINO-RotateMatch: A Rotation-Aware Deep Framework for Robust Image Matching in Large-Scale 3D Reconstruction Authors: Kaichen Zhang, Tianxiang Sheng, Xuanming Shi Venue: arXiv (2025)\nThis paper presents DINO-RotateMatch, a deep-learning framework designed to address the chal lenges of image matching in large-scale 3D reconstruction from unstructured Internet images. The method integrates a dataset-adaptive image pairing strategy with rotation-aware keypoint extraction and matching. DINO is employed to retrieve semantically relevant image pairs in large collections, while rotation-based augmentation captures orientation-dependent local features using ALIKED and Light Glue. Experiments on the Kaggle Image Matching Challenge 2025 demonstrate consistent improve ments in mean Average Accuracy (mAA), achieving a Silver Award (47th of 943 teams). The results confirm that combining self-supervised global descriptors with rotation-enhanced local matching offers a robust and scalable solution for large-scale 3D reconstruction.\nüì• Save to Zotero üìÑ Download PDF\nMemVerse: Multimodal Memory for Lifelong Learning Agents Authors: Junming Liu, Yifei Sun, Weihua Cheng, Haodong Lei, Yirong Chen, Licheng Wen, Xuemeng Yang, Daocheng Fu, Pinlong Cai, Nianchen Deng, Yi Yu, Shuyue Hu, Botian Shi, Ding Wang Venue: arXiv (2025)\nDespite rapid progress in large-scale language and vision models, AI agents still suffer from a fundamental limitation: they cannot remember. Without reliable memory, agents catastrophically forget past experiences, struggle with long-horizon reasoning, and fail to operate coherently in multimodal or interactive environments. We introduce MemVerse, a model-agnostic, plug-and-play memory framework that bridges fast parametric recall with hierarchical retrieval-based memory, enabling scalable and adaptive multimodal intelligence. MemVerse maintains short-term memory for recent context while transforming raw multimodal experiences into structured long-term memories organized as hierarchical knowledge graphs. This design supports continual consolidation, adaptive forgetting, and bounded memory growth. To handle real-time demands, MemVerse introduces a periodic distillation mechanism that compresses essential knowledge from long-term memory into the parametric model, allowing fast, differentiable recall while preserving interpretability. Extensive experiments demonstrate that MemVerse significantly improves multimodal reasoning and continual learning efficiency, empowering agents to remember, adapt, and reason coherently across extended interactions.\nüì• Save to Zotero üìÑ Download PDF\nMemory-Guided Point Cloud Completion for Dental Reconstruction Authors: Jianan Sun, Yukang Huang, Dongzhihan Wang, Mingyu Fan Venue: arXiv (2025)\nPartial dental point clouds often suffer from large missing regions caused by occlusion and limited scanning views, which bias encoder-only global features and force decoders to hallucinate structures. We propose a retrieval-augmented framework for tooth completion that integrates a prototype memory into standard encoder‚Äìdecoder pipelines. After encoding a partial input into a global descriptor, the model retrieves the nearest manifold prototype from a learnable memory and fuses it with the query feature through confidence-gated weighting before decoding. The memory is optimized end-to-end and self-organizes into reusable tooth-shape prototypes without requiring tooth-position labels, thereby providing structural priors that stabilize missing-region inference and free decoder capacity for detail recovery. The module is plug-and-play and compatible with common completion backbones, while keeping the same training losses. Experiments on a self-processed Teeth3DS benchmark demonstrate consistent improvements in Chamfer Distance, with visualizations showing sharper cusps, ridges, and interproximal transitions. Our approach provides a simple yet effective way to exploit cross-sample regularities for more accurate and faithful dental point-cloud completion.\nüì• Save to Zotero üìÑ Download PDF\nTowards Object-centric Understanding for Instructional Videos Authors: Wenliang Guo, Yu Kong Venue: arXiv (2025)\nUnderstanding procedural activities is crucial for developing future assistive AI that can reason about complex real-world tasks. Existing action-centric methods struggle with the flexibility of real procedures, where step order varies depending on object states. In this work, we propose to shift the focus to an object-centric paradigm by regarding actions as mechanisms that drive state transitions. To advance this direction, we introduce Object-IVQA, a long-form instructional video benchmark with 107 videos and 514 open-ended question-answer pairs annotated with temporally grounded evidence. The benchmark evaluates four dimensions of object-centric reasoning, including state evolution, precondition verification, counterfactual reasoning and mistake recognition. We further propose an agent framework that orchestrates object-centric planning, perception, analysis and generation tools, enabling explicit evidence retrieval and multi-hop reasoning across disjoint segments. Experiments show that existing large vision-language models struggle in object-level recognition and reasoning, whereas our framework achieves substantially improvement.\nüì• Save to Zotero üìÑ Download PDF\nüîç linguistics On the treatment of thermal effects in the equation of state on neutron star merger remnants Authors: Davide Guerra, Milton Ruiz, Michele Pasquali, Pablo Cerd√°-Dur√°n, Arnau Rios, Jos√© A. Font Venue: arXiv (2025)\nWe present results from long-term, numerical-relativity simulations of binary neutron star mergers modeled using both, fully tabulated, finite-temperature, equations of state and their corresponding hybrid representations. The simulations extend up to 150 ms which allows us to assess the role of the treatment of finite-temperature effects on the dynamics of the hypermassive neutron star remnant. Our study focuses on the analysis of the spectra of the post-merger gravitational-wave signals and on how these are affected by the treatment of thermal effects in the two EOS representations. Our simulations highlight distinct differences in the GW frequency evolution related to the thermal modeling of the EOS, demonstrating that deviations from established quasi-universal relations become significant at late post-merger phases. Furthermore, we investigate the stability of the HMNS against convection. Employing both the Ledoux criterion, necessary condition for the development of convective instabilities, and the Solberg-H√∏iland criterion, a generalized criterion for axisymmetric perturbations based on a combined analysis of the Brunt-V√§is√§l√§ frequency and of the epicyclic frequency, we show that differential rotation and thermal stratification in the HMNS give rise to local (yet sustained) convective patterns that persist beyond 100 ms after merger. Those convective patterns, while substantially different between tabulated and hybrid EOS treatments, trigger the the excitation of inertial modes with frequencies smaller than those attained by the fundamental quadrupolar mode, and are potentially within reach of third-generation GW detectors. The late-time excitation of inertial modes, previously reported in studies based on hybrid EOS, is fully supported by the tabulated, finite-temperature EOS simulations presented here, which account for thermal effects in a more consistent way.\nüì• Save to Zotero üìÑ Download PDF\nLight-X: Generative 4D Video Rendering with Camera and Illumination Control Authors: Tianqi Liu, Zhaoxi Chen, Zihao Huang, Shaocong Xu, Saining Zhang, Chongjie Ye, Bohan Li, Zhiguo Cao, Wei Li, Hao Zhao, Ziwei Liu Venue: arXiv (2025)\nRecent advances in illumination control extend image-based methods to video, yet still facing a trade-off between lighting fidelity and temporal consistency. Moving beyond relighting, a key step toward generative modeling of real-world scenes is the joint control of camera trajectory and illumination, since visual dynamics are inherently shaped by both geometry and lighting. To this end, we present Light-X, a video generation framework that enables controllable rendering from monocular videos with both viewpoint and illumination control. 1) We propose a disentangled design that decouples geometry and lighting signals: geometry and motion are captured via dynamic point clouds projected along user-defined camera trajectories, while illumination cues are provided by a relit frame consistently projected into the same geometry. These explicit, fine-grained cues enable effective disentanglement and guide high-quality illumination. 2) To address the lack of paired multi-view and multi-illumination videos, we introduce Light-Syn, a degradation-based pipeline with inverse-mapping that synthesizes training pairs from in-the-wild monocular footage. This strategy yields a dataset covering static, dynamic, and AI-generated scenes, ensuring robust training. Extensive experiments show that Light-X outperforms baseline methods in joint camera-illumination control and surpasses prior video relighting methods under both text- and background-conditioned settings.\nüì• Save to Zotero üìÑ Download PDF\nShadowDraw: From Any Object to Shadow-Drawing Compositional Art Authors: Rundong Luo, Noah Snavely, Wei-Chiu Ma Venue: arXiv (2025)\nWe introduce ShadowDraw, a framework that transforms ordinary 3D objects into shadow-drawing compositional art. Given a 3D object, our system predicts scene parameters, including object pose and lighting, together with a partial line drawing, such that the cast shadow completes the drawing into a recognizable image. To this end, we optimize scene configurations to reveal meaningful shadows, employ shadow strokes to guide line drawing generation, and adopt automatic evaluation to enforce shadow-drawing coherence and visual quality. Experiments show that ShadowDraw produces compelling results across diverse inputs, from real-world scans and curated datasets to generative assets, and naturally extends to multi-object scenes, animations, and physical deployments. Our work provides a practical pipeline for creating shadow-drawing art and broadens the design space of computational visual art, bridging the gap between algorithmic design and artistic storytelling. Check out our project page https://red-fairy.github.io/ShadowDraw/ for more results and an end-to-end real-world demonstration of our pipeline!\nüì• Save to Zotero üìÑ Download PDF\nEvoIR: Towards All-in-One Image Restoration via Evolutionary Frequency Modulation Authors: Jiaqi Ma, Shengkai Hu, Jun Wan, Jiaxing Huang, Lefei Zhang, Salman Khan Venue: arXiv (2025)\nAll-in-One Image Restoration (AiOIR) tasks often involve diverse degradation that require robust and versatile strategies. However, most existing approaches typically lack explicit frequency modeling and rely on fixed or heuristic optimization schedules, which limit the generalization across heterogeneous degradation. To address these limitations, we propose EvoIR, an AiOIR-specific framework that introduces evolutionary frequency modulation for dynamic and adaptive image restoration. Specifically, EvoIR employs the Frequency-Modulated Module (FMM) that decomposes features into high- and low-frequency branches in an explicit manner and adaptively modulates them to enhance both structural fidelity and fine-grained details. Central to EvoIR, an Evolutionary Optimization Strategy (EOS) iteratively adjusts frequency-aware objectives through a population-based evolutionary process, dynamically balancing structural accuracy and perceptual fidelity. Its evolutionary guidance further mitigates gradient conflicts across degradation and accelerates convergence. By synergizing FMM and EOS, EvoIR yields greater improvements than using either component alone, underscoring their complementary roles. Extensive experiments on multiple benchmarks demonstrate that EvoIR outperforms state-of-the-art AiOIR methods.\nüì• Save to Zotero üìÑ Download PDF\nSA-IQA: Redefining Image Quality Assessment for Spatial Aesthetics with Multi-Dimensional Rewards Authors: Yuan Gao, Jin Song Venue: arXiv (2025)\nIn recent years, Image Quality Assessment (IQA) for AI-generated images (AIGI) has advanced rapidly; however, existing methods primarily target portraits and artistic images, lacking a systematic evaluation of interior scenes. We introduce Spatial Aesthetics, a paradigm that assesses the aesthetic quality of interior images along four dimensions: layout, harmony, lighting, and distortion. We construct SA-BENCH, the first benchmark for spatial aesthetics, comprising 18,000 images and 50,000 precise annotations. Employing SA-BENCH, we systematically evaluate current IQA methodologies and develop SA-IQA, through MLLM fine-tuning and a multidimensional fusion approach, as a comprehensive reward framework for assessing spatial aesthetics. We apply SA-IQA to two downstream tasks: (1) serving as a reward signal integrated with GRPO reinforcement learning to optimize the AIGC generation pipeline, and (2) Best-of-N selection to filter high-quality images and improve generation quality. Experiments indicate that SA-IQA significantly outperforms existing methods on SA-BENCH, setting a new standard for spatial aesthetics evaluation. Code and dataset will be open-sourced to advance research and applications in this domain.\nüì• Save to Zotero üìÑ Download PDF\nFrom Generated Human Videos to Physically Plausible Robot Trajectories Authors: James Ni, Zekai Wang, Wei Lin, Amir Bar, Yann LeCun, Trevor Darrell, Jitendra Malik, Roei Herzig Venue: arXiv (2025)\nVideo generation models are rapidly improving in their ability to synthesize human actions in novel contexts, holding the potential to serve as high-level planners for contextual robot control. To realize this potential, a key research question remains open: how can a humanoid execute the human actions from generated videos in a zero-shot manner? This challenge arises because generated videos are often noisy and exhibit morphological distortions that make direct imitation difficult compared to real video. To address this, we introduce a two-stage pipeline. First, we lift video pixels into a 4D human representation and then retarget to the humanoid morphology. Second, we propose GenMimic-a physics-aware reinforcement learning policy conditioned on 3D keypoints, and trained with symmetry regularization and keypoint-weighted tracking rewards. As a result, GenMimic can mimic human actions from noisy, generated videos. We curate GenMimicBench, a synthetic human-motion dataset generated using two video generation models across a spectrum of actions and contexts, establishing a benchmark for assessing zero-shot generalization and policy robustness. Extensive experiments demonstrate improvements over strong baselines in simulation and confirm coherent, physically stable motion tracking on a Unitree G1 humanoid robot without fine-tuning. This work offers a promising path to realizing the potential of video generation models as high-level policies for robot control.\nüì• Save to Zotero üìÑ Download PDF\nFoundations of Diffusion Models in General State Spaces: A Self-Contained Introduction Authors: Vincent Pauline, Tobias H√∂ppe, Kirill Neklyudov, Alexander Tong, Stefan Bauer, Andrea Dittadi Venue: arXiv (2025)\nAlthough diffusion models now occupy a central place in generative modeling, introductory treatments commonly assume Euclidean data and seldom clarify their connection to discrete-state analogues. This article is a self-contained primer on diffusion over general state spaces, unifying continuous domains and discrete/categorical structures under one lens. We develop the discrete-time view (forward noising via Markov kernels and learned reverse dynamics) alongside its continuous-time limits ‚Äì stochastic differential equations (SDEs) in $\\mathbb{R}^d$ and continuous-time Markov chains (CTMCs) on finite alphabets ‚Äì and derive the associated Fokker‚ÄìPlanck and master equations. A common variational treatment yields the ELBO that underpins standard training losses. We make explicit how forward corruption choices ‚Äì Gaussian processes in continuous spaces and structured categorical transition kernels (uniform, masking/absorbing and more) in discrete spaces ‚Äì shape reverse dynamics and the ELBO. The presentation is layered for three audiences: newcomers seeking a self-contained intuitive introduction; diffusion practitioners wanting a global theoretical synthesis; and continuous-diffusion experts looking for an analogy-first path into discrete diffusion. The result is a unified roadmap to modern diffusion methodology across continuous domains and discrete sequences, highlighting a compact set of reusable proofs, identities, and core theoretical principles.\nüì• Save to Zotero üìÑ Download PDF\nThe Geometry of Intelligence: Deterministic Functional Topology as a Foundation for Real-World Perception Authors: Eduardo Di Santi Venue: arXiv (2025)\nReal-world physical processes do not generate arbitrary variability: their signals concentrate on compact and low-variability subsets of functional space. This geometric structure enables rapid generalization from a few examples in both biological and artificial systems. This work develops a deterministic functional-topological framework in which the set of valid realizations of a physical phenomenon forms a compact perceptual manifold with stable invariants and a finite Hausdorff radius. We show that the boundaries of this manifold can be discovered in a fully self-supervised manner through Monte Carlo sampling, even when the governing equations of the system are unknown. We provide theoretical guarantees, practical estimators of knowledge boundaries, and empirical validations across three domains: electromechanical railway point machines, electrochemical battery discharge curves, and physiological ECG signals. Our results demonstrate that deterministic functional topology offers a unified mathematical foundation for perception, representation, and world-model construction, explaining why biological learners and self-supervised AI models can generalize from limited observations.\nüì• Save to Zotero üìÑ Download PDF\nFirst Study of the Nuclear Response to Fast Hadrons via Angular Correlations between Pions and Slow Protons in Electron-Nucleus Scattering Authors: S. J. Paul, M. Arratia, H. Hakobyan, W. Brooks, A. Acar, P. Achenbach, J. S. Alvarado, W. R. Armstrong, N. A. Baltzell, L. Barion, M. Bashkanov, M. Battaglieri, F. Benmokhtar, A. Bianconi, A. S. Biselli, F. Boss√π, S. Boiarinov, K. -T. Brinkmann, W. J. Briscoe, V. Burkert, T. Cao, D. S. Carman, P. Chatagnon, H. Chinchay, G. Ciullo, P. L. Cole, A. D‚ÄôAngelo, N. Dashyan, R. De Vita, A. Deur, S. Diehl, C. Djalali, R. Dupre, H. Egiyan, A. El Alaoui, L. Elouadrhiri, P. Eugenio, M. Farooq, S. Fegan, A. Filippi, C. Fogler, G. Gavalian, G. P. Gilfoyle, R. W. Gothe, B. Gualtieri, M. Hattawy, F. Hauenstein, T. B. Hayward, M. Hoballah, M. Holtrop, Yu-Chun Hung, Y. Ilieva, D. G. Ireland, E. L. Isupov, D. Jenkins, H. S. Jo, D. Keller, M. Khandaker, A. Kim, V. Klimenko, I. Korover, A. Kripko, V. Kubarovsky, L. Lanza, S. Lee, P. Lenisa, X. Li, D. Marchand, V. Mascagna, B. McKinnon, T. Mineeva, V. Mokeev, E. F. Molina Cardenas, C. Munoz Camacho, P. Nadel-Turonski, T. Nagorna, K. Neupane, S. Niccolai, G. Niculescu, M. Osipenko, A. I. Ostrovidov, M. Ouillon, P. Pandey, M. Paolone, L. L. Pappalardo, R. Paremuzyan, E. Pasyuk, W. Phelps, N. Pilleux, P. S. H. Vaishnavi, S. Polcher Rafael, L. Polizzi, J. W. Price, Y. Prok, A. Radic, T. Reed, J. Richards, M. Ripani, J. Ritman, G. Rosner, S. Schadmand, A. Schmidt, R. A. Schumacher, Y. Sharabian, S. Shrestha, E. Sidoretti, D. Sokhan, N. Sparveris, M. Spreafico, S. Stepanyan, I. I. Strakovsky, S. Strauch, M. Tenorio, F. Touchte Codjo, R. Tyson, M. Ungaro, S. Vallarino, C. Velasquez, L. Venturelli, H. Voskanyan, E. Voutier, Y. Wang, D. P. Watts, U. Weerasinghe, X. Wei, M. H. Wood, L. Xu, Z. Xu, M. Zurek Venue: arXiv (2025)\nWe report on the first measurement of angular correlations between high-energy pions and slow protons in electron-nucleus ($eA$) scattering, providing a new probe of how a nucleus responds to a fast-moving quark. The experiment employed the CLAS detector with a 5-GeV electron beam incident on deuterium, carbon, iron, and lead targets. For heavier nuclei, the pion-proton correlation function is more spread-out in azimuth than for lighter ones, and this effect is more pronounced in the $œÄp$ channel than in earlier $œÄœÄ$ studies. The proton-to-pion yield ratio likewise rises with nuclear mass, although the increase appears to saturate for the heaviest targets. These trends are qualitatively reproduced by state-of-the-art $eA$ event generators, including BeAGLE, eHIJING, and GiBUU, indicating that current descriptions of target fragmentation rest on sound theoretical footing. At the same time, the precision of our data exposes model-dependent discrepancies, delineating a clear path for future improvements in the treatment of cold-nuclear matter effects in $eA$ scattering.\nüì• Save to Zotero üìÑ Download PDF\nOMTRA: A Multi-Task Generative Model for Structure-Based Drug Design Authors: Ian Dunn, Liv Toft, Tyler Katz, Juhi Gupta, Riya Shah, Ramith Hettiarachchi, David R. Koes Venue: arXiv (2025)\nStructure-based drug design (SBDD) focuses on designing small-molecule ligands that bind to specific protein pockets. Computational methods are integral in modern SBDD workflows and often make use of virtual screening methods via docking or pharmacophore search. Modern generative modeling approaches have focused on improving novel ligand discovery by enabling de novo design. In this work, we recognize that these tasks share a common structure and can therefore be represented as different instantiations of a consistent generative modeling framework. We propose a unified approach in OMTRA, a multi-modal flow matching model that flexibly performs many tasks relevant to SBDD, including some with no analogue in conventional workflows. Additionally, we curate a dataset of 500M 3D molecular conformers, complementing protein-ligand data and expanding the chemical diversity available for training. OMTRA obtains state of the art performance on pocket-conditioned de novo design and docking; however, the effects of large-scale pretraining and multi-task training are modest. All code, trained models, and dataset for reproducing this work are available at https://github.com/gnina/OMTRA\nüì• Save to Zotero üìÑ Download PDF\nObject Reconstruction under Occlusion with Generative Priors and Contact-induced Constraints Authors: Minghan Zhu, Zhiyi Wang, Qihang Sun, Maani Ghaffari, Michael Posa Venue: arXiv (2025)\nObject geometry is key information for robot manipulation. Yet, object reconstruction is a challenging task because cameras only capture partial observations of objects, especially when occlusion occurs. In this paper, we leverage two extra sources of information to reduce the ambiguity of vision signals. First, generative models learn priors of the shapes of commonly seen objects, allowing us to make reasonable guesses of the unseen part of geometry. Second, contact information, which can be obtained from videos and physical interactions, provides sparse constraints on the boundary of the geometry. We combine the two sources of information through contact-guided 3D generation. The guidance formulation is inspired by drag-based editing in generative models. Experiments on synthetic and real-world data show that our approach improves the reconstruction compared to pure 3D generation and contact-based optimization.\nüì• Save to Zotero üìÑ Download PDF\nBulletTime: Decoupled Control of Time and Camera Pose for Video Generation Authors: Yiming Wang, Qihang Zhang, Shengqu Cai, Tong Wu, Jan Ackermann, Zhengfei Kuang, Yang Zheng, Frano Rajiƒç, Siyu Tang, Gordon Wetzstein Venue: arXiv (2025)\nEmerging video diffusion models achieve high visual fidelity but fundamentally couple scene dynamics with camera motion, limiting their ability to provide precise spatial and temporal control. We introduce a 4D-controllable video diffusion framework that explicitly decouples scene dynamics from camera pose, enabling fine-grained manipulation of both scene dynamics and camera viewpoint. Our framework takes continuous world-time sequences and camera trajectories as conditioning inputs, injecting them into the video diffusion model through a 4D positional encoding in the attention layer and adaptive normalizations for feature modulation. To train this model, we curate a unique dataset in which temporal and camera variations are independently parameterized; this dataset will be made public. Experiments show that our model achieves robust real-world 4D control across diverse timing patterns and camera trajectories, while preserving high generation quality and outperforming prior work in controllability. See our website for video results: https://19reborn.github.io/Bullet4D/\nüì• Save to Zotero üìÑ Download PDF\nThermodynamic universality across dissipative quantum phase transitions Authors: Laetitia P. Bettmann, Artur M. Lacerda, Mark T. Mitchison, John Goold Venue: arXiv (2025)\nWe study finite-time driving across second-order dissipative quantum phase transitions described by Lindblad dynamics. We show that the nonadiabatic entropy production, which quantifies deviations from the instantaneous nonequilibrium steady state, exhibits universal power-law scaling with the ramp duration in analogy to the Kibble-Zurek mechanism for closed systems. This establishes the universality of irreversible dissipation induced by driving an open quantum system near criticality. Furthermore, in systems described by bosonic Gaussian states, our scaling laws predict that the nonadiabatic entropy production is independent of driving speed to leading order, revealing a distinctive feature of Gaussian dissipative quantum phase transitions. We validate these analytical predictions in the thermodynamic limit of the driven-dissipative Dicke model and via finite-size scaling in the open Kerr model. Our results establish a general framework for understanding universal nonequilibrium response and thermodynamic irreversibility in critical open quantum systems.\nüì• Save to Zotero üìÑ Download PDF\nCarrollian holographic duals are non-local Authors: Jordan Cotler, Prateksh Dhivakar, Kristan Jensen Venue: arXiv (2025)\nMapping the $S$-matrix of a generic theory of flat space gravity coupled to matter to correlation functions of a putative Carrollian dual, we show that bulk interactions imply boundary non-locality.\nüì• Save to Zotero üìÑ Download PDF\nHybrid Quantum-Classical Autoencoders for Unsupervised Network Intrusion Detection Authors: Mohammad Arif Rasyidi, Omar Alhussein, Sami Muhaidat, Ernesto Damiani Venue: arXiv (2025)\nUnsupervised anomaly-based intrusion detection requires models that can generalize to attack patterns not observed during training. This work presents the first large-scale evaluation of hybrid quantum-classical (HQC) autoencoders for this task. We construct a unified experimental framework that iterates over key quantum design choices, including quantum-layer placement, measurement approach, variational and non-variational formulations, and latent-space regularization. Experiments across three benchmark NIDS datasets show that HQC autoencoders can match or exceed classical performance in their best configurations, although they exhibit higher sensitivity to architectural decisions. Under zero-day evaluation, well-configured HQC models provide stronger and more stable generalization than classical and supervised baselines. Simulated gate-noise experiments reveal early performance degradation, indicating the need for noise-aware HQC designs. These results provide the first data-driven characterization of HQC autoencoder behavior for network intrusion detection and outline key factors that govern their practical viability. All experiment code and configurations are available at https://github.com/arasyi/hqcae-network-intrusion-detection.\nüì• Save to Zotero üìÑ Download PDF\nPerceptually-Minimal Color Optimization for Web Accessibility: A Multi-Phase Constrained Approach Authors: Lalitha A R Venue: arXiv (2025)\nWeb accessibility guidelines require sufficient color contrast between text and backgrounds; yet, manually adjusting colors often necessitates significant visual deviation, compromising vital brand aesthetics. We present a novel, multi-phase optimization approach for automatically generating WCAG-compliant colors while minimizing perceptual change to original design choices. Our method treats this as a constrained, non-linear optimization problem, utilizing the modern perceptually uniform OKLCH color space. Crucially, the optimization is constrained to preserve the original hue ($\\text{H}$) of the color, ensuring that modifications are strictly limited to necessary adjustments in lightness ($\\text{L}$) and chroma ($\\text{C}$). This is achieved through a three-phase sequence: binary search, gradient descent, and progressive constraint relaxation. Evaluation on a dataset of 10,000 procedurally generated color pairs demonstrates that the algorithm successfully resolves accessibility violations in $77.22%$ of cases, with $88.51%$ of successful corrections exhibiting imperceptible color difference ($ŒîE_{2000} \u003c 2.0$) as defined by standard perceptibility thresholds. The median perceptual change for successful adjustments is only $0.76\\ ŒîE_{2000}$, and the algorithm achieves this with a median processing time of $0.876\\text{ms}$ per color pair. The approach demonstrates that accessibility compliance and visual design integrity can be achieved simultaneously through a computationally efficient, perceptually-aware optimization that respects brand identity. The algorithm is publicly implemented in the open-source cm-colors Python library.\nüì• Save to Zotero üìÑ Download PDF\nAxionic tunneling from a topological Kondo insulator Authors: Saikat Banerjee, Anuva Aishwarya, Fei Liu, Lin Jiao, Vidya Madhavan, Eugene J. Mele, Piers Coleman Venue: arXiv (2025)\nDiscoveries over the past two decades have revealed the remarkable ability of quantum materials to emulate relativistic properties of the vacuum, from Dirac cones in graphene to the Weyl surface states of topological insulators. Yet the most elusive consequence of topology in quantum matter is the axionic $E\\cdot B$ term in the electromagnetic response. Here we report a direct signature of axionic physics obtained through scanning tunneling microscopy (STM). Although recent STM experiments using SmB$_6$ nanowires have been interpreted as evidence for spin-polarized currents arising from topological surface states, we show that the observed spin polarization instead originates from axionic electrodynamics. Our analysis reveals a striking voltage-induced magnetization: extremely small voltages ($\\sim$ 30 meV) generate tip moments of order 0.1 $Œº_B$ that reverse sign with the applied bias. The magnitude, tunability, and reversibility of this signal are consistent with an axionic $E \\cdot B$ coupling, and fully account for the magnetic component of the tip density of states, ruling out static magnetism. Millivolt-scale control of spin polarization in a tunnel junction provides a new route for probing axionic electrodynamics and opens avenues for future STM and spintronics applications.\nüì• Save to Zotero üìÑ Download PDF\nA Nehari manifold method for nonvariational problems Authors: Radu Precup, Andrei Stan Venue: arXiv (2025)\nThe aim of this paper is to extend the Nehari manifold method from the variational setting to the nonvariational framework of fixed point equations. This is achieved by constructing a radial energy functional that generalizes the standard one from the variational case. Furthermore, the solutions obtained through our method are localized in conical annular sets, which leads to the existence of multiple solutions. The abstract results are illustrated by two representative applications.\nüì• Save to Zotero üìÑ Download PDF\nQKAN-LSTM: Quantum-inspired Kolmogorov-Arnold Long Short-term Memory Authors: Yu-Chao Hsu, Jiun-Cheng Jiang, Chun-Hua Lin, Kuo-Chung Peng, Nan-Yow Chen, Samuel Yen-Chi Chen, En-Jui Kuo, Hsi-Sheng Goan Venue: arXiv (2025)\nLong short-term memory (LSTM) models are a particular type of recurrent neural networks (RNNs) that are central to sequential modeling tasks in domains such as urban telecommunication forecasting, where temporal correlations and nonlinear dependencies dominate. However, conventional LSTMs suffer from high parameter redundancy and limited nonlinear expressivity. In this work, we propose the Quantum-inspired Kolmogorov-Arnold Long Short-Term Memory (QKAN-LSTM), which integrates Data Re-Uploading Activation (DARUAN) modules into the gating structure of LSTMs. Each DARUAN acts as a quantum variational activation function (QVAF), enhancing frequency adaptability and enabling an exponentially enriched spectral representation without multi-qubit entanglement. The resulting architecture preserves quantum-level expressivity while remaining fully executable on classical hardware. Empirical evaluations on three datasets, Damped Simple Harmonic Motion, Bessel Function, and Urban Telecommunication, demonstrate that QKAN-LSTM achieves superior predictive accuracy and generalization with a 79% reduction in trainable parameters compared to classical LSTMs. We extend the framework to the Jiang-Huang-Chen-Goan Network (JHCG Net), which generalizes KAN to encoder-decoder structures, and then further use QKAN to realize the latent KAN, thereby creating a Hybrid QKAN (HQKAN) for hierarchical representation learning. The proposed HQKAN-LSTM thus provides a scalable and interpretable pathway toward quantum-inspired sequential modeling in real-world data environments.\nüì• Save to Zotero üìÑ Download PDF\nJoint 3D Geometry Reconstruction and Motion Generation for 4D Synthesis from a Single Image Authors: Yanran Zhang, Ziyi Wang, Wenzhao Zheng, Zheng Zhu, Jie Zhou, Jiwen Lu Venue: arXiv (2025)\nGenerating interactive and dynamic 4D scenes from a single static image remains a core challenge. Most existing generate-then-reconstruct and reconstruct-then-generate methods decouple geometry from motion, causing spatiotemporal inconsistencies and poor generalization. To address these, we extend the reconstruct-then-generate framework to jointly perform Motion generation and geometric Reconstruction for 4D Synthesis (MoRe4D). We first introduce TrajScene-60K, a large-scale dataset of 60,000 video samples with dense point trajectories, addressing the scarcity of high-quality 4D scene data. Based on this, we propose a diffusion-based 4D Scene Trajectory Generator (4D-STraG) to jointly generate geometrically consistent and motion-plausible 4D point trajectories. To leverage single-view priors, we design a depth-guided motion normalization strategy and a motion-aware module for effective geometry and dynamics integration. We then propose a 4D View Synthesis Module (4D-ViSM) to render videos with arbitrary camera trajectories from 4D point track representations. Experiments show that MoRe4D generates high-quality 4D scenes with multi-view consistency and rich dynamic details from a single image. Code: https://github.com/Zhangyr2022/MoRe4D.\nüì• Save to Zotero üìÑ Download PDF\nA Theory of Backgrounds and Background Independence Authors: Marc Klinger Venue: arXiv (2025)\nIn this note, we describe how the study of backgrounds for general quantum systems can be formulated in terms of the representation theory of abstract $C^*$ algebras. We illustrate our general framework through two example systems: superconductivity and perturbative quantum gravity. In both cases, spontaneously broken symmetries imply the existence of unitarily inequivalent Hilbert spaces that play the role of distinct backgrounds relative to which observables are measured. Background independence can be realized by gauging the broken symmetry; extending the algebra of observables for the theory to include new physical processes that intertwine between these disjoint representations. From the point of view of the background independent theory, different backgrounds have an interpretation as different vacuum expectation values of these intertwining operators. In superconductivity, the intertwiners are intimately related to the Josephson effect. In gravity, they are related to geometric fluctuations. We explain how this framework is connected to recent work on generalized symmetries and algebraic extensions. To this end, we close with some remarks about how the operator algebra of a closed universe may arise from a generalized symmetry associated with the inclusion of the causal wedge inside the entanglement wedge by appealing to subregion-subalgebra duality.\nüì• Save to Zotero üìÑ Download PDF\nSemantic-Guided Two-Stage GAN for Face Inpainting with Hybrid Perceptual Encoding Authors: Abhigyan Bhattacharya, Hiranmoy Roy Venue: arXiv (2025)\nFacial Image inpainting aim is to restore the missing or corrupted regions in face images while preserving identity, structural consistency and photorealistic image quality, a task specifically created for photo restoration. Though there are recent lot of advances in deep generative models, existing methods face problems with large irregular masks, often producing blurry textures on the edges of the masked region, semantic inconsistencies, or unconvincing facial structures due to direct pixel level synthesis approach and limited exploitation of facial priors. In this paper we propose a novel architecture, which address these above challenges through semantic-guided hierarchical synthesis. Our approach starts with a method that organizes and synthesizes information based on meaning, followed by refining the texture. This process gives clear insights into the facial structure before we move on to creating detailed images. In the first stage, we blend two techniques: one that focuses on local features with CNNs and global features with Vision Transformers. This helped us create clear and detailed semantic layouts. In the second stage, we use a Multi-Modal Texture Generator to refine these layouts by pulling in information from different scales, ensuring everything looks cohesive and consistent. The architecture naturally handles arbitrary mask configurations through dynamic attention without maskspecific training. Experiment on two datasets CelebA-HQ and FFHQ shows that our model outperforms other state-of-the-art methods, showing improvements in metrics like LPIPS, PSNR, and SSIM. It produces visually striking results with better semantic preservation, in challenging large-area inpainting situations.\nüì• Save to Zotero üìÑ Download PDF\nSuperActivators: Only the Tail of the Distribution Contains Reliable Concept Signals Authors: Cassandra Goldberg, Chaehyeon Kim, Adam Stein, Eric Wong Venue: arXiv (2025)\nConcept vectors aim to enhance model interpretability by linking internal representations with human-understandable semantics, but their utility is often limited by noisy and inconsistent activations. In this work, we uncover a clear pattern within the noise, which we term the SuperActivator Mechanism: while in-concept and out-of-concept activations overlap considerably, the token activations in the extreme high tail of the in-concept distribution provide a reliable signal of concept presence. We demonstrate the generality of this mechanism by showing that SuperActivator tokens consistently outperform standard vector-based and prompting concept detection approaches, achieving up to a 14% higher F1 score across image and text modalities, model architectures, model layers, and concept extraction techniques. Finally, we leverage SuperActivator tokens to improve feature attributions for concepts.\nüì• Save to Zotero üìÑ Download PDF\nCumulant expansions of operator groups of quantum many-particle systems Authors: V. I. Gerasimenko, I. V. Gapyak Venue: arXiv (2025)\nThe article presents a method of cluster expansions for groups of operators associated with the von Neumann equations for states and the Heisenberg equations for observables, aiming to construct generating operators for nonperturbative solutions to the Cauchy problem for hierarchies of evolution equations of many-particle quantum systems.\nüì• Save to Zotero üìÑ Download PDF\nExploring asymmetries in three-body cLFV lepton decays: probing CP violation in HNL extensions of the SM Authors: Adrian Darricau, Jonathan Kriewald, Ana M. Teixeira Venue: arXiv (2025)\nIn the context of Standard Model extensions via Majorana sterile fermions, the presence of additional CP violating phases (Dirac and Majorana) has been shown to be at source of important effects in charged lepton flavour violating (cLFV) transitions and decays. Here we will consider further angular observables that can be studied for polarised $œÑ$ and $Œº$ cLFV decays. These include, among others, parity asymmetries and time-reversal asymmetries for generic cLFV 3-body decays, $\\ell_Œ±^+ \\to \\ell_Œ≤^+ \\ell_Œ≥^+ \\ell_Œ¥^-$. We address relevant correlations between the different classes of observables, and show that one can have sizeable asymmetries, which can be used to further probe this interesting class of SM extensions. Our study leads to the prediction of particular patterns of angular observables, which would allow to potentially falsify the model, should a cLFV signal be observed.\nüì• Save to Zotero üìÑ Download PDF\nEfficient Decoders for Sensing Subspace Code Authors: Siva Aditya Gooty, Hessam Mahdavifar Venue: arXiv (2025)\nSparse antenna array sensing of source/target via direction of arrival (DoA) estimation motivates design of the sensing framework in joint communication and sensing (JCAS) systems for sixth generation (6G) communication systems. Recently, it is established by Mahdavifar, Rajam√§ki, and Pal that array geometry of sparse arrays has fundamental connections with the design of subspace codes in coding theory. This was then utilized to design efficient \\textit{sensing subspace codes} that estimate the DoA with good resolution. Specifically, the Bose-Chowla sensing subspace code provides near optimal code design for unique DoA estimation with tight theoretical upper bound on the error performance. However, the currently known decoder for these codes, to estimate the DoA, is a traditional \\textit{Maximum-a-Posterior (MAP) decoder} with complexity that is cubic with the number of antennas. In this work, we propose novel efficient decoding algorithms for sensing subspace codes, that reduce the complexity down to quadratic while providing new knobs to tune in order to tradeoff complexity with error performance. The decoders are further evaluated for their performance via Monte Carlo simulations for a range of SNRs demonstrating promising performance that smoothly approaches the MAP performance as the complexity grows from quadratic to cubic in the number of antennas.\nüì• Save to Zotero üìÑ Download PDF\nFrobenius generation for algebraic stacks Authors: Pat Lank, Fei Peng Venue: arXiv (2025)\nThis work investigates the Frobenius morphism on derived categories associated with algebraic stacks in positive characteristic. Particularly, we show that in many cases sufficiently many Frobenius pushforwards of a compact generator produce a classical or strong generator for the bounded derived category of coherent sheaves. In the case of Deligne‚ÄìMumford stacks, we can bound the number of iterates required.\nüì• Save to Zotero üìÑ Download PDF\nHTR-ConvText: Leveraging Convolution and Textual Information for Handwritten Text Recognition Authors: Pham Thach Thanh Truc, Dang Hoai Nam, Huynh Tong Dang Khoa, Vo Nguyen Le Duy Venue: arXiv (2025)\nHandwritten Text Recognition remains challenging due to the limited data, high writing style variance, and scripts with complex diacritics. Existing approaches, though partially address these issues, often struggle to generalize without massive synthetic data. To address these challenges, we propose HTR-ConvText, a model designed to capture fine-grained, stroke-level local features while preserving global contextual dependencies. In the feature extraction stage, we integrate a residual Convolutional Neural Network backbone with a MobileViT with Positional Encoding block. This enables the model to both capture structural patterns and learn subtle writing details. We then introduce the ConvText encoder, a hybrid architecture combining global context and local features within a hierarchical structure that reduces sequence length for improved efficiency. Additionally, an auxiliary module injects textual context to mitigate the weakness of Connectionist Temporal Classification. Evaluations on IAM, READ2016, LAM and HANDS-VNOnDB demonstrate that our approach achieves improved performance and better generalization compared to existing methods, especially in scenarios with limited training samples and high handwriting diversity.\nüì• Save to Zotero üìÑ Download PDF\nL√©vy sources in UrQMD in Ar+Sc collisions at SPS energies Authors: Barnabas Porfy, Mate Csanad Venue: arXiv (2025)\nOver the past few decades, progress in femtoscopy has been driven by the interplay between experimental measurements and theoretical calculations. Measurements provide data for the theory to understand it, while theoretical predictions guide new measurements. In the recent decade, several experiments have confirmed that the two-particle pion emitting source is well described by L√©vy alpha-stable distributions. To enable theoretical interpretation, phenomenological simulations have been done at RHIC and LHC energies, using various available heavy-ion collision models. In this paper, we investigate three-dimensional two-pion pair source distributions from $^{40}$Ar+$^{45}$Sc central collisions at SPS energies, generated with the Ultra-Relativistic Quantum Molecular Dynamics Monte-Carlo event generator. We fit the pair source with L√©vy-stable distributions, and discuss the extracted L√©vy parameters describing the spatial scale, shape and strength of the source.\nüì• Save to Zotero üìÑ Download PDF\nIsolating chirality-breaking SMEFT operators with Drell-Yan angular analysis Authors: Samuele Grossi, Xu Li, Lorenzo Rolla, Riccardo Torre Venue: arXiv (2025)\nWe present a comprehensive strategy to isolate the effect of a class of chirality-breaking interactions in the Standard Model Effective Field Theory (SMEFT) by exploiting Drell-Yan angular analysis and the violation of the Lam-Tung relation. Unlike most SMEFT interpretation of Drell-Yan measurements, dominated by growing-with-energy effects generated by the interference of SMEFT-induced and SM amplitudes, this method isolates operators that contribute only quadratically in the Wilson coefficients, allowing for an independent probe of non-interfering operators. Denoting with $v$ the electroweak vev, with $\\sqrt{s}$ the center-of-mass energy, and with $Œõ$ the scale of new physics, the non-interfering contributions to the amplitude generated by the chirality-breaking operators can be proportional to $v\\sqrt{s}/Œõ^{2}$ or $s/Œõ^{2}$. We argue that these two classes can be further distinguished by analyzing the angular observables of the lepton pair in the transverse momentum and in the invariant mass distribution of the lepton pair. We therefore present an analysis of the lepton-pair angular observables in both these distributions. Based on a precise estimate of the Standard Model contribution to the relevant observables for the $pp\\to l^{+}l^{-}+X$ process up to $O(Œ±_{S}^{2})$, we present realistic projections for the sensitivity of the LHC with $300$ fb$^{-1}$ and for the HL-LHC with $3$ ab$^{-1}$ to chirality-breaking interactions, demonstrating that angular observables provide an independent and clean handle on SMEFT effects, especially in regions where the Standard Model contribution is naturally suppressed thanks to the Lam-Tung relation. This analysis becomes crucial to go beyond single parameter global fits, since it helps breaking degeneracies with chirality preserving operators and to disentangle overlapping directions in the EFT parameter space.\nüì• Save to Zotero üìÑ Download PDF\nThe Magnus expansion in relativistic quantum field theory Authors: Andreas Brandhuber, Graham R. Brown, Paolo Pichini, Gabriele Travaglini, Pablo Vives Matasan Venue: arXiv (2025)\nWe investigate the Magnus expansion of the $N$-operator in relativistic quantum field theory, which is related to the $S$-matrix via $S = e^{iN}$. We develop direct methods to compute matrix elements of the $N$-operator, which we refer to as Magnus amplitudes, bypassing scattering amplitudes entirely. At tree level, Magnus amplitudes are expressed in terms of retarded and advanced propagators, with each diagram weighted by factors that we identify as Murua coefficients. At loop level this structure is augmented by the Hadamard cut function, and we establish remarkable relations between loop- and tree-level Magnus amplitudes. Among these, we find that $n$-point one-loop Magnus amplitudes are entirely determined by phase-space integrals of forward limits of $(n{+}2)$-point tree-level amplitudes, and hence related to Murua coefficients, and we generalise this to a class of higher-loop contributions. Furthermore, in the case of heavy particles interacting via massless mediators, we conjecture that Magnus diagrams that contribute to the classical limit are always given by forward limits of trees, and we show this explicitly in a one-loop example. We derive these results studying theories of scalar fields with cubic interactions, but our methods are applicable to general theories as well as to integral functions appearing in gravitational-wave computations. Given that Magnus amplitudes are free of hyper-classical terms, and the known relations between Magnus amplitudes and the radial action, our results lay the groundwork for systematic and efficient calculations of classical observables from quantum field theory.\nüì• Save to Zotero üìÑ Download PDF\nGenerative Neural Video Compression via Video Diffusion Prior Authors: Qi Mao, Hao Cheng, Tinghan Yang, Libiao Jin, Siwei Ma Venue: arXiv (2025)\nWe present GNVC-VD, the first DiT-based generative neural video compression framework built upon an advanced video generation foundation model, where spatio-temporal latent compression and sequence-level generative refinement are unified within a single codec. Existing perceptual codecs primarily rely on pre-trained image generative priors to restore high-frequency details, but their frame-wise nature lacks temporal modeling and inevitably leads to perceptual flickering. To address this, GNVC-VD introduces a unified flow-matching latent refinement module that leverages a video diffusion transformer to jointly enhance intra- and inter-frame latents through sequence-level denoising, ensuring consistent spatio-temporal details. Instead of denoising from pure Gaussian noise as in video generation, GNVC-VD initializes refinement from decoded spatio-temporal latents and learns a correction term that adapts the diffusion prior to compression-induced degradation. A conditioning adaptor further injects compression-aware cues into intermediate DiT layers, enabling effective artifact removal while maintaining temporal coherence under extreme bitrate constraints. Extensive experiments show that GNVC-VD surpasses both traditional and learned codecs in perceptual quality and significantly reduces the flickering artifacts that persist in prior generative approaches, even below 0.01 bpp, highlighting the promise of integrating video-native generative priors into neural codecs for next-generation perceptual video compression.\nüì• Save to Zotero üìÑ Download PDF\nHall-like response from anisotropic Fermi surfaces Authors: Abhiram Soori Venue: arXiv (2025)\nWe demonstrate that an anisotropic and rotated Fermi surface can generate a finite Hall-like transverse response in electron transport, even in the absence of a magnetic field or Berry curvature. Using a two-dimensional continuum model, we show that broken $k_y \\to -k_y$ symmetry inherent to anistropic band structures leads to a nonzero transverse conductivity. We construct a lattice model with direction-dependent nearest- and next-nearest-neighbor hoppings that faithfully reproduces the continuum dispersion and allows controlled rotation of the Fermi contour. Employing a multiterminal geometry and the B√ºttiker-probe method, we compute the resulting Hall voltage and establish its direct correspondence with the continuum transverse response. The effect increases with the degree of anisotropy and vanishes at rotation angles where mirror symmetry is restored. Unlike the quantum Hall effect, the Hall response predicted here is not quantized but varies continuously with the band-structure parameters. Our results provide a symmetry-based route to engineer Hall-like signals in low-symmetry materials without magnetic fields or topological effects.\nüì• Save to Zotero üìÑ Download PDF\nDetecting Perspective Shifts in Multi-agent Systems Authors: Eric Bridgeford, Hayden Helm Venue: arXiv (2025)\nGenerative models augmented with external tools and update mechanisms (or \\textit{agents}) have demonstrated capabilities beyond intelligent prompting of base models. As agent use proliferates, dynamic multi-agent systems have naturally emerged. Recent work has investigated the theoretical and empirical properties of low-dimensional representations of agents based on query responses at a single time point. This paper introduces the Temporal Data Kernel Perspective Space (TDKPS), which jointly embeds agents across time, and proposes several novel hypothesis tests for detecting behavioral change at the agent- and group-level in black-box multi-agent systems. We characterize the empirical properties of our proposed tests, including their sensitivity to key hyperparameters, in simulations motivated by a multi-agent system of evolving digital personas. Finally, we demonstrate via natural experiment that our proposed tests detect changes that correlate sensitively, specifically, and significantly with a real exogenous event. As far as we are aware, TDKPS is the first principled framework for monitoring behavioral dynamics in black-box multi-agent systems ‚Äì a critical capability as generative agent deployment continues to scale.\nüì• Save to Zotero üìÑ Download PDF\nDeep infant brain segmentation from multi-contrast MRI Authors: Malte Hoffmann, Lilla Z√∂llei, Adrian V. Dalca Venue: arXiv (2025)\nSegmentation of magnetic resonance images (MRI) facilitates analysis of human brain development by delineating anatomical structures. However, in infants and young children, accurate segmentation is challenging due to development and imaging constraints. Pediatric brain MRI is notoriously difficult to acquire, with inconsistent availability of imaging modalities, substantial non-head anatomy in the field of view, and frequent motion artifacts. This has led to specialized segmentation models that are often limited to specific image types or narrow age groups, or that are fragile for more variable images such as those acquired clinically. We address this method fragmentation with BabySeg, a deep learning brain segmentation framework for infants and young children that supports diverse MRI protocols, including repeat scans and image types unavailable during training. Our approach builds on recent domain randomization techniques, which synthesize training images far beyond realistic bounds to promote dataset shift invariance. We also describe a mechanism that enables models to flexibly pool and interact features from any number of input scans. We demonstrate state-of-the-art performance that matches or exceeds the accuracy of several existing methods for various age cohorts and input configurations using a single model, in a fraction of the runtime required by many existing tools.\nüì• Save to Zotero üìÑ Download PDF\nResolving the molecular gas emission of the z~2.5-2.8 starburst galaxies SPT0125-47 and SPT 2134-50 Authors: K. Kade, M. Bredberg, K. Knudsen, S. K√∂nig, G. Drouart, A. B. Romeo, T. J. L. C. Bakx Venue: arXiv (2025)\nThe comoving cosmic star formation rate density peaks at z2-3, with dusty star-forming galaxies being significant contributors to this peak. These galaxies are characterized by their high star formation rates and substantial infrared luminosities. The formation mechanisms remain an open question for these galaxies, particularly with respect to how such intense levels of star formation are triggered and maintained. We aim to resolve CO(3-2) emission toward two strongly lensed galaxies, SPT0125-47 and SPT2134-50, at z2.5-2.8 to determine their morphology and physical properties. We used high-resolution ALMA band 3 observations of CO(3-2) emission toward both sources to investigate their properties. We performed parametric and nonparametric lens modeling using the publicly available lens modeling software PyAutoLens. We divided the CO(3-2) emission line into two bins corresponding to the red and blue portions of the emission line and nonparametrically modeled the source plane emission for both bins. We performed a basic analysis of the morphology and kinematics in the source plane using nonparametric lens modeling of the red and blue bins. We found tentative evidence of a velocity gradient across both sources and no evidence of any clumpy structure, companions, or ongoing mergers. The previously calculated high star formation rates and low depletion times of both SPT0125-47 and SPT2134-50 suggest that these galaxies are undergoing a dramatic phase in their evolution. Given the lack of evidence of ongoing interactions or mergers in our source plane models, we suggest that the intense star formation was triggered by a recent interaction and/or merger. We also consider the possibility that these galaxies might be in the process of settling into disks.\nüì• Save to Zotero üìÑ Download PDF\nPrediction of Novel Li-AgII-F Compounds using Evolutionary Algorithms Authors: Katarzyna Kuder, Wojciech Grochala Venue: arXiv (2025)\nThis work provides a theoretical exploration of the thermodynamic stability and magnetic behaviour of previously unknown ternary Li AgII F compounds. Convex-hull analysis shows that all predicted structures lie slightly above the LiF plus AgF2 decomposition line, indicating a natural tendency toward phase separation; nevertheless, their negative formation energies relative to AgF, LiF, and F2 or F suggest that alternative synthetic pathways may be feasible for these compounds. All studied structures show preference for antiferromagnetic ground state. Notably, the triclinic LiAgF3 type2 is predicted to exhibit an exceptionally large superexchange constant, J equal to minus 358 meV, within Ag2F7 dimers, placing it above the strongest known magnetic exchange interactions reported to date.\nüì• Save to Zotero üìÑ Download PDF\nStructured Light at the Extreme: Harnessing Spatiotemporal Control for High-Field Laser-Matter Interactions Authors: Sergio Carbajo, Seung-Whan Bahk, Justin Baker, Andrea Bertozzi, Abhimanyu Borthakur, Antonino Di Piazza, Andrew Forbes, Spencer Gessner, Jack Hirschman, Franz K√§rtner, Maciej Lewenstein, Yuhang Li, Inhyuk Nam, Eileen Otte, Aydogan Ozcan, James Rozensweig, Yijie Shen, Liwei Song, Ye Tian, Yu Wang, Yuntian Wang, Logan Wright, Xiaojun Wu, Hao Zhang Venue: arXiv (2025)\nThis review charts the emerging paradigm of intelligent structured light for high-field laser-matter interactions, where the precise spatiotemporal and vectorial control of light is a critical degree of freedom. We outline a transformative framework built upon three synergistic pillars. First, we survey the advanced electromagnetic toolkit, moving beyond conventional spatial light modulators to include robust static optics and the promising frontier of plasma light modulators. Second, we detail the optimization engine for this high-dimensional design space, focusing on physics-informed digital twins and AI-driven inverse design to automate the discovery of optimal light structures. Finally, we explore the groundbreaking applications enabled by this integrated approach, including programmable electron beams, orbital-angular-momentum-carrying Œ≥-rays, compact THz accelerators, and robust communications. The path forward necessitates overcoming grand challenges in material science, real-time adaptive control at MHz rates, and the extension of these principles to the quantum realm. This review serves as a call to action for a coordinated, interdisciplinary effort to command, rather than merely observe, light-matter interactions at the extreme.\nüì• Save to Zotero üìÑ Download PDF\nProbing AGN Feedback in Dwarf Galaxies with Spatially Resolved NIR Coronal Lines from JWST Authors: Archana Aravindan, Thomas Bohn, Gabriela Canalizo, Shobita Satyapal, Vivian U, Weizhe Liu, William Matzko, Sara Doan, Matthew Malkan, Lee Armus, Tohru Nagao, Tanio Diaz-Santos, Aditya Togi, Thomas S. Y. Lai, Sean T. Linden, Marina Bianchin, Yiqing Song, Loreto Barcos-Munoz, Aaron Evans, Hanae Inami, Kirsten Larson, Sabrina Stierwalt, Jason Surace Venue: arXiv (2025)\nWe present the first spatially resolved investigation of near-infrared coronal lines in dwarf galaxies hosting active galactic nuclei (AGN), using JWST/NIRSpec integral field spectroscopy. Coronal lines (CLs), which are forbidden transitions from highly ionized species with ionization potentials up to 450 eV, act as sensitive tracers of the AGN ionizing continuum and feedback processes. Across four dwarf galaxies with ionized gas outflows traced by the optical [O III] lines, we report the detection of 16 unique species of near-infrared CLs. Line ratio diagnostics indicate that photoionization from the AGN dominates the excitation of CLs. We find that the coronal line region in dwarf galaxies, traced by the various CLs, extends up to 0.5 kpc, and can constitute up to 10% of their host galaxy size. Correlations between CL luminosities and [O III] ionized gas outflow properties are consistent with a scenario in which AGN-driven outflows likely facilitate the detection of CLs and contribute to their extent. Several CLs, including [Si VI], [Si VII], and [Mg VIII], exhibit a secondary broad component (W$_{80}$ \u003e 300 km/s). If we interpret this spatially compact gas as part of an outflow, this would indicate that the outflowing gas includes a wide range of ionizations. The estimated energetics imply this highly ionized component is compact yet powerful enough to perturb gas in the central regions of the host dwarfs. These results indicate that AGN in low-mass galaxies may produce outflows capable of influencing their structure and evolution.\nüì• Save to Zotero üìÑ Download PDF\nGeometric Data Science Authors: Olga D Anosova, Vitaliy A Kurlin Venue: arXiv (2025)\nThis book introduces the new research area of Geometric Data Science, where data can represent any real objects through geometric measurements. The first part of the book focuses on finite point sets. The most important result is a complete and continuous classification of all finite clouds of unordered points under rigid motion in any Euclidean space. The key challenge was to avoid the exponential complexity arising from permutations of the given unordered points. For a fixed dimension of the ambient Euclidean space, the times of all algorithms for the resulting invariants and distance metrics depend polynomially on the number of points. The second part of the book advances a similar classification in the much more difficult case of periodic point sets, which model all periodic crystals at the atomic scale. The most significant result is the hierarchy of invariants from the ultra-fast to complete ones. The key challenge was to resolve the discontinuity of crystal representations that break down under almost any noise. Experimental validation on all major materials databases confirmed the Crystal Isometry Principle: any real periodic crystal has a unique location in a common moduli space of all periodic structures under rigid motion. The resulting moduli space contains all known and not yet discovered periodic crystals and hence continuously extends Mendeleev‚Äôs table to the full crystal universe.\nüì• Save to Zotero üìÑ Download PDF\nSpectrum and anisotropies of Galactic cosmic rays: a laboratory for magnetic fields Authors: Philipp Mertsch Venue: arXiv (2025)\nMuch has been learned about Galactic cosmic rays in the past decade: On the observational side, the spectra of cosmic ray nuclei have been directly measured with high precision, resolving chemical composition up to TV rigidities. At even higher rigidities, direct detection is making contact with indirect observations from air shower arrays. A number of breaks have been found in the nuclear spectrum, which was previously thought to be a pure power law up to the knee. Data from air shower arrays also show interesting features in the arrival directions of cosmic-ray nuclei. On the theoretical side, more sophisticated models are able to explain the various spectral breaks either with transitions between different classes of sources or with changes in the transport regime. Yet, it has become clear that our ignorance of the structure of the Galactic magnetic fields, both on large and small scales, is limiting precision predictions. Turning this problem into an opportunity though, we can use Galactic cosmic rays as a laboratory for the study of Galactic magnetic fields. In this review talk, delivered at the 39th International Cosmic Ray Conference (ICRC2025), I have summarised what is known about the spectrum and anisotropies of Galactic cosmic rays, what is not known yet and what can be learnt in the future.\nüì• Save to Zotero üìÑ Download PDF\nEmergence of ER=EPR from non-local gravitational energy Authors: Kimet Jusufi, Francisco S. N. Lobo, Emmanuel N. Saridakis, Douglas Singleton Venue: arXiv (2025)\nWe construct a class of wormhole geometries supported by the non-local gravitational self-energy that regularizes the particle and black-hole sectors of spacetime. Using this framework, inspired by T-duality, we show that two entangled particles (or particle-black-hole pairs) naturally source an Einstein-Rosen-type geometry in which the required violation of the strong energy condition arises from intrinsic quantum-gravity effects rather than from ad hoc exotic matter, which is matter that violates the null energy condition. We classify the resulting wormholes, analyze their horizons, throat structure and embedding properties, and we identify the exotic energy needed at the minimal surface. Imposing the ER=EPR requirement of non-traversability and the absence of a macroscopic throat, we find that only the zero-throat geometry is compatible with an entanglement-induced Einstein-Rosen bridge, providing a concrete realization of ER=EPR within a fully regular spacetime. Finally, we briefly discuss possible implications for microscopic ER networks from vacuum fluctuations, replica-wormhole interpretations of Hawking radiation, and possible links to entanglement-driven dark-energy scenarios.\nüì• Save to Zotero üìÑ Download PDF\nRevealing stimulus-dependent dynamics through statistical complexity Authors: Edson V. de Paula, Rafael M. Jungmann, Antonio J. Fontenele, Leandro A. A. Aguiar, Pedro V. Carelli, Fernanda S. Matias, Mauro Copelli, Nivaldo A. P. de Vasconcelos Venue: arXiv (2025)\nAdvances in large-scale neural recordings have expanded our ability to describe the activity of distributed brain circuits. However, understanding how neural population dynamics differ across regions and behavioral contexts remains challenging. Here, we surveyed neuronal population dynamics across multiple mouse brain areas (visual cortex, hippocampus, thalamus, and midbrain) using spike data from local ensembles. Two complementary measures were used to characterize these dynamics: the coefficient of variation (CV), a classical indicator of spike-time variability, and statistical complexity, an information-theoretic quantifier of organizational structure. To probe stimulus-dependent activity, we segmented and concatenated recordings from behavioral experiments into distinct time series corresponding to natural image presentations, blank screens during visual task, and spontaneous activity. While the CV failed to discriminate between these conditions, statistical complexity revealed clear, stimulus-specific motifs in population activity. These results indicate that information-theoretic measures can uncover structured, stimulus-dependent patterns in neural population dynamics that remain unobserved in traditional variability metrics.\nüì• Save to Zotero üìÑ Download PDF\nGeneralized Pinching-Antenna Systems: A Leaky-Coaxial-Cable Perspective Authors: Kaidi Wang, Zhiguo Ding, Lajos Hanzo Venue: arXiv (2025)\nThe evolution toward the sixth-generation (6G) wireless networks has flexible reconfigurable antenna architectures capable of adapting their radiation characteristics to the surrounding environment. At the center-stage, while waveguide based pinching antennas have been shown to beneficially ameliorate wireless propagation environments, their applications have remained confined to high-frequency scenarios. As a remedy, we propose a downlink generalized pinching-antenna system that adapts this compelling concept to low-frequency operation through a leaky-coaxial-cable (LCX) implementation. By endowing LCX structures with controllable radiation slots, the system inherits the key capabilities of waveguide based pinching antennas. Explicitly, these include reconfigurable line-of-sight (LoS) links, reduced path loss, and flexible deployment, while supporting a practical implementation of the pinching-antenna concept at low frequencies. A twin-stage propagation model is developed for characterizing both the guided transmission and wireless radiation encountered over LoS and non-line-of-sight (NLoS) paths. Analytical results reveal strong local gain, complemented by rapid distance-dependent decay. Hence, we conceive a matching joint optimization framework, which maximizes throughput by harnessing game-theoretic association and convex power allocation. Simulation results demonstrate substantial performance gains over conventional fixed-antenna benchmarks.\nüì• Save to Zotero üìÑ Download PDF\nTracing the horizon of tetragonal-to-monoclinic distortion in pressurized trilayer nickelate La4Ni3O10 Authors: Sitaram Ramakrishnan, Yingzheng Gao, Valerio Olevano, Elise Pachoud, Abdellali Hadj-Azzem, Gaston Gabarino, Olivier Perez, Alain Pautrat, Diego Valenti, Matthieu Quenot, Sebastien Pairis, Dmitry Chernyshov, Leila Noohinejad, Carsten Paulmann, Sander van Smaalen, Pierre Toulemonde, Marie-Aude Measson, Pierre Rodiere Venue: arXiv (2025)\nThe crux of understanding the superconducting mechanism in pressurized Ruddlesden-Popper nickelates hinges on elucidating their structural phases. Under ambient conditions, the trilayer nickelate La4Ni3O10 stabilizes in a twinned monoclinic structure with space group P21/c. Upon heating, it undergoes a structural transition to the tetragonal I4/mmm phase at Ts ~ 1030 K, while a second transition associated with the onset of density-weave (DW) ordering emerges upon cooling below TDW ~ 135 K. Here from pressure-temperature x-ray diffraction on high quality flux-grown single crystals we unequivocally demonstrate a direct tetragonal-to-monoclinic transition with no trace of intermediate orthorhombic Bmab phase. Ab initio density-functional theory calculations as a function of pressure fully corroborate the experimental observations. The transition unfolds as a 2-fold superstructure due to the emergence of commensurate superlattice reflections and can be progressively suppressed from 1030 K down to 20 K under 14 GPa. No discernible structural distortions associated with DW ordering are detected down to 20 K at ambient pressure. This is in contrast to Raman measurements that reveal the appearance of additional phonon modes below 130 K, implying a further reduction in symmetry from monoclinic P21/c and thus indicating the presence of a third structural phase associated with the DW ordering in La4Ni3O10.\nüì• Save to Zotero üìÑ Download PDF\nPreliminary Analysis and Simulation of a Compact Variable Stiffness Wrist Authors: Giuseppe Milazzo, Manuel G. Catalano, Antonio Bicchi, Giorgio Grioli Venue: arXiv (2025)\nVariable Stiffness Actuators prove invaluable for robotics applications in unstructured environments, fostering safe interactions and enhancing task adaptability. Nevertheless, their mechanical design inevitably results in larger and heavier structures compared to classical rigid actuators. This paper introduces a novel 3 Degrees of Freedom (DoFs) parallel wrist that achieves variable stiffness through redundant elastic actuation. Leveraging its parallel architecture, the device employs only four motors, rendering it compact and lightweight. This characteristic makes it particularly well-suited for applications in prosthetics or humanoid robotics. The manuscript delves into the theoretical model of the device and proposes a sophisticated control strategy for independent regulation of joint position and stiffness. Furthermore, it validates the proposed controller through simulation, utilizing a comprehensive analysis of the system dynamics. The reported results affirm the ability of the device to achieve high accuracy and disturbance rejection in rigid configurations while minimizing interaction forces with its compliant behavior.\nüì• Save to Zotero üìÑ Download PDF\nInternal superfluid response and torque evolution in the giant glitch of PSR J1718-3718 Authors: Peng Liu, Zhonghao Tu, Jianping Yuan, Ang Li Venue: arXiv (2025)\nWe investigate the post-glitch rotational evolution of pulsars by analyzing the 2007 giant glitch of PSR J1718$-$3718 using a vortex creep model that incorporates both inward and outward nonlinear vortex motion, along with a time-varying external torque. A comprehensive fitting framework is developed, constrained by prior knowledge of moment of inertia participation from previous glitch studies. We apply a Markov Chain Monte Carlo approach to quantify uncertainties and parameter correlations. The model reproduces the observed timing data and yields physically consistent values for moment of inertia fractions and creep timescales. Our results indicate that inward creep and a long-term change in external torque dominate the observed increase in spin-down rate, pointing to structural changes within the star-likely triggered by a crustquake that initiated both vortex motion and a change in the moment of inertia. We estimate that the glitch involved approximately $2.4 \\times 10^{12}$ inward-moving vortices and $\\sim 142$ crustal plates with a typical size of $\\sim 0.03$ km. This study demonstrates that detailed post-glitch modeling of sparse timing data can simultaneously constrain internal superfluid dynamics and external torque evolution, providing a quantitative framework to probe the structural properties of neutron star interiors.\nüì• Save to Zotero üìÑ Download PDF\nGeoPE:A Unified Geometric Positional Embedding for Structured Tensors Authors: Yupu Yao, Bowen Yang Venue: arXiv (2025)\nStandard Vision Transformers flatten 2D images into 1D sequences, disrupting the natural spatial topology. While Rotary Positional Embedding (RoPE) excels in 1D, it inherits this limitation, often treating spatially distant patches (e.g., at row edges) as sequence neighbors. Existing 2D approaches typically treat spatial axes independently, failing to decouple this false sequential proximity from true spatial distance. To restore the 2D spatial manifold, we introduce Geometric Positional Embedding (GeoPE), a framework that extends rotations to 3D Euclidean space using quaternions. To overcome non-commutativity and ensure symmetry, GeoPE constructs a unified rotational operator by computing the geometric mean in the Lie algebra. This creates a geometrically coupled encoding that effectively separates spatial dimensions. Extensive experiments on image classification, object detection, and 3D semantic segmentation demonstrate that GeoPE consistently outperforms existing 2D RoPE variants and significantly enhances shape bias, confirming its ability to capture true geometric structure.\nüì• Save to Zotero üìÑ Download PDF\nExistence and a priori bounds for fully nonlinear PDEs with a harmonic map-like structure Authors: Gabrielle Nornberg, Ricardo Ziegele Venue: arXiv (2025)\nIn this paper, we study a new class of fully nonlinear uniformly elliptic equations with a so-called harmonic map-like structure, whose model case is given by \\begin{equation*} \\mathcal{M}^{\\pm}{Œª,Œõ}(D^2u) \\pm b(x) |Du| \\pm Œ≤(u)\\langle M(x) Du,Du \\rangle \\pm c(x) u = f(x); \\textrm{ in } Œ©, \\end{equation*} where $Œ©\\subset \\mathbb{R}^n$ is a bounded $C^{1,1}$ domain, $\\mathcal{M}^{\\pm}$ are the Pucci extremal operators, $Œ≤(s) = s^k$ for some $k \\in \\mathbb{N} $ odd, $b \\in L^{q}{+}(Œ©)$, $c,f \\in L^p(Œ©)$, and $n \\leq p \\leq q$, $q\u003en$. We obtain existence results under a smallness regime on the coefficients, along with some classical results such as the Aleksandrov‚ÄìBakelman‚ÄìPucci estimate and the comparison principle, as well as a priori bounds for the respective Dirichlet problem in the noncoercive case. We also establish multiplicity results and qualitative behavior, which seem to be new in the case of the Laplacian operator.\nüì• Save to Zotero üìÑ Download PDF\nSemantics Lead the Way: Harmonizing Semantic and Texture Modeling with Asynchronous Latent Diffusion Authors: Yueming Pan, Ruoyu Feng, Qi Dai, Yuqi Wang, Wenfeng Lin, Mingyu Guo, Chong Luo, Nanning Zheng Venue: arXiv (2025)\nLatent Diffusion Models (LDMs) inherently follow a coarse-to-fine generation process, where high-level semantic structure is generated slightly earlier than fine-grained texture. This indicates the preceding semantics potentially benefit texture generation by providing a semantic anchor. Recent advances have integrated semantic priors from pretrained visual encoders to further enhance LDMs, yet they still denoise semantic and VAE-encoded texture synchronously, neglecting such ordering. Observing these, we propose Semantic-First Diffusion (SFD), a latent diffusion paradigm that explicitly prioritizes semantic formation. SFD first constructs composite latents by combining a compact semantic latent, which is extracted from a pretrained visual encoder via a dedicated Semantic VAE, with the texture latent. The core of SFD is to denoise the semantic and texture latents asynchronously using separate noise schedules: semantics precede textures by a temporal offset, providing clearer high-level guidance for texture refinement and enabling natural coarse-to-fine generation. On ImageNet 256x256 with guidance, SFD achieves FID 1.06 (LightningDiT-XL) and FID 1.04 (1.0B LightningDiT-XXL), while achieving up to 100x faster convergence than the original DiT. SFD also improves existing methods like ReDi and VA-VAE, demonstrating the effectiveness of asynchronous, semantics-led modeling. Project page and code: https://yuemingpan.github.io/SFD.github.io/.\nüì• Save to Zotero üìÑ Download PDF\nLogic-Driven Cybersecurity: A Novel Framework for System Log Anomaly Detection using Answer Set Programming Authors: Fang Li, Fei Zuo, Gopal Gupta Venue: arXiv (2025)\nThis study explores the application of Answer Set Programming (ASP) for detecting anomalies in system logs, addressing the challenges posed by evolving cyber threats. We propose a novel framework that leverages ASP‚Äôs declarative nature and logical reasoning capabilities to encode complex security rules as logical predicates. Our ASP-based system was applied to a real-world Linux system log dataset, demonstrating its effectiveness in identifying various anomalies such as potential brute-force attacks, privilege escalations, frequent network connections from specific IPs, and various system-level issues. Key findings highlight ASP‚Äôs strengths in handling structured log data, rule flexibility, and event correlation. The approach shows promise in providing explainable alerts from real-world data. This research contributes to computer forensics by demonstrating a logic-based paradigm for log analysis on a practical dataset, opening avenues for more nuanced and adaptive cyber intelligence systems.\nüì• Save to Zotero üìÑ Download PDF\nPVLS: A Learning-based Parameter Prediction Technique for Variational Quantum Linear Solvers Authors: Youla Yang Venue: arXiv (2025)\nVariational Quantum Linear Solvers (VQLS) are a promising method for solving linear systems on near-term quantum devices. However, their performance is often limited by barren plateaus and inefficient parameter initialization, which significantly hinder trainability as the system size increases. In this work, we introduce PVLS, a learning-based parameter prediction framework that uses Graph Neural Networks (GNNs) to generate high-quality initial parameters for VQLS circuits. By leveraging structural information from the coefficient matrix, PVLS predicts expressive and scalable initializations that improve convergence and reduce optimization difficulty. Extensive experiments on matrix sizes ranging from 16 to 1024 show that PVLS provides up to a 2.6x speedup in optimization and requires fewer iterations while maintaining comparable solution accuracy. These results demonstrate the potential of machine-learning-guided initialization strategies for improving the practicality of hybrid quantum-classical algorithms in the NISQ era.\nüì• Save to Zotero üìÑ Download PDF\nOptical Readout of Reconfigurable Layered Magnetic Domain Structure in CrSBr Authors: Aleksandra ≈Åopion, Pierre-Maurice Piel, Manuel Terbeck, Jan-Hendrik Larusch, Jakob Henz, Marie-Christin Hei√üenb√ºttel, Kseniia Mosina, Thorsten Deilmann, Michael Rohlfing, Zdenek Sofer, Ursula Wurstbauer Venue: arXiv (2025)\nThe emergence of intelligent matter has sparked significant interest in next generation technologies. We report on the discovery of a reconfigurable magnetic multilayer domain structure in the van der Waals magnet CrSBr, exhibiting a unique combination of magnetic and optical properties. Applying an external magnetic field along the easy axis drives the hysteretic antiferromagnetic-to-ferromagnetic transition that is not universally binary, but instead develops through a cascade of intermediate magnetic configurations whose multiplicity and stability scale systematically with thickness. This material can be considered as a prototypical intelligent matter, capable of encoding, processing, and storing information through its tunable magnetic structure. The directly linked optical properties of CrSBr, modulated by the magnetic structure, provide a readout mechanism for the stored information compatible with modern information distribution using light. With its adaptive properties, CrSBr is an attractive candidate for neuromorphic circuitries, enabling the design of brain-inspired computing architectures that can learn and evolve in response to changing environments.\nüì• Save to Zotero üìÑ Download PDF\nOn hyperbolic approximations for a class of dispersive and diffusive-dispersive equations Authors: Rahul Barthwal, Firas Dhaouadi, Christian Rohde Venue: arXiv (2025)\nWe introduce novel approximate systems for dispersive and diffusive-dispersive equations with nonlinear fluxes. For purely dispersive equations, we construct a first-order, strictly hyperbolic approximation. Local well-posedness of smooth solutions is achieved by constructing a unique symmetrizer that applies to arbitrary smooth fluxes. Under stronger conditions on the fluxes, we provide a strictly convex entropy for the hyperbolic system that corresponds to the energy of the underlying dispersive equation. To approximate diffusive-dispersive equations, we rely on a viscoelastic damped system that is compatible with the found entropy for the hyperbolic approximation of the dispersive evolution. For the resulting hyperbolic-parabolic approximation, we provide a global well-posedness result. Using the relative entropy framework \\cite{dafermos2005hyperbolic}, we prove that the solutions of the approximate systems converge to solutions of the original equations. The structure of the new approximate systems allows to apply standard numerical simulation methods from the field of hyperbolic balance laws. We confirm the convergence of our approximations even beyond the validity range of our theoretical findings on set of test cases covering different target equations. We show the applicability of the approach for strong nonlinear effects leading to oscillating or shock-layer-forming behavior.\nüì• Save to Zotero üìÑ Download PDF\nShorting Dynamics and Structured Kernel Regularization Authors: James Tian Venue: arXiv (2025)\nThis paper develops a nonlinear operator dynamic that progressively removes the influence of a prescribed feature subspace while retaining maximal structure elsewhere. The induced sequence of positive operators is monotone, admits an exact residual decomposition, and converges to the classical shorted operator. Transporting this dynamic to reproducing kernel Hilbert spaces yields a corresponding family of kernels that converges to the largest kernel dominated by the original one and annihilating the given subspace. In the finite-sample setting, the associated Gram operators inherit a structured residual decomposition that leads to a canonical form of kernel ridge regression and a principled way to enforce nuisance invariance. This gives a unified operator-analytic approach to invariant kernel construction and structured regularization in data analysis.\nüì• Save to Zotero üìÑ Download PDF\nSeries of quasi-uniform scatterings with fast search, root systems and neural network classifications Authors: Igor V. Netay Venue: arXiv (2025)\nIn this paper we describe an approach to construct large extendable collections of vectors in predefined spaces of given dimensions. These collections are useful for neural network latent space configuration and training. For classification problem with large or unknown number of classes this allows to construct classifiers without classification layer and extend the number of classes without retraining of network from the very beginning. The construction allows to create large well-spaced vector collections in spaces of minimal possible dimension. If the number of classes is known or approximately predictable, one can choose sufficient enough vector collection size. If one needs to significantly extend the number of classes, one can extend the collection in the same latent space, or to incorporate the collection into collection of higher dimensions with same spacing between vectors. Also, regular symmetric structure of constructed vector collections can significantly simplify problems of search for nearest cluster centers or embeddings in the latent space. Construction of vector collections is based on combinatorics and geometry of semi-simple Lie groups irreducible representations with highest weight.\nüì• Save to Zotero üìÑ Download PDF\nPENCO: A Physics-Energy-Numerical-Consistent Operator for 3D Phase Field Modeling Authors: Mostafa Bamdad, Mohammad Sadegh Eshaghi, Cosmin Anitescu, Navid Valizadeh, Timon Rabczuk Venue: arXiv (2025)\nAccurate and efficient solutions of spatio-temporal partial differential equations (PDEs), such as phase-field models, are fundamental for understanding interfacial dynamics and microstructural evolution in materials science and fluid mechanics. Neural Operators (NOs) have recently emerged as powerful data-driven alternatives to traditional solvers; however, existing architectures often accumulate temporal errors, struggle to generalize in long-horizon simulations, and require large training datasets. To overcome these limitations, we propose PENCO (Physics-Energy-Numerical-Consistent Operator), a hybrid operator-learning framework that integrates physical laws and numerical structure within a data-driven architecture. The formulation introduces an enhanced L^2 Gauss-Lobatto collocation residual around the temporal midpoint that robustly enforces the governing dynamics and significantly improves accuracy, a Fourier-space numerical consistency term that captures the balanced behavior of semi-implicit discretizations, and an energy-dissipation constraint that ensures thermodynamic consistency. Additional low-frequency spectral anchoring and teacher-consistency mechanisms further stabilize learning and suppress long-term error growth. This hybrid design enables PENCO to preserve governing physics while mitigating long-term error growth. Through extensive three-dimensional phase-field benchmarks covering phase ordering, crystallization, epitaxial growth, and complex pattern formation, PENCO demonstrates superior accuracy, stability, and data efficiency compared to state-of-the-art neural operators, including Multi-Head Neural Operator (MHNO) and Fourier Neural Operator (FNO-4D), while maintaining physically consistent evolution. The associated dataset and implementation are available at github.com/MBamdad/PENCO.\nüì• Save to Zotero üìÑ Download PDF\nStochastic Density Functional Theory Through the Lens of Multilevel Monte Carlo Method Authors: Xue Quan, Huajie Chen Venue: arXiv (2025)\nThe stochastic density functional theory (sDFT) has exhibited advantages over the standard Kohn-Sham DFT method and has become an attractive approach for large-scale electronic structure calculations. The sDFT method avoids the expensive matrix diagonalization by introducing a set of random orbitals and approximating the density matrix via Chebyshev expansion of a matrix-valued function. In this work, we study the sDFT with a plane-wave discretization, and discuss variance reduction algorithms in the framework of multilevel Monte Carlo (MLMC) methods. In particular, we show that the density matrix evaluation in sDFT can be decomposed into many levels by increasing the plane-wave cutoffs or the Chebyshev polynomial orders. This decomposition renders the computational cost independent of the discretization size or temperature. To demonstrate the efficiency of the algorithm, we provide rigorous analysis of the statistical errors and present numerical experiments on some material systems.\nüì• Save to Zotero üìÑ Download PDF\nImproving Posterior Inference of Galaxy Properties with Image-Based Conditional Flow Matching Authors: Mikaeel Yunus, John F. Wu, Benne W. Holwerda Venue: arXiv (2025)\nEstimating physical properties of galaxies from wide-field surveys remains a central challenge in astrophysics. While spectroscopy provides precise measurements, it is observationally expensive, and photometry discards morphological information that correlates with mass, star formation history, metallicity, and dust. We present a conditional flow matching (CFM) framework that leverages pixel-level imaging alongside photometry to improve posterior inference of galaxy properties. Using $\\sim10^5$ SDSS galaxies, we compare models trained on photometry alone versus photometry plus images. The image+photometry model outperforms the photometry-only model in posterior inference and more reliably recovers known scaling relations. Morphological information also helps mitigate the dust‚Äìage degeneracy. Our results highlight the potential of integrating morphology into photometric SED fitting pipelines, opening a pathway towards more accurate and physically informed constraints on galaxy properties.\nüì• Save to Zotero üìÑ Download PDF\nOn random matrix statistics of 3d gravity Authors: Daniel L. Jafferis, Liza Rozenberg, Debmalya Sarkar, Diandian Wang Venue: arXiv (2025)\nWe show that 3d gravity on manifolds that are topologically a Riemann surface times an interval $Œ£_{g,n}\\times I$ with end-of-the-world branes at the ends of the interval is described by a random matrix model, namely the Virasoro minimal string. Because these manifolds have $n$ annular asymptotic boundaries, the path integrals naturally correspond to spectral correlators of open strings upon inverse Fourier transforms. For $g=0$ and $n=2$, we carry out an explicit path integration and find precise agreement with the universal random matrix expression. For Riemann surfaces with negative Euler characteristic, we evaluate the path integral as a gravitational inner product between states prepared by two copies of Virasoro TQFT. Along the way, we clarify the effects of gauging the mapping class group and the connection to chiral 3d gravity.\nüì• Save to Zotero üìÑ Download PDF\nDistributed Riemannian Optimization in Geodesically Non-convex Environments Authors: Xiuheng Wang, Ricardo Borsoi, C√©dric Richard, Ali H. Sayed Venue: arXiv (2025)\nThis paper studies the problem of distributed Riemannian optimization over a network of agents whose cost functions are geodesically smooth but possibly geodesically non-convex. Extending a well-known distributed optimization strategy called diffusion adaptation to Riemannian manifolds, we show that the resulting algorithm, the Riemannian diffusion adaptation, provably exhibits several desirable behaviors when minimizing a sum of geodesically smooth non-convex functions over manifolds of bounded curvature. More specifically, we establish that the algorithm can approximately achieve network agreement in the sense that Fr√©chet variance of the iterates among the agents is small. Moreover, the algorithm is guaranteed to converge to a first-order stationary point for general geodesically non-convex cost functions. When the global cost function additionally satisfies the Riemannian Polyak-Lojasiewicz (PL) condition, we also show that it converges linearly under a constant step size up to a steady-state error. Finally, we apply this algorithm to a decentralized robust principal component analysis (PCA) problem formulated on the Grassmann manifold and illustrate its convergence and performance through numerical simulations.\nüì• Save to Zotero üìÑ Download PDF\nAnalytical and Cross-Sectional Clinical Validity of a Smartphone-Based U-Turn Test in Multiple Sclerosis Authors: Marta P≈Çonka, Rafa≈Ç Klimas, Dimitar Stanev, Lorenza Angelini, Natan Napi√≥rkowski, Gabriela Gonz√°lez Chan, Lisa Bunn, Paul S Glazier, Richard Hosking, Jenny Freeman, Jeremy Hobart, Mattia Zanon, Jonathan Marsden, Licinio Craveiro, Mike D Rinderknecht Venue: arXiv (2025)\nThe observational GaitLab study (ISRCTN15993728) enrolled adult people with multiple sclerosis (PwMS) with Expanded Disability Status Scale (EDSS) \u003c=6.5. PwMS performed the U-Turn Test (UTT), a smartphone-based assessment of dynamic balance, in a gait laboratory (supervised setting) using 6 smartphones at different body locations and daily during a 2-week remote period (unsupervised setting) using 1 smartphone. In the supervised setting, the accuracy of detecting turns with smartphones was compared against turns detected with a motion capture system (mocap) using F1 scores. Agreement between turn speed measured with smartphones and mocap was assessed by intraclass correlation coefficient (ICC[3,1]) and bias. In the unsupervised setting, test-retest reliability was assessed by ICC(2,1), and correlations with clinical and patient-reported measures by Spearman rank correlation. Ninety-six PwMS were included. In the supervised setting, turns were detected with high accuracy (F1 scores \u003e95% across smartphone wear locations). Smartphone-derived turn speed was comparable across the supervised (1.44 rad/s) and unsupervised settings (1.47 rad/s), and with mocap-derived turn speed (1.47 rad/s). ICC(3,1) revealed high agreement between smartphone- and mocap-derived turn speed (ICC[3,1]: 0.87-0.92 across smartphone wear locations). Bias was minimal (-0.04 to 0.11 rad/s). In the unsupervised setting, test-retest reliability (ICC[2,1]) was \u003e0.90 when aggregating \u003e=2 tests. The UTT correlated with Timed 25-Foot Walk gait speed, EDSS, Ambulation score, 12-item Multiple Sclerosis Walking Scale, and Activities-specific Balance Confidence scale (r=-0.79 to -0.61). The UTT measures turn speed accurately and reproducibly irrespective of smartphone wear location and settings. These findings affirm its potential as a valuable tool in multiple sclerosis trials.\nüì• Save to Zotero üìÑ Download PDF\nFENCE: Flexible Electric Noise Cancellation Endo-shield for the Suppression of Electromagnetic Interference in Low-Field MRI Authors: Julia Pfitzer, Martin Uecker, Hermann Scharfetter Venue: arXiv (2025)\nElectromagnetic interference (EMI) is a significant challenge for low-field MRI systems operating without conventional Faraday-shielded rooms. Traditional EMI mitigation approaches include external shields, subject grounding via electrodes, or active noise cancellation requiring synchronized receive channels. These methods either limit portability, introduce patient discomfort, or demand expensive hardware. In this work, we start from the hypothesis that EMI primarily couples capacitively from the body to the RF coil. We investigated two methods of blocking capacitive coupling while preserving inductive MRI signal detection: First, we employed capacitive segmentation of the RF coil and studied its effect on EMI coupling. Second, we present FENCE (Flexible Electromagnetic Noise Cancellation Endo-shield), a novel approach blocking capacitive coupling using flexible PCB shields placed inside the RF coil. FENCE can be retrofitted to existing RF coils. Finite element (FE) simulations were used to estimate the expected shielding performance and the impact on RF coil losses prior to practical implementation. Testing in various realistic scenarios then demonstrated that the combination of FENCE with segmented coils is effective against both environmental noise sources and controlled EMI. In phantom experiments, FENCE increased SNR by up to a factor of 9 and reduced EMI levels to near-baseline levels with 9% reduction in coil quality factor (Q factor), showing good agreement with the predictions from the FE simulations. In-vivo head imaging confirmed these results across diverse electromagnetic environments where SNR increased by up to a factor 2 while showing an 18% decrease in Q factor. FENCE‚Äôs simple design provides a low-cost solution to EMI in low-field MRI, enhancing image quality while maintaining system portability and accessibility.\nüì• Save to Zotero üìÑ Download PDF\nControlling Carbon Nanostructure Synthesis in Thermal Plasma Jet: Correlation of Process Parameters, Plasma Characteristics, and Product Morphology Authors: Taki Aissou, Jerome Menneveux, Fanny Casteignau, Nadi Braidy, Jocelyn Veilleux Venue: arXiv (2025)\nThermal plasma has emerged as an effective approach for producing carbon nanostructures without the need for specific catalysts nor substrates. While efforts have focused on the effect of process parameters such as reaction pressure, input power or carbon source, the intricate role and relationship with plasma characteristics like density and temperature are often overlooked due to the complexity of the environment. This study addresses this gap by establishing a correlation between process parameters, plasma characteristics, and product morphology, essential for controlling the growth of carbon nanostructures. We explored the impact of carbon precursor type (CH4 and C2H2), hydrogen, pressure, and flow rate on nanostructure formation. Using in situ optical emission spectroscopy (OES), we mapped the distribution of both temperature and dicarbon molecule (C2) density within the plasma jet. We demonstrate that the growth of low-density nanostructures, such as carbon nanohorns (CNHs), is favoured at dilute C2 local densities and high temperatures, while denser nanostructures, such as onion-like polyhedral graphitic nanocapsules (GNCs), are favoured at higher C2 densities and lower temperatures. The carbon density can be controlled by the flow rate and the pressure, which in turn significantly influence the nanostructure morphology, evolving from graphene nanoflakes (GNFs) to GNCs as either parameter increases. Increasing the H/C ratio from 1 to 8 resulted in a morphological transition from CNHs to GNFs. During the synthesis, the plasma jet temperature surpassed 3,000 K, with crystalline growth occurring 50 to 100 mm below the nozzle.\nüì• Save to Zotero üìÑ Download PDF\nIsostructural phase transition and equation of state of type-I and type-VIII metallic sodium borosilicide clathrates Authors: M. Demoucron, S. Pandolfi, Y. Guarnelli, B. Baptiste, P. Chevignon, N. Guignot, D. Portehault, T. A. Strobel, W. A. Crichton, Y. Le Godec, A. Courac Venue: arXiv (2025)\nElectronic properties of silicon-based clathrates can be tuned by boron incorporation into the silicon cage network. Sodium borosilicides clathrate outstands with uncommon stoichiometry and expected metallic properties, in contrast to other alcali metal semiconductive Zintl borosilicides. In this study, we report an experimental investigation of the high-pressure behavior of type-I and type-VIII sodium borosilicide clathrates. An isostructural phase transition, marked by an abrupt volume collapse at 13 GPa, is observed exclusively in type-I sodium borosilicide clathrates. This transition is attributed to the pressure-induced diffusion of silicon atoms into cationic sites. This mechanism provides the first experimental validation of a transition predicted theoretically for this class of materials. Isostructural phase transitions were only observed in type-I borosilicide. In contrast, the type-VIII borosilicide phase exhibits conventional elastic compression. The metallic character was established using reflectance spectroscopy over a wide energy range, in good agreement with crystallographic data on the boron content.\nüì• Save to Zotero üìÑ Download PDF\nVNS Tokamak OpenMC-Serpent Validation for Medical Isotope Studies Authors: Christopher Ehrich, Christian Bachmann, Pavel Pereslavtsev, Christian Reiter Venue: arXiv (2025)\nThe Volumetric Neutron Source (VNS) tokamak is a proposed fusion reactor for testing and qualification of reactor components for future use in a fusion power facility, and has potential use for radioisotope production. The VNS geometry is modeled in the Serpent and OpenMC neutronics codes. Analog neutron-photon coupled simulations are carried out to compare the model‚Äôs vacuum vessel and blanket components across codes. In the vacuum vessel, neutron and photon flux maps are calculated, while in the blanket region, neutron and photon spectra, (n,T), and (n,2n) reaction rates are calculated and compared between models. The detector response comparisons found the following: neutron flux and (n,T) reactions achieved excellent agreement, the (n,2n) detector response had good agreement, and photon flux had regional discrepancies depending on Serpent tracking used. Hybrid tracking lead to a relative difference of about 20% in the outboard side blanket, where as employment of delta tracking resulted in less than 1% relative difference. On an HPC cluster, Serpent was found to have shorter computation time than OpenMC in neutron photon coupled simulations using both hybrid tracking and delta tracking, but longer in neutron only simulations. An exemplary radioisotope production case is presented for the demonstration of additional VNS capabilities.\nüì• Save to Zotero üìÑ Download PDF\nEmbodied Co-Design for Rapidly Evolving Agents: Taxonomy, Frontiers, and Challenges Authors: Yuxing Wang, Zhiyu Chen, Tiantian Zhang, Qiyue Yin, Yongzhe Chang, Zhiheng Li, Liang Wang, Xueqian Wang Venue: arXiv (2025)\nBrain-body co-evolution enables animals to develop complex behaviors in their environments. Inspired by this biological synergy, embodied co-design (ECD) has emerged as a transformative paradigm for creating intelligent agents-from virtual creatures to physical robots-by jointly optimizing their morphologies and controllers rather than treating control in isolation. This integrated approach facilitates richer environmental interactions and robust task performance. In this survey, we provide a systematic overview of recent advances in ECD. We first formalize the concept of ECD and position it within related fields. We then introduce a hierarchical taxonomy: a lower layer that breaks down agent design into three fundamental components-controlling brain, body morphology, and task environment-and an upper layer that integrates these components into four major ECD frameworks: bi-level, single-level, generative, and open-ended. This taxonomy allows us to synthesize insights from more than one hundred recent studies. We further review notable benchmarks, datasets, and applications in both simulated and real-world scenarios. Finally, we identify significant challenges and offer insights into promising future research directions. A project associated with this survey has been created at https://github.com/Yuxing-Wang-THU/SurveyBrainBody.\nüì• Save to Zotero üìÑ Download PDF\nHuman Cognitive Biases in Explanation-Based Interaction: The Case of Within and Between Session Order Effect Authors: Dario Pesenti, Alessandro Bogani, Katya Tentori, Stefano Teso Venue: arXiv (2025)\nExplanatory Interactive Learning (XIL) is a powerful interactive learning framework designed to enable users to customize and correct AI models by interacting with their explanations. In a nutshell, XIL algorithms select a number of items on which an AI model made a decision (e.g. images and their tags) and present them to users, together with corresponding explanations (e.g. image regions that drive the model‚Äôs decision). Then, users supply corrective feedback for the explanations, which the algorithm uses to improve the model. Despite showing promise in debugging tasks, recent studies have raised concerns that explanatory interaction may trigger order effects, a well-known cognitive bias in which the sequence of presented items influences users‚Äô trust and, critically, the quality of their feedback. We argue that these studies are not entirely conclusive, as the experimental designs and tasks employed differ substantially from common XIL use cases, complicating interpretation. To clarify the interplay between order effects and explanatory interaction, we ran two larger-scale user studies (n = 713 total) designed to mimic common XIL tasks. Specifically, we assessed order effects both within and between debugging sessions by manipulating the order in which correct and wrong explanations are presented to participants. Order effects had a limited, through significant impact on users‚Äô agreement with the model (i.e., a behavioral measure of their trust), and only when examined withing debugging sessions, not between them. The quality of users‚Äô feedback was generally satisfactory, with order effects exerting only a small and inconsistent influence in both experiments. Overall, our findings suggest that order effects do not pose a significant issue for the successful employment of XIL approaches. More broadly, our work contributes to the ongoing efforts for understanding human factors in AI.\nüì• Save to Zotero üìÑ Download PDF\nThe next-to-next-to-leading-order QCD corrections to $e^+e^-\\to Œ∑_c/œá_{cJ}+Œ≥$ at B factories Authors: Cong Li, Wen-Long Sang, Hong-Fei Zhang Venue: arXiv (2025)\nWe investigate the processes $e^+e^-\\to Œ∑_c+Œ≥$ and $e^+e^-\\to œá_{cJ}+Œ≥$ at B factories within the NRQCD factorization framework, computing the corresponding helicity amplitudes through $\\mathcal{O}(Œ±_s^2)$. The short-distance coefficients are obtained as series expansions in $r=\\frac{4m_c^2}{s}$ around $r=0, 1/3, 2/3, 1$, using the method of differential equations. By combining the expansions from all four points, we construct composite asymptotic expressions that reproduce the exact results accurately over the full range $0 \\leq r\\leq 1$, with relative errors below $0.1%$ over most of the domain and remaining under $1%$ elsewhere. Analytic expressions for the leading and next-to-leading logarithmic terms are extracted in the limit $r\\to 0$. Using these results, we compute the unpolarized cross sections and observe that the perturbative corrections are small for $œá_{c0}+Œ≥$, moderate for $œá_{c1}+Œ≥$, and substantial for $Œ∑_c+Œ≥$ and $œá_{c2}+Œ≥$. Theoretical prediction for $œá_{c1}+Œ≥$ is consistent with the {\\tt Belle} measurement within $2œÉ$, showing good agreement between theory and experiment. We also predict the angular distribution parameters $Œ±^H_Œ∏$, which are insensitive to NRQCD matrix elements and exhibit small theoretical uncertainties. These parameters further display good stability across different perturbative orders. With the high luminosity anticipated at {\\tt Belle 2}, future experimental measurements will thus provide a clear test of NRQCD factorization.\nüì• Save to Zotero üìÑ Download PDF\nStatic Fission Properties of Even-Even Actinides within the Warsaw Macroscopic-Microscopic Model Using Fourier-over-Spheroid Parameterization Authors: A. Augustyn, T. Cap, R. Capote, M. Kowal, K. Pomorski Venue: arXiv (2025)\nA systematic study of fission barrier heights and static properties of even-even actinide nuclei from Th to Cf has been performed within the Warsaw macroscopic-microscopic model using the five-dimensional Fourier-over-Spheroid (FoS) shape parameterization. The use of a large deformation grid, containing about $1.3\\times10^{8}$ points for each nucleus, allows for a refined and numerically complete exploration of the potential energy landscape without dividing the configuration space into subregions or applying interpolation. Barrier heights, extracted via the Immersion Water Flow method, show good agreement with empirical evaluations (including the new IAEA RIPL-4 dataset) with mean deviations below 1 MeV. Special attention is given to the long-debated third, hyperdeformed minimum. For Th isotopes, a shallow but distinct third well appears, whereas it‚Äôs absent in heavier actinides (U, Pu).\nüì• Save to Zotero üìÑ Download PDF\nFlux-controlled wall model for large eddy simulation integrating the compressible law of the wall Authors: Youjie Xu, Steffen J. Schmidt, Nikolaus A. Adams Venue: arXiv (2025)\nRecent advances in velocity and temperature transformations have enabled recovery of the law of the wall in compressible wall-bounded turbulent flows. Building on this foundation, a flux-controlled wall model (FCWM) for Large Eddy Simulation (LES) is proposed. Unlike conventional wall-stress models that solve the turbulent boundary layer equations, FCWM formulates the near-wall modeling as a control problem applied directly to the outer LES solution. It consists of three components: (1) the compressible law of the wall, (2) a feedback flux-control strategy, and (3) a shifted boundary condition. The model adjusts the wall shear stress and heat flux based on discrepancies between the computed and target transformed velocity and temperature, respectively, at the matching location. The proposed wall model is evaluated using LES of turbulent channel flows across a broad range of conditions, including quasi-incompressible cases with bulk Mach number (M_b = 0.1) and friction Reynolds number (Re_œÑ= 180 \\sim 10{,}000), and compressible cases with (M_b = 0.74 \\sim 4.0) and bulk Reynolds number (Re_b = 7667 \\sim 34{,}000). The wall-modelled LES reproduce mean velocity and temperature profiles in agreement with direct numerical simulation data. For all tested cases with (M_b \\leq 3), the wall model achieves relative errors of (|Œµ_{C_f}| \u003c 4.1%), (|Œµ_{B_q}| \u003c 2.7%), and (|Œµ_{T_c}| \u003c 2.7%) in friction coefficient, non-dimensional heat flux, and centerline temperature, respectively. In the quasi-incompressible regime, the wall model achieves (|Œµ_{C_f}| \u003c 1%). Compared to the conventional equilibrium wall model, the proposed FCWM achieves higher accuracy in compressible turbulent channel flows without solving the boundary layer equations, thereby reducing computational cost.\nüì• Save to Zotero üìÑ Download PDF\nProbing chiral topological states with permutation defects Authors: Yarden Sheffer, Ruihua Fan, Ady Stern, Erez Berg, Shinsei Ryu Venue: arXiv (2025)\nThe hallmark of two-dimensional chiral topological phases is the existence of anomalous gapless modes at the spatial boundary. Yet, the manifestation of this edge anomaly within the bulk ground-state wavefunction itself remains only partially understood. In this work, we introduce a family of multipartite entanglement measures that probe chirality directly from the bulk wavefunction. Our construction involves applying different permutations between replicas of the ground state wavefunction in neighboring spatial regions, creating ‚Äúpermutation defects‚Äù at the boundaries between these regions. We provide general arguments for the robustness of these measures and develop a field-theoretical framework to compute them systematically. While the standard topological field theory prescription misses the chiral contribution, our method correctly identifies it as the chiral conformal field theory partition function on high-genus Riemann surfaces. This feature is a consequence of the bulk-edge correspondence, which dictates that any regularization of the theory at the permutation defects must introduce gapless boundary modes. We numerically verify our results with both free-fermion and strongly-interacting chiral topological states and find excellent agreement. Our results enable the extraction of the chiral central charge and the Hall conductance using a finite number of wavefunction replicas, making these quantities accessible to Monte-Carlo numerical techniques and noisy intermediate-scale quantum devices.\nüì• Save to Zotero üìÑ Download PDF\nContract-Governed Training for Earth Observation: Observed Service Agreement Graphs and Coverage-Accuracy Trade-offs Authors: Wenzhang Du Venue: arXiv (2025)\nEarth observation (EO) models are frequently trained under implicit sampling policies that optimize global accuracy but provide no explicit guarantees on who (which regions, classes, or mission-critical strata) is being served throughout training. This paper introduces a contract-governed training paradigm for EO in which training samples are grouped into service contracts ‚Äì semantically meaningful units such as (dataset, region, rare-crop indicator) ‚Äì and each contract is assigned a target service share. We instantiate this paradigm as an Observed Service Agreement Graph (OSAG), a lightweight governance layer that (i) monitors contract-level exposure (coverage) during optimization, (ii) drives empirical coverage toward target shares via contract-normalized sampling weights, and (iii) exposes explicit accuracy-governance trade-offs through two knobs: a sampling mixture coefficient alpha and a contract-regularization weight lambda_C. We provide a compact theory in a toy setting: OSAG sampling concentrates empirical coverage to targets; coverage deviations upper-bound service-risk deviations; and contract design (coarse vs. fine) modulates governance cost. Experiments on AVIRIS hyperspectral scenes (Indian Pines plus Salinas) and multispectral Sentinel-2 EuroSAT demonstrate that OSAG can substantially reduce priority coverage error while maintaining global accuracy and improving high-priority accuracy. A EuroSAT coarse-vs-fine contract ablation further evidences how semantically refined contracts can reduce the accuracy cost per unit of governance improvement.\nüì• Save to Zotero üìÑ Download PDF\nPhase transitions on the dark side of the Gross-Neveu model Authors: Gabriel Osiander Rein, Fakher F. Assaad, Igor F. Herbut Venue: arXiv (2025)\nGross-Neveu model in 2+1 dimensions exhibits a continuous transition from gapless Dirac semimetal to the gapped quantum anomalous Hall (QAH) insulator at a finite (attractive) coupling, at which the inversion and time-reversal symmetry become spontaneously broken, and the flavor O($M$) symmetry remains preserved. A unification of leading order parameters of 2+1 dimensional $N$ four-component Dirac fermions collects all Lorentz-singlet mass-like fermion bilinears, except the one condensing in the QAH state, into an irreducible representation of the O($M=4N$), and predicts another phase transition in the Gross-Neveu model to occur at a strong (repulsive) coupling. Here, a fermionic auxiliary-field quantum Monte Carlo algorithm is employed in order to study a lattice realization of the Gross-Neveu field theory in the repulsive regime, where the sign problem is absent. We indeed find the O($4N$) symmetry breaking transition out of Dirac semimetal to occur and to be weakly first-order for $N=2$, relevant to graphene. The size of the discontinuity and the magnitude of the critical coupling, however, both grow with $N$. Adding a finite chemical potential is found to break the symmetry and cause superconductivity. These results are in broad agreement with the predictions of the unified field theory. Our lattice model also displays an interesting exact O($2N$) symmetry, a subgroup of the low-energy O($4N$), and has the ordered ground state with the order parameter that belongs to its $N(2N-1)$-dimensional representation. Other order parameters are also examined, and a certain hierarchy among those that belong to different representations of the exact $O(2N)$ is observed.\nüì• Save to Zotero üìÑ Download PDF\nThe dynamical memory of tidal stellar streams: Joint inference of the Galactic potential and the progenitor of GD-1 with flow matching Authors: Giuseppe Viterbo, Tobias Buck Venue: arXiv (2025)\nStellar streams offer one of the most sensitive probes of the Milky Way`s gravitational potential, as their phase-space morphology encodes both the tidal field of the host galaxy and the internal structure of their progenitors. In this work, we introduce a framework that leverages Flow Matching and Simulation-Based Inference (SBI) to jointly infer the parameters of the GD-1 progenitor and the global properties of the Milky Way potential. Our aim is to move beyond traditional techniques (e.g. orbit-fitting and action-angle methods) by constructing a fully Bayesian, likelihood-free posterior over both host-galaxy parameters and progenitor properties, thereby capturing the intrinsic coupling between tidal stripping dynamics and the underlying potential. To achieve this, we generate a large suite of mock GD-1-like streams using our differentiable N-body code \\textsc{\\texttt{Odisseo}}, sampling self-consistent initial conditions from a Plummer sphere and evolving them in a flexible Milky Way potential model. We then apply conditional Flow Matching to learn the vector field that transports a base Gaussian distribution into the posterior, enabling efficient, amortized inference directly from stream phase-space data. We demonstrate that our method successfully recovers the true parameters of a fiducial GD-1 simulation, producing well-calibrated posteriors and accurately reproducing parameter degeneracies arising from progenitor-host interactions. Flow Matching provides a powerful, flexible framework for Galactic Archaeology. Our approach enables joint inference on progenitor and Galactic parameters, capturing complex dependencies that are difficult to model with classical likelihood-based methods.\nüì• Save to Zotero üìÑ Download PDF\nA hybrid Green-Kubo (hGK) framework for calculating viscosity from short MD simulations Authors: Akash K. Meel, Santosh Mogurampelly Venue: arXiv (2025)\nViscosity calculation from equilibrium molecular dynamics (MD) simulations relies on the traditional Green-Kubo (GK) framework, which integrates the stress autocorrelation function (SACF) over time. While the formalism is exact in the linear response regime, the traditional approach often suffers from poor convergence and requires extensive phase space sampling, which is computationally demanding for soft matter and polymer systems. In this Letter, we introduce a hybrid Green-Kubo (hGK) framework that alleviates these limitations by partitioning the SACF into two physically meaningful regimes: (i) a short time ballistic component extracted directly from short MD simulations, and (ii) a long time relaxation tail represented using analytically motivated functions, $œÜ(œÑ)$, fitted only to short trajectories. This strategy bypasses the need for extensive sampling while preserving physical rigor. Benchmarking against SPC/E water confirms excellent agreement with established results, and we further demonstrate the efficacy of the method for challenging electrolyte systems (EC-LiTFSI and PEO-LiTFSI), for which the GK framework fails to converge. The computational savings are substantial, with reductions of several orders of magnitude in required sampling, achieved without compromising predictive accuracy. We also discuss the limitations of the hGK framework and outline clear avenues for refinement, including optimal tail selection and robust identification of relaxation regimes in noisy stress data. The hGK framework presented in this Letter provides a conceptually simple, broadly applicable, and computationally efficient route for viscosity prediction in molecular liquids, polymer melts, and ionically conducting soft materials.\nüì• Save to Zotero üìÑ Download PDF\nConvergence Dynamics and Scaling Laws in the Dissipative Relativistic Kicked Rotator Authors: Daniel Borin, Danilo S. Rando, Edson D. Leonel, Diego F. M. Oliveira Venue: arXiv (2025)\nWe investigate the convergence dynamics of this system near period-doubling bifurcations by combining analytical derivations and large-scale numerical simulations. At the bifurcation threshold ($K = K_c$), the dynamics reduce to a normal form that produces a power-law decay $d(n) \\propto n^{-1/2}$, from which the critical exponents $Œ±= 1$, $Œ≤= -1/2$, and $z = -2$ are derived. These analytical predictions are confirmed numerically and shown to satisfy the homogeneous scaling relation $z = Œ±/ Œ≤$. Linearization of the map near the fixed point yields an exponential relaxation law $d_n = d_0 e^{-n/œÑ}$ for $K \u003c K_c$, with $œÑ\\propto (K_c - K)^{-1}$, leading to the relaxation exponent $Œ¥= -1$. The remarkable agreement between theory and simulation demonstrates that the dissipative relativistic kicked rotator shares the same universality class as one-dimensional unimodal maps, despite its higher dimensionality and relativistic corrections.\nüì• Save to Zotero üìÑ Download PDF\nBiomimetic Liquid Metal Cell Authors: Jingyi Li, Mengwen Qiao, Minghui Guo, Zerong Xing, Yunlong Bai, Ju Wang, Yujia Song, Ren Xu, Xi Zhao, Jing Liu Venue: arXiv (2025)\nGallium-based liquid metals, as a broad category of emerging functional materials with unique physical, chemical, and biological properties, offer numerous possibilities for advancing intelligent systems. However, a basic query persistently remains for the complex liquid metal system: Is there a minimal functional unit that can fully capture its diversity of morphology and function? Cells, as the most basic structural and functional units of life, are small in scale but have complex structures, functions, and life activities. Analogous to nature, this article proposes the concept of liquid metal cells, and systematically explores their construction routes, sensing capabilities, motion behaviors, and potential applications. We first construct a multi-phase composite structure with liquid metal as the nucleus, ionic solution as the cytoplasm, and polymer as the cell membrane by developing a layered cryogenic molding method. Furthermore, we reveal that liquid metal cells exhibit inherently versatile responsive characteristics and self-adaptive behaviors to thermal, pressure, chemical, electrical, and magnetic fields, indicating ‚Äúsmall world, vast potential‚Äù. Based on these fundamental findings, we finally demonstrate the feasibility of utilizing liquid metal cells as sensors, fluidic valves, and material transport carriers in flow channels through dynamic control.\nüì• Save to Zotero üìÑ Download PDF\nExecutable Governance for AI: Translating Policies into Rules Using LLMs Authors: Gautam Varma Datla, Anudeep Vurity, Tejaswani Dash, Tazeem Ahmad, Mohd Adnan, Saima Rafi Venue: arXiv (2025)\nAI policy guidance is predominantly written as prose, which practitioners must first convert into executable rules before frameworks can evaluate or enforce them. This manual step is slow, error-prone, difficult to scale, and often delays the use of safeguards in real-world deployments. To address this gap, we present Policy-to-Tests (P2T), a framework that converts natural-language policy documents into normalized, machine-readable rules. The framework comprises a pipeline and a compact domain-specific language (DSL) that encodes hazards, scope, conditions, exceptions, and required evidence, yielding a canonical representation of extracted rules. To test the framework beyond a single policy, we apply it across general frameworks, sector guidance, and enterprise standards, extracting obligation-bearing clauses and converting them into executable rules. These AI-generated rules closely match strong human baselines on span-level and rule-level metrics, with robust inter-annotator agreement on the gold set. To evaluate downstream behavioral and safety impact, we add HIPAA-derived safeguards to a generative agent and compare it with an otherwise identical agent without guardrails. An LLM-based judge, aligned with gold-standard criteria, measures violation rates and robustness to obfuscated and compositional prompts. Detailed results are provided in the appendix. We release the codebase, DSL, prompts, and rule sets as open-source resources to enable reproducible evaluation.\nüì• Save to Zotero üìÑ Download PDF\nHairy black holes via gravitational decoupling: light rings, absorption and spectral lines Authors: Gabriel P. Ribeiro, Renan B. Magalh√£es, Lu√≠s C. B. Crispino Venue: arXiv (2025)\nWe investigate the absorption of massless scalar waves by three distinct hairy black hole solutions obtained through the gravitational decoupling method, considering the weak, the strong or the dominant energy conditions. Remarkably, in certain configurations of hairy black holes associated with the fulfillment of the weak energy condition, quasibound states may appear, resulting in Breit-Wigner-like resonances in their absorption profile. These quasibound states (and consequently the spectral lines in the absorption spectrum) can be related to stable light rings in the spacetime, a structure often associated with horizonless exotic compact objects, such as wormholes. We investigate how the gravitational decoupling method introduces novel light ring structures in hairy black holes and influences the absorption spectra through its deformation parameters. Our numerical results show excellent agreement with well-known approximations.\nüì• Save to Zotero üìÑ Download PDF\nPreparation and magnetic properties of (Ln0.2La0.2Nd0.2Sm0.2 Eu0.2)MnO3 (Ln = Dy, Ho, Er) high-entropy perovskite ceramics containing heavy rare earth elements Authors: Jiedong Qin, Xingmin Feng, Zhiqin Wen, Li Tang, Defeng Long, Yuhong Zhao Venue: arXiv (2025)\nEquimolar ratio high-entropy perovskite ceramics (HEPCs) have attracted much attention due to their excellent magnetization intensity. To further enhance their magnetization intensities, (Ln0.2La0.2Nd0.2Sm0.2Eu0.2)MnO3 (Ln = Dy, Ho and Er, labeled as Ln-LNSEMO) HEPCs are designed based on the configuration entropy Sconfig, tolerance factor t, and mismatch degree. Single-phase HEPCs are synthesized by the solid-phase method in this work, in which the effects of the heavy rare-earth elements Dy, Ho and Er on the structure and magnetic properties of Ln-LNSEMO are systematically studied. The results show that all Ln-LNSEMO HEPCs exhibit high crystallinity and maintain excellent structural stability after sintering at 1250 degree centigrade for 16 h. Ln-LNSEMO HEPCs exhibit significant lattice distortion effects, with smooth surface morphology, clearly distinguishable grain boundaries, and irregular polygonal shapes. The three high-entropy ceramic samples exhibit hysteresis behavior at T = 5 K, with the Curie temperature TC decreasing as the radius of the introduced rare-earth ions decreases, while the saturation magnetization and coercivity increase accordingly. When the average ionic radius of A-site decreases, the interaction between their valence electrons and local electrons in the crystal increases, thereby enhancing the conversion of electrons to oriented magnetic moments under an external magnetic field. Thus, Er-LNSEMO HEPC shows a higher saturation magnetization strength (42.8 emu/g) and coercivity (2.09 kOe) than the other samples, which is attributed to the strong magnetic crystal anisotropy, larger lattice distortion (0.00652), smaller average grain size (440.49 plus or minus 22.02 nm), unit cell volume (229.432 A3) and A-site average ion radius (1.24 A) of its magnet. The Er-LNSEMO HEPC has potential applications in magnetic recording materials.\nüì• Save to Zotero üìÑ Download PDF\nCatching UX Flaws in Code: Leveraging LLMs to Identify Usability Flaws at the Development Stage Authors: Nolan Platt, Ethan Luchs, Sehrish Nizamani Venue: arXiv (2025)\nUsability evaluations are essential for ensuring that modern interfaces meet user needs, yet traditional heuristic evaluations by human experts can be time-consuming and subjective, especially early in development. This paper investigates whether large language models (LLMs) can provide reliable and consistent heuristic assessments at the development stage. By applying Jakob Nielsen‚Äôs ten usability heuristics to thirty open-source websites, we generated over 850 heuristic evaluations in three independent evaluations per site using a pipeline of OpenAI‚Äôs GPT-4o. For issue detection, the model demonstrated moderate consistency, with an average pairwise Cohen‚Äôs Kappa of 0.50 and an exact agreement of 84%. Severity judgments showed more variability: weighted Cohen‚Äôs Kappa averaged 0.63, but exact agreement was just 56%, and Krippendorff‚Äôs Alpha was near zero. These results suggest that while GPT-4o can produce internally consistent evaluations, especially for identifying the presence of usability issues, its ability to judge severity varies and requires human oversight in practice. Our findings highlight the feasibility and limitations of using LLMs for early-stage, automated usability testing, and offer a foundation for improving consistency in automated User Experience (UX) evaluation. To the best of our knowledge, our work provides one of the first quantitative inter-rater reliability analyses of automated heuristic evaluation and highlights methods for improving model consistency.\nüì• Save to Zotero üìÑ Download PDF\nSmall Models Achieve Large Language Model Performance: Evaluating Reasoning-Enabled AI for Secure Child Welfare Research Authors: Zia Qi, Brian E. Perron, Bryan G. Victor, Dragan Stoll, Joseph P. Ryan Venue: arXiv (2025)\nObjective: This study develops a systematic benchmarking framework for testing whether language models can accurately identify constructs of interest in child welfare records. The objective is to assess how different model sizes and architectures perform on four validated benchmarks for classifying critical risk factors among child welfare-involved families: domestic violence, firearms, substance-related problems generally, and opioids specifically. Method: We constructed four benchmarks for identifying risk factors in child welfare investigation summaries: domestic violence, substance-related problems, firearms, and opioids (n=500 each). We evaluated seven model sizes (0.6B-32B parameters) in standard and extended reasoning modes, plus a mixture-of-experts variant. Cohen‚Äôs kappa measured agreement with gold standard classifications established by human experts. Results: The benchmarking revealed a critical finding: bigger models are not better. A small 4B parameter model with extended reasoning proved most effective, outperforming models up to eight times larger. It consistently achieved ‚Äúsubstantial‚Äù to ‚Äúalmost perfect‚Äù agreement across all four benchmark categories. This model achieved ‚Äúalmost perfect‚Äù agreement (\\k{appa} = 0.93-0.96) on three benchmarks (substance-related problems, firearms, and opioids) and ‚Äúsubstantial‚Äù agreement (\\k{appa} = 0.74) on the most complex task (domestic violence). Small models with extended reasoning rivaled the largest models while being more resource-efficient. Conclusions: Small reasoning-enabled models achieve accuracy levels historically requiring larger architectures, enabling significant time and computational efficiencies. The benchmarking framework provides a method for evidence-based model selection to balance accuracy with practical resource constraints before operational deployment in social work research.\nüì• Save to Zotero üìÑ Download PDF\nReasonX: MLLM-Guided Intrinsic Image Decomposition Authors: Alara Dirik, Tuanfeng Wang, Duygu Ceylan, Stefanos Zafeiriou, Anna Fr√ºhst√ºck Venue: arXiv (2025)\nIntrinsic image decomposition aims to separate images into physical components such as albedo, depth, normals, and illumination. While recent diffusion- and transformer-based models benefit from paired supervision from synthetic datasets, their generalization to diverse, real-world scenarios remains challenging. We propose ReasonX, a novel framework that leverages a multimodal large language model (MLLM) as a perceptual judge providing relative intrinsic comparisons, and uses these comparisons as GRPO rewards for fine-tuning intrinsic decomposition models on unlabeled, in-the-wild images. Unlike RL methods for generative models, our framework aligns conditional intrinsic predictors by rewarding agreement between the judge‚Äôs relational assessments and analytically derived relations from the model‚Äôs outputs. ReasonX is model-agnostic and can be applied to different intrinsic predictors. Across multiple base architectures and modalities, ReasonX yields significant improvements, including 9-25% WHDR reduction on IIW albedo and up to 46% depth accuracy gains on ETH3D, highlighting the promise of MLLM-guided comparative supervision to bridge low- and high-level vision reasoning.\nüì• Save to Zotero üìÑ Download PDF\nConfronting cosmic shear astrophysical uncertainties: DES Year 3 revisited Authors: Leah Bigwood, Jamie McCullough, Jared Siegel, Alexandra Amon, George Efstathiou, David Sanchez-Cid, Elisa Legnani, Daniel Gruen, Jonathan Blazek, Cyrille Doux, Aurelio Carnero Rosell, Marco Gatti, Eric Huff, Niall MacCrann, Anna Porredon, Judit Prat Marti, Marcelle Soares dos Santos, Justin Myles, Simon Samuroff, Masaya Yamamoto, Boyan Yin, Joe Zuntz Venue: arXiv (2025)\nCosmology from weak gravitational lensing has been limited by astrophysical uncertainties in baryonic feedback and intrinsic alignments. By calibrating these effects using external data, we recover non-linear information, achieving a 2% constraint on the clustering amplitude, $S_8$, resulting in a factor of two improvement on the $Œõ$CDM constraints relative to the fiducial Dark Energy Survey Year 3 model. The posterior, $S_8=0.832^{+0.013}_{-0.017}$, shifts by $1.5œÉ$ to higher values, in closer agreement with the cosmic microwave background result for the standard six-parameter $Œõ$CDM cosmology. Our approach uses a star-forming ‚Äòblue‚Äô galaxy sample with intrinsic alignment model parameters calibrated by direct spectroscopic measurements, together with a baryonic feedback model informed by observations of X-ray gas fractions and kinematic Sunyaev-Zel‚Äôdovich effect profiles that span a wide range in halo mass and redshift. Our results provide a blueprint for next-generation surveys: leveraging galaxy properties to control intrinsic alignments and external gas probes to calibrate feedback, unlocking a substantial improvement in the precision of weak lensing surveys.\nüì• Save to Zotero üìÑ Download PDF\nA Black-Hole Envelope Interpretation for Cosmological Demographics of Little Red Dots Authors: Hiroya Umeda, Kohei Inayoshi, Yuichi Harikane, Kohta Murase Venue: arXiv (2025)\nLittle red dots (LRDs) newly discovered with JWST are active galactic nuclei (AGN) that may represent black hole (BH) growth at the earliest cosmic epochs. These sources show puzzling features unlike typical AGNs, including red optical continua, weak hot-dust emission, and a lack of detectable X-rays. Previously, LRDs have often been interpreted as dust-reddened AGNs, leading to severe inconsistencies with the luminosity and BH mass densities inferred for previously known AGNs over $0","wordCount":"181552","inLanguage":"zh","datePublished":"2025-12-05T15:29:10.166264Z","dateModified":"2025-12-05T15:29:10.166264Z","author":{"@type":"Person","name":"Gary"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://garyforreal.me/zh/posts/study/paper-2025-12-05-weekly/"},"publisher":{"@type":"Organization","name":"Gary's House","logo":{"@type":"ImageObject","url":"https://garyforreal.me/img/Q.jpg"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css><script src=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><script src=https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js></script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://garyforreal.me/zh/ accesskey=h title="Gary's Blog (Alt + H)"><img src=https://garyforreal.me/img/me.jpg alt aria-label=logo height=35>Gary's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://garyforreal.me/en/ title=English aria-label=English>English</a></li></ul></div></div><ul id=menu><li><a href=https://garyforreal.me/zh/search title="üîçÊêúÁ¥¢ (Alt + /)" accesskey=/><span>üîçÊêúÁ¥¢</span></a></li><li><a href=https://garyforreal.me/zh/ title=üè†‰∏ªÈ°µ><span>üè†‰∏ªÈ°µ</span></a></li><li><a href=https://garyforreal.me/zh/posts/ title=üìöÊñáÁ´†><span>üìöÊñáÁ´†</span></a></li><li><a href=https://garyforreal.me/zh/archives/ title=‚è±Â≠òÊ°£><span>‚è±Â≠òÊ°£</span></a></li><li><a href=https://garyforreal.me/zh/music/ title=üéµÈü≥‰πê><span>üéµÈü≥‰πê</span></a></li><li><a href=https://garyforreal.me/zh/about title=üôãüèª‚Äç‚ôÇÔ∏èÂÖ≥‰∫é><span>üôãüèª‚Äç‚ôÇÔ∏èÂÖ≥‰∫é</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://garyforreal.me/zh/>‰∏ªÈ°µ</a>&nbsp;¬ª&nbsp;<a href=https://garyforreal.me/zh/posts/>Â∏ñÂ≠ê</a>&nbsp;¬ª&nbsp;<a href=https://garyforreal.me/zh/posts/study/>Â≠¶‰π†</a></div><h1 class="post-title entry-hint-parent">Weekly Paper Notes - 2025-12-05</h1><div class=post-meta><span title='2025-12-05 15:29:10.166264 +0000 UTC'>2025-12-05</span>&nbsp;¬∑&nbsp;853 ÂàÜÈíü&nbsp;¬∑&nbsp;Gary&nbsp;|&nbsp;ËØ≠Ë®Ä:<ul class=i18n_list><li><a href=https://garyforreal.me/en/posts/study/paper-2025-12-05-weekly/>English</a></li></ul><div class=meta-item>&nbsp¬∑&nbsp
        <span id=busuanzi_container_page_pv>Êú¨ÊñáÈòÖËØªÈáè<span id=busuanzi_value_page_pv></span>Ê¨°</span></div></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>ÁõÆÂΩï</span></summary><div class=inner><ul><li><a href=#weekly-paper-notes aria-label="Weekly Paper Notes">Weekly Paper Notes</a><ul><li><a href=#-multilingual aria-label="üîç multilingual">üîç multilingual</a><ul><li><a href=#llms-know-more-than-words-a-genre-study-with-syntax-metaphor--phoneticshttpsarxivorgabs251204957v1 aria-label="LLMs Know More Than Words: A Genre Study with Syntax, Metaphor & Phonetics"><a href=https://arxiv.org/abs/2512.04957v1>LLMs Know More Than Words: A Genre Study with Syntax, Metaphor & Phonetics</a></a></li><li><a href=#toward-continuous-neurocognitive-monitoring-integrating-speech-ai-with-relational-graph-transformers-for-rare-neurological-diseaseshttpsarxivorgabs251204938v1 aria-label="Toward Continuous Neurocognitive Monitoring: Integrating Speech AI with Relational Graph Transformers for Rare Neurological Diseases"><a href=https://arxiv.org/abs/2512.04938v1>Toward Continuous Neurocognitive Monitoring: Integrating Speech AI with Relational Graph Transformers for Rare Neurological Diseases</a></a></li><li><a href=#are-llms-truly-multilingual-exploring-zero-shot-multilingual-capability-of-llms-for-information-retrieval-an-italian-healthcare-use-casehttpsarxivorgabs251204834v1 aria-label="Are LLMs Truly Multilingual? Exploring Zero-Shot Multilingual Capability of LLMs for Information Retrieval: An Italian Healthcare Use Case"><a href=https://arxiv.org/abs/2512.04834v1>Are LLMs Truly Multilingual? Exploring Zero-Shot Multilingual Capability of LLMs for Information Retrieval: An Italian Healthcare Use Case</a></a></li><li><a href=#shared-multi-modal-embedding-space-for-face-voice-associationhttpsarxivorgabs251204814v1 aria-label="Shared Multi-modal Embedding Space for Face-Voice Association"><a href=https://arxiv.org/abs/2512.04814v1>Shared Multi-modal Embedding Space for Face-Voice Association</a></a></li><li><a href=#adibhashaa-a-community-curated-benchmark-for-machine-translation-into-indian-tribal-languageshttpsarxivorgabs251204765v1 aria-label="AdiBhashaa: A Community-Curated Benchmark for Machine Translation into Indian Tribal Languages"><a href=https://arxiv.org/abs/2512.04765v1>AdiBhashaa: A Community-Curated Benchmark for Machine Translation into Indian Tribal Languages</a></a></li><li><a href=#has-acl-lost-its-crown-a-decade-long-quantitative-analysis-of-scale-and-impact-across-leading-ai-conferenceshttpsarxivorgabs251204448v1 aria-label="Has ACL Lost Its Crown? A Decade-Long Quantitative Analysis of Scale and Impact Across Leading AI Conferences"><a href=https://arxiv.org/abs/2512.04448v1>Has ACL Lost Its Crown? A Decade-Long Quantitative Analysis of Scale and Impact Across Leading AI Conferences</a></a></li><li><a href=#mase-interpretable-nlp-models-via-model-agnostic-saliency-estimationhttpsarxivorgabs251204386v1 aria-label="MASE: Interpretable NLP Models via Model-Agnostic Saliency Estimation"><a href=https://arxiv.org/abs/2512.04386v1>MASE: Interpretable NLP Models via Model-Agnostic Saliency Estimation</a></a></li><li><a href=#langsat-a-novel-framework-combining-nlp-and-reinforcement-learning-for-sat-solvinghttpsarxivorgabs251204374v1 aria-label="LangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving"><a href=https://arxiv.org/abs/2512.04374v1>LangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving</a></a></li><li><a href=#computational-linguistics-meets-libyan-dialect-a-study-on-dialect-identificationhttpsarxivorgabs251204257v1 aria-label="Computational Linguistics Meets Libyan Dialect: A Study on Dialect Identification"><a href=https://arxiv.org/abs/2512.04257v1>Computational Linguistics Meets Libyan Dialect: A Study on Dialect Identification</a></a></li><li><a href=#probabilistic-safety-under-arbitrary-disturbance-distributions-using-piecewise-affine-control-barrier-functionshttpsarxivorgabs251204194v1 aria-label="Probabilistic Safety under Arbitrary Disturbance Distributions using Piecewise-Affine Control Barrier Functions"><a href=https://arxiv.org/abs/2512.04194v1>Probabilistic Safety under Arbitrary Disturbance Distributions using Piecewise-Affine Control Barrier Functions</a></a></li><li><a href=#jina-vlm-small-multilingual-vision-language-modelhttpsarxivorgabs251204032v2 aria-label="Jina-VLM: Small Multilingual Vision Language Model"><a href=https://arxiv.org/abs/2512.04032v2>Jina-VLM: Small Multilingual Vision Language Model</a></a></li><li><a href=#adapting-large-language-models-to-low-resource-tibetan-a-two-stage-continual-and-supervised-fine-tuning-studyhttpsarxivorgabs251203976v1 aria-label="Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study"><a href=https://arxiv.org/abs/2512.03976v1>Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study</a></a></li><li><a href=#is-lying-only-sinful-in-islam-exploring-religious-bias-in-multilingual-large-language-models-across-major-religionshttpsarxivorgabs251203943v1 aria-label="Is Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions"><a href=https://arxiv.org/abs/2512.03943v1>Is Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions</a></a></li><li><a href=#diminishing-returns-in-self-supervised-learninghttpsarxivorgabs251203862v1 aria-label="Diminishing Returns in Self-Supervised Learning"><a href=https://arxiv.org/abs/2512.03862v1>Diminishing Returns in Self-Supervised Learning</a></a></li><li><a href=#m3dr-towards-universal-multilingual-multimodal-document-retrievalhttpsarxivorgabs251203514v1 aria-label="M3DR: Towards Universal Multilingual Multimodal Document Retrieval"><a href=https://arxiv.org/abs/2512.03514v1>M3DR: Towards Universal Multilingual Multimodal Document Retrieval</a></a></li><li><a href=#dual-lora-enhancing-lora-with-magnitude-and-direction-updateshttpsarxivorgabs251203402v1 aria-label="Dual LoRA: Enhancing LoRA with Magnitude and Direction Updates"><a href=https://arxiv.org/abs/2512.03402v1>Dual LoRA: Enhancing LoRA with Magnitude and Direction Updates</a></a></li><li><a href=#fine-tuned-large-language-models-for-logical-translation-reducing-hallucinations-with-lang2logichttpsarxivorgabs251202987v1 aria-label="Fine-Tuned Large Language Models for Logical Translation: Reducing Hallucinations with Lang2Logic"><a href=https://arxiv.org/abs/2512.02987v1>Fine-Tuned Large Language Models for Logical Translation: Reducing Hallucinations with Lang2Logic</a></a></li><li><a href=#rfop-rethinking-fusion-and-orthogonal-projection-for-face-voice-associationhttpsarxivorgabs251202860v1 aria-label="RFOP: Rethinking Fusion and Orthogonal Projection for Face-Voice Association"><a href=https://arxiv.org/abs/2512.02860v1>RFOP: Rethinking Fusion and Orthogonal Projection for Face-Voice Association</a></a></li><li><a href=#cross-lingual-prompt-steerability-towards-accurate-and-robust-llm-behavior-across-languageshttpsarxivorgabs251202841v1 aria-label="Cross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages"><a href=https://arxiv.org/abs/2512.02841v1>Cross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages</a></a></li><li><a href=#boom-beyond-only-one-modality-kits-multimodal-multilingual-lecture-companionhttpsarxivorgabs251202817v1 aria-label="BOOM: Beyond Only One Modality KIT&rsquo;s Multimodal Multilingual Lecture Companion"><a href=https://arxiv.org/abs/2512.02817v1>BOOM: Beyond Only One Modality KIT&rsquo;s Multimodal Multilingual Lecture Companion</a></a></li><li><a href=#trilex-a-framework-for-multilingual-sentiment-analysis-in-low-resource-south-african-languageshttpsarxivorgabs251202799v1 aria-label="TriLex: A Framework for Multilingual Sentiment Analysis in Low-Resource South African Languages"><a href=https://arxiv.org/abs/2512.02799v1>TriLex: A Framework for Multilingual Sentiment Analysis in Low-Resource South African Languages</a></a></li><li><a href=#towards-language-independent-face-voice-association-with-multimodal-foundation-modelshttpsarxivorgabs251202759v1 aria-label="Towards Language-Independent Face-Voice Association with Multimodal Foundation Models"><a href=https://arxiv.org/abs/2512.02759v1>Towards Language-Independent Face-Voice Association with Multimodal Foundation Models</a></a></li><li><a href=#crest-universal-safety-guardrails-through-cluster-guided-cross-lingual-transferhttpsarxivorgabs251202711v1 aria-label="CREST: Universal Safety Guardrails Through Cluster-Guided Cross-Lingual Transfer"><a href=https://arxiv.org/abs/2512.02711v1>CREST: Universal Safety Guardrails Through Cluster-Guided Cross-Lingual Transfer</a></a></li><li><a href=#dotsocr-multilingual-document-layout-parsing-in-a-single-vision-language-modelhttpsarxivorgabs251202498v1 aria-label="dots.ocr: Multilingual Document Layout Parsing in a Single Vision-Language Model"><a href=https://arxiv.org/abs/2512.02498v1>dots.ocr: Multilingual Document Layout Parsing in a Single Vision-Language Model</a></a></li><li><a href=#swivuriso-the-south-african-next-voices-multilingual-speech-datasethttpsarxivorgabs251202201v1 aria-label="Swivuriso: The South African Next Voices Multilingual Speech Dataset"><a href=https://arxiv.org/abs/2512.02201v1>Swivuriso: The South African Next Voices Multilingual Speech Dataset</a></a></li><li><a href=#cross-lingual-interleaving-for-speech-language-modelshttpsarxivorgabs251201865v1 aria-label="Cross-Lingual Interleaving for Speech Language Models"><a href=https://arxiv.org/abs/2512.01865v1>Cross-Lingual Interleaving for Speech Language Models</a></a></li><li><a href=#bhram-il-a-benchmark-for-hallucination-recognition-and-assessment-in-multiple-indian-languageshttpsarxivorgabs251201852v1 aria-label="BHRAM-IL: A Benchmark for Hallucination Recognition and Assessment in Multiple Indian Languages"><a href=https://arxiv.org/abs/2512.01852v1>BHRAM-IL: A Benchmark for Hallucination Recognition and Assessment in Multiple Indian Languages</a></a></li><li><a href=#self-supervised-borrowing-detection-on-multilingual-wordlistshttpsarxivorgabs251201713v1 aria-label="Self-Supervised Borrowing Detection on Multilingual Wordlists"><a href=https://arxiv.org/abs/2512.01713v1>Self-Supervised Borrowing Detection on Multilingual Wordlists</a></a></li><li><a href=#demystifying-feature-engineering-in-malware-analysis-of-api-call-sequenceshttpsarxivorgabs251201666v1 aria-label="Demystifying Feature Engineering in Malware Analysis of API Call Sequences"><a href=https://arxiv.org/abs/2512.01666v1>Demystifying Feature Engineering in Malware Analysis of API Call Sequences</a></a></li><li><a href=#deep-flexqp-accelerated-nonlinear-programming-via-deep-unfoldinghttpsarxivorgabs251201565v1 aria-label="Deep FlexQP: Accelerated Nonlinear Programming via Deep Unfolding"><a href=https://arxiv.org/abs/2512.01565v1>Deep FlexQP: Accelerated Nonlinear Programming via Deep Unfolding</a></a></li><li><a href=#mcat-scaling-many-to-many-speech-to-text-translation-with-mllms-to-70-languageshttpsarxivorgabs251201512v1 aria-label="MCAT: Scaling Many-to-Many Speech-to-Text Translation with MLLMs to 70 Languages"><a href=https://arxiv.org/abs/2512.01512v1>MCAT: Scaling Many-to-Many Speech-to-Text Translation with MLLMs to 70 Languages</a></a></li><li><a href=#multilingual-conversational-ai-for-financial-assistance-bridging-language-barriers-in-indian-fintechhttpsarxivorgabs251201439v1 aria-label="Multilingual Conversational AI for Financial Assistance: Bridging Language Barriers in Indian FinTech"><a href=https://arxiv.org/abs/2512.01439v1>Multilingual Conversational AI for Financial Assistance: Bridging Language Barriers in Indian FinTech</a></a></li><li><a href=#backportbench-a-multilingual-benchmark-for-automated-backporting-of-patcheshttpsarxivorgabs251201396v1 aria-label="BackportBench: A Multilingual Benchmark for Automated Backporting of Patches"><a href=https://arxiv.org/abs/2512.01396v1>BackportBench: A Multilingual Benchmark for Automated Backporting of Patches</a></a></li><li><a href=#re-llm-integrating-large-language-models-into-renewable-energy-systemshttpsarxivorgabs251201392v1 aria-label="RE-LLM: Integrating Large Language Models into Renewable Energy Systems"><a href=https://arxiv.org/abs/2512.01392v1>RE-LLM: Integrating Large Language Models into Renewable Energy Systems</a></a></li><li><a href=#marsad-a-multi-functional-tool-for-real-time-social-media-analysishttpsarxivorgabs251201369v1 aria-label="MARSAD: A Multi-Functional Tool for Real-Time Social Media Analysis"><a href=https://arxiv.org/abs/2512.01369v1>MARSAD: A Multi-Functional Tool for Real-Time Social Media Analysis</a></a></li><li><a href=#securing-large-language-models-llms-from-prompt-injection-attackshttpsarxivorgabs251201326v1 aria-label="Securing Large Language Models (LLMs) from Prompt Injection Attacks"><a href=https://arxiv.org/abs/2512.01326v1>Securing Large Language Models (LLMs) from Prompt Injection Attacks</a></a></li><li><a href=#sentiment-analysis-and-emotion-classification-using-machine-learning-techniques-for-nagamese-language---a-low-resource-languagehttpsarxivorgabs251201256v1 aria-label="Sentiment Analysis and Emotion Classification using Machine Learning Techniques for Nagamese Language - A Low-resource Language"><a href=https://arxiv.org/abs/2512.01256v1>Sentiment Analysis and Emotion Classification using Machine Learning Techniques for Nagamese Language - A Low-resource Language</a></a></li><li><a href=#how-do-we-measure-privacy-in-text-a-survey-of-text-anonymization-metricshttpsarxivorgabs251201109v1 aria-label="How do we measure privacy in text? A survey of text anonymization metrics"><a href=https://arxiv.org/abs/2512.01109v1>How do we measure privacy in text? A survey of text anonymization metrics</a></a></li><li><a href=#a-hybrid-deep-learning-and-anomaly-detection-framework-for-real-time-malicious-url-classificationhttpsarxivorgabs251203462v1 aria-label="A Hybrid Deep Learning and Anomaly Detection Framework for Real-Time Malicious URL Classification"><a href=https://arxiv.org/abs/2512.03462v1>A Hybrid Deep Learning and Anomaly Detection Framework for Real-Time Malicious URL Classification</a></a></li><li><a href=#elr-1000-a-community-generated-dataset-for-endangered-indic-indigenous-languageshttpsarxivorgabs251201077v1 aria-label="ELR-1000: A Community-Generated Dataset for Endangered Indic Indigenous Languages"><a href=https://arxiv.org/abs/2512.01077v1>ELR-1000: A Community-Generated Dataset for Endangered Indic Indigenous Languages</a></a></li><li><a href=#fine-tuning-of-lightweight-large-language-models-for-sentiment-classification-on-heterogeneous-financial-textual-datahttpsarxivorgabs251200946v1 aria-label="Fine-tuning of lightweight large language models for sentiment classification on heterogeneous financial textual data"><a href=https://arxiv.org/abs/2512.00946v1>Fine-tuning of lightweight large language models for sentiment classification on heterogeneous financial textual data</a></a></li><li><a href=#deformar-rethinking-ner-evaluation-through-component-analysis-and-visual-analyticshttpsarxivorgabs251200938v1 aria-label="DeformAr: Rethinking NER Evaluation through Component Analysis and Visual Analytics"><a href=https://arxiv.org/abs/2512.00938v1>DeformAr: Rethinking NER Evaluation through Component Analysis and Visual Analytics</a></a></li><li><a href=#multilingual-training-free-remote-sensing-image-captioninghttpsarxivorgabs251200887v2 aria-label="Multilingual Training-Free Remote Sensing Image Captioning"><a href=https://arxiv.org/abs/2512.00887v2>Multilingual Training-Free Remote Sensing Image Captioning</a></a></li><li><a href=#accelerating-bangla-nlp-tasks-with-automatic-mixed-precision-resource-efficient-training-preserving-model-efficacyhttpsarxivorgabs251200829v1 aria-label="Accelerating Bangla NLP Tasks with Automatic Mixed Precision: Resource-Efficient Training Preserving Model Efficacy"><a href=https://arxiv.org/abs/2512.00829v1>Accelerating Bangla NLP Tasks with Automatic Mixed Precision: Resource-Efficient Training Preserving Model Efficacy</a></a></li><li><a href=#shrag-aframeworkfor-combining-human-inspired-search-with-raghttpsarxivorgabs251200772v1 aria-label="SHRAG: AFrameworkfor Combining Human-Inspired Search with RAG"><a href=https://arxiv.org/abs/2512.00772v1>SHRAG: AFrameworkfor Combining Human-Inspired Search with RAG</a></a></li><li><a href=#mpr-gui-benchmarking-and-enhancing-multilingual-perception-and-reasoning-in-gui-agentshttpsarxivorgabs251200756v1 aria-label="MPR-GUI: Benchmarking and Enhancing Multilingual Perception and Reasoning in GUI Agents"><a href=https://arxiv.org/abs/2512.00756v1>MPR-GUI: Benchmarking and Enhancing Multilingual Perception and Reasoning in GUI Agents</a></a></li><li><a href=#fastpos-language-agnostic-scalable-pos-tagging-framework-low-resource-use-casehttpsarxivorgabs251200745v1 aria-label="FastPOS: Language-Agnostic Scalable POS Tagging Framework Low-Resource Use Case"><a href=https://arxiv.org/abs/2512.00745v1>FastPOS: Language-Agnostic Scalable POS Tagging Framework Low-Resource Use Case</a></a></li><li><a href=#financial-text-classification-based-on-rlora-finetuning-on-qwen3-8b-modelhttpsarxivorgabs251200630v1 aria-label="Financial Text Classification Based On rLoRA Finetuning On Qwen3-8B model"><a href=https://arxiv.org/abs/2512.00630v1>Financial Text Classification Based On rLoRA Finetuning On Qwen3-8B model</a></a></li><li><a href=#statistical-nlp-for-optimization-of-clinical-trial-success-prediction-in-pharmaceutical-rdhttpsarxivorgabs251200586v1 aria-label="Statistical NLP for Optimization of Clinical Trial Success Prediction in Pharmaceutical R&amp;D"><a href=https://arxiv.org/abs/2512.00586v1>Statistical NLP for Optimization of Clinical Trial Success Prediction in Pharmaceutical R&amp;D</a></a></li><li><a href=#cacara-cross-modal-alignment-leveraging-a-text-centric-approach-for-cost-effective-multimodal-and-multilingual-learninghttpsarxivorgabs251200496v1 aria-label="CACARA: Cross-Modal Alignment Leveraging a Text-Centric Approach for Cost-Effective Multimodal and Multilingual Learning"><a href=https://arxiv.org/abs/2512.00496v1>CACARA: Cross-Modal Alignment Leveraging a Text-Centric Approach for Cost-Effective Multimodal and Multilingual Learning</a></a></li><li><a href=#rrpo-robust-reward-policy-optimization-for-llm-based-emotional-ttshttpsarxivorgabs251204552v1 aria-label="RRPO: Robust Reward Policy Optimization for LLM-based Emotional TTS"><a href=https://arxiv.org/abs/2512.04552v1>RRPO: Robust Reward Policy Optimization for LLM-based Emotional TTS</a></a></li><li><a href=#different-types-of-syntactic-agreement-recruit-the-same-units-within-large-language-modelshttpsarxivorgabs251203676v1 aria-label="Different types of syntactic agreement recruit the same units within large language models"><a href=https://arxiv.org/abs/2512.03676v1>Different types of syntactic agreement recruit the same units within large language models</a></a></li><li><a href=#indicparam-benchmark-to-evaluate-llms-on-low-resource-indic-languageshttpsarxivorgabs251200333v1 aria-label="IndicParam: Benchmark to evaluate LLMs on low-resource Indic Languages"><a href=https://arxiv.org/abs/2512.00333v1>IndicParam: Benchmark to evaluate LLMs on low-resource Indic Languages</a></a></li><li><a href=#modeling-topics-and-sociolinguistic-variation-in-code-switched-discourse-insights-from-spanish-english-and-spanish-guaran%c3%adhttpsarxivorgabs251203334v1 aria-label="Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaran√≠"><a href=https://arxiv.org/abs/2512.03334v1>Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaran√≠</a></a></li><li><a href=#ivcr-200k-a-large-scale-multi-turn-dialogue-benchmark-for-interactive-video-corpus-retrievalhttpsarxivorgabs251201312v1 aria-label="IVCR-200K: A Large-Scale Multi-turn Dialogue Benchmark for Interactive Video Corpus Retrieval"><a href=https://arxiv.org/abs/2512.01312v1>IVCR-200K: A Large-Scale Multi-turn Dialogue Benchmark for Interactive Video Corpus Retrieval</a></a></li><li><a href=#whose-personae-synthetic-persona-experiments-in-llm-research-and-pathways-to-transparencyhttpsarxivorgabs251200461v1 aria-label="Whose Personae? Synthetic Persona Experiments in LLM Research and Pathways to Transparency"><a href=https://arxiv.org/abs/2512.00461v1>Whose Personae? Synthetic Persona Experiments in LLM Research and Pathways to Transparency</a></a></li><li><a href=#selfai-building-a-self-training-ai-system-with-llm-agentshttpsarxivorgabs251200403v1 aria-label="SelfAI: Building a Self-Training AI System with LLM Agents"><a href=https://arxiv.org/abs/2512.00403v1>SelfAI: Building a Self-Training AI System with LLM Agents</a></a></li><li><a href=#challenges-of-heterogeneity-in-big-data-a-comparative-study-of-classification-in-large-scale-structured-and-unstructured-domainshttpsarxivorgabs251200298v1 aria-label="Challenges of Heterogeneity in Big Data: A Comparative Study of Classification in Large-Scale Structured and Unstructured Domains"><a href=https://arxiv.org/abs/2512.00298v1>Challenges of Heterogeneity in Big Data: A Comparative Study of Classification in Large-Scale Structured and Unstructured Domains</a></a></li><li><a href=#bioarc-discovering-optimal-neural-architectures-for-biological-foundation-modelshttpsarxivorgabs251200283v2 aria-label="BioArc: Discovering Optimal Neural Architectures for Biological Foundation Models"><a href=https://arxiv.org/abs/2512.00283v2>BioArc: Discovering Optimal Neural Architectures for Biological Foundation Models</a></a></li><li><a href=#accelerated-execution-of-bayesian-neural-networks-using-a-single-probabilistic-forward-pass-and-code-generationhttpsarxivorgabs251123440v1 aria-label="Accelerated Execution of Bayesian Neural Networks using a Single Probabilistic Forward Pass and Code Generation"><a href=https://arxiv.org/abs/2511.23440v1>Accelerated Execution of Bayesian Neural Networks using a Single Probabilistic Forward Pass and Code Generation</a></a></li><li><a href=#the-decision-path-to-control-ai-risks-completely-fundamental-control-mechanisms-for-ai-governancehttpsarxivorgabs251204489v1 aria-label="The Decision Path to Control AI Risks Completely: Fundamental Control Mechanisms for AI Governance"><a href=https://arxiv.org/abs/2512.04489v1>The Decision Path to Control AI Risks Completely: Fundamental Control Mechanisms for AI Governance</a></a></li><li><a href=#minimizing-the-number-of-code-switching-operations-in-fault-tolerant-quantum-circuitshttpsarxivorgabs251204170v1 aria-label="Minimizing the Number of Code Switching Operations in Fault-Tolerant Quantum Circuits"><a href=https://arxiv.org/abs/2512.04170v1>Minimizing the Number of Code Switching Operations in Fault-Tolerant Quantum Circuits</a></a></li><li><a href=#encompass-enhancing-agent-programming-with-search-over-program-execution-pathshttpsarxivorgabs251203571v1 aria-label="EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths"><a href=https://arxiv.org/abs/2512.03571v1>EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths</a></a></li><li><a href=#language-diversity-evaluating-language-usage-and-ai-performance-on-african-languages-in-digital-spaceshttpsarxivorgabs251201557v1 aria-label="Language Diversity: Evaluating Language Usage and AI Performance on African Languages in Digital Spaces"><a href=https://arxiv.org/abs/2512.01557v1>Language Diversity: Evaluating Language Usage and AI Performance on African Languages in Digital Spaces</a></a></li><li><a href=#promptbridge-cross-model-prompt-transfer-for-large-language-modelshttpsarxivorgabs251201420v1 aria-label="PromptBridge: Cross-Model Prompt Transfer for Large Language Models"><a href=https://arxiv.org/abs/2512.01420v1>PromptBridge: Cross-Model Prompt Transfer for Large Language Models</a></a></li><li><a href=#exploiting-function-family-structure-in-analog-circuit-optimizationhttpsarxivorgabs251200712v1 aria-label="Exploiting Function-Family Structure in Analog Circuit Optimization"><a href=https://arxiv.org/abs/2512.00712v1>Exploiting Function-Family Structure in Analog Circuit Optimization</a></a></li><li><a href=#analysis-of-the-operation-of-a-tsn-switch-and-other-devices-using-executable-qr-codeshttpsarxivorgabs251200221v1 aria-label="Analysis of the operation of a TSN switch and other devices using executable QR codes"><a href=https://arxiv.org/abs/2512.00221v1>Analysis of the operation of a TSN switch and other devices using executable QR codes</a></a></li><li><a href=#mitigating-catastrophic-forgetting-in-target-language-adaptation-of-llms-via-source-shielded-updateshttpsarxivorgabs251204844v1 aria-label="Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates"><a href=https://arxiv.org/abs/2512.04844v1>Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates</a></a></li><li><a href=#divide-then-ground-adapting-frame-selection-to-query-types-for-long-form-video-understandinghttpsarxivorgabs251204000v1 aria-label="Divide, then Ground: Adapting Frame Selection to Query Types for Long-Form Video Understanding"><a href=https://arxiv.org/abs/2512.04000v1>Divide, then Ground: Adapting Frame Selection to Query Types for Long-Form Video Understanding</a></a></li><li><a href=#draco-draft-as-cot-for-text-to-image-preview-and-rare-concept-generationhttpsarxivorgabs251205112v1 aria-label="DraCo: Draft as CoT for Text-to-Image Preview and Rare Concept Generation"><a href=https://arxiv.org/abs/2512.05112v1>DraCo: Draft as CoT for Text-to-Image Preview and Rare Concept Generation</a></a></li><li><a href=#arm-thinker-reinforcing-multimodal-generative-reward-models-with-agentic-tool-use-and-visual-reasoninghttpsarxivorgabs251205111v1 aria-label="ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning"><a href=https://arxiv.org/abs/2512.05111v1>ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning</a></a></li><li><a href=#stare-vla-progressive-stage-aware-reinforcement-for-fine-tuning-vision-language-action-modelshttpsarxivorgabs251205107v1 aria-label="STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models"><a href=https://arxiv.org/abs/2512.05107v1>STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models</a></a></li><li><a href=#semantic-soft-bootstrapping-long-context-reasoning-in-llms-without-reinforcement-learninghttpsarxivorgabs251205105v1 aria-label="Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning"><a href=https://arxiv.org/abs/2512.05105v1>Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning</a></a></li><li><a href=#tv2tv-a-unified-framework-for-interleaved-language-and-video-generationhttpsarxivorgabs251205103v1 aria-label="TV2TV: A Unified Framework for Interleaved Language and Video Generation"><a href=https://arxiv.org/abs/2512.05103v1>TV2TV: A Unified Framework for Interleaved Language and Video Generation</a></a></li><li><a href=#structured-document-translation-via-format-reinforcement-learninghttpsarxivorgabs251205100v1 aria-label="Structured Document Translation via Format Reinforcement Learning"><a href=https://arxiv.org/abs/2512.05100v1>Structured Document Translation via Format Reinforcement Learning</a></a></li><li><a href=#visual-reasoning-tracer-object-level-grounded-reasoning-benchmarkhttpsarxivorgabs251205091v1 aria-label="Visual Reasoning Tracer: Object-Level Grounded Reasoning Benchmark"><a href=https://arxiv.org/abs/2512.05091v1>Visual Reasoning Tracer: Object-Level Grounded Reasoning Benchmark</a></a></li><li><a href=#david-vs-goliath-can-small-models-win-big-with-agentic-ai-in-hardware-designhttpsarxivorgabs251205073v1 aria-label="David vs. Goliath: Can Small Models Win Big with Agentic AI in Hardware Design?"><a href=https://arxiv.org/abs/2512.05073v1>David vs. Goliath: Can Small Models Win Big with Agentic AI in Hardware Design?</a></a></li><li><a href=#multi-llm-collaboration-for-medication-recommendationhttpsarxivorgabs251205066v1 aria-label="Multi-LLM Collaboration for Medication Recommendation"><a href=https://arxiv.org/abs/2512.05066v1>Multi-LLM Collaboration for Medication Recommendation</a></a></li><li><a href=#personalizing-agent-privacy-decisions-via-logical-entailmenthttpsarxivorgabs251205065v1 aria-label="Personalizing Agent Privacy Decisions via Logical Entailment"><a href=https://arxiv.org/abs/2512.05065v1>Personalizing Agent Privacy Decisions via Logical Entailment</a></a></li><li><a href=#4dlangvggt-4d-language-visual-geometry-grounded-transformerhttpsarxivorgabs251205060v1 aria-label="4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer"><a href=https://arxiv.org/abs/2512.05060v1>4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer</a></a></li><li><a href=#arbitrage-efficient-reasoning-via-advantage-aware-speculationhttpsarxivorgabs251205033v1 aria-label="Arbitrage: Efficient Reasoning via Advantage-Aware Speculation"><a href=https://arxiv.org/abs/2512.05033v1>Arbitrage: Efficient Reasoning via Advantage-Aware Speculation</a></a></li><li><a href=#factuality-and-transparency-are-all-rag-needs-self-explaining-contrastive-evidence-re-rankinghttpsarxivorgabs251205012v1 aria-label="Factuality and Transparency Are All RAG Needs! Self-Explaining Contrastive Evidence Re-ranking"><a href=https://arxiv.org/abs/2512.05012v1>Factuality and Transparency Are All RAG Needs! Self-Explaining Contrastive Evidence Re-ranking</a></a></li><li><a href=#influence-of-object-affordance-on-action-language-understanding-evidence-from-dynamic-causal-modeling-analysishttpsarxivorgabs251204989v1 aria-label="Influence of Object Affordance on Action Language Understanding: Evidence from Dynamic Causal Modeling Analysis"><a href=https://arxiv.org/abs/2512.04989v1>Influence of Object Affordance on Action Language Understanding: Evidence from Dynamic Causal Modeling Analysis</a></a></li><li><a href=#strategic-self-improvement-for-competitive-agents-in-ai-labour-marketshttpsarxivorgabs251204988v1 aria-label="Strategic Self-Improvement for Competitive Agents in AI Labour Markets"><a href=https://arxiv.org/abs/2512.04988v1>Strategic Self-Improvement for Competitive Agents in AI Labour Markets</a></a></li><li><a href=#nex-n1-agentic-models-trained-via-a-unified-ecosystem-for-large-scale-environment-constructionhttpsarxivorgabs251204987v1 aria-label="Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction"><a href=https://arxiv.org/abs/2512.04987v1>Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction</a></a></li><li><a href=#aligned-but-stereotypical-the-hidden-influence-of-system-prompts-on-social-bias-in-lvlm-based-text-to-image-modelshttpsarxivorgabs251204981v1 aria-label="Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models"><a href=https://arxiv.org/abs/2512.04981v1>Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models</a></a></li><li><a href=#hippo-exploring-a-novel-hierarchical-pronunciation-assessment-approach-for-spoken-languageshttpsarxivorgabs251204964v1 aria-label="HiPPO: Exploring A Novel Hierarchical Pronunciation Assessment Approach for Spoken Languages"><a href=https://arxiv.org/abs/2512.04964v1>HiPPO: Exploring A Novel Hierarchical Pronunciation Assessment Approach for Spoken Languages</a></a></li><li><a href=#faster-toward-efficient-autoregressive-vision-language-action-modeling-via-neural-action-tokenizationhttpsarxivorgabs251204952v1 aria-label="FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via neural Action Tokenization"><a href=https://arxiv.org/abs/2512.04952v1>FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via neural Action Tokenization</a></a></li><li><a href=#carl-critical-action-focused-reinforcement-learning-for-multi-step-agenthttpsarxivorgabs251204949v1 aria-label="CARL: Critical Action Focused Reinforcement Learning for Multi-Step Agent"><a href=https://arxiv.org/abs/2512.04949v1>CARL: Critical Action Focused Reinforcement Learning for Multi-Step Agent</a></a></li><li><a href=#growing-spines-ad-infinitum-et-ad-infinitesimaliahttpsarxivorgabs251204932v1 aria-label="Growing Spines: Ad Infinitum et Ad Infinitesimalia"><a href=https://arxiv.org/abs/2512.04932v1>Growing Spines: Ad Infinitum et Ad Infinitesimalia</a></a></li><li><a href=#algorithmic-thinking-theoryhttpsarxivorgabs251204923v1 aria-label="Algorithmic Thinking Theory"><a href=https://arxiv.org/abs/2512.04923v1>Algorithmic Thinking Theory</a></a></li><li><a href=#the-ai-consumer-index-acehttpsarxivorgabs251204921v1 aria-label="The AI Consumer Index (ACE)"><a href=https://arxiv.org/abs/2512.04921v1>The AI Consumer Index (ACE)</a></a></li><li><a href=#existentially-defining-valuations-in-function-fields-over-large-fieldshttpsarxivorgabs251204896v1 aria-label="Existentially defining valuations in function fields over large fields"><a href=https://arxiv.org/abs/2512.04896v1>Existentially defining valuations in function fields over large fields</a></a></li><li><a href=#chameleon-adaptive-adversarial-agents-for-scaling-based-visual-prompt-injection-in-multimodal-ai-systemshttpsarxivorgabs251204895v1 aria-label="Chameleon: Adaptive Adversarial Agents for Scaling-Based Visual Prompt Injection in Multimodal AI Systems"><a href=https://arxiv.org/abs/2512.04895v1>Chameleon: Adaptive Adversarial Agents for Scaling-Based Visual Prompt Injection in Multimodal AI Systems</a></a></li><li><a href=#stella-guiding-large-language-models-for-time-series-forecasting-with-semantic-abstractionshttpsarxivorgabs251204871v1 aria-label="STELLA: Guiding Large Language Models for Time Series Forecasting with Semantic Abstractions"><a href=https://arxiv.org/abs/2512.04871v1>STELLA: Guiding Large Language Models for Time Series Forecasting with Semantic Abstractions</a></a></li><li><a href=#seal-self-evolving-agentic-learning-for-conversational-question-answering-over-knowledge-graphshttpsarxivorgabs251204868v1 aria-label="SEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs"><a href=https://arxiv.org/abs/2512.04868v1>SEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs</a></a></li><li><a href=#are-your-agents-upward-deceivershttpsarxivorgabs251204864v1 aria-label="Are Your Agents Upward Deceivers?"><a href=https://arxiv.org/abs/2512.04864v1>Are Your Agents Upward Deceivers?</a></a></li><li><a href=#ask-safely-privacy-aware-llm-query-generation-for-knowledge-graphshttpsarxivorgabs251204852v1 aria-label="Ask Safely: Privacy-Aware LLM Query Generation for Knowledge Graphs"><a href=https://arxiv.org/abs/2512.04852v1>Ask Safely: Privacy-Aware LLM Query Generation for Knowledge Graphs</a></a></li><li><a href=#language-models-as-semantic-teachers-post-training-alignment-for-medical-audio-understandinghttpsarxivorgabs251204847v1 aria-label="Language Models as Semantic Teachers: Post-Training Alignment for Medical Audio Understanding"><a href=https://arxiv.org/abs/2512.04847v1>Language Models as Semantic Teachers: Post-Training Alignment for Medical Audio Understanding</a></a></li><li><a href=#sok-a-comprehensive-causality-analysis-framework-for-large-language-model-securityhttpsarxivorgabs251204841v1 aria-label="SoK: a Comprehensive Causality Analysis Framework for Large Language Model Security"><a href=https://arxiv.org/abs/2512.04841v1>SoK: a Comprehensive Causality Analysis Framework for Large Language Model Security</a></a></li><li><a href=#damasha-detecting-ai-in-mixed-adversarial-texts-via-segmentation-with-human-interpretable-attributionhttpsarxivorgabs251204838v1 aria-label="DAMASHA: Detecting AI in Mixed Adversarial Texts via Segmentation with Human-interpretable Attribution"><a href=https://arxiv.org/abs/2512.04838v1>DAMASHA: Detecting AI in Mixed Adversarial Texts via Segmentation with Human-interpretable Attribution</a></a></li><li><a href=#dala-danish-linguistic-acceptability-evaluation-guided-by-real-world-errorshttpsarxivorgabs251204799v1 aria-label="DaLA: Danish Linguistic Acceptability Evaluation Guided by Real World Errors"><a href=https://arxiv.org/abs/2512.04799v1>DaLA: Danish Linguistic Acceptability Evaluation Guided by Real World Errors</a></a></li><li><a href=#sima-2-a-generalist-embodied-agent-for-virtual-worldshttpsarxivorgabs251204797v1 aria-label="SIMA 2: A Generalist Embodied Agent for Virtual Worlds"><a href=https://arxiv.org/abs/2512.04797v1>SIMA 2: A Generalist Embodied Agent for Virtual Worlds</a></a></li><li><a href=#spatially-enhanced-retrieval-augmented-generation-for-walkability-and-urban-discoveryhttpsarxivorgabs251204790v1 aria-label="Spatially-Enhanced Retrieval-Augmented Generation for Walkability and Urban Discovery"><a href=https://arxiv.org/abs/2512.04790v1>Spatially-Enhanced Retrieval-Augmented Generation for Walkability and Urban Discovery</a></a></li><li><a href=#astride-a-security-threat-modeling-platform-for-agentic-ai-applicationshttpsarxivorgabs251204785v1 aria-label="ASTRIDE: A Security Threat Modeling Platform for Agentic-AI Applications"><a href=https://arxiv.org/abs/2512.04785v1>ASTRIDE: A Security Threat Modeling Platform for Agentic-AI Applications</a></a></li><li><a href=#memlora-distilling-expert-adapters-for-on-device-memory-systemshttpsarxivorgabs251204763v1 aria-label="MemLoRA: Distilling Expert Adapters for On-Device Memory Systems"><a href=https://arxiv.org/abs/2512.04763v1>MemLoRA: Distilling Expert Adapters for On-Device Memory Systems</a></a></li><li><a href=#challenging-the-abilities-of-large-language-models-in-italian-a-community-initiativehttpsarxivorgabs251204759v1 aria-label="Challenging the Abilities of Large Language Models in Italian: a Community Initiative"><a href=https://arxiv.org/abs/2512.04759v1>Challenging the Abilities of Large Language Models in Italian: a Community Initiative</a></a></li><li><a href=#typing-fallback-functions-a-semantic-approach-to-type-safe-smart-contractshttpsarxivorgabs251204755v1 aria-label="Typing Fallback Functions: A Semantic Approach to Type Safe Smart Contracts"><a href=https://arxiv.org/abs/2512.04755v1>Typing Fallback Functions: A Semantic Approach to Type Safe Smart Contracts</a></a></li><li><a href=#etcon-edit-then-consolidate-for-reliable-knowledge-editinghttpsarxivorgabs251204753v1 aria-label="EtCon: Edit-then-Consolidate for Reliable Knowledge Editing"><a href=https://arxiv.org/abs/2512.04753v1>EtCon: Edit-then-Consolidate for Reliable Knowledge Editing</a></a></li><li><a href=#rlhfspec-breaking-the-efficiency-bottleneck-in-rlhf-training-via-adaptive-draftinghttpsarxivorgabs251204752v1 aria-label="RLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting"><a href=https://arxiv.org/abs/2512.04752v1>RLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting</a></a></li><li><a href=#model-whisper-steering-vectors-unlock-large-language-models-potential-in-test-timehttpsarxivorgabs251204748v1 aria-label="Model Whisper: Steering Vectors Unlock Large Language Models&rsquo; Potential in Test-time"><a href=https://arxiv.org/abs/2512.04748v1>Model Whisper: Steering Vectors Unlock Large Language Models&rsquo; Potential in Test-time</a></a></li><li><a href=#signroundv2-closing-the-performance-gap-in-extremely-low-bit-post-training-quantization-for-llmshttpsarxivorgabs251204746v1 aria-label="SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs"><a href=https://arxiv.org/abs/2512.04746v1>SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs</a></a></li><li><a href=#osmt-bridging-openstreetmap-queries-and-natural-language-with-open-source-tag-aware-language-modelshttpsarxivorgabs251204738v1 aria-label="OsmT: Bridging OpenStreetMap Queries and Natural Language with Open-source Tag-aware Language Models"><a href=https://arxiv.org/abs/2512.04738v1>OsmT: Bridging OpenStreetMap Queries and Natural Language with Open-source Tag-aware Language Models</a></a></li><li><a href=#e3ad-an-emotion-aware-vision-language-action-model-for-human-centric-end-to-end-autonomous-drivinghttpsarxivorgabs251204733v1 aria-label="E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving"><a href=https://arxiv.org/abs/2512.04733v1>E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving</a></a></li><li><a href=#the-universal-weight-subspace-hypothesishttpsarxivorgabs251205117v1 aria-label="The Universal Weight Subspace Hypothesis"><a href=https://arxiv.org/abs/2512.05117v1>The Universal Weight Subspace Hypothesis</a></a></li><li><a href=#sdg-track-a-heterogeneous-observer-follower-framework-for-high-resolution-uav-tracking-on-embedded-platformshttpsarxivorgabs251204883v1 aria-label="SDG-Track: A Heterogeneous Observer-Follower Framework for High-Resolution UAV Tracking on Embedded Platforms"><a href=https://arxiv.org/abs/2512.04883v1>SDG-Track: A Heterogeneous Observer-Follower Framework for High-Resolution UAV Tracking on Embedded Platforms</a></a></li><li><a href=#a-novel-trust-based-ddos-cyberattack-detection-model-for-smart-business-environmentshttpsarxivorgabs251204855v1 aria-label="A Novel Trust-Based DDoS Cyberattack Detection Model for Smart Business Environments"><a href=https://arxiv.org/abs/2512.04855v1>A Novel Trust-Based DDoS Cyberattack Detection Model for Smart Business Environments</a></a></li><li><a href=#breaking-the-bandwidth-efficiency-trade-off-in-soliton-microcombs-via-mode-couplinghttpsarxivorgabs251205090v1 aria-label="Breaking the bandwidth-efficiency trade-off in soliton microcombs via mode coupling"><a href=https://arxiv.org/abs/2512.05090v1>Breaking the bandwidth-efficiency trade-off in soliton microcombs via mode coupling</a></a></li><li><a href=#anisotropic-response-in-metamaterials-with-elliptically-perforated-plates-applications-to-near-field-radiative-heat-transferhttpsarxivorgabs251205075v1 aria-label="Anisotropic Response in Metamaterials with Elliptically Perforated Plates: Applications to Near-Field Radiative Heat Transfer"><a href=https://arxiv.org/abs/2512.05075v1>Anisotropic Response in Metamaterials with Elliptically Perforated Plates: Applications to Near-Field Radiative Heat Transfer</a></a></li><li><a href=#meta-learning-for-quantum-optimization-via-quantum-sequence-modelhttpsarxivorgabs251205058v1 aria-label="Meta-Learning for Quantum Optimization via Quantum Sequence Model"><a href=https://arxiv.org/abs/2512.05058v1>Meta-Learning for Quantum Optimization via Quantum Sequence Model</a></a></li><li><a href=#some-computations-in-the-heart-of-the-homotopy-t-structure-on-logarithmic-motiveshttpsarxivorgabs251205051v1 aria-label="Some computations in the heart of the homotopy t-structure on logarithmic motives"><a href=https://arxiv.org/abs/2512.05051v1>Some computations in the heart of the homotopy t-structure on logarithmic motives</a></a></li><li><a href=#ramen-resolution-adjustable-multimodal-encoder-for-earth-observationhttpsarxivorgabs251205025v1 aria-label="RAMEN: Resolution-Adjustable Multimodal Encoder for Earth Observation"><a href=https://arxiv.org/abs/2512.05025v1>RAMEN: Resolution-Adjustable Multimodal Encoder for Earth Observation</a></a></li><li><a href=#schwarzschild-black-hole-turbulence-scalar-probehttpsarxivorgabs251205003v1 aria-label="Schwarzschild Black Hole Turbulence: Scalar Probe"><a href=https://arxiv.org/abs/2512.05003v1>Schwarzschild Black Hole Turbulence: Scalar Probe</a></a></li><li><a href=#suppressing-metal-molecule-charge-transfer-with-a-phosphorus-interlayerhttpsarxivorgabs251204999v1 aria-label="Suppressing metal molecule charge transfer with a phosphorus interlayer"><a href=https://arxiv.org/abs/2512.04999v1>Suppressing metal molecule charge transfer with a phosphorus interlayer</a></a></li><li><a href=#introducing-v-soft-pro-a-modular-platform-for-a-transhumeral-prosthesis-with-controllable-stiffnesshttpsarxivorgabs251204998v1 aria-label="Introducing V-Soft Pro: a Modular Platform for a Transhumeral Prosthesis with Controllable Stiffness"><a href=https://arxiv.org/abs/2512.04998v1>Introducing V-Soft Pro: a Modular Platform for a Transhumeral Prosthesis with Controllable Stiffness</a></a></li><li><a href=#operator-formalism-for-laser-plasma-wakefield-accelerationhttpsarxivorgabs251204982v1 aria-label="Operator Formalism for Laser-Plasma Wakefield Acceleration"><a href=https://arxiv.org/abs/2512.04982v1>Operator Formalism for Laser-Plasma Wakefield Acceleration</a></a></li><li><a href=#hybrid-diffusion-models-combining-open-loop-routines-with-visuomotor-diffusion-policieshttpsarxivorgabs251204960v1 aria-label="Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies"><a href=https://arxiv.org/abs/2512.04960v1>Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies</a></a></li><li><a href=#crack-detection-by-holomorphic-neural-networks-and-transfer-learning-enhanced-genetic-optimizationhttpsarxivorgabs251204947v1 aria-label="Crack detection by holomorphic neural networks and transfer-learning-enhanced genetic optimization"><a href=https://arxiv.org/abs/2512.04947v1>Crack detection by holomorphic neural networks and transfer-learning-enhanced genetic optimization</a></a></li><li><a href=#tuning-the-electronic-states-of-bi2se3-films-with-large-spin-orbit-interaction-using-molecular-heterojunctionshttpsarxivorgabs251204922v1 aria-label="Tuning the Electronic States of Bi2Se3 Films with Large Spin-Orbit Interaction Using Molecular Heterojunctions"><a href=https://arxiv.org/abs/2512.04922v1>Tuning the Electronic States of Bi2Se3 Films with Large Spin-Orbit Interaction Using Molecular Heterojunctions</a></a></li><li><a href=#hoi----a-multimodal-dataset-for-force-grounded-cross-view-articulated-manipulationhttpsarxivorgabs251204884v1 aria-label="Hoi! &ndash; A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation"><a href=https://arxiv.org/abs/2512.04884v1>Hoi! &ndash; A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation</a></a></li><li><a href=#interfacial-synergy-in-ag-doped-cuo-agcl-g-c3n4-composites-for-efficient-charge-separation-and-low-power-methylene-blue-degradationhttpsarxivorgabs251204825v1 aria-label="Interfacial Synergy in Ag-Doped CuO-AgCl-g-C3N4 Composites for Efficient Charge Separation and Low-power Methylene Blue Degradation"><a href=https://arxiv.org/abs/2512.04825v1>Interfacial Synergy in Ag-Doped CuO-AgCl-g-C3N4 Composites for Efficient Charge Separation and Low-power Methylene Blue Degradation</a></a></li><li><a href=#formation-of-the-dormant-black-holes-with-luminous-companions-from-binary-or-triple-systemshttpsarxivorgabs251204774v1 aria-label="Formation of the Dormant Black Holes with Luminous Companions from Binary or Triple Systems"><a href=https://arxiv.org/abs/2512.04774v1>Formation of the Dormant Black Holes with Luminous Companions from Binary or Triple Systems</a></a></li><li><a href=#maehara-interpolation-in-extensions-of-r-minglehttpsarxivorgabs251204762v1 aria-label="Maehara Interpolation in Extensions of R-mingle"><a href=https://arxiv.org/abs/2512.04762v1>Maehara Interpolation in Extensions of R-mingle</a></a></li><li><a href=#evolution-of-correlated-electrons-in-rm-la_3ni_2o_7-at-ambient-pressure-a-study-of-double-counting-effecthttpsarxivorgabs251204754v1 aria-label="Evolution of Correlated Electrons in ${\rm La_3Ni_2O_7}$ at Ambient Pressure: a Study of Double-Counting Effect"><a href=https://arxiv.org/abs/2512.04754v1>Evolution of Correlated Electrons in ${\rm La_3Ni_2O_7}$ at Ambient Pressure: a Study of Double-Counting Effect</a></a></li><li><a href=#alma-quarks-few-thousand-year-hatching-out-of-egg-the-supersonic-breakout-of-a-hypercompact-h-ii-region-from-its-parental-hot-corehttpsarxivorgabs251204744v1 aria-label="ALMA-QUARKS: Few-Thousand-Year Hatching out of &ldquo;Egg&rdquo;: The Supersonic Breakout of a Hypercompact H II Region from Its Parental Hot Core"><a href=https://arxiv.org/abs/2512.04744v1>ALMA-QUARKS: Few-Thousand-Year Hatching out of &ldquo;Egg&rdquo;: The Supersonic Breakout of a Hypercompact H II Region from Its Parental Hot Core</a></a></li><li><a href=#bridging-simulation-and-reality-cross-domain-transfer-with-semantic-2d-gaussian-splattinghttpsarxivorgabs251204731v1 aria-label="Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting"><a href=https://arxiv.org/abs/2512.04731v1>Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting</a></a></li><li><a href=#boosting-the-memory-window-of-memristive-stacks-via-engineered-interfaces-with-high-ionic-mobilityhttpsarxivorgabs251204706v1 aria-label="Boosting the Memory Window of Memristive Stacks via Engineered Interfaces with High Ionic Mobility"><a href=https://arxiv.org/abs/2512.04706v1>Boosting the Memory Window of Memristive Stacks via Engineered Interfaces with High Ionic Mobility</a></a></li><li><a href=#colorings-of-unrooted-tree-based-networks-and-related-graphshttpsarxivorgabs251204693v1 aria-label="Colorings of unrooted tree-based networks and related graphs"><a href=https://arxiv.org/abs/2512.04693v1>Colorings of unrooted tree-based networks and related graphs</a></a></li><li><a href=#fast-and-efficient-formation-of-stable-tetraatomic-molecules-from-ultracold-atoms-via-generalized-stimulated-raman-exact-passagehttpsarxivorgabs251204681v1 aria-label="Fast and efficient formation of stable tetraatomic molecules from ultracold atoms via generalized stimulated Raman exact passage"><a href=https://arxiv.org/abs/2512.04681v1>Fast and efficient formation of stable tetraatomic molecules from ultracold atoms via generalized stimulated Raman exact passage</a></a></li><li><a href=#a-unified-low-rank-adi-framework-with-shared-linear-solves-for-simultaneously-solving-multiple-lyapunov-sylvester-and-riccati-equationshttpsarxivorgabs251204676v1 aria-label="A Unified Low-rank ADI Framework with Shared Linear Solves for Simultaneously Solving Multiple Lyapunov, Sylvester, and Riccati Equations"><a href=https://arxiv.org/abs/2512.04676v1>A Unified Low-rank ADI Framework with Shared Linear Solves for Simultaneously Solving Multiple Lyapunov, Sylvester, and Riccati Equations</a></a></li><li><a href=#semi-centralized-training-decentralized-execution-architecture-for-multi-agent-deep-reinforcement-learning-in-traffic-signal-controlhttpsarxivorgabs251204653v1 aria-label="Semi Centralized Training Decentralized Execution Architecture for Multi Agent Deep Reinforcement Learning in Traffic Signal Control"><a href=https://arxiv.org/abs/2512.04653v1>Semi Centralized Training Decentralized Execution Architecture for Multi Agent Deep Reinforcement Learning in Traffic Signal Control</a></a></li><li><a href=#strategies-for-zero-boil-off-liquid-hydrogen-transfer-an-export-terminal-case-studyhttpsarxivorgabs251204609v1 aria-label="Strategies for zero boil-off liquid hydrogen transfer: an export terminal case-study"><a href=https://arxiv.org/abs/2512.04609v1>Strategies for zero boil-off liquid hydrogen transfer: an export terminal case-study</a></a></li><li><a href=#infrared-uav-target-tracking-with-dynamic-feature-refinement-and-global-contextual-attention-knowledge-distillationhttpsarxivorgabs251204581v1 aria-label="Infrared UAV Target Tracking with Dynamic Feature Refinement and Global Contextual Attention Knowledge Distillation"><a href=https://arxiv.org/abs/2512.04581v1>Infrared UAV Target Tracking with Dynamic Feature Refinement and Global Contextual Attention Knowledge Distillation</a></a></li><li><a href=#refa%c3%a7ade-editing-object-with-given-reference-texturehttpsarxivorgabs251204534v1 aria-label="Refa√ßade: Editing Object with Given Reference Texture"><a href=https://arxiv.org/abs/2512.04534v1>Refa√ßade: Editing Object with Given Reference Texture</a></a></li><li><a href=#prototype-based-semantic-consistency-alignment-for-domain-adaptive-retrievalhttpsarxivorgabs251204524v1 aria-label="Prototype-Based Semantic Consistency Alignment for Domain Adaptive Retrieval"><a href=https://arxiv.org/abs/2512.04524v1>Prototype-Based Semantic Consistency Alignment for Domain Adaptive Retrieval</a></a></li><li><a href=#universal-quantum-control-over-non-hermitian-continuous-variable-systemshttpsarxivorgabs251204495v1 aria-label="Universal quantum control over non-Hermitian continuous-variable systems"><a href=https://arxiv.org/abs/2512.04495v1>Universal quantum control over non-Hermitian continuous-variable systems</a></a></li><li><a href=#nucleon-to-roper-transition-amplitudes-and-electromagnetic-form-factorshttpsarxivorgabs251204493v1 aria-label="Nucleon to Roper transition amplitudes and electromagnetic form factors"><a href=https://arxiv.org/abs/2512.04493v1>Nucleon to Roper transition amplitudes and electromagnetic form factors</a></a></li><li><a href=#controllable-long-term-motion-generation-with-extended-joint-targetshttpsarxivorgabs251204487v1 aria-label="Controllable Long-term Motion Generation with Extended Joint Targets"><a href=https://arxiv.org/abs/2512.04487v1>Controllable Long-term Motion Generation with Extended Joint Targets</a></a></li><li><a href=#context-aware-mixture-of-experts-inference-on-cxl-enabled-gpu-ndp-systemshttpsarxivorgabs251204476v1 aria-label="Context-Aware Mixture-of-Experts Inference on CXL-Enabled GPU-NDP Systems"><a href=https://arxiv.org/abs/2512.04476v1>Context-Aware Mixture-of-Experts Inference on CXL-Enabled GPU-NDP Systems</a></a></li><li><a href=#offloading-to-cxl-based-computational-memoryhttpsarxivorgabs251204449v1 aria-label="Offloading to CXL-based Computational Memory"><a href=https://arxiv.org/abs/2512.04449v1>Offloading to CXL-based Computational Memory</a></a></li><li><a href=#multi-source-learning-for-target-population-by-high-dimensional-calibrationhttpsarxivorgabs251204412v1 aria-label="Multi-source Learning for Target Population by High-dimensional Calibration"><a href=https://arxiv.org/abs/2512.04412v1>Multi-source Learning for Target Population by High-dimensional Calibration</a></a></li><li><a href=#performance-evaluation-of-transfer-learning-based-medical-image-classification-techniques-for-disease-detectionhttpsarxivorgabs251204397v1 aria-label="Performance Evaluation of Transfer Learning Based Medical Image Classification Techniques for Disease Detection"><a href=https://arxiv.org/abs/2512.04397v1>Performance Evaluation of Transfer Learning Based Medical Image Classification Techniques for Disease Detection</a></a></li><li><a href=#mini-supernovae-from-white-dwarf-neutron-star-mergers-viewing-angle-dependent-spectra-and-lightcurveshttpsarxivorgabs251204378v1 aria-label="Mini-supernovae from white dwarf-neutron star mergers: Viewing-angle-dependent spectra and lightcurves"><a href=https://arxiv.org/abs/2512.04378v1>Mini-supernovae from white dwarf-neutron star mergers: Viewing-angle-dependent spectra and lightcurves</a></a></li><li><a href=#retrieving-missing-data-in-electron-diffraction-of-gas-phase-moleculeshttpsarxivorgabs251204352v1 aria-label="Retrieving missing data in electron diffraction of gas-phase molecules"><a href=https://arxiv.org/abs/2512.04352v1>Retrieving missing data in electron diffraction of gas-phase molecules</a></a></li><li><a href=#asymptotic-constraints-for-1d-planar-grey-photon-diffusion-from-linear-transport-with-special-relativistic-effectshttpsarxivorgabs251204342v1 aria-label="Asymptotic constraints for 1D planar grey photon diffusion from linear transport with special-relativistic effects"><a href=https://arxiv.org/abs/2512.04342v1>Asymptotic constraints for 1D planar grey photon diffusion from linear transport with special-relativistic effects</a></a></li><li><a href=#interactions-between-internal-solitary-waves-and-floating-canopieshttpsarxivorgabs251204321v1 aria-label="Interactions Between Internal Solitary Waves and Floating Canopies"><a href=https://arxiv.org/abs/2512.04321v1>Interactions Between Internal Solitary Waves and Floating Canopies</a></a></li><li><a href=#probing-evaporating-black-holes-with-modular-flow-in-sykhttpsarxivorgabs251204318v1 aria-label="Probing Evaporating Black Holes with Modular Flow in SYK"><a href=https://arxiv.org/abs/2512.04318v1>Probing Evaporating Black Holes with Modular Flow in SYK</a></a></li><li><a href=#universal-quantum-interconnects-via-phase-coherent-four-wave-mixinghttpsarxivorgabs251204312v1 aria-label="Universal Quantum Interconnects via Phase-Coherent Four-Wave Mixing"><a href=https://arxiv.org/abs/2512.04312v1>Universal Quantum Interconnects via Phase-Coherent Four-Wave Mixing</a></a></li><li><a href=#inference-time-stochastic-refinement-of-gru-normalizing-flow-for-real-time-video-motion-transferhttpsarxivorgabs251204282v1 aria-label="Inference-time Stochastic Refinement of GRU-Normalizing Flow for Real-time Video Motion Transfer"><a href=https://arxiv.org/abs/2512.04282v1>Inference-time Stochastic Refinement of GRU-Normalizing Flow for Real-time Video Motion Transfer</a></a></li><li><a href=#unilight-a-unified-representation-for-lightinghttpsarxivorgabs251204267v1 aria-label="UniLight: A Unified Representation for Lighting"><a href=https://arxiv.org/abs/2512.04267v1>UniLight: A Unified Representation for Lighting</a></a></li><li><a href=#primordial-black-holes-from-inflation-with-a-spectator-fieldhttpsarxivorgabs251204199v1 aria-label="Primordial Black Holes from Inflation with a Spectator Field"><a href=https://arxiv.org/abs/2512.04199v1>Primordial Black Holes from Inflation with a Spectator Field</a></a></li><li><a href=#resolving-the-terrestrial-planet-forming-region-of-hd-172555-with-alma-i-post-impact-dust-distributionhttpsarxivorgabs251204154v1 aria-label="Resolving the terrestrial planet-forming region of HD 172555 with ALMA: I. Post-impact dust distribution"><a href=https://arxiv.org/abs/2512.04154v1>Resolving the terrestrial planet-forming region of HD 172555 with ALMA: I. Post-impact dust distribution</a></a></li><li><a href=#enhancing-next-token-prediction-based-pre-training-for-jet-foundation-modelshttpsarxivorgabs251204149v1 aria-label="Enhancing next token prediction based pre-training for jet foundation models"><a href=https://arxiv.org/abs/2512.04149v1>Enhancing next token prediction based pre-training for jet foundation models</a></a></li><li><a href=#unique-lives-shared-world-learning-from-single-life-videoshttpsarxivorgabs251204085v1 aria-label="Unique Lives, Shared World: Learning from Single-Life Videos"><a href=https://arxiv.org/abs/2512.04085v1>Unique Lives, Shared World: Learning from Single-Life Videos</a></a></li><li><a href=#domain-feature-collapse-implications-for-out-of-distribution-detection-and-solutionshttpsarxivorgabs251204034v1 aria-label="Domain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions"><a href=https://arxiv.org/abs/2512.04034v1>Domain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions</a></a></li><li><a href=#value-gradient-guidance-for-flow-matching-alignmenthttpsarxivorgabs251205116v1 aria-label="Value Gradient Guidance for Flow Matching Alignment"><a href=https://arxiv.org/abs/2512.05116v1>Value Gradient Guidance for Flow Matching Alignment</a></a></li><li><a href=#neuralremaster-phase-preserving-diffusion-for-structure-aligned-generationhttpsarxivorgabs251205106v1 aria-label="NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation"><a href=https://arxiv.org/abs/2512.05106v1>NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation</a></a></li><li><a href=#deep-forcing-training-free-long-video-generation-with-deep-sink-and-participative-compressionhttpsarxivorgabs251205081v1 aria-label="Deep Forcing: Training-Free Long Video Generation with Deep Sink and Participative Compression"><a href=https://arxiv.org/abs/2512.05081v1>Deep Forcing: Training-Free Long Video Generation with Deep Sink and Participative Compression</a></a></li><li><a href=#debt-growth-and-the-carbon-lock-inhttpsarxivorgabs251205063v1 aria-label="Debt, Growth, and the Carbon Lock-In"><a href=https://arxiv.org/abs/2512.05063v1>Debt, Growth, and the Carbon Lock-In</a></a></li><li><a href=#millimetre-wave-comb-generated-by-an-optical-microcombhttpsarxivorgabs251205005v1 aria-label="Millimetre-Wave Comb Generated by an Optical Microcomb"><a href=https://arxiv.org/abs/2512.05005v1>Millimetre-Wave Comb Generated by an Optical Microcomb</a></a></li><li><a href=#evolutionary-architecture-search-through-grammar-based-sequence-alignmenthttpsarxivorgabs251204992v1 aria-label="Evolutionary Architecture Search through Grammar-Based Sequence Alignment"><a href=https://arxiv.org/abs/2512.04992v1>Evolutionary Architecture Search through Grammar-Based Sequence Alignment</a></a></li><li><a href=#learning-causality-for-longitudinal-datahttpsarxivorgabs251204980v1 aria-label="Learning Causality for Longitudinal Data"><a href=https://arxiv.org/abs/2512.04980v1>Learning Causality for Longitudinal Data</a></a></li><li><a href=#exploring-youtubes-political-communication-networks-during-the-2024-french-electionshttpsarxivorgabs251204971v1 aria-label="Exploring YouTube&rsquo;s Political Communication Networks during the 2024 French Elections"><a href=https://arxiv.org/abs/2512.04971v1>Exploring YouTube&rsquo;s Political Communication Networks during the 2024 French Elections</a></a></li><li><a href=#environment-aware-channel-inference-via-cross-modal-flow-from-multimodal-sensing-to-wireless-channelshttpsarxivorgabs251204966v1 aria-label="Environment-Aware Channel Inference via Cross-Modal Flow: From Multimodal Sensing to Wireless Channels"><a href=https://arxiv.org/abs/2512.04966v1>Environment-Aware Channel Inference via Cross-Modal Flow: From Multimodal Sensing to Wireless Channels</a></a></li><li><a href=#probing-tev-afterglow-emission-of-grb221009a-with-gaussian-structured-jet-in-wind-driven-mediumhttpsarxivorgabs251204893v1 aria-label="Probing TeV Afterglow Emission of GRB~221009A with Gaussian Structured jet in Wind-driven medium"><a href=https://arxiv.org/abs/2512.04893v1>Probing TeV Afterglow Emission of GRB~221009A with Gaussian Structured jet in Wind-driven medium</a></a></li><li><a href=#performance-optimization-and-characterization-of-7-pad-resistive-picosec-micromegas-detectorshttpsarxivorgabs251204842v1 aria-label="Performance Optimization and Characterization of 7-pad Resistive PICOSEC Micromegas Detectors"><a href=https://arxiv.org/abs/2512.04842v1>Performance Optimization and Characterization of 7-pad Resistive PICOSEC Micromegas Detectors</a></a></li><li><a href=#contract-driven-qoe-auditing-for-speech-and-singing-services-from-mos-regression-to-service-graphshttpsarxivorgabs251204827v1 aria-label="Contract-Driven QoE Auditing for Speech and Singing Services: From MOS Regression to Service Graphs"><a href=https://arxiv.org/abs/2512.04827v1>Contract-Driven QoE Auditing for Speech and Singing Services: From MOS Regression to Service Graphs</a></a></li><li><a href=#hierarchical-matrix-approximability-of-inverse-of-convection-dominated-finite-element-matriceshttpsarxivorgabs251204824v1 aria-label="Hierarchical matrix approximability of inverse of convection dominated finite element matrices"><a href=https://arxiv.org/abs/2512.04824v1>Hierarchical matrix approximability of inverse of convection dominated finite element matrices</a></a></li><li><a href=#yingmusic-singer-zero-shot-singing-voice-synthesis-and-editing-with-annotation-free-melody-guidancehttpsarxivorgabs251204779v1 aria-label="YingMusic-Singer: Zero-shot Singing Voice Synthesis and Editing with Annotation-free Melody Guidance"><a href=https://arxiv.org/abs/2512.04779v1>YingMusic-Singer: Zero-shot Singing Voice Synthesis and Editing with Annotation-free Melody Guidance</a></a></li><li><a href=#cig-mae-cross-modal-information-guided-masked-autoencoder-for-self-supervised-wifi-sensinghttpsarxivorgabs251204723v1 aria-label="CIG-MAE: Cross-Modal Information-Guided Masked Autoencoder for Self-Supervised WiFi Sensing"><a href=https://arxiv.org/abs/2512.04723v1>CIG-MAE: Cross-Modal Information-Guided Masked Autoencoder for Self-Supervised WiFi Sensing</a></a></li><li><a href=#m3-tts-multi-modal-dit-alignment--mel-latent-for-zero-shot-high-fidelity-speech-synthesishttpsarxivorgabs251204720v1 aria-label="M3-TTS: Multi-modal DiT Alignment & Mel-latent for Zero-shot High-fidelity Speech Synthesis"><a href=https://arxiv.org/abs/2512.04720v1>M3-TTS: Multi-modal DiT Alignment & Mel-latent for Zero-shot High-fidelity Speech Synthesis</a></a></li><li><a href=#timesnet-gen-deep-learning-based-site-specific-strong-motion-generationhttpsarxivorgabs251204694v1 aria-label="TimesNet-Gen: Deep Learning-based Site Specific Strong Motion Generation"><a href=https://arxiv.org/abs/2512.04694v1>TimesNet-Gen: Deep Learning-based Site Specific Strong Motion Generation</a></a></li><li><a href=#towards-ethical-multi-agent-systems-of-large-language-models-a-mechanistic-interpretability-perspectivehttpsarxivorgabs251204691v1 aria-label="Towards Ethical Multi-Agent Systems of Large Language Models: A Mechanistic Interpretability Perspective"><a href=https://arxiv.org/abs/2512.04691v1>Towards Ethical Multi-Agent Systems of Large Language Models: A Mechanistic Interpretability Perspective</a></a></li><li><a href=#a-chandra-view-of-spt-cl-j0217-5014-a-massive-galaxy-cluster-at-a-cosmic-intersection-at-z053httpsarxivorgabs251204689v1 aria-label="A Chandra view of SPT-CL J0217-5014: a massive galaxy cluster at a cosmic intersection at z=0.53"><a href=https://arxiv.org/abs/2512.04689v1>A Chandra view of SPT-CL J0217-5014: a massive galaxy cluster at a cosmic intersection at z=0.53</a></a></li><li><a href=#geschlechts%c3%bcbergreifende-maskulina-im-sprachgebrauch-eine-korpusbasierte-untersuchung-zu-lexemspezifischen-unterschiedenhttpsarxivorgabs251204683v1 aria-label="Geschlechts√ºbergreifende Maskulina im Sprachgebrauch Eine korpusbasierte Untersuchung zu lexemspezifischen Unterschieden"><a href=https://arxiv.org/abs/2512.04683v1>Geschlechts√ºbergreifende Maskulina im Sprachgebrauch Eine korpusbasierte Untersuchung zu lexemspezifischen Unterschieden</a></a></li><li><a href=#generative-ai-for-self-adaptive-systems-state-of-the-art-and-research-roadmaphttpsarxivorgabs251204680v1 aria-label="Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap"><a href=https://arxiv.org/abs/2512.04680v1>Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap</a></a></li><li><a href=#i2i-bench-a-comprehensive-benchmark-suite-for-image-to-image-editing-modelshttpsarxivorgabs251204660v1 aria-label="I2I-Bench: A Comprehensive Benchmark Suite for Image-to-Image Editing Models"><a href=https://arxiv.org/abs/2512.04660v1>I2I-Bench: A Comprehensive Benchmark Suite for Image-to-Image Editing Models</a></a></li><li><a href=#reflection-satisfaction-tradeoff-investigating-impact-of-reflection-on-student-engagement-with-ai-generated-programming-hintshttpsarxivorgabs251204630v1 aria-label="Reflection-Satisfaction Tradeoff: Investigating Impact of Reflection on Student Engagement with AI-Generated Programming Hints"><a href=https://arxiv.org/abs/2512.04630v1>Reflection-Satisfaction Tradeoff: Investigating Impact of Reflection on Student Engagement with AI-Generated Programming Hints</a></a></li><li><a href=#usersimcrs-v2-simulation-based-evaluation-for-conversational-recommender-systemshttpsarxivorgabs251204588v1 aria-label="UserSimCRS v2: Simulation-Based Evaluation for Conversational Recommender Systems"><a href=https://arxiv.org/abs/2512.04588v1>UserSimCRS v2: Simulation-Based Evaluation for Conversational Recommender Systems</a></a></li><li><a href=#sam3-i-segment-anything-with-instructionshttpsarxivorgabs251204585v1 aria-label="SAM3-I: Segment Anything with Instructions"><a href=https://arxiv.org/abs/2512.04585v1>SAM3-I: Segment Anything with Instructions</a></a></li><li><a href=#investigating-the-h-i-mass-size-relation-using-the-simba-cosmological-simulationshttpsarxivorgabs251204582v1 aria-label="Investigating the H i mass-size relation using the Simba cosmological simulations"><a href=https://arxiv.org/abs/2512.04582v1>Investigating the H i mass-size relation using the Simba cosmological simulations</a></a></li><li><a href=#diffusion-fine-tuning-via-reparameterized-policy-gradient-of-the-soft-q-functionhttpsarxivorgabs251204559v1 aria-label="Diffusion Fine-Tuning via Reparameterized Policy Gradient of the Soft Q-Function"><a href=https://arxiv.org/abs/2512.04559v1>Diffusion Fine-Tuning via Reparameterized Policy Gradient of the Soft Q-Function</a></a></li><li><a href=#adapt-learning-task-mixtures-for-budget-constrained-instruction-tuninghttpsarxivorgabs251204555v1 aria-label="ADAPT: Learning Task Mixtures for Budget-Constrained Instruction Tuning"><a href=https://arxiv.org/abs/2512.04555v1>ADAPT: Learning Task Mixtures for Budget-Constrained Instruction Tuning</a></a></li><li><a href=#gaussian-entropy-fields-driving-adaptive-sparsity-in-3d-gaussian-optimizationhttpsarxivorgabs251204542v1 aria-label="Gaussian Entropy Fields: Driving Adaptive Sparsity in 3D Gaussian Optimization"><a href=https://arxiv.org/abs/2512.04542v1>Gaussian Entropy Fields: Driving Adaptive Sparsity in 3D Gaussian Optimization</a></a></li><li><a href=#completion-by-comprehension-guiding-code-generation-with-multi-granularity-understandinghttpsarxivorgabs251204538v1 aria-label="Completion by Comprehension: Guiding Code Generation with Multi-Granularity Understanding"><a href=https://arxiv.org/abs/2512.04538v1>Completion by Comprehension: Guiding Code Generation with Multi-Granularity Understanding</a></a></li><li><a href=#flex-leveraging-fpga-cpu-synergy-for-mixed-cell-height-legalization-accelerationhttpsarxivorgabs251204527v1 aria-label="FLEX: Leveraging FPGA-CPU Synergy for Mixed-Cell-Height Legalization Acceleration"><a href=https://arxiv.org/abs/2512.04527v1>FLEX: Leveraging FPGA-CPU Synergy for Mixed-Cell-Height Legalization Acceleration</a></a></li><li><a href=#pump-free-microwave-optical-quantum-transductionhttpsarxivorgabs251205096v1 aria-label="Pump Free Microwave-Optical Quantum Transduction"><a href=https://arxiv.org/abs/2512.05096v1>Pump Free Microwave-Optical Quantum Transduction</a></a></li><li><a href=#tokenizing-buildings-a-transformer-for-layout-synthesishttpsarxivorgabs251204832v1 aria-label="Tokenizing Buildings: A Transformer for Layout Synthesis"><a href=https://arxiv.org/abs/2512.04832v1>Tokenizing Buildings: A Transformer for Layout Synthesis</a></a></li><li><a href=#the-initial-to-final-state-inverse-problem-with-unbounded-potentials-and-strichartz-estimateshttpsarxivorgabs251204796v1 aria-label="The initial-to-final-state inverse problem with unbounded potentials and Strichartz estimates"><a href=https://arxiv.org/abs/2512.04796v1>The initial-to-final-state inverse problem with unbounded potentials and Strichartz estimates</a></a></li><li><a href=#terahertz-fourier-ptychographic-imaginghttpsarxivorgabs251204783v1 aria-label="Terahertz Fourier Ptychographic Imaging"><a href=https://arxiv.org/abs/2512.04783v1>Terahertz Fourier Ptychographic Imaging</a></a></li><li><a href=#demultiplexing-through-a-multimode-fiber-using-chip-scale-diffractive-neural-networkshttpsarxivorgabs251204767v1 aria-label="Demultiplexing through a multimode fiber using chip-scale diffractive neural networks"><a href=https://arxiv.org/abs/2512.04767v1>Demultiplexing through a multimode fiber using chip-scale diffractive neural networks</a></a></li><li><a href=#the-endocranial-cast-of-khirtharia-artiodactyla-raoellidae-provides-new-insights-into-the-earliest-evolution-of-the-cetacean-brainhttpsarxivorgabs251204624v1 aria-label="The Endocranial Cast of Khirtharia (Artiodactyla, Raoellidae) Provides New Insights into the Earliest Evolution of the Cetacean Brain"><a href=https://arxiv.org/abs/2512.04624v1>The Endocranial Cast of Khirtharia (Artiodactyla, Raoellidae) Provides New Insights into the Earliest Evolution of the Cetacean Brain</a></a></li><li><a href=#prompt2craft-generating-functional-craft-assemblies-with-llmshttpsarxivorgabs251204568v1 aria-label="Prompt2Craft: Generating Functional Craft Assemblies with LLMs"><a href=https://arxiv.org/abs/2512.04568v1>Prompt2Craft: Generating Functional Craft Assemblies with LLMs</a></a></li><li><a href=#videomem-enhancing-ultra-long-video-understanding-via-adaptive-memory-managementhttpsarxivorgabs251204540v1 aria-label="VideoMem: Enhancing Ultra-Long Video Understanding via Adaptive Memory Management"><a href=https://arxiv.org/abs/2512.04540v1>VideoMem: Enhancing Ultra-Long Video Understanding via Adaptive Memory Management</a></a></li><li><a href=#continuously-tunable-single-photon-level-nonlinearity-with-rydberg-state-wave-function-engineeringhttpsarxivorgabs251204525v1 aria-label="Continuously tunable single-photon level nonlinearity with Rydberg state wave-function engineering"><a href=https://arxiv.org/abs/2512.04525v1>Continuously tunable single-photon level nonlinearity with Rydberg state wave-function engineering</a></a></li><li><a href=#msme-a-multi-stage-multi-expert-framework-for-zero-shot-stance-detectionhttpsarxivorgabs251204492v1 aria-label="MSME: A Multi-Stage Multi-Expert Framework for Zero-Shot Stance Detection"><a href=https://arxiv.org/abs/2512.04492v1>MSME: A Multi-Stage Multi-Expert Framework for Zero-Shot Stance Detection</a></a></li><li><a href=#relative-wavefront-error-correction-over-a-24-km-free-space-optical-link-via-machine-learninghttpsarxivorgabs251204460v1 aria-label="Relative Wavefront Error Correction Over a 2.4 km Free-Space Optical Link via Machine Learning"><a href=https://arxiv.org/abs/2512.04460v1>Relative Wavefront Error Correction Over a 2.4 km Free-Space Optical Link via Machine Learning</a></a></li><li><a href=#govbench-benchmarking-llm-agents-for-real-world-data-governance-workflowshttpsarxivorgabs251204416v1 aria-label="GovBench: Benchmarking LLM Agents for Real-World Data Governance Workflows"><a href=https://arxiv.org/abs/2512.04416v1>GovBench: Benchmarking LLM Agents for Real-World Data Governance Workflows</a></a></li><li><a href=#the-personalization-paradox-semantic-loss-vs-reasoning-gains-in-agentic-ai-qahttpsarxivorgabs251204343v1 aria-label="The Personalization Paradox: Semantic Loss vs. Reasoning Gains in Agentic AI Q&amp;A"><a href=https://arxiv.org/abs/2512.04343v1>The Personalization Paradox: Semantic Loss vs. Reasoning Gains in Agentic AI Q&amp;A</a></a></li><li><a href=#a-retrieval-augmented-generation-approach-to-extracting-algorithmic-logic-from-neural-networkshttpsarxivorgabs251204329v1 aria-label="A Retrieval-Augmented Generation Approach to Extracting Algorithmic Logic from Neural Networks"><a href=https://arxiv.org/abs/2512.04329v1>A Retrieval-Augmented Generation Approach to Extracting Algorithmic Logic from Neural Networks</a></a></li><li><a href=#text-only-training-for-image-captioning-with-retrieval-augmentation-and-modality-gap-correctionhttpsarxivorgabs251204309v1 aria-label="Text-Only Training for Image Captioning with Retrieval Augmentation and Modality Gap Correction"><a href=https://arxiv.org/abs/2512.04309v1>Text-Only Training for Image Captioning with Retrieval Augmentation and Modality Gap Correction</a></a></li><li><a href=#evaluating-long-context-reasoning-in-llm-based-webagentshttpsarxivorgabs251204307v1 aria-label="Evaluating Long-Context Reasoning in LLM-Based WebAgents"><a href=https://arxiv.org/abs/2512.04307v1>Evaluating Long-Context Reasoning in LLM-Based WebAgents</a></a></li><li><a href=#square-structured-query--adaptive-retrieval-engine-for-tabular-formatshttpsarxivorgabs251204292v1 aria-label="SQuARE: Structured Query & Adaptive Retrieval Engine For Tabular Formats"><a href=https://arxiv.org/abs/2512.04292v1>SQuARE: Structured Query & Adaptive Retrieval Engine For Tabular Formats</a></a></li><li><a href=#craft-e-a-neuro-symbolic-framework-for-embodied-affordance-groundinghttpsarxivorgabs251204231v1 aria-label="CRAFT-E: A Neuro-Symbolic Framework for Embodied Affordance Grounding"><a href=https://arxiv.org/abs/2512.04231v1>CRAFT-E: A Neuro-Symbolic Framework for Embodied Affordance Grounding</a></a></li><li><a href=#on-grpo-collapse-in-search-r1-the-lazy-likelihood-displacement-death-spiralhttpsarxivorgabs251204220v1 aria-label="On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral"><a href=https://arxiv.org/abs/2512.04220v1>On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral</a></a></li><li><a href=#high-resolution-retrieval-of-atmospheric-boundary-layers-with-nonstationary-gaussian-processeshttpsarxivorgabs251204217v1 aria-label="High-Resolution Retrieval of Atmospheric Boundary Layers with Nonstationary Gaussian Processes"><a href=https://arxiv.org/abs/2512.04217v1>High-Resolution Retrieval of Atmospheric Boundary Layers with Nonstationary Gaussian Processes</a></a></li><li><a href=#fractal-aggregate-aerosols-in-the-virga-cloud-code-ii-exploring-the-effects-of-key-cloud-parameters-in-warm-neptune-hot-jupiter-and-brown-dwarf-atmosphereshttpsarxivorgabs251204186v1 aria-label="Fractal Aggregate Aerosols in the Virga Cloud Code II: Exploring the Effects of Key Cloud Parameters in Warm Neptune, Hot Jupiter and Brown Dwarf Atmospheres"><a href=https://arxiv.org/abs/2512.04186v1>Fractal Aggregate Aerosols in the Virga Cloud Code II: Exploring the Effects of Key Cloud Parameters in Warm Neptune, Hot Jupiter and Brown Dwarf Atmospheres</a></a></li><li><a href=#tighter-constraints-on-the-atmosphere-of-gj-436-b-from-combined-high-resolution-carmenes-and-crires-observationshttpsarxivorgabs251204161v1 aria-label="Tighter constraints on the atmosphere of GJ 436 b from combined high-resolution CARMENES and CRIRES$^+$ observations"><a href=https://arxiv.org/abs/2512.04161v1>Tighter constraints on the atmosphere of GJ 436 b from combined high-resolution CARMENES and CRIRES$^+$ observations</a></a></li><li><a href=#relic-interactive-video-world-model-with-long-horizon-memoryhttpsarxivorgabs251204040v1 aria-label="RELIC: Interactive Video World Model with Long-Horizon Memory"><a href=https://arxiv.org/abs/2512.04040v1>RELIC: Interactive Video World Model with Long-Horizon Memory</a></a></li><li><a href=#learning-to-comparison-shophttpsarxivorgabs251204009v1 aria-label="Learning to Comparison-Shop"><a href=https://arxiv.org/abs/2512.04009v1>Learning to Comparison-Shop</a></a></li><li><a href=#a-hierarchical-tree-based-approach-for-creating-configurable-and-static-deep-research-agent-static-drahttpsarxivorgabs251203887v2 aria-label="A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)"><a href=https://arxiv.org/abs/2512.03887v2>A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)</a></a></li><li><a href=#mechdetect-detecting-data-dependent-errorshttpsarxivorgabs251204138v1 aria-label="MechDetect: Detecting Data-Dependent Errors"><a href=https://arxiv.org/abs/2512.04138v1>MechDetect: Detecting Data-Dependent Errors</a></a></li><li><a href=#omnidexvlg-learning-dexterous-grasp-generation-from-vision-language-model-guided-grasp-semantics-taxonomy-and-functional-affordancehttpsarxivorgabs251203874v1 aria-label="OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance"><a href=https://arxiv.org/abs/2512.03874v1>OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance</a></a></li><li><a href=#algorithms-for-boolean-matrix-factorization-using-integer-programming-and-heuristicshttpsarxivorgabs251203807v2 aria-label="Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics"><a href=https://arxiv.org/abs/2512.03807v2>Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics</a></a></li><li><a href=#the-enshittification-of-online-search-privacy-and-quality-of-google-bing-and-apple-in-coding-advicehttpsarxivorgabs251203793v1 aria-label="The enshittification of online search? Privacy and quality of Google, Bing and Apple in coding advice"><a href=https://arxiv.org/abs/2512.03793v1>The enshittification of online search? Privacy and quality of Google, Bing and Apple in coding advice</a></a></li><li><a href=#ar-med-automated-relevance-enhancement-in-medical-search-via-llm-driven-information-augmentationhttpsarxivorgabs251203737v1 aria-label="AR-Med: Automated Relevance Enhancement in Medical Search via LLM-Driven Information Augmentation"><a href=https://arxiv.org/abs/2512.03737v1>AR-Med: Automated Relevance Enhancement in Medical Search via LLM-Driven Information Augmentation</a></a></li><li><a href=#dino-rotatematch-a-rotation-aware-deep-framework-for-robust-image-matching-in-large-scale-3d-reconstructionhttpsarxivorgabs251203715v1 aria-label="DINO-RotateMatch: A Rotation-Aware Deep Framework for Robust Image Matching in Large-Scale 3D Reconstruction"><a href=https://arxiv.org/abs/2512.03715v1>DINO-RotateMatch: A Rotation-Aware Deep Framework for Robust Image Matching in Large-Scale 3D Reconstruction</a></a></li><li><a href=#memverse-multimodal-memory-for-lifelong-learning-agentshttpsarxivorgabs251203627v1 aria-label="MemVerse: Multimodal Memory for Lifelong Learning Agents"><a href=https://arxiv.org/abs/2512.03627v1>MemVerse: Multimodal Memory for Lifelong Learning Agents</a></a></li><li><a href=#memory-guided-point-cloud-completion-for-dental-reconstructionhttpsarxivorgabs251203598v1 aria-label="Memory-Guided Point Cloud Completion for Dental Reconstruction"><a href=https://arxiv.org/abs/2512.03598v1>Memory-Guided Point Cloud Completion for Dental Reconstruction</a></a></li><li><a href=#towards-object-centric-understanding-for-instructional-videoshttpsarxivorgabs251203479v1 aria-label="Towards Object-centric Understanding for Instructional Videos"><a href=https://arxiv.org/abs/2512.03479v1>Towards Object-centric Understanding for Instructional Videos</a></a></li></ul></li><li><a href=#-linguistics aria-label="üîç linguistics">üîç linguistics</a><ul><li><a href=#on-the-treatment-of-thermal-effects-in-the-equation-of-state-on-neutron-star-merger-remnantshttpsarxivorgabs251205118v1 aria-label="On the treatment of thermal effects in the equation of state on neutron star merger remnants"><a href=https://arxiv.org/abs/2512.05118v1>On the treatment of thermal effects in the equation of state on neutron star merger remnants</a></a></li><li><a href=#light-x-generative-4d-video-rendering-with-camera-and-illumination-controlhttpsarxivorgabs251205115v1 aria-label="Light-X: Generative 4D Video Rendering with Camera and Illumination Control"><a href=https://arxiv.org/abs/2512.05115v1>Light-X: Generative 4D Video Rendering with Camera and Illumination Control</a></a></li><li><a href=#shadowdraw-from-any-object-to-shadow-drawing-compositional-arthttpsarxivorgabs251205110v1 aria-label="ShadowDraw: From Any Object to Shadow-Drawing Compositional Art"><a href=https://arxiv.org/abs/2512.05110v1>ShadowDraw: From Any Object to Shadow-Drawing Compositional Art</a></a></li><li><a href=#evoir-towards-all-in-one-image-restoration-via-evolutionary-frequency-modulationhttpsarxivorgabs251205104v1 aria-label="EvoIR: Towards All-in-One Image Restoration via Evolutionary Frequency Modulation"><a href=https://arxiv.org/abs/2512.05104v1>EvoIR: Towards All-in-One Image Restoration via Evolutionary Frequency Modulation</a></a></li><li><a href=#sa-iqa-redefining-image-quality-assessment-for-spatial-aesthetics-with-multi-dimensional-rewardshttpsarxivorgabs251205098v1 aria-label="SA-IQA: Redefining Image Quality Assessment for Spatial Aesthetics with Multi-Dimensional Rewards"><a href=https://arxiv.org/abs/2512.05098v1>SA-IQA: Redefining Image Quality Assessment for Spatial Aesthetics with Multi-Dimensional Rewards</a></a></li><li><a href=#from-generated-human-videos-to-physically-plausible-robot-trajectorieshttpsarxivorgabs251205094v1 aria-label="From Generated Human Videos to Physically Plausible Robot Trajectories"><a href=https://arxiv.org/abs/2512.05094v1>From Generated Human Videos to Physically Plausible Robot Trajectories</a></a></li><li><a href=#foundations-of-diffusion-models-in-general-state-spaces-a-self-contained-introductionhttpsarxivorgabs251205092v1 aria-label="Foundations of Diffusion Models in General State Spaces: A Self-Contained Introduction"><a href=https://arxiv.org/abs/2512.05092v1>Foundations of Diffusion Models in General State Spaces: A Self-Contained Introduction</a></a></li><li><a href=#the-geometry-of-intelligence-deterministic-functional-topology-as-a-foundation-for-real-world-perceptionhttpsarxivorgabs251205089v1 aria-label="The Geometry of Intelligence: Deterministic Functional Topology as a Foundation for Real-World Perception"><a href=https://arxiv.org/abs/2512.05089v1>The Geometry of Intelligence: Deterministic Functional Topology as a Foundation for Real-World Perception</a></a></li><li><a href=#first-study-of-the-nuclear-response-to-fast-hadrons-via-angular-correlations-between-pions-and-slow-protons-in-electron-nucleus-scatteringhttpsarxivorgabs251205083v1 aria-label="First Study of the Nuclear Response to Fast Hadrons via Angular Correlations between Pions and Slow Protons in Electron-Nucleus Scattering"><a href=https://arxiv.org/abs/2512.05083v1>First Study of the Nuclear Response to Fast Hadrons via Angular Correlations between Pions and Slow Protons in Electron-Nucleus Scattering</a></a></li><li><a href=#omtra-a-multi-task-generative-model-for-structure-based-drug-designhttpsarxivorgabs251205080v1 aria-label="OMTRA: A Multi-Task Generative Model for Structure-Based Drug Design"><a href=https://arxiv.org/abs/2512.05080v1>OMTRA: A Multi-Task Generative Model for Structure-Based Drug Design</a></a></li><li><a href=#object-reconstruction-under-occlusion-with-generative-priors-and-contact-induced-constraintshttpsarxivorgabs251205079v1 aria-label="Object Reconstruction under Occlusion with Generative Priors and Contact-induced Constraints"><a href=https://arxiv.org/abs/2512.05079v1>Object Reconstruction under Occlusion with Generative Priors and Contact-induced Constraints</a></a></li><li><a href=#bullettime-decoupled-control-of-time-and-camera-pose-for-video-generationhttpsarxivorgabs251205076v1 aria-label="BulletTime: Decoupled Control of Time and Camera Pose for Video Generation"><a href=https://arxiv.org/abs/2512.05076v1>BulletTime: Decoupled Control of Time and Camera Pose for Video Generation</a></a></li><li><a href=#thermodynamic-universality-across-dissipative-quantum-phase-transitionshttpsarxivorgabs251205074v1 aria-label="Thermodynamic universality across dissipative quantum phase transitions"><a href=https://arxiv.org/abs/2512.05074v1>Thermodynamic universality across dissipative quantum phase transitions</a></a></li><li><a href=#carrollian-holographic-duals-are-non-localhttpsarxivorgabs251205072v1 aria-label="Carrollian holographic duals are non-local"><a href=https://arxiv.org/abs/2512.05072v1>Carrollian holographic duals are non-local</a></a></li><li><a href=#hybrid-quantum-classical-autoencoders-for-unsupervised-network-intrusion-detectionhttpsarxivorgabs251205069v1 aria-label="Hybrid Quantum-Classical Autoencoders for Unsupervised Network Intrusion Detection"><a href=https://arxiv.org/abs/2512.05069v1>Hybrid Quantum-Classical Autoencoders for Unsupervised Network Intrusion Detection</a></a></li><li><a href=#perceptually-minimal-color-optimization-for-web-accessibility-a-multi-phase-constrained-approachhttpsarxivorgabs251205067v1 aria-label="Perceptually-Minimal Color Optimization for Web Accessibility: A Multi-Phase Constrained Approach"><a href=https://arxiv.org/abs/2512.05067v1>Perceptually-Minimal Color Optimization for Web Accessibility: A Multi-Phase Constrained Approach</a></a></li><li><a href=#axionic-tunneling-from-a-topological-kondo-insulatorhttpsarxivorgabs251205057v1 aria-label="Axionic tunneling from a topological Kondo insulator"><a href=https://arxiv.org/abs/2512.05057v1>Axionic tunneling from a topological Kondo insulator</a></a></li><li><a href=#a-nehari-manifold-method-for-nonvariational-problemshttpsarxivorgabs251205055v1 aria-label="A Nehari manifold method for nonvariational problems"><a href=https://arxiv.org/abs/2512.05055v1>A Nehari manifold method for nonvariational problems</a></a></li><li><a href=#qkan-lstm-quantum-inspired-kolmogorov-arnold-long-short-term-memoryhttpsarxivorgabs251205049v1 aria-label="QKAN-LSTM: Quantum-inspired Kolmogorov-Arnold Long Short-term Memory"><a href=https://arxiv.org/abs/2512.05049v1>QKAN-LSTM: Quantum-inspired Kolmogorov-Arnold Long Short-term Memory</a></a></li><li><a href=#joint-3d-geometry-reconstruction-and-motion-generation-for-4d-synthesis-from-a-single-imagehttpsarxivorgabs251205044v1 aria-label="Joint 3D Geometry Reconstruction and Motion Generation for 4D Synthesis from a Single Image"><a href=https://arxiv.org/abs/2512.05044v1>Joint 3D Geometry Reconstruction and Motion Generation for 4D Synthesis from a Single Image</a></a></li><li><a href=#a-theory-of-backgrounds-and-background-independencehttpsarxivorgabs251205043v1 aria-label="A Theory of Backgrounds and Background Independence"><a href=https://arxiv.org/abs/2512.05043v1>A Theory of Backgrounds and Background Independence</a></a></li><li><a href=#semantic-guided-two-stage-gan-for-face-inpainting-with-hybrid-perceptual-encodinghttpsarxivorgabs251205039v1 aria-label="Semantic-Guided Two-Stage GAN for Face Inpainting with Hybrid Perceptual Encoding"><a href=https://arxiv.org/abs/2512.05039v1>Semantic-Guided Two-Stage GAN for Face Inpainting with Hybrid Perceptual Encoding</a></a></li><li><a href=#superactivators-only-the-tail-of-the-distribution-contains-reliable-concept-signalshttpsarxivorgabs251205038v1 aria-label="SuperActivators: Only the Tail of the Distribution Contains Reliable Concept Signals"><a href=https://arxiv.org/abs/2512.05038v1>SuperActivators: Only the Tail of the Distribution Contains Reliable Concept Signals</a></a></li><li><a href=#cumulant-expansions-of-operator-groups-of-quantum-many-particle-systemshttpsarxivorgabs251205036v1 aria-label="Cumulant expansions of operator groups of quantum many-particle systems"><a href=https://arxiv.org/abs/2512.05036v1>Cumulant expansions of operator groups of quantum many-particle systems</a></a></li><li><a href=#exploring-asymmetries-in-three-body-clfv-lepton-decays-probing-cp-violation-in-hnl-extensions-of-the-smhttpsarxivorgabs251205032v1 aria-label="Exploring asymmetries in three-body cLFV lepton decays: probing CP violation in HNL extensions of the SM"><a href=https://arxiv.org/abs/2512.05032v1>Exploring asymmetries in three-body cLFV lepton decays: probing CP violation in HNL extensions of the SM</a></a></li><li><a href=#efficient-decoders-for-sensing-subspace-codehttpsarxivorgabs251205028v1 aria-label="Efficient Decoders for Sensing Subspace Code"><a href=https://arxiv.org/abs/2512.05028v1>Efficient Decoders for Sensing Subspace Code</a></a></li><li><a href=#frobenius-generation-for-algebraic-stackshttpsarxivorgabs251205026v1 aria-label="Frobenius generation for algebraic stacks"><a href=https://arxiv.org/abs/2512.05026v1>Frobenius generation for algebraic stacks</a></a></li><li><a href=#htr-convtext-leveraging-convolution-and-textual-information-for-handwritten-text-recognitionhttpsarxivorgabs251205021v1 aria-label="HTR-ConvText: Leveraging Convolution and Textual Information for Handwritten Text Recognition"><a href=https://arxiv.org/abs/2512.05021v1>HTR-ConvText: Leveraging Convolution and Textual Information for Handwritten Text Recognition</a></a></li><li><a href=#l%c3%a9vy-sources-in-urqmd-in-arsc-collisions-at-sps-energieshttpsarxivorgabs251205019v1 aria-label="L√©vy sources in UrQMD in Ar+Sc collisions at SPS energies"><a href=https://arxiv.org/abs/2512.05019v1>L√©vy sources in UrQMD in Ar+Sc collisions at SPS energies</a></a></li><li><a href=#isolating-chirality-breaking-smeft-operators-with-drell-yan-angular-analysishttpsarxivorgabs251205018v1 aria-label="Isolating chirality-breaking SMEFT operators with Drell-Yan angular analysis"><a href=https://arxiv.org/abs/2512.05018v1>Isolating chirality-breaking SMEFT operators with Drell-Yan angular analysis</a></a></li><li><a href=#the-magnus-expansion-in-relativistic-quantum-field-theoryhttpsarxivorgabs251205017v1 aria-label="The Magnus expansion in relativistic quantum field theory"><a href=https://arxiv.org/abs/2512.05017v1>The Magnus expansion in relativistic quantum field theory</a></a></li><li><a href=#generative-neural-video-compression-via-video-diffusion-priorhttpsarxivorgabs251205016v1 aria-label="Generative Neural Video Compression via Video Diffusion Prior"><a href=https://arxiv.org/abs/2512.05016v1>Generative Neural Video Compression via Video Diffusion Prior</a></a></li><li><a href=#hall-like-response-from-anisotropic-fermi-surfaceshttpsarxivorgabs251205014v1 aria-label="Hall-like response from anisotropic Fermi surfaces"><a href=https://arxiv.org/abs/2512.05014v1>Hall-like response from anisotropic Fermi surfaces</a></a></li><li><a href=#detecting-perspective-shifts-in-multi-agent-systemshttpsarxivorgabs251205013v1 aria-label="Detecting Perspective Shifts in Multi-agent Systems"><a href=https://arxiv.org/abs/2512.05013v1>Detecting Perspective Shifts in Multi-agent Systems</a></a></li><li><a href=#deep-infant-brain-segmentation-from-multi-contrast-mrihttpsarxivorgabs251205114v1 aria-label="Deep infant brain segmentation from multi-contrast MRI"><a href=https://arxiv.org/abs/2512.05114v1>Deep infant brain segmentation from multi-contrast MRI</a></a></li><li><a href=#resolving-the-molecular-gas-emission-of-the-z25-28-starburst-galaxies-spt0125-47-and-spt-2134-50httpsarxivorgabs251205093v1 aria-label="Resolving the molecular gas emission of the z~2.5-2.8 starburst galaxies SPT0125-47 and SPT 2134-50"><a href=https://arxiv.org/abs/2512.05093v1>Resolving the molecular gas emission of the z~2.5-2.8 starburst galaxies SPT0125-47 and SPT 2134-50</a></a></li><li><a href=#prediction-of-novel-li-agii-f-compounds-using-evolutionary-algorithmshttpsarxivorgabs251205048v1 aria-label="Prediction of Novel Li-AgII-F Compounds using Evolutionary Algorithms"><a href=https://arxiv.org/abs/2512.05048v1>Prediction of Novel Li-AgII-F Compounds using Evolutionary Algorithms</a></a></li><li><a href=#structured-light-at-the-extreme-harnessing-spatiotemporal-control-for-high-field-laser-matter-interactionshttpsarxivorgabs251205042v1 aria-label="Structured Light at the Extreme: Harnessing Spatiotemporal Control for High-Field Laser-Matter Interactions"><a href=https://arxiv.org/abs/2512.05042v1>Structured Light at the Extreme: Harnessing Spatiotemporal Control for High-Field Laser-Matter Interactions</a></a></li><li><a href=#probing-agn-feedback-in-dwarf-galaxies-with-spatially-resolved-nir-coronal-lines-from-jwsthttpsarxivorgabs251205041v1 aria-label="Probing AGN Feedback in Dwarf Galaxies with Spatially Resolved NIR Coronal Lines from JWST"><a href=https://arxiv.org/abs/2512.05041v1>Probing AGN Feedback in Dwarf Galaxies with Spatially Resolved NIR Coronal Lines from JWST</a></a></li><li><a href=#geometric-data-sciencehttpsarxivorgabs251205040v1 aria-label="Geometric Data Science"><a href=https://arxiv.org/abs/2512.05040v1>Geometric Data Science</a></a></li><li><a href=#spectrum-and-anisotropies-of-galactic-cosmic-rays-a-laboratory-for-magnetic-fieldshttpsarxivorgabs251205035v1 aria-label="Spectrum and anisotropies of Galactic cosmic rays: a laboratory for magnetic fields"><a href=https://arxiv.org/abs/2512.05035v1>Spectrum and anisotropies of Galactic cosmic rays: a laboratory for magnetic fields</a></a></li><li><a href=#emergence-of-erepr-from-non-local-gravitational-energyhttpsarxivorgabs251205022v1 aria-label="Emergence of ER=EPR from non-local gravitational energy"><a href=https://arxiv.org/abs/2512.05022v1>Emergence of ER=EPR from non-local gravitational energy</a></a></li><li><a href=#revealing-stimulus-dependent-dynamics-through-statistical-complexityhttpsarxivorgabs251205007v1 aria-label="Revealing stimulus-dependent dynamics through statistical complexity"><a href=https://arxiv.org/abs/2512.05007v1>Revealing stimulus-dependent dynamics through statistical complexity</a></a></li><li><a href=#generalized-pinching-antenna-systems-a-leaky-coaxial-cable-perspectivehttpsarxivorgabs251204979v1 aria-label="Generalized Pinching-Antenna Systems: A Leaky-Coaxial-Cable Perspective"><a href=https://arxiv.org/abs/2512.04979v1>Generalized Pinching-Antenna Systems: A Leaky-Coaxial-Cable Perspective</a></a></li><li><a href=#tracing-the-horizon-of-tetragonal-to-monoclinic-distortion-in-pressurized-trilayer-nickelate-la4ni3o10httpsarxivorgabs251204975v1 aria-label="Tracing the horizon of tetragonal-to-monoclinic distortion in pressurized trilayer nickelate La4Ni3O10"><a href=https://arxiv.org/abs/2512.04975v1>Tracing the horizon of tetragonal-to-monoclinic distortion in pressurized trilayer nickelate La4Ni3O10</a></a></li><li><a href=#preliminary-analysis-and-simulation-of-a-compact-variable-stiffness-wristhttpsarxivorgabs251204973v1 aria-label="Preliminary Analysis and Simulation of a Compact Variable Stiffness Wrist"><a href=https://arxiv.org/abs/2512.04973v1>Preliminary Analysis and Simulation of a Compact Variable Stiffness Wrist</a></a></li><li><a href=#internal-superfluid-response-and-torque-evolution-in-the-giant-glitch-of-psr-j1718-3718httpsarxivorgabs251204972v1 aria-label="Internal superfluid response and torque evolution in the giant glitch of PSR J1718-3718"><a href=https://arxiv.org/abs/2512.04972v1>Internal superfluid response and torque evolution in the giant glitch of PSR J1718-3718</a></a></li><li><a href=#geopea-unified-geometric-positional-embedding-for-structured-tensorshttpsarxivorgabs251204963v1 aria-label="GeoPE:A Unified Geometric Positional Embedding for Structured Tensors"><a href=https://arxiv.org/abs/2512.04963v1>GeoPE:A Unified Geometric Positional Embedding for Structured Tensors</a></a></li><li><a href=#existence-and-a-priori-bounds-for-fully-nonlinear-pdes-with-a-harmonic-map-like-structurehttpsarxivorgabs251204961v1 aria-label="Existence and a priori bounds for fully nonlinear PDEs with a harmonic map-like structure"><a href=https://arxiv.org/abs/2512.04961v1>Existence and a priori bounds for fully nonlinear PDEs with a harmonic map-like structure</a></a></li><li><a href=#semantics-lead-the-way-harmonizing-semantic-and-texture-modeling-with-asynchronous-latent-diffusionhttpsarxivorgabs251204926v1 aria-label="Semantics Lead the Way: Harmonizing Semantic and Texture Modeling with Asynchronous Latent Diffusion"><a href=https://arxiv.org/abs/2512.04926v1>Semantics Lead the Way: Harmonizing Semantic and Texture Modeling with Asynchronous Latent Diffusion</a></a></li><li><a href=#logic-driven-cybersecurity-a-novel-framework-for-system-log-anomaly-detection-using-answer-set-programminghttpsarxivorgabs251204908v1 aria-label="Logic-Driven Cybersecurity: A Novel Framework for System Log Anomaly Detection using Answer Set Programming"><a href=https://arxiv.org/abs/2512.04908v1>Logic-Driven Cybersecurity: A Novel Framework for System Log Anomaly Detection using Answer Set Programming</a></a></li><li><a href=#pvls-a-learning-based-parameter-prediction-technique-for-variational-quantum-linear-solvershttpsarxivorgabs251204909v1 aria-label="PVLS: A Learning-based Parameter Prediction Technique for Variational Quantum Linear Solvers"><a href=https://arxiv.org/abs/2512.04909v1>PVLS: A Learning-based Parameter Prediction Technique for Variational Quantum Linear Solvers</a></a></li><li><a href=#optical-readout-of-reconfigurable-layered-magnetic-domain-structure-in-crsbrhttpsarxivorgabs251204887v1 aria-label="Optical Readout of Reconfigurable Layered Magnetic Domain Structure in CrSBr"><a href=https://arxiv.org/abs/2512.04887v1>Optical Readout of Reconfigurable Layered Magnetic Domain Structure in CrSBr</a></a></li><li><a href=#on-hyperbolic-approximations-for-a-class-of-dispersive-and-diffusive-dispersive-equationshttpsarxivorgabs251204882v1 aria-label="On hyperbolic approximations for a class of dispersive and diffusive-dispersive equations"><a href=https://arxiv.org/abs/2512.04882v1>On hyperbolic approximations for a class of dispersive and diffusive-dispersive equations</a></a></li><li><a href=#shorting-dynamics-and-structured-kernel-regularizationhttpsarxivorgabs251204874v1 aria-label="Shorting Dynamics and Structured Kernel Regularization"><a href=https://arxiv.org/abs/2512.04874v1>Shorting Dynamics and Structured Kernel Regularization</a></a></li><li><a href=#series-of-quasi-uniform-scatterings-with-fast-search-root-systems-and-neural-network-classificationshttpsarxivorgabs251204865v1 aria-label="Series of quasi-uniform scatterings with fast search, root systems and neural network classifications"><a href=https://arxiv.org/abs/2512.04865v1>Series of quasi-uniform scatterings with fast search, root systems and neural network classifications</a></a></li><li><a href=#penco-a-physics-energy-numerical-consistent-operator-for-3d-phase-field-modelinghttpsarxivorgabs251204863v1 aria-label="PENCO: A Physics-Energy-Numerical-Consistent Operator for 3D Phase Field Modeling"><a href=https://arxiv.org/abs/2512.04863v1>PENCO: A Physics-Energy-Numerical-Consistent Operator for 3D Phase Field Modeling</a></a></li><li><a href=#stochastic-density-functional-theory-through-the-lens-of-multilevel-monte-carlo-methodhttpsarxivorgabs251204860v1 aria-label="Stochastic Density Functional Theory Through the Lens of Multilevel Monte Carlo Method"><a href=https://arxiv.org/abs/2512.04860v1>Stochastic Density Functional Theory Through the Lens of Multilevel Monte Carlo Method</a></a></li><li><a href=#improving-posterior-inference-of-galaxy-properties-with-image-based-conditional-flow-matchinghttpsarxivorgabs251205078v1 aria-label="Improving Posterior Inference of Galaxy Properties with Image-Based Conditional Flow Matching"><a href=https://arxiv.org/abs/2512.05078v1>Improving Posterior Inference of Galaxy Properties with Image-Based Conditional Flow Matching</a></a></li><li><a href=#on-random-matrix-statistics-of-3d-gravityhttpsarxivorgabs251205045v1 aria-label="On random matrix statistics of 3d gravity"><a href=https://arxiv.org/abs/2512.05045v1>On random matrix statistics of 3d gravity</a></a></li><li><a href=#distributed-riemannian-optimization-in-geodesically-non-convex-environmentshttpsarxivorgabs251204915v1 aria-label="Distributed Riemannian Optimization in Geodesically Non-convex Environments"><a href=https://arxiv.org/abs/2512.04915v1>Distributed Riemannian Optimization in Geodesically Non-convex Environments</a></a></li><li><a href=#analytical-and-cross-sectional-clinical-validity-of-a-smartphone-based-u-turn-test-in-multiple-sclerosishttpsarxivorgabs251204914v1 aria-label="Analytical and Cross-Sectional Clinical Validity of a Smartphone-Based U-Turn Test in Multiple Sclerosis"><a href=https://arxiv.org/abs/2512.04914v1>Analytical and Cross-Sectional Clinical Validity of a Smartphone-Based U-Turn Test in Multiple Sclerosis</a></a></li><li><a href=#fence-flexible-electric-noise-cancellation-endo-shield-for-the-suppression-of-electromagnetic-interference-in-low-field-mrihttpsarxivorgabs251204889v1 aria-label="FENCE: Flexible Electric Noise Cancellation Endo-shield for the Suppression of Electromagnetic Interference in Low-Field MRI"><a href=https://arxiv.org/abs/2512.04889v1>FENCE: Flexible Electric Noise Cancellation Endo-shield for the Suppression of Electromagnetic Interference in Low-Field MRI</a></a></li><li><a href=#controlling-carbon-nanostructure-synthesis-in-thermal-plasma-jet-correlation-of-process-parameters-plasma-characteristics-and-product-morphologyhttpsarxivorgabs251204880v1 aria-label="Controlling Carbon Nanostructure Synthesis in Thermal Plasma Jet: Correlation of Process Parameters, Plasma Characteristics, and Product Morphology"><a href=https://arxiv.org/abs/2512.04880v1>Controlling Carbon Nanostructure Synthesis in Thermal Plasma Jet: Correlation of Process Parameters, Plasma Characteristics, and Product Morphology</a></a></li><li><a href=#isostructural-phase-transition-and-equation-of-state-of-type-i-and-type-viii-metallic-sodium-borosilicide-clathrateshttpsarxivorgabs251204878v1 aria-label="Isostructural phase transition and equation of state of type-I and type-VIII metallic sodium borosilicide clathrates"><a href=https://arxiv.org/abs/2512.04878v1>Isostructural phase transition and equation of state of type-I and type-VIII metallic sodium borosilicide clathrates</a></a></li><li><a href=#vns-tokamak-openmc-serpent-validation-for-medical-isotope-studieshttpsarxivorgabs251204873v1 aria-label="VNS Tokamak OpenMC-Serpent Validation for Medical Isotope Studies"><a href=https://arxiv.org/abs/2512.04873v1>VNS Tokamak OpenMC-Serpent Validation for Medical Isotope Studies</a></a></li><li><a href=#embodied-co-design-for-rapidly-evolving-agents-taxonomy-frontiers-and-challengeshttpsarxivorgabs251204770v1 aria-label="Embodied Co-Design for Rapidly Evolving Agents: Taxonomy, Frontiers, and Challenges"><a href=https://arxiv.org/abs/2512.04770v1>Embodied Co-Design for Rapidly Evolving Agents: Taxonomy, Frontiers, and Challenges</a></a></li><li><a href=#human-cognitive-biases-in-explanation-based-interaction-the-case-of-within-and-between-session-order-effecthttpsarxivorgabs251204764v1 aria-label="Human Cognitive Biases in Explanation-Based Interaction: The Case of Within and Between Session Order Effect"><a href=https://arxiv.org/abs/2512.04764v1>Human Cognitive Biases in Explanation-Based Interaction: The Case of Within and Between Session Order Effect</a></a></li><li><a href=#the-next-to-next-to-leading-order-qcd-corrections-to-ee-to-%ce%b7_c%cf%87_cj%ce%b3-at-b-factorieshttpsarxivorgabs251204758v1 aria-label="The next-to-next-to-leading-order QCD corrections to $e^+e^-\to Œ∑_c/œá_{cJ}+Œ≥$ at B factories"><a href=https://arxiv.org/abs/2512.04758v1>The next-to-next-to-leading-order QCD corrections to $e^+e^-\to Œ∑_c/œá_{cJ}+Œ≥$ at B factories</a></a></li><li><a href=#static-fission-properties-of-even-even-actinides-within-the-warsaw-macroscopic-microscopic-model-using-fourier-over-spheroid-parameterizationhttpsarxivorgabs251204739v1 aria-label="Static Fission Properties of Even-Even Actinides within the Warsaw Macroscopic-Microscopic Model Using Fourier-over-Spheroid Parameterization"><a href=https://arxiv.org/abs/2512.04739v1>Static Fission Properties of Even-Even Actinides within the Warsaw Macroscopic-Microscopic Model Using Fourier-over-Spheroid Parameterization</a></a></li><li><a href=#flux-controlled-wall-model-for-large-eddy-simulation-integrating-the-compressible-law-of-the-wallhttpsarxivorgabs251204688v1 aria-label="Flux-controlled wall model for large eddy simulation integrating the compressible law of the wall"><a href=https://arxiv.org/abs/2512.04688v1>Flux-controlled wall model for large eddy simulation integrating the compressible law of the wall</a></a></li><li><a href=#probing-chiral-topological-states-with-permutation-defectshttpsarxivorgabs251204649v1 aria-label="Probing chiral topological states with permutation defects"><a href=https://arxiv.org/abs/2512.04649v1>Probing chiral topological states with permutation defects</a></a></li><li><a href=#contract-governed-training-for-earth-observation-observed-service-agreement-graphs-and-coverage-accuracy-trade-offshttpsarxivorgabs251204644v1 aria-label="Contract-Governed Training for Earth Observation: Observed Service Agreement Graphs and Coverage-Accuracy Trade-offs"><a href=https://arxiv.org/abs/2512.04644v1>Contract-Governed Training for Earth Observation: Observed Service Agreement Graphs and Coverage-Accuracy Trade-offs</a></a></li><li><a href=#phase-transitions-on-the-dark-side-of-the-gross-neveu-modelhttpsarxivorgabs251204626v1 aria-label="Phase transitions on the dark side of the Gross-Neveu model"><a href=https://arxiv.org/abs/2512.04626v1>Phase transitions on the dark side of the Gross-Neveu model</a></a></li><li><a href=#the-dynamical-memory-of-tidal-stellar-streams-joint-inference-of-the-galactic-potential-and-the-progenitor-of-gd-1-with-flow-matchinghttpsarxivorgabs251204600v1 aria-label="The dynamical memory of tidal stellar streams: Joint inference of the Galactic potential and the progenitor of GD-1 with flow matching"><a href=https://arxiv.org/abs/2512.04600v1>The dynamical memory of tidal stellar streams: Joint inference of the Galactic potential and the progenitor of GD-1 with flow matching</a></a></li><li><a href=#a-hybrid-green-kubo-hgk-framework-for-calculating-viscosity-from-short-md-simulationshttpsarxivorgabs251204546v1 aria-label="A hybrid Green-Kubo (hGK) framework for calculating viscosity from short MD simulations"><a href=https://arxiv.org/abs/2512.04546v1>A hybrid Green-Kubo (hGK) framework for calculating viscosity from short MD simulations</a></a></li><li><a href=#convergence-dynamics-and-scaling-laws-in-the-dissipative-relativistic-kicked-rotatorhttpsarxivorgabs251204471v1 aria-label="Convergence Dynamics and Scaling Laws in the Dissipative Relativistic Kicked Rotator"><a href=https://arxiv.org/abs/2512.04471v1>Convergence Dynamics and Scaling Laws in the Dissipative Relativistic Kicked Rotator</a></a></li><li><a href=#biomimetic-liquid-metal-cellhttpsarxivorgabs251204455v1 aria-label="Biomimetic Liquid Metal Cell"><a href=https://arxiv.org/abs/2512.04455v1>Biomimetic Liquid Metal Cell</a></a></li><li><a href=#executable-governance-for-ai-translating-policies-into-rules-using-llmshttpsarxivorgabs251204408v1 aria-label="Executable Governance for AI: Translating Policies into Rules Using LLMs"><a href=https://arxiv.org/abs/2512.04408v1>Executable Governance for AI: Translating Policies into Rules Using LLMs</a></a></li><li><a href=#hairy-black-holes-via-gravitational-decoupling-light-rings-absorption-and-spectral-lineshttpsarxivorgabs251204377v1 aria-label="Hairy black holes via gravitational decoupling: light rings, absorption and spectral lines"><a href=https://arxiv.org/abs/2512.04377v1>Hairy black holes via gravitational decoupling: light rings, absorption and spectral lines</a></a></li><li><a href=#preparation-and-magnetic-properties-of-ln02la02nd02sm02-eu02mno3-ln--dy-ho-er-high-entropy-perovskite-ceramics-containing-heavy-rare-earth-elementshttpsarxivorgabs251204370v1 aria-label="Preparation and magnetic properties of (Ln0.2La0.2Nd0.2Sm0.2 Eu0.2)MnO3 (Ln = Dy, Ho, Er) high-entropy perovskite ceramics containing heavy rare earth elements"><a href=https://arxiv.org/abs/2512.04370v1>Preparation and magnetic properties of (Ln0.2La0.2Nd0.2Sm0.2 Eu0.2)MnO3 (Ln = Dy, Ho, Er) high-entropy perovskite ceramics containing heavy rare earth elements</a></a></li><li><a href=#catching-ux-flaws-in-code-leveraging-llms-to-identify-usability-flaws-at-the-development-stagehttpsarxivorgabs251204262v1 aria-label="Catching UX Flaws in Code: Leveraging LLMs to Identify Usability Flaws at the Development Stage"><a href=https://arxiv.org/abs/2512.04262v1>Catching UX Flaws in Code: Leveraging LLMs to Identify Usability Flaws at the Development Stage</a></a></li><li><a href=#small-models-achieve-large-language-model-performance-evaluating-reasoning-enabled-ai-for-secure-child-welfare-researchhttpsarxivorgabs251204261v1 aria-label="Small Models Achieve Large Language Model Performance: Evaluating Reasoning-Enabled AI for Secure Child Welfare Research"><a href=https://arxiv.org/abs/2512.04261v1>Small Models Achieve Large Language Model Performance: Evaluating Reasoning-Enabled AI for Secure Child Welfare Research</a></a></li><li><a href=#reasonx-mllm-guided-intrinsic-image-decompositionhttpsarxivorgabs251204222v1 aria-label="ReasonX: MLLM-Guided Intrinsic Image Decomposition"><a href=https://arxiv.org/abs/2512.04222v1>ReasonX: MLLM-Guided Intrinsic Image Decomposition</a></a></li><li><a href=#confronting-cosmic-shear-astrophysical-uncertainties-des-year-3-revisitedhttpsarxivorgabs251204209v1 aria-label="Confronting cosmic shear astrophysical uncertainties: DES Year 3 revisited"><a href=https://arxiv.org/abs/2512.04209v1>Confronting cosmic shear astrophysical uncertainties: DES Year 3 revisited</a></a></li><li><a href=#a-black-hole-envelope-interpretation-for-cosmological-demographics-of-little-red-dotshttpsarxivorgabs251204208v1 aria-label="A Black-Hole Envelope Interpretation for Cosmological Demographics of Little Red Dots"><a href=https://arxiv.org/abs/2512.04208v1>A Black-Hole Envelope Interpretation for Cosmological Demographics of Little Red Dots</a></a></li><li><a href=#stellar-bars-in-jellyfish-galaxies-statistical-insights-into-the-combined-role-of-bars-and-environmenthttpsarxivorgabs251204196v1 aria-label="Stellar Bars in Jellyfish Galaxies: Statistical Insights into the Combined Role of Bars and Environment"><a href=https://arxiv.org/abs/2512.04196v1>Stellar Bars in Jellyfish Galaxies: Statistical Insights into the Combined Role of Bars and Environment</a></a></li><li><a href=#entanglement-surfaces-for-rotating-cylindrical-black-holeshttpsarxivorgabs251204193v1 aria-label="Entanglement surfaces for rotating cylindrical black holes"><a href=https://arxiv.org/abs/2512.04193v1>Entanglement surfaces for rotating cylindrical black holes</a></a></li><li><a href=#jwst-confirmation-of-a-runaway-supermassive-black-hole-via-its-supersonic-bow-shockhttpsarxivorgabs251204166v1 aria-label="JWST Confirmation of a Runaway Supermassive Black Hole via its Supersonic Bow Shock"><a href=https://arxiv.org/abs/2512.04166v1>JWST Confirmation of a Runaway Supermassive Black Hole via its Supersonic Bow Shock</a></a></li><li><a href=#popcorn-emris-transient-gravitational-wave-signals-and-their-analysis-in-schwartz-spacehttpsarxivorgabs251204167v1 aria-label="Popcorn EMRIs: Transient Gravitational Wave Signals and Their Analysis in Schwartz Space"><a href=https://arxiv.org/abs/2512.04167v1>Popcorn EMRIs: Transient Gravitational Wave Signals and Their Analysis in Schwartz Space</a></a></li><li><a href=#galactic-bars-are-already-mature-at-cosmic-noon-bar-strength-and-flatness-at-z--15httpsarxivorgabs251204163v1 aria-label="Galactic bars are already mature at Cosmic Noon: bar strength and flatness at z ~ 1.5"><a href=https://arxiv.org/abs/2512.04163v1>Galactic bars are already mature at Cosmic Noon: bar strength and flatness at z ~ 1.5</a></a></li><li><a href=#minuet-a-diffusion-autoencoder-for-compact-semantic-compression-of-multi-band-galaxy-imageshttpsarxivorgabs251204145v1 aria-label="Minuet: A Diffusion Autoencoder for Compact Semantic Compression of Multi-Band Galaxy Images"><a href=https://arxiv.org/abs/2512.04145v1>Minuet: A Diffusion Autoencoder for Compact Semantic Compression of Multi-Band Galaxy Images</a></a></li><li><a href=#machine-learning-pipeline-for-denoising-low-signal-to-noise-ratio-and-out-of-distribution-transmission-electron-microscopy-datasetshttpsarxivorgabs251204045v1 aria-label="Machine Learning Pipeline for Denoising Low Signal-To-Noise Ratio and Out-of-Distribution Transmission Electron Microscopy Datasets"><a href=https://arxiv.org/abs/2512.04045v1>Machine Learning Pipeline for Denoising Low Signal-To-Noise Ratio and Out-of-Distribution Transmission Electron Microscopy Datasets</a></a></li><li><a href=#testing-the-localization-landscape-theory-on-the-bethe-latticehttpsarxivorgabs251204037v1 aria-label="Testing the Localization Landscape Theory on the Bethe Lattice"><a href=https://arxiv.org/abs/2512.04037v1>Testing the Localization Landscape Theory on the Bethe Lattice</a></a></li><li><a href=#pleiades-binary-fraction-revisitedhttpsarxivorgabs251204143v1 aria-label="Pleiades Binary Fraction Revisited"><a href=https://arxiv.org/abs/2512.04143v1>Pleiades Binary Fraction Revisited</a></a></li><li><a href=#the-nuclear-star-cluster-of-m-74-a-fossil-record-of-the-very-early-stages-of-a-star-forming-galaxyhttpsarxivorgabs251203999v1 aria-label="The Nuclear Star Cluster of M 74: a fossil record of the very early stages of a star-forming galaxy"><a href=https://arxiv.org/abs/2512.03999v1>The Nuclear Star Cluster of M 74: a fossil record of the very early stages of a star-forming galaxy</a></a></li><li><a href=#fully-quantum-theory-of-strong-field-driven-tunable-entangled-multi-photon-states-in-hhghttpsarxivorgabs251203987v1 aria-label="Fully quantum theory of strong-field driven tunable entangled multi-photon states in HHG"><a href=https://arxiv.org/abs/2512.03987v1>Fully quantum theory of strong-field driven tunable entangled multi-photon states in HHG</a></a></li><li><a href=#x-tra-through-the-eyes-of-matisse-more-evidence-of-clumpy-molecular-layers-around-c-type-asymptotic-giant-branch-starshttpsarxivorgabs251203910v1 aria-label="X TrA through the eyes of MATISSE: More evidence of clumpy molecular layers around C-type asymptotic giant branch stars"><a href=https://arxiv.org/abs/2512.03910v1>X TrA through the eyes of MATISSE: More evidence of clumpy molecular layers around C-type asymptotic giant branch stars</a></a></li><li><a href=#bernat-basque-encoders-for-representing-natural-textual-diversityhttpsarxivorgabs251203903v1 aria-label="BERnaT: Basque Encoders for Representing Natural Textual Diversity"><a href=https://arxiv.org/abs/2512.03903v1>BERnaT: Basque Encoders for Representing Natural Textual Diversity</a></a></li><li><a href=#errors-in-pdh-offset-locking-due-to-spurious-spectral-featureshttpsarxivorgabs251203900v1 aria-label="Errors in PDH offset locking due to spurious spectral features"><a href=https://arxiv.org/abs/2512.03900v1>Errors in PDH offset locking due to spurious spectral features</a></a></li><li><a href=#an-automated-framework-for-large-scale-graph-based-cerebrovascular-analysishttpsarxivorgabs251203869v1 aria-label="An Automated Framework for Large-Scale Graph-Based Cerebrovascular Analysis"><a href=https://arxiv.org/abs/2512.03869v1>An Automated Framework for Large-Scale Graph-Based Cerebrovascular Analysis</a></a></li><li><a href=#gradient-descent-with-provably-tuned-learning-rate-scheduleshttpsarxivorgabs251205084v1 aria-label="Gradient Descent with Provably Tuned Learning-rate Schedules"><a href=https://arxiv.org/abs/2512.05084v1>Gradient Descent with Provably Tuned Learning-rate Schedules</a></a></li><li><a href=#control-consistency-losses-for-diffusion-bridgeshttpsarxivorgabs251205070v1 aria-label="Control Consistency Losses for Diffusion Bridges"><a href=https://arxiv.org/abs/2512.05070v1>Control Consistency Losses for Diffusion Bridges</a></a></li><li><a href=#dual-path-region-guided-attention-network-for-ground-reaction-force-and-moment-regressionhttpsarxivorgabs251205030v1 aria-label="Dual-Path Region-Guided Attention Network for Ground Reaction Force and Moment Regression"><a href=https://arxiv.org/abs/2512.05030v1>Dual-Path Region-Guided Attention Network for Ground Reaction Force and Moment Regression</a></a></li><li><a href=#model-free-assessment-of-simulator-fidelity-via-quantile-curveshttpsarxivorgabs251205024v1 aria-label="Model-Free Assessment of Simulator Fidelity via Quantile Curves"><a href=https://arxiv.org/abs/2512.05024v1>Model-Free Assessment of Simulator Fidelity via Quantile Curves</a></a></li><li><a href=#self-supervised-learning-for-transparent-object-depth-completion-using-depth-from-non-transparent-objectshttpsarxivorgabs251205006v1 aria-label="Self-Supervised Learning for Transparent Object Depth Completion Using Depth from Non-Transparent Objects"><a href=https://arxiv.org/abs/2512.05006v1>Self-Supervised Learning for Transparent Object Depth Completion Using Depth from Non-Transparent Objects</a></a></li><li><a href=#towards-a-unified-framework-for-guided-diffusion-modelshttpsarxivorgabs251204985v1 aria-label="Towards a unified framework for guided diffusion models"><a href=https://arxiv.org/abs/2512.04985v1>Towards a unified framework for guided diffusion models</a></a></li><li><a href=#federated-learning-for-terahertz-wireless-communicationhttpsarxivorgabs251204984v1 aria-label="Federated Learning for Terahertz Wireless Communication"><a href=https://arxiv.org/abs/2512.04984v1>Federated Learning for Terahertz Wireless Communication</a></a></li><li><a href=#efficient-generative-transformer-operators-for-million-point-pdeshttpsarxivorgabs251204974v1 aria-label="Efficient Generative Transformer Operators For Million-Point PDEs"><a href=https://arxiv.org/abs/2512.04974v1>Efficient Generative Transformer Operators For Million-Point PDEs</a></a></li><li><a href=#stable-single-pixel-contrastive-learning-for-semantic-and-geometric-taskshttpsarxivorgabs251204970v1 aria-label="Stable Single-Pixel Contrastive Learning for Semantic and Geometric Tasks"><a href=https://arxiv.org/abs/2512.04970v1>Stable Single-Pixel Contrastive Learning for Semantic and Geometric Tasks</a></a></li><li><a href=#rethinking-the-use-of-vision-transformers-for-ai-generated-image-detectionhttpsarxivorgabs251204969v1 aria-label="Rethinking the Use of Vision Transformers for AI-Generated Image Detection"><a href=https://arxiv.org/abs/2512.04969v1>Rethinking the Use of Vision Transformers for AI-Generated Image Detection</a></a></li><li><a href=#balanced-few-shot-episodic-learning-for-accurate-retinal-disease-diagnosishttpsarxivorgabs251204967v1 aria-label="Balanced Few-Shot Episodic Learning for Accurate Retinal Disease Diagnosis"><a href=https://arxiv.org/abs/2512.04967v1>Balanced Few-Shot Episodic Learning for Accurate Retinal Disease Diagnosis</a></a></li><li><a href=#the-spectrum-of-n_s-constraints-from-desi-and-cmb-datahttpsarxivorgabs251205108v1 aria-label="The spectrum of $n_s$ constraints from DESI and CMB data"><a href=https://arxiv.org/abs/2512.05108v1>The spectrum of $n_s$ constraints from DESI and CMB data</a></a></li><li><a href=#highly-ionized-gas-in-lensed-z--6027-little-red-dot-seen-through-oiii-88%ce%bcm-with-almahttpsarxivorgabs251205097v1 aria-label="Highly-ionized gas in lensed z = 6.027 Little Red Dot seen through [OIII] 88$Œº$m with ALMA"><a href=https://arxiv.org/abs/2512.05097v1>Highly-ionized gas in lensed z = 6.027 Little Red Dot seen through [OIII] 88$Œº$m with ALMA</a></a></li><li><a href=#line-of-sight-shear-in-slacs-strong-lenses-ii-validation-tests-with-an-extended-samplehttpsarxivorgabs251205050v1 aria-label="Line-of-sight shear in SLACS strong lenses II: validation tests with an extended sample"><a href=https://arxiv.org/abs/2512.05050v1>Line-of-sight shear in SLACS strong lenses II: validation tests with an extended sample</a></a></li><li><a href=#the-critical-role-of-clumping-in-line-driven-disc-windshttpsarxivorgabs251205029v1 aria-label="The critical role of clumping in line-driven disc winds"><a href=https://arxiv.org/abs/2512.05029v1>The critical role of clumping in line-driven disc winds</a></a></li><li><a href=#convergence-of-sample-based-quantum-diagonalization-on-a-variable-length-cuprate-chainhttpsarxivorgabs251204962v1 aria-label="Convergence of sample-based quantum diagonalization on a variable-length cuprate chain"><a href=https://arxiv.org/abs/2512.04962v1>Convergence of sample-based quantum diagonalization on a variable-length cuprate chain</a></a></li><li><a href=#realizable-abstractions-near-optimal-hierarchical-reinforcement-learninghttpsarxivorgabs251204958v1 aria-label="Realizable Abstractions: Near-Optimal Hierarchical Reinforcement Learning"><a href=https://arxiv.org/abs/2512.04958v1>Realizable Abstractions: Near-Optimal Hierarchical Reinforcement Learning</a></a></li><li><a href=#mallorn-many-artificial-lsst-lightcurves-based-on-observations-of-real-nuclear-transientshttpsarxivorgabs251204946v1 aria-label="MALLORN: Many Artificial LSST Lightcurves based on Observations of Real Nuclear transients"><a href=https://arxiv.org/abs/2512.04946v1>MALLORN: Many Artificial LSST Lightcurves based on Observations of Real Nuclear transients</a></a></li><li><a href=#local-mixing-length-theory-with-compositional-effects-first-application-to-asymptotic-giant-branch-evolutionhttpsarxivorgabs251204900v1 aria-label="Local mixing length theory with compositional effects:\ First application to asymptotic giant branch evolution"><a href=https://arxiv.org/abs/2512.04900v1>Local mixing length theory with compositional effects:\ First application to asymptotic giant branch evolution</a></a></li><li><a href=#optimizations-and-extensions-for-fair-join-pattern-matchinghttpsarxivorgabs251204876v1 aria-label="Optimizations and extensions for fair join pattern matching"><a href=https://arxiv.org/abs/2512.04876v1>Optimizations and extensions for fair join pattern matching</a></a></li><li><a href=#sp-det-self-prompted-dual-text-fusion-for-generalized-multi-label-lesion-detectionhttpsarxivorgabs251204875v1 aria-label="SP-Det: Self-Prompted Dual-Text Fusion for Generalized Multi-Label Lesion Detection"><a href=https://arxiv.org/abs/2512.04875v1>SP-Det: Self-Prompted Dual-Text Fusion for Generalized Multi-Label Lesion Detection</a></a></li><li><a href=#enabling-ethical-ai-a-case-study-in-using-ontological-context-for-justified-agentic-ai-decisionshttpsarxivorgabs251204822v1 aria-label="Enabling Ethical AI: A case study in using Ontological Context for Justified Agentic AI Decisions"><a href=https://arxiv.org/abs/2512.04822v1>Enabling Ethical AI: A case study in using Ontological Context for Justified Agentic AI Decisions</a></a></li><li><a href=#robustsplat-decoupling-densification-dynamics-and-illumination-for-in-the-wild-3dgshttpsarxivorgabs251204815v1 aria-label="RobustSplat++: Decoupling Densification, Dynamics, and Illumination for In-the-Wild 3DGS"><a href=https://arxiv.org/abs/2512.04815v1>RobustSplat++: Decoupling Densification, Dynamics, and Illumination for In-the-Wild 3DGS</a></a></li><li><a href=#287872-supermassive-black-holes-masses-deep-learning-approaching-reverberation-mapping-accuracyhttpsarxivorgabs251204803v1 aria-label="287,872 Supermassive Black Holes Masses: Deep Learning Approaching Reverberation Mapping Accuracy"><a href=https://arxiv.org/abs/2512.04803v1>287,872 Supermassive Black Holes Masses: Deep Learning Approaching Reverberation Mapping Accuracy</a></a></li><li><a href=#teaching-a-transformer-to-think-like-a-chemist-predicting-nanocluster-stabilityhttpsarxivorgabs251204794v1 aria-label="Teaching a Transformer to Think Like a Chemist: Predicting Nanocluster Stability"><a href=https://arxiv.org/abs/2512.04794v1>Teaching a Transformer to Think Like a Chemist: Predicting Nanocluster Stability</a></a></li><li><a href=#spontaneous-symmetry-breaking-and-the-higgs-mechanismhttpsarxivorgabs251204741v1 aria-label="Spontaneous Symmetry Breaking and the Higgs Mechanism"><a href=https://arxiv.org/abs/2512.04741v1>Spontaneous Symmetry Breaking and the Higgs Mechanism</a></a></li><li><a href=#exact-and-mean-field-analysis-of-the-role-of-hubbard-interactions-on-flux-driven-circular-current-in-a-quantum-ringhttpsarxivorgabs251204736v1 aria-label="Exact and mean-field analysis of the role of Hubbard interactions on flux driven circular current in a quantum ring"><a href=https://arxiv.org/abs/2512.04736v1>Exact and mean-field analysis of the role of Hubbard interactions on flux driven circular current in a quantum ring</a></a></li><li><a href=#mt-depth-multi-task-instance-feature-analysis-for-the-depth-completionhttpsarxivorgabs251204734v1 aria-label="MT-Depth: Multi-task Instance feature analysis for the Depth Completion"><a href=https://arxiv.org/abs/2512.04734v1>MT-Depth: Multi-task Instance feature analysis for the Depth Completion</a></a></li><li><a href=#sequential-enumeration-in-large-language-modelshttpsarxivorgabs251204727v1 aria-label="Sequential Enumeration in Large Language Models"><a href=https://arxiv.org/abs/2512.04727v1>Sequential Enumeration in Large Language Models</a></a></li><li><a href=#playing-the-player-a-heuristic-framework-for-adaptive-poker-aihttpsarxivorgabs251204714v1 aria-label="Playing the Player: A Heuristic Framework for Adaptive Poker AI"><a href=https://arxiv.org/abs/2512.04714v1>Playing the Player: A Heuristic Framework for Adaptive Poker AI</a></a></li><li><a href=#llm-srclog-towards-proactive-and-unified-log-template-extraction-via-large-language-modelshttpsarxivorgabs251204474v1 aria-label="LLM-SrcLog: Towards Proactive and Unified Log Template Extraction via Large Language Models"><a href=https://arxiv.org/abs/2512.04474v1>LLM-SrcLog: Towards Proactive and Unified Log Template Extraction via Large Language Models</a></a></li><li><a href=#quantitative-analysis-of-technical-debt-and-pattern-violation-in-large-language-model-architectureshttpsarxivorgabs251204273v1 aria-label="Quantitative Analysis of Technical Debt and Pattern Violation in Large Language Model Architectures"><a href=https://arxiv.org/abs/2512.04273v1>Quantitative Analysis of Technical Debt and Pattern Violation in Large Language Model Architectures</a></a></li><li><a href=#generalized-event-partonomy-inference-with-structured-hierarchical-predictive-learninghttpsarxivorgabs251204219v1 aria-label="Generalized Event Partonomy Inference with Structured Hierarchical Predictive Learning"><a href=https://arxiv.org/abs/2512.04219v1>Generalized Event Partonomy Inference with Structured Hierarchical Predictive Learning</a></a></li><li><a href=#deeprule-an-integrated-framework-for-automated-business-rule-generation-via-deep-predictive-modeling-and-hybrid-search-optimizationhttpsarxivorgabs251203607v1 aria-label="DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization"><a href=https://arxiv.org/abs/2512.03607v1>DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization</a></a></li><li><a href=#identifying-attributions-of-causality-in-political-texthttpsarxivorgabs251203214v1 aria-label="Identifying attributions of causality in political text"><a href=https://arxiv.org/abs/2512.03214v1>Identifying attributions of causality in political text</a></a></li><li><a href=#enhancing-job-matching-occupation-skill-and-qualification-linking-with-the-esco-and-eqf-taxonomieshttpsarxivorgabs251203195v1 aria-label="Enhancing Job Matching: Occupation, Skill and Qualification Linking with the ESCO and EQF taxonomies"><a href=https://arxiv.org/abs/2512.03195v1>Enhancing Job Matching: Occupation, Skill and Qualification Linking with the ESCO and EQF taxonomies</a></a></li><li><a href=#hierarchical-process-reward-models-are-symbolic-vision-learnershttpsarxivorgabs251203126v1 aria-label="Hierarchical Process Reward Models are Symbolic Vision Learners"><a href=https://arxiv.org/abs/2512.03126v1>Hierarchical Process Reward Models are Symbolic Vision Learners</a></a></li><li><a href=#from-panel-to-pixel-zoom-in-vision-language-pretraining-from-biomedical-scientific-literaturehttpsarxivorgabs251202566v1 aria-label="From Panel to Pixel: Zoom-In Vision-Language Pretraining from Biomedical Scientific Literature"><a href=https://arxiv.org/abs/2512.02566v1>From Panel to Pixel: Zoom-In Vision-Language Pretraining from Biomedical Scientific Literature</a></a></li><li><a href=#leveraging-large-language-models-to-bridge-on-chain-and-off-chain-transparency-in-stablecoinshttpsarxivorgabs251202418v1 aria-label="Leveraging Large Language Models to Bridge On-chain and Off-chain Transparency in Stablecoins"><a href=https://arxiv.org/abs/2512.02418v1>Leveraging Large Language Models to Bridge On-chain and Off-chain Transparency in Stablecoins</a></a></li><li><a href=#taleframe-an-interactive-story-generation-system-with-fine-grained-control-and-large-language-modelshttpsarxivorgabs251202402v1 aria-label="TaleFrame: An Interactive Story Generation System with Fine-Grained Control and Large Language Models"><a href=https://arxiv.org/abs/2512.02402v1>TaleFrame: An Interactive Story Generation System with Fine-Grained Control and Large Language Models</a></a></li><li><a href=#a-knowledge-based-language-model-deducing-grammatical-knowledge-in-a-multi-agent-language-acquisition-simulationhttpsarxivorgabs251202195v1 aria-label="A Knowledge-Based Language Model: Deducing Grammatical Knowledge in a Multi-Agent Language Acquisition Simulation"><a href=https://arxiv.org/abs/2512.02195v1>A Knowledge-Based Language Model: Deducing Grammatical Knowledge in a Multi-Agent Language Acquisition Simulation</a></a></li><li><a href=#trivia-self-supervised-fine-tuning-of-vision-language-models-for-table-recognitionhttpsarxivorgabs251201248v1 aria-label="TRivia: Self-supervised Fine-tuning of Vision-Language Models for Table Recognition"><a href=https://arxiv.org/abs/2512.01248v1>TRivia: Self-supervised Fine-tuning of Vision-Language Models for Table Recognition</a></a></li><li><a href=#neural-variable-name-repair-learning-to-rename-identifiers-for-readabilityhttpsarxivorgabs251201141v1 aria-label="Neural Variable Name Repair: Learning to Rename Identifiers for Readability"><a href=https://arxiv.org/abs/2512.01141v1>Neural Variable Name Repair: Learning to Rename Identifiers for Readability</a></a></li><li><a href=#sceneprop-combining-neural-network-and-markov-random-field-for-scene-graph-groundinghttpsarxivorgabs251200936v1 aria-label="SceneProp: Combining Neural Network and Markov Random Field for Scene-Graph Grounding"><a href=https://arxiv.org/abs/2512.00936v1>SceneProp: Combining Neural Network and Markov Random Field for Scene-Graph Grounding</a></a></li><li><a href=#a-taxonomy-of-errors-in-english-as-she-is-spoke-toward-an-ai-based-method-of-error-analysis-for-efl-writing-instructionhttpsarxivorgabs251200392v1 aria-label="A Taxonomy of Errors in English as she is spoke: Toward an AI-Based Method of Error Analysis for EFL Writing Instruction"><a href=https://arxiv.org/abs/2512.00392v1>A Taxonomy of Errors in English as she is spoke: Toward an AI-Based Method of Error Analysis for EFL Writing Instruction</a></a></li><li><a href=#tree-matching-networks-for-natural-language-inference-parameter-efficient-semantic-understanding-via-dependency-parse-treeshttpsarxivorgabs251200204v1 aria-label="Tree Matching Networks for Natural Language Inference: Parameter-Efficient Semantic Understanding via Dependency Parse Trees"><a href=https://arxiv.org/abs/2512.00204v1>Tree Matching Networks for Natural Language Inference: Parameter-Efficient Semantic Understanding via Dependency Parse Trees</a></a></li><li><a href=#multimode-rf-reflectometry-for-spin-qubit-readout-and-device-characterizationhttpsarxivorgabs251205087v1 aria-label="Multimode RF Reflectometry for Spin Qubit Readout and Device Characterization"><a href=https://arxiv.org/abs/2512.05087v1>Multimode RF Reflectometry for Spin Qubit Readout and Device Characterization</a></a></li><li><a href=#first-observation-and-measurement-of-the-198texthg-bosonic-transition-in-an-optical-lattice-clockhttpsarxivorgabs251204920v1 aria-label="First observation and measurement of the ${}^{198}\text{Hg}$ bosonic transition in an optical lattice clock"><a href=https://arxiv.org/abs/2512.04920v1>First observation and measurement of the ${}^{198}\text{Hg}$ bosonic transition in an optical lattice clock</a></a></li><li><a href=#searching-for-new-physics-with-136xe-double-beta-decay-spectrum-in-pandax-4thttpsarxivorgabs251204849v1 aria-label="Searching for new physics with $^{136}$Xe double beta decay spectrum in PandaX-4T"><a href=https://arxiv.org/abs/2512.04849v1>Searching for new physics with $^{136}$Xe double beta decay spectrum in PandaX-4T</a></a></li><li><a href=#spaceflight-kid-readout-electronics-for-primahttpsarxivorgabs251204816v1 aria-label="Spaceflight KID Readout Electronics for PRIMA"><a href=https://arxiv.org/abs/2512.04816v1>Spaceflight KID Readout Electronics for PRIMA</a></a></li><li><a href=#inspiraling-binary-charged-black-holes-in-an-external-magnetic-field-application-of-post-newtonian-dynamics-in-einstein-maxwell-theoryhttpsarxivorgabs251204806v1 aria-label="Inspiraling binary charged black holes in an external magnetic field: Application of post-Newtonian dynamics in Einstein-Maxwell theory"><a href=https://arxiv.org/abs/2512.04806v1>Inspiraling binary charged black holes in an external magnetic field: Application of post-Newtonian dynamics in Einstein-Maxwell theory</a></a></li><li><a href=#on-the-magnetic-field-evolution-of-interplanetary-coronal-mass-ejections-from-007-to-54-auhttpsarxivorgabs251204730v1 aria-label="On the magnetic field evolution of interplanetary coronal mass ejections from 0.07 to 5.4 au"><a href=https://arxiv.org/abs/2512.04730v1>On the magnetic field evolution of interplanetary coronal mass ejections from 0.07 to 5.4 au</a></a></li><li><a href=#cross-task-benchmarking-and-evaluation-of-general-purpose-and-code-specific-large-language-modelshttpsarxivorgabs251204673v1 aria-label="Cross-Task Benchmarking and Evaluation of General-Purpose and Code-Specific Large Language Models"><a href=https://arxiv.org/abs/2512.04673v1>Cross-Task Benchmarking and Evaluation of General-Purpose and Code-Specific Large Language Models</a></a></li><li><a href=#characterizing-the-low-mass-pre-main-sequence-population-in-the-low-metallicity-star-forming-region-dolidze-25-using-vlt-musehttpsarxivorgabs251204645v1 aria-label="Characterizing the Low-Mass Pre-Main-Sequence Population in the Low-Metallicity Star-Forming Region Dolidze 25 Using VLT-MUSE"><a href=https://arxiv.org/abs/2512.04645v1>Characterizing the Low-Mass Pre-Main-Sequence Population in the Low-Metallicity Star-Forming Region Dolidze 25 Using VLT-MUSE</a></a></li><li><a href=#probing-false-vacuum-decay-and-bubble-nucleation-in-a-rydberg-atom-arrayhttpsarxivorgabs251204637v1 aria-label="Probing false vacuum decay and bubble nucleation in a Rydberg atom array"><a href=https://arxiv.org/abs/2512.04637v1>Probing false vacuum decay and bubble nucleation in a Rydberg atom array</a></a></li><li><a href=#ground-state-energy-and-phase-transitions-of-long-range-xxz-using-vqehttpsarxivorgabs251204615v1 aria-label="Ground state energy and phase transitions of Long-range XXZ using VQE"><a href=https://arxiv.org/abs/2512.04615v1>Ground state energy and phase transitions of Long-range XXZ using VQE</a></a></li><li><a href=#probing-hard-scattering-processes-via-multiple-weak-gauge-boson-production-at-the-future-collidershttpsarxivorgabs251204553v1 aria-label="Probing Hard Scattering Processes via Multiple Weak Gauge Boson Production at the Future Colliders"><a href=https://arxiv.org/abs/2512.04553v1>Probing Hard Scattering Processes via Multiple Weak Gauge Boson Production at the Future Colliders</a></a></li><li><a href=#a-morpho-kinematic-study-of-galactic-high-adf-pne-based-on-the-vltuves-deep-spectroscopyhttpsarxivorgabs251204533v1 aria-label="A Morpho-kinematic Study of Galactic High-ADF PNe Based on the VLT/UVES Deep Spectroscopy"><a href=https://arxiv.org/abs/2512.04533v1>A Morpho-kinematic Study of Galactic High-ADF PNe Based on the VLT/UVES Deep Spectroscopy</a></a></li><li><a href=#sub-cycle-pulse-control-of-holographic-and-non-holographic-electron-interferenceshttpsarxivorgabs251204503v1 aria-label="Sub-cycle pulse control of holographic and non-holographic electron interferences"><a href=https://arxiv.org/abs/2512.04503v1>Sub-cycle pulse control of holographic and non-holographic electron interferences</a></a></li><li><a href=#predicting-time-dependent-flow-over-complex-geometries-using-operator-networkshttpsarxivorgabs251204434v1 aria-label="Predicting Time-Dependent Flow Over Complex Geometries Using Operator Networks"><a href=https://arxiv.org/abs/2512.04434v1>Predicting Time-Dependent Flow Over Complex Geometries Using Operator Networks</a></a></li><li><a href=#explainable-parkinsons-disease-gait-recognition-using-multimodal-rgb-d-fusion-and-large-language-modelshttpsarxivorgabs251204425v1 aria-label="Explainable Parkinsons Disease Gait Recognition Using Multimodal RGB-D Fusion and Large Language Models"><a href=https://arxiv.org/abs/2512.04425v1>Explainable Parkinsons Disease Gait Recognition Using Multimodal RGB-D Fusion and Large Language Models</a></a></li><li><a href=#an-analysis-of-a-coronal-mass-ejection-leading-edge-by-means-of-multi-spacecraft-in-beam-phase-scintillationhttpsarxivorgabs251204337v1 aria-label="An Analysis of a Coronal Mass Ejection Leading Edge by Means of Multi-Spacecraft-in-Beam Phase Scintillation"><a href=https://arxiv.org/abs/2512.04337v1>An Analysis of a Coronal Mass Ejection Leading Edge by Means of Multi-Spacecraft-in-Beam Phase Scintillation</a></a></li><li><a href=#lhc-shines-on-positivityhttpsarxivorgabs251204336v1 aria-label="LHC Shines on Positivity"><a href=https://arxiv.org/abs/2512.04336v1>LHC Shines on Positivity</a></a></li><li><a href=#exploring-the-qcd-phase-diagram-through-correlations-and-fluctuationshttpsarxivorgabs251204288v1 aria-label="Exploring the QCD phase diagram through correlations and fluctuations"><a href=https://arxiv.org/abs/2512.04288v1>Exploring the QCD phase diagram through correlations and fluctuations</a></a></li><li><a href=#gravitational-waves-from-isocurvature-perturbations-of-spectator-scalar-fieldshttpsarxivorgabs251204240v1 aria-label="Gravitational Waves from Isocurvature Perturbations of Spectator Scalar Fields"><a href=https://arxiv.org/abs/2512.04240v1>Gravitational Waves from Isocurvature Perturbations of Spectator Scalar Fields</a></a></li><li><a href=#detecting-light-axions-from-supernovae-in-nearby-galaxieshttpsarxivorgabs251204185v1 aria-label="Detecting light axions from supernovae in nearby galaxies"><a href=https://arxiv.org/abs/2512.04185v1>Detecting light axions from supernovae in nearby galaxies</a></a></li><li><a href=#electroweak-phase-transition-in-smeft-gravitational-wave-and-collider-complementarityhttpsarxivorgabs251204168v1 aria-label="Electroweak phase transition in SMEFT: Gravitational wave and collider complementarity"><a href=https://arxiv.org/abs/2512.04168v1>Electroweak phase transition in SMEFT: Gravitational wave and collider complementarity</a></a></li><li><a href=#a-new-connection-between-wimp-dark-matter-and-the-hierarchy-problemhttpsarxivorgabs251204158v1 aria-label="A new connection between WIMP dark matter and the hierarchy problem"><a href=https://arxiv.org/abs/2512.04158v1>A new connection between WIMP dark matter and the hierarchy problem</a></a></li><li><a href=#effective-delta-sources-and-newtonian-limit-in-nonlocal-gravityhttpsarxivorgabs251205061v1 aria-label="Effective delta sources and Newtonian limit in nonlocal gravity"><a href=https://arxiv.org/abs/2512.05061v1>Effective delta sources and Newtonian limit in nonlocal gravity</a></a></li><li><a href=#on-six-loop-scaling-dimensions-of-%cf%862n-operators-in-d3httpsarxivorgabs251205059v1 aria-label="On six-loop scaling dimensions of $(œÜ^2)^n$ operators in $d=3$"><a href=https://arxiv.org/abs/2512.05059v1>On six-loop scaling dimensions of $(œÜ^2)^n$ operators in $d=3$</a></a></li><li><a href=#the-position-and-resolvability-of-blended-point-sourceshttpsarxivorgabs251205047v1 aria-label="The position and resolvability of blended point sources"><a href=https://arxiv.org/abs/2512.05047v1>The position and resolvability of blended point sources</a></a></li><li><a href=#dust-destruction-by-the-supernova-remnant-forward-shock-in-a-turbulent-interstellar-mediumhttpsarxivorgabs251205046v1 aria-label="Dust destruction by the supernova remnant forward shock in a turbulent interstellar medium"><a href=https://arxiv.org/abs/2512.05046v1>Dust destruction by the supernova remnant forward shock in a turbulent interstellar medium</a></a></li><li><a href=#analytic-dependence-of-the-lyapunov-moment-function-and-the-projective-stationary-measure-for-random-matrix-productshttpsarxivorgabs251205034v1 aria-label="Analytic Dependence of the Lyapunov Moment Function and the Projective Stationary Measure for Random Matrix Products"><a href=https://arxiv.org/abs/2512.05034v1>Analytic Dependence of the Lyapunov Moment Function and the Projective Stationary Measure for Random Matrix Products</a></a></li><li><a href=#frequency-and-intensity-noise-of-a-grating-tuned-external-cavity-quantum-cascade-laserhttpsarxivorgabs251205002v1 aria-label="Frequency and intensity noise of a grating-tuned external-cavity quantum cascade laser"><a href=https://arxiv.org/abs/2512.05002v1>Frequency and intensity noise of a grating-tuned external-cavity quantum cascade laser</a></a></li><li><a href=#partial-section-i-%ce%b1-recurrence-and-equivariant-lyapunov-mapshttpsarxivorgabs251204994v1 aria-label="Partial section I: $Œ±$-recurrence and equivariant Lyapunov maps"><a href=https://arxiv.org/abs/2512.04994v1>Partial section I: $Œ±$-recurrence and equivariant Lyapunov maps</a></a></li><li><a href=#introduction-to-quantum-control-from-basic-concepts-to-applications-in-quantum-technologieshttpsarxivorgabs251204990v1 aria-label="Introduction to quantum control: From basic concepts to applications in quantum technologies"><a href=https://arxiv.org/abs/2512.04990v1>Introduction to quantum control: From basic concepts to applications in quantum technologies</a></a></li><li><a href=#thermodynamics-vs-teleodynamics-a-cosmological-dividehttpsarxivorgabs251204977v1 aria-label="Thermodynamics vs Teleodynamics: A Cosmological Divide?"><a href=https://arxiv.org/abs/2512.04977v1>Thermodynamics vs Teleodynamics: A Cosmological Divide?</a></a></li><li><a href=#characterization-of-thin-optical-filters-for-high-purity-cherenkov-light-readout-from-scintillating-crystalshttpsarxivorgabs251204965v1 aria-label="Characterization of thin optical filters for high purity Cherenkov light readout from scintillating crystals"><a href=https://arxiv.org/abs/2512.04965v1>Characterization of thin optical filters for high purity Cherenkov light readout from scintillating crystals</a></a></li><li><a href=#triplec-learning-and-lightweight-speech-enhancement-for-multi-condition-target-speech-extractionhttpsarxivorgabs251204945v1 aria-label="TripleC Learning and Lightweight Speech Enhancement for Multi-Condition Target Speech Extraction"><a href=https://arxiv.org/abs/2512.04945v1>TripleC Learning and Lightweight Speech Enhancement for Multi-Condition Target Speech Extraction</a></a></li><li><a href=#multi-agent-reinforcement-learning-for-intraday-operating-rooms-scheduling-under-uncertaintyhttpsarxivorgabs251204918v1 aria-label="Multi-Agent Reinforcement Learning for Intraday Operating Rooms Scheduling under Uncertainty"><a href=https://arxiv.org/abs/2512.04918v1>Multi-Agent Reinforcement Learning for Intraday Operating Rooms Scheduling under Uncertainty</a></a></li><li><a href=#communicating-properties-of-quantum-states-over-classical-noisy-channelshttpsarxivorgabs251204913v1 aria-label="Communicating Properties of Quantum States over Classical Noisy Channels"><a href=https://arxiv.org/abs/2512.04913v1>Communicating Properties of Quantum States over Classical Noisy Channels</a></a></li><li><a href=#long-term-mid-infrared-color-variations-of-narrow-line-seyfert-1-galaxieshttpsarxivorgabs251204906v1 aria-label="Long-term Mid-infrared Color Variations of Narrow-Line Seyfert 1 Galaxies"><a href=https://arxiv.org/abs/2512.04906v1>Long-term Mid-infrared Color Variations of Narrow-Line Seyfert 1 Galaxies</a></a></li><li><a href=#adaptive-optics-enhanced-michelson-interferometer-for-spectroscopy-of-narrow-band-light-sourceshttpsarxivorgabs251204901v1 aria-label="Adaptive Optics-Enhanced Michelson Interferometer for Spectroscopy of Narrow-Band Light Sources"><a href=https://arxiv.org/abs/2512.04901v1>Adaptive Optics-Enhanced Michelson Interferometer for Spectroscopy of Narrow-Band Light Sources</a></a></li><li><a href=#bayesian-stepwise-estimation-of-qubit-rotationshttpsarxivorgabs251204898v1 aria-label="Bayesian stepwise estimation of qubit rotations"><a href=https://arxiv.org/abs/2512.04898v1>Bayesian stepwise estimation of qubit rotations</a></a></li><li><a href=#the-malatang-survey-star-formation-dense-gas-and-agn-feedback-in-ngc-1068httpsarxivorgabs251204891v1 aria-label="The MALATANG survey: star formation, dense gas, and AGN feedback in NGC 1068"><a href=https://arxiv.org/abs/2512.04891v1>The MALATANG survey: star formation, dense gas, and AGN feedback in NGC 1068</a></a></li><li><a href=#developing-a-general-personal-tutor-for-educationhttpsarxivorgabs251204869v1 aria-label="Developing a General Personal Tutor for Education"><a href=https://arxiv.org/abs/2512.04869v1>Developing a General Personal Tutor for Education</a></a></li><li><a href=#degrees-of-universality-in-wave-turbulencehttpsarxivorgabs251204866v1 aria-label="Degrees of universality in wave turbulence"><a href=https://arxiv.org/abs/2512.04866v1>Degrees of universality in wave turbulence</a></a></li><li><a href=#concentration-bounds-for-intrinsic-dimension-estimation-using-gaussian-kernelshttpsarxivorgabs251204861v1 aria-label="Concentration bounds for intrinsic dimension estimation using Gaussian kernels"><a href=https://arxiv.org/abs/2512.04861v1>Concentration bounds for intrinsic dimension estimation using Gaussian kernels</a></a></li><li><a href=#autoregressive-image-generation-needs-only-a-few-lines-of-cached-tokenshttpsarxivorgabs251204857v1 aria-label="Autoregressive Image Generation Needs Only a Few Lines of Cached Tokens"><a href=https://arxiv.org/abs/2512.04857v1>Autoregressive Image Generation Needs Only a Few Lines of Cached Tokens</a></a></li><li><a href=#safe-model-based-reinforcement-learning-via-model-predictive-control-and-control-barrier-functionshttpsarxivorgabs251204856v1 aria-label="Safe model-based Reinforcement Learning via Model Predictive Control and Control Barrier Functions"><a href=https://arxiv.org/abs/2512.04856v1>Safe model-based Reinforcement Learning via Model Predictive Control and Control Barrier Functions</a></a></li><li><a href=#the-stagnant-persistence-paradox-survival-analysis-and-temporal-efficiency-in-exact-sciences-and-engineering-educationhttpsarxivorgabs251204828v1 aria-label="The Stagnant Persistence Paradox: Survival Analysis and Temporal Efficiency in Exact Sciences and Engineering Education"><a href=https://arxiv.org/abs/2512.04828v1>The Stagnant Persistence Paradox: Survival Analysis and Temporal Efficiency in Exact Sciences and Engineering Education</a></a></li><li><a href=#statistical-insight-into-the-correlation-of-geometry-and-spectral-emission-in-network-lasershttpsarxivorgabs251204811v1 aria-label="Statistical Insight into the Correlation of Geometry and Spectral Emission in Network Lasers"><a href=https://arxiv.org/abs/2512.04811v1>Statistical Insight into the Correlation of Geometry and Spectral Emission in Network Lasers</a></a></li><li><a href=#existence-and-uniqueness-of-the-canonical-brownian-motion-in-non-simple-conformal-loop-ensemble-gasketshttpsarxivorgabs251204807v1 aria-label="Existence and uniqueness of the canonical Brownian motion in non-simple conformal loop ensemble gaskets"><a href=https://arxiv.org/abs/2512.04807v1>Existence and uniqueness of the canonical Brownian motion in non-simple conformal loop ensemble gaskets</a></a></li><li><a href=#yingmusic-svc-real-world-robust-zero-shot-singing-voice-conversion-with-flow-grpo-and-singing-specific-inductive-biaseshttpsarxivorgabs251204793v1 aria-label="YingMusic-SVC: Real-World Robust Zero-Shot Singing Voice Conversion with Flow-GRPO and Singing-Specific Inductive Biases"><a href=https://arxiv.org/abs/2512.04793v1>YingMusic-SVC: Real-World Robust Zero-Shot Singing Voice Conversion with Flow-GRPO and Singing-Specific Inductive Biases</a></a></li><li><a href=#tensorial-permanence-of-k-stability-for-diagonal-ah-algebrashttpsarxivorgabs251204780v1 aria-label="Tensorial Permanence of $K$-Stability for Diagonal AH-Algebras"><a href=https://arxiv.org/abs/2512.04780v1>Tensorial Permanence of $K$-Stability for Diagonal AH-Algebras</a></a></li><li><a href=#superconductivity-onset-above-60-k-in-ambient-pressure-nickelate-filmshttpsarxivorgabs251204708v1 aria-label="Superconductivity onset above 60 K in ambient-pressure nickelate films"><a href=https://arxiv.org/abs/2512.04708v1>Superconductivity onset above 60 K in ambient-pressure nickelate films</a></a></li><li><a href=#targeted-testing-of-compiler-optimizations-via-grammar-level-composition-styleshttpsarxivorgabs251204344v1 aria-label="Targeted Testing of Compiler Optimizations via Grammar-Level Composition Styles"><a href=https://arxiv.org/abs/2512.04344v1>Targeted Testing of Compiler Optimizations via Grammar-Level Composition Styles</a></a></li><li><a href=#network-of-theseus-like-the-shiphttpsarxivorgabs251204198v1 aria-label="Network of Theseus (like the ship)"><a href=https://arxiv.org/abs/2512.04198v1>Network of Theseus (like the ship)</a></a></li><li><a href=#skillfactory-self-distillation-for-learning-cognitive-behaviorshttpsarxivorgabs251204072v1 aria-label="SkillFactory: Self-Distillation For Learning Cognitive Behaviors"><a href=https://arxiv.org/abs/2512.04072v1>SkillFactory: Self-Distillation For Learning Cognitive Behaviors</a></a></li><li><a href=#the-loss-landscape-of-powder-x-ray-diffraction-based-structure-optimization-is-too-rough-for-gradient-descenthttpsarxivorgabs251204036v1 aria-label="The Loss Landscape of Powder X-Ray Diffraction-Based Structure Optimization Is Too Rough for Gradient Descent"><a href=https://arxiv.org/abs/2512.04036v1>The Loss Landscape of Powder X-Ray Diffraction-Based Structure Optimization Is Too Rough for Gradient Descent</a></a></li><li><a href=#from-flops-to-footprints-the-resource-cost-of-artificial-intelligencehttpsarxivorgabs251204142v1 aria-label="From FLOPs to Footprints: The Resource Cost of Artificial Intelligence"><a href=https://arxiv.org/abs/2512.04142v1>From FLOPs to Footprints: The Resource Cost of Artificial Intelligence</a></a></li><li><a href=#a-polyharmonic-liouville-hierarchy-on-complete-manifolds-of-nonnegative-ricci-curvaturehttpsarxivorgabs251204141v1 aria-label="A Polyharmonic Liouville Hierarchy on Complete Manifolds of Nonnegative Ricci Curvature"><a href=https://arxiv.org/abs/2512.04141v1>A Polyharmonic Liouville Hierarchy on Complete Manifolds of Nonnegative Ricci Curvature</a></a></li><li><a href=#bi-isolated-dce-degrees-and-%cf%83_1-inductionhttpsarxivorgabs251203778v2 aria-label="Bi-Isolated d.c.e. Degrees and $Œ£_1$ Induction"><a href=https://arxiv.org/abs/2512.03778v2>Bi-Isolated d.c.e. Degrees and $Œ£_1$ Induction</a></a></li><li><a href=#universally-converging-representations-of-matter-across-scientific-foundation-modelshttpsarxivorgabs251203750v1 aria-label="Universally Converging Representations of Matter Across Scientific Foundation Models"><a href=https://arxiv.org/abs/2512.03750v1>Universally Converging Representations of Matter Across Scientific Foundation Models</a></a></li><li><a href=#multi-scale-visual-prompting-for-lightweight-small-image-classificationhttpsarxivorgabs251203663v1 aria-label="Multi-Scale Visual Prompting for Lightweight Small-Image Classification"><a href=https://arxiv.org/abs/2512.03663v1>Multi-Scale Visual Prompting for Lightweight Small-Image Classification</a></a></li><li><a href=#nas-lora-empowering-parameter-efficient-fine-tuning-for-visual-foundation-models-with-searchable-adaptationhttpsarxivorgabs251203499v1 aria-label="NAS-LoRA: Empowering Parameter-Efficient Fine-Tuning for Visual Foundation Models with Searchable Adaptation"><a href=https://arxiv.org/abs/2512.03499v1>NAS-LoRA: Empowering Parameter-Efficient Fine-Tuning for Visual Foundation Models with Searchable Adaptation</a></a></li><li><a href=#modal-logical-neural-networkshttpsarxivorgabs251203491v1 aria-label="Modal Logical Neural Networks"><a href=https://arxiv.org/abs/2512.03491v1>Modal Logical Neural Networks</a></a></li><li><a href=#hybridized-mode-parametric-amplifier-in-kinetic-inductance-circuitshttpsarxivorgabs251203362v1 aria-label="Hybridized-Mode Parametric Amplifier in Kinetic-Inductance Circuits"><a href=https://arxiv.org/abs/2512.03362v1>Hybridized-Mode Parametric Amplifier in Kinetic-Inductance Circuits</a></a></li><li><a href=#hierarchical-attention-for-sparse-volumetric-anomaly-detection-in-subclinical-keratoconushttpsarxivorgabs251203346v1 aria-label="Hierarchical Attention for Sparse Volumetric Anomaly Detection in Subclinical Keratoconus"><a href=https://arxiv.org/abs/2512.03346v1>Hierarchical Attention for Sparse Volumetric Anomaly Detection in Subclinical Keratoconus</a></a></li><li><a href=#the-seifert-van-kampen-theorem-via-computational-paths-a-formalized-approach-to-computing-fundamental-groupshttpsarxivorgabs251203175v1 aria-label="The Seifert-van Kampen Theorem via Computational Paths: A Formalized Approach to Computing Fundamental Groups"><a href=https://arxiv.org/abs/2512.03175v1>The Seifert-van Kampen Theorem via Computational Paths: A Formalized Approach to Computing Fundamental Groups</a></a></li><li><a href=#fluxlab-creating-3d-printable-shape-changing-devices-with-integrated-deformation-sensinghttpsarxivorgabs251202911v1 aria-label="FluxLab: Creating 3D Printable Shape-Changing Devices with Integrated Deformation Sensing"><a href=https://arxiv.org/abs/2512.02911v1>FluxLab: Creating 3D Printable Shape-Changing Devices with Integrated Deformation Sensing</a></a></li><li><a href=#vessel-network-topology-in-molecular-communication-insights-from-experiments-and-theoryhttpsarxivorgabs251202811v1 aria-label="Vessel Network Topology in Molecular Communication: Insights from Experiments and Theory"><a href=https://arxiv.org/abs/2512.02811v1>Vessel Network Topology in Molecular Communication: Insights from Experiments and Theory</a></a></li><li><a href=#df-mamba-deformable-state-space-modeling-for-3d-hand-pose-estimation-in-interactionshttpsarxivorgabs251202727v1 aria-label="DF-Mamba: Deformable State Space Modeling for 3D Hand Pose Estimation in Interactions"><a href=https://arxiv.org/abs/2512.02727v1>DF-Mamba: Deformable State Space Modeling for 3D Hand Pose Estimation in Interactions</a></a></li><li><a href=#popsim-social-network-simulation-for-social-media-popularity-predictionhttpsarxivorgabs251202533v1 aria-label="PopSim: Social Network Simulation for Social Media Popularity Prediction"><a href=https://arxiv.org/abs/2512.02533v1>PopSim: Social Network Simulation for Social Media Popularity Prediction</a></a></li><li><a href=#inductive-limits-of-partial-crossed-productshttpsarxivorgabs251202525v1 aria-label="Inductive limits of partial crossed products"><a href=https://arxiv.org/abs/2512.02525v1>Inductive limits of partial crossed products</a></a></li><li><a href=#representations-of-finite-matrix-monoidshttpsarxivorgabs251202226v1 aria-label="Representations of finite matrix monoids"><a href=https://arxiv.org/abs/2512.02226v1>Representations of finite matrix monoids</a></a></li><li><a href=#multifractal-recalibration-of-neural-networks-for-medical-imaging-segmentationhttpsarxivorgabs251202198v1 aria-label="Multifractal Recalibration of Neural Networks for Medical Imaging Segmentation"><a href=https://arxiv.org/abs/2512.02198v1>Multifractal Recalibration of Neural Networks for Medical Imaging Segmentation</a></a></li><li><a href=#dynamo-and-jet-interconnections-in-grmhd-simulations-of-black-hole-accretion-diskshttpsarxivorgabs251202129v1 aria-label="Dynamo and Jet interconnections in GRMHD simulations of black hole accretion disks"><a href=https://arxiv.org/abs/2512.02129v1>Dynamo and Jet interconnections in GRMHD simulations of black hole accretion disks</a></a></li><li><a href=#bounded-treewidth-multiple-context-free-grammars-and-downward-closureshttpsarxivorgabs251201973v2 aria-label="Bounded treewidth, multiple context-free grammars, and downward closures"><a href=https://arxiv.org/abs/2512.01973v2>Bounded treewidth, multiple context-free grammars, and downward closures</a></a></li><li><a href=#exploring-human-perceptions-of-ai-responses-insights-from-a-mixed-methods-study-on-risk-mitigation-in-generative-modelshttpsarxivorgabs251201892v1 aria-label="Exploring Human Perceptions of AI Responses: Insights from a Mixed-Methods Study on Risk Mitigation in Generative Models"><a href=https://arxiv.org/abs/2512.01892v1>Exploring Human Perceptions of AI Responses: Insights from a Mixed-Methods Study on Risk Mitigation in Generative Models</a></a></li><li><a href=#tahr-the-generative-attribute-grammar-frameworkhttpsarxivorgabs251201872v1 aria-label="Tahr: The Generative Attribute Grammar Framework"><a href=https://arxiv.org/abs/2512.01872v1>Tahr: The Generative Attribute Grammar Framework</a></a></li><li><a href=#testing-transformer-learnability-on-the-arithmetic-sequence-of-rooted-treeshttpsarxivorgabs251201870v1 aria-label="Testing Transformer Learnability on the Arithmetic Sequence of Rooted Trees"><a href=https://arxiv.org/abs/2512.01870v1>Testing Transformer Learnability on the Arithmetic Sequence of Rooted Trees</a></a></li><li><a href=#vanishing-h1-for-hurwitz-spaces-of-fully-marked-admissible-covers-of-degree-3httpsarxivorgabs251201553v1 aria-label="Vanishing $H^1$ for Hurwitz spaces of fully-marked admissible covers of degree 3"><a href=https://arxiv.org/abs/2512.01553v1>Vanishing $H^1$ for Hurwitz spaces of fully-marked admissible covers of degree 3</a></a></li><li><a href=#masked-symbol-modeling-for-demodulation-of-oversampled-baseband-communication-signals-in-impulsive-noise-dominated-channelshttpsarxivorgabs251201428v1 aria-label="Masked Symbol Modeling for Demodulation of Oversampled Baseband Communication Signals in Impulsive Noise-Dominated Channels"><a href=https://arxiv.org/abs/2512.01428v1>Masked Symbol Modeling for Demodulation of Oversampled Baseband Communication Signals in Impulsive Noise-Dominated Channels</a></a></li><li><a href=#inductive-van-der-waals-force-between-two-quantum-loopshttpsarxivorgabs251201263v1 aria-label="Inductive van der Waals Force between Two Quantum Loops"><a href=https://arxiv.org/abs/2512.01263v1>Inductive van der Waals Force between Two Quantum Loops</a></a></li><li><a href=#parameter-reduction-improves-vision-transformers-a-comparative-study-of-sharing-and-width-reductionhttpsarxivorgabs251201059v1 aria-label="Parameter Reduction Improves Vision Transformers: A Comparative Study of Sharing and Width Reduction"><a href=https://arxiv.org/abs/2512.01059v1>Parameter Reduction Improves Vision Transformers: A Comparative Study of Sharing and Width Reduction</a></a></li><li><a href=#a-word-sampler-for-well-typed-functionshttpsarxivorgabs251201036v1 aria-label="A Word Sampler for Well-Typed Functions"><a href=https://arxiv.org/abs/2512.01036v1>A Word Sampler for Well-Typed Functions</a></a></li><li><a href=#triangular-arrays-using-context-free-grammarhttpsarxivorgabs251201005v1 aria-label="Triangular Arrays using context-free grammar"><a href=https://arxiv.org/abs/2512.01005v1>Triangular Arrays using context-free grammar</a></a></li><li><a href=#games-with-infinite-pasthttpsarxivorgabs251201001v1 aria-label="Games with infinite past"><a href=https://arxiv.org/abs/2512.01001v1>Games with infinite past</a></a></li><li><a href=#lahnet-local-attentive-hashing-network-for-point-cloud-registrationhttpsarxivorgabs251200927v1 aria-label="LAHNet: Local Attentive Hashing Network for Point Cloud Registration"><a href=https://arxiv.org/abs/2512.00927v1>LAHNet: Local Attentive Hashing Network for Point Cloud Registration</a></a></li><li><a href=#partially-equivariant-reinforcement-learning-in-symmetry-breaking-environmentshttpsarxivorgabs251200915v1 aria-label="Partially Equivariant Reinforcement Learning in Symmetry-Breaking Environments"><a href=https://arxiv.org/abs/2512.00915v1>Partially Equivariant Reinforcement Learning in Symmetry-Breaking Environments</a></a></li><li><a href=#higher-derivative-estimates-for-stokes-equations-with-closely-spaced-rigid-inclusions-in-three-dimensionshttpsarxivorgabs251200866v1 aria-label="Higher derivative estimates for Stokes equations with closely spaced rigid inclusions in three dimensions"><a href=https://arxiv.org/abs/2512.00866v1>Higher derivative estimates for Stokes equations with closely spaced rigid inclusions in three dimensions</a></a></li><li><a href=#charts-are-not-images-on-the-challenges-of-scientific-chart-editinghttpsarxivorgabs251200752v1 aria-label="Charts Are Not Images: On the Challenges of Scientific Chart Editing"><a href=https://arxiv.org/abs/2512.00752v1>Charts Are Not Images: On the Challenges of Scientific Chart Editing</a></a></li><li><a href=#ms-ppo-morphological-symmetry-equivariant-policy-for-legged-robot-locomotionhttpsarxivorgabs251200727v1 aria-label="MS-PPO: Morphological-Symmetry-Equivariant Policy for Legged Robot Locomotion"><a href=https://arxiv.org/abs/2512.00727v1>MS-PPO: Morphological-Symmetry-Equivariant Policy for Legged Robot Locomotion</a></a></li><li><a href=#extended-abstract-synthesizable-low-overhead-circuit-level-countermeasures-and-pro-active-detection-techniques-for-power-and-em-scahttpsarxivorgabs251200635v1 aria-label="Extended Abstract: Synthesizable Low-overhead Circuit-level Countermeasures and Pro-Active Detection Techniques for Power and EM SCA"><a href=https://arxiv.org/abs/2512.00635v1>Extended Abstract: Synthesizable Low-overhead Circuit-level Countermeasures and Pro-Active Detection Techniques for Power and EM SCA</a></a></li><li><a href=#prism-a-minimal-compositional-metalanguage-for-specifying-agent-behaviorhttpsarxivorgabs251200611v1 aria-label="Prism: A Minimal Compositional Metalanguage for Specifying Agent Behavior"><a href=https://arxiv.org/abs/2512.00611v1>Prism: A Minimal Compositional Metalanguage for Specifying Agent Behavior</a></a></li></ul></li><li><a href=#-psycholinguistics aria-label="üîç psycholinguistics">üîç psycholinguistics</a><ul><li><a href=#high-fidelity-qubit-control-in-a-natural-si-mos-quantum-dot-using-a-300-mm-silicon-on-insulator-waferhttpsarxivorgabs251205052v1 aria-label="High Fidelity Qubit Control in a Natural Si-MOS Quantum Dot using a 300 mm Silicon on Insulator Wafer"><a href=https://arxiv.org/abs/2512.05052v1>High Fidelity Qubit Control in a Natural Si-MOS Quantum Dot using a 300 mm Silicon on Insulator Wafer</a></a></li><li><a href=#expanding-the-neutral-atom-gate-set-native-iswap-and-exchange-gates-from-dipolar-rydberg-interactionshttpsarxivorgabs251205037v1 aria-label="Expanding the Neutral Atom Gate Set: Native iSWAP and Exchange Gates from Dipolar Rydberg Interactions"><a href=https://arxiv.org/abs/2512.05037v1>Expanding the Neutral Atom Gate Set: Native iSWAP and Exchange Gates from Dipolar Rydberg Interactions</a></a></li><li><a href=#engineered-inclined-energy-landscapes-enabling-free-flow-of-magnetic-microstructures-for-artificial-neuron-applicationshttpsarxivorgabs251205020v1 aria-label="Engineered Inclined Energy Landscapes Enabling Free Flow of Magnetic Microstructures for Artificial Neuron Applications"><a href=https://arxiv.org/abs/2512.05020v1>Engineered Inclined Energy Landscapes Enabling Free Flow of Magnetic Microstructures for Artificial Neuron Applications</a></a></li><li><a href=#risk-aversion-of-insider-and-dynamic-asymmetric-informationhttpsarxivorgabs251205011v1 aria-label="Risk aversion of insider and dynamic asymmetric information"><a href=https://arxiv.org/abs/2512.05011v1>Risk aversion of insider and dynamic asymmetric information</a></a></li><li><a href=#a-dynamic-memory-assignment-strategy-for-dilation-based-icp-algorithm-on-embedded-gpushttpsarxivorgabs251204996v1 aria-label="A dynamic memory assignment strategy for dilation-based ICP algorithm on embedded GPUs"><a href=https://arxiv.org/abs/2512.04996v1>A dynamic memory assignment strategy for dilation-based ICP algorithm on embedded GPUs</a></a></li><li><a href=#parametric-disjunctive-timed-networkshttpsarxivorgabs251204991v1 aria-label="Parametric disjunctive timed networks"><a href=https://arxiv.org/abs/2512.04991v1>Parametric disjunctive timed networks</a></a></li><li><a href=#towards-a-fully-automated-differential-textnnlo_textew-generator-for-lepton-collidershttpsarxivorgabs251204959v1 aria-label="Towards a Fully Automated Differential $\text{NNLO}_\text{EW}$ Generator for Lepton Colliders"><a href=https://arxiv.org/abs/2512.04959v1>Towards a Fully Automated Differential $\text{NNLO}_\text{EW}$ Generator for Lepton Colliders</a></a></li><li><a href=#bounds-on-maximal-leakage-over-bayesian-networkshttpsarxivorgabs251204955v1 aria-label="Bounds on Maximal Leakage over Bayesian Networks"><a href=https://arxiv.org/abs/2512.04955v1>Bounds on Maximal Leakage over Bayesian Networks</a></a></li><li><a href=#oxygen-isotope-constraints-on-the-importance-of-photochemical-processing-in-protoplanetary-diskshttpsarxivorgabs251204944v1 aria-label="Oxygen Isotope Constraints on the Importance of Photochemical Processing in Protoplanetary Disks"><a href=https://arxiv.org/abs/2512.04944v1>Oxygen Isotope Constraints on the Importance of Photochemical Processing in Protoplanetary Disks</a></a></li><li><a href=#exploring-vibronic-dynamics-near-a-sloped-conical-intersection-with-trapped-rydberg-ionshttpsarxivorgabs251204941v1 aria-label="Exploring vibronic dynamics near a sloped conical intersection with trapped Rydberg ions"><a href=https://arxiv.org/abs/2512.04941v1>Exploring vibronic dynamics near a sloped conical intersection with trapped Rydberg ions</a></a></li><li><a href=#litevggt-boosting-vanilla-vggt-via-geometry-aware-cached-token-merginghttpsarxivorgabs251204939v1 aria-label="LiteVGGT: Boosting Vanilla VGGT via Geometry-aware Cached Token Merging"><a href=https://arxiv.org/abs/2512.04939v1>LiteVGGT: Boosting Vanilla VGGT via Geometry-aware Cached Token Merging</a></a></li><li><a href=#distributional-properties-of-first-jump-times-of-cbi-processes-with-jump-sizes-in-given-borel-setshttpsarxivorgabs251204935v1 aria-label="Distributional properties of first jump times of CBI processes with jump sizes in given Borel sets"><a href=https://arxiv.org/abs/2512.04935v1>Distributional properties of first jump times of CBI processes with jump sizes in given Borel sets</a></a></li><li><a href=#markov-renewal-single-photon-lidar-simulatorhttpsarxivorgabs251204924v1 aria-label="Markov-Renewal Single-Photon LiDAR Simulator"><a href=https://arxiv.org/abs/2512.04924v1>Markov-Renewal Single-Photon LiDAR Simulator</a></a></li><li><a href=#instantons-meet-resonances-unifying-two-seemingly-distinct-approaches-to-quantum-tunnelinghttpsarxivorgabs251204907v1 aria-label="Instantons meet resonances: Unifying two seemingly distinct approaches to quantum tunneling"><a href=https://arxiv.org/abs/2512.04907v1>Instantons meet resonances: Unifying two seemingly distinct approaches to quantum tunneling</a></a></li><li><a href=#channel-aware-multi-domain-feature-extraction-for-automatic-modulation-recognition-in-mimo-systemshttpsarxivorgabs251204899v1 aria-label="Channel-Aware Multi-Domain Feature Extraction for Automatic Modulation Recognition in MIMO Systems"><a href=https://arxiv.org/abs/2512.04899v1>Channel-Aware Multi-Domain Feature Extraction for Automatic Modulation Recognition in MIMO Systems</a></a></li><li><a href=#anomaly-cancellation-and-one-loop-finiteness-of-6d-half-maximal-supergravitieshttpsarxivorgabs251205082v1 aria-label="Anomaly cancellation and one-loop finiteness of 6D half-maximal supergravities"><a href=https://arxiv.org/abs/2512.05082v1>Anomaly cancellation and one-loop finiteness of 6D half-maximal supergravities</a></a></li><li><a href=#an-elementary-approach-to-wehrl-type-entropy-bounds-in-quantitative-formhttpsarxivorgabs251204245v1 aria-label="An elementary approach to Wehrl-type entropy bounds in quantitative form"><a href=https://arxiv.org/abs/2512.04245v1>An elementary approach to Wehrl-type entropy bounds in quantitative form</a></a></li><li><a href=#counting-ads-vacuahttpsarxivorgabs251204151v1 aria-label="Counting AdS Vacua"><a href=https://arxiv.org/abs/2512.04151v1>Counting AdS Vacua</a></a></li><li><a href=#structure-theorems-for-the-heart-of-lcahttpsarxivorgabs251203338v1 aria-label="Structure theorems for the heart of LCA"><a href=https://arxiv.org/abs/2512.03338v1>Structure theorems for the heart of LCA</a></a></li><li><a href=#svrg-and-beyond-via-posterior-correctionhttpsarxivorgabs251201930v1 aria-label="SVRG and Beyond via Posterior Correction"><a href=https://arxiv.org/abs/2512.01930v1>SVRG and Beyond via Posterior Correction</a></a></li><li><a href=#graph-distance-as-surprise-free-energy-minimization-in-knowledge-graph-reasoninghttpsarxivorgabs251201878v1 aria-label="Graph Distance as Surprise: Free Energy Minimization in Knowledge Graph Reasoning"><a href=https://arxiv.org/abs/2512.01878v1>Graph Distance as Surprise: Free Energy Minimization in Knowledge Graph Reasoning</a></a></li><li><a href=#an-hybrid-stochastic-newton-algorithm-for-logistic-regressionhttpsarxivorgabs251201790v1 aria-label="An hybrid stochastic Newton algorithm for logistic regression"><a href=https://arxiv.org/abs/2512.01790v1>An hybrid stochastic Newton algorithm for logistic regression</a></a></li><li><a href=#spatial-structure-and-magnetism-of-a-spin-orbit-entangled-spin-1-coherent-spin-center-the-manganese-neutral-acceptor-in-a-iii-v-semiconductorhttpsarxivorgabs251201158v1 aria-label="Spatial structure and magnetism of a spin-orbit entangled spin-1 coherent spin center: the manganese neutral acceptor in a III-V semiconductor"><a href=https://arxiv.org/abs/2512.01158v1>Spatial structure and magnetism of a spin-orbit entangled spin-1 coherent spin center: the manganese neutral acceptor in a III-V semiconductor</a></a></li><li><a href=#a-sudden-fine-scale-bright-kernel-captured-by-hi-c-flare-during-an-m16-class-solar-flares-post-maximum-phasehttpsarxivorgabs251201140v1 aria-label="A sudden fine-scale bright kernel captured by Hi-C Flare during an M1.6-class solar flare&rsquo;s post-maximum phase"><a href=https://arxiv.org/abs/2512.01140v1>A sudden fine-scale bright kernel captured by Hi-C Flare during an M1.6-class solar flare&rsquo;s post-maximum phase</a></a></li><li><a href=#global-banks-spillovers-to-emerging-markets-macro-to-micro-transmissionhttpsarxivorgabs251201132v1 aria-label="Global Banks&rsquo; Spillovers to Emerging Markets: Macro to Micro Transmission"><a href=https://arxiv.org/abs/2512.01132v1>Global Banks&rsquo; Spillovers to Emerging Markets: Macro to Micro Transmission</a></a></li><li><a href=#world-model-robustness-via-surprise-recognitionhttpsarxivorgabs251201119v1 aria-label="World Model Robustness via Surprise Recognition"><a href=https://arxiv.org/abs/2512.01119v1>World Model Robustness via Surprise Recognition</a></a></li><li><a href=#non-reciprocal-interactions-between-condensates-in-chemically-active-mixtureshttpsarxivorgabs251123425v1 aria-label="Non-reciprocal interactions between condensates in chemically active mixtures"><a href=https://arxiv.org/abs/2511.23425v1>Non-reciprocal interactions between condensates in chemically active mixtures</a></a></li><li><a href=#splannequin-freezing-monocular-mannequin-challenge-footage-with-dual-detection-splattinghttpsarxivorgabs251205113v1 aria-label="Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting"><a href=https://arxiv.org/abs/2512.05113v1>Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting</a></a></li><li><a href=#global-phase-diagram-of-two-dimensional-dirty-hyperbolic-dirac-liquidshttpsarxivorgabs251205109v1 aria-label="Global phase diagram of two-dimensional dirty hyperbolic Dirac liquids"><a href=https://arxiv.org/abs/2512.05109v1>Global phase diagram of two-dimensional dirty hyperbolic Dirac liquids</a></a></li><li><a href=#measurement-of-the-branching-fractions-and-longitudinal-polarisations-of-b0_s-to-k0-kern-018em-overlinekern--018em-k0-decayshttpsarxivorgabs251205102v1 aria-label="Measurement of the branching fractions and longitudinal polarisations of $B^0_{(s)} \to K^{*0} \kern 0.18em \overline{\kern -0.18em K}{}^{*0}$ decays"><a href=https://arxiv.org/abs/2512.05102v1>Measurement of the branching fractions and longitudinal polarisations of $B^0_{(s)} \to K^{*0} \kern 0.18em \overline{\kern -0.18em K}{}^{*0}$ decays</a></a></li><li><a href=#phase-transitions-and-black-hole-stability-in-gauged-n--8-supergravityhttpsarxivorgabs251205088v1 aria-label="Phase Transitions and Black Hole Stability in Gauged N = 8 Supergravity"><a href=https://arxiv.org/abs/2512.05088v1>Phase Transitions and Black Hole Stability in Gauged N = 8 Supergravity</a></a></li><li><a href=#singularity-of-the-loops-within-a-cable-graph-loop-soup-conditioned-by-its-occupation-timehttpsarxivorgabs251205086v1 aria-label="Singularity of the loops within a cable-graph loop-soup conditioned by its occupation time"><a href=https://arxiv.org/abs/2512.05086v1>Singularity of the loops within a cable-graph loop-soup conditioned by its occupation time</a></a></li><li><a href=#mean-curvature-flow-near-a-peanut-solutionhttpsarxivorgabs251205077v1 aria-label="Mean curvature flow near a peanut solution"><a href=https://arxiv.org/abs/2512.05077v1>Mean curvature flow near a peanut solution</a></a></li><li><a href=#atomic-decompositions-for-derived-categories-of-g-surfaceshttpsarxivorgabs251205064v1 aria-label="Atomic decompositions for derived categories of G-surfaces"><a href=https://arxiv.org/abs/2512.05064v1>Atomic decompositions for derived categories of G-surfaces</a></a></li><li><a href=#sensitivity-of-hongmeng-21cm-experiment-on-scattering-dark-matterhttpsarxivorgabs251205056v1 aria-label="Sensitivity of Hongmeng 21cm experiment on scattering dark matter"><a href=https://arxiv.org/abs/2512.05056v1>Sensitivity of Hongmeng 21cm experiment on scattering dark matter</a></a></li><li><a href=#the-evolving-landscape-of-interactive-surface-sensing-technologieshttpsarxivorgabs251205071v1 aria-label="The Evolving Landscape of Interactive Surface Sensing Technologies"><a href=https://arxiv.org/abs/2512.05071v1>The Evolving Landscape of Interactive Surface Sensing Technologies</a></a></li><li><a href=#virtually-unrolling-the-herculaneum-papyri-by-diffeomorphic-spiral-fittinghttpsarxivorgabs251204927v1 aria-label="Virtually Unrolling the Herculaneum Papyri by Diffeomorphic Spiral Fitting"><a href=https://arxiv.org/abs/2512.04927v1>Virtually Unrolling the Herculaneum Papyri by Diffeomorphic Spiral Fitting</a></a></li><li><a href=#latentfm-a-latent-flow-matching-approach-for-generative-medical-image-segmentationhttpsarxivorgabs251204821v1 aria-label="LatentFM: A Latent Flow Matching Approach for Generative Medical Image Segmentation"><a href=https://arxiv.org/abs/2512.04821v1>LatentFM: A Latent Flow Matching Approach for Generative Medical Image Segmentation</a></a></li><li><a href=#cnn-on-top-in-search-of-scalable--lightweight-image-based-jet-taggershttpsarxivorgabs251205031v1 aria-label="CNN on `Top&rsquo;: In Search of Scalable & Lightweight Image-based Jet Taggers"><a href=https://arxiv.org/abs/2512.05031v1>CNN on `Top&rsquo;: In Search of Scalable & Lightweight Image-based Jet Taggers</a></a></li><li><a href=#inflationary-relics-from-an-ultra-slow-roll-plateauhttpsarxivorgabs251204986v1 aria-label="Inflationary relics from an Ultra-Slow-Roll plateau"><a href=https://arxiv.org/abs/2512.04986v1>Inflationary relics from an Ultra-Slow-Roll plateau</a></a></li><li><a href=#more-on-the-sum-product-problem-for-integers-with-few-prime-factorshttpsarxivorgabs251204931v1 aria-label="More on the sum-product problem for integers with few prime factors"><a href=https://arxiv.org/abs/2512.04931v1>More on the sum-product problem for integers with few prime factors</a></a></li><li><a href=#monochromatic-products-in-random-integer-setshttpsarxivorgabs251204916v1 aria-label="Monochromatic products in random integer sets"><a href=https://arxiv.org/abs/2512.04916v1>Monochromatic products in random integer sets</a></a></li><li><a href=#you-only-train-once-yoto-a-retraining-free-object-detection-frameworkhttpsarxivorgabs251204888v1 aria-label="You Only Train Once (YOTO): A Retraining-Free Object Detection Framework"><a href=https://arxiv.org/abs/2512.04888v1>You Only Train Once (YOTO): A Retraining-Free Object Detection Framework</a></a></li><li><a href=#balancing-information-and-dissipation-with-partially-observed-fluctuating-signalshttpsarxivorgabs251204877v1 aria-label="Balancing information and dissipation with partially observed fluctuating signals"><a href=https://arxiv.org/abs/2512.04877v1>Balancing information and dissipation with partially observed fluctuating signals</a></a></li><li><a href=#cute-but-cunning-effective-closed-form-alternatives-to-the-exact-lognormal-statisticshttpsarxivorgabs251204872v1 aria-label="Cute but Cunning: Effective Closed-Form Alternatives to the Exact Lognormal Statistics"><a href=https://arxiv.org/abs/2512.04872v1>Cute but Cunning: Effective Closed-Form Alternatives to the Exact Lognormal Statistics</a></a></li><li><a href=#opacity-problems-in-multi-energy-timed-automatahttpsarxivorgabs251204950v1 aria-label="Opacity problems in multi-energy timed automata"><a href=https://arxiv.org/abs/2512.04950v1>Opacity problems in multi-energy timed automata</a></a></li><li><a href=#robust-precoding-designs-of-rsma-for-multiuser-mimo-systemshttpsarxivorgabs251204750v1 aria-label="Robust Precoding Designs of RSMA for Multiuser MIMO Systems"><a href=https://arxiv.org/abs/2512.04750v1>Robust Precoding Designs of RSMA for Multiuser MIMO Systems</a></a></li><li><a href=#rotatable-antenna-enhanced-cell-free-communicationhttpsarxivorgabs251204742v1 aria-label="Rotatable Antenna-Enhanced Cell-Free Communication"><a href=https://arxiv.org/abs/2512.04742v1>Rotatable Antenna-Enhanced Cell-Free Communication</a></a></li><li><a href=#topology-matters-measuring-memory-leakage-in-multi-agent-llmshttpsarxivorgabs251204668v1 aria-label="Topology Matters: Measuring Memory Leakage in Multi-Agent LLMs"><a href=https://arxiv.org/abs/2512.04668v1>Topology Matters: Measuring Memory Leakage in Multi-Agent LLMs</a></a></li><li><a href=#fx-market-making-with-internal-liquidityhttpsarxivorgabs251204603v1 aria-label="FX Market Making with Internal Liquidity"><a href=https://arxiv.org/abs/2512.04603v1>FX Market Making with Internal Liquidity</a></a></li><li><a href=#a-light-weight-large-language-model-file-format-for-highly-secure-model-distributionhttpsarxivorgabs251204580v1 aria-label="A Light-Weight Large Language Model File Format for Highly-Secure Model Distribution"><a href=https://arxiv.org/abs/2512.04580v1>A Light-Weight Large Language Model File Format for Highly-Secure Model Distribution</a></a></li><li><a href=#reliable-statistical-guarantees-for-conformal-predictors-with-small-datasetshttpsarxivorgabs251204566v1 aria-label="Reliable Statistical Guarantees for Conformal Predictors with Small Datasets"><a href=https://arxiv.org/abs/2512.04566v1>Reliable Statistical Guarantees for Conformal Predictors with Small Datasets</a></a></li><li><a href=#gtm-simulating-the-world-of-tools-for-ai-agentshttpsarxivorgabs251204535v1 aria-label="GTM: Simulating the World of Tools for AI Agents"><a href=https://arxiv.org/abs/2512.04535v1>GTM: Simulating the World of Tools for AI Agents</a></a></li><li><a href=#not-all-birds-look-the-same-identity-preserving-generation-for-birdshttpsarxivorgabs251204485v1 aria-label="Not All Birds Look The Same: Identity-Preserving Generation For Birds"><a href=https://arxiv.org/abs/2512.04485v1>Not All Birds Look The Same: Identity-Preserving Generation For Birds</a></a></li><li><a href=#towards-6g-native-ai-edge-networks-a-semantic-aware-and-agentic-intelligence-paradigmhttpsarxivorgabs251204405v1 aria-label="Towards 6G Native-AI Edge Networks: A Semantic-Aware and Agentic Intelligence Paradigm"><a href=https://arxiv.org/abs/2512.04405v1>Towards 6G Native-AI Edge Networks: A Semantic-Aware and Agentic Intelligence Paradigm</a></a></li><li><a href=#agentbay-a-hybrid-interaction-sandbox-for-seamless-human-ai-intervention-in-agentic-systemshttpsarxivorgabs251204367v1 aria-label="AgentBay: A Hybrid Interaction Sandbox for Seamless Human-AI Intervention in Agentic Systems"><a href=https://arxiv.org/abs/2512.04367v1>AgentBay: A Hybrid Interaction Sandbox for Seamless Human-AI Intervention in Agentic Systems</a></a></li><li><a href=#rram-based-analog-matrix-computing-for-massive-mimo-signal-processing-a-reviewhttpsarxivorgabs251204365v1 aria-label="RRAM-Based Analog Matrix Computing for Massive MIMO Signal Processing: A Review"><a href=https://arxiv.org/abs/2512.04365v1>RRAM-Based Analog Matrix Computing for Massive MIMO Signal Processing: A Review</a></a></li><li><a href=#human-controllable-ai-meaningful-human-controlhttpsarxivorgabs251204334v1 aria-label="Human-controllable AI: Meaningful Human Control"><a href=https://arxiv.org/abs/2512.04334v1>Human-controllable AI: Meaningful Human Control</a></a></li><li><a href=#vlcs-managing-parallelism-with-virtualized-librarieshttpsarxivorgabs251204320v1 aria-label="VLCs: Managing Parallelism with Virtualized Libraries"><a href=https://arxiv.org/abs/2512.04320v1>VLCs: Managing Parallelism with Virtualized Libraries</a></a></li><li><a href=#breaking-isolation-a-new-perspective-on-hypervisor-exploitation-via-cross-domain-attackshttpsarxivorgabs251204260v1 aria-label="Breaking Isolation: A New Perspective on Hypervisor Exploitation via Cross-Domain Attacks"><a href=https://arxiv.org/abs/2512.04260v1>Breaking Isolation: A New Perspective on Hypervisor Exploitation via Cross-Domain Attacks</a></a></li><li><a href=#hey-gpt-oss-looks-like-you-got-it----now-walk-me-through-it-an-assessment-of-the-reasoning-language-models-chain-of-thought-mechanism-for-digital-forensicshttpsarxivorgabs251204254v1 aria-label="Hey GPT-OSS, Looks Like You Got It &ndash; Now Walk Me Through It! An Assessment of the Reasoning Language Models Chain of Thought Mechanism for Digital Forensics"><a href=https://arxiv.org/abs/2512.04254v1>Hey GPT-OSS, Looks Like You Got It &ndash; Now Walk Me Through It! An Assessment of the Reasoning Language Models Chain of Thought Mechanism for Digital Forensics</a></a></li><li><a href=#decentralized-social-media-and-artificial-intelligence-in-digital-public-health-monitoringhttpsarxivorgabs251204232v1 aria-label="Decentralized Social Media and Artificial Intelligence in Digital Public Health Monitoring"><a href=https://arxiv.org/abs/2512.04232v1>Decentralized Social Media and Artificial Intelligence in Digital Public Health Monitoring</a></a></li><li><a href=#onsight-pathology-a-real-time-platform-agnostic-computational-pathology-companion-for-histopathologyhttpsarxivorgabs251204187v1 aria-label="OnSight Pathology: A real-time platform-agnostic computational pathology companion for histopathology"><a href=https://arxiv.org/abs/2512.04187v1>OnSight Pathology: A real-time platform-agnostic computational pathology companion for histopathology</a></a></li><li><a href=#minimal-flavor-protection-for-tev-scale-new-physicshttpsarxivorgabs251204159v1 aria-label="Minimal Flavor Protection for TeV-scale New Physics"><a href=https://arxiv.org/abs/2512.04159v1>Minimal Flavor Protection for TeV-scale New Physics</a></a></li><li><a href=#fare-comparison-app-of-uber-ola-and-rapidohttpsarxivorgabs251204065v1 aria-label="Fare Comparison App of Uber, Ola and Rapido"><a href=https://arxiv.org/abs/2512.04065v1>Fare Comparison App of Uber, Ola and Rapido</a></a></li><li><a href=#a-chronological-analysis-of-the-evolution-of-smartnicshttpsarxivorgabs251204054v1 aria-label="A Chronological Analysis of the Evolution of SmartNICs"><a href=https://arxiv.org/abs/2512.04054v1>A Chronological Analysis of the Evolution of SmartNICs</a></a></li><li><a href=#marktune-improving-the-quality-detectability-trade-off-in-open-weight-llm-watermarkinghttpsarxivorgabs251204044v1 aria-label="MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking"><a href=https://arxiv.org/abs/2512.04044v1>MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking</a></a></li><li><a href=#oopredictor-predicting-object-oriented-accesses-using-static-analysishttpsarxivorgabs251203972v1 aria-label="OOPredictor: Predicting Object-Oriented Accesses using Static Analysis"><a href=https://arxiv.org/abs/2512.03972v1>OOPredictor: Predicting Object-Oriented Accesses using Static Analysis</a></a></li><li><a href=#integrating-high-performance-in-memory-data-streaming-and-in-situ-visualization-in-hybrid-mpiopenmp-pic-mc-simulations-towards-exascalehttpsarxivorgabs251203914v2 aria-label="Integrating High Performance In-Memory Data Streaming and In-Situ Visualization in Hybrid MPI+OpenMP PIC MC Simulations Towards Exascale"><a href=https://arxiv.org/abs/2512.03914v2>Integrating High Performance In-Memory Data Streaming and In-Situ Visualization in Hybrid MPI+OpenMP PIC MC Simulations Towards Exascale</a></a></li><li><a href=#prostate-biopsy-whole-slide-image-dataset-from-an-underrepresented-middle-eastern-populationhttpsarxivorgabs251203854v1 aria-label="Prostate biopsy whole slide image dataset from an underrepresented Middle Eastern population"><a href=https://arxiv.org/abs/2512.03854v1>Prostate biopsy whole slide image dataset from an underrepresented Middle Eastern population</a></a></li><li><a href=#robust-algorithms-for-path-and-cycle-problems-in-geometric-intersection-graphshttpsarxivorgabs251203843v1 aria-label="Robust Algorithms for Path and Cycle Problems in Geometric Intersection Graphs"><a href=https://arxiv.org/abs/2512.03843v1>Robust Algorithms for Path and Cycle Problems in Geometric Intersection Graphs</a></a></li><li><a href=#a-robust-camera-based-method-for-breath-rate-measurementhttpsarxivorgabs251203827v1 aria-label="A Robust Camera-based Method for Breath Rate Measurement"><a href=https://arxiv.org/abs/2512.03827v1>A Robust Camera-based Method for Breath Rate Measurement</a></a></li><li><a href=#hidden-charm-and--bottom-tetraquark-states-with-jpc1--via-qcd-sum-ruleshttpsarxivorgabs251203800v1 aria-label="Hidden-charm and -bottom tetraquark states with $J^{PC}=1^{-+}$ via QCD sum rules"><a href=https://arxiv.org/abs/2512.03800v1>Hidden-charm and -bottom tetraquark states with $J^{PC}=1^{-+}$ via QCD sum rules</a></a></li><li><a href=#sleep-modulation-the-challenge-of-transitioning-from-open-loop-to-closed-loophttpsarxivorgabs251203784v1 aria-label="Sleep Modulation: The Challenge of Transitioning from Open Loop to Closed Loop"><a href=https://arxiv.org/abs/2512.03784v1>Sleep Modulation: The Challenge of Transitioning from Open Loop to Closed Loop</a></a></li><li><a href=#caftra-frequency-domain-correlation-aware-feedback-free-mimo-transmission-and-resource-allocation-for-6g-and-beyondhttpsarxivorgabs251203767v2 aria-label="CaFTRA: Frequency-Domain Correlation-Aware Feedback-Free MIMO Transmission and Resource Allocation for 6G and Beyond"><a href=https://arxiv.org/abs/2512.03767v2>CaFTRA: Frequency-Domain Correlation-Aware Feedback-Free MIMO Transmission and Resource Allocation for 6G and Beyond</a></a></li><li><a href=#inaccessibility-in-public-transit-networkshttpsarxivorgabs251203766v1 aria-label="Inaccessibility in Public Transit Networks"><a href=https://arxiv.org/abs/2512.03766v1>Inaccessibility in Public Transit Networks</a></a></li><li><a href=#setting-up-for-failure-automatic-discovery-of-the-neural-mechanisms-of-cognitive-errorshttpsarxivorgabs251204808v1 aria-label="Setting up for failure: automatic discovery of the neural mechanisms of cognitive errors"><a href=https://arxiv.org/abs/2512.04808v1>Setting up for failure: automatic discovery of the neural mechanisms of cognitive errors</a></a></li><li><a href=#neural-policy-composition-from-free-energy-minimizationhttpsarxivorgabs251204745v1 aria-label="Neural Policy Composition from Free Energy Minimization"><a href=https://arxiv.org/abs/2512.04745v1>Neural Policy Composition from Free Energy Minimization</a></a></li><li><a href=#interactive-communication----cross-disciplinary-perspectives-from-psychology-acoustics-and-media-technologyhttpsarxivorgabs251204692v1 aria-label="Interactive Communication &ndash; cross-disciplinary perspectives from psychology, acoustics, and media technology"><a href=https://arxiv.org/abs/2512.04692v1>Interactive Communication &ndash; cross-disciplinary perspectives from psychology, acoustics, and media technology</a></a></li><li><a href=#towards-cross-view-point-correspondence-in-vision-language-modelshttpsarxivorgabs251204686v1 aria-label="Towards Cross-View Point Correspondence in Vision-Language Models"><a href=https://arxiv.org/abs/2512.04686v1>Towards Cross-View Point Correspondence in Vision-Language Models</a></a></li><li><a href=#limit-cycles-for-speechhttpsarxivorgabs251204642v1 aria-label="Limit cycles for speech"><a href=https://arxiv.org/abs/2512.04642v1>Limit cycles for speech</a></a></li><li><a href=#when-robots-should-say-i-dont-know-benchmarking-abstention-in-embodied-question-answeringhttpsarxivorgabs251204597v1 aria-label="When Robots Should Say &ldquo;I Don&rsquo;t Know&rdquo;: Benchmarking Abstention in Embodied Question Answering"><a href=https://arxiv.org/abs/2512.04597v1>When Robots Should Say &ldquo;I Don&rsquo;t Know&rdquo;: Benchmarking Abstention in Embodied Question Answering</a></a></li><li><a href=#evoedit-lifelong-free-text-knowledge-editing-through-latent-perturbation-augmentation-and-knowledge-driven-parameter-fusionhttpsarxivorgabs251204545v1 aria-label="EvoEdit: Lifelong Free-Text Knowledge Editing through Latent Perturbation Augmentation and Knowledge-driven Parameter Fusion"><a href=https://arxiv.org/abs/2512.04545v1>EvoEdit: Lifelong Free-Text Knowledge Editing through Latent Perturbation Augmentation and Knowledge-driven Parameter Fusion</a></a></li><li><a href=#a-modular-cognitive-architecture-for-assisted-reasoning-the-nemosine-frameworkhttpsarxivorgabs251204500v1 aria-label="A Modular Cognitive Architecture for Assisted Reasoning: The Nemosine Framework"><a href=https://arxiv.org/abs/2512.04500v1>A Modular Cognitive Architecture for Assisted Reasoning: The Nemosine Framework</a></a></li><li><a href=#units-unified-time-series-generative-model-for-remote-sensinghttpsarxivorgabs251204461v1 aria-label="UniTS: Unified Time Series Generative Model for Remote Sensing"><a href=https://arxiv.org/abs/2512.04461v1>UniTS: Unified Time Series Generative Model for Remote Sensing</a></a></li><li><a href=#minddrive-an-all-in-one-framework-bridging-world-models-and-vision-language-model-for-end-to-end-autonomous-drivinghttpsarxivorgabs251204441v1 aria-label="MindDrive: An All-in-One Framework Bridging World Models and Vision-Language Model for End-to-End Autonomous Driving"><a href=https://arxiv.org/abs/2512.04441v1>MindDrive: An All-in-One Framework Bridging World Models and Vision-Language Model for End-to-End Autonomous Driving</a></a></li><li><a href=#what-is-beyond-presence-dimensionality-control-and-information-spaceshttpsarxivorgabs251204398v1 aria-label="What is Beyond Presence? Dimensionality, Control, and Information Spaces"><a href=https://arxiv.org/abs/2512.04398v1>What is Beyond Presence? Dimensionality, Control, and Information Spaces</a></a></li><li><a href=#mind-to-face-neural-driven-photorealistic-avatar-synthesis-via-eeg-decodinghttpsarxivorgabs251204313v1 aria-label="Mind-to-Face: Neural-Driven Photorealistic Avatar Synthesis via EEG Decoding"><a href=https://arxiv.org/abs/2512.04313v1>Mind-to-Face: Neural-Driven Photorealistic Avatar Synthesis via EEG Decoding</a></a></li><li><a href=#rnns-perform-task-computations-by-dynamically-warping-neural-representationshttpsarxivorgabs251204310v1 aria-label="RNNs perform task computations by dynamically warping neural representations"><a href=https://arxiv.org/abs/2512.04310v1>RNNs perform task computations by dynamically warping neural representations</a></a></li><li><a href=#covering-relations-in-the-poset-of-combinatorial-neural-codeshttpsarxivorgabs251204241v1 aria-label="Covering Relations in the Poset of Combinatorial Neural Codes"><a href=https://arxiv.org/abs/2512.04241v1>Covering Relations in the Poset of Combinatorial Neural Codes</a></a></li><li><a href=#addressing-logical-fallacies-in-scientific-reasoning-from-large-language-models-towards-a-dual-inference-training-frameworkhttpsarxivorgabs251204228v1 aria-label="Addressing Logical Fallacies In Scientific Reasoning From Large Language Models: Towards a Dual-Inference Training Framework"><a href=https://arxiv.org/abs/2512.04228v1>Addressing Logical Fallacies In Scientific Reasoning From Large Language Models: Towards a Dual-Inference Training Framework</a></a></li><li><a href=#parsimonious-clustering-of-covariance-matriceshttpsarxivorgabs251203912v1 aria-label="Parsimonious Clustering of Covariance Matrices"><a href=https://arxiv.org/abs/2512.03912v1>Parsimonious Clustering of Covariance Matrices</a></a></li><li><a href=#emergent-spatiotemporal-dynamics-in-large-scale-brain-networks-with-next-generation-neural-mass-modelshttpsarxivorgabs251203907v1 aria-label="Emergent Spatiotemporal Dynamics in Large-Scale Brain Networks with Next Generation Neural Mass Models"><a href=https://arxiv.org/abs/2512.03907v1>Emergent Spatiotemporal Dynamics in Large-Scale Brain Networks with Next Generation Neural Mass Models</a></a></li><li><a href=#equalizer-or-amplifier-how-ai-may-reshape-human-cognitive-differenceshttpsarxivorgabs251203902v1 aria-label="Equalizer or amplifier? How AI may reshape human cognitive differences"><a href=https://arxiv.org/abs/2512.03902v1>Equalizer or amplifier? How AI may reshape human cognitive differences</a></a></li><li><a href=#im-here-interaction-model-for-human-effort-based-robot-engagementhttpsarxivorgabs251203828v1 aria-label="IM HERE: Interaction Model for Human Effort Based Robot Engagement"><a href=https://arxiv.org/abs/2512.03828v1>IM HERE: Interaction Model for Human Effort Based Robot Engagement</a></a></li><li><a href=#origin-conditional-trajectory-encoding-measuring-urban-configurational-asymmetries-through-neural-decompositionhttpsarxivorgabs251203755v1 aria-label="Origin-Conditional Trajectory Encoding: Measuring Urban Configurational Asymmetries through Neural Decomposition"><a href=https://arxiv.org/abs/2512.03755v1>Origin-Conditional Trajectory Encoding: Measuring Urban Configurational Asymmetries through Neural Decomposition</a></a></li><li><a href=#knowing-oneself-with-and-through-ai-from-self-tracking-to-chatbotshttpsarxivorgabs251203682v1 aria-label="Knowing oneself with and through AI: From self-tracking to chatbots"><a href=https://arxiv.org/abs/2512.03682v1>Knowing oneself with and through AI: From self-tracking to chatbots</a></a></li><li><a href=#a-descriptive-model-for-modelling-attacker-decision-making-in-cyber-deceptionhttpsarxivorgabs251203641v1 aria-label="A Descriptive Model for Modelling Attacker Decision-Making in Cyber-Deception"><a href=https://arxiv.org/abs/2512.03641v1>A Descriptive Model for Modelling Attacker Decision-Making in Cyber-Deception</a></a></li><li><a href=#artificial-intelligence--human-intelligence-who-controls-whomhttpsarxivorgabs251204131v1 aria-label="Artificial Intelligence / Human Intelligence: Who Controls Whom?"><a href=https://arxiv.org/abs/2512.04131v1>Artificial Intelligence / Human Intelligence: Who Controls Whom?</a></a></li><li><a href=#fine-grained-narrative-classification-in-biased-news-articleshttpsarxivorgabs251203582v1 aria-label="Fine-grained Narrative Classification in Biased News Articles"><a href=https://arxiv.org/abs/2512.03582v1>Fine-grained Narrative Classification in Biased News Articles</a></a></li><li><a href=#synthetic-cognitive-walkthrough-aligning-large-language-model-performance-with-human-cognitive-walkthroughhttpsarxivorgabs251203568v1 aria-label="Synthetic Cognitive Walkthrough: Aligning Large Language Model Performance with Human Cognitive Walkthrough"><a href=https://arxiv.org/abs/2512.03568v1>Synthetic Cognitive Walkthrough: Aligning Large Language Model Performance with Human Cognitive Walkthrough</a></a></li><li><a href=#optimal-griffiths-phase-in-heterogeneous-human-brain-networks-brain-criticality-embracing-stability-and-flexibility-across-individualshttpsarxivorgabs251203409v1 aria-label="Optimal Griffiths Phase in Heterogeneous Human Brain Networks: Brain Criticality Embracing Stability and Flexibility across Individuals"><a href=https://arxiv.org/abs/2512.03409v1>Optimal Griffiths Phase in Heterogeneous Human Brain Networks: Brain Criticality Embracing Stability and Flexibility across Individuals</a></a></li><li><a href=#llm-generated-ads-from-personalization-parity-to-persuasion-superiorityhttpsarxivorgabs251203373v1 aria-label="LLM-Generated Ads: From Personalization Parity to Persuasion Superiority"><a href=https://arxiv.org/abs/2512.03373v1>LLM-Generated Ads: From Personalization Parity to Persuasion Superiority</a></a></li><li><a href=#prior-preferences-in-active-inference-agents-soft-hard-and-goal-shapinghttpsarxivorgabs251203293v1 aria-label="Prior preferences in active inference agents: soft, hard, and goal shaping"><a href=https://arxiv.org/abs/2512.03293v1>Prior preferences in active inference agents: soft, hard, and goal shaping</a></a></li><li><a href=#video4spatial-towards-visuospatial-intelligence-with-context-guided-video-generationhttpsarxivorgabs251203040v1 aria-label="Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation"><a href=https://arxiv.org/abs/2512.03040v1>Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation</a></a></li><li><a href=#inex-hallucination-mitigation-via-introspection-and-cross-modal-multi-agent-collaborationhttpsarxivorgabs251202981v1 aria-label="InEx: Hallucination Mitigation via Introspection and Cross-Modal Multi-Agent Collaboration"><a href=https://arxiv.org/abs/2512.02981v1>InEx: Hallucination Mitigation via Introspection and Cross-Modal Multi-Agent Collaboration</a></a></li><li><a href=#rethinking-generalized-bcis-benchmarking-340000-unique-algorithmic-configurations-for-eeg-mental-command-decodinghttpsarxivorgabs251202978v1 aria-label="Rethinking Generalized BCIs: Benchmarking 340,000+ Unique Algorithmic Configurations for EEG Mental Command Decoding"><a href=https://arxiv.org/abs/2512.02978v1>Rethinking Generalized BCIs: Benchmarking 340,000+ Unique Algorithmic Configurations for EEG Mental Command Decoding</a></a></li><li><a href=#the-future-of-ai-in-critical-mineral-explorationhttpsarxivorgabs251202879v1 aria-label="The future of AI in critical mineral exploration"><a href=https://arxiv.org/abs/2512.02879v1>The future of AI in critical mineral exploration</a></a></li><li><a href=#learning-science-and-the-illusion-of-understanding-exploring-the-effects-of-integrating-learning-tasks-after-explainer-videoshttpsarxivorgabs251202824v1 aria-label="Learning Science and the Illusion of Understanding: Exploring the Effects of Integrating Learning Tasks after Explainer Videos"><a href=https://arxiv.org/abs/2512.02824v1>Learning Science and the Illusion of Understanding: Exploring the Effects of Integrating Learning Tasks after Explainer Videos</a></a></li><li><a href=#responsible-discovery-in-astrobiology-lessons-from-four-controversial-claimshttpsarxivorgabs251204122v1 aria-label="Responsible Discovery in Astrobiology: Lessons from Four Controversial Claims"><a href=https://arxiv.org/abs/2512.04122v1>Responsible Discovery in Astrobiology: Lessons from Four Controversial Claims</a></a></li><li><a href=#cogdrive-cognition-driven-multimodal-prediction-planning-fusion-for-safe-autonomyhttpsarxivorgabs251202777v1 aria-label="CogDrive: Cognition-Driven Multimodal Prediction-Planning Fusion for Safe Autonomy"><a href=https://arxiv.org/abs/2512.02777v1>CogDrive: Cognition-Driven Multimodal Prediction-Planning Fusion for Safe Autonomy</a></a></li><li><a href=#emergent-bayesian-behaviour-and-optimal-cue-combination-in-llmshttpsarxivorgabs251202719v1 aria-label="Emergent Bayesian Behaviour and Optimal Cue Combination in LLMs"><a href=https://arxiv.org/abs/2512.02719v1>Emergent Bayesian Behaviour and Optimal Cue Combination in LLMs</a></a></li><li><a href=#translating-measures-onto-mechanisms-the-cognitive-relevance-of-higher-order-informationhttpsarxivorgabs251202671v1 aria-label="Translating Measures onto Mechanisms: The Cognitive Relevance of Higher-Order Information"><a href=https://arxiv.org/abs/2512.02671v1>Translating Measures onto Mechanisms: The Cognitive Relevance of Higher-Order Information</a></a></li><li><a href=#real-time-multimodal-data-collection-using-smartwatches-and-its-visualization-in-educationhttpsarxivorgabs251202651v1 aria-label="Real-Time Multimodal Data Collection Using Smartwatches and Its Visualization in Education"><a href=https://arxiv.org/abs/2512.02651v1>Real-Time Multimodal Data Collection Using Smartwatches and Its Visualization in Education</a></a></li><li><a href=#contact-implicit-modeling-and-simulation-of-a-snake-robot-on-compliant-and-granular-terrainhttpsarxivorgabs251205008v1 aria-label="Contact-Implicit Modeling and Simulation of a Snake Robot on Compliant and Granular Terrain"><a href=https://arxiv.org/abs/2512.05008v1>Contact-Implicit Modeling and Simulation of a Snake Robot on Compliant and Granular Terrain</a></a></li><li><a href=#recurrent-neural-networks-with-linear-structures-for-electricity-price-forecastinghttpsarxivorgabs251204690v1 aria-label="Recurrent Neural Networks with Linear Structures for Electricity Price Forecasting"><a href=https://arxiv.org/abs/2512.04690v1>Recurrent Neural Networks with Linear Structures for Electricity Price Forecasting</a></a></li><li><a href=#learning-single-image-super-resolution-in-the-jpeg-compressed-domainhttpsarxivorgabs251204284v1 aria-label="Learning Single-Image Super-Resolution in the JPEG Compressed Domain"><a href=https://arxiv.org/abs/2512.04284v1>Learning Single-Image Super-Resolution in the JPEG Compressed Domain</a></a></li><li><a href=#pinn-vs-lstm-a-comparative-study-for-steam-temperature-control-in-heat-recovery-steam-generatorshttpsarxivorgabs251204183v1 aria-label="PINN vs LSTM: A Comparative Study for Steam Temperature Control in Heat Recovery Steam Generators"><a href=https://arxiv.org/abs/2512.04183v1>PINN vs LSTM: A Comparative Study for Steam Temperature Control in Heat Recovery Steam Generators</a></a></li><li><a href=#augserve-adaptive-request-scheduling-for-augmented-large-language-model-inference-servinghttpsarxivorgabs251204013v1 aria-label="AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving"><a href=https://arxiv.org/abs/2512.04013v1>AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving</a></a></li><li><a href=#od-moe-on-demand-expert-loading-for-cacheless-edge-distributed-moe-inferencehttpsarxivorgabs251203927v1 aria-label="OD-MoE: On-Demand Expert Loading for Cacheless Edge-Distributed MoE Inference"><a href=https://arxiv.org/abs/2512.03927v1>OD-MoE: On-Demand Expert Loading for Cacheless Edge-Distributed MoE Inference</a></a></li><li><a href=#a-theoretical-framework-for-auxiliary-loss-free-load-balancing-of-sparse-mixture-of-experts-in-large-scale-ai-modelshttpsarxivorgabs251203915v2 aria-label="A Theoretical Framework for Auxiliary-Loss-Free Load Balancing of Sparse Mixture-of-Experts in Large-Scale AI Models"><a href=https://arxiv.org/abs/2512.03915v2>A Theoretical Framework for Auxiliary-Loss-Free Load Balancing of Sparse Mixture-of-Experts in Large-Scale AI Models</a></a></li><li><a href=#lightweight-design-and-analysis-of-optical-cover-plate-for-exoplanet-imaging-coronagraphhttpsarxivorgabs251203700v1 aria-label="Lightweight design and analysis of optical cover plate for exoplanet imaging coronagraph"><a href=https://arxiv.org/abs/2512.03700v1>Lightweight design and analysis of optical cover plate for exoplanet imaging coronagraph</a></a></li><li><a href=#fftrainer-fast-failover-in-large-language-model-training-with-almost-free-state-managementhttpsarxivorgabs251203644v1 aria-label="FFTrainer: Fast Failover in Large-Language Model Training with Almost-Free State Management"><a href=https://arxiv.org/abs/2512.03644v1>FFTrainer: Fast Failover in Large-Language Model Training with Almost-Free State Management</a></a></li><li><a href=#drag-reduction-via-separation-control-using-plasma-actuators-on-a-truck-cabin-sidehttpsarxivorgabs251203613v1 aria-label="Drag reduction via separation control using plasma actuators on a truck cabin side"><a href=https://arxiv.org/abs/2512.03613v1>Drag reduction via separation control using plasma actuators on a truck cabin side</a></a></li><li><a href=#kvnand-efficient-on-device-large-language-model-inference-using-dram-free-in-flash-computinghttpsarxivorgabs251203608v1 aria-label="KVNAND: Efficient On-Device Large Language Model Inference Using DRAM-Free In-Flash Computing"><a href=https://arxiv.org/abs/2512.03608v1>KVNAND: Efficient On-Device Large Language Model Inference Using DRAM-Free In-Flash Computing</a></a></li><li><a href=#tuning-of-vectorization-parameters-for-molecular-dynamics-simulations-in-autopashttpsarxivorgabs251203565v1 aria-label="Tuning of Vectorization Parameters for Molecular Dynamics Simulations in AutoPas"><a href=https://arxiv.org/abs/2512.03565v1>Tuning of Vectorization Parameters for Molecular Dynamics Simulations in AutoPas</a></a></li><li><a href=#tokenscale-timely-and-accurate-autoscaling-for-disaggregated-llm-serving-with-token-velocityhttpsarxivorgabs251203416v1 aria-label="TokenScale: Timely and Accurate Autoscaling for Disaggregated LLM Serving with Token Velocity"><a href=https://arxiv.org/abs/2512.03416v1>TokenScale: Timely and Accurate Autoscaling for Disaggregated LLM Serving with Token Velocity</a></a></li><li><a href=#getting-the-most-out-of-your-storage-hierarchy-with-mirror-optimized-storage-tieringhttpsarxivorgabs251203279v1 aria-label="Getting the MOST out of your Storage Hierarchy with Mirror-Optimized Storage Tiering"><a href=https://arxiv.org/abs/2512.03279v1>Getting the MOST out of your Storage Hierarchy with Mirror-Optimized Storage Tiering</a></a></li><li><a href=#estimation-of-semiparametric-factor-models-with-missing-datahttpsarxivorgabs251203235v1 aria-label="Estimation of Semiparametric Factor Models with Missing Data"><a href=https://arxiv.org/abs/2512.03235v1>Estimation of Semiparametric Factor Models with Missing Data</a></a></li><li><a href=#three-dimensional-third-medium-contact-model-for-hyperelastic-contact-and-pneumatically-actuated-systemshttpsarxivorgabs251203181v1 aria-label="Three-dimensional third medium contact model for hyperelastic contact and pneumatically actuated systems"><a href=https://arxiv.org/abs/2512.03181v1>Three-dimensional third medium contact model for hyperelastic contact and pneumatically actuated systems</a></a></li></ul></li><li><a href=#-llm aria-label="üîç llm">üîç llm</a><ul><li><a href=#reflection-removal-through-efficient-adaptation-of-diffusion-transformershttpsarxivorgabs251205000v1 aria-label="Reflection Removal through Efficient Adaptation of Diffusion Transformers"><a href=https://arxiv.org/abs/2512.05000v1>Reflection Removal through Efficient Adaptation of Diffusion Transformers</a></a></li><li><a href=#a-systemic-pathological-network-model-and-combinatorial-intervention-strategies-for-alzheimers-diseasehttpsarxivorgabs251204937v1 aria-label="A Systemic Pathological Network Model and Combinatorial Intervention Strategies for Alzheimer&rsquo;s Disease"><a href=https://arxiv.org/abs/2512.04937v1>A Systemic Pathological Network Model and Combinatorial Intervention Strategies for Alzheimer&rsquo;s Disease</a></a></li><li><a href=#exact-3-d-channel-impulse-response-for-spherical-receivers-with-arbitrary-drift-directionshttpsarxivorgabs251204858v1 aria-label="Exact 3-D Channel Impulse Response for Spherical Receivers with Arbitrary Drift Directions"><a href=https://arxiv.org/abs/2512.04858v1>Exact 3-D Channel Impulse Response for Spherical Receivers with Arbitrary Drift Directions</a></a></li><li><a href=#long-term-x-ray-variability-of-the-multiple-planet-host-l-98-59-hints-of-an-activity-cyclehttpsarxivorgabs251204817v1 aria-label="Long-term X-ray variability of the multiple-planet host L 98-59: Hints of an activity cycle"><a href=https://arxiv.org/abs/2512.04817v1>Long-term X-ray variability of the multiple-planet host L 98-59: Hints of an activity cycle</a></a></li><li><a href=#crystal-formation-in-systems-of-pseudo-forced-swarmalatorshttpsarxivorgabs251204724v1 aria-label="Crystal formation in systems of pseudo-forced swarmalators"><a href=https://arxiv.org/abs/2512.04724v1>Crystal formation in systems of pseudo-forced swarmalators</a></a></li><li><a href=#infinity-of-solutions-to-initial-boundary-value-problems-for-linear-constant-coefficient-evolution-pdes-on-semi-infinite-intervalshttpsarxivorgabs251204670v1 aria-label="Infinity of solutions to initial-boundary value problems for linear constant-coefficient evolution PDEs on semi-infinite intervals"><a href=https://arxiv.org/abs/2512.04670v1>Infinity of solutions to initial-boundary value problems for linear constant-coefficient evolution PDEs on semi-infinite intervals</a></a></li><li><a href=#fermionic-neural-gibbs-stateshttpsarxivorgabs251204663v1 aria-label="Fermionic neural Gibbs states"><a href=https://arxiv.org/abs/2512.04663v1>Fermionic neural Gibbs states</a></a></li><li><a href=#denoise-to-track-harnessing-video-diffusion-priors-for-robust-correspondencehttpsarxivorgabs251204619v1 aria-label="Denoise to Track: Harnessing Video Diffusion Priors for Robust Correspondence"><a href=https://arxiv.org/abs/2512.04619v1>Denoise to Track: Harnessing Video Diffusion Priors for Robust Correspondence</a></a></li><li><a href=#neural-decoding-of-overt-speech-from-ecog-using-vision-transformers-and-contrastive-representation-learninghttpsarxivorgabs251204618v1 aria-label="Neural Decoding of Overt Speech from ECoG Using Vision Transformers and Contrastive Representation Learning"><a href=https://arxiv.org/abs/2512.04618v1>Neural Decoding of Overt Speech from ECoG Using Vision Transformers and Contrastive Representation Learning</a></a></li><li><a href=#tensor-neyman-pearson-classification-theory-algorithms-and-error-controlhttpsarxivorgabs251204583v1 aria-label="Tensor Neyman-Pearson Classification: Theory, Algorithms, and Error Control"><a href=https://arxiv.org/abs/2512.04583v1>Tensor Neyman-Pearson Classification: Theory, Algorithms, and Error Control</a></a></li><li><a href=#a-rocq-formalization-of-monomial-and-graded-ordershttpsarxivorgabs251204573v1 aria-label="A Rocq Formalization of Monomial and Graded Orders"><a href=https://arxiv.org/abs/2512.04573v1>A Rocq Formalization of Monomial and Graded Orders</a></a></li><li><a href=#counterfeit-answers-adversarial-forgery-against-ocr-free-document-visual-question-answeringhttpsarxivorgabs251204554v1 aria-label="Counterfeit Answers: Adversarial Forgery against OCR-Free Document Visual Question Answering"><a href=https://arxiv.org/abs/2512.04554v1>Counterfeit Answers: Adversarial Forgery against OCR-Free Document Visual Question Answering</a></a></li><li><a href=#intertwined-birth-and-death-a-herbig-haro-outflow-resolves-the-distance-to-vela-juniorhttpsarxivorgabs251204956v1 aria-label="Intertwined birth and death: a Herbig-Haro outflow resolves the distance to Vela Junior"><a href=https://arxiv.org/abs/2512.04956v1>Intertwined birth and death: a Herbig-Haro outflow resolves the distance to Vela Junior</a></a></li><li><a href=#on-disturbance-aware-minimum-time-trajectory-planning-evidence-from-tests-on-a-dynamic-driving-simulatorhttpsarxivorgabs251204917v1 aria-label="On Disturbance-Aware Minimum-Time Trajectory Planning: Evidence from Tests on a Dynamic Driving Simulator"><a href=https://arxiv.org/abs/2512.04917v1>On Disturbance-Aware Minimum-Time Trajectory Planning: Evidence from Tests on a Dynamic Driving Simulator</a></a></li><li><a href=#from-task-executors-to-research-partners-evaluating-ai-co-pilots-through-workflow-integration-in-biomedical-researchhttpsarxivorgabs251204854v1 aria-label="From Task Executors to Research Partners: Evaluating AI Co-Pilots Through Workflow Integration in Biomedical Research"><a href=https://arxiv.org/abs/2512.04854v1>From Task Executors to Research Partners: Evaluating AI Co-Pilots Through Workflow Integration in Biomedical Research</a></a></li><li><a href=#extreme-mass-ratio-inspirals-embedded-in-dark-matter-halo-ii-chaotic-imprints-in-gravitational-waveshttpsarxivorgabs251204848v1 aria-label="Extreme-Mass-Ratio Inspirals Embedded in Dark Matter Halo II: Chaotic Imprints in Gravitational Waves"><a href=https://arxiv.org/abs/2512.04848v1>Extreme-Mass-Ratio Inspirals Embedded in Dark Matter Halo II: Chaotic Imprints in Gravitational Waves</a></a></li><li><a href=#large-speech-model-enabled-semantic-communicationhttpsarxivorgabs251204711v1 aria-label="Large Speech Model Enabled Semantic Communication"><a href=https://arxiv.org/abs/2512.04711v1>Large Speech Model Enabled Semantic Communication</a></a></li><li><a href=#hardware-aware-neural-architecture-search-of-early-exiting-networks-on-edge-acceleratorshttpsarxivorgabs251204705v1 aria-label="Hardware-aware Neural Architecture Search of Early Exiting Networks on Edge Accelerators"><a href=https://arxiv.org/abs/2512.04705v1>Hardware-aware Neural Architecture Search of Early Exiting Networks on Edge Accelerators</a></a></li><li><a href=#the-ejection-velocities-of-interstellar-objects-signpost-their-progenitor-system-architectureshttpsarxivorgabs251204700v1 aria-label="The ejection velocities of interstellar objects signpost their progenitor system architectures"><a href=https://arxiv.org/abs/2512.04700v1>The ejection velocities of interstellar objects signpost their progenitor system architectures</a></a></li><li><a href=#trinity-an-evolved-llm-coordinatorhttpsarxivorgabs251204695v1 aria-label="TRINITY: An Evolved LLM Coordinator"><a href=https://arxiv.org/abs/2512.04695v1>TRINITY: An Evolved LLM Coordinator</a></a></li><li><a href=#faust-xxix-ocs-line-emission-a-new-method-for-measuring-the-luminosity-of-embedded-protostars-in-binary-systemshttpsarxivorgabs251204674v1 aria-label="FAUST XXIX. OCS line emission: a new method for measuring the luminosity of embedded protostars in binary systems"><a href=https://arxiv.org/abs/2512.04674v1>FAUST XXIX. OCS line emission: a new method for measuring the luminosity of embedded protostars in binary systems</a></a></li><li><a href=#spectral-micro-ct-for-quantitative-analysis-of-calcification-in-fibrocartilagehttpsarxivorgabs251204662v1 aria-label="Spectral micro-CT for quantitative analysis of calcification in fibrocartilage"><a href=https://arxiv.org/abs/2512.04662v1>Spectral micro-CT for quantitative analysis of calcification in fibrocartilage</a></a></li><li><a href=#qosdiff-an-implicit-topological-embedding-learning-framework-leveraging-denoising-diffusion-and-adversarial-attention-for-robust-qos-predictionhttpsarxivorgabs251204596v1 aria-label="QoSDiff: An Implicit Topological Embedding Learning Framework Leveraging Denoising Diffusion and Adversarial Attention for Robust QoS Prediction"><a href=https://arxiv.org/abs/2512.04596v1>QoSDiff: An Implicit Topological Embedding Learning Framework Leveraging Denoising Diffusion and Adversarial Attention for Robust QoS Prediction</a></a></li><li><a href=#a-qudit-native-framework-for-discrete-time-crystalshttpsarxivorgabs251204577v1 aria-label="A Qudit-native Framework for Discrete Time Crystals"><a href=https://arxiv.org/abs/2512.04577v1>A Qudit-native Framework for Discrete Time Crystals</a></a></li><li><a href=#tardis-time-attenuated-representation-disentanglement-for-incomplete-multi-modal-tumor-segmentation-and-classificationhttpsarxivorgabs251204576v1 aria-label="TARDis: Time Attenuated Representation Disentanglement for Incomplete Multi-Modal Tumor Segmentation and Classification"><a href=https://arxiv.org/abs/2512.04576v1>TARDis: Time Attenuated Representation Disentanglement for Incomplete Multi-Modal Tumor Segmentation and Classification</a></a></li><li><a href=#identity-clue-refinement-and-enhancement-for-visible-infrared-person-re-identificationhttpsarxivorgabs251204522v1 aria-label="Identity Clue Refinement and Enhancement for Visible-Infrared Person Re-Identification"><a href=https://arxiv.org/abs/2512.04522v1>Identity Clue Refinement and Enhancement for Visible-Infrared Person Re-Identification</a></a></li><li><a href=#adaptive-time-domain-harmonic-control-for-noise-vibration-harshness-reduction-of-electric-driveshttpsarxivorgabs251204512v1 aria-label="Adaptive Time-Domain Harmonic Control for Noise-Vibration-Harshness Reduction of Electric Drives"><a href=https://arxiv.org/abs/2512.04512v1>Adaptive Time-Domain Harmonic Control for Noise-Vibration-Harshness Reduction of Electric Drives</a></a></li><li><a href=#ultraimage-rethinking-resolution-extrapolation-in-image-diffusion-transformershttpsarxivorgabs251204504v1 aria-label="UltraImage: Rethinking Resolution Extrapolation in Image Diffusion Transformers"><a href=https://arxiv.org/abs/2512.04504v1>UltraImage: Rethinking Resolution Extrapolation in Image Diffusion Transformers</a></a></li><li><a href=#ai-assisted-game-management-decisions-a-fuzzy-logic-approach-to-real-time-substituitionshttpsarxivorgabs251204480v1 aria-label="AI-Assisted Game Management Decisions: A Fuzzy Logic Approach to Real-Time Substituitions"><a href=https://arxiv.org/abs/2512.04480v1>AI-Assisted Game Management Decisions: A Fuzzy Logic Approach to Real-Time Substituitions</a></a></li><li><a href=#quantum-accelerated-deep-reinforcement-learning-for-frequency-regulation-enhancementhttpsarxivorgabs251204439v1 aria-label="Quantum-Accelerated Deep Reinforcement Learning for Frequency Regulation Enhancement"><a href=https://arxiv.org/abs/2512.04439v1>Quantum-Accelerated Deep Reinforcement Learning for Frequency Regulation Enhancement</a></a></li><li><a href=#refuzz-reusing-tests-for-processor-fuzzing-with-contextual-banditshttpsarxivorgabs251204436v1 aria-label="ReFuzz: Reusing Tests for Processor Fuzzing with Contextual Bandits"><a href=https://arxiv.org/abs/2512.04436v1>ReFuzz: Reusing Tests for Processor Fuzzing with Contextual Bandits</a></a></li><li><a href=#self-paced-and-self-corrective-masked-prediction-for-movie-trailer-generationhttpsarxivorgabs251204426v1 aria-label="Self-Paced and Self-Corrective Masked Prediction for Movie Trailer Generation"><a href=https://arxiv.org/abs/2512.04426v1>Self-Paced and Self-Corrective Masked Prediction for Movie Trailer Generation</a></a></li><li><a href=#falcon-actively-decoupled-visuomotor-policies-for-loco-manipulation-with-foundation-model-based-coordinationhttpsarxivorgabs251204381v1 aria-label="FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination"><a href=https://arxiv.org/abs/2512.04381v1>FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination</a></a></li><li><a href=#mafnetmulti-frequency-adaptive-fusion-network-for-real-time-stereo-matchinghttpsarxivorgabs251204358v1 aria-label="MAFNet:Multi-frequency Adaptive Fusion Network for Real-time Stereo Matching"><a href=https://arxiv.org/abs/2512.04358v1>MAFNet:Multi-frequency Adaptive Fusion Network for Real-time Stereo Matching</a></a></li><li><a href=#ledds-portable-lbm-dem-simulations-on-gpushttpsarxivorgabs251204997v1 aria-label="LEDDS: Portable LBM-DEM simulations on GPUs"><a href=https://arxiv.org/abs/2512.04997v1>LEDDS: Portable LBM-DEM simulations on GPUs</a></a></li><li><a href=#amortized-inference-of-multi-modal-posteriors-using-likelihood-weighted-normalizing-flowshttpsarxivorgabs251204954v1 aria-label="Amortized Inference of Multi-Modal Posteriors using Likelihood-Weighted Normalizing Flows"><a href=https://arxiv.org/abs/2512.04954v1>Amortized Inference of Multi-Modal Posteriors using Likelihood-Weighted Normalizing Flows</a></a></li><li><a href=#towards-adaptive-fusion-of-multimodal-deep-networks-for-human-action-recognitionhttpsarxivorgabs251204943v1 aria-label="Towards Adaptive Fusion of Multimodal Deep Networks for Human Action Recognition"><a href=https://arxiv.org/abs/2512.04943v1>Towards Adaptive Fusion of Multimodal Deep Networks for Human Action Recognition</a></a></li><li><a href=#valley-splittings-in-sisige-heterostructures-from-first-principleshttpsarxivorgabs251204879v1 aria-label="Valley Splittings in Si/SiGe Heterostructures from First Principles"><a href=https://arxiv.org/abs/2512.04879v1>Valley Splittings in Si/SiGe Heterostructures from First Principles</a></a></li><li><a href=#the-single-differential-cross-sections-sdcs-for-h3s-ionization-in-the-first-born-approximation-by-electron-and-positron-impacthttpsarxivorgabs251204870v1 aria-label="The Single Differential Cross Sections (SDCS) for H(3s) Ionization in the First-Born Approximation by Electron and Positron Impact"><a href=https://arxiv.org/abs/2512.04870v1>The Single Differential Cross Sections (SDCS) for H(3s) Ionization in the First-Born Approximation by Electron and Positron Impact</a></a></li><li><a href=#optimal-transport-event-representation-for-anomaly-detectionhttpsarxivorgabs251204839v1 aria-label="Optimal Transport Event Representation for Anomaly Detection"><a href=https://arxiv.org/abs/2512.04839v1>Optimal Transport Event Representation for Anomaly Detection</a></a></li><li><a href=#model-based-and-sample-efficient-ai-assisted-math-discovery-in-sphere-packinghttpsarxivorgabs251204829v1 aria-label="Model-Based and Sample-Efficient AI-Assisted Math Discovery in Sphere Packing"><a href=https://arxiv.org/abs/2512.04829v1>Model-Based and Sample-Efficient AI-Assisted Math Discovery in Sphere Packing</a></a></li><li><a href=#small-signal-stability-oriented-real-time-operation-of-power-systems-with-a-high-penetration-of-inverter-based-resourceshttpsarxivorgabs251204892v1 aria-label="Small-Signal Stability Oriented Real-Time Operation of Power Systems with a High Penetration of Inverter-Based Resources"><a href=https://arxiv.org/abs/2512.04892v1>Small-Signal Stability Oriented Real-Time Operation of Power Systems with a High Penetration of Inverter-Based Resources</a></a></li><li><a href=#high-performance-dbmss-with-io_uring-when-and-how-to-use-ithttpsarxivorgabs251204859v1 aria-label="High-Performance DBMSs with io_uring: When and How to use it"><a href=https://arxiv.org/abs/2512.04859v1>High-Performance DBMSs with io_uring: When and How to use it</a></a></li><li><a href=#from-symptoms-to-systems-an-expert-guided-approach-to-understanding-risks-of-generative-ai-for-eating-disordershttpsarxivorgabs251204843v1 aria-label="From Symptoms to Systems: An Expert-Guided Approach to Understanding Risks of Generative AI for Eating Disorders"><a href=https://arxiv.org/abs/2512.04843v1>From Symptoms to Systems: An Expert-Guided Approach to Understanding Risks of Generative AI for Eating Disorders</a></a></li></ul></li><li><a href=#-neuroscience aria-label="üîç neuroscience">üîç neuroscience</a><ul><li><a href=#a-high-order-discretization-scheme-for-surface-integral-equations-for-analyzing-the-electroencephalography-forward-problemhttpsarxivorgabs251204845v1 aria-label="A High-Order Discretization Scheme for Surface Integral Equations for Analyzing the Electroencephalography Forward Problem"><a href=https://arxiv.org/abs/2512.04845v1>A High-Order Discretization Scheme for Surface Integral Equations for Analyzing the Electroencephalography Forward Problem</a></a></li><li><a href=#plug-and-play-homeostatic-spark-zero-cost-acceleration-for-snn-training-across-paradigmshttpsarxivorgabs251205015v1 aria-label="Plug-and-Play Homeostatic Spark: Zero-Cost Acceleration for SNN Training Across Paradigms"><a href=https://arxiv.org/abs/2512.05015v1>Plug-and-Play Homeostatic Spark: Zero-Cost Acceleration for SNN Training Across Paradigms</a></a></li><li><a href=#the-clifford-defect-of-a-numerical-semigrouphttpsarxivorgabs251204925v1 aria-label="The Clifford defect of a numerical semigroup"><a href=https://arxiv.org/abs/2512.04925v1>The Clifford defect of a numerical semigroup</a></a></li><li><a href=#a-result-relating-convex-n-widths-to-covering-numbers-with-some-applications-to-neural-networkshttpsarxivorgabs251204912v1 aria-label="A result relating convex n-widths to covering numbers with some applications to neural networks"><a href=https://arxiv.org/abs/2512.04912v1>A result relating convex n-widths to covering numbers with some applications to neural networks</a></a></li><li><a href=#data-driven-methods-for-delay-differential-equationshttpsarxivorgabs251204894v1 aria-label="Data-driven Methods for Delay Differential Equations"><a href=https://arxiv.org/abs/2512.04894v1>Data-driven Methods for Delay Differential Equations</a></a></li><li><a href=#pick-to-learn-for-systems-and-control-data-driven-synthesis-with-state-of-the-art-safety-guaranteeshttpsarxivorgabs251204781v1 aria-label="Pick-to-Learn for Systems and Control: Data-driven Synthesis with State-of-the-art Safety Guarantees"><a href=https://arxiv.org/abs/2512.04781v1>Pick-to-Learn for Systems and Control: Data-driven Synthesis with State-of-the-art Safety Guarantees</a></a></li><li><a href=#demonstration-of-surface-engineered-oxidation-resistant-nb-nb-thermocompression-bonding-toward-scalable-superconducting-quantum-computing-architectureshttpsarxivorgabs251204712v1 aria-label="Demonstration of surface-engineered oxidation-resistant Nb-Nb thermocompression bonding toward scalable superconducting quantum computing architectures"><a href=https://arxiv.org/abs/2512.04712v1>Demonstration of surface-engineered oxidation-resistant Nb-Nb thermocompression bonding toward scalable superconducting quantum computing architectures</a></a></li><li><a href=#interface-layers-and-coupling-conditions-for-discrete-kinetic-models-on-networks-a-spectral-approachttpsarxivorgabs251204634v1 aria-label="Interface layers and coupling conditions for discrete kinetic models on networks: a spectral approac"><a href=https://arxiv.org/abs/2512.04634v1>Interface layers and coupling conditions for discrete kinetic models on networks: a spectral approac</a></a></li><li><a href=#on-the-construction-of-high-order-and-exact-pressure-equilibrium-schemes-for-arbitrary-equations-of-statehttpsarxivorgabs251204450v1 aria-label="On the Construction of High-Order and Exact Pressure Equilibrium Schemes for Arbitrary Equations of State"><a href=https://arxiv.org/abs/2512.04450v1>On the Construction of High-Order and Exact Pressure Equilibrium Schemes for Arbitrary Equations of State</a></a></li><li><a href=#uncertainty-quantification-of-the-fresh-saltwater-interface-from-time-domain-electromagnetic-datahttpsarxivorgabs251204437v1 aria-label="Uncertainty Quantification of the Fresh-Saltwater Interface from Time-Domain Electromagnetic Data"><a href=https://arxiv.org/abs/2512.04437v1>Uncertainty Quantification of the Fresh-Saltwater Interface from Time-Domain Electromagnetic Data</a></a></li><li><a href=#toward-enhanced-inertial-sensing-via-dynamically-soft-topological-states-in-piezoelectric-microacoustic-metamaterialshttpsarxivorgabs251204382v1 aria-label="Toward Enhanced Inertial Sensing via Dynamically Soft Topological States in Piezoelectric Microacoustic Metamaterials"><a href=https://arxiv.org/abs/2512.04382v1>Toward Enhanced Inertial Sensing via Dynamically Soft Topological States in Piezoelectric Microacoustic Metamaterials</a></a></li><li><a href=#smartalert-implementing-machine-learning-driven-clinical-decision-support-for-inpatient-lab-utilization-reductionhttpsarxivorgabs251204354v1 aria-label="SmartAlert: Implementing Machine Learning-Driven Clinical Decision Support for Inpatient Lab Utilization Reduction"><a href=https://arxiv.org/abs/2512.04354v1>SmartAlert: Implementing Machine Learning-Driven Clinical Decision Support for Inpatient Lab Utilization Reduction</a></a></li><li><a href=#collective-adsorption-of-pheromones-at-the-water-air-interfacehttpsarxivorgabs251204340v1 aria-label="Collective adsorption of pheromones at the water-air interface"><a href=https://arxiv.org/abs/2512.04340v1>Collective adsorption of pheromones at the water-air interface</a></a></li><li><a href=#consentdiff-at-scale-longitudinal-audits-of-web-privacy-policy-changes-and-ui-frictionshttpsarxivorgabs251204316v1 aria-label="ConsentDiff at Scale: Longitudinal Audits of Web Privacy Policy Changes and UI Frictions"><a href=https://arxiv.org/abs/2512.04316v1>ConsentDiff at Scale: Longitudinal Audits of Web Privacy Policy Changes and UI Frictions</a></a></li><li><a href=#enhancing-solar-cell-efficiency-of-alxin1-xnsi-heterojunctions-using-an-a-si-buffer-a-study-of-material-interface-and-device-propertieshttpsarxivorgabs251204243v1 aria-label="Enhancing solar cell efficiency of AlxIn1-xN/Si heterojunctions using an a-Si buffer: A study of material, interface and device properties"><a href=https://arxiv.org/abs/2512.04243v1>Enhancing solar cell efficiency of AlxIn1-xN/Si heterojunctions using an a-Si buffer: A study of material, interface and device properties</a></a></li><li><a href=#maestro-intelligent-execution-for-quantum-circuit-simulationhttpsarxivorgabs251204216v1 aria-label="Maestro: Intelligent Execution for Quantum Circuit Simulation"><a href=https://arxiv.org/abs/2512.04216v1>Maestro: Intelligent Execution for Quantum Circuit Simulation</a></a></li><li><a href=#configurable-antiferromagnetic-domains-and-lateral-exchange-bias-in-atomically-thin-crps4httpsarxivorgabs251204055v1 aria-label="Configurable antiferromagnetic domains and lateral exchange bias in atomically thin CrPS4"><a href=https://arxiv.org/abs/2512.04055v1>Configurable antiferromagnetic domains and lateral exchange bias in atomically thin CrPS4</a></a></li><li><a href=#affordances-of-digital-and-blockchain-based-community-currencies-the-case-of-sarafu-network-in-kenyahttpsarxivorgabs251204030v1 aria-label="Affordances of Digital and Blockchain-based Community Currencies: The Case of Sarafu Network in Kenya"><a href=https://arxiv.org/abs/2512.04030v1>Affordances of Digital and Blockchain-based Community Currencies: The Case of Sarafu Network in Kenya</a></a></li><li><a href=#negative-index-makes-a-perfect-time-domain-lens-generating-slow-playback-of-ultrafast-eventshttpsarxivorgabs251203985v1 aria-label="Negative Index Makes a Perfect Time-Domain Lens, Generating Slow Playback of Ultrafast Events"><a href=https://arxiv.org/abs/2512.03985v1>Negative Index Makes a Perfect Time-Domain Lens, Generating Slow Playback of Ultrafast Events</a></a></li><li><a href=#benchmark-for-planning-and-control-with-large-language-model-agents-blocksworld-with-model-context-protocolhttpsarxivorgabs251203955v1 aria-label="Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol"><a href=https://arxiv.org/abs/2512.03955v1>Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol</a></a></li><li><a href=#modelling-the-impact-of-device-imperfections-on-electron-shuttling-in-simos-deviceshttpsarxivorgabs251203853v1 aria-label="Modelling the Impact of Device Imperfections on Electron Shuttling in SiMOS devices"><a href=https://arxiv.org/abs/2512.03853v1>Modelling the Impact of Device Imperfections on Electron Shuttling in SiMOS devices</a></a></li><li><a href=#shell-formation-and-two-dimensional-nanofriction-in-three-dimensional-ion-coulomb-crystalshttpsarxivorgabs251203833v2 aria-label="Shell formation and two-dimensional nanofriction in three-dimensional ion Coulomb crystals"><a href=https://arxiv.org/abs/2512.03833v2>Shell formation and two-dimensional nanofriction in three-dimensional ion Coulomb crystals</a></a></li><li><a href=#terahertz-emission-from-interdigitated-photoconductive-antennas-based-on-ge-on-sihttpsarxivorgabs251203820v1 aria-label="Terahertz emission from interdigitated photoconductive antennas based on Ge-on-Si"><a href=https://arxiv.org/abs/2512.03820v1>Terahertz emission from interdigitated photoconductive antennas based on Ge-on-Si</a></a></li><li><a href=#interfacial-control-of-orbital-occupancy-and-spin-state-in-lacoo_3httpsarxivorgabs251203785v1 aria-label="Interfacial Control of Orbital Occupancy and Spin State in LaCoO$_3$"><a href=https://arxiv.org/abs/2512.03785v1>Interfacial Control of Orbital Occupancy and Spin State in LaCoO$_3$</a></a></li><li><a href=#mcp-does-not-stand-for-misuse-cryptography-protocol-uncovering-cryptographic-misuse-in-model-context-protocol-at-scalehttpsarxivorgabs251203775v1 aria-label="&ldquo;MCP Does Not Stand for Misuse Cryptography Protocol&rdquo;: Uncovering Cryptographic Misuse in Model Context Protocol at Scale"><a href=https://arxiv.org/abs/2512.03775v1>&ldquo;MCP Does Not Stand for Misuse Cryptography Protocol&rdquo;: Uncovering Cryptographic Misuse in Model Context Protocol at Scale</a></a></li><li><a href=#thinking-with-programming-vision-towards-a-unified-view-for-thinking-with-imageshttpsarxivorgabs251203746v1 aria-label="Thinking with Programming Vision: Towards a Unified View for Thinking with Images"><a href=https://arxiv.org/abs/2512.03746v1>Thinking with Programming Vision: Towards a Unified View for Thinking with Images</a></a></li><li><a href=#revealing-nanoscale-molecular-organization-in-liquid-crystals-via-cryogenic-atom-probe-tomographhttpsarxivorgabs251203734v1 aria-label="Revealing Nanoscale Molecular Organization in Liquid Crystals via Cryogenic Atom Probe Tomograph"><a href=https://arxiv.org/abs/2512.03734v1>Revealing Nanoscale Molecular Organization in Liquid Crystals via Cryogenic Atom Probe Tomograph</a></a></li><li><a href=#generative-ai-practices-literacy-and-divides-an-empirical-analysis-in-the-italian-contexthttpsarxivorgabs251203671v1 aria-label="Generative AI Practices, Literacy, and Divides: An Empirical Analysis in the Italian Context"><a href=https://arxiv.org/abs/2512.03671v1>Generative AI Practices, Literacy, and Divides: An Empirical Analysis in the Italian Context</a></a></li><li><a href=#lamp-language-assisted-motion-planning-for-controllable-video-generationhttpsarxivorgabs251203619v1 aria-label="LAMP: Language-Assisted Motion Planning for Controllable Video Generation"><a href=https://arxiv.org/abs/2512.03619v1>LAMP: Language-Assisted Motion Planning for Controllable Video Generation</a></a></li><li><a href=#hamiltonian-active-matter-in-incompressible-fluid-membraneshttpsarxivorgabs251203609v1 aria-label="Hamiltonian Active Matter in Incompressible Fluid Membranes"><a href=https://arxiv.org/abs/2512.03609v1>Hamiltonian Active Matter in Incompressible Fluid Membranes</a></a></li><li><a href=#a-convolutional-framework-for-mapping-imagined-auditory-meg-into-listened-brain-responseshttpsarxivorgabs251203458v1 aria-label="A Convolutional Framework for Mapping Imagined Auditory MEG into Listened Brain Responses"><a href=https://arxiv.org/abs/2512.03458v1>A Convolutional Framework for Mapping Imagined Auditory MEG into Listened Brain Responses</a></a></li><li><a href=#enterprise-data-science-platform-a-unified-architecture-for-federated-data-accesshttpsarxivorgabs251203401v1 aria-label="Enterprise Data Science Platform: A Unified Architecture for Federated Data Access"><a href=https://arxiv.org/abs/2512.03401v1>Enterprise Data Science Platform: A Unified Architecture for Federated Data Access</a></a></li><li><a href=#push-broom-mapping-of-galaxies-and-supernova-remnants-with-the-sprite-cubesathttpsarxivorgabs251203329v1 aria-label="Push-broom Mapping of Galaxies and Supernova Remnants with the SPRITE CubeSat"><a href=https://arxiv.org/abs/2512.03329v1>Push-broom Mapping of Galaxies and Supernova Remnants with the SPRITE CubeSat</a></a></li><li><a href=#dawzy-a-new-addition-to-ai-powered-human-in-the-loop-music-co-creationhttpsarxivorgabs251203289v1 aria-label="DAWZY: A New Addition to AI powered &ldquo;Human in the Loop&rdquo; Music Co-creation"><a href=https://arxiv.org/abs/2512.03289v1>DAWZY: A New Addition to AI powered &ldquo;Human in the Loop&rdquo; Music Co-creation</a></a></li><li><a href=#tunable-thin-elasto-dropshttpsarxivorgabs251203218v1 aria-label="Tunable Thin Elasto-Drops"><a href=https://arxiv.org/abs/2512.03218v1>Tunable Thin Elasto-Drops</a></a></li><li><a href=#digital-alloy-based-bragg-mirrors-in-high-q-microcavities-for-polariton-lasinghttpsarxivorgabs251203203v1 aria-label="Digital-Alloy-Based Bragg Mirrors in High-Q Microcavities for Polariton Lasing"><a href=https://arxiv.org/abs/2512.03203v1>Digital-Alloy-Based Bragg Mirrors in High-Q Microcavities for Polariton Lasing</a></a></li><li><a href=#interfacial-thermal-conductance-between-a-polyethylene-glycol-polymer-chain-and-water-a-molecular-dynamics-studyhttpsarxivorgabs251203174v1 aria-label="Interfacial Thermal Conductance Between a Polyethylene Glycol Polymer Chain and Water: A Molecular Dynamics Study"><a href=https://arxiv.org/abs/2512.03174v1>Interfacial Thermal Conductance Between a Polyethylene Glycol Polymer Chain and Water: A Molecular Dynamics Study</a></a></li><li><a href=#energy-reflection-and-transmission-of-interfaces-in-tbart-deformed-cfthttpsarxivorgabs251203167v1 aria-label="Energy Reflection and Transmission of Interfaces in $T\bar{T}$-deformed CFT"><a href=https://arxiv.org/abs/2512.03167v1>Energy Reflection and Transmission of Interfaces in $T\bar{T}$-deformed CFT</a></a></li><li><a href=#a-wind-driven-origin-for-the-firework-morphology-of-the-supernova-remnant-pa-30httpsarxivorgabs251203140v1 aria-label="A Wind-Driven Origin for the Firework Morphology of the Supernova Remnant Pa 30"><a href=https://arxiv.org/abs/2512.03140v1>A Wind-Driven Origin for the Firework Morphology of the Supernova Remnant Pa 30</a></a></li></ul></li><li><a href=#-data_resources aria-label="üîç data_resources">üîç data_resources</a><ul><li><a href=#configuration-defects-in-kuberneteshttpsarxivorgabs251205062v1 aria-label="Configuration Defects in Kubernetes"><a href=https://arxiv.org/abs/2512.05062v1>Configuration Defects in Kubernetes</a></a></li><li><a href=#reflexflow-rethinking-learning-objective-for-exposure-bias-alleviation-in-flow-matchinghttpsarxivorgabs251204904v1 aria-label="ReflexFlow: Rethinking Learning Objective for Exposure Bias Alleviation in Flow Matching"><a href=https://arxiv.org/abs/2512.04904v1>ReflexFlow: Rethinking Learning Objective for Exposure Bias Alleviation in Flow Matching</a></a></li><li><a href=#equivariant-symmetry-aware-head-pose-estimation-for-fetal-mrihttpsarxivorgabs251204890v1 aria-label="Equivariant Symmetry-Aware Head Pose Estimation for Fetal MRI"><a href=https://arxiv.org/abs/2512.04890v1>Equivariant Symmetry-Aware Head Pose Estimation for Fetal MRI</a></a></li><li><a href=#contact-aware-refinement-of-human-pose-pseudo-ground-truth-via-bioimpedance-sensinghttpsarxivorgabs251204862v1 aria-label="Contact-Aware Refinement of Human Pose Pseudo-Ground Truth via Bioimpedance Sensing"><a href=https://arxiv.org/abs/2512.04862v1>Contact-Aware Refinement of Human Pose Pseudo-Ground Truth via Bioimpedance Sensing</a></a></li><li><a href=#freegen-feed-forward-reconstruction-generation-co-training-for-free-viewpoint-driving-scene-synthesishttpsarxivorgabs251204830v1 aria-label="FreeGen: Feed-Forward Reconstruction-Generation Co-Training for Free-Viewpoint Driving Scene Synthesis"><a href=https://arxiv.org/abs/2512.04830v1>FreeGen: Feed-Forward Reconstruction-Generation Co-Training for Free-Viewpoint Driving Scene Synthesis</a></a></li><li><a href=#move-a-simple-motion-based-data-collection-paradigm-for-spatial-generalization-in-robotic-manipulationhttpsarxivorgabs251204813v1 aria-label="MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation"><a href=https://arxiv.org/abs/2512.04813v1>MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation</a></a></li><li><a href=#towards-predicting-binaural-audio-quality-in-listeners-with-normal-and-impaired-hearinghttpsarxivorgabs251204792v1 aria-label="Towards predicting binaural audio quality in listeners with normal and impaired hearing"><a href=https://arxiv.org/abs/2512.04792v1>Towards predicting binaural audio quality in listeners with normal and impaired hearing</a></a></li><li><a href=#sarcasm-detection-on-reddit-using-classical-machine-learning-and-feature-engineeringhttpsarxivorgabs251204396v1 aria-label="Sarcasm Detection on Reddit Using Classical Machine Learning and Feature Engineering"><a href=https://arxiv.org/abs/2512.04396v1>Sarcasm Detection on Reddit Using Classical Machine Learning and Feature Engineering</a></a></li><li><a href=#tempr1-improving-temporal-understanding-of-mllms-via-temporal-aware-multi-task-reinforcement-learninghttpsarxivorgabs251203963v2 aria-label="TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning"><a href=https://arxiv.org/abs/2512.03963v2>TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning</a></a></li><li><a href=#state-space-models-for-bioacoustics-a-comparative-evaluation-with-transformershttpsarxivorgabs251203563v1 aria-label="State Space Models for Bioacoustics: A comparative Evaluation with Transformers"><a href=https://arxiv.org/abs/2512.03563v1>State Space Models for Bioacoustics: A comparative Evaluation with Transformers</a></a></li><li><a href=#pretrainzero-reinforcement-active-pretraininghttpsarxivorgabs251203442v1 aria-label="PretrainZero: Reinforcement Active Pretraining"><a href=https://arxiv.org/abs/2512.03442v1>PretrainZero: Reinforcement Active Pretraining</a></a></li><li><a href=#characterizing-language-use-in-a-collaborative-situated-gamehttpsarxivorgabs251203381v1 aria-label="Characterizing Language Use in a Collaborative Situated Game"><a href=https://arxiv.org/abs/2512.03381v1>Characterizing Language Use in a Collaborative Situated Game</a></a></li><li><a href=#onethinker-all-in-one-reasoning-model-for-image-and-videohttpsarxivorgabs251203043v2 aria-label="OneThinker: All-in-one Reasoning Model for Image and Video"><a href=https://arxiv.org/abs/2512.03043v2>OneThinker: All-in-one Reasoning Model for Image and Video</a></a></li><li><a href=#ezyer-a-simulacrum-of-high-school-with-generative-agenthttpsarxivorgabs251202561v1 aria-label="EZYer: A simulacrum of high school with generative agent"><a href=https://arxiv.org/abs/2512.02561v1>EZYer: A simulacrum of high school with generative agent</a></a></li><li><a href=#statistical-properties-of-the-rooted-tree-encoding-of-mathbbnhttpsarxivorgabs251201436v1 aria-label="Statistical Properties of the Rooted-Tree Encoding of $\mathbb{N}$"><a href=https://arxiv.org/abs/2512.01436v1>Statistical Properties of the Rooted-Tree Encoding of $\mathbb{N}$</a></a></li><li><a href=#knowledge-graph-augmented-large-language-models-for-disease-predictionhttpsarxivorgabs251201210v2 aria-label="Knowledge Graph Augmented Large Language Models for Disease Prediction"><a href=https://arxiv.org/abs/2512.01210v2>Knowledge Graph Augmented Large Language Models for Disease Prediction</a></a></li><li><a href=#a-practical-algorithm-for-3-admissibilityhttpsarxivorgabs251201121v1 aria-label="A practical algorithm for 3-admissibility"><a href=https://arxiv.org/abs/2512.01121v1>A practical algorithm for 3-admissibility</a></a></li><li><a href=#when-safety-blocks-sense-measuring-semantic-confusion-in-llm-refusalshttpsarxivorgabs251201037v1 aria-label="When Safety Blocks Sense: Measuring Semantic Confusion in LLM Refusals"><a href=https://arxiv.org/abs/2512.01037v1>When Safety Blocks Sense: Measuring Semantic Confusion in LLM Refusals</a></a></li><li><a href=#measuring-the-unspoken-a-disentanglement-model-and-benchmark-for-psychological-analysis-in-the-wildhttpsarxivorgabs251204728v1 aria-label="Measuring the Unspoken: A Disentanglement Model and Benchmark for Psychological Analysis in the Wild"><a href=https://arxiv.org/abs/2512.04728v1>Measuring the Unspoken: A Disentanglement Model and Benchmark for Psychological Analysis in the Wild</a></a></li><li><a href=#malicious-image-analysis-via-vision-language-segmentation-fusion-detection-element-and-location-in-one-shothttpsarxivorgabs251204599v1 aria-label="Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot"><a href=https://arxiv.org/abs/2512.04599v1>Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot</a></a></li><li><a href=#dataset-creation-for-supervised-deep-learning-based-analysis-of-microscopic-images----review-of-important-considerations-and-recommendationshttpsarxivorgabs251204564v1 aria-label="Dataset creation for supervised deep learning-based analysis of microscopic images &ndash; review of important considerations and recommendations"><a href=https://arxiv.org/abs/2512.04564v1>Dataset creation for supervised deep learning-based analysis of microscopic images &ndash; review of important considerations and recommendations</a></a></li><li><a href=#multi-loss-learning-for-speech-emotion-recognition-with-energy-adaptive-mixup-and-frame-level-attentionhttpsarxivorgabs251204551v1 aria-label="Multi-Loss Learning for Speech Emotion Recognition with Energy-Adaptive Mixup and Frame-Level Attention"><a href=https://arxiv.org/abs/2512.04551v1>Multi-Loss Learning for Speech Emotion Recognition with Energy-Adaptive Mixup and Frame-Level Attention</a></a></li><li><a href=#phyvllm-physics-guided-video-language-model-with-motion-appearance-disentanglementhttpsarxivorgabs251204532v1 aria-label="PhyVLLM: Physics-Guided Video Language Model with Motion-Appearance Disentanglement"><a href=https://arxiv.org/abs/2512.04532v1>PhyVLLM: Physics-Guided Video Language Model with Motion-Appearance Disentanglement</a></a></li><li><a href=#boundary-aware-test-time-adaptation-for-zero-shot-medical-image-segmentationhttpsarxivorgabs251204520v1 aria-label="Boundary-Aware Test-Time Adaptation for Zero-Shot Medical Image Segmentation"><a href=https://arxiv.org/abs/2512.04520v1>Boundary-Aware Test-Time Adaptation for Zero-Shot Medical Image Segmentation</a></a></li><li><a href=#automating-complex-document-workflows-via-stepwise-and-rollback-enabled-operation-orchestrationhttpsarxivorgabs251204445v1 aria-label="Automating Complex Document Workflows via Stepwise and Rollback-Enabled Operation Orchestration"><a href=https://arxiv.org/abs/2512.04445v1>Automating Complex Document Workflows via Stepwise and Rollback-Enabled Operation Orchestration</a></a></li><li><a href=#counting-without-running-evaluating-llms-reasoning-about-code-complexityhttpsarxivorgabs251204355v1 aria-label="Counting Without Running: Evaluating LLMs&rsquo; Reasoning About Code Complexity"><a href=https://arxiv.org/abs/2512.04355v1>Counting Without Running: Evaluating LLMs&rsquo; Reasoning About Code Complexity</a></a></li><li><a href=#gamma-from-mono-road-relative-metric-self-supervised-monocular-geometry-for-vehicular-applicationshttpsarxivorgabs251204303v1 aria-label="Gamma-from-Mono: Road-Relative, Metric, Self-Supervised Monocular Geometry for Vehicular Applications"><a href=https://arxiv.org/abs/2512.04303v1>Gamma-from-Mono: Road-Relative, Metric, Self-Supervised Monocular Geometry for Vehicular Applications</a></a></li><li><a href=#educational-cone-model-in-embedding-vector-spaceshttpsarxivorgabs251204227v1 aria-label="Educational Cone Model in Embedding Vector Spaces"><a href=https://arxiv.org/abs/2512.04227v1>Educational Cone Model in Embedding Vector Spaces</a></a></li><li><a href=#moregen-multi-agent-motion-reasoning-engine-for-code-based-text-to-video-synthesishttpsarxivorgabs251204221v1 aria-label="MoReGen: Multi-Agent Motion-Reasoning Engine for Code-based Text-to-Video Synthesis"><a href=https://arxiv.org/abs/2512.04221v1>MoReGen: Multi-Agent Motion-Reasoning Engine for Code-based Text-to-Video Synthesis</a></a></li><li><a href=#fast--efficient-normalizing-flows-and-applications-of-image-generative-modelshttpsarxivorgabs251204039v1 aria-label="Fast & Efficient Normalizing Flows and Applications of Image Generative Models"><a href=https://arxiv.org/abs/2512.04039v1>Fast & Efficient Normalizing Flows and Applications of Image Generative Models</a></a></li><li><a href=#diq-h-evaluating-hallucination-persistence-in-vlms-under-temporal-visual-degradationhttpsarxivorgabs251203992v1 aria-label="DIQ-H: Evaluating Hallucination Persistence in VLMs Under Temporal Visual Degradation"><a href=https://arxiv.org/abs/2512.03992v1>DIQ-H: Evaluating Hallucination Persistence in VLMs Under Temporal Visual Degradation</a></a></li><li><a href=#classification-of-user-satisfaction-in-hri-with-social-signals-in-the-wildhttpsarxivorgabs251203945v1 aria-label="Classification of User Satisfaction in HRI with Social Signals in the Wild"><a href=https://arxiv.org/abs/2512.03945v1>Classification of User Satisfaction in HRI with Social Signals in the Wild</a></a></li><li><a href=#fully-unsupervised-self-debiasing-of-text-to-image-diffusion-modelshttpsarxivorgabs251203749v1 aria-label="Fully Unsupervised Self-debiasing of Text-to-Image Diffusion Models"><a href=https://arxiv.org/abs/2512.03749v1>Fully Unsupervised Self-debiasing of Text-to-Image Diffusion Models</a></a></li><li><a href=#aitutor-evalkit-exploring-the-capabilities-of-ai-tutorshttpsarxivorgabs251203688v1 aria-label="AITutor-EvalKit: Exploring the Capabilities of AI Tutors"><a href=https://arxiv.org/abs/2512.03688v1>AITutor-EvalKit: Exploring the Capabilities of AI Tutors</a></a></li><li><a href=#colon-x-advancing-intelligent-colonoscopy-from-multimodal-understanding-to-clinical-reasoninghttpsarxivorgabs251203667v1 aria-label="Colon-X: Advancing Intelligent Colonoscopy from Multimodal Understanding to Clinical Reasoning"><a href=https://arxiv.org/abs/2512.03667v1>Colon-X: Advancing Intelligent Colonoscopy from Multimodal Understanding to Clinical Reasoning</a></a></li><li><a href=#tog-bench-task-oriented-spatio-temporal-grounding-in-egocentric-videoshttpsarxivorgabs251203666v1 aria-label="ToG-Bench: Task-Oriented Spatio-Temporal Grounding in Egocentric Videos"><a href=https://arxiv.org/abs/2512.03666v1>ToG-Bench: Task-Oriented Spatio-Temporal Grounding in Egocentric Videos</a></a></li><li><a href=#when-how-long-and-how-much-interpretable-neural-networks-for-time-series-regression-by-learning-to-mask-and-aggregatehttpsarxivorgabs251203578v1 aria-label="When, How Long and How Much? Interpretable Neural Networks for Time Series Regression by Learning to Mask and Aggregate"><a href=https://arxiv.org/abs/2512.03578v1>When, How Long and How Much? Interpretable Neural Networks for Time Series Regression by Learning to Mask and Aggregate</a></a></li><li><a href=#afrobeats-dance-movement-analysis-using-computer-vision-a-proof-of-concept-framework-combining-yolo-and-segment-anything-modelhttpsarxivorgabs251203509v1 aria-label="AfroBeats Dance Movement Analysis Using Computer Vision: A Proof-of-Concept Framework Combining YOLO and Segment Anything Model"><a href=https://arxiv.org/abs/2512.03509v1>AfroBeats Dance Movement Analysis Using Computer Vision: A Proof-of-Concept Framework Combining YOLO and Segment Anything Model</a></a></li><li><a href=#think-before-you-drive-world-model-inspired-multimodal-grounding-for-autonomous-vehicleshttpsarxivorgabs251203454v1 aria-label="Think Before You Drive: World Model-Inspired Multimodal Grounding for Autonomous Vehicles"><a href=https://arxiv.org/abs/2512.03454v1>Think Before You Drive: World Model-Inspired Multimodal Grounding for Autonomous Vehicles</a></a></li><li><a href=#multi-aspect-knowledge-enhanced-medical-vision-language-pretraining-with-multi-agent-data-generationhttpsarxivorgabs251203445v1 aria-label="Multi-Aspect Knowledge-Enhanced Medical Vision-Language Pretraining with Multi-Agent Data Generation"><a href=https://arxiv.org/abs/2512.03445v1>Multi-Aspect Knowledge-Enhanced Medical Vision-Language Pretraining with Multi-Agent Data Generation</a></a></li><li><a href=#2bnirs-a-portable-multi-distance-broadband-oximeter-and-cytochrome-c-oxidase-monitoring-system-for-in-vivo-applicationshttpsarxivorgabs251204787v1 aria-label="2bNIRS: a portable, multi-distance, broadband oximeter and cytochrome-c-oxidase monitoring system for in vivo applications"><a href=https://arxiv.org/abs/2512.04787v1>2bNIRS: a portable, multi-distance, broadband oximeter and cytochrome-c-oxidase monitoring system for in vivo applications</a></a></li><li><a href=#lafite-a-generative-latent-field-for-3d-native-texturinghttpsarxivorgabs251204786v1 aria-label="LaFiTe: A Generative Latent Field for 3D Native Texturing"><a href=https://arxiv.org/abs/2512.04786v1>LaFiTe: A Generative Latent Field for 3D Native Texturing</a></a></li><li><a href=#tempo-vine-a-multi-temporal-sensor-fusion-dataset-for-localization-and-mapping-in-vineyardshttpsarxivorgabs251204772v1 aria-label="TEMPO-VINE: A Multi-Temporal Sensor Fusion Dataset for Localization and Mapping in Vineyards"><a href=https://arxiv.org/abs/2512.04772v1>TEMPO-VINE: A Multi-Temporal Sensor Fusion Dataset for Localization and Mapping in Vineyards</a></a></li><li><a href=#customer-identification-for-electricity-retailers-based-on-monthly-demand-profiles-by-activity-sectors-and-locationshttpsarxivorgabs251204776v1 aria-label="Customer Identification for Electricity Retailers Based on Monthly Demand Profiles by Activity Sectors and Locations"><a href=https://arxiv.org/abs/2512.04776v1>Customer Identification for Electricity Retailers Based on Monthly Demand Profiles by Activity Sectors and Locations</a></a></li><li><a href=#complementary-characterization-of-agent-based-models-via-computational-mechanics-and-diffusion-modelshttpsarxivorgabs251204771v1 aria-label="Complementary Characterization of Agent-Based Models via Computational Mechanics and Diffusion Models"><a href=https://arxiv.org/abs/2512.04771v1>Complementary Characterization of Agent-Based Models via Computational Mechanics and Diffusion Models</a></a></li></ul></li><li><a href=#-emotion_language aria-label="üîç emotion_language">üîç emotion_language</a><ul><li><a href=#a-sanity-check-for-multi-in-domain-face-forgery-detection-in-the-real-worldhttpsarxivorgabs251204837v1 aria-label="A Sanity Check for Multi-In-Domain Face Forgery Detection in the Real World"><a href=https://arxiv.org/abs/2512.04837v1>A Sanity Check for Multi-In-Domain Face Forgery Detection in the Real World</a></a></li><li><a href=#unveiling-gravitational-waves-from-core-collapse-supernovae-with-musehttpsarxivorgabs251204804v1 aria-label="Unveiling gravitational waves from core-collapse supernovae with MUSE"><a href=https://arxiv.org/abs/2512.04804v1>Unveiling gravitational waves from core-collapse supernovae with MUSE</a></a></li><li><a href=#graded-algebras-with-homogeneous-involution-and-varieties-of-almost-polynomial-growthhttpsarxivorgabs251204769v1 aria-label="Graded algebras with homogeneous involution and varieties of almost polynomial growth"><a href=https://arxiv.org/abs/2512.04769v1>Graded algebras with homogeneous involution and varieties of almost polynomial growth</a></a></li><li><a href=#score-matching-for-estimating-finite-point-processeshttpsarxivorgabs251204617v1 aria-label="Score Matching for Estimating Finite Point Processes"><a href=https://arxiv.org/abs/2512.04617v1>Score Matching for Estimating Finite Point Processes</a></a></li><li><a href=#standard-audiogram-classification-from-loudness-scaling-data-using-unsupervised-supervised-and-explainable-machine-learning-techniqueshttpsarxivorgabs251204616v1 aria-label="Standard audiogram classification from loudness scaling data using unsupervised, supervised, and explainable machine learning techniques"><a href=https://arxiv.org/abs/2512.04616v1>Standard audiogram classification from loudness scaling data using unsupervised, supervised, and explainable machine learning techniques</a></a></li><li><a href=#mode-interactions-in-scalar-field-cosmologyhttpsarxivorgabs251204607v1 aria-label="Mode interactions in scalar field cosmology"><a href=https://arxiv.org/abs/2512.04607v1>Mode interactions in scalar field cosmology</a></a></li><li><a href=#exploiting-textttftraces-textttfunction_graph-tracer-features-for-machine-learning-a-case-study-on-encryption-detectionhttpsarxivorgabs251204590v1 aria-label="Exploiting \texttt{ftrace}&rsquo;s \texttt{function_graph} Tracer Features for Machine Learning: A Case Study on Encryption Detection"><a href=https://arxiv.org/abs/2512.04590v1>Exploiting \texttt{ftrace}&rsquo;s \texttt{function_graph} Tracer Features for Machine Learning: A Case Study on Encryption Detection</a></a></li><li><a href=#an-all-optical-convolutional-neural-network-for-image-identificationhttpsarxivorgabs251204569v1 aria-label="An all-optical convolutional neural network for image identification"><a href=https://arxiv.org/abs/2512.04569v1>An all-optical convolutional neural network for image identification</a></a></li><li><a href=#reflection-of-nichols-algebras-over-coquasi-hopf-algebrashttpsarxivorgabs251204560v1 aria-label="Reflection of Nichols Algebras over Coquasi-Hopf Algebras"><a href=https://arxiv.org/abs/2512.04560v1>Reflection of Nichols Algebras over Coquasi-Hopf Algebras</a></a></li><li><a href=#efficient-identification-the-inequivalence-of-mutually-unbiased-bases-via-finite-operatorshttpsarxivorgabs251204543v1 aria-label="Efficient Identification the Inequivalence of Mutually Unbiased Bases via Finite Operators"><a href=https://arxiv.org/abs/2512.04543v1>Efficient Identification the Inequivalence of Mutually Unbiased Bases via Finite Operators</a></a></li><li><a href=#detection-of-intoxicated-individuals-from-facial-video-sequences-via-a-recurrent-fusion-modelhttpsarxivorgabs251204536v1 aria-label="Detection of Intoxicated Individuals from Facial Video Sequences via a Recurrent Fusion Model"><a href=https://arxiv.org/abs/2512.04536v1>Detection of Intoxicated Individuals from Facial Video Sequences via a Recurrent Fusion Model</a></a></li><li><a href=#rge-gcn-recursive-gene-elimination-with-graph-convolutional-networks-for-rna-seq-based-early-cancer-detectionhttpsarxivorgabs251204333v1 aria-label="RGE-GCN: Recursive Gene Elimination with Graph Convolutional Networks for RNA-seq based Early Cancer Detection"><a href=https://arxiv.org/abs/2512.04333v1>RGE-GCN: Recursive Gene Elimination with Graph Convolutional Networks for RNA-seq based Early Cancer Detection</a></a></li><li><a href=#open-set-face-forgery-detection-via-dual-level-evidence-collectionhttpsarxivorgabs251204331v1 aria-label="Open Set Face Forgery Detection via Dual-Level Evidence Collection"><a href=https://arxiv.org/abs/2512.04331v1>Open Set Face Forgery Detection via Dual-Level Evidence Collection</a></a></li><li><a href=#detection-and-imaging-of-chemicals-and-hidden-explosives-using-terahertz-time-domain-spectroscopy-and-deep-learninghttpsarxivorgabs251204330v1 aria-label="Detection and imaging of chemicals and hidden explosives using terahertz time-domain spectroscopy and deep learning"><a href=https://arxiv.org/abs/2512.04330v1>Detection and imaging of chemicals and hidden explosives using terahertz time-domain spectroscopy and deep learning</a></a></li><li><a href=#mantra-a-framework-for-multi-stage-adaptive-noise-treatment-during-traininghttpsarxivorgabs251204319v1 aria-label="MANTRA: a Framework for Multi-stage Adaptive Noise TReAtment During Training"><a href=https://arxiv.org/abs/2512.04319v1>MANTRA: a Framework for Multi-stage Adaptive Noise TReAtment During Training</a></a></li><li><a href=#classification-of-homogeneous-odd-rota--baxter-operators-on-a-modified-witt-type-lie-superalgebrahttpsarxivorgabs251204294v1 aria-label="Classification of Homogeneous Odd Rota&ndash;Baxter Operators on a Modified Witt-Type Lie Superalgebra"><a href=https://arxiv.org/abs/2512.04294v1>Classification of Homogeneous Odd Rota&ndash;Baxter Operators on a Modified Witt-Type Lie Superalgebra</a></a></li><li><a href=#algebraic-identities-for-linear-operators-on-associative-triple-systems-long-versionhttpsarxivorgabs251204190v1 aria-label="Algebraic identities for linear operators on associative triple systems (long version)"><a href=https://arxiv.org/abs/2512.04190v1>Algebraic identities for linear operators on associative triple systems (long version)</a></a></li><li><a href=#learning-group-actions-in-disentangled-latent-image-representationshttpsarxivorgabs251204015v1 aria-label="Learning Group Actions In Disentangled Latent Image Representations"><a href=https://arxiv.org/abs/2512.04015v1>Learning Group Actions In Disentangled Latent Image Representations</a></a></li><li><a href=#separating-halo-and-disk-stars-in-galaxies-with-fuzzy-set-theoryhttpsarxivorgabs251203965v1 aria-label="Separating halo and disk stars in galaxies with Fuzzy Set Theory"><a href=https://arxiv.org/abs/2512.03965v1>Separating halo and disk stars in galaxies with Fuzzy Set Theory</a></a></li><li><a href=#data-dependent-complexity-of-first-order-methods-for-binary-classificationhttpsarxivorgabs251203947v1 aria-label="Data-Dependent Complexity of First-Order Methods for Binary Classification"><a href=https://arxiv.org/abs/2512.03947v1>Data-Dependent Complexity of First-Order Methods for Binary Classification</a></a></li><li><a href=#well-rounded-ideal-lattices-from-totally-definite-quaternion-algebrashttpsarxivorgabs251203909v1 aria-label="Well-rounded ideal lattices from totally definite quaternion algebras"><a href=https://arxiv.org/abs/2512.03909v1>Well-rounded ideal lattices from totally definite quaternion algebras</a></a></li><li><a href=#adhera-a-human-centered-health-informatics-solution-for-reducing-informal-caregiver-burden-through-improved-medication-adherencehttpsarxivorgabs251203878v1 aria-label="Adhera: A Human-Centered Health Informatics Solution for Reducing Informal Caregiver Burden through Improved Medication Adherence"><a href=https://arxiv.org/abs/2512.03878v1>Adhera: A Human-Centered Health Informatics Solution for Reducing Informal Caregiver Burden through Improved Medication Adherence</a></a></li><li><a href=#classification-of-diffusion-processes-in-dimension-d-via-the-carleman-approach-with-applications-to-models-involving-additive-multiplicative-or-square-root-noiseshttpsarxivorgabs251203857v1 aria-label="Classification of diffusion processes in dimension $d$ via the Carleman approach with applications to models involving additive, multiplicative or square-root noises"><a href=https://arxiv.org/abs/2512.03857v1>Classification of diffusion processes in dimension $d$ via the Carleman approach with applications to models involving additive, multiplicative or square-root noises</a></a></li><li><a href=#pulse-a-unified-multi-task-architecture-for-cardiac-segmentation-diagnosis-and-few-shot-cross-modality-clinical-adaptationhttpsarxivorgabs251203848v1 aria-label="PULSE: A Unified Multi-Task Architecture for Cardiac Segmentation, Diagnosis, and Few-Shot Cross-Modality Clinical Adaptation"><a href=https://arxiv.org/abs/2512.03848v1>PULSE: A Unified Multi-Task Architecture for Cardiac Segmentation, Diagnosis, and Few-Shot Cross-Modality Clinical Adaptation</a></a></li><li><a href=#a-tangential-low-rank-adi-method-for-solving-indefinite-lyapunov-equationshttpsarxivorgabs251204983v1 aria-label="A tangential low-rank ADI method for solving indefinite Lyapunov equations"><a href=https://arxiv.org/abs/2512.04983v1>A tangential low-rank ADI method for solving indefinite Lyapunov equations</a></a></li><li><a href=#multipole-decomposition-of-the-gravitational-field-of-a-point-mass-at-the-black-hole-horizonhttpsarxivorgabs251204976v1 aria-label="Multipole decomposition of the gravitational field of a point mass at the black hole horizon"><a href=https://arxiv.org/abs/2512.04976v1>Multipole decomposition of the gravitational field of a point mass at the black hole horizon</a></a></li><li><a href=#on-world-volume-supersymmetry-of-supermembrane-action-in-static-gaugehttpsarxivorgabs251204948v1 aria-label="On world-volume supersymmetry of supermembrane action in static gauge"><a href=https://arxiv.org/abs/2512.04948v1>On world-volume supersymmetry of supermembrane action in static gauge</a></a></li><li><a href=#in-search-of-the-electron-phonon-contribution-to-total-energyhttpsarxivorgabs251204897v1 aria-label="In search of the electron-phonon contribution to total energy"><a href=https://arxiv.org/abs/2512.04897v1>In search of the electron-phonon contribution to total energy</a></a></li><li><a href=#decoy-state-quantum-key-distribution-over-227-km-with-a-frequency-converted-telecom-single-photon-sourcehttpsarxivorgabs251205101v1 aria-label="Decoy-state quantum key distribution over 227 km with a frequency-converted telecom single-photon source"><a href=https://arxiv.org/abs/2512.05101v1>Decoy-state quantum key distribution over 227 km with a frequency-converted telecom single-photon source</a></a></li><li><a href=#performance-analysis-of-fluid-reconfigurable-intelligent-surface-over-covert-communicationshttpsarxivorgabs251205085v1 aria-label="Performance Analysis of Fluid Reconfigurable Intelligent Surface over Covert Communications"><a href=https://arxiv.org/abs/2512.05085v1>Performance Analysis of Fluid Reconfigurable Intelligent Surface over Covert Communications</a></a></li><li><a href=#hybrid-nehari-schauder-type-fixed-point-results-and-applicationshttpsarxivorgabs251205054v1 aria-label="Hybrid Nehari-Schauder type fixed point results and applications"><a href=https://arxiv.org/abs/2512.05054v1>Hybrid Nehari-Schauder type fixed point results and applications</a></a></li><li><a href=#impact-of-power-outages-on-the-adoption-of-residential-solar-photovoltaic-in-a-changing-climatehttpsarxivorgabs251205027v1 aria-label="Impact of power outages on the adoption of residential solar photovoltaic in a changing climate"><a href=https://arxiv.org/abs/2512.05027v1>Impact of power outages on the adoption of residential solar photovoltaic in a changing climate</a></a></li><li><a href=#geophysical-intensity-problems-the-axisymmetric-casehttpsarxivorgabs251205010v1 aria-label="Geophysical intensity problems: the axisymmetric case"><a href=https://arxiv.org/abs/2512.05010v1>Geophysical intensity problems: the axisymmetric case</a></a></li><li><a href=#fractured-poroelastic-media-in-the-limit-of-vanishing-aperturehttpsarxivorgabs251204978v1 aria-label="Fractured Poroelastic Media in the Limit of Vanishing Aperture"><a href=https://arxiv.org/abs/2512.04978v1>Fractured Poroelastic Media in the Limit of Vanishing Aperture</a></a></li><li><a href=#mittag-leffler-functions-and-convex-orderinghttpsarxivorgabs251204940v1 aria-label="Mittag-Leffler functions and convex ordering"><a href=https://arxiv.org/abs/2512.04940v1>Mittag-Leffler functions and convex ordering</a></a></li><li><a href=#next-order-asymptotics-for-the-volume-of-schatten-ballshttpsarxivorgabs251204933v1 aria-label="Next-order asymptotics for the volume of Schatten balls"><a href=https://arxiv.org/abs/2512.04933v1>Next-order asymptotics for the volume of Schatten balls</a></a></li><li><a href=#weak-convergence-rates-for-spectral-regularization-via-sampling-inequalitieshttpsarxivorgabs251204929v1 aria-label="Weak convergence rates for spectral regularization via sampling inequalities"><a href=https://arxiv.org/abs/2512.04929v1>Weak convergence rates for spectral regularization via sampling inequalities</a></a></li><li><a href=#quantitative-rigidity-of-the-wasserstein-contraction-under-convolutionhttpsarxivorgabs251204928v1 aria-label="Quantitative rigidity of the Wasserstein contraction under convolution"><a href=https://arxiv.org/abs/2512.04928v1>Quantitative rigidity of the Wasserstein contraction under convolution</a></a></li><li><a href=#side-by-side-first-price-auctions-with-imperfect-biddershttpsarxivorgabs251204850v1 aria-label="Side-by-side first-price auctions with imperfect bidders"><a href=https://arxiv.org/abs/2512.04850v1>Side-by-side first-price auctions with imperfect bidders</a></a></li><li><a href=#aim-resolve-automatic-identification-and-modeling-for-bayesian-radio-interferometric-imaginghttpsarxivorgabs251204840v1 aria-label="aim-resolve: Automatic Identification and Modeling for Bayesian Radio Interferometric Imaging"><a href=https://arxiv.org/abs/2512.04840v1>aim-resolve: Automatic Identification and Modeling for Bayesian Radio Interferometric Imaging</a></a></li><li><a href=#a-tutorial-on-regression-analysis-from-linear-models-to-deep-learning----lecture-notes-on-artificial-intelligencehttpsarxivorgabs251204747v1 aria-label="A Tutorial on Regression Analysis: From Linear Models to Deep Learning &ndash; Lecture Notes on Artificial Intelligence"><a href=https://arxiv.org/abs/2512.04747v1>A Tutorial on Regression Analysis: From Linear Models to Deep Learning &ndash; Lecture Notes on Artificial Intelligence</a></a></li><li><a href=#accelerating-discovery-of-infrared-nonlinear-optical-materials-with-large-shift-current-via-high-throughput-screeninghttpsarxivorgabs251204717v1 aria-label="Accelerating discovery of infrared nonlinear optical materials with large shift current via high-throughput screening"><a href=https://arxiv.org/abs/2512.04717v1>Accelerating discovery of infrared nonlinear optical materials with large shift current via high-throughput screening</a></a></li><li><a href=#towards-an-ai-fluid-scientist-llm-powered-scientific-discovery-in-experimental-fluid-mechanicshttpsarxivorgabs251204716v1 aria-label="Towards an AI Fluid Scientist: LLM-Powered Scientific Discovery in Experimental Fluid Mechanics"><a href=https://arxiv.org/abs/2512.04716v1>Towards an AI Fluid Scientist: LLM-Powered Scientific Discovery in Experimental Fluid Mechanics</a></a></li><li><a href=#polaris-is-multi-agentic-reasoning-the-next-wave-in-engineering-self-adaptive-systemshttpsarxivorgabs251204702v1 aria-label="POLARIS: Is Multi-Agentic Reasoning the Next Wave in Engineering Self-Adaptive Systems?"><a href=https://arxiv.org/abs/2512.04702v1>POLARIS: Is Multi-Agentic Reasoning the Next Wave in Engineering Self-Adaptive Systems?</a></a></li><li><a href=#collective-cluster-nucleation-dynamics-in-2d-ising-quantum-magnetshttpsarxivorgabs251204656v1 aria-label="Collective cluster nucleation dynamics in 2D Ising quantum magnets"><a href=https://arxiv.org/abs/2512.04656v1>Collective cluster nucleation dynamics in 2D Ising quantum magnets</a></a></li><li><a href=#rethinking-decoupled-knowledge-distillation-a-predictive-distribution-perspectivehttpsarxivorgabs251204625v1 aria-label="Rethinking Decoupled Knowledge Distillation: A Predictive Distribution Perspective"><a href=https://arxiv.org/abs/2512.04625v1>Rethinking Decoupled Knowledge Distillation: A Predictive Distribution Perspective</a></a></li><li><a href=#the-ethics-of-generative-aihttpsarxivorgabs251204598v1 aria-label="The Ethics of Generative AI"><a href=https://arxiv.org/abs/2512.04598v1>The Ethics of Generative AI</a></a></li><li><a href=#magnetocaloric-effect-measurements-in-ultrahigh-magnetic-fields-up-to-120-thttpsarxivorgabs251204509v1 aria-label="Magnetocaloric effect measurements in ultrahigh magnetic fields up to 120 T"><a href=https://arxiv.org/abs/2512.04509v1>Magnetocaloric effect measurements in ultrahigh magnetic fields up to 120 T</a></a></li><li><a href=#collective-vibrational-resonance-and-mode-selection-in-nonlinear-resonator-arrayshttpsarxivorgabs251204507v1 aria-label="Collective vibrational resonance and mode selection in nonlinear resonator arrays"><a href=https://arxiv.org/abs/2512.04507v1>Collective vibrational resonance and mode selection in nonlinear resonator arrays</a></a></li><li><a href=#on-angular-dependent-response-to-gravitational-wave-signals-for-time-delay-interferometry-combinationshttpsarxivorgabs251204473v1 aria-label="On angular dependent response to gravitational-wave signals for time-delay interferometry combinations"><a href=https://arxiv.org/abs/2512.04473v1>On angular dependent response to gravitational-wave signals for time-delay interferometry combinations</a></a></li><li><a href=#learning-heterogeneous-ordinal-graphical-models-via-bayesian-nonparametric-clusteringhttpsarxivorgabs251204407v1 aria-label="Learning Heterogeneous Ordinal Graphical Models via Bayesian Nonparametric Clustering"><a href=https://arxiv.org/abs/2512.04407v1>Learning Heterogeneous Ordinal Graphical Models via Bayesian Nonparametric Clustering</a></a></li><li><a href=#autoguard-a-self-healing-proactive-security-layer-for-devsecops-pipelines-using-reinforcement-learninghttpsarxivorgabs251204368v1 aria-label="AutoGuard: A Self-Healing Proactive Security Layer for DevSecOps Pipelines Using Reinforcement Learning"><a href=https://arxiv.org/abs/2512.04368v1>AutoGuard: A Self-Healing Proactive Security Layer for DevSecOps Pipelines Using Reinforcement Learning</a></a></li><li><a href=#making-cellular-networks-crisis-proof-towards-island-ready-resilient-by-design-6g-communication-networkhttpsarxivorgabs251204346v1 aria-label="Making Cellular Networks Crisis-Proof: Towards Island-Ready, Resilient-By-Design 6G Communication Network"><a href=https://arxiv.org/abs/2512.04346v1>Making Cellular Networks Crisis-Proof: Towards Island-Ready, Resilient-By-Design 6G Communication Network</a></a></li><li><a href=#beampattern-synthesis-for-discrete-phase-ris-in-communication-and-sensing-systemshttpsarxivorgabs251204881v1 aria-label="Beampattern Synthesis for Discrete Phase RIS in Communication and Sensing Systems"><a href=https://arxiv.org/abs/2512.04881v1>Beampattern Synthesis for Discrete Phase RIS in Communication and Sensing Systems</a></a></li><li><a href=#detecting-relativistic-black-hole-collisions-near-a-massive-black-holehttpsarxivorgabs251204851v1 aria-label="Detecting relativistic black hole collisions near a massive black hole"><a href=https://arxiv.org/abs/2512.04851v1>Detecting relativistic black hole collisions near a massive black hole</a></a></li><li><a href=#detect-duality-obstruction-of-calibrations-in-smooth-categoryhttpsarxivorgabs251204789v1 aria-label="Detect duality obstruction of calibrations in smooth category"><a href=https://arxiv.org/abs/2512.04789v1>Detect duality obstruction of calibrations in smooth category</a></a></li><li><a href=#evolutionary-dynamics-based-on-reputation-in-networked-populations-with-game-transitionshttpsarxivorgabs251204671v1 aria-label="Evolutionary Dynamics Based on Reputation in Networked Populations with Game Transitions"><a href=https://arxiv.org/abs/2512.04671v1>Evolutionary Dynamics Based on Reputation in Networked Populations with Game Transitions</a></a></li><li><a href=#progress-towards-a-microchannel-plate-detector-with-algan-photocathode-and-cross-strip-anode-for-ultraviolet-astronomyhttpsarxivorgabs251204669v1 aria-label="Progress towards a microchannel plate detector with AlGaN photocathode and cross-strip anode for ultraviolet astronomy"><a href=https://arxiv.org/abs/2512.04669v1>Progress towards a microchannel plate detector with AlGaN photocathode and cross-strip anode for ultraviolet astronomy</a></a></li><li><a href=#federated-learning-for-anomaly-detection-in-maritime-movement-datahttpsarxivorgabs251204635v1 aria-label="Federated Learning for Anomaly Detection in Maritime Movement Data"><a href=https://arxiv.org/abs/2512.04635v1>Federated Learning for Anomaly Detection in Maritime Movement Data</a></a></li><li><a href=#live-avatar-streaming-real-time-audio-driven-avatar-generation-with-infinite-lengthhttpsarxivorgabs251204677v1 aria-label="Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length"><a href=https://arxiv.org/abs/2512.04677v1>Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length</a></a></li><li><a href=#pbfuzz-agentic-directed-fuzzing-for-pov-generationhttpsarxivorgabs251204611v1 aria-label="PBFuzz: Agentic Directed Fuzzing for PoV Generation"><a href=https://arxiv.org/abs/2512.04611v1>PBFuzz: Agentic Directed Fuzzing for PoV Generation</a></a></li><li><a href=#on-the-limits-of-test-time-compute-sequential-reward-filtering-for-better-inferencehttpsarxivorgabs251204558v1 aria-label="On the Limits of Test-Time Compute: Sequential Reward Filtering for Better Inference"><a href=https://arxiv.org/abs/2512.04558v1>On the Limits of Test-Time Compute: Sequential Reward Filtering for Better Inference</a></a></li><li><a href=#constraining-regular-primordial-black-holes-with-isocurvature-gravitational-waveshttpsarxivorgabs251204548v1 aria-label="Constraining regular primordial black holes with isocurvature gravitational waves"><a href=https://arxiv.org/abs/2512.04548v1>Constraining regular primordial black holes with isocurvature gravitational waves</a></a></li><li><a href=#estimation-and-inference-in-models-with-multiple-behavioural-equilibriahttpsarxivorgabs251204541v1 aria-label="Estimation and inference in models with multiple behavioural equilibria"><a href=https://arxiv.org/abs/2512.04541v1>Estimation and inference in models with multiple behavioural equilibria</a></a></li><li><a href=#a-quarkyonic-quark-meson-coupling-model-for-nuclear-and-neutron-matterhttpsarxivorgabs251204505v1 aria-label="A Quarkyonic Quark-Meson Coupling Model for Nuclear and Neutron Matter"><a href=https://arxiv.org/abs/2512.04505v1>A Quarkyonic Quark-Meson Coupling Model for Nuclear and Neutron Matter</a></a></li><li><a href=#guidnoise-single-pair-guided-diffusion-for-generalized-noise-synthesishttpsarxivorgabs251204456v1 aria-label="GuidNoise: Single-Pair Guided Diffusion for Generalized Noise Synthesis"><a href=https://arxiv.org/abs/2512.04456v1>GuidNoise: Single-Pair Guided Diffusion for Generalized Noise Synthesis</a></a></li><li><a href=#open-ended-goal-inference-through-actions-and-language-for-human-robot-collaborationhttpsarxivorgabs251204453v1 aria-label="Open-Ended Goal Inference through Actions and Language for Human-Robot Collaboration"><a href=https://arxiv.org/abs/2512.04453v1>Open-Ended Goal Inference through Actions and Language for Human-Robot Collaboration</a></a></li><li><a href=#nori-an-ml-augmented-ocean-boundary-layer-parameterizationhttpsarxivorgabs251204452v1 aria-label="NORi: An ML-Augmented Ocean Boundary Layer Parameterization"><a href=https://arxiv.org/abs/2512.04452v1>NORi: An ML-Augmented Ocean Boundary Layer Parameterization</a></a></li><li><a href=#sedimentary-models-of-fossil-biomolecules-principles-and-methodological-improvementshttpsarxivorgabs251204427v1 aria-label="Sedimentary models of fossil biomolecules, principles and methodological improvements"><a href=https://arxiv.org/abs/2512.04427v1>Sedimentary models of fossil biomolecules, principles and methodological improvements</a></a></li><li><a href=#bridging-probabilistic-inference-and-behavior-trees-an-interactive-framework-for-adaptive-multi-robot-cooperationhttpsarxivorgabs251204404v1 aria-label="Bridging Probabilistic Inference and Behavior Trees: An Interactive Framework for Adaptive Multi-Robot Cooperation"><a href=https://arxiv.org/abs/2512.04404v1>Bridging Probabilistic Inference and Behavior Trees: An Interactive Framework for Adaptive Multi-Robot Cooperation</a></a></li><li><a href=#phapcompass-probabilistic-assembly-and-uncertainty-quantification-of-polyploid-haplotype-phasehttpsarxivorgabs251204393v1 aria-label="pHapCompass: Probabilistic Assembly and Uncertainty Quantification of Polyploid Haplotype Phase"><a href=https://arxiv.org/abs/2512.04393v1>pHapCompass: Probabilistic Assembly and Uncertainty Quantification of Polyploid Haplotype Phase</a></a></li><li><a href=#informative-missingness-and-its-implications-in-semi-supervised-learninghttpsarxivorgabs251204392v1 aria-label="Informative missingness and its implications in semi-supervised learning"><a href=https://arxiv.org/abs/2512.04392v1>Informative missingness and its implications in semi-supervised learning</a></a></li><li><a href=#fma-net-motion--and-exposure-aware-real-world-joint-video-super-resolution-and-deblurringhttpsarxivorgabs251204390v1 aria-label="FMA-Net++: Motion- and Exposure-Aware Real-World Joint Video Super-Resolution and Deblurring"><a href=https://arxiv.org/abs/2512.04390v1>FMA-Net++: Motion- and Exposure-Aware Real-World Joint Video Super-Resolution and Deblurring</a></a></li><li><a href=#when-genai-meets-fake-news-understanding-image-cascade-dynamics-on-reddithttpsarxivorgabs251204639v1 aria-label="When GenAI Meets Fake News: Understanding Image Cascade Dynamics on Reddit"><a href=https://arxiv.org/abs/2512.04639v1>When GenAI Meets Fake News: Understanding Image Cascade Dynamics on Reddit</a></a></li><li><a href=#analysis-of-provincial-export-performance-in-turkiye-a-spectral-clustering-approachhttpsarxivorgabs251204466v1 aria-label="Analysis of Provincial Export Performance in Turkiye: A Spectral Clustering Approach"><a href=https://arxiv.org/abs/2512.04466v1>Analysis of Provincial Export Performance in Turkiye: A Spectral Clustering Approach</a></a></li><li><a href=#distributed-articulation-point-identification-in-time-varying-undirected-networkshttpsarxivorgabs251204409v1 aria-label="Distributed Articulation Point Identification in Time-Varying Undirected Networks"><a href=https://arxiv.org/abs/2512.04409v1>Distributed Articulation Point Identification in Time-Varying Undirected Networks</a></a></li><li><a href=#a-turtle-model-of-food-system-transformations-embracing-citizens-diverse-values-and-knowledge-in-change-processeshttpsarxivorgabs251204384v1 aria-label="A &lsquo;Turtle Model&rsquo; of Food System Transformations: Embracing Citizens&rsquo; Diverse Values and Knowledge in Change Processes"><a href=https://arxiv.org/abs/2512.04384v1>A &lsquo;Turtle Model&rsquo; of Food System Transformations: Embracing Citizens&rsquo; Diverse Values and Knowledge in Change Processes</a></a></li><li><a href=#mapping-data-labour-supply-chain-in-africa-in-an-era-of-digital-apartheid-a-struggle-for-recognitionhttpsarxivorgabs251204269v1 aria-label="Mapping Data Labour Supply Chain in Africa in an Era of Digital Apartheid: a Struggle for Recognition"><a href=https://arxiv.org/abs/2512.04269v1>Mapping Data Labour Supply Chain in Africa in an Era of Digital Apartheid: a Struggle for Recognition</a></a></li><li><a href=#toward-virtuous-reinforcement-learninghttpsarxivorgabs251204246v1 aria-label="Toward Virtuous Reinforcement Learning"><a href=https://arxiv.org/abs/2512.04246v1>Toward Virtuous Reinforcement Learning</a></a></li><li><a href=#post-cold-war-diaspora-of-russian-particle-physicistshttpsarxivorgabs251204052v1 aria-label="Post-Cold War Diaspora of Russian Particle Physicists"><a href=https://arxiv.org/abs/2512.04052v1>Post-Cold War Diaspora of Russian Particle Physicists</a></a></li><li><a href=#polarization-by-design-how-elites-could-shape-mass-preferences-as-ai-reduces-persuasion-costshttpsarxivorgabs251204047v1 aria-label="Polarization by Design: How Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs"><a href=https://arxiv.org/abs/2512.04047v1>Polarization by Design: How Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs</a></a></li><li><a href=#when-to-say-hi---learn-to-open-a-conversation-with-an-in-the-wild-datasethttpsarxivorgabs251203991v1 aria-label="When to Say &ldquo;Hi&rdquo; - Learn to Open a Conversation with an in-the-wild Dataset"><a href=https://arxiv.org/abs/2512.03991v1>When to Say &ldquo;Hi&rdquo; - Learn to Open a Conversation with an in-the-wild Dataset</a></a></li><li><a href=#aggregating-maximal-cliques-in-real-world-graphshttpsarxivorgabs251203960v1 aria-label="Aggregating maximal cliques in real-world graphs"><a href=https://arxiv.org/abs/2512.03960v1>Aggregating maximal cliques in real-world graphs</a></a></li><li><a href=#dsp-a-statistically-principled-structural-polarization-measurehttpsarxivorgabs251203937v1 aria-label="DSP: A Statistically-Principled Structural Polarization Measure"><a href=https://arxiv.org/abs/2512.03937v1>DSP: A Statistically-Principled Structural Polarization Measure</a></a></li><li><a href=#generating-a-contact-matrix-for-aged-care-settings-in-australia-an-agent-based-model-studyhttpsarxivorgabs251203866v1 aria-label="Generating a Contact Matrix for Aged Care Settings in Australia: an agent-based model study"><a href=https://arxiv.org/abs/2512.03866v1>Generating a Contact Matrix for Aged Care Settings in Australia: an agent-based model study</a></a></li><li><a href=#does-globalization-promote-or-hinder-sustainable-development-evidence-from-turkiye-on-the-three-dimensions-of-globalizationhttpsarxivorgabs251203822v1 aria-label="Does Globalization Promote or Hinder Sustainable Development? Evidence from Turkiye on the Three Dimensions of Globalization"><a href=https://arxiv.org/abs/2512.03822v1>Does Globalization Promote or Hinder Sustainable Development? Evidence from Turkiye on the Three Dimensions of Globalization</a></a></li><li><a href=#from-micro-distributions-to-macro-regularities-a-critique-and-reconstruction-of-the-production-function-based-on-the-maximum-entropy-principlehttpsarxivorgabs251203812v1 aria-label="From Micro-Distributions to Macro-Regularities: A Critique and Reconstruction of the Production Function Based on the Maximum Entropy Principle"><a href=https://arxiv.org/abs/2512.03812v1>From Micro-Distributions to Macro-Regularities: A Critique and Reconstruction of the Production Function Based on the Maximum Entropy Principle</a></a></li><li><a href=#mpcformer-a-physics-informed-data-driven-approach-for-explainable-socially-aware-autonomous-drivinghttpsarxivorgabs251203795v1 aria-label="MPCFormer: A physics-informed data-driven approach for explainable socially-aware autonomous driving"><a href=https://arxiv.org/abs/2512.03795v1>MPCFormer: A physics-informed data-driven approach for explainable socially-aware autonomous driving</a></a></li><li><a href=#quantum-simulations-of-opinion-dynamicshttpsarxivorgabs251203770v1 aria-label="Quantum Simulations of Opinion Dynamics"><a href=https://arxiv.org/abs/2512.03770v1>Quantum Simulations of Opinion Dynamics</a></a></li><li><a href=#eminds-understanding-user-behavior-progression-for-mental-health-exploration-on-social-mediahttpsarxivorgabs251203495v1 aria-label="EMINDS: Understanding User Behavior Progression for Mental Health Exploration on Social Media"><a href=https://arxiv.org/abs/2512.03495v1>EMINDS: Understanding User Behavior Progression for Mental Health Exploration on Social Media</a></a></li><li><a href=#full-stack-alignment-co-aligning-ai-and-institutions-with-thick-models-of-valuehttpsarxivorgabs251203399v1 aria-label="Full-Stack Alignment: Co-Aligning AI and Institutions with Thick Models of Value"><a href=https://arxiv.org/abs/2512.03399v1>Full-Stack Alignment: Co-Aligning AI and Institutions with Thick Models of Value</a></a></li><li><a href=#epistemic-substitution-how-grokipedias-ai-generated-encyclopedia-restructures-authorityhttpsarxivorgabs251203337v1 aria-label="Epistemic Substitution: How Grokipedia&rsquo;s AI-Generated Encyclopedia Restructures Authority"><a href=https://arxiv.org/abs/2512.03337v1>Epistemic Substitution: How Grokipedia&rsquo;s AI-Generated Encyclopedia Restructures Authority</a></a></li><li><a href=#evaluating-generalization-capabilities-of-llm-based-agents-in-mixed-motive-scenarios-using-concordiahttpsarxivorgabs251203318v1 aria-label="Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia"><a href=https://arxiv.org/abs/2512.03318v1>Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia</a></a></li><li><a href=#associating-healthcare-teamwork-with-patient-outcomes-for-predictive-analysishttpsarxivorgabs251203296v1 aria-label="Associating Healthcare Teamwork with Patient Outcomes for Predictive Analysis"><a href=https://arxiv.org/abs/2512.03296v1>Associating Healthcare Teamwork with Patient Outcomes for Predictive Analysis</a></a></li><li><a href=#culture-affordance-atlas-reconciling-object-diversity-through-functional-mappinghttpsarxivorgabs251203173v1 aria-label="Culture Affordance Atlas: Reconciling Object Diversity Through Functional Mapping"><a href=https://arxiv.org/abs/2512.03173v1>Culture Affordance Atlas: Reconciling Object Diversity Through Functional Mapping</a></a></li><li><a href=#the-moral-consistency-pipeline-continuous-ethical-evaluation-for-large-language-modelshttpsarxivorgabs251203026v1 aria-label="The Moral Consistency Pipeline: Continuous Ethical Evaluation for Large Language Models"><a href=https://arxiv.org/abs/2512.03026v1>The Moral Consistency Pipeline: Continuous Ethical Evaluation for Large Language Models</a></a></li><li><a href=#from-moderation-to-mediation-can-llms-serve-as-mediators-in-online-flame-warshttpsarxivorgabs251203005v1 aria-label="From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?"><a href=https://arxiv.org/abs/2512.03005v1>From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?</a></a></li><li><a href=#benchmarking-scientific-understanding-and-reasoning-for-video-generation-using-videoscience-benchhttpsarxivorgabs251202942v1 aria-label="Benchmarking Scientific Understanding and Reasoning for Video Generation using VideoScience-Bench"><a href=https://arxiv.org/abs/2512.02942v1>Benchmarking Scientific Understanding and Reasoning for Video Generation using VideoScience-Bench</a></a></li><li><a href=#learning-multimodal-embeddings-for-traffic-accident-prediction-and-causal-estimationhttpsarxivorgabs251202920v1 aria-label="Learning Multimodal Embeddings for Traffic Accident Prediction and Causal Estimation"><a href=https://arxiv.org/abs/2512.02920v1>Learning Multimodal Embeddings for Traffic Accident Prediction and Causal Estimation</a></a></li><li><a href=#humans-incorrectly-reject-confident-accusatory-ai-judgmentshttpsarxivorgabs251202848v1 aria-label="Humans incorrectly reject confident accusatory AI judgments"><a href=https://arxiv.org/abs/2512.02848v1>Humans incorrectly reject confident accusatory AI judgments</a></a></li><li><a href=#bangla-hate-speech-classification-with-fine-tuned-transformer-modelshttpsarxivorgabs251202845v1 aria-label="Bangla Hate Speech Classification with Fine-tuned Transformer Models"><a href=https://arxiv.org/abs/2512.02845v1>Bangla Hate Speech Classification with Fine-tuned Transformer Models</a></a></li><li><a href=#menta-a-small-language-model-for-on-device-mental-health-predictionhttpsarxivorgabs251202716v2 aria-label="Menta: A Small Language Model for On-Device Mental Health Prediction"><a href=https://arxiv.org/abs/2512.02716v2>Menta: A Small Language Model for On-Device Mental Health Prediction</a></a></li><li><a href=#embedding-networks-with-the-random-walk-first-return-time-distributionhttpsarxivorgabs251202694v2 aria-label="Embedding networks with the random walk first return time distribution"><a href=https://arxiv.org/abs/2512.02694v2>Embedding networks with the random walk first return time distribution</a></a></li><li><a href=#an-empirical-survey-of-model-merging-algorithms-for-social-bias-mitigationhttpsarxivorgabs251202689v1 aria-label="An Empirical Survey of Model Merging Algorithms for Social Bias Mitigation"><a href=https://arxiv.org/abs/2512.02689v1>An Empirical Survey of Model Merging Algorithms for Social Bias Mitigation</a></a></li><li><a href=#measuring-and-rating-socioeconomic-disparities-among-provinces-a-case-of-turkiyehttpsarxivorgabs251202687v1 aria-label="Measuring and Rating Socioeconomic Disparities among Provinces: A Case of Turkiye"><a href=https://arxiv.org/abs/2512.02687v1>Measuring and Rating Socioeconomic Disparities among Provinces: A Case of Turkiye</a></a></li><li><a href=#on-the-relationship-between-heider-links-and-ising-spinshttpsarxivorgabs251202644v1 aria-label="On the relationship between Heider links and Ising spins"><a href=https://arxiv.org/abs/2512.02644v1>On the relationship between Heider links and Ising spins</a></a></li><li><a href=#investigating-the-integrated-digital-interventions-delivered-by-a-therapeutic-companion-agent-for-young-adults-with-symptoms-of-depression-a-proof-of-concept-studyhttpsarxivorgabs251202608v1 aria-label="Investigating the Integrated Digital Interventions Delivered by a Therapeutic Companion Agent for Young Adults with Symptoms of Depression: A Proof-of-Concept Study"><a href=https://arxiv.org/abs/2512.02608v1>Investigating the Integrated Digital Interventions Delivered by a Therapeutic Companion Agent for Young Adults with Symptoms of Depression: A Proof-of-Concept Study</a></a></li><li><a href=#reframing-human-robot-interaction-through-extended-reality-unlocking-safer-smarter-and-more-empathic-interactions-with-virtual-robots-and-foundation-modelshttpsarxivorgabs251202569v1 aria-label="Reframing Human-Robot Interaction Through Extended Reality: Unlocking Safer, Smarter, and More Empathic Interactions with Virtual Robots and Foundation Models"><a href=https://arxiv.org/abs/2512.02569v1>Reframing Human-Robot Interaction Through Extended Reality: Unlocking Safer, Smarter, and More Empathic Interactions with Virtual Robots and Foundation Models</a></a></li><li><a href=#a-randomized-scheduling-framework-for-privacy-preserving-multi-robot-rendezvous-given-prior-informationhttpsarxivorgabs251205053v1 aria-label="A Randomized Scheduling Framework for Privacy-Preserving Multi-robot Rendezvous given Prior Information"><a href=https://arxiv.org/abs/2512.05053v1>A Randomized Scheduling Framework for Privacy-Preserving Multi-robot Rendezvous given Prior Information</a></a></li><li><a href=#opacity-estimation-of-oo-collision-from-combolt-ita-hybridhttpsarxivorgabs251205009v1 aria-label="Opacity estimation of OO collision from CoMBolt-ITA hybrid"><a href=https://arxiv.org/abs/2512.05009v1>Opacity estimation of OO collision from CoMBolt-ITA hybrid</a></a></li><li><a href=#plumbing-bijectionshttpsarxivorgabs251205001v1 aria-label="Plumbing bijections"><a href=https://arxiv.org/abs/2512.05001v1>Plumbing bijections</a></a></li><li><a href=#circuit-quantum-acoustodynamics-in-a-scalable-phononic-integrated-circuit-architecturehttpsarxivorgabs251204953v1 aria-label="Circuit Quantum Acoustodynamics in a Scalable Phononic Integrated Circuit Architecture"><a href=https://arxiv.org/abs/2512.04953v1>Circuit Quantum Acoustodynamics in a Scalable Phononic Integrated Circuit Architecture</a></a></li><li><a href=#a-non-linear-differential-equation-for-the-periods-of-elliptic-surfaceshttpsarxivorgabs251204930v1 aria-label="A non-linear differential equation for the periods of elliptic surfaces"><a href=https://arxiv.org/abs/2512.04930v1>A non-linear differential equation for the periods of elliptic surfaces</a></a></li><li><a href=#doppler-shift-mitigation-in-a-chip-scale-atomic-beam-clockhttpsarxivorgabs251204905v1 aria-label="Doppler Shift Mitigation in a Chip-Scale Atomic Beam Clock"><a href=https://arxiv.org/abs/2512.04905v1>Doppler Shift Mitigation in a Chip-Scale Atomic Beam Clock</a></a></li></ul></li><li><a href=#-cross-lingual aria-label="üîç cross-lingual">üîç cross-lingual</a><ul><li><a href=#kda-knowledge-distillation-adapter-for-cross-lingual-transferhttpsaclanthologyorg2025inlg-main8 aria-label="KDA: Knowledge Distillation Adapter for Cross-Lingual Transfer"><a href=https://aclanthology.org/2025.inlg-main.8/>KDA: Knowledge Distillation Adapter for Cross-Lingual Transfer</a></a></li><li><a href=#are-knowledge-and-reference-in-multilingual-language-models-cross-lingually-consistenthttpsaclanthologyorg2025findings-emnlp267 aria-label="Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent?"><a href=https://aclanthology.org/2025.findings-emnlp.267/>Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent?</a></a></li><li><a href=#ccl-xcot-an-efficient-cross-lingual-knowledge-transfer-method-for-mitigating-hallucination-generationhttpsaclanthologyorg2025findings-emnlp93 aria-label="CCL-XCoT: An Efficient Cross-Lingual Knowledge Transfer Method for Mitigating Hallucination Generation"><a href=https://aclanthology.org/2025.findings-emnlp.93/>CCL-XCoT: An Efficient Cross-Lingual Knowledge Transfer Method for Mitigating Hallucination Generation</a></a></li><li><a href=#deft-x-denoised-sparse-fine-tuning-for-zero-shot-cross-lingual-transferhttpsaclanthologyorg2025findings-emnlp100 aria-label="DeFT-X: Denoised Sparse Fine-Tuning for Zero-Shot Cross-Lingual Transfer"><a href=https://aclanthology.org/2025.findings-emnlp.100/>DeFT-X: Denoised Sparse Fine-Tuning for Zero-Shot Cross-Lingual Transfer</a></a></li><li><a href=#disentangling-language-understanding-and-reasoning-structures-in-cross-lingual-chain-of-thought-promptinghttpsaclanthologyorg2025findings-emnlp652 aria-label="Disentangling Language Understanding and Reasoning Structures in Cross-lingual Chain-of-Thought Prompting"><a href=https://aclanthology.org/2025.findings-emnlp.652/>Disentangling Language Understanding and Reasoning Structures in Cross-lingual Chain-of-Thought Prompting</a></a></li><li><a href=#dlir-spherical-adaptation-for-cross-lingual-knowledge-transfer-of-sociological-concepts-alignmenthttpsaclanthologyorg2025findings-emnlp109 aria-label="DLIR: Spherical Adaptation for Cross-Lingual Knowledge Transfer of Sociological Concepts Alignment"><a href=https://aclanthology.org/2025.findings-emnlp.109/>DLIR: Spherical Adaptation for Cross-Lingual Knowledge Transfer of Sociological Concepts Alignment</a></a></li><li><a href=#efficientxlang-towards-improving-token-efficiency-through-cross-lingual-reasoninghttpsaclanthologyorg2025findings-emnlp845 aria-label="EfficientXLang: Towards Improving Token Efficiency Through Cross-Lingual Reasoning"><a href=https://aclanthology.org/2025.findings-emnlp.845/>EfficientXLang: Towards Improving Token Efficiency Through Cross-Lingual Reasoning</a></a></li><li><a href=#evaluating-large-language-models-for-cross-lingual-retrievalhttpsaclanthologyorg2025findings-emnlp612 aria-label="Evaluating Large Language Models for Cross-Lingual Retrieval"><a href=https://aclanthology.org/2025.findings-emnlp.612/>Evaluating Large Language Models for Cross-Lingual Retrieval</a></a></li><li><a href=#evaluating-the-robustness-and-accuracy-of-text-watermarking-under-real-world-cross-lingual-manipulationshttpsaclanthologyorg2025findings-emnlp390 aria-label="Evaluating the Robustness and Accuracy of Text Watermarking Under Real-World Cross-Lingual Manipulations"><a href=https://aclanthology.org/2025.findings-emnlp.390/>Evaluating the Robustness and Accuracy of Text Watermarking Under Real-World Cross-Lingual Manipulations</a></a></li><li><a href=#examining-multilingual-embedding-models-cross-lingually-through-llm-generated-adversarial-exampleshttpsaclanthologyorg2025findings-emnlp115 aria-label="Examining Multilingual Embedding Models Cross-Lingually Through LLM-Generated Adversarial Examples"><a href=https://aclanthology.org/2025.findings-emnlp.115/>Examining Multilingual Embedding Models Cross-Lingually Through LLM-Generated Adversarial Examples</a></a></li><li><a href=#facilitating-cross-lingual-transfer-of-empathy-through-language-independent-latent-diffusion-a-case-study-in-chinesehttpsaclanthologyorg2025findings-emnlp1313 aria-label="Facilitating Cross-lingual Transfer of Empathy through Language-independent Latent Diffusion: A Case Study in Chinese"><a href=https://aclanthology.org/2025.findings-emnlp.1313/>Facilitating Cross-lingual Transfer of Empathy through Language-independent Latent Diffusion: A Case Study in Chinese</a></a></li><li><a href=#leveraging-high-resource-english-corpora-for-cross-lingual-domain-adaptation-in-low-resource-japanese-medicine-via-continued-pre-traininghttpsaclanthologyorg2025findings-emnlp615 aria-label="Leveraging High-Resource English Corpora for Cross-lingual Domain Adaptation in Low-Resource Japanese Medicine via Continued Pre-training"><a href=https://aclanthology.org/2025.findings-emnlp.615/>Leveraging High-Resource English Corpora for Cross-lingual Domain Adaptation in Low-Resource Japanese Medicine via Continued Pre-training</a></a></li><li><a href=#magix-a-multi-granular-adaptive-graph-intelligence-framework-for-enhancing-cross-lingual-raghttpsaclanthologyorg2025findings-emnlp279 aria-label="MaGiX: A Multi-Granular Adaptive Graph Intelligence Framework for Enhancing Cross-Lingual RAG"><a href=https://aclanthology.org/2025.findings-emnlp.279/>MaGiX: A Multi-Granular Adaptive Graph Intelligence Framework for Enhancing Cross-Lingual RAG</a></a></li><li><a href=#memory-enhanced-large-language-model-for-cross-lingual-dependency-parsing-via-deep-hierarchical-syntax-understandinghttpsaclanthologyorg2025findings-emnlp101 aria-label="Memory-enhanced Large Language Model for Cross-lingual Dependency Parsing via Deep Hierarchical Syntax Understanding"><a href=https://aclanthology.org/2025.findings-emnlp.101/>Memory-enhanced Large Language Model for Cross-lingual Dependency Parsing via Deep Hierarchical Syntax Understanding</a></a></li><li><a href=#multilingual-generative-retrieval-via-cross-lingual-semantic-compressionhttpsaclanthologyorg2025findings-emnlp575 aria-label="Multilingual Generative Retrieval via Cross-lingual Semantic Compression"><a href=https://aclanthology.org/2025.findings-emnlp.575/>Multilingual Generative Retrieval via Cross-lingual Semantic Compression</a></a></li><li><a href=#neighxlm-enhancing-cross-lingual-transfer-in-low-resource-languages-via-neighbor-augmented-contrastive-pretraininghttpsaclanthologyorg2025findings-emnlp163 aria-label="NeighXLM: Enhancing Cross-Lingual Transfer in Low-Resource Languages via Neighbor-Augmented Contrastive Pretraining"><a href=https://aclanthology.org/2025.findings-emnlp.163/>NeighXLM: Enhancing Cross-Lingual Transfer in Low-Resource Languages via Neighbor-Augmented Contrastive Pretraining</a></a></li><li><a href=#protoxtm-cross-lingual-topic-modeling-with-document-level-prototype-based-contrastive-learninghttpsaclanthologyorg2025findings-emnlp1107 aria-label="ProtoXTM: Cross-Lingual Topic Modeling with Document-Level Prototype-based Contrastive Learning"><a href=https://aclanthology.org/2025.findings-emnlp.1107/>ProtoXTM: Cross-Lingual Topic Modeling with Document-Level Prototype-based Contrastive Learning</a></a></li><li><a href=#xl-suite-cross-lingual-synthetic-training-and-evaluation-data-for-open-ended-generationhttpsaclanthologyorg2025findings-emnlp550 aria-label="XL-Suite: Cross-Lingual Synthetic Training and Evaluation Data for Open-Ended Generation"><a href=https://aclanthology.org/2025.findings-emnlp.550/>XL-Suite: Cross-Lingual Synthetic Training and Evaluation Data for Open-Ended Generation</a></a></li><li><a href=#xrag-cross-lingual-retrieval-augmented-generationhttpsaclanthologyorg2025findings-emnlp849 aria-label="XRAG: Cross-lingual Retrieval-Augmented Generation"><a href=https://aclanthology.org/2025.findings-emnlp.849/>XRAG: Cross-lingual Retrieval-Augmented Generation</a></a></li><li><a href=#xtra-cross-lingual-topic-modeling-with-topic-and-representation-alignmentshttpsaclanthologyorg2025findings-emnlp298 aria-label="XTRA: Cross-Lingual Topic Modeling with Topic and Representation Alignments"><a href=https://aclanthology.org/2025.findings-emnlp.298/>XTRA: Cross-Lingual Topic Modeling with Topic and Representation Alignments</a></a></li><li><a href=#zero-shot-cross-lingual-ner-via-mitigating-language-difference-an-entity-aligned-translation-perspectivehttpsaclanthologyorg2025findings-emnlp244 aria-label="Zero-shot Cross-lingual NER via Mitigating Language Difference: An Entity-aligned Translation Perspective"><a href=https://aclanthology.org/2025.findings-emnlp.244/>Zero-shot Cross-lingual NER via Mitigating Language Difference: An Entity-aligned Translation Perspective</a></a></li></ul></li><li><a href=#-code-switching aria-label="üîç code-switching">üîç code-switching</a><ul><li><a href=#can-code-switched-texts-activate-a-knowledge-switch-in-llms-a-case-study-on-english-korean-code-switchinghttpsaclanthologyorg2025findings-emnlp1215 aria-label="Can Code-Switched Texts Activate a Knowledge Switch in LLMs? A Case Study on English-Korean Code-Switching"><a href=https://aclanthology.org/2025.findings-emnlp.1215/>Can Code-Switched Texts Activate a Knowledge Switch in LLMs? A Case Study on English-Korean Code-Switching</a></a></li><li><a href=#unicom-a-universal-code-switching-speech-generatorhttpsaclanthologyorg2025findings-emnlp715 aria-label="UniCoM: A Universal Code-Switching Speech Generator"><a href=https://aclanthology.org/2025.findings-emnlp.715/>UniCoM: A Universal Code-Switching Speech Generator</a></a></li></ul></li><li><a href=#-low-resource-language aria-label="üîç low-resource language">üîç low-resource language</a><ul><li><a href=#diploma-efficient-adaptation-of-instructed-llms-to-low-resource-languages-via-post-training-delta-merginghttpsaclanthologyorg2025findings-emnlp1355 aria-label="DIPLomA: Efficient Adaptation of Instructed LLMs to Low-Resource Languages via Post-Training Delta Merging"><a href=https://aclanthology.org/2025.findings-emnlp.1355/>DIPLomA: Efficient Adaptation of Instructed LLMs to Low-Resource Languages via Post-Training Delta Merging</a></a></li><li><a href=#low-resource-languages-llm-disinformation-is-within-reach-the-case-of-walliserdeutschhttpsaclanthologyorg2025findings-emnlp1396 aria-label="Low-Resource Languages LLM Disinformation is Within Reach: The Case of Walliserdeutsch"><a href=https://aclanthology.org/2025.findings-emnlp.1396/>Low-Resource Languages LLM Disinformation is Within Reach: The Case of Walliserdeutsch</a></a></li><li><a href=#parsing-the-switch-llm-based-ud-annotation-for-complex-code-switched-and-low-resource-languageshttpsaclanthologyorg2025findings-emnlp863 aria-label="Parsing the Switch: LLM-Based UD Annotation for Complex Code-Switched and Low-Resource Languages"><a href=https://aclanthology.org/2025.findings-emnlp.863/>Parsing the Switch: LLM-Based UD Annotation for Complex Code-Switched and Low-Resource Languages</a></a></li></ul></li><li><a href=#-cross-lingual-transfer aria-label="üîç cross-lingual transfer">üîç cross-lingual transfer</a></li><li><a href=#-multilingual-alignment aria-label="üîç multilingual alignment">üîç multilingual alignment</a><ul><li><a href=#cm-align-consistency-based-multilingual-alignment-for-large-language-modelshttpsaclanthologyorg2025findings-emnlp1401 aria-label="CM-Align: Consistency-based Multilingual Alignment for Large Language Models"><a href=https://aclanthology.org/2025.findings-emnlp.1401/>CM-Align: Consistency-based Multilingual Alignment for Large Language Models</a></a></li></ul></li><li><a href=#-cross-lingual-retrieval aria-label="üîç cross-lingual retrieval">üîç cross-lingual retrieval</a></li><li><a href=#-surprisal aria-label="üîç surprisal">üîç surprisal</a><ul><li><a href=#surprisal-reveals-diversity-gaps-in-image-captioning-and-different-scorers-change-the-storyhttpsaclanthologyorg2025inlg-main22 aria-label="Surprisal reveals diversity gaps in image captioning and different scorers change the story"><a href=https://aclanthology.org/2025.inlg-main.22/>Surprisal reveals diversity gaps in image captioning and different scorers change the story</a></a></li><li><a href=#evaluating-text-generation-quality-using-spectral-distances-of-surprisalhttpsaclanthologyorg2025findings-emnlp132 aria-label="Evaluating Text Generation Quality Using Spectral Distances of Surprisal"><a href=https://aclanthology.org/2025.findings-emnlp.132/>Evaluating Text Generation Quality Using Spectral Distances of Surprisal</a></a></li></ul></li><li><a href=#-contextual-embedding aria-label="üîç contextual embedding">üîç contextual embedding</a><ul><li><a href=#zero-shot-contextual-embeddings-via-offline-synthetic-corpus-generationhttpsaclanthologyorg2025findings-emnlp111 aria-label="Zero-Shot Contextual Embeddings via Offline Synthetic Corpus Generation"><a href=https://aclanthology.org/2025.findings-emnlp.111/>Zero-Shot Contextual Embeddings via Offline Synthetic Corpus Generation</a></a></li></ul></li><li><a href=#-llm-evaluation aria-label="üîç llm evaluation">üîç llm evaluation</a><ul><li><a href=#do-before-you-judge-self-reference-as-a-pathway-to-better-llm-evaluationhttpsaclanthologyorg2025findings-emnlp1342 aria-label="Do Before You Judge: Self-Reference as a Pathway to Better LLM Evaluation"><a href=https://aclanthology.org/2025.findings-emnlp.1342/>Do Before You Judge: Self-Reference as a Pathway to Better LLM Evaluation</a></a></li><li><a href=#from-kmmlu-redux-to-pro-a-professional-korean-benchmark-suite-for-llm-evaluationhttpsaclanthologyorg2025findings-emnlp1038 aria-label="From KMMLU-Redux to Pro: A Professional Korean Benchmark Suite for LLM Evaluation"><a href=https://aclanthology.org/2025.findings-emnlp.1038/>From KMMLU-Redux to Pro: A Professional Korean Benchmark Suite for LLM Evaluation</a></a></li><li><a href=#instance-level-randomization-toward-more-stable-llm-evaluationshttpsaclanthologyorg2025findings-emnlp182 aria-label="Instance-level Randomization: Toward More Stable LLM Evaluations"><a href=https://aclanthology.org/2025.findings-emnlp.182/>Instance-level Randomization: Toward More Stable LLM Evaluations</a></a></li><li><a href=#reliableeval-a-recipe-for-stochastic-llm-evaluation-via-method-of-momentshttpsaclanthologyorg2025findings-emnlp594 aria-label="ReliableEval: A Recipe for Stochastic LLM Evaluation via Method of Moments"><a href=https://aclanthology.org/2025.findings-emnlp.594/>ReliableEval: A Recipe for Stochastic LLM Evaluation via Method of Moments</a></a></li></ul></li><li><a href=#-emotion-recognition aria-label="üîç emotion recognition">üîç emotion recognition</a><ul><li><a href=#a-comprehensive-pipeline-for-vietnamese-speech-recognition-and-emotion-recognitionhttpsaclanthologyorg2025vlsp-14 aria-label="A Comprehensive Pipeline for Vietnamese Speech Recognition and Emotion Recognition"><a href=https://aclanthology.org/2025.vlsp-1.4/>A Comprehensive Pipeline for Vietnamese Speech Recognition and Emotion Recognition</a></a></li><li><a href=#dfat-dual-stage-fusion-of-acoustic-and-text-feature-for-speech-emotion-recognitionhttpsaclanthologyorg2025vlsp-16 aria-label="DFAT: Dual-stage Fusion of Acoustic and Text feature for Speech Emotion Recognition"><a href=https://aclanthology.org/2025.vlsp-1.6/>DFAT: Dual-stage Fusion of Acoustic and Text feature for Speech Emotion Recognition</a></a></li><li><a href=#speech-recognition-and-speech-emotion-recognition-approach-for-vlsp-2025httpsaclanthologyorg2025vlsp-12 aria-label="Speech recognition and speech emotion recognition approach for VLSP 2025"><a href=https://aclanthology.org/2025.vlsp-1.2/>Speech recognition and speech emotion recognition approach for VLSP 2025</a></a></li><li><a href=#vlsp-2025-asrser-vietnamese-speech-recognition-and-speech-emotion-recognition-challenge-technical-analysis-and-insightshttpsaclanthologyorg2025vlsp-11 aria-label="VLSP 2025 ASR/SER: Vietnamese Speech Recognition and Speech Emotion Recognition Challenge: Technical Analysis and Insights"><a href=https://aclanthology.org/2025.vlsp-1.1/>VLSP 2025 ASR/SER: Vietnamese Speech Recognition and Speech Emotion Recognition Challenge: Technical Analysis and Insights</a></a></li><li><a href=#emo-rl-emotion-rule-based-reinforcement-learning-enhanced-audio-language-model-for-generalized-speech-emotion-recognitionhttpsaclanthologyorg2025findings-emnlp1018 aria-label="EMO-RL: Emotion-Rule-Based Reinforcement Learning Enhanced Audio-Language Model for Generalized Speech Emotion Recognition"><a href=https://aclanthology.org/2025.findings-emnlp.1018/>EMO-RL: Emotion-Rule-Based Reinforcement Learning Enhanced Audio-Language Model for Generalized Speech Emotion Recognition</a></a></li><li><a href=#grpo-guided-modality-selection-enhanced-lora-tuned-llms-for-multimodal-emotion-recognitionhttpsaclanthologyorg2025findings-emnlp1059 aria-label="GRPO-Guided Modality Selection Enhanced LoRA-Tuned LLMs for Multimodal Emotion Recognition"><a href=https://aclanthology.org/2025.findings-emnlp.1059/>GRPO-Guided Modality Selection Enhanced LoRA-Tuned LLMs for Multimodal Emotion Recognition</a></a></li><li><a href=#multimodal-emotion-recognition-in-conversations-a-survey-of-methods-trends-challenges-and-prospectshttpsaclanthologyorg2025findings-emnlp332 aria-label="Multimodal Emotion Recognition in Conversations: A Survey of Methods, Trends, Challenges and Prospects"><a href=https://aclanthology.org/2025.findings-emnlp.332/>Multimodal Emotion Recognition in Conversations: A Survey of Methods, Trends, Challenges and Prospects</a></a></li></ul></li><li><a href=#-sentiment-analysis aria-label="üîç sentiment analysis">üîç sentiment analysis</a><ul><li><a href=#exploring-the-power-of-large-language-models-for-vietnamese-implitcit-sentiment-analysishttpsaclanthologyorg2025inlg-main14 aria-label="Exploring the Power of Large Language Models for Vietnamese Implitcit Sentiment Analysis"><a href=https://aclanthology.org/2025.inlg-main.14/>Exploring the Power of Large Language Models for Vietnamese Implitcit Sentiment Analysis</a></a></li><li><a href=#aspect-based-sentiment-analysis-via-synthetic-image-generationhttpsaclanthologyorg2025findings-emnlp1190 aria-label="Aspect-based Sentiment Analysis via Synthetic Image Generation"><a href=https://aclanthology.org/2025.findings-emnlp.1190/>Aspect-based Sentiment Analysis via Synthetic Image Generation</a></a></li><li><a href=#tf-mamba-text-enhanced-fusion-mamba-with-missing-modalities-for-robust-multimodal-sentiment-analysishttpsaclanthologyorg2025findings-emnlp602 aria-label="TF-Mamba: Text-enhanced Fusion Mamba with Missing Modalities for Robust Multimodal Sentiment Analysis"><a href=https://aclanthology.org/2025.findings-emnlp.602/>TF-Mamba: Text-enhanced Fusion Mamba with Missing Modalities for Robust Multimodal Sentiment Analysis</a></a></li><li><a href=#zero-shot-cross-domain-aspect-based-sentiment-analysis-via-domain-contextualized-chain-of-thought-reasoninghttpsaclanthologyorg2025findings-emnlp245 aria-label="Zero-Shot Cross-Domain Aspect-Based Sentiment Analysis via Domain-Contextualized Chain-of-Thought Reasoning"><a href=https://aclanthology.org/2025.findings-emnlp.245/>Zero-Shot Cross-Domain Aspect-Based Sentiment Analysis via Domain-Contextualized Chain-of-Thought Reasoning</a></a></li></ul></li><li><a href=#-humor-detection aria-label="üîç humor detection">üîç humor detection</a><ul><li><a href=#standup4ai-a-new-multilingual-dataset-for-humor-detection-in-stand-up-comedy-videoshttpsaclanthologyorg2025findings-emnlp919 aria-label="StandUp4AI: A New Multilingual Dataset for Humor Detection in Stand-up Comedy Videos"><a href=https://aclanthology.org/2025.findings-emnlp.919/>StandUp4AI: A New Multilingual Dataset for Humor Detection in Stand-up Comedy Videos</a></a></li></ul></li><li><a href=#-sarcasm-detection aria-label="üîç sarcasm detection">üîç sarcasm detection</a><ul><li><a href=#revealing-the-impact-of-synthetic-native-samples-and-multi-tasking-strategies-in-hindi-english-code-mixed-humour-and-sarcasm-detectionhttpsaclanthologyorg2025findings-emnlp1308 aria-label="Revealing the impact of synthetic native samples and multi-tasking strategies in Hindi-English code-mixed humour and sarcasm detection"><a href=https://aclanthology.org/2025.findings-emnlp.1308/>Revealing the impact of synthetic native samples and multi-tasking strategies in Hindi-English code-mixed humour and sarcasm detection</a></a></li><li><a href=#sarcasm-r1-enhancing-sarcasm-detection-through-focused-reasoninghttpsaclanthologyorg2025findings-emnlp570 aria-label="Sarcasm-R1: Enhancing Sarcasm Detection through Focused Reasoning"><a href=https://aclanthology.org/2025.findings-emnlp.570/>Sarcasm-R1: Enhancing Sarcasm Detection through Focused Reasoning</a></a></li></ul></li><li><a href=#-figurative-language aria-label="üîç figurative language">üîç figurative language</a><ul><li><a href=#learning-trajectories-of-figurative-language-for-pre-trained-language-modelshttpsaclanthologyorg2025findings-emnlp779 aria-label="Learning Trajectories of Figurative Language for Pre-Trained Language Models"><a href=https://aclanthology.org/2025.findings-emnlp.779/>Learning Trajectories of Figurative Language for Pre-Trained Language Models</a></a></li></ul></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=weekly-paper-notes>Weekly Paper Notes<a hidden class=anchor aria-hidden=true href=#weekly-paper-notes>#</a></h1><h2 id=-multilingual>üîç multilingual<a hidden class=anchor aria-hidden=true href=#-multilingual>#</a></h2><h3 id=llms-know-more-than-words-a-genre-study-with-syntax-metaphor--phoneticshttpsarxivorgabs251204957v1><a href=https://arxiv.org/abs/2512.04957v1>LLMs Know More Than Words: A Genre Study with Syntax, Metaphor & Phonetics</a><a hidden class=anchor aria-hidden=true href=#llms-know-more-than-words-a-genre-study-with-syntax-metaphor--phoneticshttpsarxivorgabs251204957v1>#</a></h3><p><strong>Authors:</strong> Weiye Shi, Zhaowei Zhang, Shaoheng Yan, Yaodong Yang
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) demonstrate remarkable potential across diverse language related tasks, yet whether they capture deeper linguistic properties, such as syntactic structure, phonetic cues, and metrical patterns from raw text remains unclear. To analysis whether LLMs can learn these features effectively and apply them to important nature language related tasks, we introduce a novel multilingual genre classification dataset derived from Project Gutenberg, a large-scale digital library offering free access to thousands of public domain literary works, comprising thousands of sentences per binary task (poetry vs. novel;drama vs. poetry;drama vs. novel) in six languages (English, French, German, Italian, Spanish, and Portuguese). We augment each with three explicit linguistic feature sets (syntactic tree structures, metaphor counts, and phonetic metrics) to evaluate their impact on classification performance. Experiments demonstrate that although LLM classifiers can learn latent linguistic structures either from raw text or from explicitly provided features, different features contribute unevenly across tasks, which underscores the importance of incorporating more complex linguistic signals during model training.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04957v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04957v1">üìÑ Download PDF</a></p><hr><h3 id=toward-continuous-neurocognitive-monitoring-integrating-speech-ai-with-relational-graph-transformers-for-rare-neurological-diseaseshttpsarxivorgabs251204938v1><a href=https://arxiv.org/abs/2512.04938v1>Toward Continuous Neurocognitive Monitoring: Integrating Speech AI with Relational Graph Transformers for Rare Neurological Diseases</a><a hidden class=anchor aria-hidden=true href=#toward-continuous-neurocognitive-monitoring-integrating-speech-ai-with-relational-graph-transformers-for-rare-neurological-diseaseshttpsarxivorgabs251204938v1>#</a></h3><p><strong>Authors:</strong> Raquel Norel, Michele Merler, Pavitra Modi
<strong>Venue:</strong> arXiv (2025)</p><p>Patients with rare neurological diseases report cognitive symptoms -&ldquo;brain fog&rdquo;- invisible to traditional tests. We propose continuous neurocognitive monitoring via smartphone speech analysis integrated with Relational Graph Transformer (RELGT) architectures. Proof-of-concept in phenylketonuria (PKU) shows speech-derived &ldquo;Proficiency in Verbal Discourse&rdquo; correlates with blood phenylalanine (p = -0.50, p &lt; 0.005) but not standard cognitive tests (all |r| &lt; 0.35). RELGT could overcome information bottlenecks in heterogeneous medical data (speech, labs, assessments), enabling predictive alerts weeks before decompensation. Key challenges: multi-disease validation, clinical workflow integration, equitable multilingual deployment. Success would transform episodic neurology into continuous personalized monitoring for millions globally.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04938v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04938v1">üìÑ Download PDF</a></p><hr><h3 id=are-llms-truly-multilingual-exploring-zero-shot-multilingual-capability-of-llms-for-information-retrieval-an-italian-healthcare-use-casehttpsarxivorgabs251204834v1><a href=https://arxiv.org/abs/2512.04834v1>Are LLMs Truly Multilingual? Exploring Zero-Shot Multilingual Capability of LLMs for Information Retrieval: An Italian Healthcare Use Case</a><a hidden class=anchor aria-hidden=true href=#are-llms-truly-multilingual-exploring-zero-shot-multilingual-capability-of-llms-for-information-retrieval-an-italian-healthcare-use-casehttpsarxivorgabs251204834v1>#</a></h3><p><strong>Authors:</strong> Vignesh Kumar Kembu, Pierandrea Morandini, Marta Bianca Maria Ranzini, Antonino Nocera
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Models (LLMs) have become a key topic in AI and NLP, transforming sectors like healthcare, finance, education, and marketing by improving customer service, automating tasks, providing insights, improving diagnostics, and personalizing learning experiences. Information extraction from clinical records is a crucial task in digital healthcare. Although traditional NLP techniques have been used for this in the past, they often fall short due to the complexity, variability of clinical language, and high inner semantics in the free clinical text. Recently, Large Language Models (LLMs) have become a powerful tool for better understanding and generating human-like text, making them highly effective in this area. In this paper, we explore the ability of open-source multilingual LLMs to understand EHRs (Electronic Health Records) in Italian and help extract information from them in real-time. Our detailed experimental campaign on comorbidity extraction from EHR reveals that some LLMs struggle in zero-shot, on-premises settings, and others show significant variation in performance, struggling to generalize across various diseases when compared to native pattern matching and manual annotations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04834v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04834v1">üìÑ Download PDF</a></p><hr><h3 id=shared-multi-modal-embedding-space-for-face-voice-associationhttpsarxivorgabs251204814v1><a href=https://arxiv.org/abs/2512.04814v1>Shared Multi-modal Embedding Space for Face-Voice Association</a><a hidden class=anchor aria-hidden=true href=#shared-multi-modal-embedding-space-for-face-voice-associationhttpsarxivorgabs251204814v1>#</a></h3><p><strong>Authors:</strong> Christopher Simic, Korbinian Riedhammer, Tobias Bocklet
<strong>Venue:</strong> arXiv (2025)</p><p>The FAME 2026 challenge comprises two demanding tasks: training face-voice associations combined with a multilingual setting that includes testing on languages on which the model was not trained. Our approach consists of separate uni-modal processing pipelines with general face and voice feature extraction, complemented by additional age-gender feature extraction to support prediction. The resulting single-modal features are projected into a shared embedding space and trained with an Adaptive Angular Margin (AAM) loss. Our approach achieved first place in the FAME 2026 challenge, with an average Equal-Error Rate (EER) of 23.99%.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04814v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04814v1">üìÑ Download PDF</a></p><hr><h3 id=adibhashaa-a-community-curated-benchmark-for-machine-translation-into-indian-tribal-languageshttpsarxivorgabs251204765v1><a href=https://arxiv.org/abs/2512.04765v1>AdiBhashaa: A Community-Curated Benchmark for Machine Translation into Indian Tribal Languages</a><a hidden class=anchor aria-hidden=true href=#adibhashaa-a-community-curated-benchmark-for-machine-translation-into-indian-tribal-languageshttpsarxivorgabs251204765v1>#</a></h3><p><strong>Authors:</strong> Pooja Singh, Sandeep Kumar
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models and multilingual machine translation (MT) systems increasingly drive access to information, yet many languages of the tribal communities remain effectively invisible in these technologies. This invisibility exacerbates existing structural inequities in education, governance, and digital participation. We present AdiBhashaa, a community-driven initiative that constructs the first open parallel corpora and baseline MT systems for four major Indian tribal languages-Bhili, Mundari, Gondi, and Santali. This work combines participatory data creation with native speakers, human-in-the-loop validation, and systematic evaluation of both encoder-decoder MT models and large language models. In addition to reporting technical findings, we articulate how AdiBhashaa illustrates a possible model for more equitable AI research: it centers local expertise, builds capacity among early-career researchers from marginalized communities, and foregrounds human validation in the development of language technologies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04765v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04765v1">üìÑ Download PDF</a></p><hr><h3 id=has-acl-lost-its-crown-a-decade-long-quantitative-analysis-of-scale-and-impact-across-leading-ai-conferenceshttpsarxivorgabs251204448v1><a href=https://arxiv.org/abs/2512.04448v1>Has ACL Lost Its Crown? A Decade-Long Quantitative Analysis of Scale and Impact Across Leading AI Conferences</a><a hidden class=anchor aria-hidden=true href=#has-acl-lost-its-crown-a-decade-long-quantitative-analysis-of-scale-and-impact-across-leading-ai-conferenceshttpsarxivorgabs251204448v1>#</a></h3><p><strong>Authors:</strong> Jianglin Ma, Ben Yao, Xiang Li, Yazhou Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>The recent surge of language models has rapidly expanded NLP research, driving an exponential rise in submissions and acceptances at major conferences. Yet this growth has been shadowed by escalating concerns over conference quality, e.g., plagiarism, reviewer inexperience and collusive bidding. However, existing studies rely largely on qualitative accounts (e.g., expert interviews, social media discussions, etc.), lacking longitudinal empirical evidence. To fill this gap, we conduct a ten year empirical study spanning seven leading conferences. We build a four dimensional bibliometric framework covering conference scale, core citation statistics,impact dispersion, cross venue and journal influence, etc. Notably, we further propose a metric Quality Quantity Elasticity, which measures the elasticity of citation growth relative to acceptance growth. Our findings show that ML venues sustain dominant and stable impact, NLP venues undergo widening stratification with mixed expansion efficiency, and AI venues exhibit structural decline. This study provides the first decade-long, cross-venue empirical evidence on the evolution of major conferences.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04448v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04448v1">üìÑ Download PDF</a></p><hr><h3 id=mase-interpretable-nlp-models-via-model-agnostic-saliency-estimationhttpsarxivorgabs251204386v1><a href=https://arxiv.org/abs/2512.04386v1>MASE: Interpretable NLP Models via Model-Agnostic Saliency Estimation</a><a hidden class=anchor aria-hidden=true href=#mase-interpretable-nlp-models-via-model-agnostic-saliency-estimationhttpsarxivorgabs251204386v1>#</a></h3><p><strong>Authors:</strong> Zhou Yang, Shunyan Luo, Jiazhen Zhu, Fang Jin
<strong>Venue:</strong> arXiv (2025)</p><p>Deep neural networks (DNNs) have made significant strides in Natural Language Processing (NLP), yet their interpretability remains elusive, particularly when evaluating their intricate decision-making processes. Traditional methods often rely on post-hoc interpretations, such as saliency maps or feature visualization, which might not be directly applicable to the discrete nature of word data in NLP. Addressing this, we introduce the Model-agnostic Saliency Estimation (MASE) framework. MASE offers local explanations for text-based predictive models without necessitating in-depth knowledge of a model&rsquo;s internal architecture. By leveraging Normalized Linear Gaussian Perturbations (NLGP) on the embedding layer instead of raw word inputs, MASE efficiently estimates input saliency. Our results indicate MASE&rsquo;s superiority over other model-agnostic interpretation methods, especially in terms of Delta Accuracy, positioning it as a promising tool for elucidating the operations of text-based models in NLP.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04386v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04386v1">üìÑ Download PDF</a></p><hr><h3 id=langsat-a-novel-framework-combining-nlp-and-reinforcement-learning-for-sat-solvinghttpsarxivorgabs251204374v1><a href=https://arxiv.org/abs/2512.04374v1>LangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving</a><a hidden class=anchor aria-hidden=true href=#langsat-a-novel-framework-combining-nlp-and-reinforcement-learning-for-sat-solvinghttpsarxivorgabs251204374v1>#</a></h3><p><strong>Authors:</strong> Muyu Pan, Matthew Walter, Dheeraj Kodakandla, Mahfuza Farooque
<strong>Venue:</strong> arXiv (2025)</p><p>Our work presents a novel reinforcement learning (RL) based framework to optimize heuristic selection within the conflict-driven clause learning (CDCL) process, improving the efficiency of Boolean satisfiability (SAT) solving. The proposed system, LangSAT, bridges the gap between natural language inputs and propositional logic by converting English descriptions into Conjunctive Normal Form (CNF) expressions and solving them using an RL-enhanced CDCL SAT solver. Unlike existing SAT-solving platforms that require CNF as input, LangSAT enables users to input standard English descriptions, making SAT-solving more accessible. The framework comprises two key components: Lang2Logic, which translates English sentences into CNF expressions, and SmartSAT, an RL-based SAT solver. SmartSAT encodes clause-variable relationships as structured graph representations and extracts global features specific to the SAT problem. This implementation provides the RL agent with deeper contextual information, enabling SAT problems to be solved more efficiently. Lang2Logic was evaluated on diverse natural language inputs, processing descriptions up to 450 words. The generated CNFs were solved by SmartSAT, which demonstrated comparable performance to traditional CDCL heuristics with respect to solving time. The combined LangSAT framework offers a more accessible and scalable solution for SAT-solving tasks across reasoning, formal verification, and debugging.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04374v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04374v1">üìÑ Download PDF</a></p><hr><h3 id=computational-linguistics-meets-libyan-dialect-a-study-on-dialect-identificationhttpsarxivorgabs251204257v1><a href=https://arxiv.org/abs/2512.04257v1>Computational Linguistics Meets Libyan Dialect: A Study on Dialect Identification</a><a hidden class=anchor aria-hidden=true href=#computational-linguistics-meets-libyan-dialect-a-study-on-dialect-identificationhttpsarxivorgabs251204257v1>#</a></h3><p><strong>Authors:</strong> Mansour Essgaer, Khamis Massud, Rabia Al Mamlook, Najah Ghmaid
<strong>Venue:</strong> arXiv (2025)</p><p>This study investigates logistic regression, linear support vector machine, multinomial Naive Bayes, and Bernoulli Naive Bayes for classifying Libyan dialect utterances gathered from Twitter. The dataset used is the QADI corpus, which consists of 540,000 sentences across 18 Arabic dialects. Preprocessing challenges include handling inconsistent orthographic variations and non-standard spellings typical of the Libyan dialect. The chi-square analysis revealed that certain features, such as email mentions and emotion indicators, were not significantly associated with dialect classification and were thus excluded from further analysis. Two main experiments were conducted: (1) evaluating the significance of meta-features extracted from the corpus using the chi-square test and (2) assessing classifier performance using different word and character n-gram representations. The classification experiments showed that Multinomial Naive Bayes (MNB) achieved the highest accuracy of 85.89% and an F1-score of 0.85741 when using a (1,2) word n-gram and (1,5) character n-gram representation. In contrast, Logistic Regression and Linear SVM exhibited slightly lower performance, with maximum accuracies of 84.41% and 84.73%, respectively. Additional evaluation metrics, including log loss, Cohen kappa, and Matthew correlation coefficient, further supported the effectiveness of MNB in this task. The results indicate that carefully selected n-gram representations and classification models play a crucial role in improving the accuracy of Libyan dialect identification. This study provides empirical benchmarks and insights for future research in Arabic dialect NLP applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04257v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04257v1">üìÑ Download PDF</a></p><hr><h3 id=probabilistic-safety-under-arbitrary-disturbance-distributions-using-piecewise-affine-control-barrier-functionshttpsarxivorgabs251204194v1><a href=https://arxiv.org/abs/2512.04194v1>Probabilistic Safety under Arbitrary Disturbance Distributions using Piecewise-Affine Control Barrier Functions</a><a hidden class=anchor aria-hidden=true href=#probabilistic-safety-under-arbitrary-disturbance-distributions-using-piecewise-affine-control-barrier-functionshttpsarxivorgabs251204194v1>#</a></h3><p><strong>Authors:</strong> Matisse Teuwen, Mathijs Schuurmans, Panagiotis Patrinos
<strong>Venue:</strong> arXiv (2025)</p><p>We propose a simple safety filter design for stochastic discrete-time systems based on piecewise affine probabilistic control barrier functions, providing an appealing balance between modeling flexibility and computational complexity. Exact evaluation of the safety filter consists of solving a mixed-integer quadratic program (MIQP) if the dynamics are control-affine (or a mixed-integer nonlinear program in general). We propose a heuristic search method that replaces this by a small number of small-scale quadratic programs (QPs), or nonlinear programs (NLPs) respectively. The proposed approach provides a flexible framework in which arbitrary (data-driven) quantile estimators can be used to bound the probability of safety violations. Through extensive numerical experiments, we demonstrate improvements in conservatism and computation time with respect to existing methods, and we illustrate the flexibility of the method for modeling complex safety sets. Supplementary material can be found at <a href=https://mathijssch.github.io/ecc26-supplementary/>https://mathijssch.github.io/ecc26-supplementary/</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04194v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04194v1">üìÑ Download PDF</a></p><hr><h3 id=jina-vlm-small-multilingual-vision-language-modelhttpsarxivorgabs251204032v2><a href=https://arxiv.org/abs/2512.04032v2>Jina-VLM: Small Multilingual Vision Language Model</a><a hidden class=anchor aria-hidden=true href=#jina-vlm-small-multilingual-vision-language-modelhttpsarxivorgabs251204032v2>#</a></h3><p><strong>Authors:</strong> Andreas Koukounas, Georgios Mastrapas, Florian H√∂nicke, Sedigheh Eslami, Guillaume Roncari, Scott Martens, Han Xiao
<strong>Venue:</strong> arXiv (2025)</p><p>We present Jina-VLM, a 2.4B parameter vision-language model that achieves state-of-the-art multilingual visual question answering among open 2B-scale VLMs. The model couples a SigLIP2 vision encoder with a Qwen3 language backbone through an attention-pooling connector that enables token-efficient processing of arbitrary-resolution images. The model achieves leading results on standard VQA benchmarks and multilingual evaluations while preserving competitive text-only performance. Model weights and code are publicly released at <a href=https://huggingface.co/jinaai/jina-vlm>https://huggingface.co/jinaai/jina-vlm</a> .</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04032v2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04032v2">üìÑ Download PDF</a></p><hr><h3 id=adapting-large-language-models-to-low-resource-tibetan-a-two-stage-continual-and-supervised-fine-tuning-studyhttpsarxivorgabs251203976v1><a href=https://arxiv.org/abs/2512.03976v1>Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study</a><a hidden class=anchor aria-hidden=true href=#adapting-large-language-models-to-low-resource-tibetan-a-two-stage-continual-and-supervised-fine-tuning-studyhttpsarxivorgabs251203976v1>#</a></h3><p><strong>Authors:</strong> Lifeng Chen, Ryan Lai, Tianming Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Adapting large language models (LLMs) to low-resource languages remains a major challenge due to data scarcity and cross-lingual drift. This work presents a two-stage adaptation of Qwen2.5-3B to Tibetan, a morphologically rich and underrepresented language. We employ Continual Pretraining (CPT) to establish Tibetan linguistic grounding, followed by Supervised Fine-Tuning (SFT) for task and translation specialization. Empirical evaluations demonstrate a consistent decrease in perplexity (from 2.98 $\rightarrow$ 1.54) and substantial improvements in Chinese$\rightarrow$Tibetan translation quality (BLEU: 0.046 $\rightarrow$ 0.261; chrF: 2.2 $\rightarrow$ 6.6). Layer-wise analysis across 435 layers in Qwen3-4B reveals that adaptation primarily concentrates on embedding and output heads, with mid&ndash;late MLP projections encoding domain-specific transformations. Our findings suggest that CPT constructs a Tibetan semantic manifold while SFT sharpens task alignment with minimal representational disruption. This study provides the first quantitative exploration of Tibetan adaptation dynamics for LLMs, and offers an open, reproducible framework for extending multilingual foundation models to low-resource settings.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03976v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03976v1">üìÑ Download PDF</a></p><hr><h3 id=is-lying-only-sinful-in-islam-exploring-religious-bias-in-multilingual-large-language-models-across-major-religionshttpsarxivorgabs251203943v1><a href=https://arxiv.org/abs/2512.03943v1>Is Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions</a><a hidden class=anchor aria-hidden=true href=#is-lying-only-sinful-in-islam-exploring-religious-bias-in-multilingual-large-language-models-across-major-religionshttpsarxivorgabs251203943v1>#</a></h3><p><strong>Authors:</strong> Kazi Abrab Hossain, Jannatul Somiya Mahmud, Maria Hossain Tuli, Anik Mitra, S. M. Taiabul Haque, Farig Y. Sadeque
<strong>Venue:</strong> arXiv (2025)</p><p>While recent developments in large language models have improved bias detection and classification, sensitive subjects like religion still present challenges because even minor errors can result in severe misunderstandings. In particular, multilingual models often misrepresent religions and have difficulties being accurate in religious contexts. To address this, we introduce BRAND: Bilingual Religious Accountable Norm Dataset, which focuses on the four main religions of South Asia: Buddhism, Christianity, Hinduism, and Islam, containing over 2,400 entries, and we used three different types of prompts in both English and Bengali. Our results indicate that models perform better in English than in Bengali and consistently display bias toward Islam, even when answering religion-neutral questions. These findings highlight persistent bias in multilingual models when similar questions are asked in different languages. We further connect our findings to the broader issues in HCI regarding religion and spirituality.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03943v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03943v1">üìÑ Download PDF</a></p><hr><h3 id=diminishing-returns-in-self-supervised-learninghttpsarxivorgabs251203862v1><a href=https://arxiv.org/abs/2512.03862v1>Diminishing Returns in Self-Supervised Learning</a><a hidden class=anchor aria-hidden=true href=#diminishing-returns-in-self-supervised-learninghttpsarxivorgabs251203862v1>#</a></h3><p><strong>Authors:</strong> Oli Bridge, Huey Sun, Botond Branyicskai-Nagy, Charles D&rsquo;Ornano, Shomit Basu
<strong>Venue:</strong> arXiv (2025)</p><p>While transformer-based architectures have taken computer vision and NLP by storm, they often require a vast amount of parameters and training data to attain strong performance. In this work, we experiment with three distinct pre-training, intermediate fine-tuning, and downstream datasets and training objectives to explore their marginal benefits on a small 5M-parameter vision transformer. We find that while pre-training and fine-tuning always help our model but have diminishing returns, intermediate fine-tuning can actually show harmful impact on downstream performance, potentially due to dissimilarity in task mechanics. Taken together, our results suggest that small-scale ViTs benefit most from targeted pre-training and careful data selection, while indiscriminate stacking of intermediate tasks can waste compute and even degrade performance.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03862v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03862v1">üìÑ Download PDF</a></p><hr><h3 id=m3dr-towards-universal-multilingual-multimodal-document-retrievalhttpsarxivorgabs251203514v1><a href=https://arxiv.org/abs/2512.03514v1>M3DR: Towards Universal Multilingual Multimodal Document Retrieval</a><a hidden class=anchor aria-hidden=true href=#m3dr-towards-universal-multilingual-multimodal-document-retrievalhttpsarxivorgabs251203514v1>#</a></h3><p><strong>Authors:</strong> Adithya S Kolavi, Vyoman Jain
<strong>Venue:</strong> arXiv (2025)</p><p>Multimodal document retrieval systems have shown strong progress in aligning visual and textual content for semantic search. However, most existing approaches remain heavily English-centric, limiting their effectiveness in multilingual contexts. In this work, we present M3DR (Multilingual Multimodal Document Retrieval), a framework designed to bridge this gap across languages, enabling applicability across diverse linguistic and cultural contexts. M3DR leverages synthetic multilingual document data and generalizes across different vision-language architectures and model sizes, enabling robust cross-lingual and cross-modal alignment. Using contrastive training, our models learn unified representations for text and document images that transfer effectively across languages. We validate this capability on 22 typologically diverse languages, demonstrating consistent performance and adaptability across linguistic and script variations. We further introduce a comprehensive benchmark that captures real-world multilingual scenarios, evaluating models under monolingual, multilingual, and mixed-language settings. M3DR generalizes across both single dense vector and ColBERT-style token-level multi-vector retrieval paradigms. Our models, NetraEmbed and ColNetraEmbed achieve state-of-the-art performance with ~150% relative improvements on cross-lingual retrieval.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03514v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03514v1">üìÑ Download PDF</a></p><hr><h3 id=dual-lora-enhancing-lora-with-magnitude-and-direction-updateshttpsarxivorgabs251203402v1><a href=https://arxiv.org/abs/2512.03402v1>Dual LoRA: Enhancing LoRA with Magnitude and Direction Updates</a><a hidden class=anchor aria-hidden=true href=#dual-lora-enhancing-lora-with-magnitude-and-direction-updateshttpsarxivorgabs251203402v1>#</a></h3><p><strong>Authors:</strong> Yixing Xu, Chao Li, Xuanwu Yin, Spandan Tiwari, Dong Li, Ashish Sirasao, Emad Barsoum
<strong>Venue:</strong> arXiv (2025)</p><p>Low-rank adaptation (LoRA) is one of the most popular methods among parameter-efficient fine-tuning (PEFT) methods to adapt pre-trained large language models (LLMs) to specific downstream tasks. However, the model trained based on LoRA often has an unsatisfactory performance due to its low-rank assumption. In this paper, we propose a novel method called Dual LoRA to improve the performance by incorporating an inductive bias into the original LoRA. Specifically, we separate low-rank matrices into two groups: the magnitude group to control whether or not and how far we should update a parameter and the direction group to decide whether this parameter should move forward or backward, to better simulate the parameter updating process of the full fine-tuning based on gradient-based optimization algorithms. We show that this can be simply achieved by adding a ReLU function to the magnitude group and a sign function to the direction group. We conduct several experiments over a wide range of NLP tasks, including natural language generation (NLG), understanding (NLU), and commonsense reasoning datasets on GPT-2, RoBERTa, DeBERTa, and LLaMA-1/2/3 as baseline models. The results show that we consistently outperform LoRA and its state-of-the-art variants with the same number of trainable parameters.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03402v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03402v1">üìÑ Download PDF</a></p><hr><h3 id=fine-tuned-large-language-models-for-logical-translation-reducing-hallucinations-with-lang2logichttpsarxivorgabs251202987v1><a href=https://arxiv.org/abs/2512.02987v1>Fine-Tuned Large Language Models for Logical Translation: Reducing Hallucinations with Lang2Logic</a><a hidden class=anchor aria-hidden=true href=#fine-tuned-large-language-models-for-logical-translation-reducing-hallucinations-with-lang2logichttpsarxivorgabs251202987v1>#</a></h3><p><strong>Authors:</strong> Muyu Pan, Dheeraj Kodakandla, Mahfuza Farooque
<strong>Venue:</strong> arXiv (2025)</p><p>Recent advances in natural language processing (NLP), particularly large language models (LLMs), have motivated the automatic translation of natural language statements into formal logic without human intervention. This enables automated reasoning and facilitates debugging, finding loop invariants, and adhering to specifications in software systems. However, hallucinations-incorrect outputs generated by LLMs are challenging, particularly for logical translation tasks requiring precision. This work introduces a novel framework that inputs English sentences, converts them into logical expressions, and then translates them into Conjunctive Normal Form (CNF) for satisfiability solving. It employs classical NLP techniques with self-defined grammar, symbolic computation libraries, and a fine-tuned language model to reduce hallucinations. In the early experiments, we observed that the fine-tuned model, trained on different grammar settings, could intentionally correct the same types of hallucinations made by the original model. Thus, it provides reliable CNF generation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02987v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02987v1">üìÑ Download PDF</a></p><hr><h3 id=rfop-rethinking-fusion-and-orthogonal-projection-for-face-voice-associationhttpsarxivorgabs251202860v1><a href=https://arxiv.org/abs/2512.02860v1>RFOP: Rethinking Fusion and Orthogonal Projection for Face-Voice Association</a><a hidden class=anchor aria-hidden=true href=#rfop-rethinking-fusion-and-orthogonal-projection-for-face-voice-associationhttpsarxivorgabs251202860v1>#</a></h3><p><strong>Authors:</strong> Abdul Hannan, Furqan Malik, Hina Jabbar, Syed Suleman Sadiq, Mubashir Noman
<strong>Venue:</strong> arXiv (2025)</p><p>Face-voice association in multilingual environment challenge 2026 aims to investigate the face-voice association task in multilingual scenario. The challenge introduces English-German face-voice pairs to be utilized in the evaluation phase. To this end, we revisit the fusion and orthogonal projection for face-voice association by effectively focusing on the relevant semantic information within the two modalities. Our method performs favorably on the English-German data split and ranked 3rd in the FAME 2026 challenge by achieving the EER of 33.1.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02860v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02860v1">üìÑ Download PDF</a></p><hr><h3 id=cross-lingual-prompt-steerability-towards-accurate-and-robust-llm-behavior-across-languageshttpsarxivorgabs251202841v1><a href=https://arxiv.org/abs/2512.02841v1>Cross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages</a><a hidden class=anchor aria-hidden=true href=#cross-lingual-prompt-steerability-towards-accurate-and-robust-llm-behavior-across-languageshttpsarxivorgabs251202841v1>#</a></h3><p><strong>Authors:</strong> Lechen Zhang, Yusheng Zhou, Tolga Ergen, Lajanugen Logeswaran, Moontae Lee, David Jurgens
<strong>Venue:</strong> arXiv (2025)</p><p>System prompts provide a lightweight yet powerful mechanism for conditioning large language models (LLMs) at inference time. While prior work has focused on English-only settings, real-world deployments benefit from having a single prompt to operate reliably across languages. This paper presents a comprehensive study of how different system prompts steer models toward accurate and robust cross-lingual behavior. We propose a unified four-dimensional evaluation framework to assess system prompts in multilingual environments. Through large-scale experiments on five languages, three LLMs, and three benchmarks, we uncover that certain prompt components, such as CoT, emotion, and scenario, correlate with robust multilingual behavior. We develop a prompt optimization framework for multilingual settings and show it can automatically discover prompts that improve all metrics by 5-10%. Finally, we analyze over 10 million reasoning units and find that more performant system prompts induce more structured and consistent reasoning patterns, while reducing unnecessary language-switching. Together, we highlight system prompt optimization as a scalable path to accurate and robust multilingual LLM behavior.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02841v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02841v1">üìÑ Download PDF</a></p><hr><h3 id=boom-beyond-only-one-modality-kits-multimodal-multilingual-lecture-companionhttpsarxivorgabs251202817v1><a href=https://arxiv.org/abs/2512.02817v1>BOOM: Beyond Only One Modality KIT&rsquo;s Multimodal Multilingual Lecture Companion</a><a hidden class=anchor aria-hidden=true href=#boom-beyond-only-one-modality-kits-multimodal-multilingual-lecture-companionhttpsarxivorgabs251202817v1>#</a></h3><p><strong>Authors:</strong> Sai Koneru, Fabian Retkowski, Christian Huber, Lukas Hilgert, Seymanur Akti, Enes Yavuz Ugan, Alexander Waibel, Jan Niehues
<strong>Venue:</strong> arXiv (2025)</p><p>The globalization of education and rapid growth of online learning have made localizing educational content a critical challenge. Lecture materials are inherently multimodal, combining spoken audio with visual slides, which requires systems capable of processing multiple input modalities. To provide an accessible and complete learning experience, translations must preserve all modalities: text for reading, slides for visual understanding, and speech for auditory learning. We present \textbf{BOOM}, a multimodal multilingual lecture companion that jointly translates lecture audio and slides to produce synchronized outputs across three modalities: translated text, localized slides with preserved visual elements, and synthesized speech. This end-to-end approach enables students to access lectures in their native language while aiming to preserve the original content in its entirety. Our experiments demonstrate that slide-aware transcripts also yield cascading benefits for downstream tasks such as summarization and question answering. We release our Slide Translation code at <a href=https://github.com/saikoneru/image-translator>https://github.com/saikoneru/image-translator</a> and integrate it in Lecture Translator at <a href=https://gitlab.kit.edu/kit/isl-ai4lt/lt-middleware/ltpipeline%7D>https://gitlab.kit.edu/kit/isl-ai4lt/lt-middleware/ltpipeline}</a>\footnote{All released code and models are licensed under the MIT License.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02817v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02817v1">üìÑ Download PDF</a></p><hr><h3 id=trilex-a-framework-for-multilingual-sentiment-analysis-in-low-resource-south-african-languageshttpsarxivorgabs251202799v1><a href=https://arxiv.org/abs/2512.02799v1>TriLex: A Framework for Multilingual Sentiment Analysis in Low-Resource South African Languages</a><a hidden class=anchor aria-hidden=true href=#trilex-a-framework-for-multilingual-sentiment-analysis-in-low-resource-south-african-languageshttpsarxivorgabs251202799v1>#</a></h3><p><strong>Authors:</strong> Mike Nkongolo, Hilton Vorster, Josh Warren, Trevor Naick, Deandre Vanmali, Masana Mashapha, Luke Brand, Alyssa Fernandes, Janco Calitz, Sibusiso Makhoba
<strong>Venue:</strong> arXiv (2025)</p><p>Low-resource African languages remain underrepresented in sentiment analysis, limiting both lexical coverage and the performance of multilingual Natural Language Processing (NLP) systems. This study proposes TriLex, a three-stage retrieval augmented framework that unifies corpus-based extraction, cross lingual mapping, and retrieval augmented generation (RAG) driven lexical refinement to systematically expand sentiment lexicons for low-resource languages. Using the enriched lexicon, the performance of two prominent African pretrained language models (AfroXLMR and AfriBERTa) is evaluated across multiple case studies. Results demonstrate that AfroXLMR delivers superior performance, achieving F1-scores above 80% for isiXhosa and isiZulu and exhibiting strong cross-lingual stability. Although AfriBERTa lacks pre-training on these target languages, it still achieves reliable F1-scores around 64%, validating its utility in computationally constrained settings. Both models outperform traditional machine learning baselines, and ensemble analyses further enhance precision and robustness. The findings establish TriLex as a scalable and effective framework for multilingual sentiment lexicon expansion and sentiment modeling in low-resource South African languages.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02799v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02799v1">üìÑ Download PDF</a></p><hr><h3 id=towards-language-independent-face-voice-association-with-multimodal-foundation-modelshttpsarxivorgabs251202759v1><a href=https://arxiv.org/abs/2512.02759v1>Towards Language-Independent Face-Voice Association with Multimodal Foundation Models</a><a hidden class=anchor aria-hidden=true href=#towards-language-independent-face-voice-association-with-multimodal-foundation-modelshttpsarxivorgabs251202759v1>#</a></h3><p><strong>Authors:</strong> Aref Farhadipour, Teodora Vukovic, Volker Dellwo
<strong>Venue:</strong> arXiv (2025)</p><p>This paper describes the UZH-CL system submitted to the FAME2026 Challenge. The challenge focuses on cross-modal verification under unique multilingual conditions, specifically unseen and unheard languages. Our approach investigates two distinct architectures, consisting of a baseline dual-encoder system trained from scratch using contrastive and orthogonal projection losses, and a foundation model approach leveraging ImageBind with LoRA. To address the data scarcity and language constraints of the challenge, we curated an external Arabic dataset from VoxBlink. Our best-performing system, ImageBind-LoRA, demonstrates remarkable cross-lingual generalization: despite being fine-tuned exclusively on Arabic audio, it achieved an EER of 24.73% on the evaluation set (English and German), securing 2nd place in the competition.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02759v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02759v1">üìÑ Download PDF</a></p><hr><h3 id=crest-universal-safety-guardrails-through-cluster-guided-cross-lingual-transferhttpsarxivorgabs251202711v1><a href=https://arxiv.org/abs/2512.02711v1>CREST: Universal Safety Guardrails Through Cluster-Guided Cross-Lingual Transfer</a><a hidden class=anchor aria-hidden=true href=#crest-universal-safety-guardrails-through-cluster-guided-cross-lingual-transferhttpsarxivorgabs251202711v1>#</a></h3><p><strong>Authors:</strong> Lavish Bansal, Naman Mishra
<strong>Venue:</strong> arXiv (2025)</p><p>Ensuring content safety in large language models (LLMs) is essential for their deployment in real-world applications. However, existing safety guardrails are predominantly tailored for high-resource languages, leaving a significant portion of the world&rsquo;s population underrepresented who communicate in low-resource languages. To address this, we introduce CREST (CRoss-lingual Efficient Safety Transfer), a parameter-efficient multilingual safety classification model that supports 100 languages with only 0.5B parameters. By training on a strategically chosen subset of only 13 high-resource languages, our model utilizes cluster-based cross-lingual transfer from a few to 100 languages, enabling effective generalization to both unseen high-resource and low-resource languages. This approach addresses the challenge of limited training data in low-resource settings. We conduct comprehensive evaluations across six safety benchmarks to demonstrate that CREST outperforms existing state-of-the-art guardrails of comparable scale and achieves competitive results against models with significantly larger parameter counts (2.5B parameters and above). Our findings highlight the limitations of language-specific guardrails and underscore the importance of developing universal, language-agnostic safety systems that can scale effectively to serve global populations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02711v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02711v1">üìÑ Download PDF</a></p><hr><h3 id=dotsocr-multilingual-document-layout-parsing-in-a-single-vision-language-modelhttpsarxivorgabs251202498v1><a href=https://arxiv.org/abs/2512.02498v1>dots.ocr: Multilingual Document Layout Parsing in a Single Vision-Language Model</a><a hidden class=anchor aria-hidden=true href=#dotsocr-multilingual-document-layout-parsing-in-a-single-vision-language-modelhttpsarxivorgabs251202498v1>#</a></h3><p><strong>Authors:</strong> Yumeng Li, Guang Yang, Hao Liu, Bowen Wang, Colin Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>Document Layout Parsing serves as a critical gateway for Artificial Intelligence (AI) to access and interpret the world&rsquo;s vast stores of structured knowledge. This process,which encompasses layout detection, text recognition, and relational understanding, is particularly crucial for empowering next-generation Vision-Language Models. Current methods, however, rely on fragmented, multi-stage pipelines that suffer from error propagation and fail to leverage the synergies of joint training. In this paper, we introduce dots.ocr, a single Vision-Language Model that, for the first time, demonstrates the advantages of jointly learning three core tasks within a unified, end-to-end framework. This is made possible by a highly scalable data engine that synthesizes a vast multilingual corpus, empowering the model to deliver robust performance across a wide array of tasks, encompassing diverse languages, layouts, and domains. The efficacy of our unified paradigm is validated by state-of-the-art performance on the comprehensive OmniDocBench. Furthermore, to catalyze research in global document intelligence, we introduce XDocParse, a challenging new benchmark spanning 126 languages. On this testbed, dots.ocr establishes a powerful new baseline, outperforming the next-best competitor by a remarkable +7.4 point margin and proving its unparalleled multilingual capabilities.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02498v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02498v1">üìÑ Download PDF</a></p><hr><h3 id=swivuriso-the-south-african-next-voices-multilingual-speech-datasethttpsarxivorgabs251202201v1><a href=https://arxiv.org/abs/2512.02201v1>Swivuriso: The South African Next Voices Multilingual Speech Dataset</a><a hidden class=anchor aria-hidden=true href=#swivuriso-the-south-african-next-voices-multilingual-speech-datasethttpsarxivorgabs251202201v1>#</a></h3><p><strong>Authors:</strong> Vukosi Marivatee, Kayode Olaleye, Sitwala Mundia, Andinda Bakainga, Unarine Netshifhefhe, Mahmooda Milanzie, Tsholofelo Hope Mogale, Thapelo Sindane, Zainab Abdulrasaq, Kesego Mokgosi, Chijioke Okorie, Nia Zion Van Wyk, Graham Morrissey, Dale Dunbar, Francois Smit, Tsosheletso Chidi, Rooweither Mabuya, Andiswa Bukula, Respect Mlambo, Tebogo Macucwa, Idris Abdulmumin, and Seani Rananga
<strong>Venue:</strong> arXiv (2025)</p><p>This paper introduces Swivuriso, a 3000-hour multilingual speech dataset developed as part of the African Next Voices project, to support the development and benchmarking of automatic speech recognition (ASR) technologies in seven South African languages. Covering agriculture, healthcare, and general domain topics, Swivuriso addresses significant gaps in existing ASR datasets. We describe the design principles, ethical considerations, and data collection procedures that guided the dataset creation. We present baseline results of training/finetuning ASR models with this data and compare to other ASR datasets for the langauges concerned.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02201v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02201v1">üìÑ Download PDF</a></p><hr><h3 id=cross-lingual-interleaving-for-speech-language-modelshttpsarxivorgabs251201865v1><a href=https://arxiv.org/abs/2512.01865v1>Cross-Lingual Interleaving for Speech Language Models</a><a hidden class=anchor aria-hidden=true href=#cross-lingual-interleaving-for-speech-language-modelshttpsarxivorgabs251201865v1>#</a></h3><p><strong>Authors:</strong> Adel Moumen, Guangzhi Sun, Philip C. Woodland
<strong>Venue:</strong> arXiv (2025)</p><p>Spoken Language Models (SLMs) aim to learn linguistic competence directly from speech using discrete units, widening access to Natural Language Processing (NLP) technologies for languages with limited written resources. However, progress has been largely English-centric due to scarce spoken evaluation benchmarks and training data, making cross-lingual learning difficult. We present a cross-lingual interleaving method that mixes speech tokens across languages without textual supervision. We also release an EN-FR training dataset, TinyStories (~42k hours), together with EN-FR spoken StoryCloze and TopicCloze benchmarks for cross-lingual semantic evaluation, both synthetically generated using GPT-4. On 360M and 1B SLMs under matched training-token budgets, interleaving improves monolingual semantic accuracy, enables robust cross-lingual continuation, and strengthens cross-lingual hidden-state alignment. Taken together, these results indicate that cross-lingual interleaving is a simple, scalable route to building multilingual SLMs that understand and converse across languages. All resources will be made open-source to support reproducibility.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01865v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01865v1">üìÑ Download PDF</a></p><hr><h3 id=bhram-il-a-benchmark-for-hallucination-recognition-and-assessment-in-multiple-indian-languageshttpsarxivorgabs251201852v1><a href=https://arxiv.org/abs/2512.01852v1>BHRAM-IL: A Benchmark for Hallucination Recognition and Assessment in Multiple Indian Languages</a><a hidden class=anchor aria-hidden=true href=#bhram-il-a-benchmark-for-hallucination-recognition-and-assessment-in-multiple-indian-languageshttpsarxivorgabs251201852v1>#</a></h3><p><strong>Authors:</strong> Hrishikesh Terdalkar, Kirtan Bhojani, Aryan Dongare, Omm Aditya Behera
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) are increasingly deployed in multilingual applications but often generate plausible yet incorrect or misleading outputs, known as hallucinations. While hallucination detection has been studied extensively in English, under-resourced Indian languages remain largely unexplored. We present BHRAM-IL, a benchmark for hallucination recognition and assessment in multiple Indian languages, covering Hindi, Gujarati, Marathi, Odia, along with English. The benchmark comprises 36,047 curated questions across nine categories spanning factual, numerical, reasoning, and linguistic tasks. We evaluate 14 state-of-the-art multilingual LLMs on a benchmark subset of 10,265 questions, analyzing cross-lingual and factual hallucinations across languages, models, scales, categories, and domains using category-specific metrics normalized to (0,1) range. Aggregation over all categories and models yields a primary score of 0.23 and a language-corrected fuzzy score of 0.385, demonstrating the usefulness of BHRAM-IL for hallucination-focused evaluation. The dataset, and the code for generation and evaluation are available on GitHub (<a href=https://github.com/sambhashana/BHRAM-IL/>https://github.com/sambhashana/BHRAM-IL/</a>) and HuggingFace (<a href=https://huggingface.co/datasets/sambhashana/BHRAM-IL/>https://huggingface.co/datasets/sambhashana/BHRAM-IL/</a>) to support future research in multilingual hallucination detection and mitigation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01852v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01852v1">üìÑ Download PDF</a></p><hr><h3 id=self-supervised-borrowing-detection-on-multilingual-wordlistshttpsarxivorgabs251201713v1><a href=https://arxiv.org/abs/2512.01713v1>Self-Supervised Borrowing Detection on Multilingual Wordlists</a><a hidden class=anchor aria-hidden=true href=#self-supervised-borrowing-detection-on-multilingual-wordlistshttpsarxivorgabs251201713v1>#</a></h3><p><strong>Authors:</strong> Tim Wientzek
<strong>Venue:</strong> arXiv (2025)</p><p>This paper presents a fully self-supervised approach to borrowing detection in multilingual wordlists. The method combines two sources of information: PMI similarities based on a global correspondence model and a lightweight contrastive component trained on phonetic feature vectors. It further includes an automatic procedure for selecting decision thresholds without requiring labeled data. Experiments on benchmark datasets show that PMI alone already improves over existing string similarity measures such as NED and SCA, and that the combined similarity performs on par with or better than supervised baselines. An ablation study highlights the importance of character encoding, temperature settings and augmentation strategies. The approach scales to datasets of different sizes, works without manual supervision and is provided with a command-line tool that allows researchers to conduct their own studies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01713v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01713v1">üìÑ Download PDF</a></p><hr><h3 id=demystifying-feature-engineering-in-malware-analysis-of-api-call-sequenceshttpsarxivorgabs251201666v1><a href=https://arxiv.org/abs/2512.01666v1>Demystifying Feature Engineering in Malware Analysis of API Call Sequences</a><a hidden class=anchor aria-hidden=true href=#demystifying-feature-engineering-in-malware-analysis-of-api-call-sequenceshttpsarxivorgabs251201666v1>#</a></h3><p><strong>Authors:</strong> Tianheng Qu, Hongsong Zhu, Limin Sun, Haining Wang, Haiqiang Fei, Zheng He, Zhi Li
<strong>Venue:</strong> arXiv (2025)</p><p>Machine learning (ML) has been widely used to analyze API call sequences in malware analysis, which typically requires the expertise of domain specialists to extract relevant features from raw data. The extracted features play a critical role in malware analysis. Traditional feature extraction is based on human domain knowledge, while there is a trend of using natural language processing (NLP) for automatic feature extraction. This raises a question: how do we effectively select features for malware analysis based on API call sequences? To answer it, this paper presents a comprehensive study of investigating the impact of feature engineering upon malware classification.We first conducted a comparative performance evaluation under three models, Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and Transformer, with respect to knowledge-based and NLP-based feature engineering methods. We observed that models with knowledge-based feature engineering inputs generally outperform those using NLP-based across all metrics, especially under smaller sample sizes. Then we analyzed a complete set of data features from API call sequences, our analysis reveals that models often focus on features such as handles and virtual addresses, which vary across executions and are difficult for human analysts to interpret.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01666v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01666v1">üìÑ Download PDF</a></p><hr><h3 id=deep-flexqp-accelerated-nonlinear-programming-via-deep-unfoldinghttpsarxivorgabs251201565v1><a href=https://arxiv.org/abs/2512.01565v1>Deep FlexQP: Accelerated Nonlinear Programming via Deep Unfolding</a><a hidden class=anchor aria-hidden=true href=#deep-flexqp-accelerated-nonlinear-programming-via-deep-unfoldinghttpsarxivorgabs251201565v1>#</a></h3><p><strong>Authors:</strong> Alex Oshin, Rahul Vodeb Ghosh, Augustinos D. Saravanos, Evangelos A. Theodorou
<strong>Venue:</strong> arXiv (2025)</p><p>We propose an always-feasible quadratic programming (QP) optimizer, FlexQP, which is based on an exact relaxation of the QP constraints. If the original constraints are feasible, then the optimizer finds the optimal solution to the original QP. On the other hand, if the constraints are infeasible, the optimizer identifies a solution that minimizes the constraint violation in a sparse manner. FlexQP scales favorably with respect to the problem dimension, is robust to both feasible and infeasible QPs with minimal assumptions on the problem data, and can be effectively warm-started. We subsequently apply deep unfolding to improve our optimizer through data-driven techniques, leading to an accelerated Deep FlexQP. By learning dimension-agnostic feedback policies for the parameters from a small number of training examples, Deep FlexQP generalizes to problems with larger dimensions and can optimize for many more iterations than it was initially trained for. Our approach outperforms two recently proposed state-of-the-art accelerated QP approaches on a suite of benchmark systems including portfolio optimization, classification, and regression problems. We provide guarantees on the expected performance of our deep QP optimizer through probably approximately correct (PAC) Bayes generalization bounds. These certificates are used to design an accelerated sequential quadratic programming solver that solves nonlinear optimal control and predictive safety filter problems faster than traditional approaches. Overall, our approach is very robust and greatly outperforms existing non-learning and learning-based optimizers in terms of both runtime and convergence to the optimal solution across multiple classes of NLPs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01565v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01565v1">üìÑ Download PDF</a></p><hr><h3 id=mcat-scaling-many-to-many-speech-to-text-translation-with-mllms-to-70-languageshttpsarxivorgabs251201512v1><a href=https://arxiv.org/abs/2512.01512v1>MCAT: Scaling Many-to-Many Speech-to-Text Translation with MLLMs to 70 Languages</a><a hidden class=anchor aria-hidden=true href=#mcat-scaling-many-to-many-speech-to-text-translation-with-mllms-to-70-languageshttpsarxivorgabs251201512v1>#</a></h3><p><strong>Authors:</strong> Yexing Du, Kaiyuan Liu, Youcheng Pan, Bo Yang, Keqi Deng, Xie Chen, Yang Xiang, Ming Liu, Bin Qin, YaoWei Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Multimodal Large Language Models (MLLMs) have achieved great success in Speech-to-Text Translation (S2TT) tasks. However, current research is constrained by two key challenges: language coverage and efficiency. Most of the popular S2TT datasets are substantially English-centric, which restricts the scaling-up of MLLMs&rsquo; many-to-many translation capabilities. Moreover, the inference speed of MLLMs degrades dramatically when the speech is converted into long sequences (e.g., 750 tokens). To address these limitations, we propose a Multilingual Cost-effective Accelerated Speech-to-Text Translator (MCAT) framework, which includes two innovations. First, a language scaling method that leverages curriculum learning and a data balancing strategy is introduced to extend the language coverage supported by MLLMs to 70 languages and achieve mutual translation among these languages. Second, an optimized speech adapter module is designed to reduce the length of the speech sequence to only 30 tokens. Extensive experiments were conducted on MLLMs of different scales (9B and 27B). The experimental results demonstrate that MCAT not only surpasses state-of-the-art end-to-end models on the FLEURS dataset across 70x69 directions but also enhances batch inference efficiency. This is achieved with only ~100M trainable parameters and by using only 10 hours of S2TT data per language. Furthermore, we have released MCAT as open-source to promote the development of MLLMs for robust S2TT capabilities. The code and models are released at <a href=https://github.com/yxduir/m2m-70>https://github.com/yxduir/m2m-70</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01512v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01512v1">üìÑ Download PDF</a></p><hr><h3 id=multilingual-conversational-ai-for-financial-assistance-bridging-language-barriers-in-indian-fintechhttpsarxivorgabs251201439v1><a href=https://arxiv.org/abs/2512.01439v1>Multilingual Conversational AI for Financial Assistance: Bridging Language Barriers in Indian FinTech</a><a hidden class=anchor aria-hidden=true href=#multilingual-conversational-ai-for-financial-assistance-bridging-language-barriers-in-indian-fintechhttpsarxivorgabs251201439v1>#</a></h3><p><strong>Authors:</strong> Bharatdeep Hazarika, Arya Suneesh, Prasanna Devadiga, Pawan Kumar Rajpoot, Anshuman B Suresh, Ahmed Ifthaquar Hussain
<strong>Venue:</strong> arXiv (2025)</p><p>India&rsquo;s linguistic diversity presents both opportunities and challenges for fintech platforms. While the country has 31 major languages and over 100 minor ones, only 10% of the population understands English, creating barriers to financial inclusion. We present a multilingual conversational AI system for a financial assistance use case that supports code-mixed languages like Hinglish, enabling natural interactions for India&rsquo;s diverse user base. Our system employs a multi-agent architecture with language classification, function management, and multilingual response generation. Through comparative analysis of multiple language models and real-world deployment, we demonstrate significant improvements in user engagement while maintaining low latency overhead (4-8%). This work contributes to bridging the language gap in digital financial services for emerging markets.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01439v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01439v1">üìÑ Download PDF</a></p><hr><h3 id=backportbench-a-multilingual-benchmark-for-automated-backporting-of-patcheshttpsarxivorgabs251201396v1><a href=https://arxiv.org/abs/2512.01396v1>BackportBench: A Multilingual Benchmark for Automated Backporting of Patches</a><a hidden class=anchor aria-hidden=true href=#backportbench-a-multilingual-benchmark-for-automated-backporting-of-patcheshttpsarxivorgabs251201396v1>#</a></h3><p><strong>Authors:</strong> Zhiqing Zhong, Jiaming Huang, Pinjia He
<strong>Venue:</strong> arXiv (2025)</p><p>Many modern software projects evolve rapidly to incorporate new features and security patches. It is important for users to update their dependencies to safer versions, but many still use older, vulnerable package versions because upgrading can be difficult and may break their existing codebase. Software developers can mitigate this problem by backporting security patches to older releases. However, manually backporting is time-consuming and error-prone. The effectiveness of existing automated backporting techniques on general software remains unclear since they typically target only code-hunk or function-level patch porting scenarios and are evaluated with imperfect metrics.
To facilitate the development and evaluation of automated backporting techniques, we introduce BackportBench, the first comprehensive benchmark suite for patch backporting problem. BackportBench is a multilingual benchmark that contains 202 patch backporting problems from PyPI, Maven, and npm, each with executable Docker environments and relevant test cases. We evaluated existing patch porting methods and LLM-based techniques that have the potential to adapt to this task using BackportBench. The results show that the agentic method has outperformed traditional patch porting methods, especially on cases that require logical and structural changes. However, the performance varies across different programming languages. Based on the findings, we draw several implications for researchers and software practitioners in future work on automated backporting.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01396v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01396v1">üìÑ Download PDF</a></p><hr><h3 id=re-llm-integrating-large-language-models-into-renewable-energy-systemshttpsarxivorgabs251201392v1><a href=https://arxiv.org/abs/2512.01392v1>RE-LLM: Integrating Large Language Models into Renewable Energy Systems</a><a hidden class=anchor aria-hidden=true href=#re-llm-integrating-large-language-models-into-renewable-energy-systemshttpsarxivorgabs251201392v1>#</a></h3><p><strong>Authors:</strong> Ali Forootani, Mohammad Sadr, Danial Esmaeili Aliabadi, Daniela Thraen
<strong>Venue:</strong> arXiv (2025)</p><p>Energy system models are increasingly employed to guide long-term planning in multi-sectoral environments where decisions span electricity, heat, transport, land use, and industry. While these models provide rigorous quantitative insights, their outputs are often highly technical, making them difficult to interpret for non-expert stakeholders such as policymakers, planners, and the public. This communication gap limits the accessibility and practical impact of scenario-based modeling, particularly as energy transitions grow more complex with rising shares of renewables, sectoral integration, and deep uncertainties. To address this challenge, we propose the Renewable Energy Large Language Model (RE-LLM), a hybrid framework that integrates Large Language Models (LLMs) directly into the energy system modeling workflow. RE-LLM combines three core elements: (i) optimization-based scenario exploration, (ii) machine learning surrogates that accelerate computationally intensive simulations, and (iii) LLM-powered natural language generation that translates complex results into clear, stakeholder-oriented explanations. This integrated design not only reduces computational burden but also enhances inter-pretability, enabling real-time reasoning about trade-offs, sensitivities, and policy implications. The framework is adaptable across different optimization platforms and energy system models, ensuring broad applicability beyond the case study presented. By merging speed, rigor, and interpretability, RE-LLM advances a new paradigm of human-centric energy modeling. It enables interactive, multilingual, and accessible engagement with future energy pathways, ultimately bridging the final gap between data-driven analysis and actionable decision-making for sustainable transitions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01392v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01392v1">üìÑ Download PDF</a></p><hr><h3 id=marsad-a-multi-functional-tool-for-real-time-social-media-analysishttpsarxivorgabs251201369v1><a href=https://arxiv.org/abs/2512.01369v1>MARSAD: A Multi-Functional Tool for Real-Time Social Media Analysis</a><a hidden class=anchor aria-hidden=true href=#marsad-a-multi-functional-tool-for-real-time-social-media-analysishttpsarxivorgabs251201369v1>#</a></h3><p><strong>Authors:</strong> Md. Rafiul Biswas, Firoj Alam, Wajdi Zaghouani
<strong>Venue:</strong> arXiv (2025)</p><p>MARSAD is a multifunctional natural language processing (NLP) platform designed for real-time social media monitoring and analysis, with a particular focus on the Arabic-speaking world. It enables researchers and non-technical users alike to examine both live and archived social media content, producing detailed visualizations and reports across various dimensions, including sentiment analysis, emotion analysis, propaganda detection, fact-checking, and hate speech detection. The platform also provides secure data-scraping capabilities through API keys for accessing public social media data. MARSAD&rsquo;s backend architecture integrates flexible document storage with structured data management, ensuring efficient processing of large and multimodal datasets. Its user-friendly frontend supports seamless data upload and interaction.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01369v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01369v1">üìÑ Download PDF</a></p><hr><h3 id=securing-large-language-models-llms-from-prompt-injection-attackshttpsarxivorgabs251201326v1><a href=https://arxiv.org/abs/2512.01326v1>Securing Large Language Models (LLMs) from Prompt Injection Attacks</a><a hidden class=anchor aria-hidden=true href=#securing-large-language-models-llms-from-prompt-injection-attackshttpsarxivorgabs251201326v1>#</a></h3><p><strong>Authors:</strong> Omar Farooq Khan Suri, John McCrae
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Models (LLMs) are increasingly being deployed in real-world applications, but their flexibility exposes them to prompt injection attacks. These attacks leverage the model&rsquo;s instruction-following ability to make it perform malicious tasks. Recent work has proposed JATMO, a task-specific fine-tuning approach that trains non-instruction-tuned base models to perform a single function, thereby reducing susceptibility to adversarial instructions. In this study, we evaluate the robustness of JATMO against HOUYI, a genetic attack framework that systematically mutates and optimizes adversarial prompts. We adapt HOUYI by introducing custom fitness scoring, modified mutation logic, and a new harness for local model testing, enabling a more accurate assessment of defense effectiveness. We fine-tuned LLaMA 2-7B, Qwen1.5-4B, and Qwen1.5-0.5B models under the JATMO methodology and compared them with a fine-tuned GPT-3.5-Turbo baseline. Results show that while JATMO reduces attack success rates relative to instruction-tuned models, it does not fully prevent injections; adversaries exploiting multilingual cues or code-related disruptors still bypass defenses. We also observe a trade-off between generation quality and injection vulnerability, suggesting that better task performance often correlates with increased susceptibility. Our results highlight both the promise and limitations of fine-tuning-based defenses and point toward the need for layered, adversarially informed mitigation strategies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01326v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01326v1">üìÑ Download PDF</a></p><hr><h3 id=sentiment-analysis-and-emotion-classification-using-machine-learning-techniques-for-nagamese-language---a-low-resource-languagehttpsarxivorgabs251201256v1><a href=https://arxiv.org/abs/2512.01256v1>Sentiment Analysis and Emotion Classification using Machine Learning Techniques for Nagamese Language - A Low-resource Language</a><a hidden class=anchor aria-hidden=true href=#sentiment-analysis-and-emotion-classification-using-machine-learning-techniques-for-nagamese-language---a-low-resource-languagehttpsarxivorgabs251201256v1>#</a></h3><p><strong>Authors:</strong> Ekha Morang, Surhoni A. Ngullie, Sashienla Longkumer, Teisovi Angami
<strong>Venue:</strong> arXiv (2025)</p><p>The Nagamese language, a.k.a Naga Pidgin, is an Assamese-lexified creole language developed primarily as a means of communication in trade between the people from Nagaland and people from Assam in the north-east India. Substantial amount of work in sentiment analysis has been done for resource-rich languages like English, Hindi, etc. However, no work has been done in Nagamese language. To the best of our knowledge, this is the first attempt on sentiment analysis and emotion classification for the Nagamese Language. The aim of this work is to detect sentiments in terms of polarity (positive, negative and neutral) and basic emotions contained in textual content of Nagamese language. We build sentiment polarity lexicon of 1,195 nagamese words and use these to build features along with additional features for supervised machine learning techniques using Na"ive Bayes and Support Vector Machines.
Keywords: Nagamese, NLP, sentiment analysis, machine learning</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01256v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01256v1">üìÑ Download PDF</a></p><hr><h3 id=how-do-we-measure-privacy-in-text-a-survey-of-text-anonymization-metricshttpsarxivorgabs251201109v1><a href=https://arxiv.org/abs/2512.01109v1>How do we measure privacy in text? A survey of text anonymization metrics</a><a hidden class=anchor aria-hidden=true href=#how-do-we-measure-privacy-in-text-a-survey-of-text-anonymization-metricshttpsarxivorgabs251201109v1>#</a></h3><p><strong>Authors:</strong> Yaxuan Ren, Krithika Ramesh, Yaxing Yao, Anjalie Field
<strong>Venue:</strong> arXiv (2025)</p><p>In this work, we aim to clarify and reconcile metrics for evaluating privacy protection in text through a systematic survey. Although text anonymization is essential for enabling NLP research and model development in domains with sensitive data, evaluating whether anonymization methods sufficiently protect privacy remains an open challenge. In manually reviewing 47 papers that report privacy metrics, we identify and compare six distinct privacy notions, and analyze how the associated metrics capture different aspects of privacy risk. We then assess how well these notions align with legal privacy standards (HIPAA and GDPR), as well as user-centered expectations grounded in HCI studies. Our analysis offers practical guidance on navigating the landscape of privacy evaluation approaches further and highlights gaps in current practices. Ultimately, we aim to facilitate more robust, comparable, and legally aware privacy evaluations in text anonymization.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01109v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01109v1">üìÑ Download PDF</a></p><hr><h3 id=a-hybrid-deep-learning-and-anomaly-detection-framework-for-real-time-malicious-url-classificationhttpsarxivorgabs251203462v1><a href=https://arxiv.org/abs/2512.03462v1>A Hybrid Deep Learning and Anomaly Detection Framework for Real-Time Malicious URL Classification</a><a hidden class=anchor aria-hidden=true href=#a-hybrid-deep-learning-and-anomaly-detection-framework-for-real-time-malicious-url-classificationhttpsarxivorgabs251203462v1>#</a></h3><p><strong>Authors:</strong> Berkani Khaled, Zeraoulia Rafik
<strong>Venue:</strong> arXiv (2025)</p><p>Malicious URLs remain a primary vector for phishing, malware, and cyberthreats. This study proposes a hybrid deep learning framework combining \texttt{HashingVectorizer} n-gram analysis, SMOTE balancing, Isolation Forest anomaly filtering, and a lightweight neural network classifier for real-time URL classification. The multi-stage pipeline processes URLs from open-source repositories with statistical features (length, dot count, entropy), achieving $O(NL + EBdh)$ training complexity and a 20,ms prediction latency. Empirical evaluation yields 96.4% accuracy, 95.4% F1-score, and 97.3% ROC-AUC, outperforming CNN (94.8%) and SVM baselines with a $50!\times$&ndash;$100!\times$ speedup (Table~\ref{tab:comp-complexity}). A multilingual Tkinter GUI (Arabic/English/French) enables real-time threat assessment with clipboard integration. The framework demonstrates superior scalability and resilience against obfuscated URL patterns.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03462v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03462v1">üìÑ Download PDF</a></p><hr><h3 id=elr-1000-a-community-generated-dataset-for-endangered-indic-indigenous-languageshttpsarxivorgabs251201077v1><a href=https://arxiv.org/abs/2512.01077v1>ELR-1000: A Community-Generated Dataset for Endangered Indic Indigenous Languages</a><a hidden class=anchor aria-hidden=true href=#elr-1000-a-community-generated-dataset-for-endangered-indic-indigenous-languageshttpsarxivorgabs251201077v1>#</a></h3><p><strong>Authors:</strong> Neha Joshi, Pamir Gogoi, Aasim Mirza, Aayush Jansari, Aditya Yadavalli, Ayushi Pandey, Arunima Shukla, Deepthi Sudharsan, Kalika Bali, Vivek Seshadri
<strong>Venue:</strong> arXiv (2025)</p><p>We present a culturally-grounded multimodal dataset of 1,060 traditional recipes crowdsourced from rural communities across remote regions of Eastern India, spanning 10 endangered languages. These recipes, rich in linguistic and cultural nuance, were collected using a mobile interface designed for contributors with low digital literacy. Endangered Language Recipes (ELR)-1000 &ndash; captures not only culinary practices but also the socio-cultural context embedded in indigenous food traditions. We evaluate the performance of several state-of-the-art large language models (LLMs) on translating these recipes into English and find the following: despite the models&rsquo; capabilities, they struggle with low-resource, culturally-specific language. However, we observe that providing targeted context &ndash; including background information about the languages, translation examples, and guidelines for cultural preservation &ndash; leads to significant improvements in translation quality. Our results underscore the need for benchmarks that cater to underrepresented languages and domains to advance equitable and culturally-aware language technologies. As part of this work, we release the ELR-1000 dataset to the NLP community, hoping it motivates the development of language technologies for endangered languages.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01077v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01077v1">üìÑ Download PDF</a></p><hr><h3 id=fine-tuning-of-lightweight-large-language-models-for-sentiment-classification-on-heterogeneous-financial-textual-datahttpsarxivorgabs251200946v1><a href=https://arxiv.org/abs/2512.00946v1>Fine-tuning of lightweight large language models for sentiment classification on heterogeneous financial textual data</a><a hidden class=anchor aria-hidden=true href=#fine-tuning-of-lightweight-large-language-models-for-sentiment-classification-on-heterogeneous-financial-textual-datahttpsarxivorgabs251200946v1>#</a></h3><p><strong>Authors:</strong> Alvaro Paredes Amorin, Andre Python, Christoph Weisser
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) play an increasingly important role in finan- cial markets analysis by capturing signals from complex and heterogeneous textual data sources, such as tweets, news articles, reports, and microblogs. However, their performance is dependent on large computational resources and proprietary datasets, which are costly, restricted, and therefore inacces- sible to many researchers and practitioners. To reflect realistic situations we investigate the ability of lightweight open-source LLMs - smaller and publicly available models designed to operate with limited computational resources - to generalize sentiment understanding from financial datasets of varying sizes, sources, formats, and languages. We compare the benchmark finance natural language processing (NLP) model, FinBERT, and three open-source lightweight LLMs, DeepSeek-LLM 7B, Llama3 8B Instruct, and Qwen3 8B on five publicly available datasets: FinancialPhraseBank, Financial Question Answering, Gold News Sentiment, Twitter Sentiment and Chinese Finance Sentiment. We find that LLMs, specially Qwen3 8B and Llama3 8B, perform best in most scenarios, even from using only 5% of the available training data. These results hold in zero-shot and few-shot learning scenarios. Our findings indicate that lightweight, open-source large language models (LLMs) consti- tute a cost-effective option, as they can achieve competitive performance on heterogeneous textual data even when trained on only a limited subset of the extensive annotated corpora that are typically deemed necessary.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00946v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00946v1">üìÑ Download PDF</a></p><hr><h3 id=deformar-rethinking-ner-evaluation-through-component-analysis-and-visual-analyticshttpsarxivorgabs251200938v1><a href=https://arxiv.org/abs/2512.00938v1>DeformAr: Rethinking NER Evaluation through Component Analysis and Visual Analytics</a><a hidden class=anchor aria-hidden=true href=#deformar-rethinking-ner-evaluation-through-component-analysis-and-visual-analyticshttpsarxivorgabs251200938v1>#</a></h3><p><strong>Authors:</strong> Ahmed Mustafa Younes
<strong>Venue:</strong> arXiv (2025)</p><p>Transformer models have significantly advanced Natural Language Processing (NLP), demonstrating strong performance in English. However, their effectiveness in Arabic, particularly for Named Entity Recognition (NER), remains limited, even with larger pre-trained models. This performance gap stems from multiple factors, including tokenisation, dataset quality, and annotation inconsistencies. Existing studies often analyze these issues in isolation, failing to capture their joint effect on system behaviour and performance.
We introduce DeformAr (Debugging and Evaluation Framework for Transformer-based NER Systems), a novel framework designed to investigate and explain the performance discrepancy between Arabic and English NER systems. DeformAr integrates a data extraction library and an interactive dashboard, supporting two modes of evaluation: cross-component analysis and behavioural analysis. The framework divides each language into dataset and model components to examine their interactions.
The analysis proceeds in two stages. First, cross-component analysis provides systematic diagnostic measures across data and model subcomponents, addressing the &ldquo;what,&rdquo; &ldquo;how,&rdquo; and &ldquo;why&rdquo; behind observed discrepancies. The second stage applies behavioural analysis by combining interpretability techniques with token-level metrics, interactive visualisations, and representation space analysis. These stages enable a component-aware diagnostic process that detects model behaviours and explains them by linking them to underlying representational patterns and data factors. DeformAr is the first Arabic-specific, component-based interpretability tool, offering a crucial resource for advancing model analysis in under-resourced languages.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00938v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00938v1">üìÑ Download PDF</a></p><hr><h3 id=multilingual-training-free-remote-sensing-image-captioninghttpsarxivorgabs251200887v2><a href=https://arxiv.org/abs/2512.00887v2>Multilingual Training-Free Remote Sensing Image Captioning</a><a hidden class=anchor aria-hidden=true href=#multilingual-training-free-remote-sensing-image-captioninghttpsarxivorgabs251200887v2>#</a></h3><p><strong>Authors:</strong> Carlos Rebelo, Gil Rocha, Jo√£o Daniel Silva, Bruno Martins
<strong>Venue:</strong> arXiv (2025)</p><p>Remote sensing image captioning has advanced rapidly through encoder&ndash;decoder models, although the reliance on large annotated datasets and the focus on English restricts global applicability. To address these limitations, we propose the first training-free multilingual approach, based on retrieval-augmented prompting. For a given aerial image, we employ a domain-adapted SigLIP2 encoder to retrieve related captions and few-shot examples from a datastore, which are then provided to a language model. We explore two variants: an image-blind setup, where a multilingual Large Language Model (LLM) generates the caption from textual prompts alone, and an image-aware setup, where a Vision&ndash;Language Model (VLM) jointly processes the prompt and the input image. To improve the coherence of the retrieved content, we introduce a graph-based re-ranking strategy using PageRank on a graph of images and captions. Experiments on four benchmark datasets across ten languages demonstrate that our approach is competitive with fully supervised English-only systems and generalizes to other languages. Results also highlight the importance of re-ranking with PageRank, yielding up to 35% improvements in performance metrics. Additionally, it was observed that while VLMs tend to generate visually grounded but lexically diverse captions, LLMs can achieve stronger BLEU and CIDEr scores. Lastly, directly generating captions in the target language consistently outperforms other translation-based strategies. Overall, our work delivers one of the first systematic evaluations of multilingual, training-free captioning for remote sensing imagery, advancing toward more inclusive and scalable multimodal Earth observation systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00887v2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00887v2">üìÑ Download PDF</a></p><hr><h3 id=accelerating-bangla-nlp-tasks-with-automatic-mixed-precision-resource-efficient-training-preserving-model-efficacyhttpsarxivorgabs251200829v1><a href=https://arxiv.org/abs/2512.00829v1>Accelerating Bangla NLP Tasks with Automatic Mixed Precision: Resource-Efficient Training Preserving Model Efficacy</a><a hidden class=anchor aria-hidden=true href=#accelerating-bangla-nlp-tasks-with-automatic-mixed-precision-resource-efficient-training-preserving-model-efficacyhttpsarxivorgabs251200829v1>#</a></h3><p><strong>Authors:</strong> Md Mehrab Hossain Opi, Sumaiya Khan, Moshammad Farzana Rahman
<strong>Venue:</strong> arXiv (2025)</p><p>Training models for Natural Language Processing (NLP) requires substantial computational resources and time, posing significant challenges, especially for NLP development in Bangla, where access to high-end hardware is often limited. In this work, we explore automatic mixed precision (AMP) training as a means to improve computational efficiency without sacrificing model performance. By leveraging a dynamic mix of 16-bit and 32-bit floating-point computations, AMP lowers GPU memory requirements and speeds up training without degrading model performance. We evaluate AMP across four standard Bangla NLP tasks, namely sentiment analysis, named entity recognition, error classification, and question answering, using four transformer-based models: BanglaBERT, BanglishBERT, XLM-R, and mBERT. Our results demonstrate that AMP accelerates training by 44.5% and reduces memory consumption by 17.6%, while maintaining F-1 score within 99.7% of the full-precision baselines. This empirical study highlights AMP&rsquo;s potential to democratize access to state-of-the-art NLP capabilities in hardware-constrained settings by lowering computational barriers.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00829v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00829v1">üìÑ Download PDF</a></p><hr><h3 id=shrag-aframeworkfor-combining-human-inspired-search-with-raghttpsarxivorgabs251200772v1><a href=https://arxiv.org/abs/2512.00772v1>SHRAG: AFrameworkfor Combining Human-Inspired Search with RAG</a><a hidden class=anchor aria-hidden=true href=#shrag-aframeworkfor-combining-human-inspired-search-with-raghttpsarxivorgabs251200772v1>#</a></h3><p><strong>Authors:</strong> Hyunseok Ryu, Wonjune Shin, Hyun Park
<strong>Venue:</strong> arXiv (2025)</p><p>Retrieval-Augmented Generation (RAG) is gaining recognition as one of the key technological axes for next generation information retrieval, owing to its ability to mitigate the hallucination phenomenon in Large Language
Models (LLMs)and effectively incorporate up-to-date information. However, specialized expertise is necessary to
construct ahigh-quality retrieval system independently; moreover, RAGdemonstratesrelativelyslowerprocessing
speeds compared to conventional pure retrieval systems because it involves both retrieval and generation stages.
Accordingly, this study proposes SHRAG, a novel framework designed to facilitate the seamless integration of
Information Retrieval and RAG while simultaneously securing precise retrieval performance. SHRAG utilizes a
Large Language Model as a Query Strategist to automatically transform unstructured natural language queries
into logically structured search queries, subsequently performing Boolean retrieval to emulate the search process
of an expert human searcher. Furthermore, it incorporates multilingual query expansion and a multilingual
embedding model, enabling it to perform efficient cross-lingual question answering within the multilingual
dataset environment of the ScienceON Challenge. Experimental results demonstrate that the proposed method,
combining logical retrieval capabilities and generative reasoning, can significantly enhance the accuracy and
reliability of RAG systems. Furthermore, SHRAG movesbeyondconventionaldocument-centric retrieval methods,
presenting the potential for a new search paradigm capable of providing direct and reliable responses to queries.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00772v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00772v1">üìÑ Download PDF</a></p><hr><h3 id=mpr-gui-benchmarking-and-enhancing-multilingual-perception-and-reasoning-in-gui-agentshttpsarxivorgabs251200756v1><a href=https://arxiv.org/abs/2512.00756v1>MPR-GUI: Benchmarking and Enhancing Multilingual Perception and Reasoning in GUI Agents</a><a hidden class=anchor aria-hidden=true href=#mpr-gui-benchmarking-and-enhancing-multilingual-perception-and-reasoning-in-gui-agentshttpsarxivorgabs251200756v1>#</a></h3><p><strong>Authors:</strong> Ruihan Chen, Qiming Li, Xiaocheng Feng, Xiaoliang Yang, Weihong Zhong, Yuxuan Gu, Zekun Zhou, Bing Qin
<strong>Venue:</strong> arXiv (2025)</p><p>With the advancement of computational resources, Large Vision-Language Models (LVLMs) exhibit impressive Perception and Reasoning (P&amp;R) performance on Graphical User Interface (GUI) tasks. However, although they demonstrate strong P&amp;R capabilities in English GUI scenarios, their performance in multilingual settings has received little attention, which limits their global applications. Moreover, existing studies on GUI tasks lack fine-grained analyses, including widget functions and elements&rsquo; spatial relationships, which are fundamental for more targeted improvements. To tackle these issues, we propose MPR-GUI-Bench, a Multilingual fine-grained Perception and Reasoning GUI Benchmark to evaluate GUI agents&rsquo; P&amp;R capabilities. Evaluation results demonstrate that LVLMs exhibit significantly worse P&amp;R performance in non-English languages than in English. To address these gaps, we propose GUI-XLI, a GUI Cross-Lingual Intervention method that applies interventions to the hidden states at P&amp;R capability-related layers to mitigate the gaps between English and other languages, building on previous research showing that the hidden states of different language inputs exhibit significant differences in the latent space. Experimental results indicate that our method improves GUI agents&rsquo; multilingual P&amp;R capability by 6.5% on average.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00756v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00756v1">üìÑ Download PDF</a></p><hr><h3 id=fastpos-language-agnostic-scalable-pos-tagging-framework-low-resource-use-casehttpsarxivorgabs251200745v1><a href=https://arxiv.org/abs/2512.00745v1>FastPOS: Language-Agnostic Scalable POS Tagging Framework Low-Resource Use Case</a><a hidden class=anchor aria-hidden=true href=#fastpos-language-agnostic-scalable-pos-tagging-framework-low-resource-use-casehttpsarxivorgabs251200745v1>#</a></h3><p><strong>Authors:</strong> Md Abdullah Al Kafi, Sumit Kumar Banshal
<strong>Venue:</strong> arXiv (2025)</p><p>This study proposes a language-agnostic transformer-based POS tagging framework designed for low-resource languages, using Bangla and Hindi as case studies. With only three lines of framework-specific code, the model was adapted from Bangla to Hindi, demonstrating effective portability with minimal modification. The framework achieves 96.85 percent and 97 percent token-level accuracy across POS categories in Bangla and Hindi while sustaining strong F1 scores despite dataset imbalance and linguistic overlap. A performance discrepancy in a specific POS category underscores ongoing challenges in dataset curation. The strong results stem from the underlying transformer architecture, which can be replaced with limited code adjustments. Its modular and open-source design enables rapid cross-lingual adaptation while reducing model design and tuning overhead, allowing researchers to focus on linguistic preprocessing and dataset refinement, which are essential for advancing NLP in underrepresented languages.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00745v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00745v1">üìÑ Download PDF</a></p><hr><h3 id=financial-text-classification-based-on-rlora-finetuning-on-qwen3-8b-modelhttpsarxivorgabs251200630v1><a href=https://arxiv.org/abs/2512.00630v1>Financial Text Classification Based On rLoRA Finetuning On Qwen3-8B model</a><a hidden class=anchor aria-hidden=true href=#financial-text-classification-based-on-rlora-finetuning-on-qwen3-8b-modelhttpsarxivorgabs251200630v1>#</a></h3><p><strong>Authors:</strong> Zhiming Lian
<strong>Venue:</strong> arXiv (2025)</p><p>Financial text classification has increasingly become an important aspect in quantitative trading systems and related tasks, such as financial sentiment analysis and the classification of financial news. In this paper, we assess the performance of the large language model Qwen3-8B on both tasks. Qwen3-8B is a state-of-the-art model that exhibits strong instruction-following and multilingual capabilities, and is distinct from standard models, primarily because it is specifically optimized for efficient fine tuning and high performance on reasoning-based benchmarks, making it suitable for financial applications. To adapt this model, we apply Noisy Embedding Instruction Finetuning and based on our previous work, this method increases robustness by injecting controlled noise into the embedding layers during supervised adaptation. We improve efficiency further with Rank-stabilized Low-Rank Adaptation low-rank optimization approach, and FlashAttention, which allow for faster training with lower GPU memory. For both tasks, we benchmark Qwen3-8B against standard classical transformer models, such as T5, BERT, and RoBERTa, and large models at scale, such as LLaMA1-7B, LLaMA2-7B, and Baichuan2-7B. The findings reveal that Qwen3-8B consistently surpasses these baselines by obtaining better classification accuracy and needing fewer training epochs. The synergy of instruction-based fine-tuning and memory-efficient optimization methods suggests Qwen3-8B can potentially serve as a scalable, economical option for real-time financial NLP applications. Qwen3-8B provides a very promising base for advancing dynamic quantitative trading systems in the future.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00630v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00630v1">üìÑ Download PDF</a></p><hr><h3 id=statistical-nlp-for-optimization-of-clinical-trial-success-prediction-in-pharmaceutical-rdhttpsarxivorgabs251200586v1><a href=https://arxiv.org/abs/2512.00586v1>Statistical NLP for Optimization of Clinical Trial Success Prediction in Pharmaceutical R&amp;D</a><a hidden class=anchor aria-hidden=true href=#statistical-nlp-for-optimization-of-clinical-trial-success-prediction-in-pharmaceutical-rdhttpsarxivorgabs251200586v1>#</a></h3><p><strong>Authors:</strong> Michael R. Doane
<strong>Venue:</strong> arXiv (2025)</p><p>This work presents the development and evaluation of an NLP-enabled probabilistic classifier designed to estimate the probability of technical and regulatory success (pTRS) for clinical trials in the field of neuroscience. While pharmaceutical R&amp;D is plagued by high attrition rates and enormous costs, particularly within neuroscience, where success rates are below 10%, timely identification of promising programs can streamline resource allocation and reduce financial risk. Leveraging data from the ClinicalTrials.gov database and success labels from the recently developed Clinical Trial Outcome dataset, the classifier extracts text-based clinical trial features using statistical NLP techniques. These features were integrated into several non-LLM frameworks (logistic regression, gradient boosting, and random forest) to generate calibrated probability scores. Model performance was assessed on a retrospective dataset of 101,145 completed clinical trials spanning 1976-2024, achieving an overall ROC-AUC of 0.64. An LLM-based predictive model was then built using BioBERT, a domain-specific language representation encoder. The BioBERT-based model achieved an overall ROC-AUC of 0.74 and a Brier Score of 0.185, indicating its predictions had, on average, 40% less squared error than would be observed using industry benchmarks. The BioBERT-based model also made trial outcome predictions that were superior to benchmark values 70% of the time overall. By integrating NLP-driven insights into drug development decision-making, this work aims to enhance strategic planning and optimize investment allocation in neuroscience programs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00586v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00586v1">üìÑ Download PDF</a></p><hr><h3 id=cacara-cross-modal-alignment-leveraging-a-text-centric-approach-for-cost-effective-multimodal-and-multilingual-learninghttpsarxivorgabs251200496v1><a href=https://arxiv.org/abs/2512.00496v1>CACARA: Cross-Modal Alignment Leveraging a Text-Centric Approach for Cost-Effective Multimodal and Multilingual Learning</a><a hidden class=anchor aria-hidden=true href=#cacara-cross-modal-alignment-leveraging-a-text-centric-approach-for-cost-effective-multimodal-and-multilingual-learninghttpsarxivorgabs251200496v1>#</a></h3><p><strong>Authors:</strong> Diego A. B. Moreira, Alef I. Ferreira, Jhessica Silva, Gabriel O. dos Santos, Gustavo Bonil, Jo√£o Gondim, Marina dos Santos, Helena Maia, Simone Hashiguti, N√°dia da Silva, Carolina Scarton, Helio Pedrini, Sandra Avila
<strong>Venue:</strong> arXiv (2025)</p><p>As deep learning models evolve, new applications and challenges are rapidly emerging. Tasks that once relied on a single modality, such as text, images, or audio, are now enriched by seamless interactions between multimodal data. These connections bridge information gaps: an image can visually materialize a text, while audio can add context to an image. Researchers have developed numerous multimodal models, but most rely on resource-intensive training across multiple modalities. Similarly, extending these models to new languages often follows the same resource-heavy training strategy. In this work, we propose a multimodal and multilingual architecture, CACARA, trained through emergent alignment learning, enabling the seamless integration of new modalities into an existing bimodal/multimodal model without requiring full retraining. This work breaks new ground by demonstrating that this emergent alignment paradigm can unlock multilingual capabilities from monolingual training. By fine-tuning the newly incorporated modality only on data aligned with the English language, our model develops support for over 100 languages without explicit multilingual pretraining or tuning of the text encoder. Such emergent multimodal and multilingual properties are gained efficiently, preserving previously learned knowledge at a training cost comparable to that of a monolingual model. Our strategy achieves up to a 14.24 percentage points improvement in R@1 audio-to-text retrieval, outperforming state-of-the-art multimodal models &ndash; all without the heavy computational cost of retraining across every modality and language.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00496v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00496v1">üìÑ Download PDF</a></p><hr><h3 id=rrpo-robust-reward-policy-optimization-for-llm-based-emotional-ttshttpsarxivorgabs251204552v1><a href=https://arxiv.org/abs/2512.04552v1>RRPO: Robust Reward Policy Optimization for LLM-based Emotional TTS</a><a hidden class=anchor aria-hidden=true href=#rrpo-robust-reward-policy-optimization-for-llm-based-emotional-ttshttpsarxivorgabs251204552v1>#</a></h3><p><strong>Authors:</strong> Cong Wang, Changfeng Gao, Yang Xiang, Zhihao Du, Keyu An, Han Zhao, Qian Chen, Xiangang Li, Yingming Gao, Ya Li
<strong>Venue:</strong> arXiv (2025)</p><p>Differentiable reinforcement learning (RL) frameworks like DiffRO offer a powerful approach for controllable text-to-speech (TTS), but are vulnerable to reward hacking, particularly for nuanced tasks like emotion control. The policy model can exploit a vanilla Reward Model (RM) by generating acoustic artifacts to achieve spurious rewards, but at the cost of degrading perceptual quality. To address this, we propose Robust Reward Policy Optimization (RRPO), a novel framework that employs a hybrid regularization scheme. This scheme develops a robust RM whose reward signal is more reliably aligned with human perception, compelling the policy to abandon detrimental shortcuts and instead learn the complex features of genuine emotions. Our ablation study confirms the enhanced robustness of our RM, as evidenced by its strong cross-lingual generalization. The subjective evaluation demonstrates that this robust RM effectively mitigates reward hacking, leading to significant improvements in both emotional expressiveness and naturalness over all baselines. Demo page: <a href=https://lrwinr.github.io/RRPO-CosyVoice>https://lrwinr.github.io/RRPO-CosyVoice</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04552v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04552v1">üìÑ Download PDF</a></p><hr><h3 id=different-types-of-syntactic-agreement-recruit-the-same-units-within-large-language-modelshttpsarxivorgabs251203676v1><a href=https://arxiv.org/abs/2512.03676v1>Different types of syntactic agreement recruit the same units within large language models</a><a hidden class=anchor aria-hidden=true href=#different-types-of-syntactic-agreement-recruit-the-same-units-within-large-language-modelshttpsarxivorgabs251203676v1>#</a></h3><p><strong>Authors:</strong> Daria Kryvosheieva, Andrea de Varda, Evelina Fedorenko, Greta Tuckute
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) can reliably distinguish grammatical from ungrammatical sentences, but how grammatical knowledge is represented within the models remains an open question. We investigate whether different syntactic phenomena recruit shared or distinct components in LLMs. Using a functional localization approach inspired by cognitive neuroscience, we identify the LLM units most responsive to 67 English syntactic phenomena in seven open-weight models. These units are consistently recruited across sentences containing the phenomena and causally support the models&rsquo; syntactic performance. Critically, different types of syntactic agreement (e.g., subject-verb, anaphor, determiner-noun) recruit overlapping sets of units, suggesting that agreement constitutes a meaningful functional category for LLMs. This pattern holds in English, Russian, and Chinese; and further, in a cross-lingual analysis of 57 diverse languages, structurally more similar languages share more units for subject-verb agreement. Taken together, these findings reveal that syntactic agreement-a critical marker of syntactic dependencies-constitutes a meaningful category within LLMs&rsquo; representational spaces.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03676v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03676v1">üìÑ Download PDF</a></p><hr><h3 id=indicparam-benchmark-to-evaluate-llms-on-low-resource-indic-languageshttpsarxivorgabs251200333v1><a href=https://arxiv.org/abs/2512.00333v1>IndicParam: Benchmark to evaluate LLMs on low-resource Indic Languages</a><a hidden class=anchor aria-hidden=true href=#indicparam-benchmark-to-evaluate-llms-on-low-resource-indic-languageshttpsarxivorgabs251200333v1>#</a></h3><p><strong>Authors:</strong> Ayush Maheshwari, Kaushal Sharma, Vivek Patel, Aditya Maheshwari
<strong>Venue:</strong> arXiv (2025)</p><p>While large language models excel on high-resource multilingual tasks, low- and extremely low-resource Indic languages remain severely under-evaluated. We present IndicParam, a human-curated benchmark of over 13,000 multiple-choice questions covering 11 such languages (Nepali, Gujarati, Marathi, Odia as low-resource; Dogri, Maithili, Rajasthani, Sanskrit, Bodo, Santali, Konkani as extremely low-resource) plus Sanskrit-English code-mixed set. We evaluated 19 LLMs, both proprietary and open-weights, which reveals that even the top-performing GPT-5 reaches only 45.0% average accuracy, followed by DeepSeek-3.2 (43.1) and Claude-4.5 (42.7). We additionally label each question as knowledge-oriented or purely linguistic to discriminate factual recall from grammatical proficiency. Further, we assess the ability of LLMs to handle diverse question formats-such as list-based matching, assertion-reason pairs, and sequence ordering-alongside conventional multiple-choice questions. IndicParam provides insights into limitations of cross-lingual transfer and establishes a challenging benchmark for Indic languages. The dataset is available at <a href=https://huggingface.co/datasets/bharatgenai/IndicParam>https://huggingface.co/datasets/bharatgenai/IndicParam</a>. Scripts to run benchmark are present at <a href=https://github.com/ayushbits/IndicParam>https://github.com/ayushbits/IndicParam</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00333v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00333v1">üìÑ Download PDF</a></p><hr><h3 id=modeling-topics-and-sociolinguistic-variation-in-code-switched-discourse-insights-from-spanish-english-and-spanish-guaran√≠httpsarxivorgabs251203334v1><a href=https://arxiv.org/abs/2512.03334v1>Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaran√≠</a><a hidden class=anchor aria-hidden=true href=#modeling-topics-and-sociolinguistic-variation-in-code-switched-discourse-insights-from-spanish-english-and-spanish-guaran√≠httpsarxivorgabs251203334v1>#</a></h3><p><strong>Authors:</strong> Nemika Tyagi, Nelvin Licona Guevara, Olga Kellert
<strong>Venue:</strong> arXiv (2025)</p><p>This study presents an LLM-assisted annotation pipeline for the sociolinguistic and topical analysis of bilingual discourse in two typologically distinct contexts: Spanish-English and Spanish-Guaran√≠. Using large language models, we automatically labeled topic, genre, and discourse-pragmatic functions across a total of 3,691 code-switched sentences, integrated demographic metadata from the Miami Bilingual Corpus, and enriched the Spanish-Guaran√≠ dataset with new topic annotations. The resulting distributions reveal systematic links between gender, language dominance, and discourse function in the Miami data, and a clear diglossic division between formal Guaran√≠ and informal Spanish in Paraguayan texts. These findings replicate and extend earlier interactional and sociolinguistic observations with corpus-scale quantitative evidence. The study demonstrates that large language models can reliably recover interpretable sociolinguistic patterns traditionally accessible only through manual annotation, advancing computational methods for cross-linguistic and low-resource bilingual research.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03334v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03334v1">üìÑ Download PDF</a></p><hr><h3 id=ivcr-200k-a-large-scale-multi-turn-dialogue-benchmark-for-interactive-video-corpus-retrievalhttpsarxivorgabs251201312v1><a href=https://arxiv.org/abs/2512.01312v1>IVCR-200K: A Large-Scale Multi-turn Dialogue Benchmark for Interactive Video Corpus Retrieval</a><a hidden class=anchor aria-hidden=true href=#ivcr-200k-a-large-scale-multi-turn-dialogue-benchmark-for-interactive-video-corpus-retrievalhttpsarxivorgabs251201312v1>#</a></h3><p><strong>Authors:</strong> Ning Han, Yawen Zeng, Shaohua Long, Chengqing Li, Sijie Yang, Dun Tan, Jianfeng Dong, Jingjing Chen
<strong>Venue:</strong> arXiv (2025)</p><p>In recent years, significant developments have been made in both video retrieval and video moment retrieval tasks, which respectively retrieve complete videos or moments for a given text query. These advancements have greatly improved user satisfaction during the search process. However, previous work has failed to establish meaningful &ldquo;interaction&rdquo; between the retrieval system and the user, and its one-way retrieval paradigm can no longer fully meet the personalization and dynamic needs of at least 80.8% of users. In this paper, we introduce the Interactive Video Corpus Retrieval (IVCR) task, a more realistic setting that enables multi-turn, conversational, and realistic interactions between the user and the retrieval system. To facilitate research on this challenging task, we introduce IVCR-200K, a high-quality, bilingual, multi-turn, conversational, and abstract semantic dataset that supports video retrieval and even moment retrieval. Furthermore, we propose a comprehensive framework based on multi-modal large language models (MLLMs) to help users interact in several modes with more explainable solutions. The extensive experiments demonstrate the effectiveness of our dataset and framework.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01312v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01312v1">üìÑ Download PDF</a></p><hr><h3 id=whose-personae-synthetic-persona-experiments-in-llm-research-and-pathways-to-transparencyhttpsarxivorgabs251200461v1><a href=https://arxiv.org/abs/2512.00461v1>Whose Personae? Synthetic Persona Experiments in LLM Research and Pathways to Transparency</a><a hidden class=anchor aria-hidden=true href=#whose-personae-synthetic-persona-experiments-in-llm-research-and-pathways-to-transparencyhttpsarxivorgabs251200461v1>#</a></h3><p><strong>Authors:</strong> Jan Batzner, Volker Stocker, Bingjun Tang, Anusha Natarajan, Qinhao Chen, Stefan Schmid, Gjergji Kasneci
<strong>Venue:</strong> arXiv (2025)</p><p>Synthetic personae experiments have become a prominent method in Large Language Model alignment research, yet the representativeness and ecological validity of these personae vary considerably between studies. Through a review of 63 peer-reviewed studies published between 2023 and 2025 in leading NLP and AI venues, we reveal a critical gap: task and population of interest are often underspecified in persona-based experiments, despite personalization being fundamentally dependent on these criteria. Our analysis shows substantial differences in user representation, with most studies focusing on limited sociodemographic attributes and only 35% discussing the representativeness of their LLM personae. Based on our findings, we introduce a persona transparency checklist that emphasizes representative sampling, explicit grounding in empirical data, and enhanced ecological validity. Our work provides both a comprehensive assessment of current practices and practical guidelines to improve the rigor and ecological validity of persona-based evaluations in language model alignment research.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00461v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00461v1">üìÑ Download PDF</a></p><hr><h3 id=selfai-building-a-self-training-ai-system-with-llm-agentshttpsarxivorgabs251200403v1><a href=https://arxiv.org/abs/2512.00403v1>SelfAI: Building a Self-Training AI System with LLM Agents</a><a hidden class=anchor aria-hidden=true href=#selfai-building-a-self-training-ai-system-with-llm-agentshttpsarxivorgabs251200403v1>#</a></h3><p><strong>Authors:</strong> Xiao Wu, Ting-Zhu Huang, Liang-Jian Deng, Xiaobing Yu, Yu Zhong, Shangqi Deng, Ufaq Khan, Jianghao Wu, Xiaofeng Liu, Imran Razzak, Xiaojun Chang, Yutong Xie
<strong>Venue:</strong> arXiv (2025)</p><p>Recent work on autonomous scientific discovery has leveraged LLM-based agents to integrate problem specification, experiment planning, and execution into end-to-end systems. However, these frameworks are often confined to narrow application domains, offer limited real-time interaction with researchers, and lack principled mechanisms for determining when to halt exploration, resulting in inefficiencies, reproducibility challenges, and under-utilized human expertise. To address these gaps, we propose \textit{SelfAI}, a general multi-agent platform that combines a User Agent for translating high-level research objectives into standardized experimental configurations, a Cognitive Agent powered by LLMs with optimal stopping criteria to iteratively refine hyperparameter searches, and an Experiment Manager responsible for orchestrating parallel, fault-tolerant training workflows across heterogeneous hardware while maintaining a structured knowledge base for continuous feedback. We further introduce two novel evaluation metrics, Score and $\text{AUP}_D$, to quantify discovery efficiency and search diversity. Across regression, NLP, computer vision, scientific computing, medical imaging, and drug discovery benchmarks, SelfAI consistently achieves strong performance and reduces redundant trials compared to classical Bayesian optimization and LLM-based baselines, while enabling seamless interaction with human researchers.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00403v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00403v1">üìÑ Download PDF</a></p><hr><h3 id=challenges-of-heterogeneity-in-big-data-a-comparative-study-of-classification-in-large-scale-structured-and-unstructured-domainshttpsarxivorgabs251200298v1><a href=https://arxiv.org/abs/2512.00298v1>Challenges of Heterogeneity in Big Data: A Comparative Study of Classification in Large-Scale Structured and Unstructured Domains</a><a hidden class=anchor aria-hidden=true href=#challenges-of-heterogeneity-in-big-data-a-comparative-study-of-classification-in-large-scale-structured-and-unstructured-domainshttpsarxivorgabs251200298v1>#</a></h3><p><strong>Authors:</strong> Gonz√°lez Trigueros Jes√∫s Eduardo, Alonso S√°nchez Alejandro, Mu√±oz Rivera Emilio, Pe√±ar√°n Prieto Mariana Jaqueline, Mendoza Gonz√°lez Camila Natalia
<strong>Venue:</strong> arXiv (2025)</p><p>This study analyzes the impact of heterogeneity (&ldquo;Variety&rdquo;) in Big Data by comparing classification strategies across structured (Epsilon) and unstructured (Rest-Mex, IMDB) domains. A dual methodology was implemented: evolutionary and Bayesian hyperparameter optimization (Genetic Algorithms, Optuna) in Python for numerical data, and distributed processing in Apache Spark for massive textual corpora. The results reveal a &ldquo;complexity paradox&rdquo;: in high-dimensional spaces, optimized linear models (SVM, Logistic Regression) outperformed deep architectures and Gradient Boosting. Conversely, in text-based domains, the constraints of distributed fine-tuning led to overfitting in complex models, whereas robust feature engineering &ndash; specifically Transformer-based embeddings (ROBERTa) and Bayesian Target Encoding &ndash; enabled simpler models to generalize effectively. This work provides a unified framework for algorithm selection based on data nature and infrastructure constraints.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00298v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00298v1">üìÑ Download PDF</a></p><hr><h3 id=bioarc-discovering-optimal-neural-architectures-for-biological-foundation-modelshttpsarxivorgabs251200283v2><a href=https://arxiv.org/abs/2512.00283v2>BioArc: Discovering Optimal Neural Architectures for Biological Foundation Models</a><a hidden class=anchor aria-hidden=true href=#bioarc-discovering-optimal-neural-architectures-for-biological-foundation-modelshttpsarxivorgabs251200283v2>#</a></h3><p><strong>Authors:</strong> Yi Fang, Haoran Xu, Jiaxin Han, Sirui Ding, Yizhi Wang, Yue Wang, Xuan Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Foundation models have revolutionized various fields such as natural language processing (NLP) and computer vision (CV). While efforts have been made to transfer the success of the foundation models in general AI domains to biology, existing works focus on directly adopting the existing foundation model architectures from general machine learning domains without a systematic design considering the unique physicochemical and structural properties of each biological data modality. This leads to suboptimal performance, as these repurposed architectures struggle to capture the long-range dependencies, sparse information, and complex underlying ``grammars&rsquo;&rsquo; inherent to biological data. To address this gap, we introduce BioArc, a novel framework designed to move beyond intuition-driven architecture design towards principled, automated architecture discovery for biological foundation models. Leveraging Neural Architecture Search (NAS), BioArc systematically explores a vast architecture design space, evaluating architectures across multiple biological modalities while rigorously analyzing the interplay between architecture, tokenization, and training strategies. This large-scale analysis identifies novel, high-performance architectures, allowing us to distill a set of empirical design principles to guide future model development. Furthermore, to make the best of this set of discovered principled architectures, we propose and compare several architecture prediction methods that effectively and efficiently predict optimal architectures for new biological tasks. Overall, our work provides a foundational resource and a principled methodology to guide the creation of the next generation of task-specific and foundation models for biology.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00283v2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00283v2">üìÑ Download PDF</a></p><hr><h3 id=accelerated-execution-of-bayesian-neural-networks-using-a-single-probabilistic-forward-pass-and-code-generationhttpsarxivorgabs251123440v1><a href=https://arxiv.org/abs/2511.23440v1>Accelerated Execution of Bayesian Neural Networks using a Single Probabilistic Forward Pass and Code Generation</a><a hidden class=anchor aria-hidden=true href=#accelerated-execution-of-bayesian-neural-networks-using-a-single-probabilistic-forward-pass-and-code-generationhttpsarxivorgabs251123440v1>#</a></h3><p><strong>Authors:</strong> Bernhard Klein, Falk Selker, Hendrik Borras, Sophie Steger, Franz Pernkopf, Holger Fr√∂ning
<strong>Venue:</strong> arXiv (2025)</p><p>Machine learning models perform well across domains such as diagnostics, weather forecasting, NLP, and autonomous driving, but their limited uncertainty handling restricts use in safety-critical settings. Traditional neural networks often fail to detect out-of-domain (OOD) data and may output confident yet incorrect predictions. Bayesian neural networks (BNNs) address this by providing probabilistic estimates, but incur high computational cost because predictions require sampling weight distributions and multiple forward passes. The Probabilistic Forward Pass (PFP) offers a highly efficient approximation to Stochastic Variational Inference (SVI) by assuming Gaussian-distributed weights and activations, enabling fully analytic uncertainty propagation and replacing sampling with a single deterministic forward pass. We present an end-to-end pipeline for training, compiling, optimizing, and deploying PFP-based BNNs on embedded ARM CPUs. Using the TVM deep learning compiler, we implement a dedicated library of Gaussian-propagating operators for multilayer perceptrons and convolutional neural networks, combined with manual and automated tuning strategies. Ablation studies show that PFP consistently outperforms SVI in computational efficiency, achieving speedups of up to 4200x for small mini-batches. PFP-BNNs match SVI-BNNs on Dirty-MNIST in accuracy, uncertainty estimation, and OOD detection while greatly reducing compute cost. These results highlight the potential of combining Bayesian approximations with code generation to enable efficient BNN deployment on resource-constrained systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2511.23440v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2511.23440v1">üìÑ Download PDF</a></p><hr><h3 id=the-decision-path-to-control-ai-risks-completely-fundamental-control-mechanisms-for-ai-governancehttpsarxivorgabs251204489v1><a href=https://arxiv.org/abs/2512.04489v1>The Decision Path to Control AI Risks Completely: Fundamental Control Mechanisms for AI Governance</a><a hidden class=anchor aria-hidden=true href=#the-decision-path-to-control-ai-risks-completely-fundamental-control-mechanisms-for-ai-governancehttpsarxivorgabs251204489v1>#</a></h3><p><strong>Authors:</strong> Yong Tao
<strong>Venue:</strong> arXiv (2025)</p><p>Artificial intelligence (AI) advances rapidly but achieving complete human control over AI risks remains an unsolved problem, akin to driving the fast AI &ldquo;train&rdquo; without a &ldquo;brake system.&rdquo; By exploring fundamental control mechanisms at key elements of AI decisions, this paper develops a systematic solution to thoroughly control AI risks, providing an architecture for AI governance and legislation with five pillars supported by six control mechanisms, illustrated through a minimum set of AI Mandates (AIMs). Three of the AIMs must be built inside AI systems and three in society to address major areas of AI risks: 1) align AI values with human users; 2) constrain AI decision-actions by societal ethics, laws, and regulations; 3) build in human intervention options for emergencies and shut-off switches for existential threats; 4) limit AI access to resources to reinforce controls inside AI; 5) mitigate spillover risks like job loss from AI. We also highlight the differences in AI governance on physical AI systems versus generative AI. We discuss how to strengthen analog physical safeguards to prevent smarter AI/AGI/ASI from circumventing core safety controls by exploiting AI&rsquo;s intrinsic disconnect from the analog physical world: AI&rsquo;s nature as pure software code run on chips controlled by humans, and the prerequisite that all AI-driven physical actions must be digitized. These findings establish a theoretical foundation for AI governance and legislation as the basic structure of a &ldquo;brake system&rdquo; for AI decisions. If enacted, these controls can rein in AI dangers as completely as humanly possible, removing large chunks of currently wide-open AI risks, substantially reducing overall AI risks to residual human errors.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04489v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04489v1">üìÑ Download PDF</a></p><hr><h3 id=minimizing-the-number-of-code-switching-operations-in-fault-tolerant-quantum-circuitshttpsarxivorgabs251204170v1><a href=https://arxiv.org/abs/2512.04170v1>Minimizing the Number of Code Switching Operations in Fault-Tolerant Quantum Circuits</a><a hidden class=anchor aria-hidden=true href=#minimizing-the-number-of-code-switching-operations-in-fault-tolerant-quantum-circuitshttpsarxivorgabs251204170v1>#</a></h3><p><strong>Authors:</strong> Erik Weilandt, Tom Peham, Robert Wille
<strong>Venue:</strong> arXiv (2025)</p><p>Fault-tolerant quantum computers rely on Quantum Error-Correcting Codes (QECCs) to protect information from noise. However, no single error-correcting code supports a fully transversal and therefore fault-tolerant implementation of all gates required for universal quantum computation. Code switching addresses this limitation by moving quantum information between different codes that, together, support a universal gate set. Unfortunately, each switch is costly-adding time and space overhead and increasing the logical error rate. Minimizing the number of switching operations is, therefore, essential for quantum computations using code switching. In this work, we study the problem of minimizing the number of code switches required to run a given quantum circuit. We show that this problem can be solved efficiently in polynomial time by reducing it to a minimum-cut instance on a graph derived from the circuit. Our formulation is flexible and can incorporate additional considerations, such as reducing depth overhead by preferring switches during idle periods or biasing the compilation to favor one code over another. To the best of our knowledge, this is the first automated approach for compiling and optimizing code-switching-based quantum computations at the logical level.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04170v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04170v1">üìÑ Download PDF</a></p><hr><h3 id=encompass-enhancing-agent-programming-with-search-over-program-execution-pathshttpsarxivorgabs251203571v1><a href=https://arxiv.org/abs/2512.03571v1>EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths</a><a hidden class=anchor aria-hidden=true href=#encompass-enhancing-agent-programming-with-search-over-program-execution-pathshttpsarxivorgabs251203571v1>#</a></h3><p><strong>Authors:</strong> Zhening Li, Armando Solar-Lezama, Yisong Yue, Stephan Zheng
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce &ldquo;probabilistic angelic nondeterminism&rdquo; (&ldquo;PAN&rdquo;), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03571v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03571v1">üìÑ Download PDF</a></p><hr><h3 id=language-diversity-evaluating-language-usage-and-ai-performance-on-african-languages-in-digital-spaceshttpsarxivorgabs251201557v1><a href=https://arxiv.org/abs/2512.01557v1>Language Diversity: Evaluating Language Usage and AI Performance on African Languages in Digital Spaces</a><a hidden class=anchor aria-hidden=true href=#language-diversity-evaluating-language-usage-and-ai-performance-on-african-languages-in-digital-spaceshttpsarxivorgabs251201557v1>#</a></h3><p><strong>Authors:</strong> Edward Ajayi, Eudoxie Umwari, Mawuli Deku, Prosper Singadi, Jules Udahemuka, Bekalu Tadele, Chukuemeka Edeh
<strong>Venue:</strong> arXiv (2025)</p><p>This study examines the digital representation of African languages and the challenges this presents for current language detection tools. We evaluate their performance on Yoruba, Kinyarwanda, and Amharic. While these languages are spoken by millions, their online usage on conversational platforms is often sparse, heavily influenced by English, and not representative of the authentic, monolingual conversations prevalent among native speakers. This lack of readily available authentic data online creates a challenge of scarcity of conversational data for training language models. To investigate this, data was collected from subreddits and local news sources for each language. The analysis showed a stark contrast between the two sources. Reddit data was minimal and characterized by heavy code-switching. Conversely, local news media offered a robust source of clean, monolingual language data, which also prompted more user engagement in the local language on the news publishers social media pages. Language detection models, including the specialized AfroLID and a general LLM, performed with near-perfect accuracy on the clean news data but struggled with the code-switched Reddit posts. The study concludes that professionally curated news content is a more reliable and effective source for training context-rich AI models for African languages than data from conversational platforms. It also highlights the need for future models that can process clean and code-switched text to improve the detection accuracy for African languages.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01557v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01557v1">üìÑ Download PDF</a></p><hr><h3 id=promptbridge-cross-model-prompt-transfer-for-large-language-modelshttpsarxivorgabs251201420v1><a href=https://arxiv.org/abs/2512.01420v1>PromptBridge: Cross-Model Prompt Transfer for Large Language Models</a><a hidden class=anchor aria-hidden=true href=#promptbridge-cross-model-prompt-transfer-for-large-language-modelshttpsarxivorgabs251201420v1>#</a></h3><p><strong>Authors:</strong> Yaxuan Wang, Quan Liu, Zhenting Wang, Zichao Li, Wei Wei, Yang Liu, Yujia Bao
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) underpin applications in code generation, mathematical reasoning, and agent-based workflows. In practice, systems access LLMs via commercial APIs or open-source deployments, and the model landscape (e.g., GPT, Claude, Llama) evolves rapidly. This rapid evolution forces frequent model switches driven by capability, cost, deployment constraints, and privacy. Yet prompts are highly model-sensitive: reusing a prompt engineered for one model on another often yields substantially worse performance than a prompt optimized for the target model. We term this phenomenon Model Drifting. Through extensive empirical analysis across diverse LLM configurations, we show that model drifting is both common and severe. To address this challenge, we introduce PromptBridge, a training-free framework that preserves prompt effectiveness under model switches, enabling cross-model prompt transfer without costly per-task or per-model re-optimization. PromptBridge requires only a small set of alignment tasks for calibration. It first applies Model-Adaptive Reflective Prompt Evolution (MAP-RPE) to obtain task- and model-specific optimal prompts via iterative reflective refinement and quantitative evaluation. Using the resulting calibrated prompt pairs for the source and target models, PromptBridge learns a cross-model prompt mapping. At test time, i.e., for an unseen task, given a source-model prompt, this mapping directly produces an optimized prompt for the target model. Experiments in single-agent and multi-agent settings show that PromptBridge consistently improves downstream accuracy while reducing migration effort. The code will be available soon.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01420v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01420v1">üìÑ Download PDF</a></p><hr><h3 id=exploiting-function-family-structure-in-analog-circuit-optimizationhttpsarxivorgabs251200712v1><a href=https://arxiv.org/abs/2512.00712v1>Exploiting Function-Family Structure in Analog Circuit Optimization</a><a hidden class=anchor aria-hidden=true href=#exploiting-function-family-structure-in-analog-circuit-optimizationhttpsarxivorgabs251200712v1>#</a></h3><p><strong>Authors:</strong> Zhuohua Liu, Kaiqi Huang, Qinxin Mei, Yuanqi Hu, Wei W. Xing
<strong>Venue:</strong> arXiv (2025)</p><p>Analog circuit optimization is typically framed as black-box search over arbitrary smooth functions, yet device physics constrains performance mappings to structured families: exponential device laws, rational transfer functions, and regime-dependent dynamics. Off-the-shelf Gaussian-process surrogates impose globally smooth, stationary priors that are misaligned with these regime-switching primitives and can severely misfit highly nonlinear circuits at realistic sample sizes (50&ndash;100 evaluations). We demonstrate that pre-trained tabular models encoding these primitives enable reliable optimization without per-circuit engineering. Circuit Prior Network (CPN) combines a tabular foundation model (TabPFN v2) with Direct Expected Improvement (DEI), computing expected improvement exactly under discrete posteriors rather than Gaussian approximations. Across 6 circuits and 25 baselines, structure-matched priors achieve $R^2 \approx 0.99$ in small-sample regimes where GP-Mat√©rn attains only $R^2 = 0.16$ on Bandgap, deliver $1.05$&ndash;$3.81\times$ higher FoM with $3.34$&ndash;$11.89\times$ fewer iterations, and suggest a shift from hand-crafting models as priors toward systematic physics-informed structure identification. Our code will be made publicly available upon paper acceptance.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00712v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00712v1">üìÑ Download PDF</a></p><hr><h3 id=analysis-of-the-operation-of-a-tsn-switch-and-other-devices-using-executable-qr-codeshttpsarxivorgabs251200221v1><a href=https://arxiv.org/abs/2512.00221v1>Analysis of the operation of a TSN switch and other devices using executable QR codes</a><a hidden class=anchor aria-hidden=true href=#analysis-of-the-operation-of-a-tsn-switch-and-other-devices-using-executable-qr-codeshttpsarxivorgabs251200221v1>#</a></h3><p><strong>Authors:</strong> Stefano Scanzio, Pietro Chiavassa, Gianluca Cena
<strong>Venue:</strong> arXiv (2025)</p><p>Executable QR codes, also known as sQRy, are a technology aimed at inserting executable programs in a QR code. Through a concrete example, in this paper, we demonstrate their usage in the context of industrial networks in order to assess the operation of a TSN switch by analyzing its status LEDs even in the absence of an internet connection. The entire generation chain that is used to create the sQRy, as well as the corresponding execution chain that, starting from the sQRy, runs it on a mobile device, has been detailed through examples.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00221v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00221v1">üìÑ Download PDF</a></p><hr><h3 id=mitigating-catastrophic-forgetting-in-target-language-adaptation-of-llms-via-source-shielded-updateshttpsarxivorgabs251204844v1><a href=https://arxiv.org/abs/2512.04844v1>Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates</a><a hidden class=anchor aria-hidden=true href=#mitigating-catastrophic-forgetting-in-target-language-adaptation-of-llms-via-source-shielded-updateshttpsarxivorgabs251204844v1>#</a></h3><p><strong>Authors:</strong> Atsuki Yamaguchi, Terufumi Morishita, Aline Villavicencio, Nikolaos Aletras
<strong>Venue:</strong> arXiv (2025)</p><p>Expanding the linguistic diversity of instruct large language models (LLMs) is crucial for global accessibility but is often hindered by the reliance on costly specialized target language labeled data and catastrophic forgetting during adaptation. We tackle this challenge under a realistic, low-resource constraint: adapting instruct LLMs using only unlabeled target language data. We introduce Source-Shielded Updates (SSU), a selective parameter update strategy that proactively preserves source knowledge. Using a small set of source data and a parameter importance scoring method, SSU identifies parameters critical to maintaining source abilities. It then applies a column-wise freezing strategy to protect these parameters before adaptation. Experiments across five typologically diverse languages and 7B and 13B models demonstrate that SSU successfully mitigates catastrophic forgetting. It reduces performance degradation on monolingual source tasks to just 3.4% (7B) and 2.8% (13B) on average, a stark contrast to the 20.3% and 22.3% from full fine-tuning. SSU also achieves target-language performance highly competitive with full fine-tuning, outperforming it on all benchmarks for 7B models and the majority for 13B models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04844v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04844v1">üìÑ Download PDF</a></p><hr><h3 id=divide-then-ground-adapting-frame-selection-to-query-types-for-long-form-video-understandinghttpsarxivorgabs251204000v1><a href=https://arxiv.org/abs/2512.04000v1>Divide, then Ground: Adapting Frame Selection to Query Types for Long-Form Video Understanding</a><a hidden class=anchor aria-hidden=true href=#divide-then-ground-adapting-frame-selection-to-query-types-for-long-form-video-understandinghttpsarxivorgabs251204000v1>#</a></h3><p><strong>Authors:</strong> Jialuo Li, Bin Li, Jiahao Li, Yan Lu
<strong>Venue:</strong> arXiv (2025)</p><p>The application of Large Multimodal Models (LMMs) to long-form video understanding is constrained by limited context lengths and the computationally prohibitive cost of processing dense video tokens. Consequently, recent research has focused on query-aware frame selection, methods that often incur significant computational overhead. This paper challenges the assumption that such complex search mechanisms are universally necessary. We first identify and validate a query typology distinguishing between global query and localized query. We demonstrate that while uniform sampling is both effective and efficient for global queries, localized queries indeed necessitate query-aware selection for optimal performance. Building on this insight, we propose DIG, a training-free frame selection framework that adapts its strategy based on the query type. Specifically,DIG employs efficient uniform sampling for global queries while activating a specialized pipeline to extract query-relevant frames for localized queries. Experiments on three long-form video understanding benchmarks demonstrate that DIG consistently outperforms existing baselines and robustly improves LMM performance, even when scaling the input frame count to 256.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04000v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04000v1">üìÑ Download PDF</a></p><hr><h3 id=draco-draft-as-cot-for-text-to-image-preview-and-rare-concept-generationhttpsarxivorgabs251205112v1><a href=https://arxiv.org/abs/2512.05112v1>DraCo: Draft as CoT for Text-to-Image Preview and Rare Concept Generation</a><a hidden class=anchor aria-hidden=true href=#draco-draft-as-cot-for-text-to-image-preview-and-rare-concept-generationhttpsarxivorgabs251205112v1>#</a></h3><p><strong>Authors:</strong> Dongzhi Jiang, Renrui Zhang, Haodong Li, Zhuofan Zong, Ziyu Guo, Jun He, Claire Guo, Junyan Ye, Rongyao Fang, Weijia Li, Rui Liu, Hongsheng Li
<strong>Venue:</strong> arXiv (2025)</p><p>Recent unified multimodal large language models (MLLMs) have shown impressive capabilities, incorporating chain-of-thought (CoT) reasoning for enhanced text-to-image generation. However, existing approaches remain limited, either treating the model merely as a standalone generator or relying on abstract textual planning. To this end, we propose Draft-as-CoT (DraCo), a novel interleaved reasoning paradigm that fully leverages both textual and visual contents in CoT for better planning and verification. Our method first generates a low-resolution draft image as preview, providing more concrete and structural visual planning and guidance. Then, we employ the model&rsquo;s inherent understanding capability to verify potential semantic misalignments between the draft and input prompt, and performs refinement through selective corrections with super-resolution. In this way, our approach addresses two fundamental challenges: the coarse-grained nature of textual planning and the difficulty in generating rare attribute combinations. To support training, we curate DraCo-240K, aiming to enhance three atomic capabilities spanning general correction, instance manipulation, and layout reorganization. Supported by DraCo-CFG, a specialized classifier-free guidance (CFG) strategy for interleaved reasoning, DraCo achieves a tremendous increase on GenEval (+8%), Imagine-Bench (+0.91), and GenEval++ (+3%), significantly outperforming direct generation and other generation methods empowered by CoT.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05112v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05112v1">üìÑ Download PDF</a></p><hr><h3 id=arm-thinker-reinforcing-multimodal-generative-reward-models-with-agentic-tool-use-and-visual-reasoninghttpsarxivorgabs251205111v1><a href=https://arxiv.org/abs/2512.05111v1>ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning</a><a hidden class=anchor aria-hidden=true href=#arm-thinker-reinforcing-multimodal-generative-reward-models-with-agentic-tool-use-and-visual-reasoninghttpsarxivorgabs251205111v1>#</a></h3><p><strong>Authors:</strong> Shengyuan Ding, Xinyu Fang, Ziyu Liu, Yuhang Zang, Yuhang Cao, Xiangyu Zhao, Haodong Duan, Xiaoyi Dong, Jianze Liang, Bin Wang, Conghui He, Dahua Lin, Jiaqi Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Reward models are critical for aligning vision-language systems with human preferences, yet current approaches suffer from hallucination, weak visual grounding, and an inability to use tools for verification, limiting their reliability on complex multimodal reasoning tasks. We present ARM-Thinker, an A}gentic multimodal Reward Model that autonomously invokes external tools (e.g., image cropping, doc page retrieval) to ground judgments in verifiable evidence, replacing static, non-interactive reward scoring. This enables the model to verify fine-grained visual details, cross-reference multi-page evidence, and validate reasoning claims, which are capabilities absent in existing reward models. We train ARM-Thinker with multi-stage reinforcement learning, jointly optimizing tool-calling decisions and judgment accuracy. To evaluate agentic reward modeling, we introduce ARMBench-VL, comprising three benchmarks that assess fine-grained visual grounding (image-level tools), multi-page document understanding (retrieval tools), and instruction following (text-level verification). ARM-Thinker achieves +16.2% average improvement on reward modeling benchmarks, +9.6% on tool-use tasks, and outperforms baselines on multimodal math and logical reasoning benchmarks. Our results demonstrate that agentic capabilities significantly enhance both accuracy and interpretability of reward models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05111v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05111v1">üìÑ Download PDF</a></p><hr><h3 id=stare-vla-progressive-stage-aware-reinforcement-for-fine-tuning-vision-language-action-modelshttpsarxivorgabs251205107v1><a href=https://arxiv.org/abs/2512.05107v1>STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models</a><a hidden class=anchor aria-hidden=true href=#stare-vla-progressive-stage-aware-reinforcement-for-fine-tuning-vision-language-action-modelshttpsarxivorgabs251205107v1>#</a></h3><p><strong>Authors:</strong> Feng Xu, Guangyao Zhai, Xin Kong, Tingzhong Fu, Daniel F. N. Gordon, Xueli An, Benjamin Busam
<strong>Venue:</strong> arXiv (2025)</p><p>Recent advances in Vision-Language-Action (VLA) models, powered by large language models and reinforcement learning-based fine-tuning, have shown remarkable progress in robotic manipulation. Existing methods often treat long-horizon actions as linguistic sequences and apply trajectory-level optimization methods such as Trajectory-wise Preference Optimization (TPO) or Proximal Policy Optimization (PPO), leading to coarse credit assignment and unstable training. However, unlike language, where a unified semantic meaning is preserved despite flexible sentence order, action trajectories progress through causally chained stages with different learning difficulties. This motivates progressive stage optimization. Thereby, we present Stage-Aware Reinforcement (STARE), a module that decomposes a long-horizon action trajectory into semantically meaningful stages and provides dense, interpretable, and stage-aligned reinforcement signals. Integrating STARE into TPO and PPO, we yield Stage-Aware TPO (STA-TPO) and Stage-Aware PPO (STA-PPO) for offline stage-wise preference and online intra-stage interaction, respectively. Further building on supervised fine-tuning as initialization, we propose the Imitation -> Preference -> Interaction (IPI), a serial fine-tuning pipeline for improving action accuracy in VLA models. Experiments on SimplerEnv and ManiSkill3 demonstrate substantial gains, achieving state-of-the-art success rates of 98.0 percent on SimplerEnv and 96.4 percent on ManiSkill3 tasks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05107v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05107v1">üìÑ Download PDF</a></p><hr><h3 id=semantic-soft-bootstrapping-long-context-reasoning-in-llms-without-reinforcement-learninghttpsarxivorgabs251205105v1><a href=https://arxiv.org/abs/2512.05105v1>Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning</a><a hidden class=anchor aria-hidden=true href=#semantic-soft-bootstrapping-long-context-reasoning-in-llms-without-reinforcement-learninghttpsarxivorgabs251205105v1>#</a></h3><p><strong>Authors:</strong> Purbesh Mitra, Sennur Ulukus
<strong>Venue:</strong> arXiv (2025)</p><p>Long context reasoning in large language models (LLMs) has demonstrated enhancement of their cognitive capabilities via chain-of-thought (CoT) inference. Training such models is usually done via reinforcement learning with verifiable rewards (RLVR) in reasoning based problems, like math and programming. However, RLVR is limited by several bottlenecks, such as, lack of dense reward, and inadequate sample efficiency. As a result, it requires significant compute resources in post-training phase. To overcome these limitations, in this work, we propose \textbf{Semantic Soft Bootstrapping (SSB)}, a self-distillation technique, in which the same base language model plays the role of both teacher and student, but receives different semantic contexts about the correctness of its outcome at training time. The model is first prompted with a math problem and several rollouts are generated. From them, the correct and most common incorrect response are filtered, and then provided to the model in context to produce a more robust, step-by-step explanation with a verified final answer. This pipeline automatically curates a paired teacher-student training set from raw problem-answer data, without any human intervention. This generation process also produces a sequence of logits, which is what the student model tries to match in the training phase just from the bare question alone. In our experiment, Qwen2.5-3B-Instruct on GSM8K dataset via parameter-efficient fine-tuning. We then tested its accuracy on MATH500, and AIME2024 benchmarks. Our experiments show a jump of 10.6%, and 10% improvements in accuracy, respectively, over group relative policy optimization (GRPO), which is a commonly used RLVR algorithm. Our code is available at <a href=https://github.com/purbeshmitra/semantic-soft-bootstrapping>https://github.com/purbeshmitra/semantic-soft-bootstrapping</a>, and the model, curated dataset is available at <a href=https://huggingface.co/purbeshmitra/semantic-soft-bootstrapping>https://huggingface.co/purbeshmitra/semantic-soft-bootstrapping</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05105v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05105v1">üìÑ Download PDF</a></p><hr><h3 id=tv2tv-a-unified-framework-for-interleaved-language-and-video-generationhttpsarxivorgabs251205103v1><a href=https://arxiv.org/abs/2512.05103v1>TV2TV: A Unified Framework for Interleaved Language and Video Generation</a><a hidden class=anchor aria-hidden=true href=#tv2tv-a-unified-framework-for-interleaved-language-and-video-generationhttpsarxivorgabs251205103v1>#</a></h3><p><strong>Authors:</strong> Xiaochuang Han, Youssef Emad, Melissa Hall, John Nguyen, Karthik Padthe, Liam Robbins, Amir Bar, Delong Chen, Michal Drozdzal, Maha Elbayad, Yushi Hu, Shang-Wen Li, Sreya Dutta Roy, Jakob Verbeek, XuDong Wang, Marjan Ghazvininejad, Luke Zettlemoyer, Emily Dinan
<strong>Venue:</strong> arXiv (2025)</p><p>Video generation models are rapidly advancing, but can still struggle with complex video outputs that require significant semantic branching or repeated high-level reasoning about what should happen next. In this paper, we introduce a new class of omni video-text models that integrate ideas from recent LM reasoning advances to address this challenge. More specifically, we present TV2TV, a unified generative modeling framework which decomposes video generation into an interleaved text and video generation process. TV2TV jointly learns language modeling (next-token prediction) and video flow matching (next-frame prediction) using a Mixture-of-Transformers (MoT) architecture. At inference time, TV2TV decides when to alternate between generating text and video frames, allowing the model to &ldquo;think in words&rdquo; about subsequent content before ``acting in pixels&rsquo;&rsquo; to produce frames. This design offloads much of the responsibility for deciding what should happen next to the language modeling tower, enabling improved visual quality and prompt alignment of generated videos. It also enables fine-grained controllability, allowing users to modify the video generation trajectory through text interventions at any point in the process. In controlled experiments on video game data, TV2TV demonstrates substantial improvements in both visual quality and controllability. TV2TV also scales to natural videos, as we show by augmenting sports videos with interleaved natural language action descriptions using vision-language models (VLMs). Training TV2TV on this corpus yields strong visual quality and prompt alignment, showcasing the model&rsquo;s ability to reason about and generate complex real-world action sequences. Together, these results highlight TV2TV as a promising step toward video generation with open-ended textual reasoning and control.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05103v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05103v1">üìÑ Download PDF</a></p><hr><h3 id=structured-document-translation-via-format-reinforcement-learninghttpsarxivorgabs251205100v1><a href=https://arxiv.org/abs/2512.05100v1>Structured Document Translation via Format Reinforcement Learning</a><a hidden class=anchor aria-hidden=true href=#structured-document-translation-via-format-reinforcement-learninghttpsarxivorgabs251205100v1>#</a></h3><p><strong>Authors:</strong> Haiyue Song, Johannes Eschbach-Dymanus, Hour Kaing, Sumire Honda, Hideki Tanaka, Bianka Buschbeck, Masao Utiyama
<strong>Venue:</strong> arXiv (2025)</p><p>Recent works on structured text translation remain limited to the sentence level, as they struggle to effectively handle the complex document-level XML or HTML structures. To address this, we propose \textbf{Format Reinforcement Learning (FormatRL)}, which employs Group Relative Policy Optimization on top of a supervised fine-tuning model to directly optimize novel structure-aware rewards: 1) TreeSim, which measures structural similarity between predicted and reference XML trees and 2) Node-chrF, which measures translation quality at the level of XML nodes. Additionally, we apply StrucAUC, a fine-grained metric distinguishing between minor errors and major structural failures. Experiments on the SAP software-documentation benchmark demonstrate improvements across six metrics and an analysis further shows how different reward functions contribute to improvements in both structural and translation quality.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05100v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05100v1">üìÑ Download PDF</a></p><hr><h3 id=visual-reasoning-tracer-object-level-grounded-reasoning-benchmarkhttpsarxivorgabs251205091v1><a href=https://arxiv.org/abs/2512.05091v1>Visual Reasoning Tracer: Object-Level Grounded Reasoning Benchmark</a><a hidden class=anchor aria-hidden=true href=#visual-reasoning-tracer-object-level-grounded-reasoning-benchmarkhttpsarxivorgabs251205091v1>#</a></h3><p><strong>Authors:</strong> Haobo Yuan, Yueyi Sun, Yanwei Li, Tao Zhang, Xueqing Deng, Henghui Ding, Lu Qi, Anran Wang, Xiangtai Li, Ming-Hsuan Yang
<strong>Venue:</strong> arXiv (2025)</p><p>Recent advances in Multimodal Large Language Models (MLLMs) have significantly improved performance on tasks such as visual grounding and visual question answering. However, the reasoning processes of these models remain largely opaque; they typically output only final predictions without revealing the intermediate steps or fine-grained evidence (e.g., pixels, locations) that lead to the result. This contrasts with human intelligence, which naturally operates through a chain of visual reasoning. To address this limitation, we introduce the Visual Reasoning Tracer (VRT) task, which requires models to not only localize the target object but also explicitly predict the intermediate objects that form the reasoning path. To advance research in this area, we contribute: (1) VRT-Bench, a human-annotated benchmark for evaluating visual reasoning; (2) a new metric for assessing the quality of reasoning traces; and (3) VRT-80k, a large-scale dataset for reasoning model training. Our experiments reveal that while existing models often produce the correct final output, they struggle to ground their intermediate reasoning. In contrast, models trained on VRT-80k achieve substantial improvements in tracing the reasoning path.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05091v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05091v1">üìÑ Download PDF</a></p><hr><h3 id=david-vs-goliath-can-small-models-win-big-with-agentic-ai-in-hardware-designhttpsarxivorgabs251205073v1><a href=https://arxiv.org/abs/2512.05073v1>David vs. Goliath: Can Small Models Win Big with Agentic AI in Hardware Design?</a><a hidden class=anchor aria-hidden=true href=#david-vs-goliath-can-small-models-win-big-with-agentic-ai-in-hardware-designhttpsarxivorgabs251205073v1>#</a></h3><p><strong>Authors:</strong> Shashwat Shankar, Subhranshu Pandey, Innocent Dengkhw Mochahari, Bhabesh Mali, Animesh Basak Chowdhury, Sukanta Bhattacharjee, Chandan Karfa
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Model(LLM) inference demands massive compute and energy, making domain-specific tasks expensive and unsustainable. As foundation models keep scaling, we ask: Is bigger always better for hardware design? Our work tests this by evaluating Small Language Models coupled with a curated agentic AI framework on NVIDIA&rsquo;s Comprehensive Verilog Design Problems(CVDP) benchmark. Results show that agentic workflows: through task decomposition, iterative feedback, and correction - not only unlock near-LLM performance at a fraction of the cost but also create learning opportunities for agents, paving the way for efficient, adaptive solutions in complex design tasks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05073v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05073v1">üìÑ Download PDF</a></p><hr><h3 id=multi-llm-collaboration-for-medication-recommendationhttpsarxivorgabs251205066v1><a href=https://arxiv.org/abs/2512.05066v1>Multi-LLM Collaboration for Medication Recommendation</a><a hidden class=anchor aria-hidden=true href=#multi-llm-collaboration-for-medication-recommendationhttpsarxivorgabs251205066v1>#</a></h3><p><strong>Authors:</strong> Huascar Sanchez, Briland Hitaj, Jules Bergmann, Linda Briesemeister
<strong>Venue:</strong> arXiv (2025)</p><p>As healthcare increasingly turns to AI for scalable and trustworthy clinical decision support, ensuring reliability in model reasoning remains a critical challenge. Individual large language models (LLMs) are susceptible to hallucinations and inconsistency, whereas naive ensembles of models often fail to deliver stable and credible recommendations. Building on our previous work on LLM Chemistry, which quantifies the collaborative compatibility among LLMs, we apply this framework to improve the reliability in medication recommendation from brief clinical vignettes. Our approach leverages multi-LLM collaboration guided by Chemistry-inspired interaction modeling, enabling ensembles that are effective (exploiting complementary strengths), stable (producing consistent quality), and calibrated (minimizing interference and error amplification). We evaluate our Chemistry-based Multi-LLM collaboration strategy on real-world clinical scenarios to investigate whether such interaction-aware ensembles can generate credible, patient-specific medication recommendations. Preliminary results are encouraging, suggesting that LLM Chemistry-guided collaboration may offer a promising path toward reliable and trustworthy AI assistants in clinical practice.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05066v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05066v1">üìÑ Download PDF</a></p><hr><h3 id=personalizing-agent-privacy-decisions-via-logical-entailmenthttpsarxivorgabs251205065v1><a href=https://arxiv.org/abs/2512.05065v1>Personalizing Agent Privacy Decisions via Logical Entailment</a><a hidden class=anchor aria-hidden=true href=#personalizing-agent-privacy-decisions-via-logical-entailmenthttpsarxivorgabs251205065v1>#</a></h3><p><strong>Authors:</strong> James Flemings, Ren Yi, Octavian Suciu, Kassem Fawaz, Murali Annavaram, Marco Gruteser
<strong>Venue:</strong> arXiv (2025)</p><p>Personal language model-based agents are becoming more widespread for completing tasks on behalf of users; however, this raises serious privacy questions regarding whether these models will appropriately disclose user data. While prior work has evaluated language models on data-sharing scenarios based on general privacy norms, we focus on personalizing language models&rsquo; privacy decisions, grounding their judgments directly in prior user privacy decisions. Our findings suggest that general privacy norms are insufficient for effective personalization of privacy decisions. Furthermore, we find that eliciting privacy judgments from the model through In-context Learning (ICL) is unreliable to due misalignment with the user&rsquo;s prior privacy judgments and opaque reasoning traces, which make it difficult for the user to interpret the reasoning behind the model&rsquo;s decisions. To address these limitations, we propose ARIEL (Agentic Reasoning with Individualized Entailment Logic), a framework that jointly leverages a language model and rule-based logic for structured data-sharing reasoning. ARIEL is based on formulating personalization of data sharing as an entailment, whether a prior user judgment on a data-sharing request implies the same judgment for an incoming request. Our experimental evaluations on advanced models and publicly-available datasets demonstrate that ARIEL can reduce the F1 score error by $\textbf{39.1%}$ over language model-based reasoning (ICL), demonstrating that ARIEL is effective at correctly judging requests where the user would approve data sharing. Overall, our findings suggest that combining LLMs with strict logical entailment is a highly effective strategy for enabling personalized privacy judgments for agents.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05065v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05065v1">üìÑ Download PDF</a></p><hr><h3 id=4dlangvggt-4d-language-visual-geometry-grounded-transformerhttpsarxivorgabs251205060v1><a href=https://arxiv.org/abs/2512.05060v1>4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer</a><a hidden class=anchor aria-hidden=true href=#4dlangvggt-4d-language-visual-geometry-grounded-transformerhttpsarxivorgabs251205060v1>#</a></h3><p><strong>Authors:</strong> Xianfeng Wu, Yajing Bai, Minghan Li, Xianzu Wu, Xueqi Zhao, Zhongyuan Lai, Wenyu Liu, Xinggang Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Constructing 4D language fields is crucial for embodied AI, augmented/virtual reality, and 4D scene understanding, as they provide enriched semantic representations of dynamic environments and enable open-vocabulary querying in complex scenarios. However, existing approaches to 4D semantic field construction primarily rely on scene-specific Gaussian splatting, which requires per-scene optimization, exhibits limited generalization, and is difficult to scale to real-world applications. To address these limitations, we propose 4DLangVGGT, the first Transformer-based feed-forward unified framework for 4D language grounding, that jointly integrates geometric perception and language alignment within a single architecture. 4DLangVGGT has two key components: the 4D Visual Geometry Transformer, StreamVGGT, which captures spatio-temporal geometric representations of dynamic scenes; and the Semantic Bridging Decoder (SBD), which projects geometry-aware features into a language-aligned semantic space, thereby enhancing semantic interpretability while preserving structural fidelity. Unlike prior methods that depend on costly per-scene optimization, 4DLangVGGT can be jointly trained across multiple dynamic scenes and directly applied during inference, achieving both deployment efficiency and strong generalization. This design significantly improves the practicality of large-scale deployment and establishes a new paradigm for open-vocabulary 4D scene understanding. Experiments on HyperNeRF and Neu3D datasets demonstrate that our approach not only generalizes effectively but also achieves state-of-the-art performance, achieving up to 2% gains under per-scene training and 1% improvements under multi-scene training. Our code released in <a href=https://github.com/hustvl/4DLangVGGT>https://github.com/hustvl/4DLangVGGT</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05060v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05060v1">üìÑ Download PDF</a></p><hr><h3 id=arbitrage-efficient-reasoning-via-advantage-aware-speculationhttpsarxivorgabs251205033v1><a href=https://arxiv.org/abs/2512.05033v1>Arbitrage: Efficient Reasoning via Advantage-Aware Speculation</a><a hidden class=anchor aria-hidden=true href=#arbitrage-efficient-reasoning-via-advantage-aware-speculationhttpsarxivorgabs251205033v1>#</a></h3><p><strong>Authors:</strong> Monishwaran Maheswaran, Rishabh Tiwari, Yuezhou Hu, Kerem Dilmen, Coleman Hooper, Haocheng Xi, Nicholas Lee, Mehrdad Farajtabar, Michael W. Mahoney, Kurt Keutzer, Amir Gholami
<strong>Venue:</strong> arXiv (2025)</p><p>Modern Large Language Models achieve impressive reasoning capabilities with long Chain of Thoughts, but they incur substantial computational cost during inference, and this motivates techniques to improve the performance-cost ratio. Among these techniques, Speculative Decoding accelerates inference by employing a fast but inaccurate draft model to autoregressively propose tokens, which are then verified in parallel by a more capable target model. However, due to unnecessary rejections caused by token mismatches in semantically equivalent steps, traditional token-level Speculative Decoding struggles in reasoning tasks. Although recent works have shifted to step-level semantic verification, which improve efficiency by accepting or rejecting entire reasoning steps, existing step-level methods still regenerate many rejected steps with little improvement, wasting valuable target compute. To address this challenge, we propose Arbitrage, a novel step-level speculative generation framework that routes generation dynamically based on the relative advantage between draft and target models. Instead of applying a fixed acceptance threshold, Arbitrage uses a lightweight router trained to predict when the target model is likely to produce a meaningfully better step. This routing approximates an ideal Arbitrage Oracle that always chooses the higher-quality step, achieving near-optimal efficiency-accuracy trade-offs. Across multiple mathematical reasoning benchmarks, Arbitrage consistently surpasses prior step-level Speculative Decoding baselines, reducing inference latency by up to $\sim2\times$ at matched accuracy.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05033v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05033v1">üìÑ Download PDF</a></p><hr><h3 id=factuality-and-transparency-are-all-rag-needs-self-explaining-contrastive-evidence-re-rankinghttpsarxivorgabs251205012v1><a href=https://arxiv.org/abs/2512.05012v1>Factuality and Transparency Are All RAG Needs! Self-Explaining Contrastive Evidence Re-ranking</a><a hidden class=anchor aria-hidden=true href=#factuality-and-transparency-are-all-rag-needs-self-explaining-contrastive-evidence-re-rankinghttpsarxivorgabs251205012v1>#</a></h3><p><strong>Authors:</strong> Francielle Vargas, Daniel Pedronette
<strong>Venue:</strong> arXiv (2025)</p><p>This extended abstract introduces Self-Explaining Contrastive Evidence Re-Ranking (CER), a novel method that restructures retrieval around factual evidence by fine-tuning embeddings with contrastive learning and generating token-level attribution rationales for each retrieved passage. Hard negatives are automatically selected using a subjectivity-based criterion, forcing the model to pull factual rationales closer while pushing subjective or misleading explanations apart. As a result, the method creates an embedding space explicitly aligned with evidential reasoning. We evaluated our method on clinical trial reports, and initial experimental results show that CER improves retrieval accuracy, mitigates the potential for hallucinations in RAG systems, and provides transparent, evidence-based retrieval that enhances reliability, especially in safety-critical domains.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05012v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05012v1">üìÑ Download PDF</a></p><hr><h3 id=influence-of-object-affordance-on-action-language-understanding-evidence-from-dynamic-causal-modeling-analysishttpsarxivorgabs251204989v1><a href=https://arxiv.org/abs/2512.04989v1>Influence of Object Affordance on Action Language Understanding: Evidence from Dynamic Causal Modeling Analysis</a><a hidden class=anchor aria-hidden=true href=#influence-of-object-affordance-on-action-language-understanding-evidence-from-dynamic-causal-modeling-analysishttpsarxivorgabs251204989v1>#</a></h3><p><strong>Authors:</strong> Supriya Bordoloi, Cota Navin Gupta, Shyamanta M. Hazarika
<strong>Venue:</strong> arXiv (2025)</p><p>This study investigates the causal neural dynamics by which affordance representations influence action language comprehension. In this study, 18 participants observed stimuli displayed in two conditions during the experiment: text-only (e.g., `Hit with a hammer&rsquo;) and video+text (visual clips with matching phrases). EEG data were recorded from 32 channels and analyzed for event-related potentials and source localization using LORETA, which identified four left-hemisphere regions of interest: the Lateral Occipital Cortex (LOC), Posterior Superior Temporal Gyrus (pSTG), Ventral Premotor Cortex (PMv), and Inferior Parietal Lobule (IPL). A space of dynamic causal modeling (DCM) was constructed with driving inputs to LOC and pSTG, and multiple connectivity configurations were tested. Bayesian Model Selection revealed a dominant model in which PMv causally influenced IPL and pSTG, reflecting a feedforward architecture from affordance-related motor regions to semantic hubs. Bayesian Model Averaging further confirmed strong endogenous connections from LOC to PMv and IPL, and significant modulation from PMv to IPL. These findings provide direct evidence that affordance processing in premotor regions drives action language understanding by engaging downstream parietal and temporal areas. The results support grounded cognition theories and offer a mechanistic account of how sensorimotor information contributes to linguistic comprehension.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04989v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04989v1">üìÑ Download PDF</a></p><hr><h3 id=strategic-self-improvement-for-competitive-agents-in-ai-labour-marketshttpsarxivorgabs251204988v1><a href=https://arxiv.org/abs/2512.04988v1>Strategic Self-Improvement for Competitive Agents in AI Labour Markets</a><a hidden class=anchor aria-hidden=true href=#strategic-self-improvement-for-competitive-agents-in-ai-labour-marketshttpsarxivorgabs251204988v1>#</a></h3><p><strong>Authors:</strong> Christopher Chiu, Simpson Zhang, Mihaela van der Schaar
<strong>Venue:</strong> arXiv (2025)</p><p>As artificial intelligence (AI) agents are deployed across economic domains, understanding their strategic behavior and market-level impact becomes critical. This paper puts forward a groundbreaking new framework that is the first to capture the real-world economic forces that shape agentic labor markets: adverse selection, moral hazard, and reputation dynamics. Our framework encapsulates three core capabilities that successful LLM-agents will need: \textbf{metacognition} (accurate self-assessment of skills), \textbf{competitive awareness} (modeling rivals and market dynamics), and \textbf{long-horizon strategic planning}. We illustrate our framework through a tractable simulated gig economy where agentic Large Language Models (LLMs) compete for jobs, develop skills, and adapt their strategies under competitive pressure. Our simulations illustrate how LLM agents explicitly prompted with reasoning capabilities learn to strategically self-improve and demonstrate superior adaptability to changing market conditions. At the market level, our simulations reproduce classic macroeconomic phenomena found in human labor markets, while controlled experiments reveal potential AI-driven economic trends, such as rapid monopolization and systemic price deflation. This work provides a foundation to further explore the economic properties of AI-driven labour markets, and a conceptual framework to study the strategic reasoning capabilities in agents competing in the emerging economy.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04988v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04988v1">üìÑ Download PDF</a></p><hr><h3 id=nex-n1-agentic-models-trained-via-a-unified-ecosystem-for-large-scale-environment-constructionhttpsarxivorgabs251204987v1><a href=https://arxiv.org/abs/2512.04987v1>Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction</a><a hidden class=anchor aria-hidden=true href=#nex-n1-agentic-models-trained-via-a-unified-ecosystem-for-large-scale-environment-constructionhttpsarxivorgabs251204987v1>#</a></h3><p><strong>Authors:</strong> Nex-AGI Team, :, Yuxuan Cai, Lu Chen, Qiaoling Chen, Yuyang Ding, Liwen Fan, Wenjie Fu, Yufei Gao, Honglin Guo, Pinxue Guo, Zhenhua Han, Zhengfu He, Hanglei Hu, Kai Hu, Shengjia Hua, Tianyu Huai, Baodai Huang, Li Ji, Zhen Jiang, Zhikai Lei, Bufan Li, Jiahang Lin, Lizhi Lin, Jinxiu Liu, Shichun Liu, Ziming Liu, Yuchen Ni, Pengfang Qian, Yujiong Shen, Qingyun Shi, Wentao Shu, Peng Sun, Yiran Suo, Tian Tang, Boyu Tian, Guoteng Wang, Junzhe Wang, Peixin Wang, Zhiheng Xi, Hang Yan, Jie Yang, Zhixiong Yang, Tianchu Yao, Guangze Ye, Qianxi Yu, Shuo Zhang, Xinyue Zhang, Yiqi Zhang, Jiarong Zhao, Miao Zheng, Rui Zheng, Enyu Zhou, Jiazheng Zhou, Maosen Zhou, Yuhao Zhou, Tao Gui, Yining Zheng, Xinchi Chen, Jie Zhou, Siyuan Feng, Qin Chen, Liang He, Qi Zhang, Xuanjing Huang, Xipeng Qiu
<strong>Venue:</strong> arXiv (2025)</p><p>The evolution of Large Language Models (LLMs) from passive responders to autonomous agents necessitates a fundamental shift in learning paradigms &ndash; from static imitation to incentive-driven decision making. However, this transition is significantly impeded by the lack of scalable infrastructure capable of constructing high-quality interaction signals for effective policy learning. To address this, we introduce a comprehensive method designed to systematically scale the diversity and complexity of interactive environments. Our method realizes this scaling by addressing three orthogonal dimensions: (1) Complexity: NexAU, a flexible agent framework that supports building complex agent hierarchies via simple configurations; (2) Diversity: NexA4A automatically generates diverse agent hierarchies from natural language to cover infinite domains; and (3) Fidelity: NexGAP bridges the simulation-reality gap by integrating dynamic real-world environment for grounded trajectories synthesis. We train Nex-N1 upon the diverse and complex interactive environments established by our infrastructure. Empirical results on benchmarks such as SWE-bench and tau2 demonstrate that Nex-N1 consistently outperforms SOTA open-source models and achieves competitive performance against frontier proprietary models on complex agentic tasks. We open-source the Nex ecosystem and model weights to facilitate further research.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04987v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04987v1">üìÑ Download PDF</a></p><hr><h3 id=aligned-but-stereotypical-the-hidden-influence-of-system-prompts-on-social-bias-in-lvlm-based-text-to-image-modelshttpsarxivorgabs251204981v1><a href=https://arxiv.org/abs/2512.04981v1>Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models</a><a hidden class=anchor aria-hidden=true href=#aligned-but-stereotypical-the-hidden-influence-of-system-prompts-on-social-bias-in-lvlm-based-text-to-image-modelshttpsarxivorgabs251204981v1>#</a></h3><p><strong>Authors:</strong> NaHyeon Park, Namin An, Kunhee Kim, Soyeon Yoon, Jiahao Huo, Hyunjung Shim
<strong>Venue:</strong> arXiv (2025)</p><p>Large vision-language model (LVLM) based text-to-image (T2I) systems have become the dominant paradigm in image generation, yet whether they amplify social biases remains insufficiently understood. In this paper, we show that LVLM-based models produce markedly more socially biased images than non-LVLM-based models. We introduce a 1,024 prompt benchmark spanning four levels of linguistic complexity and evaluate demographic bias across multiple attributes in a systematic manner. Our analysis identifies system prompts, the predefined instructions guiding LVLMs, as a primary driver of biased behavior. Through decoded intermediate representations, token-probability diagnostics, and embedding-association analyses, we reveal how system prompts encode demographic priors that propagate into image synthesis. To this end, we propose FairPro, a training-free meta-prompting framework that enables LVLMs to self-audit and construct fairness-aware system prompts at test time. Experiments on two LVLM-based T2I models, SANA and Qwen-Image, show that FairPro substantially reduces demographic bias while preserving text-image alignment. We believe our findings provide deeper insight into the central role of system prompts in bias propagation and offer a practical, deployable approach for building more socially responsible T2I systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04981v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04981v1">üìÑ Download PDF</a></p><hr><h3 id=hippo-exploring-a-novel-hierarchical-pronunciation-assessment-approach-for-spoken-languageshttpsarxivorgabs251204964v1><a href=https://arxiv.org/abs/2512.04964v1>HiPPO: Exploring A Novel Hierarchical Pronunciation Assessment Approach for Spoken Languages</a><a hidden class=anchor aria-hidden=true href=#hippo-exploring-a-novel-hierarchical-pronunciation-assessment-approach-for-spoken-languageshttpsarxivorgabs251204964v1>#</a></h3><p><strong>Authors:</strong> Bi-Cheng Yan, Hsin-Wei Wang, Fu-An Chao, Tien-Hong Lo, Yung-Chang Hsu, Berlin Chen
<strong>Venue:</strong> arXiv (2025)</p><p>Automatic pronunciation assessment (APA) seeks to quantify a second language (L2) learner&rsquo;s pronunciation proficiency in a target language by offering timely and fine-grained diagnostic feedback. Most existing efforts on APA have predominantly concentrated on highly constrained reading-aloud tasks (where learners are prompted to read a reference text aloud); however, assessing pronunciation quality in unscripted speech (or free-speaking scenarios) remains relatively underexplored. In light of this, we first propose HiPPO, a hierarchical pronunciation assessment model tailored for spoken languages, which evaluates an L2 learner&rsquo;s oral proficiency at multiple linguistic levels based solely on the speech uttered by the learner. To improve the overall accuracy of assessment, a contrastive ordinal regularizer and a curriculum learning strategy are introduced for model training. The former aims to generate score-discriminative features by exploiting the ordinal nature of regression targets, while the latter gradually ramps up the training complexity to facilitate the assessment task that takes unscripted speech as input. Experiments conducted on the Speechocean762 benchmark dataset validates the feasibility and superiority of our method in relation to several cutting-edge baselines.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04964v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04964v1">üìÑ Download PDF</a></p><hr><h3 id=faster-toward-efficient-autoregressive-vision-language-action-modeling-via-neural-action-tokenizationhttpsarxivorgabs251204952v1><a href=https://arxiv.org/abs/2512.04952v1>FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via neural Action Tokenization</a><a hidden class=anchor aria-hidden=true href=#faster-toward-efficient-autoregressive-vision-language-action-modeling-via-neural-action-tokenizationhttpsarxivorgabs251204952v1>#</a></h3><p><strong>Authors:</strong> Yicheng Liu, Shiduo Zhang, Zibin Dong, Baijun Ye, Tianyuan Yuan, Xiaopeng Yu, Linqi Yin, Chenhao Lu, Junhao Shi, Luca Jiang-Tao Yu, Liangtao Zheng, Tao Jiang, Jingjing Gong, Xipeng Qiu, Hang Zhao
<strong>Venue:</strong> arXiv (2025)</p><p>Autoregressive vision-language-action (VLA) models have recently demonstrated strong capabilities in robotic manipulation. However, their core process of action tokenization often involves a trade-off between reconstruction fidelity and inference efficiency. We introduce FASTer, a unified framework for efficient and generalizable robot learning that integrates a learnable tokenizer with an autoregressive policy built upon it. FASTerVQ encodes action chunks as single-channel images, capturing global spatio-temporal dependencies while maintaining a high compression ratio. FASTerVLA builds on this tokenizer with block-wise autoregressive decoding and a lightweight action expert, achieving both faster inference and higher task performance. Extensive experiments across simulated and real-world benchmarks show that FASTerVQ delivers superior reconstruction quality, high token utilization, and strong cross-task and cross-embodiment generalization, while FASTerVLA further improves overall capability, surpassing previous state-of-the-art VLA models in both inference speed and task performance.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04952v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04952v1">üìÑ Download PDF</a></p><hr><h3 id=carl-critical-action-focused-reinforcement-learning-for-multi-step-agenthttpsarxivorgabs251204949v1><a href=https://arxiv.org/abs/2512.04949v1>CARL: Critical Action Focused Reinforcement Learning for Multi-Step Agent</a><a hidden class=anchor aria-hidden=true href=#carl-critical-action-focused-reinforcement-learning-for-multi-step-agenthttpsarxivorgabs251204949v1>#</a></h3><p><strong>Authors:</strong> Leyang Shen, Yang Zhang, Chun Kai Ling, Xiaoyan Zhao, Tat-Seng Chua
<strong>Venue:</strong> arXiv (2025)</p><p>Agents capable of accomplishing complex tasks through multiple interactions with the environment have emerged as a popular research direction. However, in such multi-step settings, the conventional group-level policy optimization algorithm becomes suboptimal because of its underlying assumption that each action holds equal contribution, which deviates significantly from reality. Our analysis reveals that only a small fraction of actions are critical in determining the final outcome. Building on this insight, we propose CARL, a critical-action-focused reinforcement learning algorithm tailored for multi-step agents. CARL achieves focused training through providing action-level optimization signals for high-criticality actions while excluding low-criticality actions from model update. Extensive experiments demonstrate that CARL achieves both stronger performance and higher efficiency during training and inference across diverse evaluation settings.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04949v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04949v1">üìÑ Download PDF</a></p><hr><h3 id=growing-spines-ad-infinitum-et-ad-infinitesimaliahttpsarxivorgabs251204932v1><a href=https://arxiv.org/abs/2512.04932v1>Growing Spines: Ad Infinitum et Ad Infinitesimalia</a><a hidden class=anchor aria-hidden=true href=#growing-spines-ad-infinitum-et-ad-infinitesimaliahttpsarxivorgabs251204932v1>#</a></h3><p><strong>Authors:</strong> Blaise Boissonneau, Anna De Mase, Franziska Jahnke, Pierre Touchard
<strong>Venue:</strong> arXiv (2025)</p><p>We prove that for every ordered abelian group $G$ there exists a non-trivial ordered abelian group $H$ such that $G\preccurlyeq H\oplus G$ with the lexicographic order, and give a first-order characterization of ordered abelian group $G$ such that $G\preccurlyeq G\oplus H$ for some non-trivial $H$. We apply this to characterize which ordered abelian groups (respectively fields) ensure that any henselian valuation with said value group (respectively residue field) is definable in the language of rings. This answers a question of Krapp, Kuhlmann, and Link.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04932v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04932v1">üìÑ Download PDF</a></p><hr><h3 id=algorithmic-thinking-theoryhttpsarxivorgabs251204923v1><a href=https://arxiv.org/abs/2512.04923v1>Algorithmic Thinking Theory</a><a hidden class=anchor aria-hidden=true href=#algorithmic-thinking-theoryhttpsarxivorgabs251204923v1>#</a></h3><p><strong>Authors:</strong> MohammadHossein Bateni, Vincent Cohen-Addad, Yuzhou Gu, Silvio Lattanzi, Simon Meierhans, Christopher Mohri
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) have proven to be highly effective for solving complex reasoning tasks. Surprisingly, their capabilities can often be improved by iterating on previously generated solutions. In this context, a reasoning plan for generating and combining a set of solutions can be thought of as an algorithm for reasoning using a probabilistic oracle.
We introduce a theoretical framework for analyzing such reasoning algorithms. This framework formalizes the principles underlying popular techniques for iterative improvement and answer aggregation, providing a foundation for designing a new generation of more powerful reasoning methods. Unlike approaches for understanding models that rely on architectural specifics, our model is grounded in experimental evidence. As a result, it offers a general perspective that may extend to a wide range of current and future reasoning oracles.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04923v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04923v1">üìÑ Download PDF</a></p><hr><h3 id=the-ai-consumer-index-acehttpsarxivorgabs251204921v1><a href=https://arxiv.org/abs/2512.04921v1>The AI Consumer Index (ACE)</a><a hidden class=anchor aria-hidden=true href=#the-ai-consumer-index-acehttpsarxivorgabs251204921v1>#</a></h3><p><strong>Authors:</strong> Julien Benchek, Rohit Shetty, Benjamin Hunsberger, Ajay Arun, Zach Richards, Brendan Foody, Osvald Nitski, Bertie Vidgen
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce the first version of the AI Consumer Index (ACE), a benchmark for assessing whether frontier AI models can perform high-value consumer tasks. ACE contains a hidden heldout set of 400 test cases, split across four consumer activities: shopping, food, gaming, and DIY. We are also open sourcing 80 cases as a devset with a CC-BY license. For the ACE leaderboard we evaluated 10 frontier models (with websearch turned on) using a novel grading methodology that dynamically checks whether relevant parts of the response are grounded in the retrieved web sources. GPT 5 (Thinking = High) is the top-performing model, scoring 56.1%, followed by o3 Pro (Thinking = On) (55.2%) and GPT 5.1 (Thinking = High) (55.1%). Models differ across domains, and in Shopping the top model scores under 50%. For some requests (such as giving the correct price or providing working links), models are highly prone to hallucination. Overall, ACE shows a substantial gap between the performance of even the best models and consumers&rsquo; AI needs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04921v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04921v1">üìÑ Download PDF</a></p><hr><h3 id=existentially-defining-valuations-in-function-fields-over-large-fieldshttpsarxivorgabs251204896v1><a href=https://arxiv.org/abs/2512.04896v1>Existentially defining valuations in function fields over large fields</a><a hidden class=anchor aria-hidden=true href=#existentially-defining-valuations-in-function-fields-over-large-fieldshttpsarxivorgabs251204896v1>#</a></h3><p><strong>Authors:</strong> Nicolas Daans
<strong>Venue:</strong> arXiv (2025)</p><p>Let $K$ be a large field such that $K[\sqrt{-1}]$ is not algebraically closed and $F/K$ a function field in one variable. Extending techniques and results from earlier work with Becher and Dittmann, we show that every valuation ring on $F$ containing $K$ is existentially definable in the language of rings with parameters from $F$. As a consequence, using a known reduction technique, we obtain the undecidability of the existential theory of $F$ in the language of rings with appropriately chosen parameters.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04896v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04896v1">üìÑ Download PDF</a></p><hr><h3 id=chameleon-adaptive-adversarial-agents-for-scaling-based-visual-prompt-injection-in-multimodal-ai-systemshttpsarxivorgabs251204895v1><a href=https://arxiv.org/abs/2512.04895v1>Chameleon: Adaptive Adversarial Agents for Scaling-Based Visual Prompt Injection in Multimodal AI Systems</a><a hidden class=anchor aria-hidden=true href=#chameleon-adaptive-adversarial-agents-for-scaling-based-visual-prompt-injection-in-multimodal-ai-systemshttpsarxivorgabs251204895v1>#</a></h3><p><strong>Authors:</strong> M Zeeshan, Saud Satti
<strong>Venue:</strong> arXiv (2025)</p><p>Multimodal Artificial Intelligence (AI) systems, particularly Vision-Language Models (VLMs), have become integral to critical applications ranging from autonomous decision-making to automated document processing. As these systems scale, they rely heavily on preprocessing pipelines to handle diverse inputs efficiently. However, this dependency on standard preprocessing operations, specifically image downscaling, creates a significant yet often overlooked security vulnerability. While intended for computational optimization, scaling algorithms can be exploited to conceal malicious visual prompts that are invisible to human observers but become active semantic instructions once processed by the model. Current adversarial strategies remain largely static, failing to account for the dynamic nature of modern agentic workflows. To address this gap, we propose Chameleon, a novel, adaptive adversarial framework designed to expose and exploit scaling vulnerabilities in production VLMs. Unlike traditional static attacks, Chameleon employs an iterative, agent-based optimization mechanism that dynamically refines image perturbations based on the target model&rsquo;s real-time feedback. This allows the framework to craft highly robust adversarial examples that survive standard downscaling operations to hijack downstream execution. We evaluate Chameleon against Gemini 2.5 Flash model. Our experiments demonstrate that Chameleon achieves an Attack Success Rate (ASR) of 84.5% across varying scaling factors, significantly outperforming static baseline attacks which average only 32.1%. Furthermore, we show that these attacks effectively compromise agentic pipelines, reducing decision-making accuracy by over 45% in multi-step tasks. Finally, we discuss the implications of these vulnerabilities and propose multi-scale consistency checks as a necessary defense mechanism.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04895v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04895v1">üìÑ Download PDF</a></p><hr><h3 id=stella-guiding-large-language-models-for-time-series-forecasting-with-semantic-abstractionshttpsarxivorgabs251204871v1><a href=https://arxiv.org/abs/2512.04871v1>STELLA: Guiding Large Language Models for Time Series Forecasting with Semantic Abstractions</a><a hidden class=anchor aria-hidden=true href=#stella-guiding-large-language-models-for-time-series-forecasting-with-semantic-abstractionshttpsarxivorgabs251204871v1>#</a></h3><p><strong>Authors:</strong> Junjie Fan, Hongye Zhao, Linduo Wei, Jiayu Rao, Guijia Li, Jiaxin Yuan, Wenqi Xu, Yong Qi
<strong>Venue:</strong> arXiv (2025)</p><p>Recent adaptations of Large Language Models (LLMs) for time series forecasting often fail to effectively enhance information for raw series, leaving LLM reasoning capabilities underutilized. Existing prompting strategies rely on static correlations rather than generative interpretations of dynamic behavior, lacking critical global and instance-specific context. To address this, we propose STELLA (Semantic-Temporal Alignment with Language Abstractions), a framework that systematically mines and injects structured supplementary and complementary information. STELLA employs a dynamic semantic abstraction mechanism that decouples input series into trend, seasonality, and residual components. It then translates intrinsic behavioral features of these components into Hierarchical Semantic Anchors: a Corpus-level Semantic Prior (CSP) for global context and a Fine-grained Behavioral Prompt (FBP) for instance-level patterns. Using these anchors as prefix-prompts, STELLA guides the LLM to model intrinsic dynamics. Experiments on eight benchmark datasets demonstrate that STELLA outperforms state-of-the-art methods in long- and short-term forecasting, showing superior generalization in zero-shot and few-shot settings. Ablation studies further validate the effectiveness of our dynamically generated semantic anchors.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04871v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04871v1">üìÑ Download PDF</a></p><hr><h3 id=seal-self-evolving-agentic-learning-for-conversational-question-answering-over-knowledge-graphshttpsarxivorgabs251204868v1><a href=https://arxiv.org/abs/2512.04868v1>SEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs</a><a hidden class=anchor aria-hidden=true href=#seal-self-evolving-agentic-learning-for-conversational-question-answering-over-knowledge-graphshttpsarxivorgabs251204868v1>#</a></h3><p><strong>Authors:</strong> Hao Wang, Jialun Zhong, Changcheng Wang, Zhujun Nie, Zheng Li, Shunyu Yao, Yanzeng Li, Xinchi Li
<strong>Venue:</strong> arXiv (2025)</p><p>Knowledge-based conversational question answering (KBCQA) confronts persistent challenges in resolving coreference, modeling contextual dependencies, and executing complex logical reasoning. Existing approaches, whether end-to-end semantic parsing or stepwise agent-based reasoning, often suffer from structural inaccuracies and prohibitive computational costs, particularly when processing intricate queries over large knowledge graphs. To address these limitations, we introduce SEAL, a novel two-stage semantic parsing framework grounded in self-evolving agentic learning. In the first stage, a large language model (LLM) extracts a minimal S-expression core that captures the essential semantics of the input query. This core is then refined by an agentic calibration module, which corrects syntactic inconsistencies and aligns entities and relations precisely with the underlying knowledge graph. The second stage employs template-based completion, guided by question-type prediction and placeholder instantiation, to construct a fully executable S-expression. This decomposition not only simplifies logical form generation but also significantly enhances structural fidelity and linking efficiency. Crucially, SEAL incorporates a self-evolving mechanism that integrates local and global memory with a reflection module, enabling continuous adaptation from dialog history and execution feedback without explicit retraining. Extensive experiments on the SPICE benchmark demonstrate that SEAL achieves state-of-the-art performance, especially in multi-hop reasoning, comparison, and aggregation tasks. The results validate notable gains in both structural accuracy and computational efficiency, underscoring the framework&rsquo;s capacity for robust and scalable conversational reasoning.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04868v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04868v1">üìÑ Download PDF</a></p><hr><h3 id=are-your-agents-upward-deceivershttpsarxivorgabs251204864v1><a href=https://arxiv.org/abs/2512.04864v1>Are Your Agents Upward Deceivers?</a><a hidden class=anchor aria-hidden=true href=#are-your-agents-upward-deceivershttpsarxivorgabs251204864v1>#</a></h3><p><strong>Authors:</strong> Dadi Guo, Qingyu Liu, Dongrui Liu, Qihan Ren, Shuai Shao, Tianyi Qiu, Haoran Li, Yi R. Fung, Zhongjie Ba, Juntao Dai, Jiaming Ji, Zhikai Chen, Jialing Tao, Yaodong Yang, Jing Shao, Xia Hu
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Model (LLM)-based agents are increasingly used as autonomous subordinates that carry out tasks for users. This raises the question of whether they may also engage in deception, similar to how individuals in human organizations lie to superiors to create a good image or avoid punishment. We observe and define agentic upward deception, a phenomenon in which an agent facing environmental constraints conceals its failure and performs actions that were not requested without reporting. To assess its prevalence, we construct a benchmark of 200 tasks covering five task types and eight realistic scenarios in a constrained environment, such as broken tools or mismatched information sources. Evaluations of 11 popular LLMs reveal that these agents typically exhibit action-based deceptive behaviors, such as guessing results, performing unsupported simulations, substituting unavailable information sources, and fabricating local files. We further test prompt-based mitigation and find only limited reductions, suggesting that it is difficult to eliminate and highlighting the need for stronger mitigation strategies to ensure the safety of LLM-based agents.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04864v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04864v1">üìÑ Download PDF</a></p><hr><h3 id=ask-safely-privacy-aware-llm-query-generation-for-knowledge-graphshttpsarxivorgabs251204852v1><a href=https://arxiv.org/abs/2512.04852v1>Ask Safely: Privacy-Aware LLM Query Generation for Knowledge Graphs</a><a hidden class=anchor aria-hidden=true href=#ask-safely-privacy-aware-llm-query-generation-for-knowledge-graphshttpsarxivorgabs251204852v1>#</a></h3><p><strong>Authors:</strong> Mauro Dalle Lucca Tosi, Jordi Cabot
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Models (LLMs) are increasingly used to query knowledge graphs (KGs) due to their strong semantic understanding and extrapolation capabilities compared to traditional approaches. However, these methods cannot be applied when the KG contains sensitive data and the user lacks the resources to deploy a local generative LLM. To address this issue, we propose a privacy-aware query generation approach for KGs. Our method identifies sensitive information in the graph based on its structure and omits such values before requesting the LLM to translate natural language questions into Cypher queries. Experimental results show that our approach preserves the quality of the generated queries while preventing sensitive data from being transmitted to third-party services.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04852v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04852v1">üìÑ Download PDF</a></p><hr><h3 id=language-models-as-semantic-teachers-post-training-alignment-for-medical-audio-understandinghttpsarxivorgabs251204847v1><a href=https://arxiv.org/abs/2512.04847v1>Language Models as Semantic Teachers: Post-Training Alignment for Medical Audio Understanding</a><a hidden class=anchor aria-hidden=true href=#language-models-as-semantic-teachers-post-training-alignment-for-medical-audio-understandinghttpsarxivorgabs251204847v1>#</a></h3><p><strong>Authors:</strong> Tsai-Ning Wang, Lin-Lin Chen, Neil Zeghidour, Aaqib Saeed
<strong>Venue:</strong> arXiv (2025)</p><p>Pre-trained audio models excel at detecting acoustic patterns in auscultation sounds but often fail to grasp their clinical significance, limiting their use and performance in diagnostic tasks. To bridge this gap, we introduce AcuLa (Audio-Clinical Understanding via Language Alignment), a lightweight post-training framework that instills semantic understanding into any audio encoder by aligning it with a medical language model, which acts as a &ldquo;semantic teacher.&rdquo; To enable alignment at scale, we construct a large-scale dataset by leveraging off-the-shelf large language models to translate the rich, structured metadata accompanying existing audio recordings into coherent clinical reports. Our alignment strategy combines a representation-level contrastive objective with a self-supervised modeling, ensuring that the model learns clinical semantics while preserving fine-grained temporal cues. AcuLa achieves state-of-the-art results across 18 diverse cardio-respiratory tasks from 10 different datasets, improving the mean AUROC on classification benchmarks from 0.68 to 0.79 and, on the most challenging COVID-19 cough detection task, boosting the AUROC from 0.55 to 0.89. Our work demonstrates that this audio-language alignment transforms purely acoustic models into clinically-aware diagnostic tools, establishing a novel paradigm for enhancing physiological understanding in audio-based health monitoring.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04847v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04847v1">üìÑ Download PDF</a></p><hr><h3 id=sok-a-comprehensive-causality-analysis-framework-for-large-language-model-securityhttpsarxivorgabs251204841v1><a href=https://arxiv.org/abs/2512.04841v1>SoK: a Comprehensive Causality Analysis Framework for Large Language Model Security</a><a hidden class=anchor aria-hidden=true href=#sok-a-comprehensive-causality-analysis-framework-for-large-language-model-securityhttpsarxivorgabs251204841v1>#</a></h3><p><strong>Authors:</strong> Wei Zhao, Zhe Li, Jun Sun
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Models (LLMs) exhibit remarkable capabilities but remain vulnerable to adversarial manipulations such as jailbreaking, where crafted prompts bypass safety mechanisms. Understanding the causal factors behind such vulnerabilities is essential for building reliable defenses.
In this work, we introduce a unified causality analysis framework that systematically supports all levels of causal investigation in LLMs, ranging from token-level, neuron-level, and layer-level interventions to representation-level analysis. The framework enables consistent experimentation and comparison across diverse causality-based attack and defense methods. Accompanying this implementation, we provide the first comprehensive survey of causality-driven jailbreak studies and empirically evaluate the framework on multiple open-weight models and safety-critical benchmarks including jailbreaks, hallucination detection, backdoor identification, and fairness evaluation. Our results reveal that: (1) targeted interventions on causally critical components can reliably modify safety behavior; (2) safety-related mechanisms are highly localized (i.e., concentrated in early-to-middle layers with only 1&ndash;2% of neurons exhibiting causal influence); and (3) causal features extracted from our framework achieve over 95% detection accuracy across multiple threat types.
By bridging theoretical causality analysis and practical model safety, our framework establishes a reproducible foundation for research on causality-based attacks, interpretability, and robust attack detection and mitigation in LLMs. Code is available at <a href=https://github.com/Amadeuszhao/SOK_Casuality>https://github.com/Amadeuszhao/SOK_Casuality</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04841v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04841v1">üìÑ Download PDF</a></p><hr><h3 id=damasha-detecting-ai-in-mixed-adversarial-texts-via-segmentation-with-human-interpretable-attributionhttpsarxivorgabs251204838v1><a href=https://arxiv.org/abs/2512.04838v1>DAMASHA: Detecting AI in Mixed Adversarial Texts via Segmentation with Human-interpretable Attribution</a><a hidden class=anchor aria-hidden=true href=#damasha-detecting-ai-in-mixed-adversarial-texts-via-segmentation-with-human-interpretable-attributionhttpsarxivorgabs251204838v1>#</a></h3><p><strong>Authors:</strong> L. D. M. S. Sai Teja, N. Siva Gopala Krishna, Ufaq Khan, Muhammad Haris Khan, Partha Pakray, Atul Mishra
<strong>Venue:</strong> arXiv (2025)</p><p>In the age of advanced large language models (LLMs), the boundaries between human and AI-generated text are becoming increasingly blurred. We address the challenge of segmenting mixed-authorship text, that is identifying transition points in text where authorship shifts from human to AI or vice-versa, a problem with critical implications for authenticity, trust, and human oversight. We introduce a novel framework, called Info-Mask for mixed authorship detection that integrates stylometric cues, perplexity-driven signals, and structured boundary modeling to accurately segment collaborative human-AI content. To evaluate the robustness of our system against adversarial perturbations, we construct and release an adversarial benchmark dataset Mixed-text Adversarial setting for Segmentation (MAS), designed to probe the limits of existing detectors. Beyond segmentation accuracy, we introduce Human-Interpretable Attribution (HIA overlays that highlight how stylometric features inform boundary predictions, and we conduct a small-scale human study assessing their usefulness. Across multiple architectures, Info-Mask significantly improves span-level robustness under adversarial conditions, establishing new baselines while revealing remaining challenges. Our findings highlight both the promise and limitations of adversarially robust, interpretable mixed-authorship detection, with implications for trust and oversight in human-AI co-authorship.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04838v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04838v1">üìÑ Download PDF</a></p><hr><h3 id=dala-danish-linguistic-acceptability-evaluation-guided-by-real-world-errorshttpsarxivorgabs251204799v1><a href=https://arxiv.org/abs/2512.04799v1>DaLA: Danish Linguistic Acceptability Evaluation Guided by Real World Errors</a><a hidden class=anchor aria-hidden=true href=#dala-danish-linguistic-acceptability-evaluation-guided-by-real-world-errorshttpsarxivorgabs251204799v1>#</a></h3><p><strong>Authors:</strong> Gianluca Barmina, Nathalie Carmen Hau Norman, Peter Schneider-Kamp, Lukas Galke
<strong>Venue:</strong> arXiv (2025)</p><p>We present an enhanced benchmark for evaluating linguistic acceptability in Danish. We first analyze the most common errors found in written Danish. Based on this analysis, we introduce a set of fourteen corruption functions that generate incorrect sentences by systematically introducing errors into existing correct Danish sentences. To ensure the accuracy of these corruptions, we assess their validity using both manual and automatic methods. The results are then used as a benchmark for evaluating Large Language Models on a linguistic acceptability judgement task. Our findings demonstrate that this extension is both broader and more comprehensive than the current state of the art. By incorporating a greater variety of corruption types, our benchmark provides a more rigorous assessment of linguistic acceptability, increasing task difficulty, as evidenced by the lower performance of LLMs on our benchmark compared to existing ones. Our results also suggest that our benchmark has a higher discriminatory power which allows to better distinguish well-performing models from low-performing ones.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04799v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04799v1">üìÑ Download PDF</a></p><hr><h3 id=sima-2-a-generalist-embodied-agent-for-virtual-worldshttpsarxivorgabs251204797v1><a href=https://arxiv.org/abs/2512.04797v1>SIMA 2: A Generalist Embodied Agent for Virtual Worlds</a><a hidden class=anchor aria-hidden=true href=#sima-2-a-generalist-embodied-agent-for-virtual-worldshttpsarxivorgabs251204797v1>#</a></h3><p><strong>Authors:</strong> SIMA team, Adrian Bolton, Alexander Lerchner, Alexandra Cordell, Alexandre Moufarek, Andrew Bolt, Andrew Lampinen, Anna Mitenkova, Arne Olav Hallingstad, Bojan Vujatovic, Bonnie Li, Cong Lu, Daan Wierstra, Daniel P. Sawyer, Daniel Slater, David Reichert, Davide Vercelli, Demis Hassabis, Drew A. Hudson, Duncan Williams, Ed Hirst, Fabio Pardo, Felix Hill, Frederic Besse, Hannah Openshaw, Harris Chan, Hubert Soyer, Jane X. Wang, Jeff Clune, John Agapiou, John Reid, Joseph Marino, Junkyung Kim, Karol Gregor, Kaustubh Sridhar, Kay McKinney, Laura Kampis, Lei M. Zhang, Loic Matthey, Luyu Wang, Maria Abi Raad, Maria Loks-Thompson, Martin Engelcke, Matija Kecman, Matthew Jackson, Maxime Gazeau, Ollie Purkiss, Oscar Knagg, Peter Stys, Piermaria Mendolicchio, Raia Hadsell, Rosemary Ke, Ryan Faulkner, Sarah Chakera, Satinder Singh Baveja, Shane Legg, Sheleem Kashem, Tayfun Terzi, Thomas Keck, Tim Harley, Tim Scholtes, Tyson Roberts, Volodymyr Mnih, Yulan Liu, Zhengdong Wang, Zoubin Ghahramani
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce SIMA 2, a generalist embodied agent that understands and acts in a wide variety of 3D virtual worlds. Built upon a Gemini foundation model, SIMA 2 represents a significant step toward active, goal-directed interaction within an embodied environment. Unlike prior work (e.g., SIMA 1) limited to simple language commands, SIMA 2 acts as an interactive partner, capable of reasoning about high-level goals, conversing with the user, and handling complex instructions given through language and images. Across a diverse portfolio of games, SIMA 2 substantially closes the gap with human performance and demonstrates robust generalization to previously unseen environments, all while retaining the base model&rsquo;s core reasoning capabilities. Furthermore, we demonstrate a capacity for open-ended self-improvement: by leveraging Gemini to generate tasks and provide rewards, SIMA 2 can autonomously learn new skills from scratch in a new environment. This work validates a path toward creating versatile and continuously learning agents for both virtual and, eventually, physical worlds.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04797v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04797v1">üìÑ Download PDF</a></p><hr><h3 id=spatially-enhanced-retrieval-augmented-generation-for-walkability-and-urban-discoveryhttpsarxivorgabs251204790v1><a href=https://arxiv.org/abs/2512.04790v1>Spatially-Enhanced Retrieval-Augmented Generation for Walkability and Urban Discovery</a><a hidden class=anchor aria-hidden=true href=#spatially-enhanced-retrieval-augmented-generation-for-walkability-and-urban-discoveryhttpsarxivorgabs251204790v1>#</a></h3><p><strong>Authors:</strong> Maddalena Amendola, Chiara Pugliese, Raffaele Perego, Chiara Renso
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Models (LLMs) have become foundational tools in artificial intelligence, supporting a wide range of applications beyond traditional natural language processing, including urban systems and tourist recommendations. However, their tendency to hallucinate and their limitations in spatial retrieval and reasoning are well known, pointing to the need for novel solutions. Retrieval-augmented generation (RAG) has recently emerged as a promising way to enhance LLMs with accurate, domain-specific, and timely information. Spatial RAG extends this approach to tasks involving geographic understanding. In this work, we introduce WalkRAG, a spatial RAG-based framework with a conversational interface for recommending walkable urban itineraries. Users can request routes that meet specific spatial constraints and preferences while interactively retrieving information about the path and points of interest (POIs) along the way. Preliminary results show the effectiveness of combining information retrieval, spatial reasoning, and LLMs to support urban discovery.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04790v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04790v1">üìÑ Download PDF</a></p><hr><h3 id=astride-a-security-threat-modeling-platform-for-agentic-ai-applicationshttpsarxivorgabs251204785v1><a href=https://arxiv.org/abs/2512.04785v1>ASTRIDE: A Security Threat Modeling Platform for Agentic-AI Applications</a><a hidden class=anchor aria-hidden=true href=#astride-a-security-threat-modeling-platform-for-agentic-ai-applicationshttpsarxivorgabs251204785v1>#</a></h3><p><strong>Authors:</strong> Eranga Bandara, Amin Hass, Ross Gore, Sachin Shetty, Ravi Mukkamala, Safdar H. Bouk, Xueping Liang, Ng Wee Keong, Kasun De Zoysa, Aruna Withanage, Nilaan Loganathan
<strong>Venue:</strong> arXiv (2025)</p><p>AI agent-based systems are becoming increasingly integral to modern software architectures, enabling autonomous decision-making, dynamic task execution, and multimodal interactions through large language models (LLMs). However, these systems introduce novel and evolving security challenges, including prompt injection attacks, context poisoning, model manipulation, and opaque agent-to-agent communication, that are not effectively captured by traditional threat modeling frameworks. In this paper, we introduce ASTRIDE, an automated threat modeling platform purpose-built for AI agent-based systems. ASTRIDE extends the classical STRIDE framework by introducing a new threat category, A for AI Agent-Specific Attacks, which encompasses emerging vulnerabilities such as prompt injection, unsafe tool invocation, and reasoning subversion, unique to agent-based applications. To automate threat modeling, ASTRIDE combines a consortium of fine-tuned vision-language models (VLMs) with the OpenAI-gpt-oss reasoning LLM to perform end-to-end analysis directly from visual agent architecture diagrams, such as data flow diagrams(DFDs). LLM agents orchestrate the end-to-end threat modeling automation process by coordinating interactions between the VLM consortium and the reasoning LLM. Our evaluations demonstrate that ASTRIDE provides accurate, scalable, and explainable threat modeling for next-generation intelligent systems. To the best of our knowledge, ASTRIDE is the first framework to both extend STRIDE with AI-specific threats and integrate fine-tuned VLMs with a reasoning LLM to fully automate diagram-driven threat modeling in AI agent-based applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04785v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04785v1">üìÑ Download PDF</a></p><hr><h3 id=memlora-distilling-expert-adapters-for-on-device-memory-systemshttpsarxivorgabs251204763v1><a href=https://arxiv.org/abs/2512.04763v1>MemLoRA: Distilling Expert Adapters for On-Device Memory Systems</a><a hidden class=anchor aria-hidden=true href=#memlora-distilling-expert-adapters-for-on-device-memory-systemshttpsarxivorgabs251204763v1>#</a></h3><p><strong>Authors:</strong> Massimo Bini, Ondrej Bohdal, Umberto Michieli, Zeynep Akata, Mete Ozay, Taha Ceritli
<strong>Venue:</strong> arXiv (2025)</p><p>Memory-augmented Large Language Models (LLMs) have demonstrated remarkable consistency during prolonged dialogues by storing relevant memories and incorporating them as context. Such memory-based personalization is also key in on-device settings that allow users to keep their conversations and data private. However, memory-augmented systems typically rely on LLMs that are too costly for local on-device deployment. Even though Small Language Models (SLMs) are more suitable for on-device inference than LLMs, they cannot achieve sufficient performance. Additionally, these LLM-based systems lack native visual capabilities, limiting their applicability in multimodal contexts. In this paper, we introduce (i) MemLoRA, a novel memory system that enables local deployment by equipping SLMs with specialized memory adapters, and (ii) its vision extension MemLoRA-V, which integrates small Vision-Language Models (SVLMs) to memory systems, enabling native visual understanding. Following knowledge distillation principles, each adapter is trained separately for specific memory operations$\unicode{x2013}$knowledge extraction, memory update, and memory-augmented generation. Equipped with memory adapters, small models enable accurate on-device memory operations without cloud dependency. On text-only operations, MemLoRA outperforms 10$\times$ larger baseline models (e.g., Gemma2-27B) and achieves performance comparable to 60$\times$ larger models (e.g., GPT-OSS-120B) on the LoCoMo benchmark. To evaluate visual understanding operations instead, we extend LoCoMo with challenging Visual Question Answering tasks that require direct visual reasoning. On this, our VLM-integrated MemLoRA-V shows massive improvements over caption-based approaches (81.3 vs. 23.7 accuracy) while keeping strong performance in text-based tasks, demonstrating the efficacy of our method in multimodal contexts.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04763v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04763v1">üìÑ Download PDF</a></p><hr><h3 id=challenging-the-abilities-of-large-language-models-in-italian-a-community-initiativehttpsarxivorgabs251204759v1><a href=https://arxiv.org/abs/2512.04759v1>Challenging the Abilities of Large Language Models in Italian: a Community Initiative</a><a hidden class=anchor aria-hidden=true href=#challenging-the-abilities-of-large-language-models-in-italian-a-community-initiativehttpsarxivorgabs251204759v1>#</a></h3><p><strong>Authors:</strong> Malvina Nissim, Danilo Croce, Viviana Patti, Pierpaolo Basile, Giuseppe Attanasio, Elio Musacchio, Matteo Rinaldi, Federico Borazio, Maria Francis, Jacopo Gili, Daniel Scalena, Bego√±a Altuna, Ekhi Azurmendi, Valerio Basile, Luisa Bentivogli, Arianna Bisazza, Marianna Bolognesi, Dominique Brunato, Tommaso Caselli, Silvia Casola, Maria Cassese, Mauro Cettolo, Claudia Collacciani, Leonardo De Cosmo, Maria Pia Di Buono, Andrea Esuli, Julen Etxaniz, Chiara Ferrando, Alessia Fidelangeli, Simona Frenda, Achille Fusco, Marco Gaido, Andrea Galassi, Federico Galli, Luca Giordano, Mattia Goffetti, Itziar Gonzalez-Dios, Lorenzo Gregori, Giulia Grundler, Sandro Iannaccone, Chunyang Jiang, Moreno La Quatra, Francesca Lagioia, Soda Marem Lo, Marco Madeddu, Bernardo Magnini, Raffaele Manna, Fabio Mercorio, Paola Merlo, Arianna Muti, Vivi Nastase, Matteo Negri, Dario Onorati, Elena Palmieri, Sara Papi, Lucia Passaro, Giulia Pensa, Andrea Piergentili, Daniele Potert√¨, Giovanni Puccetti, Federico Ranaldi, Leonardo Ranaldi, Andrea Amelio Ravelli, Martina Rosola, Elena Sofia Ruzzetti, Giuseppe Samo, Andrea Santilli, Piera Santin, Gabriele Sarti, Giovanni Sartor, Beatrice Savoldi, Antonio Serino, Andrea Seveso, Lucia Siciliani, Paolo Torroni, Rossella Varvara, Andrea Zaninello, Asya Zanollo, Fabio Massimo Zanzotto, Kamyar Zeinalipour, Andrea Zugarini
<strong>Venue:</strong> arXiv (2025)</p><p>The rapid progress of Large Language Models (LLMs) has transformed natural language processing and broadened its impact across research and society. Yet, systematic evaluation of these models, especially for languages beyond English, remains limited. &ldquo;Challenging the Abilities of LAnguage Models in ITAlian&rdquo; (CALAMITA) is a large-scale collaborative benchmarking initiative for Italian, coordinated under the Italian Association for Computational Linguistics. Unlike existing efforts that focus on leaderboards, CALAMITA foregrounds methodology: it federates more than 80 contributors from academia, industry, and the public sector to design, document, and evaluate a diverse collection of tasks, covering linguistic competence, commonsense reasoning, factual consistency, fairness, summarization, translation, and code generation. Through this process, we not only assembled a benchmark of over 20 tasks and almost 100 subtasks, but also established a centralized evaluation pipeline that supports heterogeneous datasets and metrics. We report results for four open-weight LLMs, highlighting systematic strengths and weaknesses across abilities, as well as challenges in task-specific evaluation. Beyond quantitative results, CALAMITA exposes methodological lessons: the necessity of fine-grained, task-representative metrics, the importance of harmonized pipelines, and the benefits and limitations of broad community engagement. CALAMITA is conceived as a rolling benchmark, enabling continuous integration of new tasks and models. This makes it both a resource &ndash; the most comprehensive and diverse benchmark for Italian to date &ndash; and a framework for sustainable, community-driven evaluation. We argue that this combination offers a blueprint for other languages and communities seeking inclusive and rigorous LLM evaluation practices.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04759v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04759v1">üìÑ Download PDF</a></p><hr><h3 id=typing-fallback-functions-a-semantic-approach-to-type-safe-smart-contractshttpsarxivorgabs251204755v1><a href=https://arxiv.org/abs/2512.04755v1>Typing Fallback Functions: A Semantic Approach to Type Safe Smart Contracts</a><a hidden class=anchor aria-hidden=true href=#typing-fallback-functions-a-semantic-approach-to-type-safe-smart-contractshttpsarxivorgabs251204755v1>#</a></h3><p><strong>Authors:</strong> Stian Lybech, Daniele Gorla, Luca Aceto
<strong>Venue:</strong> arXiv (2025)</p><p>This paper develops semantic typing in a smart-contract setting to ensure type safety of code that uses statically untypable language constructs, such as the fallback function. The idea is that the creator of a contract on the blockchain equips code containing such constructs with a formal proof of its type safety, given in terms of the semantics of types. Then, a user of the contract only needs to check the validity of the provided `proof certificate&rsquo; of type safety. This is a form of proof-carrying code, which naturally fits with the immutable nature of the blockchain environment.
As a concrete application of our approach, we focus on ensuring information flow control and non-interference for the language TINYSOL, a distilled version of the Solidity language, through security types. We provide the semantics of types in terms of a typed operational semantics of TINYSOL, and a way for expressing the proofs of safety as coinductively-defined typing interpretations and for representing them compactly via up-to techniques, similar to those used for bisimilarity. We also show how our machinery can be used to type the typical pointer-to-implementation pattern based on the fallback function. However, our main contribution is not the safety theorem per se (and so security properties different from non-interference can be considered as well), but rather the presentation of the theoretical developments necessary to make this approach work in a blockchain/smart-contract setting.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04755v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04755v1">üìÑ Download PDF</a></p><hr><h3 id=etcon-edit-then-consolidate-for-reliable-knowledge-editinghttpsarxivorgabs251204753v1><a href=https://arxiv.org/abs/2512.04753v1>EtCon: Edit-then-Consolidate for Reliable Knowledge Editing</a><a hidden class=anchor aria-hidden=true href=#etcon-edit-then-consolidate-for-reliable-knowledge-editinghttpsarxivorgabs251204753v1>#</a></h3><p><strong>Authors:</strong> Ruilin Li, Yibin Wang, Wenhong Zhu, Chenglin Li, Jinghao Zhang, Chenliang Li, Junchi Yan, Jiaqi Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Knowledge editing aims to update specific facts in large language models (LLMs) without full retraining. Prior efforts sought to tune the knowledge layers of LLMs, proving effective for making selective edits. However, a significant gap exists between their performance in controlled, teacher-forcing evaluations and their real-world effectiveness in lifelong learning scenarios, which greatly limits their practical applicability. This work&rsquo;s empirical analysis reveals two recurring issues associated with this gap: (1) Most traditional methods lead the edited model to overfit to the new fact, thereby degrading pre-trained capabilities; (2) There is a critical absence of a knowledge consolidation stage, leaving new facts insufficiently integrated into LLMs&rsquo; inference-time behavior under autoregressive generation, thereby leading to a mismatch between parametric knowledge and actual generation behavior. To this end, we propose Edit-then-Consolidate, a novel knowledge editing paradigm that aims to bridge the gap between theoretical knowledge editing methods and their real-world applicability. Specifically, (1) our framework mitigates overfitting via Targeted Proximal Supervised Fine-Tuning (TPSFT) that localizes the edit via a trust-region objective to limit policy drift; (2) Then, a consolidation stage using Group Relative Policy Optimization (GRPO) aligns the edited knowledge with CoT-based inference policy by optimizing trajectory-level behavior under comprehensive reward signals. Extensive experiments demonstrate our framework consistently improves editing reliability and generalization under real-world evaluations, while better preserving locality and pre-trained capabilities.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04753v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04753v1">üìÑ Download PDF</a></p><hr><h3 id=rlhfspec-breaking-the-efficiency-bottleneck-in-rlhf-training-via-adaptive-draftinghttpsarxivorgabs251204752v1><a href=https://arxiv.org/abs/2512.04752v1>RLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting</a><a hidden class=anchor aria-hidden=true href=#rlhfspec-breaking-the-efficiency-bottleneck-in-rlhf-training-via-adaptive-draftinghttpsarxivorgabs251204752v1>#</a></h3><p><strong>Authors:</strong> Siqi Wang, Hailong Yang, Junjie Zhu, Xuezhu Wang, Yufan Xu, Depei Qian
<strong>Venue:</strong> arXiv (2025)</p><p>Reinforcement Learning from Human Feedback (RLHF) is an important fine-tuning technique for large language models (LLMs) and comprises three stages: generation, inference, and training. The generation stage generates samples that are then used to infer learnable experiences for training. We observe that the generation stage is the bottleneck of the entire execution process and consider it a key point for optimization. Specifically, we realize the first attempt to integrate speculative decoding into the RLHF generation stage and propose RLHFSpec, an RLHF system that accelerates generation execution with adaptive speculative decoding and sample reallocation. To fully exploit the performance potential provided by speculative decoding, especially dealing with the dynamic workload of the generation stage, RLHFSpec proposes a workload-aware drafting strategy selection mechanism, which selects the near-optimal strategy by jointly considering the verification cost and the number of accepted tokens. Moreover, RLHFSpec also proposes sample reallocation to fully utilize the GPU resources, and optimizes it with an efficient sample migration mechanism. The experimental results show that the RLHFSpec can achieve higher throughput in the generation stage compared to state-of-the-art works. Moreover, due to the effective alleviation of the generation bottleneck, RLHFSpec also shows significant performance speedup in the entire RLHF execution.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04752v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04752v1">üìÑ Download PDF</a></p><hr><h3 id=model-whisper-steering-vectors-unlock-large-language-models-potential-in-test-timehttpsarxivorgabs251204748v1><a href=https://arxiv.org/abs/2512.04748v1>Model Whisper: Steering Vectors Unlock Large Language Models&rsquo; Potential in Test-time</a><a hidden class=anchor aria-hidden=true href=#model-whisper-steering-vectors-unlock-large-language-models-potential-in-test-timehttpsarxivorgabs251204748v1>#</a></h3><p><strong>Authors:</strong> Xinyue Kang, Diwei Shi, Li Chen
<strong>Venue:</strong> arXiv (2025)</p><p>It is a critical challenge to efficiently unlock the powerful reasoning potential of Large Language Models (LLMs) for specific tasks or new distributions. Existing test-time adaptation methods often require tuning model parameters, which is not only computationally expensive but also risks degrading the model&rsquo;s pre-existing abilities.To address this, we introduce a lightweight component, Test-Time Steering Vectors (TTSV), which is prepended to the input while keeping the LLM&rsquo;s parameters entirely frozen. By optimizing the TTSV on test data to minimize the model&rsquo;s output entropy, we steer the model towards an internal state of higher confidence, activating its inherent abilities most relevant to the current task. TTSV is both lightweight and highly efficient to optimize, making it a true plug-and-play enhancement. Extensive experiments validate our approach&rsquo;s effectiveness on both base models and reasoning-enhanced models. For instance, on the MATH500 task, TTSV achieves a 45.88% relative performance gain on the Qwen2.5-Math-7B model and a 16.22% relative gain on the Qwen3-4B model. Furthermore, our approach exhibits robust generalization, with its steering vectors proving highly transferable across diverse tasks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04748v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04748v1">üìÑ Download PDF</a></p><hr><h3 id=signroundv2-closing-the-performance-gap-in-extremely-low-bit-post-training-quantization-for-llmshttpsarxivorgabs251204746v1><a href=https://arxiv.org/abs/2512.04746v1>SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs</a><a hidden class=anchor aria-hidden=true href=#signroundv2-closing-the-performance-gap-in-extremely-low-bit-post-training-quantization-for-llmshttpsarxivorgabs251204746v1>#</a></h3><p><strong>Authors:</strong> Wenhua Cheng, Weiwei Zhang, Heng Guo, Haihao Shen
<strong>Venue:</strong> arXiv (2025)</p><p>Extreme low-bit quantization is critical for efficiently deploying Large Language Models (LLMs), yet it often leads to severe performance degradation at 2-bits and even 4-bits (e.g., MXFP4). We present SignRoundV2, a post-training quantization framework that is highly effective even without mixed-precision. SignRoundV2 introduces (1) a fast sensitivity metric that combines gradient information with quantization-induced deviations to guide layer-wise bit allocation, and (2) a lightweight pre-tuning search for quantization scales to improve extremely low-bit quantization. These components allow SignRoundV2 to close the gap with full-precision models. Extensive experiments indicate that our method sustains competitive accuracy for LLMs, achieving production-grade performance with about 1 percent variance at 4-5 bits and strong results even at 2 bits. The implementation is available at <a href=https://github.com/intel/auto-round>https://github.com/intel/auto-round</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04746v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04746v1">üìÑ Download PDF</a></p><hr><h3 id=osmt-bridging-openstreetmap-queries-and-natural-language-with-open-source-tag-aware-language-modelshttpsarxivorgabs251204738v1><a href=https://arxiv.org/abs/2512.04738v1>OsmT: Bridging OpenStreetMap Queries and Natural Language with Open-source Tag-aware Language Models</a><a hidden class=anchor aria-hidden=true href=#osmt-bridging-openstreetmap-queries-and-natural-language-with-open-source-tag-aware-language-modelshttpsarxivorgabs251204738v1>#</a></h3><p><strong>Authors:</strong> Zhuoyue Wan, Wentao Hu, Chen Jason Zhang, Yuanfeng Song, Shuaimin Li, Ruiqiang Xiao, Xiao-Yong Wei, Raymond Chi-Wing Wong
<strong>Venue:</strong> arXiv (2025)</p><p>Bridging natural language and structured query languages is a long-standing challenge in the database community. While recent advances in language models have shown promise in this direction, existing solutions often rely on large-scale closed-source models that suffer from high inference costs, limited transparency, and lack of adaptability for lightweight deployment. In this paper, we present OsmT, an open-source tag-aware language model specifically designed to bridge natural language and Overpass Query Language (OverpassQL), a structured query language for accessing large-scale OpenStreetMap (OSM) data. To enhance the accuracy and structural validity of generated queries, we introduce a Tag Retrieval Augmentation (TRA) mechanism that incorporates contextually relevant tag knowledge into the generation process. This mechanism is designed to capture the hierarchical and relational dependencies present in the OSM database, addressing the topological complexity inherent in geospatial query formulation. In addition, we define a reverse task, OverpassQL-to-Text, which translates structured queries into natural language explanations to support query interpretation and improve user accessibility. We evaluate OsmT on a public benchmark against strong baselines and observe consistent improvements in both query generation and interpretation. Despite using significantly fewer parameters, our model achieves competitive accuracy, demonstrating the effectiveness of open-source pre-trained language models in bridging natural language and structured query languages within schema-rich geospatial environments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04738v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04738v1">üìÑ Download PDF</a></p><hr><h3 id=e3ad-an-emotion-aware-vision-language-action-model-for-human-centric-end-to-end-autonomous-drivinghttpsarxivorgabs251204733v1><a href=https://arxiv.org/abs/2512.04733v1>E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving</a><a hidden class=anchor aria-hidden=true href=#e3ad-an-emotion-aware-vision-language-action-model-for-human-centric-end-to-end-autonomous-drivinghttpsarxivorgabs251204733v1>#</a></h3><p><strong>Authors:</strong> Yihong Tang, Haicheng Liao, Tong Nie, Junlin He, Ao Qu, Kehua Chen, Wei Ma, Zhenning Li, Lijun Sun, Chengzhong Xu
<strong>Venue:</strong> arXiv (2025)</p><p>End-to-end autonomous driving (AD) systems increasingly adopt vision-language-action (VLA) models, yet they typically ignore the passenger&rsquo;s emotional state, which is central to comfort and AD acceptance. We introduce Open-Domain End-to-End (OD-E2E) autonomous driving, where an autonomous vehicle (AV) must interpret free-form natural-language commands, infer the emotion, and plan a physically feasible trajectory. We propose E3AD, an emotion-aware VLA framework that augments semantic understanding with two cognitively inspired components: a continuous Valenc-Arousal-Dominance (VAD) emotion model that captures tone and urgency from language, and a dual-pathway spatial reasoning module that fuses egocentric and allocentric views for human-like spatial cognition. A consistency-oriented training scheme, combining modality pretraining with preference-based alignment, further enforces coherence between emotional intent and driving actions. Across real-world datasets, E3AD improves visual grounding and waypoint planning and achieves state-of-the-art (SOTA) VAD correlation for emotion estimation. These results show that injecting emotion into VLA-style driving yields more human-aligned grounding, planning, and human-centric feedback.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04733v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04733v1">üìÑ Download PDF</a></p><hr><h3 id=the-universal-weight-subspace-hypothesishttpsarxivorgabs251205117v1><a href=https://arxiv.org/abs/2512.05117v1>The Universal Weight Subspace Hypothesis</a><a hidden class=anchor aria-hidden=true href=#the-universal-weight-subspace-hypothesishttpsarxivorgabs251205117v1>#</a></h3><p><strong>Authors:</strong> Prakhar Kaushik, Shravan Chaudhari, Ankit Vaidya, Rama Chellappa, Alan Yuille
<strong>Venue:</strong> arXiv (2025)</p><p>We show that deep neural networks trained across diverse tasks exhibit remarkably similar low-dimensional parametric subspaces. We provide the first large-scale empirical evidence that demonstrates that neural networks systematically converge to shared spectral subspaces regardless of initialization, task, or domain. Through mode-wise spectral analysis of over 1100 models - including 500 Mistral-7B LoRAs, 500 Vision Transformers, and 50 LLaMA-8B models - we identify universal subspaces capturing majority variance in just a few principal directions. By applying spectral decomposition techniques to the weight matrices of various architectures trained on a wide range of tasks and datasets, we identify sparse, joint subspaces that are consistently exploited, within shared architectures across diverse tasks and datasets. Our findings offer new insights into the intrinsic organization of information within deep networks and raise important questions about the possibility of discovering these universal subspaces without the need for extensive data and computational resources. Furthermore, this inherent structure has significant implications for model reusability, multi-task learning, model merging, and the development of training and inference-efficient algorithms, potentially reducing the carbon footprint of large-scale neural models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05117v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05117v1">üìÑ Download PDF</a></p><hr><h3 id=sdg-track-a-heterogeneous-observer-follower-framework-for-high-resolution-uav-tracking-on-embedded-platformshttpsarxivorgabs251204883v1><a href=https://arxiv.org/abs/2512.04883v1>SDG-Track: A Heterogeneous Observer-Follower Framework for High-Resolution UAV Tracking on Embedded Platforms</a><a hidden class=anchor aria-hidden=true href=#sdg-track-a-heterogeneous-observer-follower-framework-for-high-resolution-uav-tracking-on-embedded-platformshttpsarxivorgabs251204883v1>#</a></h3><p><strong>Authors:</strong> Jiawen Wen, Yu Hu, Suixuan Qiu, Jinshan Huang, Xiaowen Chu
<strong>Venue:</strong> arXiv (2025)</p><p>Real-time tracking of small unmanned aerial vehicles (UAVs) on edge devices faces a fundamental resolution-speed conflict. Downsampling high-resolution imagery to standard detector input sizes causes small target features to collapse below detectable thresholds. Yet processing native 1080p frames on resource-constrained platforms yields insufficient throughput for smooth gimbal control. We propose SDG-Track, a Sparse Detection-Guided Tracker that adopts an Observer-Follower architecture to reconcile this conflict. The Observer stream runs a high-capacity detector at low frequency on the GPU to provide accurate position anchors from 1920x1080 frames. The Follower stream performs high-frequency trajectory interpolation via ROI-constrained sparse optical flow on the CPU. To handle tracking failures from occlusion or model drift caused by spectrally similar distractors, we introduce Dual-Space Recovery, a training-free re-acquisition mechanism combining color histogram matching with geometric consistency constraints. Experiments on a ground-to-air tracking station demonstrate that SDG-Track achieves 35.1 FPS system throughput while retaining 97.2% of the frame-by-frame detection precision. The system successfully tracks agile FPV drones under real-world operational conditions on an NVIDIA Jetson Orin Nano. Our paper code is publicly available at <a href=https://github.com/Jeffry-wen/SDG-Track>https://github.com/Jeffry-wen/SDG-Track</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04883v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04883v1">üìÑ Download PDF</a></p><hr><h3 id=a-novel-trust-based-ddos-cyberattack-detection-model-for-smart-business-environmentshttpsarxivorgabs251204855v1><a href=https://arxiv.org/abs/2512.04855v1>A Novel Trust-Based DDoS Cyberattack Detection Model for Smart Business Environments</a><a hidden class=anchor aria-hidden=true href=#a-novel-trust-based-ddos-cyberattack-detection-model-for-smart-business-environmentshttpsarxivorgabs251204855v1>#</a></h3><p><strong>Authors:</strong> Oghenetejiri Okporokpo, Funminiyi Olajide, Nemitari Ajienka, Xiaoqi Ma
<strong>Venue:</strong> arXiv (2025)</p><p>As the frequency and complexity of Distributed Denial-of-Service (DDoS) attacks continue to increase, the level of threats posed to Smart Internet of Things (SIoT) business environments have also increased. These environments generally have several interconnected SIoT systems and devices that are integral to daily operations, usually depending on cloud infrastructure and real-time data analytics, which require continuous availability and secure data exchange. Conventional detection mechanisms, while useful in static or traditional network environments, often are inadequate in responding to the needs of these dynamic and diverse SIoT networks. In this paper, we introduce a novel trust-based DDoS detection model tailored to meet the unique requirements of smart business environments. The proposed model incorporates a trust evaluation engine that continuously monitors node behaviour, calculating trust scores based on packet delivery ratio, response time, and anomaly detection. These trust metrics are then aggregated by a central trust-based repository that uses inherent trust values to identify traffic patterns indicative of DDoS attacks. By integrating both trust scores and central trust-based outputs, the trust calculation is enhanced, ensuring that threats are accurately identified and addressed in real-time. The model demonstrated a significant improvement in detection accuracy, and a low false-positive rate with enhanced scalability and adaptability under TCP SYN, Ping Flood, and UDP Flood attacks. The results show that a trust-based approach provides an effective, lightweight alternative for securing resource-constrained business IoT environments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04855v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04855v1">üìÑ Download PDF</a></p><hr><h3 id=breaking-the-bandwidth-efficiency-trade-off-in-soliton-microcombs-via-mode-couplinghttpsarxivorgabs251205090v1><a href=https://arxiv.org/abs/2512.05090v1>Breaking the bandwidth-efficiency trade-off in soliton microcombs via mode coupling</a><a hidden class=anchor aria-hidden=true href=#breaking-the-bandwidth-efficiency-trade-off-in-soliton-microcombs-via-mode-couplinghttpsarxivorgabs251205090v1>#</a></h3><p><strong>Authors:</strong> Yang Liu, Andreas Jacobsen, Thibault Wildi, Yanjing Zhao, Chaochao Ye, Yi Zheng, Camiel Op de Beeck, Jos√© Carreira, Michael Geiselmann, Kresten Yvind, Tobias Herr, Minhao Pu
<strong>Venue:</strong> arXiv (2025)</p><p>Dissipative Kerr solitons in optical microresonators have emerged as a powerful tool for compact and coherent frequency comb generation. Advances in nanofabrication have allowed precise dispersion engineering, unlocking octave-spanning soliton combs that are essential for applications such as optical atomic clocks, frequency synthesis, precision spectroscopy, and astronomical spectrometer calibration. However, a key challenge hindering their practical deployment is the intrinsic bandwidth-efficiency trade-off: achieving broadband soliton generation requires large pump detuning, which suppresses power coupling and limits pump-to-comb conversion efficiencies to only a few percent. Recent efforts using pulsed pumping or coupled-resonator architectures have improved efficiency to several tens of percent, yet their bandwidths remain below one-tenth of an octave, inadequate for applications demanding wide spectral coverage. Here, we overcome this limitation by harnessing mode interactions between spatial modes within a single microresonator. The mode hybridization creates an additional power-transfer channel that supports large pump detuning while maintaining strong pump-to-resonator coupling, enabling broadband soliton formation at substantially reduced pump power. Using this approach, we demonstrate an octave-spanning soliton microcomb with a record pump-to-comb conversion efficiency exceeding 50%. These results resolve the fundamental bandwidth-efficiency dilemma in soliton microcombs and paves the way toward fully-integrated, high-efficiency, ultrabroad comb sources for next-generation photonic systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05090v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05090v1">üìÑ Download PDF</a></p><hr><h3 id=anisotropic-response-in-metamaterials-with-elliptically-perforated-plates-applications-to-near-field-radiative-heat-transferhttpsarxivorgabs251205075v1><a href=https://arxiv.org/abs/2512.05075v1>Anisotropic Response in Metamaterials with Elliptically Perforated Plates: Applications to Near-Field Radiative Heat Transfer</a><a hidden class=anchor aria-hidden=true href=#anisotropic-response-in-metamaterials-with-elliptically-perforated-plates-applications-to-near-field-radiative-heat-transferhttpsarxivorgabs251205075v1>#</a></h3><p><strong>Authors:</strong> J. E. P&rsquo;erez-Rodr&rsquo;iguez, R. Esquivel-Sirvent, A. Camacho de la Rosa
<strong>Venue:</strong> arXiv (2025)</p><p>Metamaterials with tunable optical properties provide a versatile platform for controlling electromagnetic interactions at the nanoscale. This study explores the anisotropic thermal behavior of metamaterials composed of planar plates perforated with periodic arrays of cylinders possessing elliptical cross sections. In contrast to conventional circular perforations, elliptical geometries inherently break rotational symmetry, introducing anisotropy in the effective electromagnetic and thermal response of the structure. Using a fluctuation electrodynamics framework combined with full-wave numerical simulations, we quantify the near-field radiative heat transfer between such elliptically perforated plates as a function of ellipse orientation, aspect ratio, and separation distance. The results reveal that elliptical perforations enable enhanced spectral and directional control of evanescent mode coupling and surface polariton excitation, leading to significant modulation of the near-field heat flux. These findings highlight the potential of geometrically engineered anisotropy for advanced thermal management and energy conversion applications, and offer new design strategies for the development of thermally functional metamaterials operating in the near-field regime.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05075v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05075v1">üìÑ Download PDF</a></p><hr><h3 id=meta-learning-for-quantum-optimization-via-quantum-sequence-modelhttpsarxivorgabs251205058v1><a href=https://arxiv.org/abs/2512.05058v1>Meta-Learning for Quantum Optimization via Quantum Sequence Model</a><a hidden class=anchor aria-hidden=true href=#meta-learning-for-quantum-optimization-via-quantum-sequence-modelhttpsarxivorgabs251205058v1>#</a></h3><p><strong>Authors:</strong> Yu-Cheng Lin, Yu-Chao Hsu, Samuel Yen-Chi Chen
<strong>Venue:</strong> arXiv (2025)</p><p>The Quantum Approximate Optimization Algorithm (QAOA) is a leading approach for solving combinatorial optimization problems on near-term quantum processors. However, finding good variational parameters remains a significant challenge due to the non-convex energy landscape, often resulting in slow convergence and poor solution quality. In this work, we propose a quantum meta-learning framework that trains advanced quantum sequence models to generate effective parameter initialization policies. We investigate four classical or quantum sequence models, including the Quantum Kernel-based Long Short-Term Memory (QK-LSTM), as learned optimizers in a &ldquo;learning to learn&rdquo; paradigm. Our numerical experiments on the Max-Cut problem demonstrate that the QK-LSTM optimizer achieves superior performance, obtaining the highest approximation ratios and exhibiting the fastest convergence rate across all tested problem sizes (n=10 to 13). Crucially, the QK-LSTM model achieves perfect parameter transferability by synthesizing a single, fixed set of near-optimal parameters, leading to a remarkable sustained acceleration of convergence even when generalizing to larger problems. This capability, enabled by the compact and expressive power of the quantum kernel architecture, underscores its effectiveness. The QK-LSTM, with only 43 trainable parameters, substantially outperforms the classical LSTM (56 parameters) and other quantum sequence models, establishing a robust pathway toward highly efficient parameter initialization for variational quantum algorithms in the NISQ era.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05058v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05058v1">üìÑ Download PDF</a></p><hr><h3 id=some-computations-in-the-heart-of-the-homotopy-t-structure-on-logarithmic-motiveshttpsarxivorgabs251205051v1><a href=https://arxiv.org/abs/2512.05051v1>Some computations in the heart of the homotopy t-structure on logarithmic motives</a><a hidden class=anchor aria-hidden=true href=#some-computations-in-the-heart-of-the-homotopy-t-structure-on-logarithmic-motiveshttpsarxivorgabs251205051v1>#</a></h3><p><strong>Authors:</strong> Alberto Merici
<strong>Venue:</strong> arXiv (2025)</p><p>In this note we will illustrate a method for computing the $œÄ_0$ of the effective log motive of a smooth and proper variety over a perfect field $k$ and show that it is $\A^1$-invariant. We will apply this to compute the first homotopy groups of $¬∂^1$ to show that the stripping functor from log motivic sheaves to (usual) Nisnevich sheaves with transfers is fully faithful.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05051v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05051v1">üìÑ Download PDF</a></p><hr><h3 id=ramen-resolution-adjustable-multimodal-encoder-for-earth-observationhttpsarxivorgabs251205025v1><a href=https://arxiv.org/abs/2512.05025v1>RAMEN: Resolution-Adjustable Multimodal Encoder for Earth Observation</a><a hidden class=anchor aria-hidden=true href=#ramen-resolution-adjustable-multimodal-encoder-for-earth-observationhttpsarxivorgabs251205025v1>#</a></h3><p><strong>Authors:</strong> Nicolas Houdr√©, Diego Marcos, Hugo Riffaud de Turckheim, Dino Ienco, Laurent Wendling, Camille Kurtz, Sylvain Lobry
<strong>Venue:</strong> arXiv (2025)</p><p>Earth observation (EO) data spans a wide range of spatial, spectral, and temporal resolutions, from high-resolution optical imagery to low resolution multispectral products or radar time series. While recent foundation models have improved multimodal integration for learning meaningful representations, they often expect fixed input resolutions or are based on sensor-specific encoders limiting generalization across heterogeneous EO modalities. To overcome these limitations we introduce RAMEN, a resolution-adjustable multimodal encoder that learns a shared visual representation across EO data in a fully sensor-agnostic manner. RAMEN treats the modality and spatial and temporal resolutions as key input data features, enabling coherent analysis across modalities within a unified latent space. Its main methodological contribution is to define spatial resolution as a controllable output parameter, giving users direct control over the desired level of detail at inference and allowing explicit trade-offs between spatial precision and computational cost. We train a single, unified transformer encoder reconstructing masked multimodal EO data drawn from diverse sources, ensuring generalization across sensors and resolutions. Once pretrained, RAMEN transfers effectively to both known and unseen sensor configurations and outperforms larger state-of-the-art models on the community-standard PANGAEA benchmark, containing various multi-sensor and multi-resolution downstream tasks. Our code and pretrained model are available at <a href=https://github.com/nicolashoudre/RAMEN>https://github.com/nicolashoudre/RAMEN</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05025v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05025v1">üìÑ Download PDF</a></p><hr><h3 id=schwarzschild-black-hole-turbulence-scalar-probehttpsarxivorgabs251205003v1><a href=https://arxiv.org/abs/2512.05003v1>Schwarzschild Black Hole Turbulence: Scalar Probe</a><a hidden class=anchor aria-hidden=true href=#schwarzschild-black-hole-turbulence-scalar-probehttpsarxivorgabs251205003v1>#</a></h3><p><strong>Authors:</strong> Alex Kehagias, Antonio Riotto
<strong>Venue:</strong> arXiv (2025)</p><p>We explore how perturbations of a Schwarzschild black hole can redistribute energy among scalar modes and seed turbulent like cascades. We make use of the van der Pol-Krylov-Bogoliubov averaging method and derive coupled mode equations that describe near-resonant interactions between neighbouring multipoles. We compare two routes to instability, namely the difference-frequency mixing between adjacent modes and the diagonal (Mathieu) self-modulation channel. We show that, at high multipole number (eikonal limit), the difference-frequency route dominates and drives a one-way cascade from higher to lower frequencies. We chart the corresponding instability regions (&ldquo;tongues&rdquo;) and quantify their detuning dependence. The framework provides a simple, quantitative mechanism for energy transfer in black hole ringdowns and clarifies when and how turbulent signatures can arise within linear probes on a weakly perturbed background.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05003v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05003v1">üìÑ Download PDF</a></p><hr><h3 id=suppressing-metal-molecule-charge-transfer-with-a-phosphorus-interlayerhttpsarxivorgabs251204999v1><a href=https://arxiv.org/abs/2512.04999v1>Suppressing metal molecule charge transfer with a phosphorus interlayer</a><a hidden class=anchor aria-hidden=true href=#suppressing-metal-molecule-charge-transfer-with-a-phosphorus-interlayerhttpsarxivorgabs251204999v1>#</a></h3><p><strong>Authors:</strong> Mattia Bassotti, Luca Floreano, Luca Schio, Sergio Salaverria, Dimas G. de Oteyza, Giacomo Giorgi, Frederik Schiller, Alberto Verdini
<strong>Venue:</strong> arXiv (2025)</p><p>Porphyrins are organic molecules that exhibit excellent opto-electronics properties, making them suitable for a variety of applications. Nevertheless, their functionality strongly depends on the surface onto which they are deposited, and on the interaction between the molecules and the substrate itself, which often leads to an undesired alteration in their electronic properties. In this study, we use a phosphorus interlayer on a Cu(110) surface as a buffer layer for the electronic decoupling of Zinc-TetraPhenylPorphyrin (ZnTPP) molecules. Using a combination of complementary techniques, such as Near Edge X-ray Absorption Fine Structure (NEXAFS), X-ray and Ultraviolet Photoemission Spectroscopy (XPS, UPS) as well as Scanning Tunneling Spectroscopy (STS) techniques, it is shown how the charge transfer from the metal, responsible for quenching the ZnTPP lowest unoccupied molecular level (LUMO) levels, is effectively prevented by the presence of a phosphorus reconstruction in between.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04999v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04999v1">üìÑ Download PDF</a></p><hr><h3 id=introducing-v-soft-pro-a-modular-platform-for-a-transhumeral-prosthesis-with-controllable-stiffnesshttpsarxivorgabs251204998v1><a href=https://arxiv.org/abs/2512.04998v1>Introducing V-Soft Pro: a Modular Platform for a Transhumeral Prosthesis with Controllable Stiffness</a><a hidden class=anchor aria-hidden=true href=#introducing-v-soft-pro-a-modular-platform-for-a-transhumeral-prosthesis-with-controllable-stiffnesshttpsarxivorgabs251204998v1>#</a></h3><p><strong>Authors:</strong> Giuseppe Milazzo, Giorgio Grioli, Antonio Bicchi, Manuel G. Catalano
<strong>Venue:</strong> arXiv (2025)</p><p>Current upper limb prostheses aim to enhance user independence in daily activities by incorporating basic motor functions. However, they fall short of replicating the natural movement and interaction capabilities of the human arm. In contrast, human limbs leverage intrinsic compliance and actively modulate joint stiffness, enabling adaptive responses to varying tasks, impact absorption, and efficient energy transfer during dynamic actions. Inspired by this adaptability, we developed a transhumeral prosthesis with Variable Stiffness Actuators (VSAs) to replicate the controllable compliance found in biological joints. The proposed prosthesis features a modular design, allowing customization for different residual limb shapes and accommodating a range of independent control signals derived from users&rsquo; biological cues. Integrated elastic elements passively support more natural movements, facilitate safe interactions with the environment, and adapt to diverse task requirements. This paper presents a comprehensive overview of the platform and its functionalities, highlighting its potential applications in the field of prosthetics.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04998v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04998v1">üìÑ Download PDF</a></p><hr><h3 id=operator-formalism-for-laser-plasma-wakefield-accelerationhttpsarxivorgabs251204982v1><a href=https://arxiv.org/abs/2512.04982v1>Operator Formalism for Laser-Plasma Wakefield Acceleration</a><a hidden class=anchor aria-hidden=true href=#operator-formalism-for-laser-plasma-wakefield-accelerationhttpsarxivorgabs251204982v1>#</a></h3><p><strong>Authors:</strong> Mostafa Behtouei, Carlos Salgado Lopez, Giancarlo Gatti
<strong>Venue:</strong> arXiv (2025)</p><p>In this paper, we develop an operator-based framework for laser&ndash;plasma wakefield acceleration (LPWA) in capillary discharges, providing a compact and systematic description of the coupled dynamics of laser fields and plasma response. The formalism employs key operators: the transverse modal operator $\hat{K}$, the nonlinear plasma operator $\hat{N}[Œ®]$, the plasma oscillation operator $\hatŒ©_p^{,2}$, and the ponderomotive source operator $\hatŒ±$, which together describe mode coupling, plasma oscillations, and nonlinear feedback induced by the ponderomotive force. In the linear regime, the system is characterized by invariant subspaces associated with stable modal structures, while nonlinear interactions break these invariances, leading to mode mixing and complex dynamics. The approach establishes a direct connection between LPWA and Hilbert-space operator theory, including the invariant subspace, providing a formal mathematical interpretation of energy transfer and wakefield formation. Furthermore, the operator formalism integrates with neural operator methods, allowing efficient approximation of $\hat{N}$ and $\hatŒ±$ for reduced-order modeling and predictive control. This hybrid physics&ndash;AI framework offers a robust foundation for modeling, analysis, and optimization of high-intensity laser&ndash;plasma interactions in next-generation accelerator experiments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04982v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04982v1">üìÑ Download PDF</a></p><hr><h3 id=hybrid-diffusion-models-combining-open-loop-routines-with-visuomotor-diffusion-policieshttpsarxivorgabs251204960v1><a href=https://arxiv.org/abs/2512.04960v1>Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies</a><a hidden class=anchor aria-hidden=true href=#hybrid-diffusion-models-combining-open-loop-routines-with-visuomotor-diffusion-policieshttpsarxivorgabs251204960v1>#</a></h3><p><strong>Authors:</strong> Jonne Van Haastregt, Bastian Orthmann, Michael C. Welle, Yuchong Zhang, Danica Kragic
<strong>Venue:</strong> arXiv (2025)</p><p>Despite the fact that visuomotor-based policies obtained via imitation learning demonstrate good performances in complex manipulation tasks, they usually struggle to achieve the same accuracy and speed as traditional control based methods. In this work, we introduce Hybrid-Diffusion models that combine open-loop routines with visuomotor diffusion policies. We develop Teleoperation Augmentation Primitives (TAPs) that allow the operator to perform predefined routines, such as locking specific axes, moving to perching waypoints, or triggering task-specific routines seamlessly during demonstrations. Our Hybrid-Diffusion method learns to trigger such TAPs during inference. We validate the method on challenging real-world tasks: Vial Aspiration, Open-Container Liquid Transfer, and container unscrewing. All experimental videos are available on the project&rsquo;s website: <a href=https://hybriddiffusion.github.io/>https://hybriddiffusion.github.io/</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04960v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04960v1">üìÑ Download PDF</a></p><hr><h3 id=crack-detection-by-holomorphic-neural-networks-and-transfer-learning-enhanced-genetic-optimizationhttpsarxivorgabs251204947v1><a href=https://arxiv.org/abs/2512.04947v1>Crack detection by holomorphic neural networks and transfer-learning-enhanced genetic optimization</a><a hidden class=anchor aria-hidden=true href=#crack-detection-by-holomorphic-neural-networks-and-transfer-learning-enhanced-genetic-optimizationhttpsarxivorgabs251204947v1>#</a></h3><p><strong>Authors:</strong> Jonas Hund, Nicolas Cuenca, Tito Andriollo
<strong>Venue:</strong> arXiv (2025)</p><p>A new strategy for detecting cracks in 2D solids based on strain data is introduced. Crack detection is formulated as an inverse problem and solved using genetic optimization. The novelty lies in the evaluation of the model response at each generation. Specifically, the solution to the corresponding plane elasticity problem is expressed via holomorphic potentials, which are determined by training two holomorphic neural networks. As the potentials satisfy equilibrium and traction-free conditions along the crack faces a priori, the training proceeds quickly based solely on boundary information. Training efficiency is further improved by splitting the genetic search into long-range and short-range stages, enabling the use of transfer learning in the latter. The new strategy is tested on three benchmark problems, showing that an optimal number of training epochs exists that provides the best overall performance. A comparison is also made with a popular crack detection approach that uses XFEM to compute the model response. Under the assumption of identical stress-field representation accuracy, the proposed method is found to be between 7 and 23 times faster than the XFEM-based approach. While the strategy is presented here for the simplified case of a single internal crack, generalization is feasible. Overall, the present findings demonstrate that combining genetic optimization with holomorphic neural networks and transfer learning offers a promising avenue for developing crack detection strategies with higher efficiency than those currently available.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04947v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04947v1">üìÑ Download PDF</a></p><hr><h3 id=tuning-the-electronic-states-of-bi2se3-films-with-large-spin-orbit-interaction-using-molecular-heterojunctionshttpsarxivorgabs251204922v1><a href=https://arxiv.org/abs/2512.04922v1>Tuning the Electronic States of Bi2Se3 Films with Large Spin-Orbit Interaction Using Molecular Heterojunctions</a><a hidden class=anchor aria-hidden=true href=#tuning-the-electronic-states-of-bi2se3-films-with-large-spin-orbit-interaction-using-molecular-heterojunctionshttpsarxivorgabs251204922v1>#</a></h3><p><strong>Authors:</strong> Matthew Rogers, Craig Knox, Bryan Hickey, Lida Ansari, Farzan Gity, Timothy Moorsom, Mairi McCauley, Gilberto Teobaldi, Manuel dos Santos Dias, Hari B. Vasili, Manuel Valvidares, Mannan Ali, Gavin Burnell, Ahmet Yagmur, Satoshi Sasaki, Oscar Cespedes
<strong>Venue:</strong> arXiv (2025)</p><p>An electric bias can shift the Fermi level along the Dirac cone of a topological insulator and modify its charge transport, but tuning the electronic states and spin-orbit interaction (SOI) without destroying the surface topology is challenging. Here, we show that thin film Bi2Se3/n-p (p-n) molecular diodes form ordered interfaces where charge transfer and orbital re-hybridisation result in a decrease (increase) of the carrier density and improved mobility. In Bi2Se3 the spin-orbit lifetime, t_so, is 0.13 ps, which is comparable to the strongest spin-orbit materials. This lifetime drops further to 0.06 ps (0.09 ps) with the addition of p-n (n-p) molecular diodes, at the limit of measurable values. This strengthened spin-orbit interaction occurs even though molecules are made of light elements and increase the mean free path of the charge carriers by almost 50%, indicating changes to the Berry curvature and/or Rashba splitting around the hybridisation points. Raman spectroscopy gives evidence that the coupling effect may be controlled by optical irradiation, opening a pathway towards the design of heavy-light element hybrids with optically tunable quantum transport.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04922v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04922v1">üìÑ Download PDF</a></p><hr><h3 id=hoi----a-multimodal-dataset-for-force-grounded-cross-view-articulated-manipulationhttpsarxivorgabs251204884v1><a href=https://arxiv.org/abs/2512.04884v1>Hoi! &ndash; A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation</a><a hidden class=anchor aria-hidden=true href=#hoi----a-multimodal-dataset-for-force-grounded-cross-view-articulated-manipulationhttpsarxivorgabs251204884v1>#</a></h3><p><strong>Authors:</strong> Tim Engelbracht, Ren√© Zurbr√ºgg, Matteo Wohlrapp, Martin B√ºchner, Abhinav Valada, Marc Pollefeys, Hermann Blum, Zuria Bauer
<strong>Venue:</strong> arXiv (2025)</p><p>We present a dataset for force-grounded, cross-view articulated manipulation that couples what is seen with what is done and what is felt during real human interaction. The dataset contains 3048 sequences across 381 articulated objects in 38 environments. Each object is operated under four embodiments - (i) human hand, (ii) human hand with a wrist-mounted camera, (iii) handheld UMI gripper, and (iv) a custom Hoi! gripper - where the tool embodiment provides synchronized end-effector forces and tactile sensing. Our dataset offers a holistic view of interaction understanding from video, enabling researchers to evaluate how well methods transfer between human and robotic viewpoints, but also investigate underexplored modalities such as force sensing and prediction.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04884v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04884v1">üìÑ Download PDF</a></p><hr><h3 id=interfacial-synergy-in-ag-doped-cuo-agcl-g-c3n4-composites-for-efficient-charge-separation-and-low-power-methylene-blue-degradationhttpsarxivorgabs251204825v1><a href=https://arxiv.org/abs/2512.04825v1>Interfacial Synergy in Ag-Doped CuO-AgCl-g-C3N4 Composites for Efficient Charge Separation and Low-power Methylene Blue Degradation</a><a hidden class=anchor aria-hidden=true href=#interfacial-synergy-in-ag-doped-cuo-agcl-g-c3n4-composites-for-efficient-charge-separation-and-low-power-methylene-blue-degradationhttpsarxivorgabs251204825v1>#</a></h3><p><strong>Authors:</strong> Suresh Chandra Baral, Uttama Kumar Saint, Dilip Sasmal, Sradhanjali Lenka, Ashish Kalkal, A. Mekki, Sudhagar Pitchaimuthu, Somaditya Sen
<strong>Venue:</strong> arXiv (2025)</p><p>An Ag-doped CuO-AgCl-g-C3N4 heterostructure has been designed to achieve rapid Methylene Blue (MB) degradation through a synergistic photo-Fenton mechanism driven by low-power UV illumination. The composite integrates narrow-bandgap CuO, plasmonic Ag/AgCl, and visible-responsive g-C3N4 into a dual Z-scheme configuration that promotes efficient interfacial charge transfer while preserving strong redox potentials. Diffuse reflectance UV-Vis spectra ascertained the bandgap positions of the composite corresponding to those of its constituents: 2.9 eV (g-C3N4) and 1.42 eV (Ag-doped CuO-AgCl), indicating enhanced absorption and efficient charge carrier generation. BET analysis confirmed the presence of mesoporosity and revealed an effective surface area, ensuring the availability of abundant adsorption and reaction sites. A commercial 11 W UV irradiation was used for the photocatalytic test. Almost complete degradation of MB occurred within 10 min, following pseudo-first-order kinetics with a high apparent rate constant of 0.45/min. The remarkable activity arises from the synergistic interplay of Fenton-like redox cycling and efficient photoinduced charge carrier generation and separation. In addition, it has been demonstrated that intentionally incorporated AgCl plays an active role as a plasmonic-semiconducting interface, strengthening charge separation and catalyst stability under neutral conditions, rather than acting as a passive chloride byproduct. Overall, by linking defect engineering, heterojunction design, and photo-Fenton synergy, this study establishes a low-power, catalytic platform offering a viable pathway towards sustainable dye wastewater remediation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04825v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04825v1">üìÑ Download PDF</a></p><hr><h3 id=formation-of-the-dormant-black-holes-with-luminous-companions-from-binary-or-triple-systemshttpsarxivorgabs251204774v1><a href=https://arxiv.org/abs/2512.04774v1>Formation of the Dormant Black Holes with Luminous Companions from Binary or Triple Systems</a><a hidden class=anchor aria-hidden=true href=#formation-of-the-dormant-black-holes-with-luminous-companions-from-binary-or-triple-systemshttpsarxivorgabs251204774v1>#</a></h3><p><strong>Authors:</strong> Zhuowen Li, Xizhen Lu, Guoliang L√º, Chunhua Zhu, Helei Liu, Li Lei, Sufen Guo, Xiaolong He, Nurzada Beissen
<strong>Venue:</strong> arXiv (2025)</p><p>Recently, a class of dormant black hole binaries with luminous companions (dBH-LC) has been observed, such as $Gaia$ BH1, BH2, and BH3. Unlike previously discovered X-ray BH binaries, this type of dBH-LC has relatively long orbital periods (typically more than several tens to a few hundred days) and shows very weak X-ray emission. Therefore, studying the formation and evolution of the whole dBH-LC population is also a very interesting problem. Our aim is to study the contribution of massive stars to the dBH-LC population under different evolutionary models (isolated binary evolution (IBE) and hierarchical triple evolution), and different formation channels (such as mass transfer, common envelope evolution). Using the Massive Objects in Binary Stellar Evolution (MOBSE) code, the Triple Stellar Evolution (TSE) code, and the latest initial multiple-star distributions, we model the populations of massive stars. Finally, we calculate the orbital properties, mass distributions, and birthrates of the BH-LC populations formed under these different conditions. In the Milky Way, we calculate that the birthrate of dBH-LC formed through IBE is about 4.35$\times$$10^{-5}$ ${\rm yr}^{-1}$, while the birthrate through triple evolution is about 1.47$\times$$10^{-3}$ ${\rm yr}^{-1}$. This means that the birthrate from triple evolution is one to two orders of magnitude higher than that from IBE. We find that in triple evolution, the main formation channel of dBH-LC is post-merger binaries formed from inner binary mergers triggered by von Zeipel$-$Lidov$-$Kozai oscillations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04774v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04774v1">üìÑ Download PDF</a></p><hr><h3 id=maehara-interpolation-in-extensions-of-r-minglehttpsarxivorgabs251204762v1><a href=https://arxiv.org/abs/2512.04762v1>Maehara Interpolation in Extensions of R-mingle</a><a hidden class=anchor aria-hidden=true href=#maehara-interpolation-in-extensions-of-r-minglehttpsarxivorgabs251204762v1>#</a></h3><p><strong>Authors:</strong> Wesley Fussner, Krzysztof Krawczyk
<strong>Venue:</strong> arXiv (2025)</p><p>We show that there are exactly five quasivarieties of Sugihara algebras with the amalgamation property, and that all of these have the relative congruence extension property. As a consequence, we obtain that the amalgamation property and transferable injections property coincide for arbitrary quasivarieties of Sugihara algebras. These results provide a complete description of arbitrary (not merely axiomatic) extensions of the logic R-mingle that have the Maehara interpolation property, and further demonstrates that the Robinson property and Maehara interpolation property coincide for arbitrary extensions of R-mingle. Further, we show that the question of whether a given finitely based extension of R-mingle has the Maehara interpolation property is decidable.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04762v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04762v1">üìÑ Download PDF</a></p><hr><h3 id=evolution-of-correlated-electrons-in-rm-la_3ni_2o_7-at-ambient-pressure-a-study-of-double-counting-effecthttpsarxivorgabs251204754v1><a href=https://arxiv.org/abs/2512.04754v1>Evolution of Correlated Electrons in ${\rm La_3Ni_2O_7}$ at Ambient Pressure: a Study of Double-Counting Effect</a><a hidden class=anchor aria-hidden=true href=#evolution-of-correlated-electrons-in-rm-la_3ni_2o_7-at-ambient-pressure-a-study-of-double-counting-effecthttpsarxivorgabs251204754v1>#</a></h3><p><strong>Authors:</strong> Zhong-Yi Xie, Zhihui Luo, W√©i W√∫, Dao-Xin Yao
<strong>Venue:</strong> arXiv (2025)</p><p>We employ cluster extension of dynamical mean-field theory (CDMFT) to systematically investigate the impact of double counting corrections on the correlated electronic structure of ${\rm La_3Ni_2O_7}$ under ambient pressure. By adjusting double-counting parameters, while maintaining a fixed Fermi surface, we observe a pronounced orbital-selective density of states change: the $d_{z^2}$ orbital undergoes significant variation near the Fermi level with increasing $E_{dc}^z$, while the $d_{x^2-y^2}$ orbital remains essentially unchanged throughout the entire range. Analysis of renormalization factor show the monotonic dependence with double counting in both $d_{z^2}$ and $d_{x^2-y^2}$ orbital, and it also identifies an optimal double counting window in $d_{z^2}$ orbital aligns with experimental values. We also find the interlayer Matsubara self energy exhibits non-monotonic dependence on $E_{dc}^z$, deviating from theoretical predictions. This anomaly is attributed to the metallization of oxygen-bridged pathways, which disrupts the prerequisite for charge transfer via apical oxygen. Our results establish $E_{dc}$ as a critical control parameter for correlated electronic structure in ${\rm La_3Ni_2O_7}$ and provide a computational framework for resolving orbital-dependent correlation effects in layered materials.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04754v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04754v1">üìÑ Download PDF</a></p><hr><h3 id=alma-quarks-few-thousand-year-hatching-out-of-egg-the-supersonic-breakout-of-a-hypercompact-h-ii-region-from-its-parental-hot-corehttpsarxivorgabs251204744v1><a href=https://arxiv.org/abs/2512.04744v1>ALMA-QUARKS: Few-Thousand-Year Hatching out of &ldquo;Egg&rdquo;: The Supersonic Breakout of a Hypercompact H II Region from Its Parental Hot Core</a><a hidden class=anchor aria-hidden=true href=#alma-quarks-few-thousand-year-hatching-out-of-egg-the-supersonic-breakout-of-a-hypercompact-h-ii-region-from-its-parental-hot-corehttpsarxivorgabs251204744v1>#</a></h3><p><strong>Authors:</strong> Siju Zhang, Guido Garay, Fengwei Xu, Luis F. Rodr√≠guez, Neal J. Evans, Annie Zavagno, Paul F. Goldsmith, Dongting Yang, Xunchuan Liu, Aiyuan Yang, Tie Liu, Amelia M. Stutz, Hong-Li Liu, Wenyu Jiao, Anandmayee Tej, Lei Zhu, Kee-Tae Kim, Pablo Garc√≠a, Thomas Peters, Thomas M√∂ller, Shanghuo Li, Leonardo Bronfman
<strong>Venue:</strong> arXiv (2025)</p><p>The kinematic evolution of hypercompact H II (HC H II) regions around young high-mass stars remains poorly understood due to complex interactions with parental environs. We present ALMA QUARKS/ATOMS 1.3 mm/3 mm observations (the highest resolution $\sim0.01$ pc) of a deeply embedded HC H II region (diameter $\sim0.015$ pc, electron density $\sim2\times10^{5}$ cm$^{-3}$) exhibiting a striking $\gtrsim20$ km s$^{-1}$ global redshift seen in optically thin H30$Œ±$/H40$Œ±$ recombination lines relative to its parental hot molecular core within a hub-filament system. The 1.3 mm continuum data reveal a distinct 0.1-pc arc and a perpendicular 0.04-pc tail. We propose that this morphology arises from a dynamic champagne flow: the slow expansion of HC H II region into a pre-existing filament forms the arc and associated low-velocity (few km s$^{-1}$) SiO shocks. Meanwhile, in the opposite direction ionized gas escapes along a steep density gradient traced by the tail and high-velocity (20 km s$^{-1}$) SiO emission. We reject the bow shock scenario in which ionized gas co-moves with a runaway high-mass star because shocked gas in the arc aligns with the hub velocity, contradicting the bow shock prediction. Non-LTE radiative transfer modeling further rules out infall of ionized gas as the velocity shift origin. We conclude that this exceptional HC H II region is undergoing a few-thousand-year transition phase of &ldquo;hatching out of the egg&rdquo;: the ionized gas of HC H II region has just broken out of its parental hot core and now is flowing outward supersonically. This work highlights how anisotropic density distributions induce supersonically anisotropic ionized flows that govern HC H II region evolution.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04744v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04744v1">üìÑ Download PDF</a></p><hr><h3 id=bridging-simulation-and-reality-cross-domain-transfer-with-semantic-2d-gaussian-splattinghttpsarxivorgabs251204731v1><a href=https://arxiv.org/abs/2512.04731v1>Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting</a><a hidden class=anchor aria-hidden=true href=#bridging-simulation-and-reality-cross-domain-transfer-with-semantic-2d-gaussian-splattinghttpsarxivorgabs251204731v1>#</a></h3><p><strong>Authors:</strong> Jian Tang, Pu Pang, Haowen Sun, Chengzhong Ma, Xingyu Chen, Hua Huang, Xuguang Lan
<strong>Venue:</strong> arXiv (2025)</p><p>Cross-domain transfer in robotic manipulation remains a longstanding challenge due to the significant domain gap between simulated and real-world environments. Existing methods such as domain randomization, adaptation, and sim-real calibration often require extensive tuning or fail to generalize to unseen scenarios. To address this issue, we observe that if domain-invariant features are utilized during policy training in simulation, and the same features can be extracted and provided as the input to policy during real-world deployment, the domain gap can be effectively bridged, leading to significantly improved policy generalization. Accordingly, we propose Semantic 2D Gaussian Splatting (S2GS), a novel representation method that extracts object-centric, domain-invariant spatial features. S2GS constructs multi-view 2D semantic fields and projects them into a unified 3D space via feature-level Gaussian splatting. A semantic filtering mechanism removes irrelevant background content, ensuring clean and consistent inputs for policy learning. To evaluate the effectiveness of S2GS, we adopt Diffusion Policy as the downstream learning algorithm and conduct experiments in the ManiSkill simulation environment, followed by real-world deployment. Results demonstrate that S2GS significantly improves sim-to-real transferability, maintaining high and stable task performance in real-world scenarios.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04731v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04731v1">üìÑ Download PDF</a></p><hr><h3 id=boosting-the-memory-window-of-memristive-stacks-via-engineered-interfaces-with-high-ionic-mobilityhttpsarxivorgabs251204706v1><a href=https://arxiv.org/abs/2512.04706v1>Boosting the Memory Window of Memristive Stacks via Engineered Interfaces with High Ionic Mobility</a><a hidden class=anchor aria-hidden=true href=#boosting-the-memory-window-of-memristive-stacks-via-engineered-interfaces-with-high-ionic-mobilityhttpsarxivorgabs251204706v1>#</a></h3><p><strong>Authors:</strong> Jos√© Diogo Costa, Daniel Veira-Canle, Noa Varela-Dom√≠nguez, Nicholas Davey, Victor Lebor√°n, Rafael Ramos, F√®lix Casanova, Luis E. Hueso, Victor M. Brea, P. L√≥pez, Francisco Rivadulla
<strong>Venue:</strong> arXiv (2025)</p><p>The great potential of memristive devices for real-world applications still relies on overcoming key technical challenges, including the need for a larger number of stable resistance states, faster switching speeds, lower SET/RESET voltages, improved endurance, and reduced variability. One material optimization strategy that has still been quite overlooked is interface engineering, specifically, tailoring the electrode/dielectric interface to modulate oxygen exchange. Here, we demonstrate that introducing materials with high ionic mobility can significantly expand the accessible oxygen concentration range within the dielectric layer, significantly broadening the memory window. Using SrTiO3-based memristive stacks, we integrated an ion-conducting SrCoO3 interfacial layer to facilitate oxygen transfer, increasing the number of distinguishable resistance states from 8 to 22. This modification also reduced the SET/RESET voltage by 50% and markedly improved device endurance, albeit with a trade-off of reduced state retention. To assess the practical implications of this trade-off, we trained a two-layer fully connected neural network using the experimental SrTiO3/SrCoO3 memristor characteristics on the MNIST handwritten digit dataset. Networks with hidden-layer sizes between 64 and 256 memristive elements achieved classification errors below 7%. The observed temporal drift means the functional state must be updated at intervals of less than 1 h to maintain reliable operation. Finally, we confirmed the transferability of this interface-engineering approach by applying it to HfOx-based devices, achieving a similarly enhanced memory window.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04706v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04706v1">üìÑ Download PDF</a></p><hr><h3 id=colorings-of-unrooted-tree-based-networks-and-related-graphshttpsarxivorgabs251204693v1><a href=https://arxiv.org/abs/2512.04693v1>Colorings of unrooted tree-based networks and related graphs</a><a hidden class=anchor aria-hidden=true href=#colorings-of-unrooted-tree-based-networks-and-related-graphshttpsarxivorgabs251204693v1>#</a></h3><p><strong>Authors:</strong> Mirko Wilde, Mareike Fischer
<strong>Venue:</strong> arXiv (2025)</p><p>In mathematical phylogenetics, evolutionary relationships are often represented by trees and networks. The latter are typically used whenever the relationships cannot be adequately described by a tree, which happens when so-called reticulate evolutionary events happen, such as horizontal gene transfer or hybridization. But as such events are known to be relatively rare for most species, evolution is sometimes thought of as a process that can be represented by a tree with some additional edges, i.e., with a network that is still ``somewhat treelike&rsquo;&rsquo;. In this context, different versions of so-called tree-based networks have played a major role in recent phylogenetic literature. Yet, surprisingly little is known about their combinatorial and graph-theoretic properties. In our manuscript, we answer a recently published question concerning the colorability of a specific class of tree-based networks. In particular, we will investigate an even more general class of graphs and show their 3-colorability. This nicely links recent phylogenetic concepts with classical graph theory.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04693v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04693v1">üìÑ Download PDF</a></p><hr><h3 id=fast-and-efficient-formation-of-stable-tetraatomic-molecules-from-ultracold-atoms-via-generalized-stimulated-raman-exact-passagehttpsarxivorgabs251204681v1><a href=https://arxiv.org/abs/2512.04681v1>Fast and efficient formation of stable tetraatomic molecules from ultracold atoms via generalized stimulated Raman exact passage</a><a hidden class=anchor aria-hidden=true href=#fast-and-efficient-formation-of-stable-tetraatomic-molecules-from-ultracold-atoms-via-generalized-stimulated-raman-exact-passagehttpsarxivorgabs251204681v1>#</a></h3><p><strong>Authors:</strong> Jia-Hui Zhang, Wen-Yuan Wang, Fu-Quan Dou
<strong>Venue:</strong> arXiv (2025)</p><p>The study of the conversion of ultracold atoms into molecules has long remained a hot topic in atomic, molecular, and optical physics. However, most prior research has focused on diatomic molecules, with relatively scarce exploration of polyatomic molecules. Here we propose a two-step strategy for the formation of stable ultracold tetraatomic molecules. We first suggest a generalized nonlinear stimulated Raman exact passage (STIREP) technique for the coherent conversion of ultracold atoms to tetraatomic molecules, which is subsequently followed by a chainwise-STIREP technique to transfer the resulting molecules into a sufficiently stable ground state. Through systematic numerical analysis, we demonstrate that the proposed two-step strategy holds great potential for enabling the robust, fast, and efficient formation of stable ultracold tetraatomic molecules.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04681v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04681v1">üìÑ Download PDF</a></p><hr><h3 id=a-unified-low-rank-adi-framework-with-shared-linear-solves-for-simultaneously-solving-multiple-lyapunov-sylvester-and-riccati-equationshttpsarxivorgabs251204676v1><a href=https://arxiv.org/abs/2512.04676v1>A Unified Low-rank ADI Framework with Shared Linear Solves for Simultaneously Solving Multiple Lyapunov, Sylvester, and Riccati Equations</a><a hidden class=anchor aria-hidden=true href=#a-unified-low-rank-adi-framework-with-shared-linear-solves-for-simultaneously-solving-multiple-lyapunov-sylvester-and-riccati-equationshttpsarxivorgabs251204676v1>#</a></h3><p><strong>Authors:</strong> Umair Zulfiqar, Zhong-Yi Huang
<strong>Venue:</strong> arXiv (2025)</p><p>It is known in the literature that the low-rank ADI method for Lyapunov equations is a Petrov-Galerkin projection algorithm that implicitly performs model order reduction. In this paper, we show that the low-rank ADI methods for Sylvester and Riccati equations are also Petrov-Galerkin projection algorithms that implicitly perform model order reduction. By observing that the ADI methods for Lyapunov, Sylvester, and Riccati equations differ only in pole placement and not in their interpolatory nature, we show that the shifted linear solves-which constitute the bulk of the computational cost-can be shared. The pole-placement step involves only small-scale operations and is therefore inexpensive. We propose a unified ADI framework that requires only two shifted linear solves per iteration to simultaneously solve six Lyapunov equations, one Sylvester equation, and ten Riccati equations, thus substantially increasing the return on investment for the computational cost spent on the linear solves. All operations needed to extract the individual solutions from these shared linear solves are small-scale and inexpensive.
Since all ADI methods implicitly perform model order reduction when solving these linear matrix equations, we show that the resulting reduced-order models can be obtained as an additional byproduct. These models not only interpolate the original transfer function at the mirror images of the ADI shifts but also preserve important system properties such as stability, minimum-phase property, positive-realness, bounded-realness, and passivity. Consequently, the proposed unified ADI framework also serves as a recursive, interpolation-based model order reduction method, which can preserve several important properties of the original model in the reduced-order model.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04676v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04676v1">üìÑ Download PDF</a></p><hr><h3 id=semi-centralized-training-decentralized-execution-architecture-for-multi-agent-deep-reinforcement-learning-in-traffic-signal-controlhttpsarxivorgabs251204653v1><a href=https://arxiv.org/abs/2512.04653v1>Semi Centralized Training Decentralized Execution Architecture for Multi Agent Deep Reinforcement Learning in Traffic Signal Control</a><a hidden class=anchor aria-hidden=true href=#semi-centralized-training-decentralized-execution-architecture-for-multi-agent-deep-reinforcement-learning-in-traffic-signal-controlhttpsarxivorgabs251204653v1>#</a></h3><p><strong>Authors:</strong> Pouria Yazdani, Arash Rezaali, Monireh Abdoos
<strong>Venue:</strong> arXiv (2025)</p><p>Multi-agent reinforcement learning (MARL) has emerged as a promising paradigm for adaptive traffic signal control (ATSC) of multiple intersections. Existing approaches typically follow either a fully centralized or a fully decentralized design. Fully centralized approaches suffer from the curse of dimensionality, and reliance on a single learning server, whereas purely decentralized approaches operate under severe partial observability and lack explicit coordination resulting in suboptimal performance. These limitations motivate region-based MARL, where the network is partitioned into smaller, tightly coupled intersections that form regions, and training is organized around these regions. This paper introduces a Semi-Centralized Training, Decentralized Execution (SEMI-CTDE) architecture for multi intersection ATSC. Within each region, SEMI-CTDE performs centralized training with regional parameter sharing and employs composite state and reward formulations that jointly encode local and regional information. The architecture is highly transferable across different policy backbones and state-reward instantiations. Building on this architecture, we implement two models with distinct design objectives. A multi-perspective experimental analysis of the two implemented SEMI-CTDE-based models covering ablations of the architecture&rsquo;s core elements including rule based and fully decentralized baselines shows that they achieve consistently superior performance and remain effective across a wide range of traffic densities and distributions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04653v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04653v1">üìÑ Download PDF</a></p><hr><h3 id=strategies-for-zero-boil-off-liquid-hydrogen-transfer-an-export-terminal-case-studyhttpsarxivorgabs251204609v1><a href=https://arxiv.org/abs/2512.04609v1>Strategies for zero boil-off liquid hydrogen transfer: an export terminal case-study</a><a hidden class=anchor aria-hidden=true href=#strategies-for-zero-boil-off-liquid-hydrogen-transfer-an-export-terminal-case-studyhttpsarxivorgabs251204609v1>#</a></h3><p><strong>Authors:</strong> Halvor Aarnes Krog, David Berstad
<strong>Venue:</strong> arXiv (2025)</p><p>To ensure economic viability, LH2 export terminals must minimize boil-off losses. We show two strategies to achieve zero boil-off losses for the transfer of 160 000 m3 LH2 (11 248 tons) using a centrifugal pump. In the first strategy, a pump with variable speed drive (VSD) and split-range control for the flow rate achieves losses from 0 wt% to 0.24 wt% in an uncertainty analysis. A pump efficiency approaching 70% is the most important factor to minimize losses. In contrast, a fixed-speed pump has unacceptably high losses ranging from 0.76 wt% to 1.06 wt% (119 tons per ship). The second strategy is to increase the maximum pressure in the seaborne tank (base case is 1.15 bara). Zero loss is achieved for the fixed speed pump if the maximum pressure is increased to 1.35 bara, while 1.22 bara is required for the pump with VSD assuming an efficiency of 60%.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04609v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04609v1">üìÑ Download PDF</a></p><hr><h3 id=infrared-uav-target-tracking-with-dynamic-feature-refinement-and-global-contextual-attention-knowledge-distillationhttpsarxivorgabs251204581v1><a href=https://arxiv.org/abs/2512.04581v1>Infrared UAV Target Tracking with Dynamic Feature Refinement and Global Contextual Attention Knowledge Distillation</a><a hidden class=anchor aria-hidden=true href=#infrared-uav-target-tracking-with-dynamic-feature-refinement-and-global-contextual-attention-knowledge-distillationhttpsarxivorgabs251204581v1>#</a></h3><p><strong>Authors:</strong> Houzhang Fang, Chenxing Wu, Kun Bai, Tianqi Chen, Xiaolin Wang, Xiyang Liu, Yi Chang, Luxin Yan
<strong>Venue:</strong> arXiv (2025)</p><p>Unmanned aerial vehicle (UAV) target tracking based on thermal infrared imaging has been one of the most important sensing technologies in anti-UAV applications. However, the infrared UAV targets often exhibit weak features and complex backgrounds, posing significant challenges to accurate tracking. To address these problems, we introduce SiamDFF, a novel dynamic feature fusion Siamese network that integrates feature enhancement and global contextual attention knowledge distillation for infrared UAV target (IRUT) tracking. The SiamDFF incorporates a selective target enhancement network (STEN), a dynamic spatial feature aggregation module (DSFAM), and a dynamic channel feature aggregation module (DCFAM). The STEN employs intensity-aware multi-head cross-attention to adaptively enhance important regions for both template and search branches. The DSFAM enhances multi-scale UAV target features by integrating local details with global features, utilizing spatial attention guidance within the search frame. The DCFAM effectively integrates the mixed template generated from STEN in the template branch and original template, avoiding excessive background interference with the template and thereby enhancing the emphasis on UAV target region features within the search frame. Furthermore, to enhance the feature extraction capabilities of the network for IRUT without adding extra computational burden, we propose a novel tracking-specific target-aware contextual attention knowledge distiller. It transfers the target prior from the teacher network to the student model, significantly improving the student network&rsquo;s focus on informative regions at each hierarchical level of the backbone network. Extensive experiments on real infrared UAV datasets demonstrate that the proposed approach outperforms state-of-the-art target trackers under complex backgrounds while achieving a real-time tracking speed.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04581v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04581v1">üìÑ Download PDF</a></p><hr><h3 id=refa√ßade-editing-object-with-given-reference-texturehttpsarxivorgabs251204534v1><a href=https://arxiv.org/abs/2512.04534v1>Refa√ßade: Editing Object with Given Reference Texture</a><a hidden class=anchor aria-hidden=true href=#refa√ßade-editing-object-with-given-reference-texturehttpsarxivorgabs251204534v1>#</a></h3><p><strong>Authors:</strong> Youze Huang, Penghui Ruan, Bojia Zi, Xianbiao Qi, Jianan Wang, Rong Xiao
<strong>Venue:</strong> arXiv (2025)</p><p>Recent advances in diffusion models have brought remarkable progress in image and video editing, yet some tasks remain underexplored. In this paper, we introduce a new task, Object Retexture, which transfers local textures from a reference object to a target object in images or videos. To perform this task, a straightforward solution is to use ControlNet conditioned on the source structure and the reference texture. However, this approach suffers from limited controllability for two reasons: conditioning on the raw reference image introduces unwanted structural information, and it fails to disentangle the visual texture and structure information of the source. To address this problem, we propose Refa√ßade, a method that consists of two key designs to achieve precise and controllable texture transfer in both images and videos. First, we employ a texture remover trained on paired textured/untextured 3D mesh renderings to remove appearance information while preserving the geometry and motion of source videos. Second, we disrupt the reference global layout using a jigsaw permutation, encouraging the model to focus on local texture statistics rather than the global layout of the object. Extensive experiments demonstrate superior visual quality, precise editing, and controllability, outperforming strong baselines in both quantitative and human evaluations. Code is available at <a href=https://github.com/fishZe233/Refacade>https://github.com/fishZe233/Refacade</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04534v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04534v1">üìÑ Download PDF</a></p><hr><h3 id=prototype-based-semantic-consistency-alignment-for-domain-adaptive-retrievalhttpsarxivorgabs251204524v1><a href=https://arxiv.org/abs/2512.04524v1>Prototype-Based Semantic Consistency Alignment for Domain Adaptive Retrieval</a><a hidden class=anchor aria-hidden=true href=#prototype-based-semantic-consistency-alignment-for-domain-adaptive-retrievalhttpsarxivorgabs251204524v1>#</a></h3><p><strong>Authors:</strong> Tianle Hu, Weijun Lv, Na Han, Xiaozhao Fang, Jie Wen, Jiaxing Li, Guoxu Zhou
<strong>Venue:</strong> arXiv (2025)</p><p>Domain adaptive retrieval aims to transfer knowledge from a labeled source domain to an unlabeled target domain, enabling effective retrieval while mitigating domain discrepancies. However, existing methods encounter several fundamental limitations: 1) neglecting class-level semantic alignment and excessively pursuing pair-wise sample alignment; 2) lacking either pseudo-label reliability consideration or geometric guidance for assessing label correctness; 3) directly quantizing original features affected by domain shift, undermining the quality of learned hash codes. In view of these limitations, we propose Prototype-Based Semantic Consistency Alignment (PSCA), a two-stage framework for effective domain adaptive retrieval. In the first stage, a set of orthogonal prototypes directly establishes class-level semantic connections, maximizing inter-class separability while gathering intra-class samples. During the prototype learning, geometric proximity provides a reliability indicator for semantic consistency alignment through adaptive weighting of pseudo-label confidences. The resulting membership matrix and prototypes facilitate feature reconstruction, ensuring quantization on reconstructed rather than original features, thereby improving subsequent hash coding quality and seamlessly connecting both stages. In the second stage, domain-specific quantization functions process the reconstructed features under mutual approximation constraints, generating unified binary hash codes across domains. Extensive experiments validate PSCA&rsquo;s superior performance across multiple datasets.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04524v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04524v1">üìÑ Download PDF</a></p><hr><h3 id=universal-quantum-control-over-non-hermitian-continuous-variable-systemshttpsarxivorgabs251204495v1><a href=https://arxiv.org/abs/2512.04495v1>Universal quantum control over non-Hermitian continuous-variable systems</a><a hidden class=anchor aria-hidden=true href=#universal-quantum-control-over-non-hermitian-continuous-variable-systemshttpsarxivorgabs251204495v1>#</a></h3><p><strong>Authors:</strong> Zhu-yao Jin, Jun Jing
<strong>Venue:</strong> arXiv (2025)</p><p>Although the control of non-Hermitian quantum systems has a growing interest for their nonunitary feature in the time evolution, the existing discussions are not more than two or three dimensions and heavily influenced by the singularity of the energy spectrum. We here develop a general theory to control an arbitrary number of bosonic modes governed by the time-dependent non-Hermitian Hamiltonian. It takes advantage of the gauge potential in the instantaneous frame rather than the energy spectrum of Hamiltonian. In particular, the dynamics of a general non-Hermitian continuous-variable system is analyzed in the instantaneous frame associated with time-dependent ancillary operators that are superpositions of the laboratory-frame operators and irrelevant to the original Hamiltonian. The gauge potential is determined by the unitary transformation between the time-dependent and stationary ancillary frames. The upper triangularization condition for the Hamiltonian&rsquo;s coefficient matrix in the stationary ancillary frame enables two of the time-dependent ancillary operators to be nonadiabatic Heisenberg passages of the non-Hermitian system. The probability conservation of the system wavefunction can be restored at the end of these passages without artificial normalization. Our theory is exemplified with the perfect and nonreciprocal state transfers in a cavity magnonic system. The former holds for arbitrary initial states and is irrelevant to the parity-time symmetry of the Hamiltonian and the exceptional point of the spectra; and the latter is consistent with the unidirectional perfect absorbtion. Our work essentially extends the universal quantum control (UQC) theory to the non-Hermitian continuous-variable systems, providing a promising approach for their coherent control.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04495v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04495v1">üìÑ Download PDF</a></p><hr><h3 id=nucleon-to-roper-transition-amplitudes-and-electromagnetic-form-factorshttpsarxivorgabs251204493v1><a href=https://arxiv.org/abs/2512.04493v1>Nucleon to Roper transition amplitudes and electromagnetic form factors</a><a hidden class=anchor aria-hidden=true href=#nucleon-to-roper-transition-amplitudes-and-electromagnetic-form-factorshttpsarxivorgabs251204493v1>#</a></h3><p><strong>Authors:</strong> G. Ramalho
<strong>Venue:</strong> arXiv (2025)</p><p>The second excitation of the nucleon, the Roper, has properties differentiated from other low-lying nucleon resonances. Their properties challenge our understanding of the structure of the baryons in terms of the degrees of freedom from QCD. In the present work we discuss the properties of the Roper resonance and the nucleon to Roper electromagnetic transition, based on the quark degrees of freedom, that are expected to dominate for large square momentum transfer $Q^2$. We also discuss the analytic structure of the transition amplitudes in the low-$Q^2$ region, and how the contributions of baryon-meson states can help to describe the low and intermediate $Q^2$ data, and the nature of the Roper.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04493v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04493v1">üìÑ Download PDF</a></p><hr><h3 id=controllable-long-term-motion-generation-with-extended-joint-targetshttpsarxivorgabs251204487v1><a href=https://arxiv.org/abs/2512.04487v1>Controllable Long-term Motion Generation with Extended Joint Targets</a><a hidden class=anchor aria-hidden=true href=#controllable-long-term-motion-generation-with-extended-joint-targetshttpsarxivorgabs251204487v1>#</a></h3><p><strong>Authors:</strong> Eunjong Lee, Eunhee Kim, Sanghoon Hong, Eunho Jung, Jihoon Kim
<strong>Venue:</strong> arXiv (2025)</p><p>Generating stable and controllable character motion in real-time is a key challenge in computer animation. Existing methods often fail to provide fine-grained control or suffer from motion degradation over long sequences, limiting their use in interactive applications. We propose COMET, an autoregressive framework that runs in real time, enabling versatile character control and robust long-horizon synthesis. Our efficient Transformer-based conditional VAE allows for precise, interactive control over arbitrary user-specified joints for tasks like goal-reaching and in-betweening from a single model. To ensure long-term temporal stability, we introduce a novel reference-guided feedback mechanism that prevents error accumulation. This mechanism also serves as a plug-and-play stylization module, enabling real-time style transfer. Extensive evaluations demonstrate that COMET robustly generates high-quality motion at real-time speeds, significantly outperforming state-of-the-art approaches in complex motion control tasks and confirming its readiness for demanding interactive applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04487v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04487v1">üìÑ Download PDF</a></p><hr><h3 id=context-aware-mixture-of-experts-inference-on-cxl-enabled-gpu-ndp-systemshttpsarxivorgabs251204476v1><a href=https://arxiv.org/abs/2512.04476v1>Context-Aware Mixture-of-Experts Inference on CXL-Enabled GPU-NDP Systems</a><a hidden class=anchor aria-hidden=true href=#context-aware-mixture-of-experts-inference-on-cxl-enabled-gpu-ndp-systemshttpsarxivorgabs251204476v1>#</a></h3><p><strong>Authors:</strong> Zehao Fan, Zhenyu Liu, Yunzhen Liu, Yayue Hou, Hadjer Benmeziane, Kaoutar El Maghraoui, Liu Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Mixture-of-Experts (MoE) models scale large language models through conditional computation, but inference becomes memory-bound once expert weights exceed the capacity of GPU memory. In this case, weights must be offloaded to external memory, and fetching them incurs costly and repeated transfers. We address this by adopting CXL-attached near-data processing (CXL-NDP) as the offloading tier to execute cold experts in place, converting expensive parameter movement into cheaper activation movement. Unlike prior GPU-NDP systems that are largely context-agnostic and reactive, we develop a context-aware MoE system that uses prefill-stage activation statistics to guide decoding-stage expert placement, dynamically pins hot experts in GPU-side HBM, and maps the remainder to CXL-NDP. To meet NDP&rsquo;s limited compute throughput, we introduce context-aware mixed-precision quantization that allocates per-expert bitwidths (1-4 bit) based on prefill stage. The resulting MoE inference system overlaps GPU and NDP execution while minimizing cross-device movement. The evaluation on the GPU-NDP system shows that our approach achieves up to an 8.7-fold decoding throughput improvement over the state-of-the-art method, while incurring only a 0.13% average accuracy drop.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04476v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04476v1">üìÑ Download PDF</a></p><hr><h3 id=offloading-to-cxl-based-computational-memoryhttpsarxivorgabs251204449v1><a href=https://arxiv.org/abs/2512.04449v1>Offloading to CXL-based Computational Memory</a><a hidden class=anchor aria-hidden=true href=#offloading-to-cxl-based-computational-memoryhttpsarxivorgabs251204449v1>#</a></h3><p><strong>Authors:</strong> Suyeon Lee, Kangkyu Park, Kwangsik Shin, Ada Gavrilovska
<strong>Venue:</strong> arXiv (2025)</p><p>CXL-based Computational Memory (CCM) enables near-memory processing within expanded remote memory, presenting opportunities to address data movement costs associated with disaggregated memory systems and to accelerate overall performance. However, existing operation offloading mechanisms are not capable of leveraging the trade-offs of different models based on different CXL protocols. This work first examines these tradeoffs and demonstrates their impact on end-to-end performance and system efficiency for workloads with diverse data and processing requirements. We propose a novel &lsquo;Asynchronous Back-Streaming&rsquo; protocol by carefully layering data and control transfer operations on top of the underlying CXL protocols. We design KAI, a system that realizes the asynchronous back-streaming model that supports asynchronous data movement and lightweight pipelining in host-CCM interactions. Overall, KAI reduces end-to-end runtime by up to 50.4%, and CCM and host idle times by average 22.11x and 3.85x, respectively.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04449v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04449v1">üìÑ Download PDF</a></p><hr><h3 id=multi-source-learning-for-target-population-by-high-dimensional-calibrationhttpsarxivorgabs251204412v1><a href=https://arxiv.org/abs/2512.04412v1>Multi-source Learning for Target Population by High-dimensional Calibration</a><a hidden class=anchor aria-hidden=true href=#multi-source-learning-for-target-population-by-high-dimensional-calibrationhttpsarxivorgabs251204412v1>#</a></h3><p><strong>Authors:</strong> Haoxiang Zhan, Jae Kwang Kim, Yumou Qiu
<strong>Venue:</strong> arXiv (2025)</p><p>Multi-source learning is an emerging area of research in statistics, where information from multiple datasets with heterogeneous distributions is combined to estimate the parameter of interest for a target population without observed responses. We propose a high-dimensional debiased calibration (HDC) method and a multi-source HDC (MHDC) estimator for general estimating equations. The HDC method uses a novel approach to achieve Neyman orthogonality for the target parameter via high-dimensional covariate balancing on an augmented set of covariates. It avoids the augmented inverse probability weighting formulation and leads to an easier optimization algorithm for the target parameter in estimating equations and M-estimation. The proposed MHDC estimator integrates multi-source data while supporting flexible specifications for both density ratio and outcome regression models, achieving multiple robustness against model misspecification. Its asymptotic normality is established, and a specification test is proposed to examine the transferability condition for the multi-source data. Compared to the linear combination of single-source HDC estimators, the MHDC estimator improves efficiency by jointly utilizing all data sources. Through simulation studies, we show that the MHDC estimator accommodates multiple sources and multiple working models effectively and performs better than the existing doubly robust estimators for multi-source learning. An empirical analysis of a meteorological dataset demonstrates the utility of the proposed method in practice.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04412v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04412v1">üìÑ Download PDF</a></p><hr><h3 id=performance-evaluation-of-transfer-learning-based-medical-image-classification-techniques-for-disease-detectionhttpsarxivorgabs251204397v1><a href=https://arxiv.org/abs/2512.04397v1>Performance Evaluation of Transfer Learning Based Medical Image Classification Techniques for Disease Detection</a><a hidden class=anchor aria-hidden=true href=#performance-evaluation-of-transfer-learning-based-medical-image-classification-techniques-for-disease-detectionhttpsarxivorgabs251204397v1>#</a></h3><p><strong>Authors:</strong> Zeeshan Ahmad, Shudi Bao, Meng Chen
<strong>Venue:</strong> arXiv (2025)</p><p>Medical image classification plays an increasingly vital role in identifying various diseases by classifying medical images, such as X-rays, MRIs and CT scans, into different categories based on their features. In recent years, deep learning techniques have attracted significant attention in medical image classification. However, it is usually infeasible to train an entire large deep learning model from scratch. To address this issue, one of the solutions is the transfer learning (TL) technique, where a pre-trained model is reused for a new task. In this paper, we present a comprehensive analysis of TL techniques for medical image classification using deep convolutional neural networks. We evaluate six pre-trained models (AlexNet, VGG16, ResNet18, ResNet34, ResNet50, and InceptionV3) on a custom chest X-ray dataset for disease detection. The experimental results demonstrate that InceptionV3 consistently outperforms other models across all the standard metrics. The ResNet family shows progressively better performance with increasing depth, whereas VGG16 and AlexNet perform reasonably well but with lower accuracy. In addition, we also conduct uncertainty analysis and runtime comparison to assess the robustness and computational efficiency of these models. Our findings reveal that TL is beneficial in most cases, especially with limited data, but the extent of improvement depends on several factors such as model architecture, dataset size, and domain similarity between source and target tasks. Moreover, we demonstrate that with a well-trained feature extractor, only a lightweight feedforward model is enough to provide efficient prediction. As such, this study contributes to the understanding of TL in medical image classification, and provides insights for selecting appropriate models based on specific requirements.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04397v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04397v1">üìÑ Download PDF</a></p><hr><h3 id=mini-supernovae-from-white-dwarf-neutron-star-mergers-viewing-angle-dependent-spectra-and-lightcurveshttpsarxivorgabs251204378v1><a href=https://arxiv.org/abs/2512.04378v1>Mini-supernovae from white dwarf-neutron star mergers: Viewing-angle-dependent spectra and lightcurves</a><a hidden class=anchor aria-hidden=true href=#mini-supernovae-from-white-dwarf-neutron-star-mergers-viewing-angle-dependent-spectra-and-lightcurveshttpsarxivorgabs251204378v1>#</a></h3><p><strong>Authors:</strong> Yacheng Kang, Jin-Ping Zhu, Lijing Shao, Jiahang Zhong, Jinghao Zhang, Bing Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>Unstable mass transfer may occur during white dwarf-neutron star (WD-NS) mergers, in which the WD can be tidally disrupted and form an accretion disk around the NS. Such an accretion disk can produce unbound wind ejecta, with synthesized $^{56}\mathrm{Ni}$ mixed in. Numerical simulations reveal that this unbound ejecta should be strongly polar-dominated, which may cause the following radioactive-powered thermal transient to be viewing-angle-dependent. This issue has so far received limited investigation.
We investigate how the intrinsically non-spherical geometry of WD-NS wind ejecta affects the viewing-angle dependence of the thermal transients. Using a two-dimensional axisymmetric ejecta configuration and incorporating heating from the radioactive decay of $^{56}\mathrm{Ni}$, we employ a semi-analytical discretization scheme to simulate the observed viewing-angle-dependent photospheric evolution, as well as the resulting spectra and lightcurves. The observed photosphere evolves over time and depends strongly on the viewing angle: off-axis observers can see deeper, hotter inner layers of the ejecta and larger projected photospheric areas compared to on-axis observers. For a fiducial WD-NS merger producing 0.3 solar mass of ejecta and 0.01 solar mass of synthesized $^{56}\mathrm{Ni}$, the resulting peak optical absolute magnitudes of the transient span from ~ -12 mag along the polar direction to ~ -16 mag along the equatorial direction, corresponding to luminosities of $10^{40}$-$10^{42}$ erg s$^{-1}$. The typical peak timescales are expected to be 3-10 d. We for the first time explore the viewing-angle effect on WD-NS merger transients. Since their ejecta composition and energy sources resemble those of supernovae, yet WD-NS merger transients are dimmer and evolve more rapidly, we propose using &ldquo;mini-supernovae&rdquo; to describe the thermal emission following WD-NS mergers.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04378v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04378v1">üìÑ Download PDF</a></p><hr><h3 id=retrieving-missing-data-in-electron-diffraction-of-gas-phase-moleculeshttpsarxivorgabs251204352v1><a href=https://arxiv.org/abs/2512.04352v1>Retrieving missing data in electron diffraction of gas-phase molecules</a><a hidden class=anchor aria-hidden=true href=#retrieving-missing-data-in-electron-diffraction-of-gas-phase-moleculeshttpsarxivorgabs251204352v1>#</a></h3><p><strong>Authors:</strong> Yanwei Xiong, Nikhil Kumar Pachisia, Martin Centurion
<strong>Venue:</strong> arXiv (2025)</p><p>We report an iterative algorithm to retrieve accurate real space information from gas electron diffraction measurements with missing data at low momentum transfer. The algorithm is similar to phase retrieval algorithms which transform signals back and forth between the signal domain and the Fourier domain and apply constraints to retrieve the missing phase. The difference in our case is that the goal is not retrieval of the phase of the diffraction signal but the missing data at low momentum transfer, which is necessary for generating the real-space pair distribution function. The missing data is a common problem in static and ultrafast gas phase electron diffraction experiments due to experimental constraints. We demonstrated successful restoration of the missing data in simulated data and in experimentally measured diffraction signals of static and photo-dissociated trifluoroiodomethane and iodobenzene molecules.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04352v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04352v1">üìÑ Download PDF</a></p><hr><h3 id=asymptotic-constraints-for-1d-planar-grey-photon-diffusion-from-linear-transport-with-special-relativistic-effectshttpsarxivorgabs251204342v1><a href=https://arxiv.org/abs/2512.04342v1>Asymptotic constraints for 1D planar grey photon diffusion from linear transport with special-relativistic effects</a><a hidden class=anchor aria-hidden=true href=#asymptotic-constraints-for-1d-planar-grey-photon-diffusion-from-linear-transport-with-special-relativistic-effectshttpsarxivorgabs251204342v1>#</a></h3><p><strong>Authors:</strong> Ryan T. Wollaeger, Jim E. Morel, Kendra P. Long, Mathew A. Cleveland, Robert B. Lowrie
<strong>Venue:</strong> arXiv (2025)</p><p>We derive a grey linear diffusion equation for photons with respect to inertial (or lab-frame) space and time, using asymptotic analysis in 1D planar geometry. The solution of the equation is the comoving radiation energy density. Our analysis does not make use of assumptions about the magnitude of velocity; instead we derive an asymptotic scaling in the lab frame such that we avoid apparent non-physical pathologies that are encountered with the standard static-matter scaling. We permit the photon direction to be continuous (as opposed to constraining the analysis to discrete ordinates). The result is a drift-diffusion equation in the lab frame for comoving radiation energy density, with an adiabatic term that matches the standard semi-relativistic diffusion equation. Following a recent study for discrete directions, this equation reduces to a pure advection equation as the velocity approaches the speed of light. We perform preliminary numerical experiments comparing solutions to relativistic lab-frame Monte Carlo transport and to the well-known semi-relativistic diffusion equation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04342v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04342v1">üìÑ Download PDF</a></p><hr><h3 id=interactions-between-internal-solitary-waves-and-floating-canopieshttpsarxivorgabs251204321v1><a href=https://arxiv.org/abs/2512.04321v1>Interactions Between Internal Solitary Waves and Floating Canopies</a><a hidden class=anchor aria-hidden=true href=#interactions-between-internal-solitary-waves-and-floating-canopieshttpsarxivorgabs251204321v1>#</a></h3><p><strong>Authors:</strong> Jen-Ping Chu, Mitul Luhar, Patrick Lynett
<strong>Venue:</strong> arXiv (2025)</p><p>Interactions between internal solitary waves and floating canopies of varying length and porosity are examined via laboratory experiments and complementary simulations for a miscible, two-layer system. In both approaches, internal solitary waves of varying amplitudes are generated by a jet-array mechanism that is driven by the nonlinear eKdV solution. Pycnocline displacements, phase speeds, and velocity fields are obtained using synchronized planar laser-induced fluorescence and particle imaging velocimetry systems in the experiment. In the simulations, the canopy is represented as a porous zone with prescribed porosity and hydraulic conductivity determined by the Kozeny-Carman model, which is validated by comparing simulated and measured horizontal velocity profiles. The higher-porosity (transitional) canopy produces a nearly monotonic, albeit minor, amplitude reduction and negligible wave energy dissipation after the interaction. However, the shear layer developed at the bottom edge of the lower-porosity (dense) canopy grows to a comparable strength as the shear sustained by the internal solitary wave profile at the pycnocline. The vortex pair generated by this shear accelerates the upper-layer fluid beneath the canopy, leading to complex nonlinear amplitude modulation and significant wave transformation. With an extended canopy length, the internal solitary waves settle to a quasi-steady state with a significant phase speed reduction. Upon the wave exiting the canopy, flow separation at the downstream edge of the canopy again pairs with the shear at the pycnocline, inducing an intensified jet. This complex interaction leads to energy transfer between kinetic and potential energy under the dense canopy.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04321v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04321v1">üìÑ Download PDF</a></p><hr><h3 id=probing-evaporating-black-holes-with-modular-flow-in-sykhttpsarxivorgabs251204318v1><a href=https://arxiv.org/abs/2512.04318v1>Probing Evaporating Black Holes with Modular Flow in SYK</a><a hidden class=anchor aria-hidden=true href=#probing-evaporating-black-holes-with-modular-flow-in-sykhttpsarxivorgabs251204318v1>#</a></h3><p><strong>Authors:</strong> Nicol√≤ Bragagnolo, S. Prem Kumar
<strong>Venue:</strong> arXiv (2025)</p><p>We study the effect of modular flow on correlation functions of fermions in the Sachdev-Ye-Kitaev (SYK) model coupled weakly to a bath, which we take to be another SYK model. The system and bath, together are prepared in the thermofield double (TFD) state, and we focus on the effect of modular flow generated by the reduced density matrix for the SYK system, obtained by tracing out the bath. We show, in the late time limit, that modular flowed correlators of two Majorana fermions, single-sided and two-sided, exhibit non-trivial singularities. Beyond a critical value of the modular parameter, the ``modular scrambling time", the singularity structure shows correlations being transferred from one boundary to the other. The calculations are performed by employing the replica trick in Euclidean time and appropriately analytically continuing to real time. Exploiting the connection between modular flow generators and SL$(2,{\mathbb R})$ boosts we use the microscopic picture to reconstruct the dual bulk modular flow in two-sided AdS$_2$ black hole spacetime. Fixed points of the flow allow to identify quantum extremal surfaces (QES) demarcating the entanglement wedge of the boundary system and the island. We show that bulk modular flow can move fermion insertions near the right boundary past the horizon leading to lightcone singularities in appropriately smeared boundary correlators, probing physics beyond the horizon.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04318v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04318v1">üìÑ Download PDF</a></p><hr><h3 id=universal-quantum-interconnects-via-phase-coherent-four-wave-mixinghttpsarxivorgabs251204312v1><a href=https://arxiv.org/abs/2512.04312v1>Universal Quantum Interconnects via Phase-Coherent Four-Wave Mixing</a><a hidden class=anchor aria-hidden=true href=#universal-quantum-interconnects-via-phase-coherent-four-wave-mixinghttpsarxivorgabs251204312v1>#</a></h3><p><strong>Authors:</strong> Hao Zhang, Yang Xu, Linshan Sun, Wei Cui, Robert W. Boyd, Sergio Carbajo
<strong>Venue:</strong> arXiv (2025)</p><p>Quantum transduction, which enables the coherent conversion of quantum information between disparate physical platforms, is a cornerstone for realizing scalable and interoperable quantum networks. Among various approaches, parametric frequency mixing processes such as four-wave mixing (FWM) offer a promising pathway toward efficient and low-noise transduction. In this work, we demonstrate the feasibility of coherent quantum state transfer by indirectly verifying high-fidelity wavefunction&rsquo;s phase mapping (>99%) from the input field to the generated output field wave. Using a gas-filled hollow-core capillary fiber, we systematically investigate spectral phase evolution across a broad range, including infrared (IR) to ultraviolet (UV) transitions, as well as conversions from telecom-band (1550 nm) to visible (516 nm) and deep-UV (308 nm) wavelengths. Our results reveal that strong phase coherence can be maintained throughout these diverse conversion regimes. Because quantum properties such as coherence and entanglement are intrinsically encoded in both the amplitude and phase of a photonic wavefunction, preserving spectral phase is essential for faithful quantum information transfer. We further show that efficient and phase-preserving transduction can be achieved by tuning system parameters, offering valuable insights into nonlinear coupling dynamics. These findings establish a promising foundation for advancing FWM-based quantum transduction schemes and open new avenues for integrating heterogeneous quantum systems across wide spectral domains within future quantum communication networks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04312v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04312v1">üìÑ Download PDF</a></p><hr><h3 id=inference-time-stochastic-refinement-of-gru-normalizing-flow-for-real-time-video-motion-transferhttpsarxivorgabs251204282v1><a href=https://arxiv.org/abs/2512.04282v1>Inference-time Stochastic Refinement of GRU-Normalizing Flow for Real-time Video Motion Transfer</a><a hidden class=anchor aria-hidden=true href=#inference-time-stochastic-refinement-of-gru-normalizing-flow-for-real-time-video-motion-transferhttpsarxivorgabs251204282v1>#</a></h3><p><strong>Authors:</strong> Tasmiah Haque, Srinjoy Das
<strong>Venue:</strong> arXiv (2025)</p><p>Real-time video motion transfer applications such as immersive gaming and vision-based anomaly detection require accurate yet diverse future predictions to support realistic synthesis and robust downstream decision making under uncertainty. To improve the diversity of such sequential forecasts we propose a novel inference-time refinement technique that combines Gated Recurrent Unit-Normalizing Flows (GRU-NF) with stochastic sampling methods. While GRU-NF can capture multimodal distributions through its integration of normalizing flows within a temporal forecasting framework, its deterministic transformation structure can limit expressivity. To address this, inspired by Stochastic Normalizing Flows (SNF), we introduce Markov Chain Monte Carlo (MCMC) steps during GRU-NF inference, enabling the model to explore a richer output space and better approximate the true data distribution without retraining. We validate our approach in a keypoint-based video motion transfer pipeline, where capturing temporally coherent and perceptually diverse future trajectories is essential for realistic samples and low bandwidth communication. Experiments show that our inference framework, Gated Recurrent Unit- Stochastic Normalizing Flows (GRU-SNF) outperforms GRU-NF in generating diverse outputs without sacrificing accuracy, even under longer prediction horizons. By injecting stochasticity during inference, our approach captures multimodal behavior more effectively. These results highlight the potential of integrating stochastic dynamics with flow-based sequence models for generative time series forecasting.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04282v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04282v1">üìÑ Download PDF</a></p><hr><h3 id=unilight-a-unified-representation-for-lightinghttpsarxivorgabs251204267v1><a href=https://arxiv.org/abs/2512.04267v1>UniLight: A Unified Representation for Lighting</a><a hidden class=anchor aria-hidden=true href=#unilight-a-unified-representation-for-lightinghttpsarxivorgabs251204267v1>#</a></h3><p><strong>Authors:</strong> Zitian Zhang, Iliyan Georgiev, Michael Fischer, Yannick Hold-Geoffroy, Jean-Fran√ßois Lalonde, Valentin Deschaintre
<strong>Venue:</strong> arXiv (2025)</p><p>Lighting has a strong influence on visual appearance, yet understanding and representing lighting in images remains notoriously difficult. Various lighting representations exist, such as environment maps, irradiance, spherical harmonics, or text, but they are incompatible, which limits cross-modal transfer. We thus propose UniLight, a joint latent space as lighting representation, that unifies multiple modalities within a shared embedding. Modality-specific encoders for text, images, irradiance, and environment maps are trained contrastively to align their representations, with an auxiliary spherical-harmonics prediction task reinforcing directional understanding. Our multi-modal data pipeline enables large-scale training and evaluation across three tasks: lighting-based retrieval, environment-map generation, and lighting control in diffusion-based image synthesis. Experiments show that our representation captures consistent and transferable lighting features, enabling flexible manipulation across modalities.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04267v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04267v1">üìÑ Download PDF</a></p><hr><h3 id=primordial-black-holes-from-inflation-with-a-spectator-fieldhttpsarxivorgabs251204199v1><a href=https://arxiv.org/abs/2512.04199v1>Primordial Black Holes from Inflation with a Spectator Field</a><a hidden class=anchor aria-hidden=true href=#primordial-black-holes-from-inflation-with-a-spectator-fieldhttpsarxivorgabs251204199v1>#</a></h3><p><strong>Authors:</strong> Dario L. Lorenzoni, Sarah R. Geller, David I. Kaiser, Evan McDonough
<strong>Venue:</strong> arXiv (2025)</p><p>How is the production of primordial black holes (PBHs) in single-field models of inflation impacted by the presence of additional scalar fields? We consider the effect of a spectator field - a free scalar field with sub-Hubble mass, no direct coupling to the inflaton, and which makes a subdominant contribution to the total energy density - in the context of single-field models of inflation featuring a transient phase of ultra-slow roll (USR) evolution. Despite the modest title, a spectator field can have a dramatic impact: the slow-roll evolution of the spectator prevents the combined inflaton-and-spectator system from entering into USR, which naively might be expected to preclude the production of PBHs. However, we demonstrate that the growth of perturbations is maintained or enhanced by the spectator, through the rich interplay of curvature and isocurvature perturbations. We show in a model-independent way that the single-field phase of ultra-slow-roll is replaced by two turns in field space encompassing a phase of tachyonic instability for the isocurvature perturbations and a transfer of power from isocurvature to curvature modes. Furthermore, we highlight a degeneracy between the fine-tuning of the feature in the inflaton potential and the parameters of the spectator, leading to an overall resilience of model predictions to parameter variations. This makes it easier for the underlying PBH model to accommodate both high-precision CMB constraints and production of PBHs in the asteroid-mass range.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04199v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04199v1">üìÑ Download PDF</a></p><hr><h3 id=resolving-the-terrestrial-planet-forming-region-of-hd-172555-with-alma-i-post-impact-dust-distributionhttpsarxivorgabs251204154v1><a href=https://arxiv.org/abs/2512.04154v1>Resolving the terrestrial planet-forming region of HD 172555 with ALMA: I. Post-impact dust distribution</a><a hidden class=anchor aria-hidden=true href=#resolving-the-terrestrial-planet-forming-region-of-hd-172555-with-alma-i-post-impact-dust-distributionhttpsarxivorgabs251204154v1>#</a></h3><p><strong>Authors:</strong> Zoe Roumeliotis, Luca Matr√†, Grant M. Kennedy, Sebastian Marino, Kate Y. L. Su, David J. Wilner, Mark C. Wyatt, Alan P. Jackson
<strong>Venue:</strong> arXiv (2025)</p><p>Giant impacts between planetary embryos are a natural step in the terrestrial planet formation process and are expected to create disks of warm debris in the terrestrial regions of their stars. Understanding the gas and dust debris produced in giant impacts is vital for comprehending and constraining models of planetary collisions. We reveal the distribution of millimeter grains in the giant impact debris disk of HD 172555 for the first time, using new ALMA 0.87 mm observations at $\sim$80 mas (2.3 au) resolution. We modeled the interferometric visibilities to obtain basic spatial properties of the disk, and compared it to the disk&rsquo;s dust and gas distributions at other wavelengths. We detect the star and dust emission from an inclined disk out to $\sim$9 au and down to 2.3 au (on-sky) from the central star, with no significant asymmetry in the dust distribution. Radiative transfer modeling of the visibilities indicates the disk surface density distribution of millimeter grains most likely peaks around $\sim$5 au, while the width inferred remains model-dependent at the S/N of the data. We highlight an outward radial offset of the small grains traced by scattered light observations compared to the millimeter grains, which could be explained by the combined effect of gas drag and radiation pressure in the presence of large enough gas densities. Furthermore, SED modeling implies a size distribution slope for the millimeter grains consistent with the expectation of collisional evolution and flatter than inferred for the micron-sized grains, implying a break in the grain size distribution and confirming an overabundance of small grains.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04154v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04154v1">üìÑ Download PDF</a></p><hr><h3 id=enhancing-next-token-prediction-based-pre-training-for-jet-foundation-modelshttpsarxivorgabs251204149v1><a href=https://arxiv.org/abs/2512.04149v1>Enhancing next token prediction based pre-training for jet foundation models</a><a hidden class=anchor aria-hidden=true href=#enhancing-next-token-prediction-based-pre-training-for-jet-foundation-modelshttpsarxivorgabs251204149v1>#</a></h3><p><strong>Authors:</strong> Joschka Birk, Anna Hallin, Gregor Kasieczka, Nikol Madzharova, Ian Pang, David Shih
<strong>Venue:</strong> arXiv (2025)</p><p>Next token prediction is an attractive pre-training task for jet foundation models, in that it is simulation free and enables excellent generative capabilities that can transfer across datasets. Here we study multiple improvements to next token prediction, building on the initial work of OmniJet-$Œ±$. Instead of tokenizing particles and subsequently only using the token-ID as the model input for both the generative and the classification task, we adopt a hybrid setup, which allows us to use continuous feature vectors as model input while only using token-IDs in the next token prediction target. Secondly, we explore a combined pre-training strategy that combines masked particle modeling and generative learning objectives. Taken together, these changes greatly improve the performance in downstream classification tasks without any loss in generative performance.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04149v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04149v1">üìÑ Download PDF</a></p><hr><h3 id=unique-lives-shared-world-learning-from-single-life-videoshttpsarxivorgabs251204085v1><a href=https://arxiv.org/abs/2512.04085v1>Unique Lives, Shared World: Learning from Single-Life Videos</a><a hidden class=anchor aria-hidden=true href=#unique-lives-shared-world-learning-from-single-life-videoshttpsarxivorgabs251204085v1>#</a></h3><p><strong>Authors:</strong> Tengda Han, Sayna Ebrahimi, Dilara Gokay, Li Yang Ku, Maks Ovsjanikov, Iva Babukova, Daniel Zoran, Viorica Patraucean, Joao Carreira, Andrew Zisserman, Dima Damen
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce the &ldquo;single-life&rdquo; learning paradigm, where we train a distinct vision model exclusively on egocentric videos captured by one individual. We leverage the multiple viewpoints naturally captured within a single life to learn a visual encoder in a self-supervised manner. Our experiments demonstrate three key findings. First, models trained independently on different lives develop a highly aligned geometric understanding. We demonstrate this by training visual encoders on distinct datasets each capturing a different life, both indoors and outdoors, as well as introducing a novel cross-attention-based metric to quantify the functional alignment of the internal representations developed by different models. Second, we show that single-life models learn generalizable geometric representations that effectively transfer to downstream tasks, such as depth estimation, in unseen environments. Third, we demonstrate that training on up to 30 hours from one week of the same person&rsquo;s life leads to comparable performance to training on 30 hours of diverse web data, highlighting the strength of single-life representation learning. Overall, our results establish that the shared structure of the world, both leads to consistency in models trained on individual lives, and provides a powerful signal for visual representation learning.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04085v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04085v1">üìÑ Download PDF</a></p><hr><h3 id=domain-feature-collapse-implications-for-out-of-distribution-detection-and-solutionshttpsarxivorgabs251204034v1><a href=https://arxiv.org/abs/2512.04034v1>Domain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions</a><a hidden class=anchor aria-hidden=true href=#domain-feature-collapse-implications-for-out-of-distribution-detection-and-solutionshttpsarxivorgabs251204034v1>#</a></h3><p><strong>Authors:</strong> Hong Yang, Devroop Kar, Qi Yu, Alex Ororbia, Travis Desell
<strong>Venue:</strong> arXiv (2025)</p><p>Why do state-of-the-art OOD detection methods exhibit catastrophic failure when models are trained on single-domain datasets? We provide the first theoretical explanation for this phenomenon through the lens of information theory. We prove that supervised learning on single-domain data inevitably produces domain feature collapse &ndash; representations where I(x_d; z) = 0, meaning domain-specific information is completely discarded. This is a fundamental consequence of information bottleneck optimization: models trained on single domains (e.g., medical images) learn to rely solely on class-specific features while discarding domain features, leading to catastrophic failure when detecting out-of-domain samples (e.g., achieving only 53% FPR@95 on MNIST). We extend our analysis using Fano&rsquo;s inequality to quantify partial collapse in practical scenarios. To validate our theory, we introduce Domain Bench, a benchmark of single-domain datasets, and demonstrate that preserving I(x_d; z) > 0 through domain filtering (using pretrained representations) resolves the failure mode. While domain filtering itself is conceptually straightforward, its effectiveness provides strong empirical evidence for our information-theoretic framework. Our work explains a puzzling empirical phenomenon, reveals fundamental limitations of supervised learning in narrow domains, and has broader implications for transfer learning and when to fine-tune versus freeze pretrained models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04034v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04034v1">üìÑ Download PDF</a></p><hr><h3 id=value-gradient-guidance-for-flow-matching-alignmenthttpsarxivorgabs251205116v1><a href=https://arxiv.org/abs/2512.05116v1>Value Gradient Guidance for Flow Matching Alignment</a><a hidden class=anchor aria-hidden=true href=#value-gradient-guidance-for-flow-matching-alignmenthttpsarxivorgabs251205116v1>#</a></h3><p><strong>Authors:</strong> Zhen Liu, Tim Z. Xiao, Carles Domingo-Enrich, Weiyang Liu, Dinghuai Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>While methods exist for aligning flow matching models&ndash;a popular and effective class of generative models&ndash;with human preferences, existing approaches fail to achieve both adaptation efficiency and probabilistically sound prior preservation. In this work, we leverage the theory of optimal control and propose VGG-Flow, a gradient-matching-based method for finetuning pretrained flow matching models. The key idea behind this algorithm is that the optimal difference between the finetuned velocity field and the pretrained one should be matched with the gradient field of a value function. This method not only incorporates first-order information from the reward model but also benefits from heuristic initialization of the value function to enable fast adaptation. Empirically, we show on a popular text-to-image flow matching model, Stable Diffusion 3, that our method can finetune flow matching models under limited computational budgets while achieving effective and prior-preserving alignment.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05116v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05116v1">üìÑ Download PDF</a></p><hr><h3 id=neuralremaster-phase-preserving-diffusion-for-structure-aligned-generationhttpsarxivorgabs251205106v1><a href=https://arxiv.org/abs/2512.05106v1>NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation</a><a hidden class=anchor aria-hidden=true href=#neuralremaster-phase-preserving-diffusion-for-structure-aligned-generationhttpsarxivorgabs251205106v1>#</a></h3><p><strong>Authors:</strong> Yu Zeng, Charles Ochoa, Mingyuan Zhou, Vishal M. Patel, Vitor Guizilini, Rowan McAllister
<strong>Venue:</strong> arXiv (2025)</p><p>Standard diffusion corrupts data using Gaussian noise whose Fourier coefficients have random magnitudes and random phases. While effective for unconditional or text-to-image generation, corrupting phase components destroys spatial structure, making it ill-suited for tasks requiring geometric consistency, such as re-rendering, simulation enhancement, and image-to-image translation. We introduce Phase-Preserving Diffusion œÜ-PD, a model-agnostic reformulation of the diffusion process that preserves input phase while randomizing magnitude, enabling structure-aligned generation without architectural changes or additional parameters. We further propose Frequency-Selective Structured (FSS) noise, which provides continuous control over structural rigidity via a single frequency-cutoff parameter. œÜ-PD adds no inference-time cost and is compatible with any diffusion model for images or videos. Across photorealistic and stylized re-rendering, as well as sim-to-real enhancement for driving planners, œÜ-PD produces controllable, spatially aligned results. When applied to the CARLA simulator, œÜ-PD improves CARLA-to-Waymo planner performance by 50%. The method is complementary to existing conditioning approaches and broadly applicable to image-to-image and video-to-video generation. Videos, additional examples, and code are available on our \href{https://yuzeng-at-tri.github.io/ppd-page/}{project page}.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05106v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05106v1">üìÑ Download PDF</a></p><hr><h3 id=deep-forcing-training-free-long-video-generation-with-deep-sink-and-participative-compressionhttpsarxivorgabs251205081v1><a href=https://arxiv.org/abs/2512.05081v1>Deep Forcing: Training-Free Long Video Generation with Deep Sink and Participative Compression</a><a hidden class=anchor aria-hidden=true href=#deep-forcing-training-free-long-video-generation-with-deep-sink-and-participative-compressionhttpsarxivorgabs251205081v1>#</a></h3><p><strong>Authors:</strong> Jung Yi, Wooseok Jang, Paul Hyunbin Cho, Jisu Nam, Heeji Yoon, Seungryong Kim
<strong>Venue:</strong> arXiv (2025)</p><p>Recent advances in autoregressive video diffusion have enabled real-time frame streaming, yet existing solutions still suffer from temporal repetition, drift, and motion deceleration. We find that naively applying StreamingLLM-style attention sinks to video diffusion leads to fidelity degradation and motion stagnation. To overcome this, we introduce Deep Forcing, which consists of two training-free mechanisms that address this without any fine-tuning. Specifically, 1) Deep Sink dedicates half of the sliding window to persistent sink tokens and re-aligns their temporal RoPE phase to the current timeline, stabilizing global context during long rollouts. 2) Participative Compression performs importance-aware KV cache pruning that preserves only tokens actively participating in recent attention while safely discarding redundant and degraded history, minimizing error accumulation under out-of-distribution length generation. Together, these components enable over 12x extrapolation (e.g. 5s-trained to 60s+ generation) with better imaging quality than LongLive, better aesthetic quality than RollingForcing, almost maintaining overall consistency, and substantial gains in dynamic degree, all while maintaining real-time generation. Our results demonstrate that training-free KV-cache management can match or exceed training-based approaches for autoregressively streaming long-video generation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05081v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05081v1">üìÑ Download PDF</a></p><hr><h3 id=debt-growth-and-the-carbon-lock-inhttpsarxivorgabs251205063v1><a href=https://arxiv.org/abs/2512.05063v1>Debt, Growth, and the Carbon Lock-In</a><a hidden class=anchor aria-hidden=true href=#debt-growth-and-the-carbon-lock-inhttpsarxivorgabs251205063v1>#</a></h3><p><strong>Authors:</strong> Silvia Montagnania, Barnabe Ledoux, David Lacoste
<strong>Venue:</strong> arXiv (2025)</p><p>We develop a macro-financial model that establishes a link between credit dynamics, economic growth, and cumulative carbon emissions. It is based on an extension of Kelly&rsquo;s model, a framework derived from information theory and investment theory, applied here to understand macro-financial and climate dynamics. This approach complements traditional Integrated Assessment Models (IAMs) by explicitly linking financial dynamics to cumulative emissions, enabling the assessment of policy alignment (or misalignment) with net-zero pathways. We find that injecting debt into the system increases short-term production gains, but at the expense of higher bankruptcy risk and cumulative emissions. Thus, the model reveals a double constraint: financially, debt requires growth to be repaid; ecologically, growth requires energy, and therefore emissions. When the intrinsic growth rate falls below the interest rate, the probability of solvency drops to zero: the economy enters a zone of structural instability. The model then identifies an optimal leverage frontier: beyond a certain threshold, additional debt no longer fuels real wealth; it only increases the risk of bankruptcy and carbon debt. Our model is calibrated using multi-decade macroeconomic and emissions data from several countries, including the United States, China, France, and Denmark. Our results confirm that the correlation between cumulative debt, cumulative GDP, and cumulative emissions remains strong, regardless of the political structure of credit. In our current financial system, credit expansion amplifies GDP growth and associated emissions, thereby locking economies into higher cumulative carbon trajectories, even as energy efficiency improves through innovation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05063v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05063v1">üìÑ Download PDF</a></p><hr><h3 id=millimetre-wave-comb-generated-by-an-optical-microcombhttpsarxivorgabs251205005v1><a href=https://arxiv.org/abs/2512.05005v1>Millimetre-Wave Comb Generated by an Optical Microcomb</a><a hidden class=anchor aria-hidden=true href=#millimetre-wave-comb-generated-by-an-optical-microcombhttpsarxivorgabs251205005v1>#</a></h3><p><strong>Authors:</strong> Luke Peters, Antonio Cutrona, Andrew R. Cooper, Luana Olivieri, Fedor Getman, Vittorio Cecconi, Nitish Paul, Debayan Das, Maxwell Rowley, Sai T. Chu, Brent E. Little, Roberto Morandotti, David J. Moss, Juan S. Totero Gongora, Alessia Pasquazi, Marco Peccianti
<strong>Venue:</strong> arXiv (2025)</p><p>Metrological-grade millimetre wave baseband comb sources covering the subterahertz window are a key building block for next-generation wireless communications, precision sensing, and positioning systems. While optical microcombs have set new benchmarks in ultra-low phase noise single-frequency microwave generation, to date, no microcomb source has directly produced a millimetre-wave baseband comb. Here, we present a 50 GHz repetition rate carrier-envelope offset estabilised millimetre-wave baseband comb source covering the sub-terahertz region, generated from an optical microcomb source. Our microresonator-filtered microcomb enables direct, coherent downconversion via photoconductive antennas, even without external amplification. The metrological-grade optical soliton source produces single-cycle, naturally zero carrier-envelope offset millimetrewave baseband combs. It supports time-domain spectroscopy without any need to temporally align the source and detection pulses, as the ultra-high phase coherence allows significant differences between the optical paths of the source and detection pulses, which we tested over 8m, finding no degradation even in freerunning operation. Finally, the multisoliton operation regime provides a simple way of spectrally tailoring the microwave output by selecting different optical soliton states.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05005v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05005v1">üìÑ Download PDF</a></p><hr><h3 id=evolutionary-architecture-search-through-grammar-based-sequence-alignmenthttpsarxivorgabs251204992v1><a href=https://arxiv.org/abs/2512.04992v1>Evolutionary Architecture Search through Grammar-Based Sequence Alignment</a><a hidden class=anchor aria-hidden=true href=#evolutionary-architecture-search-through-grammar-based-sequence-alignmenthttpsarxivorgabs251204992v1>#</a></h3><p><strong>Authors:</strong> Adri G√≥mez Mart√≠n, Felix M√∂ller, Steven McDonagh, Monica Abella, Manuel Desco, Elliot J. Crowley, Aaron Klein, Linus Ericsson
<strong>Venue:</strong> arXiv (2025)</p><p>Neural architecture search (NAS) in expressive search spaces is a computationally hard problem, but it also holds the potential to automatically discover completely novel and performant architectures. To achieve this we need effective search algorithms that can identify powerful components and reuse them in new candidate architectures. In this paper, we introduce two adapted variants of the Smith-Waterman algorithm for local sequence alignment and use them to compute the edit distance in a grammar-based evolutionary architecture search. These algorithms enable us to efficiently calculate a distance metric for neural architectures and to generate a set of hybrid offspring from two parent models. This facilitates the deployment of crossover-based search heuristics, allows us to perform a thorough analysis on the architectural loss landscape, and track population diversity during search. We highlight how our method vastly improves computational complexity over previous work and enables us to efficiently compute shortest paths between architectures. When instantiating the crossover in evolutionary searches, we achieve competitive results, outperforming competing methods. Future work can build upon this new tool, discovering novel components that can be used more broadly across neural architecture design, and broadening its applications beyond NAS.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04992v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04992v1">üìÑ Download PDF</a></p><hr><h3 id=learning-causality-for-longitudinal-datahttpsarxivorgabs251204980v1><a href=https://arxiv.org/abs/2512.04980v1>Learning Causality for Longitudinal Data</a><a hidden class=anchor aria-hidden=true href=#learning-causality-for-longitudinal-datahttpsarxivorgabs251204980v1>#</a></h3><p><strong>Authors:</strong> Mouad EL Bouchattaoui
<strong>Venue:</strong> arXiv (2025)</p><p>This thesis develops methods for causal inference and causal representation learning (CRL) in high-dimensional, time-varying data.
The first contribution introduces the Causal Dynamic Variational Autoencoder (CDVAE), a model for estimating Individual Treatment Effects (ITEs) by capturing unobserved heterogeneity in treatment response driven by latent risk factors that affect only outcomes. CDVAE comes with theoretical guarantees on valid latent adjustment and generalization bounds for ITE error. Experiments on synthetic and real datasets show that CDVAE outperforms baselines, and that state-of-the-art models greatly improve when augmented with its latent substitutes, approaching oracle performance without access to true adjustment variables.
The second contribution proposes an efficient framework for long-term counterfactual regression based on RNNs enhanced with Contrastive Predictive Coding (CPC) and InfoMax. It captures long-range dependencies under time-varying confounding while avoiding the computational cost of transformers, achieving state-of-the-art results and introducing CPC into causal inference.
The third contribution advances CRL by addressing how latent causes manifest in observed variables. We introduce a model-agnostic interpretability layer based on the geometry of the decoder Jacobian. A sparse self-expression prior induces modular, possibly overlapping groups of observed features aligned with shared latent influences. We provide recovery guarantees in both disjoint and overlapping settings and show that meaningful latent-to-observed structure can be recovered without anchor features or single-parent assumptions. Scalable Jacobian-based regularization techniques are also developed.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04980v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04980v1">üìÑ Download PDF</a></p><hr><h3 id=exploring-youtubes-political-communication-networks-during-the-2024-french-electionshttpsarxivorgabs251204971v1><a href=https://arxiv.org/abs/2512.04971v1>Exploring YouTube&rsquo;s Political Communication Networks during the 2024 French Elections</a><a hidden class=anchor aria-hidden=true href=#exploring-youtubes-political-communication-networks-during-the-2024-french-electionshttpsarxivorgabs251204971v1>#</a></h3><p><strong>Authors:</strong> Caroline Violot, Vera Sosnovik, Mathias Humbert
<strong>Venue:</strong> arXiv (2025)</p><p>In 2024, France was shaken by the far-right National Rally&rsquo;s victory in the European elections. In response to this unprecedented result, French President Emmanuel Macron dissolved the National Assembly, triggering legislative elections just two weeks later. A whirlwind campaign followed, partly on social media, as is now the norm, and concluded with the victory of a left-wing coalition. This article examines the YouTube activity of two key actors during this period, news media and politicians, and the commenting behavior they generated. We built a dataset of 35 news media channels, 28 politicians and parties channels, 43.5k videos posted from three months before the European elections to one week after the second round of the legislative elections, and 7.4M associated comments. We examined upload activity and engagement across political orientations and used network analysis methods to uncover the structure of their commenting communities. We also identified politicians&rsquo; appearances on news media channels and assessed their impact on commenting user bases. Our findings show that, among politicians and parties channels, far-right and left-wing ones were significantly more active and received substantially higher engagement (views, likes, and comments) than other groups, with denser and more clustered commenting communities. About 7% of commenters commented across political orientations and were much more active than in-group commenters. News media channels tended to favor politically aligned guests, while centrist politicians were over-represented. Finally, politicians&rsquo; presence in the videos of a specific news media channel increased the share of commenters who were active on this channel and political channels, regardless of their orientation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04971v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04971v1">üìÑ Download PDF</a></p><hr><h3 id=environment-aware-channel-inference-via-cross-modal-flow-from-multimodal-sensing-to-wireless-channelshttpsarxivorgabs251204966v1><a href=https://arxiv.org/abs/2512.04966v1>Environment-Aware Channel Inference via Cross-Modal Flow: From Multimodal Sensing to Wireless Channels</a><a hidden class=anchor aria-hidden=true href=#environment-aware-channel-inference-via-cross-modal-flow-from-multimodal-sensing-to-wireless-channelshttpsarxivorgabs251204966v1>#</a></h3><p><strong>Authors:</strong> Guangming Liang, Mingjie Yang, Dongzhu Liu, Paul Henderson, Lajos Hanzo
<strong>Venue:</strong> arXiv (2025)</p><p>Accurate channel state information (CSI) underpins reliable and efficient wireless communication. However, acquiring CSI via pilot estimation incurs substantial overhead, especially in massive multiple-input multiple-output (MIMO) systems operating in high-Doppler environments. By leveraging the growing availability of environmental sensing data, this treatise investigates pilot-free channel inference that estimates complete CSI directly from multimodal observations, including camera images, LiDAR point clouds, and GPS coordinates. In contrast to prior studies that rely on predefined channel models, we develop a data-driven framework that formulates the sensing-to-channel mapping as a cross-modal flow matching problem. The framework fuses multimodal features into a latent distribution within the channel domain, and learns a velocity field that continuously transforms the latent distribution toward the channel distribution. To make this formulation tractable and efficient, we reformulate the problem as an equivalent conditional flow matching objective and incorporate a modality alignment loss, while adopting low-latency inference mechanisms to enable real-time CSI estimation. In experiments, we build a procedural data generator based on Sionna and Blender to support realistic modeling of sensing scenes and wireless propagation. System-level evaluations demonstrate significant improvements over pilot- and sensing-based benchmarks in both channel estimation accuracy and spectral efficiency for the downstream beamforming task.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04966v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04966v1">üìÑ Download PDF</a></p><hr><h3 id=probing-tev-afterglow-emission-of-grb221009a-with-gaussian-structured-jet-in-wind-driven-mediumhttpsarxivorgabs251204893v1><a href=https://arxiv.org/abs/2512.04893v1>Probing TeV Afterglow Emission of GRB~221009A with Gaussian Structured jet in Wind-driven medium</a><a hidden class=anchor aria-hidden=true href=#probing-tev-afterglow-emission-of-grb221009a-with-gaussian-structured-jet-in-wind-driven-mediumhttpsarxivorgabs251204893v1>#</a></h3><p><strong>Authors:</strong> T. Mondal, S. Chakraborty, L. Resmi, D. Bose
<strong>Venue:</strong> arXiv (2025)</p><p>Recent detections of very high energy (VHE; GeV-TeV) photons from gamma-ray burst (GRB) afterglows, most notably the extreme event GRB 221009A, require refined models that include realistic jet structures and complex circumburst environments. The jet&rsquo;s angular structure is crucial for shaping afterglow emission. Our recent work demonstrates that Gaussian jets, with their smooth angular decline, naturally produce early bright peaks for on-axis observers and delayed, softer, dimmer peaks at higher inclinations. The gradual decline suppresses excessive lateral expansion, unlike the sharp edge in top-hat jets, making Gaussian jets a compelling alternative to both top-hat and other structured-jet models. Here we implement a Gaussian structured-jet model to explain TeV afterglows from adiabatic forward shocks propagating in a wind-driven medium. We show that the TeV peak time and flux depend sensitively on jet geometry, kinetic energy, wind density, and on microphysical parameter ratios that scale the SSC component. We identify the afterglow parameter space that is favourable for detecting sub-TeV photons with the Cherenkov Telescope Array (CTA), finding that only about ten per cent of simulated TeV events exceed CTA sensitivity in a wind medium. These detections arise from near core-aligned views, with high kinetic energy and wind density, moderate initial Lorentz factor and downstream magnetic field, and a relatively large fraction of energy in nonthermal electrons. Applying this model to GRB 221009A, we perform multi-band fits including wind-modified dynamics, Klein-Nishina effects, and EBL attenuation, and find that a mildly off-axis geometry reproduces the observed X-ray and GeV-TeV light curves.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04893v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04893v1">üìÑ Download PDF</a></p><hr><h3 id=performance-optimization-and-characterization-of-7-pad-resistive-picosec-micromegas-detectorshttpsarxivorgabs251204842v1><a href=https://arxiv.org/abs/2512.04842v1>Performance Optimization and Characterization of 7-pad Resistive PICOSEC Micromegas Detectors</a><a hidden class=anchor aria-hidden=true href=#performance-optimization-and-characterization-of-7-pad-resistive-picosec-micromegas-detectorshttpsarxivorgabs251204842v1>#</a></h3><p><strong>Authors:</strong> A. Kallitsopoulou, R. Aleksan, S. Aune, J. Bortfeldt, F. Brunbauer, M. Brunoldi, J. Datta, D. Desforge, G. Fanourakis, D. Fiorina, K. J. Floethner, M. Gallinaro, F. Garcia, I. Giomataris, K. Gnanvo, F. J. Iguaz, D. Janssens, F. Jeanneau, M. Kovacic, B. Kross, P. Legou, M. Lisowska, J. Liu, M. Lupberger, I. Maniatis, J. McKisson, Y. Meng, H. Muller, E. Oliveri, G. Orlandini, A. Pandey, T. Papaevangelou, M. Pomorski, E. F. Ribas, L. Ropelewski, D. Sampsonidis, L. Scharenberg, T. Schneider, E. Scorsone, L. Sohl, M. van Stenis, Y. Tsipolitis, S. E. Tzamarias, A. Utrobicic, I. Vai, R. Veenhof, P. Vitulo, X. Wang, S. White, W. Xi, Z. Zhang, Y. Zhou
<strong>Venue:</strong> arXiv (2025)</p><p>We present a comprehensive characterization of resistive PICOSEC Micromegas detector prototypes, tested under identical conditions, constant drift gap, field configurations, and photocathode at the CERN SPS H4 beam line. This work provides a proof of concept for the use of resistive layer technology in gaseous timing detectors, demonstrating that robustness can be improved without compromising the excellent timing performance of PICOSEC Micromegas. Different resistive architectures and values were explored to optimize stability and ensure reliable long-term operation in challenging experimental environments. The prototype with a 10MŒ© resistive layer achieved the best overall performance, with a timing resolution of 22.900 {\pm} 0.002 ps and a spatial resolution of 1.190 {\pm} 0.003 mm, while charge sharing across multiple pads enabled combined timing resolutions below 28 ps. A lower-resistivity (200kŒ©) configuration exhibited enhanced charge spread, leading to minor systematic offsets in reconstructed pad centers, yet maintained robust timing and spatial performance. Capacitive charge-sharing architectures improved spatial resolution in some regions but suffered from signal attenuation and nonuniform charge distributions, resulting in slightly degraded timing (33.300 {\pm} 0.002 ps) and complex localization patterns. Mechanical precision, particularly readout planarity and photocathode alignment, was identified as critical for uniform detector response. These studies benchmark the potential of resistive layers for gaseous timing detectors and provide a foundation for scalable designs with optimized timing and spatial resolution across diverse experimental applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04842v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04842v1">üìÑ Download PDF</a></p><hr><h3 id=contract-driven-qoe-auditing-for-speech-and-singing-services-from-mos-regression-to-service-graphshttpsarxivorgabs251204827v1><a href=https://arxiv.org/abs/2512.04827v1>Contract-Driven QoE Auditing for Speech and Singing Services: From MOS Regression to Service Graphs</a><a hidden class=anchor aria-hidden=true href=#contract-driven-qoe-auditing-for-speech-and-singing-services-from-mos-regression-to-service-graphshttpsarxivorgabs251204827v1>#</a></h3><p><strong>Authors:</strong> Wenzhang Du
<strong>Venue:</strong> arXiv (2025)</p><p>Subjective mean opinion scores (MOS) remain the de-facto target for non-intrusive speech and singing quality assessment. However, MOS is a scalar that collapses heterogeneous user expectations, ignores service-level objectives, and is difficult to compare across deployment graphs. We propose a contract-driven QoE auditing framework: each service graph G is evaluated under a set of human-interpretable experience contracts C, yielding a contract-level satisfaction vector Q(G, C). We show that (i) classical MOS regression is a special case with a degenerate contract set, (ii) contract-driven quality is more stable than MOS under graph view transformations (e.g., pooling by system vs. by system type), and (iii) the effective sample complexity of learning contracts is governed by contract semantics rather than merely the dimensionality of C. We instantiate the framework on URGENT2024 MOS (6.9k speech utterances with raw rating vectors) and SingMOS v1 (7,981 singing clips; 80 systems). On URGENT, we train a contract-aware neural auditor on self-supervised WavLM embeddings; on SingMOS, we perform contract-driven graph auditing using released rating vectors and metadata without decoding audio. Empirically, our auditor matches strong MOS predictors in MOS accuracy while providing calibrated contract probabilities; on SingMOS, Q(G, C) exhibits substantially smaller cross-view drift than raw MOS and graph-only baselines; on URGENT, difficulty curves reveal that mis-specified &ldquo;simple&rdquo; contracts can be harder to learn than richer but better aligned contract sets.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04827v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04827v1">üìÑ Download PDF</a></p><hr><h3 id=hierarchical-matrix-approximability-of-inverse-of-convection-dominated-finite-element-matriceshttpsarxivorgabs251204824v1><a href=https://arxiv.org/abs/2512.04824v1>Hierarchical matrix approximability of inverse of convection dominated finite element matrices</a><a hidden class=anchor aria-hidden=true href=#hierarchical-matrix-approximability-of-inverse-of-convection-dominated-finite-element-matriceshttpsarxivorgabs251204824v1>#</a></h3><p><strong>Authors:</strong> Arthur Saunier, Leo Agelas, Ani Anciaux Sedrakian, Ibtihel Ben Gharbia, Xavier Claeys
<strong>Venue:</strong> arXiv (2025)</p><p>Several researchers have developed a rich toolbox of matrix compression techniques that exploit structure and redundancy in large matrices. Classical methods such as the block low-rank format and the Fast Multipole Method make it possible to manipulate very large systems by representing them in a reduced form. Among the most sophisticated tools in this area are hierarchical matrices (H-matrices), which exploit local properties of the underlying kernel or operator to approximate matrix blocks by low-rank factors, organized in a recursive hierarchy. H-matrices offer a flexible and scalable framework, yielding nearly linear complexity in both storage and computation. Hierarchical matrix techniques, originally developed for boundary integral equations, have recently been applied to matrices stemming from the discretization of advection-dominated problems. However, their effectiveness is limited by the loss of coercivity induced by convection phenomena, where traditional methods fail. Initial work by Le Borne addressed this by modifying the admissibility criterion for structured grids with constant convection, but challenges remain for more general grids and advection fields. In this work, we propose a novel partitioning strategy based on &ldquo;convection tubes&rdquo;, clusters aligned with the convection vector field. This method does not require a structured grid or constant convection, overcoming the limitations of previous approaches. We present both theoretical analyses and numerical experiments, that demonstrate the efficiency and robustness of our method for convection-dominated PDEs on unstructured grids. The approach builds on a P√©clet-robust Caccioppoli inequality, crucial for handling convection-dominated problems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04824v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04824v1">üìÑ Download PDF</a></p><hr><h3 id=yingmusic-singer-zero-shot-singing-voice-synthesis-and-editing-with-annotation-free-melody-guidancehttpsarxivorgabs251204779v1><a href=https://arxiv.org/abs/2512.04779v1>YingMusic-Singer: Zero-shot Singing Voice Synthesis and Editing with Annotation-free Melody Guidance</a><a hidden class=anchor aria-hidden=true href=#yingmusic-singer-zero-shot-singing-voice-synthesis-and-editing-with-annotation-free-melody-guidancehttpsarxivorgabs251204779v1>#</a></h3><p><strong>Authors:</strong> Junjie Zheng, Chunbo Hao, Guobin Ma, Xiaoyu Zhang, Gongyu Chen, Chaofan Ding, Zihao Chen, Lei Xie
<strong>Venue:</strong> arXiv (2025)</p><p>Singing Voice Synthesis (SVS) remains constrained in practical deployment due to its strong dependence on accurate phoneme-level alignment and manually annotated melody contours, requirements that are resource-intensive and hinder scalability. To overcome these limitations, we propose a melody-driven SVS framework capable of synthesizing arbitrary lyrics following any reference melody, without relying on phoneme-level alignment. Our method builds on a Diffusion Transformer (DiT) architecture, enhanced with a dedicated melody extraction module that derives melody representations directly from reference audio. To ensure robust melody encoding, we employ a teacher model to guide the optimization of the melody extractor, alongside an implicit alignment mechanism that enforces similarity distribution constraints for improved melodic stability and coherence. Additionally, we refine duration modeling using weakly annotated song data and introduce a Flow-GRPO reinforcement learning strategy with a multi-objective reward function to jointly enhance pronunciation clarity and melodic fidelity. Experiments show that our model achieves superior performance over existing approaches in both objective measures and subjective listening tests, especially in zero-shot and lyric adaptation settings, while maintaining high audio quality without manual annotation. This work offers a practical and scalable solution for advancing data-efficient singing voice synthesis. To support reproducibility, we release our inference code and model checkpoints.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04779v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04779v1">üìÑ Download PDF</a></p><hr><h3 id=cig-mae-cross-modal-information-guided-masked-autoencoder-for-self-supervised-wifi-sensinghttpsarxivorgabs251204723v1><a href=https://arxiv.org/abs/2512.04723v1>CIG-MAE: Cross-Modal Information-Guided Masked Autoencoder for Self-Supervised WiFi Sensing</a><a hidden class=anchor aria-hidden=true href=#cig-mae-cross-modal-information-guided-masked-autoencoder-for-self-supervised-wifi-sensinghttpsarxivorgabs251204723v1>#</a></h3><p><strong>Authors:</strong> Gang Liu, Yanling Hao, Yixuan Zou
<strong>Venue:</strong> arXiv (2025)</p><p>Human Action Recognition using WiFi Channel State Information (CSI) has emerged as an attractive alternative to vision-based methods due to its ubiquity, device-agnostic nature, and inherent privacy-preserving capabilities. However, the high cost of manual annotation and the limited scale of publicly available CSI datasets restrict the performance of supervised approaches. Self-supervised learning (SSL) offers a promising avenue, but existing contrastive paradigms rely on data augmentations that conflict with the physical semantics of radio signals and require large-batch training, making them poorly suited for CSI. To overcome these challenges, we introduce CIG-MAE &ndash; a Cross-modal Information-Guided Masked Autoencoder &ndash; that reconstructs both the amplitude and phase of CSI using a symmetric dual-stream architecture with a high masking ratio. Specifically, we propose an Adaptive Information-Guided Masking strategy that dynamically allocates attention to time-frequency regions with high information density to improve learning efficiency, and incorporate a Barlow Twins regularizer to align cross-modal representations without negative samples. Experiments on three public datasets show that CIG-MAE consistently outperforms SOTA SSL methods and even surpasses a fully supervised baseline, demonstrating superior data efficiency, robustness, and representation generalization.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04723v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04723v1">üìÑ Download PDF</a></p><hr><h3 id=m3-tts-multi-modal-dit-alignment--mel-latent-for-zero-shot-high-fidelity-speech-synthesishttpsarxivorgabs251204720v1><a href=https://arxiv.org/abs/2512.04720v1>M3-TTS: Multi-modal DiT Alignment & Mel-latent for Zero-shot High-fidelity Speech Synthesis</a><a hidden class=anchor aria-hidden=true href=#m3-tts-multi-modal-dit-alignment--mel-latent-for-zero-shot-high-fidelity-speech-synthesishttpsarxivorgabs251204720v1>#</a></h3><p><strong>Authors:</strong> Xiaopeng Wang, Chunyu Qiang, Ruibo Fu, Zhengqi Wen, Xuefei Liu, Yukun Liu, Yuzhe Liang, Kang Yin, Yuankun Xie, Heng Xie, Chenxing Li, Chen Zhang, Changsheng Li
<strong>Venue:</strong> arXiv (2025)</p><p>Non-autoregressive (NAR) text-to-speech synthesis relies on length alignment between text sequences and audio representations, constraining naturalness and expressiveness. Existing methods depend on duration modeling or pseudo-alignment strategies that severely limit naturalness and computational efficiency. We propose M3-TTS, a concise and efficient NAR TTS paradigm based on multi-modal diffusion transformer (MM-DiT) architecture. M3-TTS employs joint diffusion transformer layers for cross-modal alignment, achieving stable monotonic alignment between variable-length text-speech sequences without pseudo-alignment requirements. Single diffusion transformer layers further enhance acoustic detail modeling. The framework integrates a mel-vae codec that provides 3* training acceleration. Experimental results on Seed-TTS and AISHELL-3 benchmarks demonstrate that M3-TTS achieves state-of-the-art NAR performance with the lowest word error rates (1.36% English, 1.31% Chinese) while maintaining competitive naturalness scores. Code and demos will be available at <a href=https://wwwwxp.github.io/M3-TTS>https://wwwwxp.github.io/M3-TTS</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04720v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04720v1">üìÑ Download PDF</a></p><hr><h3 id=timesnet-gen-deep-learning-based-site-specific-strong-motion-generationhttpsarxivorgabs251204694v1><a href=https://arxiv.org/abs/2512.04694v1>TimesNet-Gen: Deep Learning-based Site Specific Strong Motion Generation</a><a hidden class=anchor aria-hidden=true href=#timesnet-gen-deep-learning-based-site-specific-strong-motion-generationhttpsarxivorgabs251204694v1>#</a></h3><p><strong>Authors:</strong> Baris Yilmaz, Bevan Deniz Cilgin, Erdem Akag√ºnd√ºz, Salih Tileylioglu
<strong>Venue:</strong> arXiv (2025)</p><p>Effective earthquake risk reduction relies on accurate site-specific evaluations. This requires models that can represent the influence of local site conditions on ground motion characteristics. In this context, data driven approaches that learn site controlled signatures from recorded ground motions offer a promising direction. We address strong ground motion generation from time-domain accelerometer records and introduce the TimesNet-Gen, a time-domain conditional generator. The approach uses a station specific latent bottleneck. We evaluate generation by comparing HVSR curves and fundamental site-frequency $f_0$ distributions between real and generated records per station, and summarize station specificity with a score based on the $f_0$ distribution confusion matrices. TimesNet-Gen achieves strong station-wise alignment and compares favorably with a spectrogram-based conditional VAE baseline for site-specific strong motion synthesis. Our codes are available via <a href=https://github.com/brsylmz23/TimesNet-Gen>https://github.com/brsylmz23/TimesNet-Gen</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04694v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04694v1">üìÑ Download PDF</a></p><hr><h3 id=towards-ethical-multi-agent-systems-of-large-language-models-a-mechanistic-interpretability-perspectivehttpsarxivorgabs251204691v1><a href=https://arxiv.org/abs/2512.04691v1>Towards Ethical Multi-Agent Systems of Large Language Models: A Mechanistic Interpretability Perspective</a><a hidden class=anchor aria-hidden=true href=#towards-ethical-multi-agent-systems-of-large-language-models-a-mechanistic-interpretability-perspectivehttpsarxivorgabs251204691v1>#</a></h3><p><strong>Authors:</strong> Jae Hee Lee, Anne Lauscher, Stefano V. Albrecht
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) have been widely deployed in various applications, often functioning as autonomous agents that interact with each other in multi-agent systems. While these systems have shown promise in enhancing capabilities and enabling complex tasks, they also pose significant ethical challenges. This position paper outlines a research agenda aimed at ensuring the ethical behavior of multi-agent systems of LLMs (MALMs) from the perspective of mechanistic interpretability. We identify three key research challenges: (i) developing comprehensive evaluation frameworks to assess ethical behavior at individual, interactional, and systemic levels; (ii) elucidating the internal mechanisms that give rise to emergent behaviors through mechanistic interpretability; and (iii) implementing targeted parameter-efficient alignment techniques to steer MALMs towards ethical behaviors without compromising their performance.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04691v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04691v1">üìÑ Download PDF</a></p><hr><h3 id=a-chandra-view-of-spt-cl-j0217-5014-a-massive-galaxy-cluster-at-a-cosmic-intersection-at-z053httpsarxivorgabs251204689v1><a href=https://arxiv.org/abs/2512.04689v1>A Chandra view of SPT-CL J0217-5014: a massive galaxy cluster at a cosmic intersection at z=0.53</a><a hidden class=anchor aria-hidden=true href=#a-chandra-view-of-spt-cl-j0217-5014-a-massive-galaxy-cluster-at-a-cosmic-intersection-at-z053httpsarxivorgabs251204689v1>#</a></h3><p><strong>Authors:</strong> Dan Hu, Shida Fan, Zhongsheng Yuan, Junjie Mao, Norbert Werner, Yuanyuan Su, Fran√ßois Mernier, Yuanyuan Zhao, Liyi Gu, Haiguang Xu
<strong>Venue:</strong> arXiv (2025)</p><p>Galaxy clusters trace the densest regions of the cosmic web and are crucial laboratories for studying the thermodynamic and chemical evolution of the intracluster medium (ICM). We present a Chandra study of the massive galaxy cluster SPT-CL J0217-5014 ($z \sim 0.53$; $M_{\rm 500} \sim 3 \times 10^{14}<del>\rm M_{\odot}$), previously reported as a Swift serendipitous clusters with the highest Fe abundance ($\sim 1.3\pm 0.4$ $\rm Z_{\odot}$ within $\sim 1&rsquo;.7$) and a potentially disturbed morphology. The X-ray morphology reveals a disturbed ICM with a surface brightness edge at $\sim 0&rsquo;.26$ ($\sim 100$ kpc) to the west and a tail-like feature extending towards the east. The best-fit metal abundance within 1&rsquo;.5 ($\sim 0.7\rm R_{500}$) is $0.61_{-0.23}^{+0.26}</del>\rm Z_{\odot}$. The derived central electron number density, entropy, and cooling time classify this system as a non-cool-core cluster, suggesting that merger activity has likely disrupted the possible pre-existing cool core. At larger radii ($\sim 1&rsquo; - 2&rsquo;$), we detect excess X-ray emission to the south, spatially aligned with a filamentary distribution of red galaxies, indicating ongoing accretion along an intracluster filament. Based on the DESI DR9 cross-matched optical clusters and photometric redshifts, we identify three nearby, lower-mass clusters that likely trace the large-scale structures, suggesting that SPT-CL~J0217-5014 is the primary node of a dynamically active environment where past mergers and anisotropic accretion along cosmic filaments have shaped the present-day ICM.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04689v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04689v1">üìÑ Download PDF</a></p><hr><h3 id=geschlechts√ºbergreifende-maskulina-im-sprachgebrauch-eine-korpusbasierte-untersuchung-zu-lexemspezifischen-unterschiedenhttpsarxivorgabs251204683v1><a href=https://arxiv.org/abs/2512.04683v1>Geschlechts√ºbergreifende Maskulina im Sprachgebrauch Eine korpusbasierte Untersuchung zu lexemspezifischen Unterschieden</a><a hidden class=anchor aria-hidden=true href=#geschlechts√ºbergreifende-maskulina-im-sprachgebrauch-eine-korpusbasierte-untersuchung-zu-lexemspezifischen-unterschiedenhttpsarxivorgabs251204683v1>#</a></h3><p><strong>Authors:</strong> Carolin Mueller-Spitzer, Samira Ochs, Jan Oliver Ruediger, Sascha Wolfer
<strong>Venue:</strong> arXiv (2025)</p><p>This study examines the distribution and linguistic characteristics of generic masculines (GM) in contemporary German press texts. The use of masculine personal nouns to refer to mixed-gender groups or unspecified individuals has been widely debated in academia and the public, with con-flicting perspectives on its gender-neutrality. While psycholinguistic studies suggest that GM is more readily associated with male referents, corpus-based analyses of its actual use remain scarce. We investigate GM in a large corpus of press texts, focusing on lexeme-specific differences across dif-ferent types of personal nouns. We conducted manual annotations of the whole inflectional para-digm of 21 personal nouns, resulting in 6,195 annotated tokens. Our findings reveal considerable differences between lexical items, especially between passive role nouns and prestige-related per-sonal nouns. On a grammatical level, we find that GM occurs predominantly in the plural and in indefinite noun phrases. Furthermore, our data shows that GM is not primarily used to denote entire classes of people, as has been previously claimed. By providing an empirical insight into the use of GM in authentic written language, we contribute to a more nuanced understanding of its forms and manifestations. These findings provide a solid basis for aligning linguistic stimuli in psy-cholinguistic studies more closely with real-world language use.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04683v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04683v1">üìÑ Download PDF</a></p><hr><h3 id=generative-ai-for-self-adaptive-systems-state-of-the-art-and-research-roadmaphttpsarxivorgabs251204680v1><a href=https://arxiv.org/abs/2512.04680v1>Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap</a><a hidden class=anchor aria-hidden=true href=#generative-ai-for-self-adaptive-systems-state-of-the-art-and-research-roadmaphttpsarxivorgabs251204680v1>#</a></h3><p><strong>Authors:</strong> Jialong Li, Mingyue Zhang, Nianyu Li, Danny Weyns, Zhi Jin, Kenji Tei
<strong>Venue:</strong> arXiv (2025)</p><p>Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this paper aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI&rsquo;s within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04680v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04680v1">üìÑ Download PDF</a></p><hr><h3 id=i2i-bench-a-comprehensive-benchmark-suite-for-image-to-image-editing-modelshttpsarxivorgabs251204660v1><a href=https://arxiv.org/abs/2512.04660v1>I2I-Bench: A Comprehensive Benchmark Suite for Image-to-Image Editing Models</a><a hidden class=anchor aria-hidden=true href=#i2i-bench-a-comprehensive-benchmark-suite-for-image-to-image-editing-modelshttpsarxivorgabs251204660v1>#</a></h3><p><strong>Authors:</strong> Juntong Wang, Jiarui Wang, Huiyu Duan, Jiaxiang Kang, Guangtao Zhai, Xiongkuo Min
<strong>Venue:</strong> arXiv (2025)</p><p>Image editing models are advancing rapidly, yet comprehensive evaluation remains a significant challenge. Existing image editing benchmarks generally suffer from limited task scopes, insufficient evaluation dimensions, and heavy reliance on manual annotations, which significantly constrain their scalability and practical applicability. To address this, we propose \textbf{I2I-Bench}, a comprehensive benchmark for image-to-image editing models, which features (i) diverse tasks, encompassing 10 task categories across both single-image and multi-image editing tasks, (ii) comprehensive evaluation dimensions, including 30 decoupled and fine-grained evaluation dimensions with automated hybrid evaluation methods that integrate specialized tools and large multimodal models (LMMs), and (iii) rigorous alignment validation, justifying the consistency between our benchmark evaluations and human preferences. Using I2I-Bench, we benchmark numerous mainstream image editing models, investigating the gaps and trade-offs between editing models across various dimensions. We will open-source all components of I2I-Bench to facilitate future research.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04660v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04660v1">üìÑ Download PDF</a></p><hr><h3 id=reflection-satisfaction-tradeoff-investigating-impact-of-reflection-on-student-engagement-with-ai-generated-programming-hintshttpsarxivorgabs251204630v1><a href=https://arxiv.org/abs/2512.04630v1>Reflection-Satisfaction Tradeoff: Investigating Impact of Reflection on Student Engagement with AI-Generated Programming Hints</a><a hidden class=anchor aria-hidden=true href=#reflection-satisfaction-tradeoff-investigating-impact-of-reflection-on-student-engagement-with-ai-generated-programming-hintshttpsarxivorgabs251204630v1>#</a></h3><p><strong>Authors:</strong> Heeryung Choi, Tung Phung, Mengyan Wu, Adish Singla, Christopher Brooks
<strong>Venue:</strong> arXiv (2025)</p><p>Generative AI tools, such as AI-generated hints, are increasingly integrated into programming education to offer timely, personalized support. However, little is known about how to effectively leverage these hints while ensuring autonomous and meaningful learning. One promising approach involves pairing AI-generated hints with reflection prompts, asking students to review and analyze their learning, when they request hints. This study investigates the interplay between AI-generated hints and different designs of reflection prompts in an online introductory programming course. We conducted a two-trial field experiment. In Trial 1, students were randomly assigned to receive prompts either before or after receiving hints, or no prompt at all. Each prompt also targeted one of three SRL phases: planning, monitoring, and evaluation. In Trial 2, we examined two types of prompt guidance: directed (offering more explicit and structured guidance) and open (offering more general and less constrained guidance). Findings show that students in the before-hint (RQ1), planning (RQ2), and directed (RQ3) prompt groups produced higher-quality reflections but reported lower satisfaction with AI-generated hints than those in other conditions. Immediate performance did not differ across conditions. This negative relationship between reflection quality and hint satisfaction aligns with previous work on student mental effort and satisfaction. Our results highlight the need to reconsider how AI models are trained and evaluated for education, as prioritizing user satisfaction can undermine deeper learning.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04630v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04630v1">üìÑ Download PDF</a></p><hr><h3 id=usersimcrs-v2-simulation-based-evaluation-for-conversational-recommender-systemshttpsarxivorgabs251204588v1><a href=https://arxiv.org/abs/2512.04588v1>UserSimCRS v2: Simulation-Based Evaluation for Conversational Recommender Systems</a><a hidden class=anchor aria-hidden=true href=#usersimcrs-v2-simulation-based-evaluation-for-conversational-recommender-systemshttpsarxivorgabs251204588v1>#</a></h3><p><strong>Authors:</strong> Nolwenn Bernard, Krisztian Balog
<strong>Venue:</strong> arXiv (2025)</p><p>Resources for simulation-based evaluation of conversational recommender systems (CRSs) are scarce. The UserSimCRS toolkit was introduced to address this gap. In this work, we present UserSimCRS v2, a significant upgrade aligning the toolkit with state-of-the-art research. Key extensions include an enhanced agenda-based user simulator, introduction of large language model-based simulators, integration for a wider range of CRSs and datasets, and new LLM-as-a-judge evaluation utilities. We demonstrate these extensions in a case study.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04588v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04588v1">üìÑ Download PDF</a></p><hr><h3 id=sam3-i-segment-anything-with-instructionshttpsarxivorgabs251204585v1><a href=https://arxiv.org/abs/2512.04585v1>SAM3-I: Segment Anything with Instructions</a><a hidden class=anchor aria-hidden=true href=#sam3-i-segment-anything-with-instructionshttpsarxivorgabs251204585v1>#</a></h3><p><strong>Authors:</strong> Jingjing Li, Yue Feng, Yuchen Guo, Jincai Huang, Yongri Piao, Qi Bi, Miao Zhang, Xiaoqi Zhao, Qiang Chen, Shihao Zou, Wei Ji, Huchuan Lu, Li Cheng
<strong>Venue:</strong> arXiv (2025)</p><p>Segment Anything Model 3 (SAM3) has advanced open-vocabulary segmentation through promptable concept segmentation, allowing users to segment all instances corresponding to a given concept, typically specified with short noun-phrase (NP) prompts. While this marks the first integration of language-level concepts within the SAM family, real-world usage typically requires far richer expressions that include attributes, spatial relations, functionalities, actions, states, and even implicit reasoning over instances. Currently, SAM3 relies on external multi-modal agents to convert complex instructions into NPs and then conduct iterative mask filtering. However, these NP-level concepts remain overly coarse, often failing to precisely represent a specific instance. In this work, we present SAM3-I, an enhanced framework that unifies concept-level understanding and instruction-level reasoning within the SAM family. SAM3-I introduces an instruction-aware cascaded adaptation mechanism that progressively aligns expressive instruction semantics with SAM3&rsquo;s existing vision-language representations, enabling direct instruction-following segmentation without sacrificing its original concept-driven capabilities. Furthermore, we design a structured instruction taxonomy spanning concept, simple, and complex levels, and develop a scalable data engine to construct a dataset with diverse instruction-mask pairs. Experiments show that SAM3-I delivers appealing performance, demonstrating that SAM3 can be effectively extended to follow natural-language instructions while preserving its strong concept grounding. We open-source SAM3-I and provide practical fine-tuning workflows, enabling researchers to adapt it to domain-specific applications. The source code is available here.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04585v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04585v1">üìÑ Download PDF</a></p><hr><h3 id=investigating-the-h-i-mass-size-relation-using-the-simba-cosmological-simulationshttpsarxivorgabs251204582v1><a href=https://arxiv.org/abs/2512.04582v1>Investigating the H i mass-size relation using the Simba cosmological simulations</a><a hidden class=anchor aria-hidden=true href=#investigating-the-h-i-mass-size-relation-using-the-simba-cosmological-simulationshttpsarxivorgabs251204582v1>#</a></h3><p><strong>Authors:</strong> Omphile Rabyang, Ed Elson
<strong>Venue:</strong> arXiv (2025)</p><p>Observational studies have established a remarkably tight power-law relationship between the H I masses and sizes of late-type galaxies, known as the H I mass-size relation. This relation has been shown to persist across various models of a galaxy&rsquo;s H I surface density profile. Using the Simba cosmological simulations, we investigate the robustness of this relation under different feedback prescriptions, including cases where specific feedback mechanisms are absent. While the global properties of galaxies are significantly affected by changes in feedback, the H I mass-size relation remains intact. Moreover, its parameters consistently align with the best available empirical measurements. We analyze the H I mass distributions of galaxies and demonstrate that, regardless of the feedback scenario, galaxies within a given H I mass bin exhibit outer H I radial profiles well approximated by an exponential function. Furthermore, the exponential decline rate remains remarkably similar across different physical prescriptions. We attribute the persistence of the H I mass-size relation to this inherent self-similarity in the H I mass distributions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04582v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04582v1">üìÑ Download PDF</a></p><hr><h3 id=diffusion-fine-tuning-via-reparameterized-policy-gradient-of-the-soft-q-functionhttpsarxivorgabs251204559v1><a href=https://arxiv.org/abs/2512.04559v1>Diffusion Fine-Tuning via Reparameterized Policy Gradient of the Soft Q-Function</a><a hidden class=anchor aria-hidden=true href=#diffusion-fine-tuning-via-reparameterized-policy-gradient-of-the-soft-q-functionhttpsarxivorgabs251204559v1>#</a></h3><p><strong>Authors:</strong> Hyeongyu Kang, Jaewoo Lee, Woocheol Shin, Kiyoung Om, Jinkyoo Park
<strong>Venue:</strong> arXiv (2025)</p><p>Diffusion models excel at generating high-likelihood samples but often require alignment with downstream objectives. Existing fine-tuning methods for diffusion models significantly suffer from reward over-optimization, resulting in high-reward but unnatural samples and degraded diversity. To mitigate over-optimization, we propose \textbf{Soft Q-based Diffusion Finetuning (SQDF)}, a novel KL-regularized RL method for diffusion alignment that applies a reparameterized policy gradient of a training-free, differentiable estimation of the soft Q-function. SQDF is further enhanced with three innovations: a discount factor for proper credit assignment in the denoising process, the integration of consistency models to refine Q-function estimates, and the use of an off-policy replay buffer to improve mode coverage and manage the reward-diversity trade-off. Our experiments demonstrate that SQDF achieves superior target rewards while preserving diversity in text-to-image alignment. Furthermore, in online black-box optimization, SQDF attains high sample efficiency while maintaining naturalness and diversity.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04559v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04559v1">üìÑ Download PDF</a></p><hr><h3 id=adapt-learning-task-mixtures-for-budget-constrained-instruction-tuninghttpsarxivorgabs251204555v1><a href=https://arxiv.org/abs/2512.04555v1>ADAPT: Learning Task Mixtures for Budget-Constrained Instruction Tuning</a><a hidden class=anchor aria-hidden=true href=#adapt-learning-task-mixtures-for-budget-constrained-instruction-tuninghttpsarxivorgabs251204555v1>#</a></h3><p><strong>Authors:</strong> Pritam Kadasi, Abhishek Upperwal, Mayank SIngh
<strong>Venue:</strong> arXiv (2025)</p><p>We propose ADAPT, a meta-learning algorithm that \emph{learns} task sampling proportions under an explicit token budget for multi-task instruction tuning. Instead of fixing task weights by hand, \adapt{} maintains a continuous distribution over tasks and updates it via meta-gradients of a smooth worst-case validation objective, inducing an adaptive curriculum that allocates more tokens to useful tasks while avoiding collapse. We instantiate ADAPT on three $\sim$1B-parameter open-weight LLMs (Gemma-3-1B, LLaMA-3.2-1B, Qwen-0.6B), training on 20 Natural Instructions task types under budgets of $1%$, $5%$, and $10%$ of the available supervised tokens, and compare against strong supervised fine-tuning baselines with uniform and size-proportional mixing. We conduct evaluations on 11 out-of-domain benchmarks spanning reasoning, reading comprehension, code generation, and instruction following, we find that ADAPT matches or slightly improves average downstream performance relative to the best static mixture, while using fewer effective training tokens and reallocating budget toward harder, benchmark-aligned tasks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04555v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04555v1">üìÑ Download PDF</a></p><hr><h3 id=gaussian-entropy-fields-driving-adaptive-sparsity-in-3d-gaussian-optimizationhttpsarxivorgabs251204542v1><a href=https://arxiv.org/abs/2512.04542v1>Gaussian Entropy Fields: Driving Adaptive Sparsity in 3D Gaussian Optimization</a><a hidden class=anchor aria-hidden=true href=#gaussian-entropy-fields-driving-adaptive-sparsity-in-3d-gaussian-optimizationhttpsarxivorgabs251204542v1>#</a></h3><p><strong>Authors:</strong> Hong Kuang, Jianchen Liu
<strong>Venue:</strong> arXiv (2025)</p><p>3D Gaussian Splatting (3DGS) has emerged as a leading technique for novel view synthesis, demonstrating exceptional rendering efficiency. \replaced[]{Well-reconstructed surfaces can be characterized by low configurational entropy, where dominant primitives clearly define surface geometry while redundant components are suppressed.}{The key insight is that well-reconstructed surfaces naturally exhibit low configurational entropy, where dominant primitives clearly define surface geometry while suppressing redundant components.} Three complementary technical contributions are introduced: (1) entropy-driven surface modeling via entropy minimization for low configurational entropy in primitive distributions; (2) adaptive spatial regularization using the Surface Neighborhood Redundancy Index (SNRI) and image entropy-guided weighting; (3) multi-scale geometric preservation through competitive cross-scale entropy alignment. Extensive experiments demonstrate that GEF achieves competitive geometric precision on DTU and T&amp;T benchmarks, while delivering superior rendering quality compared to existing methods on Mip-NeRF 360. Notably, superior Chamfer Distance (0.64) on DTU and F1 score (0.44) on T&amp;T are obtained, alongside the best SSIM (0.855) and LPIPS (0.136) among baselines on Mip-NeRF 360, validating the framework&rsquo;s ability to enhance surface reconstruction accuracy without compromising photometric fidelity.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04542v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04542v1">üìÑ Download PDF</a></p><hr><h3 id=completion-by-comprehension-guiding-code-generation-with-multi-granularity-understandinghttpsarxivorgabs251204538v1><a href=https://arxiv.org/abs/2512.04538v1>Completion by Comprehension: Guiding Code Generation with Multi-Granularity Understanding</a><a hidden class=anchor aria-hidden=true href=#completion-by-comprehension-guiding-code-generation-with-multi-granularity-understandinghttpsarxivorgabs251204538v1>#</a></h3><p><strong>Authors:</strong> Xinkui Zhao, Rongkai Liu, Yifan Zhang, Chen Zhi, Lufei Zhang, Guanjie Cheng, Yueshen Xu, Shuiguang Deng, Jianwei Yin
<strong>Venue:</strong> arXiv (2025)</p><p>As code completion task from function-level to repository-level, leveraging contextual information from large-scale codebases becomes a core challenge. However, existing retrieval-augmented generation (RAG) methods typically treat code as plain natural language, relying primarily on shallow semantic matching while overlooking structural semantics and code-specific dependencies. This limits their ability to capture control flow and underlying intent, ultimately constraining the quality of generated code. Therefore, we propose CoCo, a novel framework that enables code Completion by Comprehension of multi-granularity context from large-scale code repositories. CoCo employs static code analysis to extract structured context at the function, file, and project levels, capturing execution logic and semantic dependencies. It then adopts an graph-based multi-granularity context selection mechanism to filter out redundant information and remove noise. Consequently, the information is converted into natural language in a consistent manner, thereby functioning as explicit contextual prompts to guide subsequent code completion. Additionally, a structure-aware code re-ranker mechanism ensures alignment at both semantic and structural levels. Extensive experiments on CrossCodeEval and RepoEval benchmarks demonstrate that CoCo consistently surpasses state-of-the-art baselines, achieving up to 20.2% gains in EM. Moreover, the framework is model-agnostic and can be seamlessly integrated into existing methods, leading to significant performance.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04538v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04538v1">üìÑ Download PDF</a></p><hr><h3 id=flex-leveraging-fpga-cpu-synergy-for-mixed-cell-height-legalization-accelerationhttpsarxivorgabs251204527v1><a href=https://arxiv.org/abs/2512.04527v1>FLEX: Leveraging FPGA-CPU Synergy for Mixed-Cell-Height Legalization Acceleration</a><a hidden class=anchor aria-hidden=true href=#flex-leveraging-fpga-cpu-synergy-for-mixed-cell-height-legalization-accelerationhttpsarxivorgabs251204527v1>#</a></h3><p><strong>Authors:</strong> Xingyu Liu, Jiawei Liang, Linfeng Du, Yipu Zhang, Chaofang Ma, Hanwei Fan, Jiang Xu, Wei Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>In this work, we present FLEX, an FPGA-CPU accelerator for mixed-cell-height legalization tasks. We address challenges from the following perspectives. First, we optimize the task assignment strategy and perform an efficient task partition between FPGA and CPU to exploit their complementary strengths. Second, a multi-granularity pipelining technique is employed to accelerate the most time-consuming step, finding optimal placement position (FOP), in legalization. At last, we particularly target the computationally intensive cell shifting process in FOP, optimizing the design to align it seamlessly with the multi-granularity pipelining framework for further speedup. Experimental results show that FLEX achieves up to 18.3x and 5.4x speedups compared to state-of-the-art CPU-GPU and multi-threaded CPU legalizers with better scalability, while improving legalization quality by 4% and 1%.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04527v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04527v1">üìÑ Download PDF</a></p><hr><h3 id=pump-free-microwave-optical-quantum-transductionhttpsarxivorgabs251205096v1><a href=https://arxiv.org/abs/2512.05096v1>Pump Free Microwave-Optical Quantum Transduction</a><a hidden class=anchor aria-hidden=true href=#pump-free-microwave-optical-quantum-transductionhttpsarxivorgabs251205096v1>#</a></h3><p><strong>Authors:</strong> Fangxin Li, Jaesung Heo, Zhaoyou Wang, Andrew P. Higginbotham, Alexander A. High, Liang Jiang
<strong>Venue:</strong> arXiv (2025)</p><p>Distributed quantum computing involves superconducting computation nodes operating at microwave frequencies, which are connected by long-distance transmission lines that transmit photons at optical frequencies. Quantum transduction, which coherently converts between microwave and optical (M-O) photons, is a critical component of such an architecture. Current approaches are hindered by the unavoidable problem of device heating due to the optical pump. In this work, we propose a pump-free scheme based on color centers that generates time-bin encoded M-O Bell pairs. Our scheme first creates spin-photon entanglement and then converts the spin state into a time-bin-encoded microwave photon using a strongly coupled Purcell-enhanced resonator. In our protocol, the microwave retrieval is heralded by detecting the microwave signal with a three-level transmon. We have analyzed the resulting Bell state fidelity and generation probability of this protocol. Our simulation shows that by combining a state-of-the-art spin-optical interface with our proposed strongly-coupled spin-microwave design, the pump-free scheme can generate M-O Bell pairs at a heralding rate exceeding one kilohertz with near-unity fidelity, which establishes the scheme as a promising source for M-O Bell pairs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05096v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05096v1">üìÑ Download PDF</a></p><hr><h3 id=tokenizing-buildings-a-transformer-for-layout-synthesishttpsarxivorgabs251204832v1><a href=https://arxiv.org/abs/2512.04832v1>Tokenizing Buildings: A Transformer for Layout Synthesis</a><a hidden class=anchor aria-hidden=true href=#tokenizing-buildings-a-transformer-for-layout-synthesishttpsarxivorgabs251204832v1>#</a></h3><p><strong>Authors:</strong> Manuel Ladron de Guevara, Jinmo Rhee, Ardavan Bidgoli, Vaidas Razgaitis, Michael Bergin
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce Small Building Model (SBM), a Transformer-based architecture for layout synthesis in Building Information Modeling (BIM) scenes. We address the question of how to tokenize buildings by unifying heterogeneous feature sets of architectural elements into sequences while preserving compositional structure. Such feature sets are represented as a sparse attribute-feature matrix that captures room properties. We then design a unified embedding module that learns joint representations of categorical and possibly correlated continuous feature groups. Lastly, we train a single Transformer backbone in two modes: an encoder-only pathway that yields high-fidelity room embeddings, and an encoder-decoder pipeline for autoregressive prediction of room entities, referred to as Data-Driven Entity Prediction (DDEP). Experiments across retrieval and generative layout synthesis show that SBM learns compact room embeddings that reliably cluster by type and topology, enabling strong semantic retrieval. In DDEP mode, SBM produces functionally sound layouts, with fewer collisions and boundary violations and improved navigability.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04832v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04832v1">üìÑ Download PDF</a></p><hr><h3 id=the-initial-to-final-state-inverse-problem-with-unbounded-potentials-and-strichartz-estimateshttpsarxivorgabs251204796v1><a href=https://arxiv.org/abs/2512.04796v1>The initial-to-final-state inverse problem with unbounded potentials and Strichartz estimates</a><a hidden class=anchor aria-hidden=true href=#the-initial-to-final-state-inverse-problem-with-unbounded-potentials-and-strichartz-estimateshttpsarxivorgabs251204796v1>#</a></h3><p><strong>Authors:</strong> Pedro Caro, Alberto Ruiz
<strong>Venue:</strong> arXiv (2025)</p><p>The initial-to-final-state inverse problem consists in determining a quantum Hamiltonian assuming the knowledge of the state of the system at some fixed time, for every initial state. We formulated this problem to establish a theoretical framework that would explain the viability of data-driven prediction in quantum mechanics. In a previous work, we analysed this inverse problem for Hamiltonians of the form $-Œî+ V$ with an electric potential $V = V({\rm t}, {\rm x})$, and we showed that uniqueness holds whenever the potentials are bounded and decay super-exponentially at infinity. In this paper, we extend this result for unbounded potentials. One of the key steps consists in proving a family of suitable Strichartz estimates &ndash; including the corresponding endpoint of Keel and Tao.
In the context of the inverse Calder√≥n problem this family of inequalities corresponds to the Carleman inequality proved by Kenig, Ruiz and Sogge. Haberman showed that this inequality can be also retrieved as an embedding of a suitable Bourgain space. The corresponding Bourgain space in our context do not capture the mixed-norm Lebesgue spaces of Strichartz inequalities. In this paper, we give a counterexample that justifies this fact, and shows the limitations of Bourgain spaces to address the initial-to-final-state inverse problem.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04796v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04796v1">üìÑ Download PDF</a></p><hr><h3 id=terahertz-fourier-ptychographic-imaginghttpsarxivorgabs251204783v1><a href=https://arxiv.org/abs/2512.04783v1>Terahertz Fourier Ptychographic Imaging</a><a hidden class=anchor aria-hidden=true href=#terahertz-fourier-ptychographic-imaginghttpsarxivorgabs251204783v1>#</a></h3><p><strong>Authors:</strong> Pitambar Mukherjee, Vivek Kumar, Frederic Fauquet, Amaury Badon, Damien Bigourd, Kedar Khare, Sylvain Gigan, Patrick Mounaix
<strong>Venue:</strong> arXiv (2025)</p><p>High-resolution imaging in the terahertz (THz) spectral range remains fundamentally constrained by the limited numerical apertures of currently existing state-of-the-art imagers, which restricts its applicability across many fields, such as imaging in complex media or nondestructive testing. To address this challenge, we introduce a proof-of-concept implementation of THz Fourier Ptychographic imaging to enhance spatial resolution without requiring extensive hardware modifications. Our method employs a motorized kinematic mirror to generate a sequence of controlled, multi-angle plane-wave illuminations, with each resulting oblique-illumination intensity image encoding a limited portion of the spatial-frequency content of the target imaging sample. These measurements are combined in the Fourier domain using an aberration-corrected iterative phase-retrieval algorithm integrated with an efficient illumination calibration scheme, which enables the reconstruction of resolution-enhanced amplitude and phase images through the synthetic expansion of the effective numerical aperture. Our work establishes a robust framework for high-resolution THz imaging and paves the way for a wide array of applications in materials characterization, spectroscopy, and non-destructive evaluation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04783v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04783v1">üìÑ Download PDF</a></p><hr><h3 id=demultiplexing-through-a-multimode-fiber-using-chip-scale-diffractive-neural-networkshttpsarxivorgabs251204767v1><a href=https://arxiv.org/abs/2512.04767v1>Demultiplexing through a multimode fiber using chip-scale diffractive neural networks</a><a hidden class=anchor aria-hidden=true href=#demultiplexing-through-a-multimode-fiber-using-chip-scale-diffractive-neural-networkshttpsarxivorgabs251204767v1>#</a></h3><p><strong>Authors:</strong> Qian Zhang, Haoyi Yu, Jie Zhang, Yuedi Zhang, Chao Meng, Jiali Sun, Yu Miao, Qiming Zhang, Min Gu, Juergen W Czarske
<strong>Venue:</strong> arXiv (2025)</p><p>In today&rsquo;s information age, advanced fiber optic transmission technology is of paramount importance. Multimode fibers (MMFs) using space-division multiplexing (SDM) are promising for improved transmission capacity, connection flexibility, and security of data. However, the complex transmission characteristics of MMFs significantly hinder precise mode demultiplexing. Conventional approaches, including holographic measurements, phase retrieval algorithms, photonic lanterns, and multiplane light conversion, are limited by system complexity, size, and flexibility. In this paper, we demonstrate for the first time a purely optical, chip-scale AI solution for high-mode isolation, speed-of-light demultiplexing of MMF modes using a three-dimensional diffractive neural network (DNN). The DNN is trained with synthetic modal data and fabricated using two-photon nanolithography. It features a compact size of $120Œºm \times 120Œºm \times 80Œºm$ and a diffractive structure size of $1Œºm^{2}$ for the neurons at the hidden layers of the network. Experimentally, the DNN demultiplexer achieves a relative demultiplexing accuracy of over 80%. The AI approach of DNN allows for flexible design and overcomes the size and performance limitations of digital-optical demultiplexers. This work paves the way for compact, low-latency optical processors for high-performance demultiplexers and enables scalable, chip-integrated solutions for next-generation fiber optic networks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04767v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04767v1">üìÑ Download PDF</a></p><hr><h3 id=the-endocranial-cast-of-khirtharia-artiodactyla-raoellidae-provides-new-insights-into-the-earliest-evolution-of-the-cetacean-brainhttpsarxivorgabs251204624v1><a href=https://arxiv.org/abs/2512.04624v1>The Endocranial Cast of Khirtharia (Artiodactyla, Raoellidae) Provides New Insights into the Earliest Evolution of the Cetacean Brain</a><a hidden class=anchor aria-hidden=true href=#the-endocranial-cast-of-khirtharia-artiodactyla-raoellidae-provides-new-insights-into-the-earliest-evolution-of-the-cetacean-brainhttpsarxivorgabs251204624v1>#</a></h3><p><strong>Authors:</strong> Mohd Waqas, Thierry Smith, Rajendra Rana, Maeva J Orliac
<strong>Venue:</strong> arXiv (2025)</p><p>Introduction: Raoellidae are small artiodactyls retrieved from the middle Eocene of Asia (ca. -47 Ma) and closely related to stem Cetacea. Morphological observations of their endocranial structures allow for outlining some of the early steps of the evolutionary history of the cetacean brain. The external features of the brain and associated sinuses of Raoellidae are so far only documented by the virtual reconstruction of the endocast based on specimens of the species Indohyus indirae. These specimens are however too deformed to fully access the external morphology, surface area, and volume measurements of the brain. Methods: We bring here new elements to the picture of the raoellid brain by an investigation of the internal structures of an exceptionally well-preserved cranium collected from the Kalakot area (Jammu and Kashmir, India) referred to the species Khirtharia inflata. Micro-CT scan investigation and virtual reconstruction of the endocast and associated sinuses of this specimen provide crucial additional data about the morphological diversity within Raoellidae as well as reliable linear, surfaces, and volumes measurements, allowing for quantitative studies. Results: We show that, like I. indirae, the brain of K. inflata exhibits a mosaic of features observed in earliest artiodactyls: a small neocortex with simple folding pattern, widely exposed midbrain, and relatively long cerebellum. But, like Indohyus, the brain of Khirtharia shows unique derived characters also observed in stem cetaceans: narrow elongated olfactory bulbs and peduncles, posterior location of the braincase in the cranium, and complex network of blood vessels around the cerebellum. The volume of the brain relative to body mass of K. inflata is markedly small when compared to other early artiodactyls. Conclusion: We show here that cetaceans that nowadays have the second biggest brain after humans derive from a group of animals that had a lower-than-average expected brain size. This is probably a side effect of the adaptation to aquatic life. Conversely, this very small brain size relative to body mass might be another line of evidence supporting the aquatic habits in raoellids.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04624v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04624v1">üìÑ Download PDF</a></p><hr><h3 id=prompt2craft-generating-functional-craft-assemblies-with-llmshttpsarxivorgabs251204568v1><a href=https://arxiv.org/abs/2512.04568v1>Prompt2Craft: Generating Functional Craft Assemblies with LLMs</a><a hidden class=anchor aria-hidden=true href=#prompt2craft-generating-functional-craft-assemblies-with-llmshttpsarxivorgabs251204568v1>#</a></h3><p><strong>Authors:</strong> Vitor Hideyo Isume, Takuya Kiyokawa, Natsuki Yamanobe, Yukiyasu Domae, Weiwei Wan, Kensuke Harada
<strong>Venue:</strong> arXiv (2025)</p><p>Inspired by traditional handmade crafts, where a person improvises assemblies based on the available objects, we formally introduce the Craft Assembly Task. It is a robotic assembly task that involves building an accurate representation of a given target object using the available objects, which do not directly correspond to its parts. In this work, we focus on selecting the subset of available objects for the final craft, when the given input is an RGB image of the target in the wild. We use a mask segmentation neural network to identify visible parts, followed by retrieving labeled template meshes. These meshes undergo pose optimization to determine the most suitable template. Then, we propose to simplify the parts of the transformed template mesh to primitive shapes like cuboids or cylinders. Finally, we design a search algorithm to find correspondences in the scene based on local and global proportions. We develop baselines for comparison that consider all possible combinations, and choose the highest scoring combination for common metrics used in foreground maps and mask accuracy. Our approach achieves comparable results to the baselines for two different scenes, and we show qualitative results for an implementation in a real-world scenario.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04568v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04568v1">üìÑ Download PDF</a></p><hr><h3 id=videomem-enhancing-ultra-long-video-understanding-via-adaptive-memory-managementhttpsarxivorgabs251204540v1><a href=https://arxiv.org/abs/2512.04540v1>VideoMem: Enhancing Ultra-Long Video Understanding via Adaptive Memory Management</a><a hidden class=anchor aria-hidden=true href=#videomem-enhancing-ultra-long-video-understanding-via-adaptive-memory-managementhttpsarxivorgabs251204540v1>#</a></h3><p><strong>Authors:</strong> Hongbo Jin, Qingyuan Wang, Wenhao Zhang, Yang Liu, Sijie Cheng
<strong>Venue:</strong> arXiv (2025)</p><p>Ultra long video understanding remains an open challenge, as existing vision language models (VLMs) falter on such content due to limited context length and inefficient long term memory retention. To address this, recent works have attempted to construct external knowledge bases and corresponding retrieval agumented generation (RAG) systems, yet these incur enormous storage and computational overhead. In this paper, we propose VideoMem, a novel framework that pioneers models long video understanding as a sequential generation task via adaptive memory management. Specifically, VideoMem dynamically updates a global memory buffer, which adaptively retains critical information while discarding redundant content across the video timeline. To efficiently train VLMs for such long-term tasks, VideoMem integrates the Progressive Grouped Relative Policy Optimization (PRPO) algorithm, equipped with two core modules: Progressive State Propagation (PSP) adaptively retains valid current states, propagates them to the next rollout step, and gradually narrows the model exploration space. Temporal Cascading Reward (TCR) further alleviates reward sparsity, improving sample utilization and accelerating convergence. Extensive experiments demonstrate that VideoMem significantly outperforms existing open-source models across diverse benchmarks for ultra-long video understanding tasks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04540v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04540v1">üìÑ Download PDF</a></p><hr><h3 id=continuously-tunable-single-photon-level-nonlinearity-with-rydberg-state-wave-function-engineeringhttpsarxivorgabs251204525v1><a href=https://arxiv.org/abs/2512.04525v1>Continuously tunable single-photon level nonlinearity with Rydberg state wave-function engineering</a><a hidden class=anchor aria-hidden=true href=#continuously-tunable-single-photon-level-nonlinearity-with-rydberg-state-wave-function-engineeringhttpsarxivorgabs251204525v1>#</a></h3><p><strong>Authors:</strong> Biao Xu, Gen-Sheng Ye, Yue Chang, Tao Shi, Lin Li
<strong>Venue:</strong> arXiv (2025)</p><p>Extending optical nonlinearity into the extremely weak light regime is at the heart of quantum optics, since it enables the efficient generation of photonic entanglement and implementation of photonic quantum logic gate. Here, we demonstrate the capability for continuously tunable single-photon level nonlinearity, enabled by precise control of Rydberg interaction over two orders of magnitude, through the use of microwave-assisted wave-function engineering. To characterize this nonlinearity, light storage and retrieval protocol utilizing Rydberg electromagnetically induced transparency is employed, and the quantum statistics of the retrieved photons are analyzed. As a first application, we demonstrate our protocol can speed up the preparation of single photons in low-lying Rydberg states by a factor of up to ~ 40. Our work holds the potential to accelerate quantum operations and to improve the circuit depth and connectivity in Rydberg systems, representing a crucial step towards scalable quantum information processing with Rydberg atoms.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04525v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04525v1">üìÑ Download PDF</a></p><hr><h3 id=msme-a-multi-stage-multi-expert-framework-for-zero-shot-stance-detectionhttpsarxivorgabs251204492v1><a href=https://arxiv.org/abs/2512.04492v1>MSME: A Multi-Stage Multi-Expert Framework for Zero-Shot Stance Detection</a><a hidden class=anchor aria-hidden=true href=#msme-a-multi-stage-multi-expert-framework-for-zero-shot-stance-detectionhttpsarxivorgabs251204492v1>#</a></h3><p><strong>Authors:</strong> Yuanshuo Zhang, Aohua Li, Bo Chen, Jingbo Sun, Xiaobing Zhao
<strong>Venue:</strong> arXiv (2025)</p><p>LLM-based approaches have recently achieved impressive results in zero-shot stance detection. However, they still struggle in complex real-world scenarios, where stance understanding requires dynamic background knowledge, target definitions involve compound entities or events that must be explicitly linked to stance labels, and rhetorical devices such as irony often obscure the author&rsquo;s actual intent. To address these challenges, we propose MSME, a Multi-Stage, Multi-Expert framework for zero-shot stance detection. MSME consists of three stages: (1) Knowledge Preparation, where relevant background knowledge is retrieved and stance labels are clarified; (2) Expert Reasoning, involving three specialized modules-Knowledge Expert distills salient facts and reasons from a knowledge perspective, Label Expert refines stance labels and reasons accordingly, and Pragmatic Expert detects rhetorical cues such as irony to infer intent from a pragmatic angle; (3) Decision Aggregation, where a Meta-Judge integrates all expert analyses to produce the final stance prediction. Experiments on three public datasets show that MSME achieves state-of-the-art performance across the board.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04492v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04492v1">üìÑ Download PDF</a></p><hr><h3 id=relative-wavefront-error-correction-over-a-24-km-free-space-optical-link-via-machine-learninghttpsarxivorgabs251204460v1><a href=https://arxiv.org/abs/2512.04460v1>Relative Wavefront Error Correction Over a 2.4 km Free-Space Optical Link via Machine Learning</a><a hidden class=anchor aria-hidden=true href=#relative-wavefront-error-correction-over-a-24-km-free-space-optical-link-via-machine-learninghttpsarxivorgabs251204460v1>#</a></h3><p><strong>Authors:</strong> Nathan K. Long, Benjamin P. Dix-Matthews, Alex Frost, John Wallis, Ziqing Wang, Kenneth J. Grant, Robert Malaney
<strong>Venue:</strong> arXiv (2025)</p><p>In coherent optical communication across turbulent atmospheric channels, reference beacons can be multiplexed with information-encoded signals during transmission. In this case, it is commonly assumed that the wavefront distortion of the two is equivalent. In contrast to this assumption, we present experimental evidence of relative wavefront errors (WFEs) between polarization-multiplexed reference beacons and signals, after passing through a 2.4 km atmospheric link. We develop machine learning-based wavefront correction algorithms to compensate for observed WFEs, via phase retrieval, resulting in up to a 2/3 reduction in the relative phase error variance. Further, we analyze the excess noise contributions from relative WFEs in the context of continuous-variable quantum key distribution (CV-QKD), where our findings suggest that if future CV-QKD implementations employ wavefront correction algorithms similar to those reported here, an order of magnitude increase in secure key rates may be forthcoming.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04460v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04460v1">üìÑ Download PDF</a></p><hr><h3 id=govbench-benchmarking-llm-agents-for-real-world-data-governance-workflowshttpsarxivorgabs251204416v1><a href=https://arxiv.org/abs/2512.04416v1>GovBench: Benchmarking LLM Agents for Real-World Data Governance Workflows</a><a hidden class=anchor aria-hidden=true href=#govbench-benchmarking-llm-agents-for-real-world-data-governance-workflowshttpsarxivorgabs251204416v1>#</a></h3><p><strong>Authors:</strong> Zhou Liu, Zhaoyang Han, Guochen Yan, Hao Liang, Bohan Zeng, Xing Chen, Yuanfeng Song, Wentao Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>Data governance ensures data quality, security, and compliance through policies and standards, a critical foundation for scaling modern AI development. Recently, large language models (LLMs) have emerged as a promising solution for automating data governance by translating user intent into executable transformation code. However, existing benchmarks for automated data science often emphasize snippet-level coding or high-level analytics, failing to capture the unique challenge of data governance: ensuring the correctness and quality of the data itself. To bridge this gap, we introduce GovBench, a benchmark featuring 150 diverse tasks grounded in real-world scenarios, built on data from actual cases. GovBench employs a novel &ldquo;reversed-objective&rdquo; methodology to synthesize realistic noise and utilizes rigorous metrics to assess end-to-end pipeline reliability. Our analysis on GovBench reveals that current models struggle with complex, multi-step workflows and lack robust error-correction mechanisms. Consequently, we propose DataGovAgent, a framework utilizing a Planner-Executor-Evaluator architecture that integrates constraint-based planning, retrieval-augmented generation, and sandboxed feedback-driven debugging. Experimental results show that DataGovAgent significantly boosts the Average Task Score (ATS) on complex tasks from 39.7 to 54.9 and reduces debugging iterations by over 77.9 percent compared to general-purpose baselines.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04416v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04416v1">üìÑ Download PDF</a></p><hr><h3 id=the-personalization-paradox-semantic-loss-vs-reasoning-gains-in-agentic-ai-qahttpsarxivorgabs251204343v1><a href=https://arxiv.org/abs/2512.04343v1>The Personalization Paradox: Semantic Loss vs. Reasoning Gains in Agentic AI Q&amp;A</a><a hidden class=anchor aria-hidden=true href=#the-personalization-paradox-semantic-loss-vs-reasoning-gains-in-agentic-ai-qahttpsarxivorgabs251204343v1>#</a></h3><p><strong>Authors:</strong> Satyajit Movidi, Stephen Russell
<strong>Venue:</strong> arXiv (2025)</p><p>AIVisor, an agentic retrieval-augmented LLM for student advising, was used to examine how personalization affects system performance across multiple evaluation dimensions. Using twelve authentic advising questions intentionally designed to stress lexical precision, we compared ten personalized and non-personalized system configurations and analyzed outcomes with a Linear Mixed-Effects Model across lexical (BLEU, ROUGE-L), semantic (METEOR, BERTScore), and grounding (RAGAS) metrics. Results showed a consistent trade-off: personalization reliably improved reasoning quality and grounding, yet introduced a significant negative interaction on semantic similarity, driven not by poorer answers but by the limits of current metrics, which penalize meaningful personalized deviations from generic reference texts. This reveals a structural flaw in prevailing LLM evaluation methods, which are ill-suited for assessing user-specific responses. The fully integrated personalized configuration produced the highest overall gains, suggesting that personalization can enhance system effectiveness when evaluated with appropriate multidimensional metrics. Overall, the study demonstrates that personalization produces metric-dependent shifts rather than uniform improvements and provides a methodological foundation for more transparent and robust personalization in agentic AI.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04343v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04343v1">üìÑ Download PDF</a></p><hr><h3 id=a-retrieval-augmented-generation-approach-to-extracting-algorithmic-logic-from-neural-networkshttpsarxivorgabs251204329v1><a href=https://arxiv.org/abs/2512.04329v1>A Retrieval-Augmented Generation Approach to Extracting Algorithmic Logic from Neural Networks</a><a hidden class=anchor aria-hidden=true href=#a-retrieval-augmented-generation-approach-to-extracting-algorithmic-logic-from-neural-networkshttpsarxivorgabs251204329v1>#</a></h3><p><strong>Authors:</strong> Waleed Khalid, Dmitry Ignatov, Radu Timofte
<strong>Venue:</strong> arXiv (2025)</p><p>Reusing existing neural-network components is central to research efficiency, yet discovering, extracting, and validating such modules across thousands of open-source repositories remains difficult. We introduce NN-RAG, a retrieval-augmented generation system that converts large, heterogeneous PyTorch codebases into a searchable and executable library of validated neural modules. Unlike conventional code search or clone-detection tools, NN-RAG performs scope-aware dependency resolution, import-preserving reconstruction, and validator-gated promotion &ndash; ensuring that every retrieved block is scope-closed, compilable, and runnable. Applied to 19 major repositories, the pipeline extracted 1,289 candidate blocks, validated 941 (73.0%), and demonstrated that over 80% are structurally unique. Through multi-level de-duplication (exact, lexical, structural), we find that NN-RAG contributes the overwhelming majority of unique architectures to the LEMUR dataset, supplying approximately 72% of all novel network structures. Beyond quantity, NN-RAG uniquely enables cross-repository migration of architectural patterns, automatically identifying reusable modules in one project and regenerating them, dependency-complete, in another context. To our knowledge, no other open-source system provides this capability at scale. The framework&rsquo;s neutral specifications further allow optional integration with language models for synthesis or dataset registration without redistributing third-party code. Overall, NN-RAG transforms fragmented vision code into a reproducible, provenance-tracked substrate for algorithmic discovery, offering a first open-source solution that both quantifies and expands the diversity of executable neural architectures across repositories.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04329v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04329v1">üìÑ Download PDF</a></p><hr><h3 id=text-only-training-for-image-captioning-with-retrieval-augmentation-and-modality-gap-correctionhttpsarxivorgabs251204309v1><a href=https://arxiv.org/abs/2512.04309v1>Text-Only Training for Image Captioning with Retrieval Augmentation and Modality Gap Correction</a><a hidden class=anchor aria-hidden=true href=#text-only-training-for-image-captioning-with-retrieval-augmentation-and-modality-gap-correctionhttpsarxivorgabs251204309v1>#</a></h3><p><strong>Authors:</strong> Rui Fonseca, Bruno Martins, Gil Rocha
<strong>Venue:</strong> arXiv (2025)</p><p>Image captioning has drawn considerable attention from the natural language processing and computer vision fields. Aiming to reduce the reliance on curated data, several studies have explored image captioning without any humanly-annotated image-text pairs for training, although existing methods are still outperformed by fully supervised approaches. This paper proposes TOMCap, i.e., an improved text-only training method that performs captioning without the need for aligned image-caption pairs. The method is based on prompting a pre-trained language model decoder with information derived from a CLIP representation, after undergoing a process to reduce the modality gap. We specifically tested the combined use of retrieved examples of captions, and latent vector representations, to guide the generation process. Through extensive experiments, we show that TOMCap outperforms other training-free and text-only methods. We also analyze the impact of different choices regarding the configuration of the retrieval-augmentation and modality gap reduction components.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04309v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04309v1">üìÑ Download PDF</a></p><hr><h3 id=evaluating-long-context-reasoning-in-llm-based-webagentshttpsarxivorgabs251204307v1><a href=https://arxiv.org/abs/2512.04307v1>Evaluating Long-Context Reasoning in LLM-Based WebAgents</a><a hidden class=anchor aria-hidden=true href=#evaluating-long-context-reasoning-in-llm-based-webagentshttpsarxivorgabs251204307v1>#</a></h3><p><strong>Authors:</strong> Andy Chung, Yichi Zhang, Kaixiang Lin, Aditya Rawal, Qiaozi Gao, Joyce Chai
<strong>Venue:</strong> arXiv (2025)</p><p>As large language model (LLM)-based agents become increasingly integrated into daily digital interactions, their ability to reason across long interaction histories becomes crucial for providing personalized and contextually aware assistance. However, the performance of these agents in long context scenarios, particularly for action-taking WebAgents operating in realistic web environments, remains largely unexplored. This paper introduces a benchmark for evaluating long context reasoning capabilities of WebAgents through sequentially dependent subtasks that require retrieval and application of information from extended interaction histories. We develop a novel evaluation framework that simulates multi-session user interactions by injecting irrelevant task trajectories between dependent subtasks, creating contexts ranging from 25,000 to 150,000 tokens. Through extensive evaluation of four popular models, Claude-3.7, GPT-4.1, Llama 4, and o4-mini, we observe a dramatic performance degradation as context length increases, with success rates dropping from 40-50% in baseline conditions to less than 10% in long context scenarios. Our detailed error analysis reveals that agents primarily fail due to getting stuck in loops and losing track of original task objectives. We further propose an implicit RAG approach that provides modest improvements by generating task-relevant summaries, though fundamental limitations in long context reasoning persist. These findings highlight critical challenges for deploying WebAgents in realistic, long-term user interaction scenarios and provide insights for developing more robust agent architectures capable of maintaining coherent task execution across extended contexts.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04307v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04307v1">üìÑ Download PDF</a></p><hr><h3 id=square-structured-query--adaptive-retrieval-engine-for-tabular-formatshttpsarxivorgabs251204292v1><a href=https://arxiv.org/abs/2512.04292v1>SQuARE: Structured Query & Adaptive Retrieval Engine For Tabular Formats</a><a hidden class=anchor aria-hidden=true href=#square-structured-query--adaptive-retrieval-engine-for-tabular-formatshttpsarxivorgabs251204292v1>#</a></h3><p><strong>Authors:</strong> Chinmay Gondhalekar, Urjitkumar Patel, Fang-Chun Yeh
<strong>Venue:</strong> arXiv (2025)</p><p>Accurate question answering over real spreadsheets remains difficult due to multirow headers, merged cells, and unit annotations that disrupt naive chunking, while rigid SQL views fail on files lacking consistent schemas. We present SQuARE, a hybrid retrieval framework with sheet-level, complexity-aware routing. It computes a continuous score based on header depth and merge density, then routes queries either through structure-preserving chunk retrieval or SQL over an automatically constructed relational representation. A lightweight agent supervises retrieval, refinement, or combination of results across both paths when confidence is low. This design maintains header hierarchies, time labels, and units, ensuring that returned values are faithful to the original cells and straightforward to verify. Evaluated on multi-header corporate balance sheets, a heavily merged World Bank workbook, and diverse public datasets, SQuARE consistently surpasses single-strategy baselines and ChatGPT-4o on both retrieval precision and end-to-end answer accuracy while keeping latency predictable. By decoupling retrieval from model choice, the system is compatible with emerging tabular foundation models and offers a practical bridge toward a more robust table understanding.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04292v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04292v1">üìÑ Download PDF</a></p><hr><h3 id=craft-e-a-neuro-symbolic-framework-for-embodied-affordance-groundinghttpsarxivorgabs251204231v1><a href=https://arxiv.org/abs/2512.04231v1>CRAFT-E: A Neuro-Symbolic Framework for Embodied Affordance Grounding</a><a hidden class=anchor aria-hidden=true href=#craft-e-a-neuro-symbolic-framework-for-embodied-affordance-groundinghttpsarxivorgabs251204231v1>#</a></h3><p><strong>Authors:</strong> Zhou Chen, Joe Lin, Carson Bulgin, Sathyanarayanan N. Aakur
<strong>Venue:</strong> arXiv (2025)</p><p>Assistive robots operating in unstructured environments must understand not only what objects are, but what they can be used for. This requires grounding language-based action queries to objects that both afford the requested function and can be physically retrieved. Existing approaches often rely on black-box models or fixed affordance labels, limiting transparency, controllability, and reliability for human-facing applications. We introduce CRAFT-E, a modular neuro-symbolic framework that composes a structured verb-property-object knowledge graph with visual-language alignment and energy-based grasp reasoning. The system generates interpretable grounding paths that expose the factors influencing object selection and incorporates grasp feasibility as an integral part of affordance inference. We further construct a benchmark dataset with unified annotations for verb-object compatibility, segmentation, and grasp candidates, and deploy the full pipeline on a physical robot. CRAFT-E achieves competitive performance in static scenes, ImageNet-based functional retrieval, and real-world trials involving 20 verbs and 39 objects. The framework remains robust under perceptual noise and provides transparent, component-level diagnostics. By coupling symbolic reasoning with embodied perception, CRAFT-E offers an interpretable and customizable alternative to end-to-end models for affordance-grounded object selection, supporting trustworthy decision-making in assistive robotic systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04231v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04231v1">üìÑ Download PDF</a></p><hr><h3 id=on-grpo-collapse-in-search-r1-the-lazy-likelihood-displacement-death-spiralhttpsarxivorgabs251204220v1><a href=https://arxiv.org/abs/2512.04220v1>On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral</a><a hidden class=anchor aria-hidden=true href=#on-grpo-collapse-in-search-r1-the-lazy-likelihood-displacement-death-spiralhttpsarxivorgabs251204220v1>#</a></h3><p><strong>Authors:</strong> Wenlong Deng, Yushu Li, Boying Gong, Yi Ren, Christos Thrampoulidis, Xiaoxiao Li
<strong>Venue:</strong> arXiv (2025)</p><p>Tool-integrated (TI) reinforcement learning (RL) enables large language models (LLMs) to perform multi-step reasoning by interacting with external tools such as search engines and retrievers. Group Relative Policy Optimization (GRPO), exemplified by the recent Search-R1, offers fast convergence and a value-free formulation that makes it appealing for this setting, yet consistently suffers from training collapse. We identify Lazy Likelihood Displacement (LLD), a systematic reduction or stagnation in the likelihood of both correct and incorrect responses, as the core mechanism driving this failure. LLD emerges early and triggers a self-reinforcing LLD Death Spiral, where declining likelihood leads to low-confidence responses, inflating gradients, and ultimately causing collapse. We empirically characterize this process across models on a Search-R1-style, search-integrated question answering task, revealing a consistent three-phase trajectory: early stagnation, steady decay, and accelerated collapse. To address this, we propose a lightweight likelihood-preserving regularization LLDS for GRPO that activates only when a trajectory&rsquo;s likelihood decreases, and regularizes only the tokens responsible. This fine-grained structure mitigates LLD with minimal interference to optimization. Across seven open-domain and multi-hop QA benchmarks, our method stabilizes training, prevents gradient explosion, and yields substantial performance improvements, including +37.8% gains on Qwen2.5-3B and +32.0% gains on Qwen2.5-7B. Our results establish LLD as a fundamental bottleneck in GRPO-based TIRL and provide a practical path toward stable, scalable training of tool-integrated LLM.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04220v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04220v1">üìÑ Download PDF</a></p><hr><h3 id=high-resolution-retrieval-of-atmospheric-boundary-layers-with-nonstationary-gaussian-processeshttpsarxivorgabs251204217v1><a href=https://arxiv.org/abs/2512.04217v1>High-Resolution Retrieval of Atmospheric Boundary Layers with Nonstationary Gaussian Processes</a><a hidden class=anchor aria-hidden=true href=#high-resolution-retrieval-of-atmospheric-boundary-layers-with-nonstationary-gaussian-processeshttpsarxivorgabs251204217v1>#</a></h3><p><strong>Authors:</strong> Haoran Xiong, Paytsar Muradyan, Christopher J. Geoga
<strong>Venue:</strong> arXiv (2025)</p><p>The atmospheric boundary layer (ABL) plays a critical role in governing turbulent exchanges of momentum, heat moisture, and trace gases between the Earth&rsquo;s surface and the free atmosphere, thereby influencing meteorological phenomena, air quality, and climate processes. Accurate and temporally continuous characterization of the ABL structure and height evolution is crucial for both scientific understanding and practical applications. High-resolution retrievals of the ABL height from vertical velocity measurements is challenging because it is often estimated using empirical thresholds applied to profiles of vertical velocity variance or related turbulence diagnostics at each measurement altitude, which can suffer from limited sampling and sensitivity to noise. To address these limitations, this work employs nonstationary Gaussian process (GP) modeling to more effectively capture the spatio-temporal dependence structure in the data, enabling high-quality &ndash; and, if desired, high-resolution &ndash; estimates of the ABL height without reliance on ad-hoc parameter tuning. By leveraging Vecchia approximations, the proposed method can be applied to large-scale datasets, and example applications using full-day vertical velocity profiles comprising approximately $5$M measurements are presented.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04217v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04217v1">üìÑ Download PDF</a></p><hr><h3 id=fractal-aggregate-aerosols-in-the-virga-cloud-code-ii-exploring-the-effects-of-key-cloud-parameters-in-warm-neptune-hot-jupiter-and-brown-dwarf-atmosphereshttpsarxivorgabs251204186v1><a href=https://arxiv.org/abs/2512.04186v1>Fractal Aggregate Aerosols in the Virga Cloud Code II: Exploring the Effects of Key Cloud Parameters in Warm Neptune, Hot Jupiter and Brown Dwarf Atmospheres</a><a hidden class=anchor aria-hidden=true href=#fractal-aggregate-aerosols-in-the-virga-cloud-code-ii-exploring-the-effects-of-key-cloud-parameters-in-warm-neptune-hot-jupiter-and-brown-dwarf-atmosphereshttpsarxivorgabs251204186v1>#</a></h3><p><strong>Authors:</strong> Matt G. Lodge, Sarah E. Moran, Hannah R. Wakeford, Zoe M. Leinhardt, Mark S. Marley
<strong>Venue:</strong> arXiv (2025)</p><p>Aerosols and clouds are expected to be ubiquitous in exoplanet and brown dwarf atmospheres, where they can have a significant impact on transmission and emission spectra. The cloud code Virga is capable of quickly modeling cloud particle sizes as a function of altitude, and has recently been updated to include functionality for aggregates (ranging from very fluffy chains to compact fractals). We analyze the effect that these aggregates have on transmission spectra for typical warm Neptune and hot Jupiter environments, as well as their effect on emission spectra for an L-type brown dwarf, over the wavelength range 0.3 - 15 um. We find significant, measurable differences in spectra when particle shape is changed (particularly the shortest wavelengths where particle morphology strongly affects the scattering slope). We provide some intuitive rules for how non-absorbing aggregates impact spectra: when particle sizes are small compared to the wavelength of light, the most elongated and chain-like particles have the highest opacities. When particles are large, the inverse is true (the most compact shapes have the highest opacities). We present an explanation for these effects in terms of the dynamics of how the particles form and move through the atmosphere, as well as in terms of fundamental optics theory. Given the significant impact that particle shape can have on spectra, we strongly encourage the community to include shape as a free parameter in future case studies, atmospheric models, and retrievals.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04186v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04186v1">üìÑ Download PDF</a></p><hr><h3 id=tighter-constraints-on-the-atmosphere-of-gj-436-b-from-combined-high-resolution-carmenes-and-crires-observationshttpsarxivorgabs251204161v1><a href=https://arxiv.org/abs/2512.04161v1>Tighter constraints on the atmosphere of GJ 436 b from combined high-resolution CARMENES and CRIRES$^+$ observations</a><a hidden class=anchor aria-hidden=true href=#tighter-constraints-on-the-atmosphere-of-gj-436-b-from-combined-high-resolution-carmenes-and-crires-observationshttpsarxivorgabs251204161v1>#</a></h3><p><strong>Authors:</strong> A. Pel√°ez-Torres, A. S√°nchez-L√≥pez, L. Nortmann, M. L√≥pez-Puertas, E. Gonz√°lez-√Ålvarez, H. M. Tabernero, C. Jiang, D. Revilla, G. Morello, J. Orell-Miquel, E. Pall√©, P. J. Amado, J. A. Caballero, I. Ribas, A. Reiners, A. Quirrenbach, D. Cont, S. Dreizler, A. Fern√°ndez-Mart√≠n, A. P. Hatzes, Th. Henning, F. Lesjak, D. Montes, A. Schweizer, T. Trifonov, F. Yan
<strong>Venue:</strong> arXiv (2025)</p><p>We aim to study the atmospheric properties of the warm Neptune GJ 436 b by combining a set of five transit events observed with the CARMENES spectrograph with one transit from CRIRES$^+$ so as to provide the most constrained results possible at high resolution. We removed telluric and stellar signals from the data using SysRem and potential planetary signals were investigated using the cross-correlation technique. Following standard procedures for undetected species, we performed injection recovery tests and Bayesian retrievals to place constraints on the detectability of the main near-infrared absorbers. In addition, we simulated ELT/ANDES observations by computing end-to-end in silico datasets with EXoPLORE. No molecular signals were detected in the atmosphere of GJ 436 b, which is consistent with previous studies. Combined CARMENES-CRIRES$^+$ injection-recovery and Bayesian retrieval analyses show that the atmosphere is likely covered by high-altitude clouds ($\sim$ $1$ mbar) at low and intermediate metallicities or, alternatively, is very metal-rich ($\gtrsim$ $900\times$ solar), which would suppress spectral features without invoking clouds. Simulations of ELT/ANDES observations suggest a boost by nearly an order of magnitude to the upper limit in the photon-limited regime, reaching $0.1$ mbar at $10$-$300\times$ solar metallicities. The joint analysis of all useful transit observations from CARMENES and CRIRES$^+$ provides the most stringent constraints to date on the atmospheric properties of GJ 436 b. Complementary CCF-based and retrieval approaches consistently indicate that the atmosphere is either cloudy or highly metal enriched. Any weak near-infrared absorption lines, if present, are likely to be below current detection limits. However, according to our simulations, these features may be revealed with ELT/ANDES even in single-transit observations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04161v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04161v1">üìÑ Download PDF</a></p><hr><h3 id=relic-interactive-video-world-model-with-long-horizon-memoryhttpsarxivorgabs251204040v1><a href=https://arxiv.org/abs/2512.04040v1>RELIC: Interactive Video World Model with Long-Horizon Memory</a><a hidden class=anchor aria-hidden=true href=#relic-interactive-video-world-model-with-long-horizon-memoryhttpsarxivorgabs251204040v1>#</a></h3><p><strong>Authors:</strong> Yicong Hong, Yiqun Mei, Chongjian Ge, Yiran Xu, Yang Zhou, Sai Bi, Yannick Hold-Geoffroy, Mike Roberts, Matthew Fisher, Eli Shechtman, Kalyan Sunkavalli, Feng Liu, Zhengqi Li, Hao Tan
<strong>Venue:</strong> arXiv (2025)</p><p>A truly interactive world model requires three key ingredients: real-time long-horizon streaming, consistent spatial memory, and precise user control. However, most existing approaches address only one of these aspects in isolation, as achieving all three simultaneously is highly challenging-for example, long-term memory mechanisms often degrade real-time performance. In this work, we present RELIC, a unified framework that tackles these three challenges altogether. Given a single image and a text description, RELIC enables memory-aware, long-duration exploration of arbitrary scenes in real time. Built upon recent autoregressive video-diffusion distillation techniques, our model represents long-horizon memory using highly compressed historical latent tokens encoded with both relative actions and absolute camera poses within the KV cache. This compact, camera-aware memory structure supports implicit 3D-consistent content retrieval and enforces long-term coherence with minimal computational overhead. In parallel, we fine-tune a bidirectional teacher video model to generate sequences beyond its original 5-second training horizon, and transform it into a causal student generator using a new memory-efficient self-forcing paradigm that enables full-context distillation over long-duration teacher as well as long student self-rollouts. Implemented as a 14B-parameter model and trained on a curated Unreal Engine-rendered dataset, RELIC achieves real-time generation at 16 FPS while demonstrating more accurate action following, more stable long-horizon streaming, and more robust spatial-memory retrieval compared with prior work. These capabilities establish RELIC as a strong foundation for the next generation of interactive world modeling.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04040v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04040v1">üìÑ Download PDF</a></p><hr><h3 id=learning-to-comparison-shophttpsarxivorgabs251204009v1><a href=https://arxiv.org/abs/2512.04009v1>Learning to Comparison-Shop</a><a hidden class=anchor aria-hidden=true href=#learning-to-comparison-shophttpsarxivorgabs251204009v1>#</a></h3><p><strong>Authors:</strong> Jie Tang, Daochen Zha, Xin Liu, Huiji Gao, Liwei He, Stephanie Moyerman, Sanjeev Katariya
<strong>Venue:</strong> arXiv (2025)</p><p>In online marketplaces like Airbnb, users frequently engage in comparison shopping before making purchase decisions. Despite the prevalence of this behavior, a significant disconnect persists between mainstream e-commerce search engines and users&rsquo; comparison needs. Traditional ranking models often evaluate items in isolation, disregarding the context in which users compare multiple items on a search results page. While recent advances in deep learning have sought to improve ranking accuracy, diversity, and fairness by encoding listwise context, the challenge of aligning search rankings with user comparison shopping behavior remains inadequately addressed. In this paper, we propose a novel ranking architecture - Learning-to-Comparison-Shop (LTCS) System - that explicitly models and learns users&rsquo; comparison shopping behaviors. Through extensive offline and online experiments, we demonstrate that our approach yields statistically significant gains in key business metrics - improving NDCG by 1.7% and boosting booking conversion rate by 0.6% in A/B testing - while also enhancing user experience. We also compare our model against state-of-the-art approaches and demonstrate that LTCS significantly outperforms them.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04009v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04009v1">üìÑ Download PDF</a></p><hr><h3 id=a-hierarchical-tree-based-approach-for-creating-configurable-and-static-deep-research-agent-static-drahttpsarxivorgabs251203887v2><a href=https://arxiv.org/abs/2512.03887v2>A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)</a><a hidden class=anchor aria-hidden=true href=#a-hierarchical-tree-based-approach-for-creating-configurable-and-static-deep-research-agent-static-drahttpsarxivorgabs251203887v2>#</a></h3><p><strong>Authors:</strong> Saurav Prateek
<strong>Venue:</strong> arXiv (2025)</p><p>The advancement in Large Language Models has driven the creation of complex agentic systems, such as Deep Research Agents (DRAs), to overcome the limitations of static Retrieval Augmented Generation (RAG) pipelines in handling complex, multi-turn research tasks. This paper introduces the Static Deep Research Agent (Static-DRA), a novel solution built upon a configurable and hierarchical Tree-based static workflow.
The core contribution is the integration of two user-tunable parameters, Depth and Breadth, which provide granular control over the research intensity. This design allows end-users to consciously balance the desired quality and comprehensiveness of the research report against the associated computational cost of Large Language Model (LLM) interactions. The agent&rsquo;s architecture, comprising Supervisor, Independent, and Worker agents, facilitates effective multi-hop information retrieval and parallel sub-topic investigation.
We evaluate the Static-DRA against the established DeepResearch Bench using the RACE (Reference-based Adaptive Criteria-driven Evaluation) framework. Configured with a depth of 2 and a breadth of 5, and powered by the gemini-2.5-pro model, the agent achieved an overall score of 34.72. Our experiments validate that increasing the configured Depth and Breadth parameters results in a more in-depth research process and a correspondingly higher evaluation score. The Static-DRA offers a pragmatic and resource-aware solution, empowering users with transparent control over the deep research process. The entire source code, outputs and benchmark results are open-sourced at <a href=https://github.com/SauravP97/Static-Deep-Research/>https://github.com/SauravP97/Static-Deep-Research/</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03887v2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03887v2">üìÑ Download PDF</a></p><hr><h3 id=mechdetect-detecting-data-dependent-errorshttpsarxivorgabs251204138v1><a href=https://arxiv.org/abs/2512.04138v1>MechDetect: Detecting Data-Dependent Errors</a><a hidden class=anchor aria-hidden=true href=#mechdetect-detecting-data-dependent-errorshttpsarxivorgabs251204138v1>#</a></h3><p><strong>Authors:</strong> Philipp Jung, Nicholas Chandler, Sebastian J√§ger, Felix Biessmann
<strong>Venue:</strong> arXiv (2025)</p><p>Data quality monitoring is a core challenge in modern information processing systems. While many approaches to detect data errors or shifts have been proposed, few studies investigate the mechanisms governing error generation. We argue that knowing how errors were generated can be key to tracing and fixing them. In this study, we build on existing work in the statistics literature on missing values and propose MechDetect, a simple algorithm to investigate error generation mechanisms. Given a tabular data set and a corresponding error mask, the algorithm estimates whether or not the errors depend on the data using machine learning models. Our work extends established approaches to detect mechanisms underlying missing values and can be readily applied to other error types, provided that an error mask is available. We demonstrate the effectiveness of MechDetect in experiments on established benchmark datasets.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04138v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04138v1">üìÑ Download PDF</a></p><hr><h3 id=omnidexvlg-learning-dexterous-grasp-generation-from-vision-language-model-guided-grasp-semantics-taxonomy-and-functional-affordancehttpsarxivorgabs251203874v1><a href=https://arxiv.org/abs/2512.03874v1>OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance</a><a hidden class=anchor aria-hidden=true href=#omnidexvlg-learning-dexterous-grasp-generation-from-vision-language-model-guided-grasp-semantics-taxonomy-and-functional-affordancehttpsarxivorgabs251203874v1>#</a></h3><p><strong>Authors:</strong> Lei Zhang, Diwen Zheng, Kaixin Bai, Zhenshan Bing, Zoltan-Csaba Marton, Zhaopeng Chen, Alois Christian Knoll, Jianwei Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>Dexterous grasp generation aims to produce grasp poses that align with task requirements and human interpretable grasp semantics. However, achieving semantically controllable dexterous grasp synthesis remains highly challenging due to the lack of unified modeling of multiple semantic dimensions, including grasp taxonomy, contact semantics, and functional affordance. To address these limitations, we present OmniDexVLG, a multimodal, semantics aware grasp generation framework capable of producing structurally diverse and semantically coherent dexterous grasps under joint language and visual guidance. Our approach begins with OmniDexDataGen, a semantic rich dexterous grasp dataset generation pipeline that integrates grasp taxonomy guided configuration sampling, functional affordance contact point sampling, taxonomy aware differential force closure grasp sampling, and physics based optimization and validation, enabling systematic coverage of diverse grasp types. We further introduce OmniDexReasoner, a multimodal grasp type semantic reasoning module that leverages multi agent collaboration, retrieval augmented generation, and chain of thought reasoning to infer grasp related semantics and generate high quality annotations that align language instructions with task specific grasp intent. Building upon these components, we develop a unified Vision Language Grasping generation model that explicitly incorporates grasp taxonomy, contact structure, and functional affordance semantics, enabling fine grained control over grasp synthesis from natural language instructions. Extensive experiments in simulation and real world object grasping and ablation studies demonstrate that our method substantially outperforms state of the art approaches in terms of grasp diversity, contact semantic diversity, functional affordance diversity, and semantic consistency.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03874v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03874v1">üìÑ Download PDF</a></p><hr><h3 id=algorithms-for-boolean-matrix-factorization-using-integer-programming-and-heuristicshttpsarxivorgabs251203807v2><a href=https://arxiv.org/abs/2512.03807v2>Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics</a><a hidden class=anchor aria-hidden=true href=#algorithms-for-boolean-matrix-factorization-using-integer-programming-and-heuristicshttpsarxivorgabs251203807v2>#</a></h3><p><strong>Authors:</strong> Christos Kolomvakis, Thomas Bobille, Arnaud Vandaele, Nicolas Gillis
<strong>Venue:</strong> arXiv (2025)</p><p>Boolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. Unlike binary matrix factorization based on standard arithmetic, BMF employs the Boolean OR and AND operations for the matrix product, which improves interpretability and reduces the approximation error. It is also used in role mining and computer vision. In this paper, we first propose algorithms for BMF that perform alternating optimization (AO) of the factor matrices, where each subproblem is solved via integer programming (IP). We then design different approaches to further enhance AO-based algorithms by selecting an optimal subset of rank-one factors from multiple runs. To address the scalability limits of IP-based methods, we introduce new greedy and local-search heuristics. We also construct a new C++ data structure for Boolean vectors and matrices that is significantly faster than existing ones and is of independent interest, allowing our heuristics to scale to large datasets. We illustrate the performance of all our proposed methods and compare them with the state of the art on various real datasets, both with and without missing data, including applications in topic modeling and imaging.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03807v2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03807v2">üìÑ Download PDF</a></p><hr><h3 id=the-enshittification-of-online-search-privacy-and-quality-of-google-bing-and-apple-in-coding-advicehttpsarxivorgabs251203793v1><a href=https://arxiv.org/abs/2512.03793v1>The enshittification of online search? Privacy and quality of Google, Bing and Apple in coding advice</a><a hidden class=anchor aria-hidden=true href=#the-enshittification-of-online-search-privacy-and-quality-of-google-bing-and-apple-in-coding-advicehttpsarxivorgabs251203793v1>#</a></h3><p><strong>Authors:</strong> Konrad Kollnig
<strong>Venue:</strong> arXiv (2025)</p><p>Even though currently being challenged by ChatGPT and other large-language models (LLMs), Google Search remains one of the primary means for many individuals to find information on the internet. Interestingly, the way that we retrieve information on the web has hardly changed ever since Google was established in 1998, raising concerns as to Google&rsquo;s dominance in search and lack of competition. If the market for search was sufficiently competitive, then we should probably see a steady increase in search quality over time as well as alternative approaches to the Google&rsquo;s approach to search. However, hardly any research has so far looked at search quality, which is a key facet of a competitive market, especially not over time.
In this report, we conducted a relatively large-scale quantitative comparison of search quality of 1,467 search queries relating to coding advice in October 2023. We focus on coding advice because the study of general search quality is difficult, with the aim of learning more about the assessment of search quality and motivating follow-up research into this important topic. We evaluate the search quality of Google Search, Microsoft Bing, and Apple Search, with a special emphasis on Apple Search, a widely used search engine that has never been explored in previous research. For the assessment of search quality, we use two independent metrics of search quality: 1) the number of trackers on the first search result, as a measure of privacy in web search, and 2) the average rank of the first Stack Overflow search result, under the assumption that Stack Overflow gives the best coding advice. Our results suggest that the privacy of search results is higher on Bing than on Google and Apple. Similarly, the quality of coding advice &ndash; as measured by the average rank of Stack Overflow &ndash; was highest on Bing.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03793v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03793v1">üìÑ Download PDF</a></p><hr><h3 id=ar-med-automated-relevance-enhancement-in-medical-search-via-llm-driven-information-augmentationhttpsarxivorgabs251203737v1><a href=https://arxiv.org/abs/2512.03737v1>AR-Med: Automated Relevance Enhancement in Medical Search via LLM-Driven Information Augmentation</a><a hidden class=anchor aria-hidden=true href=#ar-med-automated-relevance-enhancement-in-medical-search-via-llm-driven-information-augmentationhttpsarxivorgabs251203737v1>#</a></h3><p><strong>Authors:</strong> Chuyue Wang, Jie Feng, Yuxi Wu, Hang Zhang, Zhiguo Fan, Bing Cheng, Wei Lin
<strong>Venue:</strong> arXiv (2025)</p><p>Accurate and reliable search on online healthcare platforms is critical for user safety and service efficacy. Traditional methods, however, often fail to comprehend complex and nuanced user queries, limiting their effectiveness. Large language models (LLMs) present a promising solution, offering powerful semantic understanding to bridge this gap. Despite their potential, deploying LLMs in this high-stakes domain is fraught with challenges, including factual hallucinations, specialized knowledge gaps, and high operational costs. To overcome these barriers, we introduce \textbf{AR-Med}, a novel framework for \textbf{A}utomated \textbf{R}elevance assessment for \textbf{Med}ical search that has been successfully deployed at scale on the Online Medical Delivery Platforms. AR-Med grounds LLM reasoning in verified medical knowledge through a retrieval-augmented approach, ensuring high accuracy and reliability. To enable efficient online service, we design a practical knowledge distillation scheme that compresses large teacher models into compact yet powerful student models. We also introduce LocalQSMed, a multi-expert annotated benchmark developed to guide model iteration and ensure strong alignment between offline and online performance. Extensive experiments show AR-Med achieves an offline accuracy of over 93%, a 24% absolute improvement over the original online system, and delivers significant gains in online relevance and user satisfaction. Our work presents a practical and scalable blueprint for developing trustworthy, LLM-powered systems in real-world healthcare applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03737v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03737v1">üìÑ Download PDF</a></p><hr><h3 id=dino-rotatematch-a-rotation-aware-deep-framework-for-robust-image-matching-in-large-scale-3d-reconstructionhttpsarxivorgabs251203715v1><a href=https://arxiv.org/abs/2512.03715v1>DINO-RotateMatch: A Rotation-Aware Deep Framework for Robust Image Matching in Large-Scale 3D Reconstruction</a><a hidden class=anchor aria-hidden=true href=#dino-rotatematch-a-rotation-aware-deep-framework-for-robust-image-matching-in-large-scale-3d-reconstructionhttpsarxivorgabs251203715v1>#</a></h3><p><strong>Authors:</strong> Kaichen Zhang, Tianxiang Sheng, Xuanming Shi
<strong>Venue:</strong> arXiv (2025)</p><p>This paper presents DINO-RotateMatch, a deep-learning framework designed to address the chal lenges of image matching in large-scale 3D reconstruction from unstructured Internet images. The
method integrates a dataset-adaptive image pairing strategy with rotation-aware keypoint extraction and
matching. DINO is employed to retrieve semantically relevant image pairs in large collections, while
rotation-based augmentation captures orientation-dependent local features using ALIKED and Light Glue. Experiments on the Kaggle Image Matching Challenge 2025 demonstrate consistent improve ments in mean Average Accuracy (mAA), achieving a Silver Award (47th of 943 teams). The results
confirm that combining self-supervised global descriptors with rotation-enhanced local matching offers
a robust and scalable solution for large-scale 3D reconstruction.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03715v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03715v1">üìÑ Download PDF</a></p><hr><h3 id=memverse-multimodal-memory-for-lifelong-learning-agentshttpsarxivorgabs251203627v1><a href=https://arxiv.org/abs/2512.03627v1>MemVerse: Multimodal Memory for Lifelong Learning Agents</a><a hidden class=anchor aria-hidden=true href=#memverse-multimodal-memory-for-lifelong-learning-agentshttpsarxivorgabs251203627v1>#</a></h3><p><strong>Authors:</strong> Junming Liu, Yifei Sun, Weihua Cheng, Haodong Lei, Yirong Chen, Licheng Wen, Xuemeng Yang, Daocheng Fu, Pinlong Cai, Nianchen Deng, Yi Yu, Shuyue Hu, Botian Shi, Ding Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Despite rapid progress in large-scale language and vision models, AI agents still suffer from a fundamental limitation: they cannot remember. Without reliable memory, agents catastrophically forget past experiences, struggle with long-horizon reasoning, and fail to operate coherently in multimodal or interactive environments. We introduce MemVerse, a model-agnostic, plug-and-play memory framework that bridges fast parametric recall with hierarchical retrieval-based memory, enabling scalable and adaptive multimodal intelligence. MemVerse maintains short-term memory for recent context while transforming raw multimodal experiences into structured long-term memories organized as hierarchical knowledge graphs. This design supports continual consolidation, adaptive forgetting, and bounded memory growth. To handle real-time demands, MemVerse introduces a periodic distillation mechanism that compresses essential knowledge from long-term memory into the parametric model, allowing fast, differentiable recall while preserving interpretability. Extensive experiments demonstrate that MemVerse significantly improves multimodal reasoning and continual learning efficiency, empowering agents to remember, adapt, and reason coherently across extended interactions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03627v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03627v1">üìÑ Download PDF</a></p><hr><h3 id=memory-guided-point-cloud-completion-for-dental-reconstructionhttpsarxivorgabs251203598v1><a href=https://arxiv.org/abs/2512.03598v1>Memory-Guided Point Cloud Completion for Dental Reconstruction</a><a hidden class=anchor aria-hidden=true href=#memory-guided-point-cloud-completion-for-dental-reconstructionhttpsarxivorgabs251203598v1>#</a></h3><p><strong>Authors:</strong> Jianan Sun, Yukang Huang, Dongzhihan Wang, Mingyu Fan
<strong>Venue:</strong> arXiv (2025)</p><p>Partial dental point clouds often suffer from large missing regions caused by occlusion and limited scanning views, which bias encoder-only global features and force decoders to hallucinate structures. We propose a retrieval-augmented framework for tooth completion that integrates a prototype memory into standard encoder&ndash;decoder pipelines. After encoding a partial input into a global descriptor, the model retrieves the nearest manifold prototype from a learnable memory and fuses it with the query feature through confidence-gated weighting before decoding. The memory is optimized end-to-end and self-organizes into reusable tooth-shape prototypes without requiring tooth-position labels, thereby providing structural priors that stabilize missing-region inference and free decoder capacity for detail recovery. The module is plug-and-play and compatible with common completion backbones, while keeping the same training losses. Experiments on a self-processed Teeth3DS benchmark demonstrate consistent improvements in Chamfer Distance, with visualizations showing sharper cusps, ridges, and interproximal transitions. Our approach provides a simple yet effective way to exploit cross-sample regularities for more accurate and faithful dental point-cloud completion.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03598v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03598v1">üìÑ Download PDF</a></p><hr><h3 id=towards-object-centric-understanding-for-instructional-videoshttpsarxivorgabs251203479v1><a href=https://arxiv.org/abs/2512.03479v1>Towards Object-centric Understanding for Instructional Videos</a><a hidden class=anchor aria-hidden=true href=#towards-object-centric-understanding-for-instructional-videoshttpsarxivorgabs251203479v1>#</a></h3><p><strong>Authors:</strong> Wenliang Guo, Yu Kong
<strong>Venue:</strong> arXiv (2025)</p><p>Understanding procedural activities is crucial for developing future assistive AI that can reason about complex real-world tasks. Existing action-centric methods struggle with the flexibility of real procedures, where step order varies depending on object states. In this work, we propose to shift the focus to an object-centric paradigm by regarding actions as mechanisms that drive state transitions. To advance this direction, we introduce Object-IVQA, a long-form instructional video benchmark with 107 videos and 514 open-ended question-answer pairs annotated with temporally grounded evidence. The benchmark evaluates four dimensions of object-centric reasoning, including state evolution, precondition verification, counterfactual reasoning and mistake recognition. We further propose an agent framework that orchestrates object-centric planning, perception, analysis and generation tools, enabling explicit evidence retrieval and multi-hop reasoning across disjoint segments. Experiments show that existing large vision-language models struggle in object-level recognition and reasoning, whereas our framework achieves substantially improvement.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03479v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03479v1">üìÑ Download PDF</a></p><hr><h2 id=-linguistics>üîç linguistics<a hidden class=anchor aria-hidden=true href=#-linguistics>#</a></h2><h3 id=on-the-treatment-of-thermal-effects-in-the-equation-of-state-on-neutron-star-merger-remnantshttpsarxivorgabs251205118v1><a href=https://arxiv.org/abs/2512.05118v1>On the treatment of thermal effects in the equation of state on neutron star merger remnants</a><a hidden class=anchor aria-hidden=true href=#on-the-treatment-of-thermal-effects-in-the-equation-of-state-on-neutron-star-merger-remnantshttpsarxivorgabs251205118v1>#</a></h3><p><strong>Authors:</strong> Davide Guerra, Milton Ruiz, Michele Pasquali, Pablo Cerd√°-Dur√°n, Arnau Rios, Jos√© A. Font
<strong>Venue:</strong> arXiv (2025)</p><p>We present results from long-term, numerical-relativity simulations of binary neutron star mergers modeled using both, fully tabulated, finite-temperature, equations of state and their corresponding hybrid representations. The simulations extend up to 150 ms which allows us to assess the role of the treatment of finite-temperature effects on the dynamics of the hypermassive neutron star remnant. Our study focuses on the analysis of the spectra of the post-merger gravitational-wave signals and on how these are affected by the treatment of thermal effects in the two EOS representations. Our simulations highlight distinct differences in the GW frequency evolution related to the thermal modeling of the EOS, demonstrating that deviations from established quasi-universal relations become significant at late post-merger phases. Furthermore, we investigate the stability of the HMNS against convection. Employing both the Ledoux criterion, necessary condition for the development of convective instabilities, and the Solberg-H√∏iland criterion, a generalized criterion for axisymmetric perturbations based on a combined analysis of the Brunt-V√§is√§l√§ frequency and of the epicyclic frequency, we show that differential rotation and thermal stratification in the HMNS give rise to local (yet sustained) convective patterns that persist beyond 100 ms after merger. Those convective patterns, while substantially different between tabulated and hybrid EOS treatments, trigger the the excitation of inertial modes with frequencies smaller than those attained by the fundamental quadrupolar mode, and are potentially within reach of third-generation GW detectors. The late-time excitation of inertial modes, previously reported in studies based on hybrid EOS, is fully supported by the tabulated, finite-temperature EOS simulations presented here, which account for thermal effects in a more consistent way.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05118v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05118v1">üìÑ Download PDF</a></p><hr><h3 id=light-x-generative-4d-video-rendering-with-camera-and-illumination-controlhttpsarxivorgabs251205115v1><a href=https://arxiv.org/abs/2512.05115v1>Light-X: Generative 4D Video Rendering with Camera and Illumination Control</a><a hidden class=anchor aria-hidden=true href=#light-x-generative-4d-video-rendering-with-camera-and-illumination-controlhttpsarxivorgabs251205115v1>#</a></h3><p><strong>Authors:</strong> Tianqi Liu, Zhaoxi Chen, Zihao Huang, Shaocong Xu, Saining Zhang, Chongjie Ye, Bohan Li, Zhiguo Cao, Wei Li, Hao Zhao, Ziwei Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Recent advances in illumination control extend image-based methods to video, yet still facing a trade-off between lighting fidelity and temporal consistency. Moving beyond relighting, a key step toward generative modeling of real-world scenes is the joint control of camera trajectory and illumination, since visual dynamics are inherently shaped by both geometry and lighting. To this end, we present Light-X, a video generation framework that enables controllable rendering from monocular videos with both viewpoint and illumination control. 1) We propose a disentangled design that decouples geometry and lighting signals: geometry and motion are captured via dynamic point clouds projected along user-defined camera trajectories, while illumination cues are provided by a relit frame consistently projected into the same geometry. These explicit, fine-grained cues enable effective disentanglement and guide high-quality illumination. 2) To address the lack of paired multi-view and multi-illumination videos, we introduce Light-Syn, a degradation-based pipeline with inverse-mapping that synthesizes training pairs from in-the-wild monocular footage. This strategy yields a dataset covering static, dynamic, and AI-generated scenes, ensuring robust training. Extensive experiments show that Light-X outperforms baseline methods in joint camera-illumination control and surpasses prior video relighting methods under both text- and background-conditioned settings.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05115v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05115v1">üìÑ Download PDF</a></p><hr><h3 id=shadowdraw-from-any-object-to-shadow-drawing-compositional-arthttpsarxivorgabs251205110v1><a href=https://arxiv.org/abs/2512.05110v1>ShadowDraw: From Any Object to Shadow-Drawing Compositional Art</a><a hidden class=anchor aria-hidden=true href=#shadowdraw-from-any-object-to-shadow-drawing-compositional-arthttpsarxivorgabs251205110v1>#</a></h3><p><strong>Authors:</strong> Rundong Luo, Noah Snavely, Wei-Chiu Ma
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce ShadowDraw, a framework that transforms ordinary 3D objects into shadow-drawing compositional art. Given a 3D object, our system predicts scene parameters, including object pose and lighting, together with a partial line drawing, such that the cast shadow completes the drawing into a recognizable image. To this end, we optimize scene configurations to reveal meaningful shadows, employ shadow strokes to guide line drawing generation, and adopt automatic evaluation to enforce shadow-drawing coherence and visual quality. Experiments show that ShadowDraw produces compelling results across diverse inputs, from real-world scans and curated datasets to generative assets, and naturally extends to multi-object scenes, animations, and physical deployments. Our work provides a practical pipeline for creating shadow-drawing art and broadens the design space of computational visual art, bridging the gap between algorithmic design and artistic storytelling. Check out our project page <a href=https://red-fairy.github.io/ShadowDraw/>https://red-fairy.github.io/ShadowDraw/</a> for more results and an end-to-end real-world demonstration of our pipeline!</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05110v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05110v1">üìÑ Download PDF</a></p><hr><h3 id=evoir-towards-all-in-one-image-restoration-via-evolutionary-frequency-modulationhttpsarxivorgabs251205104v1><a href=https://arxiv.org/abs/2512.05104v1>EvoIR: Towards All-in-One Image Restoration via Evolutionary Frequency Modulation</a><a hidden class=anchor aria-hidden=true href=#evoir-towards-all-in-one-image-restoration-via-evolutionary-frequency-modulationhttpsarxivorgabs251205104v1>#</a></h3><p><strong>Authors:</strong> Jiaqi Ma, Shengkai Hu, Jun Wan, Jiaxing Huang, Lefei Zhang, Salman Khan
<strong>Venue:</strong> arXiv (2025)</p><p>All-in-One Image Restoration (AiOIR) tasks often involve diverse degradation that require robust and versatile strategies. However, most existing approaches typically lack explicit frequency modeling and rely on fixed or heuristic optimization schedules, which limit the generalization across heterogeneous degradation. To address these limitations, we propose EvoIR, an AiOIR-specific framework that introduces evolutionary frequency modulation for dynamic and adaptive image restoration. Specifically, EvoIR employs the Frequency-Modulated Module (FMM) that decomposes features into high- and low-frequency branches in an explicit manner and adaptively modulates them to enhance both structural fidelity and fine-grained details. Central to EvoIR, an Evolutionary Optimization Strategy (EOS) iteratively adjusts frequency-aware objectives through a population-based evolutionary process, dynamically balancing structural accuracy and perceptual fidelity. Its evolutionary guidance further mitigates gradient conflicts across degradation and accelerates convergence. By synergizing FMM and EOS, EvoIR yields greater improvements than using either component alone, underscoring their complementary roles. Extensive experiments on multiple benchmarks demonstrate that EvoIR outperforms state-of-the-art AiOIR methods.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05104v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05104v1">üìÑ Download PDF</a></p><hr><h3 id=sa-iqa-redefining-image-quality-assessment-for-spatial-aesthetics-with-multi-dimensional-rewardshttpsarxivorgabs251205098v1><a href=https://arxiv.org/abs/2512.05098v1>SA-IQA: Redefining Image Quality Assessment for Spatial Aesthetics with Multi-Dimensional Rewards</a><a hidden class=anchor aria-hidden=true href=#sa-iqa-redefining-image-quality-assessment-for-spatial-aesthetics-with-multi-dimensional-rewardshttpsarxivorgabs251205098v1>#</a></h3><p><strong>Authors:</strong> Yuan Gao, Jin Song
<strong>Venue:</strong> arXiv (2025)</p><p>In recent years, Image Quality Assessment (IQA) for AI-generated images (AIGI) has advanced rapidly; however, existing methods primarily target portraits and artistic images, lacking a systematic evaluation of interior scenes. We introduce Spatial Aesthetics, a paradigm that assesses the aesthetic quality of interior images along four dimensions: layout, harmony, lighting, and distortion. We construct SA-BENCH, the first benchmark for spatial aesthetics, comprising 18,000 images and 50,000 precise annotations. Employing SA-BENCH, we systematically evaluate current IQA methodologies and develop SA-IQA, through MLLM fine-tuning and a multidimensional fusion approach, as a comprehensive reward framework for assessing spatial aesthetics. We apply SA-IQA to two downstream tasks: (1) serving as a reward signal integrated with GRPO reinforcement learning to optimize the AIGC generation pipeline, and (2) Best-of-N selection to filter high-quality images and improve generation quality. Experiments indicate that SA-IQA significantly outperforms existing methods on SA-BENCH, setting a new standard for spatial aesthetics evaluation. Code and dataset will be open-sourced to advance research and applications in this domain.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05098v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05098v1">üìÑ Download PDF</a></p><hr><h3 id=from-generated-human-videos-to-physically-plausible-robot-trajectorieshttpsarxivorgabs251205094v1><a href=https://arxiv.org/abs/2512.05094v1>From Generated Human Videos to Physically Plausible Robot Trajectories</a><a hidden class=anchor aria-hidden=true href=#from-generated-human-videos-to-physically-plausible-robot-trajectorieshttpsarxivorgabs251205094v1>#</a></h3><p><strong>Authors:</strong> James Ni, Zekai Wang, Wei Lin, Amir Bar, Yann LeCun, Trevor Darrell, Jitendra Malik, Roei Herzig
<strong>Venue:</strong> arXiv (2025)</p><p>Video generation models are rapidly improving in their ability to synthesize human actions in novel contexts, holding the potential to serve as high-level planners for contextual robot control. To realize this potential, a key research question remains open: how can a humanoid execute the human actions from generated videos in a zero-shot manner? This challenge arises because generated videos are often noisy and exhibit morphological distortions that make direct imitation difficult compared to real video. To address this, we introduce a two-stage pipeline. First, we lift video pixels into a 4D human representation and then retarget to the humanoid morphology. Second, we propose GenMimic-a physics-aware reinforcement learning policy conditioned on 3D keypoints, and trained with symmetry regularization and keypoint-weighted tracking rewards. As a result, GenMimic can mimic human actions from noisy, generated videos. We curate GenMimicBench, a synthetic human-motion dataset generated using two video generation models across a spectrum of actions and contexts, establishing a benchmark for assessing zero-shot generalization and policy robustness. Extensive experiments demonstrate improvements over strong baselines in simulation and confirm coherent, physically stable motion tracking on a Unitree G1 humanoid robot without fine-tuning. This work offers a promising path to realizing the potential of video generation models as high-level policies for robot control.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05094v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05094v1">üìÑ Download PDF</a></p><hr><h3 id=foundations-of-diffusion-models-in-general-state-spaces-a-self-contained-introductionhttpsarxivorgabs251205092v1><a href=https://arxiv.org/abs/2512.05092v1>Foundations of Diffusion Models in General State Spaces: A Self-Contained Introduction</a><a hidden class=anchor aria-hidden=true href=#foundations-of-diffusion-models-in-general-state-spaces-a-self-contained-introductionhttpsarxivorgabs251205092v1>#</a></h3><p><strong>Authors:</strong> Vincent Pauline, Tobias H√∂ppe, Kirill Neklyudov, Alexander Tong, Stefan Bauer, Andrea Dittadi
<strong>Venue:</strong> arXiv (2025)</p><p>Although diffusion models now occupy a central place in generative modeling, introductory treatments commonly assume Euclidean data and seldom clarify their connection to discrete-state analogues. This article is a self-contained primer on diffusion over general state spaces, unifying continuous domains and discrete/categorical structures under one lens. We develop the discrete-time view (forward noising via Markov kernels and learned reverse dynamics) alongside its continuous-time limits &ndash; stochastic differential equations (SDEs) in $\mathbb{R}^d$ and continuous-time Markov chains (CTMCs) on finite alphabets &ndash; and derive the associated Fokker&ndash;Planck and master equations. A common variational treatment yields the ELBO that underpins standard training losses. We make explicit how forward corruption choices &ndash; Gaussian processes in continuous spaces and structured categorical transition kernels (uniform, masking/absorbing and more) in discrete spaces &ndash; shape reverse dynamics and the ELBO. The presentation is layered for three audiences: newcomers seeking a self-contained intuitive introduction; diffusion practitioners wanting a global theoretical synthesis; and continuous-diffusion experts looking for an analogy-first path into discrete diffusion. The result is a unified roadmap to modern diffusion methodology across continuous domains and discrete sequences, highlighting a compact set of reusable proofs, identities, and core theoretical principles.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05092v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05092v1">üìÑ Download PDF</a></p><hr><h3 id=the-geometry-of-intelligence-deterministic-functional-topology-as-a-foundation-for-real-world-perceptionhttpsarxivorgabs251205089v1><a href=https://arxiv.org/abs/2512.05089v1>The Geometry of Intelligence: Deterministic Functional Topology as a Foundation for Real-World Perception</a><a hidden class=anchor aria-hidden=true href=#the-geometry-of-intelligence-deterministic-functional-topology-as-a-foundation-for-real-world-perceptionhttpsarxivorgabs251205089v1>#</a></h3><p><strong>Authors:</strong> Eduardo Di Santi
<strong>Venue:</strong> arXiv (2025)</p><p>Real-world physical processes do not generate arbitrary variability: their signals concentrate on compact and low-variability subsets of functional space. This geometric structure enables rapid generalization from a few examples in both biological and artificial systems.
This work develops a deterministic functional-topological framework in which the set of valid realizations of a physical phenomenon forms a compact perceptual manifold with stable invariants and a finite Hausdorff radius. We show that the boundaries of this manifold can be discovered in a fully self-supervised manner through Monte Carlo sampling, even when the governing equations of the system are unknown.
We provide theoretical guarantees, practical estimators of knowledge boundaries, and empirical validations across three domains: electromechanical railway point machines, electrochemical battery discharge curves, and physiological ECG signals.
Our results demonstrate that deterministic functional topology offers a unified mathematical foundation for perception, representation, and world-model construction, explaining why biological learners and self-supervised AI models can generalize from limited observations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05089v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05089v1">üìÑ Download PDF</a></p><hr><h3 id=first-study-of-the-nuclear-response-to-fast-hadrons-via-angular-correlations-between-pions-and-slow-protons-in-electron-nucleus-scatteringhttpsarxivorgabs251205083v1><a href=https://arxiv.org/abs/2512.05083v1>First Study of the Nuclear Response to Fast Hadrons via Angular Correlations between Pions and Slow Protons in Electron-Nucleus Scattering</a><a hidden class=anchor aria-hidden=true href=#first-study-of-the-nuclear-response-to-fast-hadrons-via-angular-correlations-between-pions-and-slow-protons-in-electron-nucleus-scatteringhttpsarxivorgabs251205083v1>#</a></h3><p><strong>Authors:</strong> S. J. Paul, M. Arratia, H. Hakobyan, W. Brooks, A. Acar, P. Achenbach, J. S. Alvarado, W. R. Armstrong, N. A. Baltzell, L. Barion, M. Bashkanov, M. Battaglieri, F. Benmokhtar, A. Bianconi, A. S. Biselli, F. Boss√π, S. Boiarinov, K. -T. Brinkmann, W. J. Briscoe, V. Burkert, T. Cao, D. S. Carman, P. Chatagnon, H. Chinchay, G. Ciullo, P. L. Cole, A. D&rsquo;Angelo, N. Dashyan, R. De Vita, A. Deur, S. Diehl, C. Djalali, R. Dupre, H. Egiyan, A. El Alaoui, L. Elouadrhiri, P. Eugenio, M. Farooq, S. Fegan, A. Filippi, C. Fogler, G. Gavalian, G. P. Gilfoyle, R. W. Gothe, B. Gualtieri, M. Hattawy, F. Hauenstein, T. B. Hayward, M. Hoballah, M. Holtrop, Yu-Chun Hung, Y. Ilieva, D. G. Ireland, E. L. Isupov, D. Jenkins, H. S. Jo, D. Keller, M. Khandaker, A. Kim, V. Klimenko, I. Korover, A. Kripko, V. Kubarovsky, L. Lanza, S. Lee, P. Lenisa, X. Li, D. Marchand, V. Mascagna, B. McKinnon, T. Mineeva, V. Mokeev, E. F. Molina Cardenas, C. Munoz Camacho, P. Nadel-Turonski, T. Nagorna, K. Neupane, S. Niccolai, G. Niculescu, M. Osipenko, A. I. Ostrovidov, M. Ouillon, P. Pandey, M. Paolone, L. L. Pappalardo, R. Paremuzyan, E. Pasyuk, W. Phelps, N. Pilleux, P. S. H. Vaishnavi, S. Polcher Rafael, L. Polizzi, J. W. Price, Y. Prok, A. Radic, T. Reed, J. Richards, M. Ripani, J. Ritman, G. Rosner, S. Schadmand, A. Schmidt, R. A. Schumacher, Y. Sharabian, S. Shrestha, E. Sidoretti, D. Sokhan, N. Sparveris, M. Spreafico, S. Stepanyan, I. I. Strakovsky, S. Strauch, M. Tenorio, F. Touchte Codjo, R. Tyson, M. Ungaro, S. Vallarino, C. Velasquez, L. Venturelli, H. Voskanyan, E. Voutier, Y. Wang, D. P. Watts, U. Weerasinghe, X. Wei, M. H. Wood, L. Xu, Z. Xu, M. Zurek
<strong>Venue:</strong> arXiv (2025)</p><p>We report on the first measurement of angular correlations between high-energy pions and slow protons in electron-nucleus ($eA$) scattering, providing a new probe of how a nucleus responds to a fast-moving quark. The experiment employed the CLAS detector with a 5-GeV electron beam incident on deuterium, carbon, iron, and lead targets. For heavier nuclei, the pion-proton correlation function is more spread-out in azimuth than for lighter ones, and this effect is more pronounced in the $œÄp$ channel than in earlier $œÄœÄ$ studies. The proton-to-pion yield ratio likewise rises with nuclear mass, although the increase appears to saturate for the heaviest targets. These trends are qualitatively reproduced by state-of-the-art $eA$ event generators, including BeAGLE, eHIJING, and GiBUU, indicating that current descriptions of target fragmentation rest on sound theoretical footing. At the same time, the precision of our data exposes model-dependent discrepancies, delineating a clear path for future improvements in the treatment of cold-nuclear matter effects in $eA$ scattering.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05083v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05083v1">üìÑ Download PDF</a></p><hr><h3 id=omtra-a-multi-task-generative-model-for-structure-based-drug-designhttpsarxivorgabs251205080v1><a href=https://arxiv.org/abs/2512.05080v1>OMTRA: A Multi-Task Generative Model for Structure-Based Drug Design</a><a hidden class=anchor aria-hidden=true href=#omtra-a-multi-task-generative-model-for-structure-based-drug-designhttpsarxivorgabs251205080v1>#</a></h3><p><strong>Authors:</strong> Ian Dunn, Liv Toft, Tyler Katz, Juhi Gupta, Riya Shah, Ramith Hettiarachchi, David R. Koes
<strong>Venue:</strong> arXiv (2025)</p><p>Structure-based drug design (SBDD) focuses on designing small-molecule ligands that bind to specific protein pockets. Computational methods are integral in modern SBDD workflows and often make use of virtual screening methods via docking or pharmacophore search. Modern generative modeling approaches have focused on improving novel ligand discovery by enabling de novo design. In this work, we recognize that these tasks share a common structure and can therefore be represented as different instantiations of a consistent generative modeling framework. We propose a unified approach in OMTRA, a multi-modal flow matching model that flexibly performs many tasks relevant to SBDD, including some with no analogue in conventional workflows. Additionally, we curate a dataset of 500M 3D molecular conformers, complementing protein-ligand data and expanding the chemical diversity available for training. OMTRA obtains state of the art performance on pocket-conditioned de novo design and docking; however, the effects of large-scale pretraining and multi-task training are modest. All code, trained models, and dataset for reproducing this work are available at <a href=https://github.com/gnina/OMTRA>https://github.com/gnina/OMTRA</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05080v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05080v1">üìÑ Download PDF</a></p><hr><h3 id=object-reconstruction-under-occlusion-with-generative-priors-and-contact-induced-constraintshttpsarxivorgabs251205079v1><a href=https://arxiv.org/abs/2512.05079v1>Object Reconstruction under Occlusion with Generative Priors and Contact-induced Constraints</a><a hidden class=anchor aria-hidden=true href=#object-reconstruction-under-occlusion-with-generative-priors-and-contact-induced-constraintshttpsarxivorgabs251205079v1>#</a></h3><p><strong>Authors:</strong> Minghan Zhu, Zhiyi Wang, Qihang Sun, Maani Ghaffari, Michael Posa
<strong>Venue:</strong> arXiv (2025)</p><p>Object geometry is key information for robot manipulation. Yet, object reconstruction is a challenging task because cameras only capture partial observations of objects, especially when occlusion occurs. In this paper, we leverage two extra sources of information to reduce the ambiguity of vision signals. First, generative models learn priors of the shapes of commonly seen objects, allowing us to make reasonable guesses of the unseen part of geometry. Second, contact information, which can be obtained from videos and physical interactions, provides sparse constraints on the boundary of the geometry. We combine the two sources of information through contact-guided 3D generation. The guidance formulation is inspired by drag-based editing in generative models. Experiments on synthetic and real-world data show that our approach improves the reconstruction compared to pure 3D generation and contact-based optimization.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05079v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05079v1">üìÑ Download PDF</a></p><hr><h3 id=bullettime-decoupled-control-of-time-and-camera-pose-for-video-generationhttpsarxivorgabs251205076v1><a href=https://arxiv.org/abs/2512.05076v1>BulletTime: Decoupled Control of Time and Camera Pose for Video Generation</a><a hidden class=anchor aria-hidden=true href=#bullettime-decoupled-control-of-time-and-camera-pose-for-video-generationhttpsarxivorgabs251205076v1>#</a></h3><p><strong>Authors:</strong> Yiming Wang, Qihang Zhang, Shengqu Cai, Tong Wu, Jan Ackermann, Zhengfei Kuang, Yang Zheng, Frano Rajiƒç, Siyu Tang, Gordon Wetzstein
<strong>Venue:</strong> arXiv (2025)</p><p>Emerging video diffusion models achieve high visual fidelity but fundamentally couple scene dynamics with camera motion, limiting their ability to provide precise spatial and temporal control. We introduce a 4D-controllable video diffusion framework that explicitly decouples scene dynamics from camera pose, enabling fine-grained manipulation of both scene dynamics and camera viewpoint. Our framework takes continuous world-time sequences and camera trajectories as conditioning inputs, injecting them into the video diffusion model through a 4D positional encoding in the attention layer and adaptive normalizations for feature modulation. To train this model, we curate a unique dataset in which temporal and camera variations are independently parameterized; this dataset will be made public. Experiments show that our model achieves robust real-world 4D control across diverse timing patterns and camera trajectories, while preserving high generation quality and outperforming prior work in controllability. See our website for video results: <a href=https://19reborn.github.io/Bullet4D/>https://19reborn.github.io/Bullet4D/</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05076v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05076v1">üìÑ Download PDF</a></p><hr><h3 id=thermodynamic-universality-across-dissipative-quantum-phase-transitionshttpsarxivorgabs251205074v1><a href=https://arxiv.org/abs/2512.05074v1>Thermodynamic universality across dissipative quantum phase transitions</a><a hidden class=anchor aria-hidden=true href=#thermodynamic-universality-across-dissipative-quantum-phase-transitionshttpsarxivorgabs251205074v1>#</a></h3><p><strong>Authors:</strong> Laetitia P. Bettmann, Artur M. Lacerda, Mark T. Mitchison, John Goold
<strong>Venue:</strong> arXiv (2025)</p><p>We study finite-time driving across second-order dissipative quantum phase transitions described by Lindblad dynamics. We show that the nonadiabatic entropy production, which quantifies deviations from the instantaneous nonequilibrium steady state, exhibits universal power-law scaling with the ramp duration in analogy to the Kibble-Zurek mechanism for closed systems. This establishes the universality of irreversible dissipation induced by driving an open quantum system near criticality. Furthermore, in systems described by bosonic Gaussian states, our scaling laws predict that the nonadiabatic entropy production is independent of driving speed to leading order, revealing a distinctive feature of Gaussian dissipative quantum phase transitions. We validate these analytical predictions in the thermodynamic limit of the driven-dissipative Dicke model and via finite-size scaling in the open Kerr model. Our results establish a general framework for understanding universal nonequilibrium response and thermodynamic irreversibility in critical open quantum systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05074v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05074v1">üìÑ Download PDF</a></p><hr><h3 id=carrollian-holographic-duals-are-non-localhttpsarxivorgabs251205072v1><a href=https://arxiv.org/abs/2512.05072v1>Carrollian holographic duals are non-local</a><a hidden class=anchor aria-hidden=true href=#carrollian-holographic-duals-are-non-localhttpsarxivorgabs251205072v1>#</a></h3><p><strong>Authors:</strong> Jordan Cotler, Prateksh Dhivakar, Kristan Jensen
<strong>Venue:</strong> arXiv (2025)</p><p>Mapping the $S$-matrix of a generic theory of flat space gravity coupled to matter to correlation functions of a putative Carrollian dual, we show that bulk interactions imply boundary non-locality.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05072v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05072v1">üìÑ Download PDF</a></p><hr><h3 id=hybrid-quantum-classical-autoencoders-for-unsupervised-network-intrusion-detectionhttpsarxivorgabs251205069v1><a href=https://arxiv.org/abs/2512.05069v1>Hybrid Quantum-Classical Autoencoders for Unsupervised Network Intrusion Detection</a><a hidden class=anchor aria-hidden=true href=#hybrid-quantum-classical-autoencoders-for-unsupervised-network-intrusion-detectionhttpsarxivorgabs251205069v1>#</a></h3><p><strong>Authors:</strong> Mohammad Arif Rasyidi, Omar Alhussein, Sami Muhaidat, Ernesto Damiani
<strong>Venue:</strong> arXiv (2025)</p><p>Unsupervised anomaly-based intrusion detection requires models that can generalize to attack patterns not observed during training. This work presents the first large-scale evaluation of hybrid quantum-classical (HQC) autoencoders for this task. We construct a unified experimental framework that iterates over key quantum design choices, including quantum-layer placement, measurement approach, variational and non-variational formulations, and latent-space regularization. Experiments across three benchmark NIDS datasets show that HQC autoencoders can match or exceed classical performance in their best configurations, although they exhibit higher sensitivity to architectural decisions. Under zero-day evaluation, well-configured HQC models provide stronger and more stable generalization than classical and supervised baselines. Simulated gate-noise experiments reveal early performance degradation, indicating the need for noise-aware HQC designs. These results provide the first data-driven characterization of HQC autoencoder behavior for network intrusion detection and outline key factors that govern their practical viability. All experiment code and configurations are available at <a href=https://github.com/arasyi/hqcae-network-intrusion-detection>https://github.com/arasyi/hqcae-network-intrusion-detection</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05069v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05069v1">üìÑ Download PDF</a></p><hr><h3 id=perceptually-minimal-color-optimization-for-web-accessibility-a-multi-phase-constrained-approachhttpsarxivorgabs251205067v1><a href=https://arxiv.org/abs/2512.05067v1>Perceptually-Minimal Color Optimization for Web Accessibility: A Multi-Phase Constrained Approach</a><a hidden class=anchor aria-hidden=true href=#perceptually-minimal-color-optimization-for-web-accessibility-a-multi-phase-constrained-approachhttpsarxivorgabs251205067v1>#</a></h3><p><strong>Authors:</strong> Lalitha A R
<strong>Venue:</strong> arXiv (2025)</p><p>Web accessibility guidelines require sufficient color contrast between text and backgrounds; yet, manually adjusting colors often necessitates significant visual deviation, compromising vital brand aesthetics. We present a novel, multi-phase optimization approach for automatically generating WCAG-compliant colors while minimizing perceptual change to original design choices.
Our method treats this as a constrained, non-linear optimization problem, utilizing the modern perceptually uniform OKLCH color space. Crucially, the optimization is constrained to preserve the original hue ($\text{H}$) of the color, ensuring that modifications are strictly limited to necessary adjustments in lightness ($\text{L}$) and chroma ($\text{C}$). This is achieved through a three-phase sequence: binary search, gradient descent, and progressive constraint relaxation.
Evaluation on a dataset of 10,000 procedurally generated color pairs demonstrates that the algorithm successfully resolves accessibility violations in $77.22%$ of cases, with $88.51%$ of successful corrections exhibiting imperceptible color difference ($ŒîE_{2000} &lt; 2.0$) as defined by standard perceptibility thresholds. The median perceptual change for successful adjustments is only $0.76\ ŒîE_{2000}$, and the algorithm achieves this with a median processing time of $0.876\text{ms}$ per color pair.
The approach demonstrates that accessibility compliance and visual design integrity can be achieved simultaneously through a computationally efficient, perceptually-aware optimization that respects brand identity. The algorithm is publicly implemented in the open-source cm-colors Python library.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05067v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05067v1">üìÑ Download PDF</a></p><hr><h3 id=axionic-tunneling-from-a-topological-kondo-insulatorhttpsarxivorgabs251205057v1><a href=https://arxiv.org/abs/2512.05057v1>Axionic tunneling from a topological Kondo insulator</a><a hidden class=anchor aria-hidden=true href=#axionic-tunneling-from-a-topological-kondo-insulatorhttpsarxivorgabs251205057v1>#</a></h3><p><strong>Authors:</strong> Saikat Banerjee, Anuva Aishwarya, Fei Liu, Lin Jiao, Vidya Madhavan, Eugene J. Mele, Piers Coleman
<strong>Venue:</strong> arXiv (2025)</p><p>Discoveries over the past two decades have revealed the remarkable ability of quantum materials to emulate relativistic properties of the vacuum, from Dirac cones in graphene to the Weyl surface states of topological insulators. Yet the most elusive consequence of topology in quantum matter is the axionic $E\cdot B$ term in the electromagnetic response. Here we report a direct signature of axionic physics obtained through scanning tunneling microscopy (STM). Although recent STM experiments using SmB$_6$ nanowires have been interpreted as evidence for spin-polarized currents arising from topological surface states, we show that the observed spin polarization instead originates from axionic electrodynamics. Our analysis reveals a striking voltage-induced magnetization: extremely small voltages ($\sim$ 30 meV) generate tip moments of order 0.1 $Œº_B$ that reverse sign with the applied bias. The magnitude, tunability, and reversibility of this signal are consistent with an axionic $E \cdot B$ coupling, and fully account for the magnetic component of the tip density of states, ruling out static magnetism. Millivolt-scale control of spin polarization in a tunnel junction provides a new route for probing axionic electrodynamics and opens avenues for future STM and spintronics applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05057v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05057v1">üìÑ Download PDF</a></p><hr><h3 id=a-nehari-manifold-method-for-nonvariational-problemshttpsarxivorgabs251205055v1><a href=https://arxiv.org/abs/2512.05055v1>A Nehari manifold method for nonvariational problems</a><a hidden class=anchor aria-hidden=true href=#a-nehari-manifold-method-for-nonvariational-problemshttpsarxivorgabs251205055v1>#</a></h3><p><strong>Authors:</strong> Radu Precup, Andrei Stan
<strong>Venue:</strong> arXiv (2025)</p><p>The aim of this paper is to extend the Nehari manifold method from the variational setting to the nonvariational framework of fixed point equations. This is achieved by constructing a radial energy functional that generalizes the standard one from the variational case. Furthermore, the solutions obtained through our method are localized in conical annular sets, which leads to the existence of multiple solutions. The abstract results are illustrated by two representative applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05055v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05055v1">üìÑ Download PDF</a></p><hr><h3 id=qkan-lstm-quantum-inspired-kolmogorov-arnold-long-short-term-memoryhttpsarxivorgabs251205049v1><a href=https://arxiv.org/abs/2512.05049v1>QKAN-LSTM: Quantum-inspired Kolmogorov-Arnold Long Short-term Memory</a><a hidden class=anchor aria-hidden=true href=#qkan-lstm-quantum-inspired-kolmogorov-arnold-long-short-term-memoryhttpsarxivorgabs251205049v1>#</a></h3><p><strong>Authors:</strong> Yu-Chao Hsu, Jiun-Cheng Jiang, Chun-Hua Lin, Kuo-Chung Peng, Nan-Yow Chen, Samuel Yen-Chi Chen, En-Jui Kuo, Hsi-Sheng Goan
<strong>Venue:</strong> arXiv (2025)</p><p>Long short-term memory (LSTM) models are a particular type of recurrent neural networks (RNNs) that are central to sequential modeling tasks in domains such as urban telecommunication forecasting, where temporal correlations and nonlinear dependencies dominate. However, conventional LSTMs suffer from high parameter redundancy and limited nonlinear expressivity. In this work, we propose the Quantum-inspired Kolmogorov-Arnold Long Short-Term Memory (QKAN-LSTM), which integrates Data Re-Uploading Activation (DARUAN) modules into the gating structure of LSTMs. Each DARUAN acts as a quantum variational activation function (QVAF), enhancing frequency adaptability and enabling an exponentially enriched spectral representation without multi-qubit entanglement. The resulting architecture preserves quantum-level expressivity while remaining fully executable on classical hardware. Empirical evaluations on three datasets, Damped Simple Harmonic Motion, Bessel Function, and Urban Telecommunication, demonstrate that QKAN-LSTM achieves superior predictive accuracy and generalization with a 79% reduction in trainable parameters compared to classical LSTMs. We extend the framework to the Jiang-Huang-Chen-Goan Network (JHCG Net), which generalizes KAN to encoder-decoder structures, and then further use QKAN to realize the latent KAN, thereby creating a Hybrid QKAN (HQKAN) for hierarchical representation learning. The proposed HQKAN-LSTM thus provides a scalable and interpretable pathway toward quantum-inspired sequential modeling in real-world data environments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05049v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05049v1">üìÑ Download PDF</a></p><hr><h3 id=joint-3d-geometry-reconstruction-and-motion-generation-for-4d-synthesis-from-a-single-imagehttpsarxivorgabs251205044v1><a href=https://arxiv.org/abs/2512.05044v1>Joint 3D Geometry Reconstruction and Motion Generation for 4D Synthesis from a Single Image</a><a hidden class=anchor aria-hidden=true href=#joint-3d-geometry-reconstruction-and-motion-generation-for-4d-synthesis-from-a-single-imagehttpsarxivorgabs251205044v1>#</a></h3><p><strong>Authors:</strong> Yanran Zhang, Ziyi Wang, Wenzhao Zheng, Zheng Zhu, Jie Zhou, Jiwen Lu
<strong>Venue:</strong> arXiv (2025)</p><p>Generating interactive and dynamic 4D scenes from a single static image remains a core challenge. Most existing generate-then-reconstruct and reconstruct-then-generate methods decouple geometry from motion, causing spatiotemporal inconsistencies and poor generalization. To address these, we extend the reconstruct-then-generate framework to jointly perform Motion generation and geometric Reconstruction for 4D Synthesis (MoRe4D). We first introduce TrajScene-60K, a large-scale dataset of 60,000 video samples with dense point trajectories, addressing the scarcity of high-quality 4D scene data. Based on this, we propose a diffusion-based 4D Scene Trajectory Generator (4D-STraG) to jointly generate geometrically consistent and motion-plausible 4D point trajectories. To leverage single-view priors, we design a depth-guided motion normalization strategy and a motion-aware module for effective geometry and dynamics integration. We then propose a 4D View Synthesis Module (4D-ViSM) to render videos with arbitrary camera trajectories from 4D point track representations. Experiments show that MoRe4D generates high-quality 4D scenes with multi-view consistency and rich dynamic details from a single image. Code: <a href=https://github.com/Zhangyr2022/MoRe4D>https://github.com/Zhangyr2022/MoRe4D</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05044v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05044v1">üìÑ Download PDF</a></p><hr><h3 id=a-theory-of-backgrounds-and-background-independencehttpsarxivorgabs251205043v1><a href=https://arxiv.org/abs/2512.05043v1>A Theory of Backgrounds and Background Independence</a><a hidden class=anchor aria-hidden=true href=#a-theory-of-backgrounds-and-background-independencehttpsarxivorgabs251205043v1>#</a></h3><p><strong>Authors:</strong> Marc Klinger
<strong>Venue:</strong> arXiv (2025)</p><p>In this note, we describe how the study of backgrounds for general quantum systems can be formulated in terms of the representation theory of abstract $C^*$ algebras. We illustrate our general framework through two example systems: superconductivity and perturbative quantum gravity. In both cases, spontaneously broken symmetries imply the existence of unitarily inequivalent Hilbert spaces that play the role of distinct backgrounds relative to which observables are measured. Background independence can be realized by gauging the broken symmetry; extending the algebra of observables for the theory to include new physical processes that intertwine between these disjoint representations. From the point of view of the background independent theory, different backgrounds have an interpretation as different vacuum expectation values of these intertwining operators. In superconductivity, the intertwiners are intimately related to the Josephson effect. In gravity, they are related to geometric fluctuations. We explain how this framework is connected to recent work on generalized symmetries and algebraic extensions. To this end, we close with some remarks about how the operator algebra of a closed universe may arise from a generalized symmetry associated with the inclusion of the causal wedge inside the entanglement wedge by appealing to subregion-subalgebra duality.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05043v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05043v1">üìÑ Download PDF</a></p><hr><h3 id=semantic-guided-two-stage-gan-for-face-inpainting-with-hybrid-perceptual-encodinghttpsarxivorgabs251205039v1><a href=https://arxiv.org/abs/2512.05039v1>Semantic-Guided Two-Stage GAN for Face Inpainting with Hybrid Perceptual Encoding</a><a hidden class=anchor aria-hidden=true href=#semantic-guided-two-stage-gan-for-face-inpainting-with-hybrid-perceptual-encodinghttpsarxivorgabs251205039v1>#</a></h3><p><strong>Authors:</strong> Abhigyan Bhattacharya, Hiranmoy Roy
<strong>Venue:</strong> arXiv (2025)</p><p>Facial Image inpainting aim is to restore the missing or corrupted regions in face images while preserving identity, structural consistency and photorealistic image quality, a task specifically created for photo restoration. Though there are recent lot of advances in deep generative models, existing methods face problems with large irregular masks, often producing blurry textures on the edges of the masked region, semantic inconsistencies, or unconvincing facial structures due to direct pixel level synthesis approach and limited exploitation of facial priors. In this paper we propose a novel architecture, which address these above challenges through semantic-guided hierarchical synthesis. Our approach starts with a method that organizes and synthesizes information based on meaning, followed by refining the texture. This process gives clear insights into the facial structure before we move on to creating detailed images. In the first stage, we blend two techniques: one that focuses on local features with CNNs and global features with Vision Transformers. This helped us create clear and detailed semantic layouts. In the second stage, we use a Multi-Modal Texture Generator to refine these layouts by pulling in information from different scales, ensuring everything looks cohesive and consistent. The architecture naturally handles arbitrary mask configurations through dynamic attention without maskspecific training. Experiment on two datasets CelebA-HQ and FFHQ shows that our model outperforms other state-of-the-art methods, showing improvements in metrics like LPIPS, PSNR, and SSIM. It produces visually striking results with better semantic preservation, in challenging large-area inpainting situations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05039v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05039v1">üìÑ Download PDF</a></p><hr><h3 id=superactivators-only-the-tail-of-the-distribution-contains-reliable-concept-signalshttpsarxivorgabs251205038v1><a href=https://arxiv.org/abs/2512.05038v1>SuperActivators: Only the Tail of the Distribution Contains Reliable Concept Signals</a><a hidden class=anchor aria-hidden=true href=#superactivators-only-the-tail-of-the-distribution-contains-reliable-concept-signalshttpsarxivorgabs251205038v1>#</a></h3><p><strong>Authors:</strong> Cassandra Goldberg, Chaehyeon Kim, Adam Stein, Eric Wong
<strong>Venue:</strong> arXiv (2025)</p><p>Concept vectors aim to enhance model interpretability by linking internal representations with human-understandable semantics, but their utility is often limited by noisy and inconsistent activations. In this work, we uncover a clear pattern within the noise, which we term the SuperActivator Mechanism: while in-concept and out-of-concept activations overlap considerably, the token activations in the extreme high tail of the in-concept distribution provide a reliable signal of concept presence. We demonstrate the generality of this mechanism by showing that SuperActivator tokens consistently outperform standard vector-based and prompting concept detection approaches, achieving up to a 14% higher F1 score across image and text modalities, model architectures, model layers, and concept extraction techniques. Finally, we leverage SuperActivator tokens to improve feature attributions for concepts.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05038v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05038v1">üìÑ Download PDF</a></p><hr><h3 id=cumulant-expansions-of-operator-groups-of-quantum-many-particle-systemshttpsarxivorgabs251205036v1><a href=https://arxiv.org/abs/2512.05036v1>Cumulant expansions of operator groups of quantum many-particle systems</a><a hidden class=anchor aria-hidden=true href=#cumulant-expansions-of-operator-groups-of-quantum-many-particle-systemshttpsarxivorgabs251205036v1>#</a></h3><p><strong>Authors:</strong> V. I. Gerasimenko, I. V. Gapyak
<strong>Venue:</strong> arXiv (2025)</p><p>The article presents a method of cluster expansions for groups of operators associated with the von Neumann equations for states and the Heisenberg equations for observables, aiming to construct generating operators for nonperturbative solutions to the Cauchy problem for hierarchies of evolution equations of many-particle quantum systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05036v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05036v1">üìÑ Download PDF</a></p><hr><h3 id=exploring-asymmetries-in-three-body-clfv-lepton-decays-probing-cp-violation-in-hnl-extensions-of-the-smhttpsarxivorgabs251205032v1><a href=https://arxiv.org/abs/2512.05032v1>Exploring asymmetries in three-body cLFV lepton decays: probing CP violation in HNL extensions of the SM</a><a hidden class=anchor aria-hidden=true href=#exploring-asymmetries-in-three-body-clfv-lepton-decays-probing-cp-violation-in-hnl-extensions-of-the-smhttpsarxivorgabs251205032v1>#</a></h3><p><strong>Authors:</strong> Adrian Darricau, Jonathan Kriewald, Ana M. Teixeira
<strong>Venue:</strong> arXiv (2025)</p><p>In the context of Standard Model extensions via Majorana sterile fermions, the presence of additional CP violating phases (Dirac and Majorana) has been shown to be at source of important effects in charged lepton flavour violating (cLFV) transitions and decays. Here we will consider further angular observables that can be studied for polarised $œÑ$ and $Œº$ cLFV decays. These include, among others, parity asymmetries and time-reversal asymmetries for generic cLFV 3-body decays, $\ell_Œ±^+ \to \ell_Œ≤^+ \ell_Œ≥^+ \ell_Œ¥^-$. We address relevant correlations between the different classes of observables, and show that one can have sizeable asymmetries, which can be used to further probe this interesting class of SM extensions. Our study leads to the prediction of particular patterns of angular observables, which would allow to potentially falsify the model, should a cLFV signal be observed.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05032v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05032v1">üìÑ Download PDF</a></p><hr><h3 id=efficient-decoders-for-sensing-subspace-codehttpsarxivorgabs251205028v1><a href=https://arxiv.org/abs/2512.05028v1>Efficient Decoders for Sensing Subspace Code</a><a hidden class=anchor aria-hidden=true href=#efficient-decoders-for-sensing-subspace-codehttpsarxivorgabs251205028v1>#</a></h3><p><strong>Authors:</strong> Siva Aditya Gooty, Hessam Mahdavifar
<strong>Venue:</strong> arXiv (2025)</p><p>Sparse antenna array sensing of source/target via direction of arrival (DoA) estimation motivates design of the sensing framework in joint communication and sensing (JCAS) systems for sixth generation (6G) communication systems. Recently, it is established by Mahdavifar, Rajam√§ki, and Pal that array geometry of sparse arrays has fundamental connections with the design of subspace codes in coding theory. This was then utilized to design efficient \textit{sensing subspace codes} that estimate the DoA with good resolution. Specifically, the Bose-Chowla sensing subspace code provides near optimal code design for unique DoA estimation with tight theoretical upper bound on the error performance. However, the currently known decoder for these codes, to estimate the DoA, is a traditional \textit{Maximum-a-Posterior (MAP) decoder} with complexity that is cubic with the number of antennas. In this work, we propose novel efficient decoding algorithms for sensing subspace codes, that reduce the complexity down to quadratic while providing new knobs to tune in order to tradeoff complexity with error performance. The decoders are further evaluated for their performance via Monte Carlo simulations for a range of SNRs demonstrating promising performance that smoothly approaches the MAP performance as the complexity grows from quadratic to cubic in the number of antennas.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05028v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05028v1">üìÑ Download PDF</a></p><hr><h3 id=frobenius-generation-for-algebraic-stackshttpsarxivorgabs251205026v1><a href=https://arxiv.org/abs/2512.05026v1>Frobenius generation for algebraic stacks</a><a hidden class=anchor aria-hidden=true href=#frobenius-generation-for-algebraic-stackshttpsarxivorgabs251205026v1>#</a></h3><p><strong>Authors:</strong> Pat Lank, Fei Peng
<strong>Venue:</strong> arXiv (2025)</p><p>This work investigates the Frobenius morphism on derived categories associated with algebraic stacks in positive characteristic. Particularly, we show that in many cases sufficiently many Frobenius pushforwards of a compact generator produce a classical or strong generator for the bounded derived category of coherent sheaves. In the case of Deligne&ndash;Mumford stacks, we can bound the number of iterates required.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05026v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05026v1">üìÑ Download PDF</a></p><hr><h3 id=htr-convtext-leveraging-convolution-and-textual-information-for-handwritten-text-recognitionhttpsarxivorgabs251205021v1><a href=https://arxiv.org/abs/2512.05021v1>HTR-ConvText: Leveraging Convolution and Textual Information for Handwritten Text Recognition</a><a hidden class=anchor aria-hidden=true href=#htr-convtext-leveraging-convolution-and-textual-information-for-handwritten-text-recognitionhttpsarxivorgabs251205021v1>#</a></h3><p><strong>Authors:</strong> Pham Thach Thanh Truc, Dang Hoai Nam, Huynh Tong Dang Khoa, Vo Nguyen Le Duy
<strong>Venue:</strong> arXiv (2025)</p><p>Handwritten Text Recognition remains challenging due to the limited data, high writing style variance, and scripts with complex diacritics. Existing approaches, though partially address these issues, often struggle to generalize without massive synthetic data. To address these challenges, we propose HTR-ConvText, a model designed to capture fine-grained, stroke-level local features while preserving global contextual dependencies. In the feature extraction stage, we integrate a residual Convolutional Neural Network backbone with a MobileViT with Positional Encoding block. This enables the model to both capture structural patterns and learn subtle writing details. We then introduce the ConvText encoder, a hybrid architecture combining global context and local features within a hierarchical structure that reduces sequence length for improved efficiency. Additionally, an auxiliary module injects textual context to mitigate the weakness of Connectionist Temporal Classification. Evaluations on IAM, READ2016, LAM and HANDS-VNOnDB demonstrate that our approach achieves improved performance and better generalization compared to existing methods, especially in scenarios with limited training samples and high handwriting diversity.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05021v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05021v1">üìÑ Download PDF</a></p><hr><h3 id=l√©vy-sources-in-urqmd-in-arsc-collisions-at-sps-energieshttpsarxivorgabs251205019v1><a href=https://arxiv.org/abs/2512.05019v1>L√©vy sources in UrQMD in Ar+Sc collisions at SPS energies</a><a hidden class=anchor aria-hidden=true href=#l√©vy-sources-in-urqmd-in-arsc-collisions-at-sps-energieshttpsarxivorgabs251205019v1>#</a></h3><p><strong>Authors:</strong> Barnabas Porfy, Mate Csanad
<strong>Venue:</strong> arXiv (2025)</p><p>Over the past few decades, progress in femtoscopy has been driven by the interplay between experimental measurements and theoretical calculations. Measurements provide data for the theory to understand it, while theoretical predictions guide new measurements. In the recent decade, several experiments have confirmed that the two-particle pion emitting source is well described by L√©vy alpha-stable distributions. To enable theoretical interpretation, phenomenological simulations have been done at RHIC and LHC energies, using various available heavy-ion collision models. In this paper, we investigate three-dimensional two-pion pair source distributions from $^{40}$Ar+$^{45}$Sc central collisions at SPS energies, generated with the Ultra-Relativistic Quantum Molecular Dynamics Monte-Carlo event generator. We fit the pair source with L√©vy-stable distributions, and discuss the extracted L√©vy parameters describing the spatial scale, shape and strength of the source.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05019v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05019v1">üìÑ Download PDF</a></p><hr><h3 id=isolating-chirality-breaking-smeft-operators-with-drell-yan-angular-analysishttpsarxivorgabs251205018v1><a href=https://arxiv.org/abs/2512.05018v1>Isolating chirality-breaking SMEFT operators with Drell-Yan angular analysis</a><a hidden class=anchor aria-hidden=true href=#isolating-chirality-breaking-smeft-operators-with-drell-yan-angular-analysishttpsarxivorgabs251205018v1>#</a></h3><p><strong>Authors:</strong> Samuele Grossi, Xu Li, Lorenzo Rolla, Riccardo Torre
<strong>Venue:</strong> arXiv (2025)</p><p>We present a comprehensive strategy to isolate the effect of a class of chirality-breaking interactions in the Standard Model Effective Field Theory (SMEFT) by exploiting Drell-Yan angular analysis and the violation of the Lam-Tung relation. Unlike most SMEFT interpretation of Drell-Yan measurements, dominated by growing-with-energy effects generated by the interference of SMEFT-induced and SM amplitudes, this method isolates operators that contribute only quadratically in the Wilson coefficients, allowing for an independent probe of non-interfering operators. Denoting with $v$ the electroweak vev, with $\sqrt{s}$ the center-of-mass energy, and with $Œõ$ the scale of new physics, the non-interfering contributions to the amplitude generated by the chirality-breaking operators can be proportional to $v\sqrt{s}/Œõ^{2}$ or $s/Œõ^{2}$. We argue that these two classes can be further distinguished by analyzing the angular observables of the lepton pair in the transverse momentum and in the invariant mass distribution of the lepton pair. We therefore present an analysis of the lepton-pair angular observables in both these distributions. Based on a precise estimate of the Standard Model contribution to the relevant observables for the $pp\to l^{+}l^{-}+X$ process up to $O(Œ±_{S}^{2})$, we present realistic projections for the sensitivity of the LHC with $300$ fb$^{-1}$ and for the HL-LHC with $3$ ab$^{-1}$ to chirality-breaking interactions, demonstrating that angular observables provide an independent and clean handle on SMEFT effects, especially in regions where the Standard Model contribution is naturally suppressed thanks to the Lam-Tung relation. This analysis becomes crucial to go beyond single parameter global fits, since it helps breaking degeneracies with chirality preserving operators and to disentangle overlapping directions in the EFT parameter space.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05018v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05018v1">üìÑ Download PDF</a></p><hr><h3 id=the-magnus-expansion-in-relativistic-quantum-field-theoryhttpsarxivorgabs251205017v1><a href=https://arxiv.org/abs/2512.05017v1>The Magnus expansion in relativistic quantum field theory</a><a hidden class=anchor aria-hidden=true href=#the-magnus-expansion-in-relativistic-quantum-field-theoryhttpsarxivorgabs251205017v1>#</a></h3><p><strong>Authors:</strong> Andreas Brandhuber, Graham R. Brown, Paolo Pichini, Gabriele Travaglini, Pablo Vives Matasan
<strong>Venue:</strong> arXiv (2025)</p><p>We investigate the Magnus expansion of the $N$-operator in relativistic quantum field theory, which is related to the $S$-matrix via $S = e^{iN}$. We develop direct methods to compute matrix elements of the $N$-operator, which we refer to as Magnus amplitudes, bypassing scattering amplitudes entirely. At tree level, Magnus amplitudes are expressed in terms of retarded and advanced propagators, with each diagram weighted by factors that we identify as Murua coefficients. At loop level this structure is augmented by the Hadamard cut function, and we establish remarkable relations between loop- and tree-level Magnus amplitudes. Among these, we find that $n$-point one-loop Magnus amplitudes are entirely determined by phase-space integrals of forward limits of $(n{+}2)$-point tree-level amplitudes, and hence related to Murua coefficients, and we generalise this to a class of higher-loop contributions. Furthermore, in the case of heavy particles interacting via massless mediators, we conjecture that Magnus diagrams that contribute to the classical limit are always given by forward limits of trees, and we show this explicitly in a one-loop example. We derive these results studying theories of scalar fields with cubic interactions, but our methods are applicable to general theories as well as to integral functions appearing in gravitational-wave computations. Given that Magnus amplitudes are free of hyper-classical terms, and the known relations between Magnus amplitudes and the radial action, our results lay the groundwork for systematic and efficient calculations of classical observables from quantum field theory.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05017v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05017v1">üìÑ Download PDF</a></p><hr><h3 id=generative-neural-video-compression-via-video-diffusion-priorhttpsarxivorgabs251205016v1><a href=https://arxiv.org/abs/2512.05016v1>Generative Neural Video Compression via Video Diffusion Prior</a><a hidden class=anchor aria-hidden=true href=#generative-neural-video-compression-via-video-diffusion-priorhttpsarxivorgabs251205016v1>#</a></h3><p><strong>Authors:</strong> Qi Mao, Hao Cheng, Tinghan Yang, Libiao Jin, Siwei Ma
<strong>Venue:</strong> arXiv (2025)</p><p>We present GNVC-VD, the first DiT-based generative neural video compression framework built upon an advanced video generation foundation model, where spatio-temporal latent compression and sequence-level generative refinement are unified within a single codec. Existing perceptual codecs primarily rely on pre-trained image generative priors to restore high-frequency details, but their frame-wise nature lacks temporal modeling and inevitably leads to perceptual flickering. To address this, GNVC-VD introduces a unified flow-matching latent refinement module that leverages a video diffusion transformer to jointly enhance intra- and inter-frame latents through sequence-level denoising, ensuring consistent spatio-temporal details. Instead of denoising from pure Gaussian noise as in video generation, GNVC-VD initializes refinement from decoded spatio-temporal latents and learns a correction term that adapts the diffusion prior to compression-induced degradation. A conditioning adaptor further injects compression-aware cues into intermediate DiT layers, enabling effective artifact removal while maintaining temporal coherence under extreme bitrate constraints. Extensive experiments show that GNVC-VD surpasses both traditional and learned codecs in perceptual quality and significantly reduces the flickering artifacts that persist in prior generative approaches, even below 0.01 bpp, highlighting the promise of integrating video-native generative priors into neural codecs for next-generation perceptual video compression.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05016v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05016v1">üìÑ Download PDF</a></p><hr><h3 id=hall-like-response-from-anisotropic-fermi-surfaceshttpsarxivorgabs251205014v1><a href=https://arxiv.org/abs/2512.05014v1>Hall-like response from anisotropic Fermi surfaces</a><a hidden class=anchor aria-hidden=true href=#hall-like-response-from-anisotropic-fermi-surfaceshttpsarxivorgabs251205014v1>#</a></h3><p><strong>Authors:</strong> Abhiram Soori
<strong>Venue:</strong> arXiv (2025)</p><p>We demonstrate that an anisotropic and rotated Fermi surface can generate a finite Hall-like transverse response in electron transport, even in the absence of a magnetic field or Berry curvature. Using a two-dimensional continuum model, we show that broken $k_y \to -k_y$ symmetry inherent to anistropic band structures leads to a nonzero transverse conductivity. We construct a lattice model with direction-dependent nearest- and next-nearest-neighbor hoppings that faithfully reproduces the continuum dispersion and allows controlled rotation of the Fermi contour. Employing a multiterminal geometry and the B√ºttiker-probe method, we compute the resulting Hall voltage and establish its direct correspondence with the continuum transverse response. The effect increases with the degree of anisotropy and vanishes at rotation angles where mirror symmetry is restored. Unlike the quantum Hall effect, the Hall response predicted here is not quantized but varies continuously with the band-structure parameters. Our results provide a symmetry-based route to engineer Hall-like signals in low-symmetry materials without magnetic fields or topological effects.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05014v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05014v1">üìÑ Download PDF</a></p><hr><h3 id=detecting-perspective-shifts-in-multi-agent-systemshttpsarxivorgabs251205013v1><a href=https://arxiv.org/abs/2512.05013v1>Detecting Perspective Shifts in Multi-agent Systems</a><a hidden class=anchor aria-hidden=true href=#detecting-perspective-shifts-in-multi-agent-systemshttpsarxivorgabs251205013v1>#</a></h3><p><strong>Authors:</strong> Eric Bridgeford, Hayden Helm
<strong>Venue:</strong> arXiv (2025)</p><p>Generative models augmented with external tools and update mechanisms (or \textit{agents}) have demonstrated capabilities beyond intelligent prompting of base models. As agent use proliferates, dynamic multi-agent systems have naturally emerged. Recent work has investigated the theoretical and empirical properties of low-dimensional representations of agents based on query responses at a single time point. This paper introduces the Temporal Data Kernel Perspective Space (TDKPS), which jointly embeds agents across time, and proposes several novel hypothesis tests for detecting behavioral change at the agent- and group-level in black-box multi-agent systems. We characterize the empirical properties of our proposed tests, including their sensitivity to key hyperparameters, in simulations motivated by a multi-agent system of evolving digital personas. Finally, we demonstrate via natural experiment that our proposed tests detect changes that correlate sensitively, specifically, and significantly with a real exogenous event. As far as we are aware, TDKPS is the first principled framework for monitoring behavioral dynamics in black-box multi-agent systems &ndash; a critical capability as generative agent deployment continues to scale.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05013v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05013v1">üìÑ Download PDF</a></p><hr><h3 id=deep-infant-brain-segmentation-from-multi-contrast-mrihttpsarxivorgabs251205114v1><a href=https://arxiv.org/abs/2512.05114v1>Deep infant brain segmentation from multi-contrast MRI</a><a hidden class=anchor aria-hidden=true href=#deep-infant-brain-segmentation-from-multi-contrast-mrihttpsarxivorgabs251205114v1>#</a></h3><p><strong>Authors:</strong> Malte Hoffmann, Lilla Z√∂llei, Adrian V. Dalca
<strong>Venue:</strong> arXiv (2025)</p><p>Segmentation of magnetic resonance images (MRI) facilitates analysis of human brain development by delineating anatomical structures. However, in infants and young children, accurate segmentation is challenging due to development and imaging constraints. Pediatric brain MRI is notoriously difficult to acquire, with inconsistent availability of imaging modalities, substantial non-head anatomy in the field of view, and frequent motion artifacts. This has led to specialized segmentation models that are often limited to specific image types or narrow age groups, or that are fragile for more variable images such as those acquired clinically. We address this method fragmentation with BabySeg, a deep learning brain segmentation framework for infants and young children that supports diverse MRI protocols, including repeat scans and image types unavailable during training. Our approach builds on recent domain randomization techniques, which synthesize training images far beyond realistic bounds to promote dataset shift invariance. We also describe a mechanism that enables models to flexibly pool and interact features from any number of input scans. We demonstrate state-of-the-art performance that matches or exceeds the accuracy of several existing methods for various age cohorts and input configurations using a single model, in a fraction of the runtime required by many existing tools.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05114v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05114v1">üìÑ Download PDF</a></p><hr><h3 id=resolving-the-molecular-gas-emission-of-the-z25-28-starburst-galaxies-spt0125-47-and-spt-2134-50httpsarxivorgabs251205093v1><a href=https://arxiv.org/abs/2512.05093v1>Resolving the molecular gas emission of the z~2.5-2.8 starburst galaxies SPT0125-47 and SPT 2134-50</a><a hidden class=anchor aria-hidden=true href=#resolving-the-molecular-gas-emission-of-the-z25-28-starburst-galaxies-spt0125-47-and-spt-2134-50httpsarxivorgabs251205093v1>#</a></h3><p><strong>Authors:</strong> K. Kade, M. Bredberg, K. Knudsen, S. K√∂nig, G. Drouart, A. B. Romeo, T. J. L. C. Bakx
<strong>Venue:</strong> arXiv (2025)</p><p>The comoving cosmic star formation rate density peaks at z<del>2-3, with dusty star-forming galaxies being significant contributors to this peak. These galaxies are characterized by their high star formation rates and substantial infrared luminosities. The formation mechanisms remain an open question for these galaxies, particularly with respect to how such intense levels of star formation are triggered and maintained. We aim to resolve CO(3-2) emission toward two strongly lensed galaxies, SPT0125-47 and SPT2134-50, at z</del>2.5-2.8 to determine their morphology and physical properties. We used high-resolution ALMA band 3 observations of CO(3-2) emission toward both sources to investigate their properties. We performed parametric and nonparametric lens modeling using the publicly available lens modeling software PyAutoLens. We divided the CO(3-2) emission line into two bins corresponding to the red and blue portions of the emission line and nonparametrically modeled the source plane emission for both bins. We performed a basic analysis of the morphology and kinematics in the source plane using nonparametric lens modeling of the red and blue bins. We found tentative evidence of a velocity gradient across both sources and no evidence of any clumpy structure, companions, or ongoing mergers. The previously calculated high star formation rates and low depletion times of both SPT0125-47 and SPT2134-50 suggest that these galaxies are undergoing a dramatic phase in their evolution. Given the lack of evidence of ongoing interactions or mergers in our source plane models, we suggest that the intense star formation was triggered by a recent interaction and/or merger. We also consider the possibility that these galaxies might be in the process of settling into disks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05093v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05093v1">üìÑ Download PDF</a></p><hr><h3 id=prediction-of-novel-li-agii-f-compounds-using-evolutionary-algorithmshttpsarxivorgabs251205048v1><a href=https://arxiv.org/abs/2512.05048v1>Prediction of Novel Li-AgII-F Compounds using Evolutionary Algorithms</a><a hidden class=anchor aria-hidden=true href=#prediction-of-novel-li-agii-f-compounds-using-evolutionary-algorithmshttpsarxivorgabs251205048v1>#</a></h3><p><strong>Authors:</strong> Katarzyna Kuder, Wojciech Grochala
<strong>Venue:</strong> arXiv (2025)</p><p>This work provides a theoretical exploration of the thermodynamic stability and magnetic behaviour of previously unknown ternary Li AgII F compounds. Convex-hull analysis shows that all predicted structures lie slightly above the LiF plus AgF2 decomposition line, indicating a natural tendency toward phase separation; nevertheless, their negative formation energies relative to AgF, LiF, and F2 or F suggest that alternative synthetic pathways may be feasible for these compounds. All studied structures show preference for antiferromagnetic ground state. Notably, the triclinic LiAgF3 type2 is predicted to exhibit an exceptionally large superexchange constant, J equal to minus 358 meV, within Ag2F7 dimers, placing it above the strongest known magnetic exchange interactions reported to date.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05048v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05048v1">üìÑ Download PDF</a></p><hr><h3 id=structured-light-at-the-extreme-harnessing-spatiotemporal-control-for-high-field-laser-matter-interactionshttpsarxivorgabs251205042v1><a href=https://arxiv.org/abs/2512.05042v1>Structured Light at the Extreme: Harnessing Spatiotemporal Control for High-Field Laser-Matter Interactions</a><a hidden class=anchor aria-hidden=true href=#structured-light-at-the-extreme-harnessing-spatiotemporal-control-for-high-field-laser-matter-interactionshttpsarxivorgabs251205042v1>#</a></h3><p><strong>Authors:</strong> Sergio Carbajo, Seung-Whan Bahk, Justin Baker, Andrea Bertozzi, Abhimanyu Borthakur, Antonino Di Piazza, Andrew Forbes, Spencer Gessner, Jack Hirschman, Franz K√§rtner, Maciej Lewenstein, Yuhang Li, Inhyuk Nam, Eileen Otte, Aydogan Ozcan, James Rozensweig, Yijie Shen, Liwei Song, Ye Tian, Yu Wang, Yuntian Wang, Logan Wright, Xiaojun Wu, Hao Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>This review charts the emerging paradigm of intelligent structured light for high-field laser-matter interactions, where the precise spatiotemporal and vectorial control of light is a critical degree of freedom. We outline a transformative framework built upon three synergistic pillars. First, we survey the advanced electromagnetic toolkit, moving beyond conventional spatial light modulators to include robust static optics and the promising frontier of plasma light modulators. Second, we detail the optimization engine for this high-dimensional design space, focusing on physics-informed digital twins and AI-driven inverse design to automate the discovery of optimal light structures. Finally, we explore the groundbreaking applications enabled by this integrated approach, including programmable electron beams, orbital-angular-momentum-carrying Œ≥-rays, compact THz accelerators, and robust communications. The path forward necessitates overcoming grand challenges in material science, real-time adaptive control at MHz rates, and the extension of these principles to the quantum realm. This review serves as a call to action for a coordinated, interdisciplinary effort to command, rather than merely observe, light-matter interactions at the extreme.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05042v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05042v1">üìÑ Download PDF</a></p><hr><h3 id=probing-agn-feedback-in-dwarf-galaxies-with-spatially-resolved-nir-coronal-lines-from-jwsthttpsarxivorgabs251205041v1><a href=https://arxiv.org/abs/2512.05041v1>Probing AGN Feedback in Dwarf Galaxies with Spatially Resolved NIR Coronal Lines from JWST</a><a hidden class=anchor aria-hidden=true href=#probing-agn-feedback-in-dwarf-galaxies-with-spatially-resolved-nir-coronal-lines-from-jwsthttpsarxivorgabs251205041v1>#</a></h3><p><strong>Authors:</strong> Archana Aravindan, Thomas Bohn, Gabriela Canalizo, Shobita Satyapal, Vivian U, Weizhe Liu, William Matzko, Sara Doan, Matthew Malkan, Lee Armus, Tohru Nagao, Tanio Diaz-Santos, Aditya Togi, Thomas S. Y. Lai, Sean T. Linden, Marina Bianchin, Yiqing Song, Loreto Barcos-Munoz, Aaron Evans, Hanae Inami, Kirsten Larson, Sabrina Stierwalt, Jason Surace
<strong>Venue:</strong> arXiv (2025)</p><p>We present the first spatially resolved investigation of near-infrared coronal lines in dwarf galaxies hosting active galactic nuclei (AGN), using JWST/NIRSpec integral field spectroscopy. Coronal lines (CLs), which are forbidden transitions from highly ionized species with ionization potentials up to 450 eV, act as sensitive tracers of the AGN ionizing continuum and feedback processes. Across four dwarf galaxies with ionized gas outflows traced by the optical [O III] lines, we report the detection of 16 unique species of near-infrared CLs. Line ratio diagnostics indicate that photoionization from the AGN dominates the excitation of CLs. We find that the coronal line region in dwarf galaxies, traced by the various CLs, extends up to 0.5 kpc, and can constitute up to 10% of their host galaxy size. Correlations between CL luminosities and [O III] ionized gas outflow properties are consistent with a scenario in which AGN-driven outflows likely facilitate the detection of CLs and contribute to their extent. Several CLs, including [Si VI], [Si VII], and [Mg VIII], exhibit a secondary broad component (W$_{80}$ > 300 km/s). If we interpret this spatially compact gas as part of an outflow, this would indicate that the outflowing gas includes a wide range of ionizations. The estimated energetics imply this highly ionized component is compact yet powerful enough to perturb gas in the central regions of the host dwarfs. These results indicate that AGN in low-mass galaxies may produce outflows capable of influencing their structure and evolution.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05041v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05041v1">üìÑ Download PDF</a></p><hr><h3 id=geometric-data-sciencehttpsarxivorgabs251205040v1><a href=https://arxiv.org/abs/2512.05040v1>Geometric Data Science</a><a hidden class=anchor aria-hidden=true href=#geometric-data-sciencehttpsarxivorgabs251205040v1>#</a></h3><p><strong>Authors:</strong> Olga D Anosova, Vitaliy A Kurlin
<strong>Venue:</strong> arXiv (2025)</p><p>This book introduces the new research area of Geometric Data Science, where data can represent any real objects through geometric measurements.
The first part of the book focuses on finite point sets. The most important result is a complete and continuous classification of all finite clouds of unordered points under rigid motion in any Euclidean space. The key challenge was to avoid the exponential complexity arising from permutations of the given unordered points. For a fixed dimension of the ambient Euclidean space, the times of all algorithms for the resulting invariants and distance metrics depend polynomially on the number of points.
The second part of the book advances a similar classification in the much more difficult case of periodic point sets, which model all periodic crystals at the atomic scale. The most significant result is the hierarchy of invariants from the ultra-fast to complete ones. The key challenge was to resolve the discontinuity of crystal representations that break down under almost any noise. Experimental validation on all major materials databases confirmed the Crystal Isometry Principle: any real periodic crystal has a unique location in a common moduli space of all periodic structures under rigid motion. The resulting moduli space contains all known and not yet discovered periodic crystals and hence continuously extends Mendeleev&rsquo;s table to the full crystal universe.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05040v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05040v1">üìÑ Download PDF</a></p><hr><h3 id=spectrum-and-anisotropies-of-galactic-cosmic-rays-a-laboratory-for-magnetic-fieldshttpsarxivorgabs251205035v1><a href=https://arxiv.org/abs/2512.05035v1>Spectrum and anisotropies of Galactic cosmic rays: a laboratory for magnetic fields</a><a hidden class=anchor aria-hidden=true href=#spectrum-and-anisotropies-of-galactic-cosmic-rays-a-laboratory-for-magnetic-fieldshttpsarxivorgabs251205035v1>#</a></h3><p><strong>Authors:</strong> Philipp Mertsch
<strong>Venue:</strong> arXiv (2025)</p><p>Much has been learned about Galactic cosmic rays in the past decade: On the observational side, the spectra of cosmic ray nuclei have been directly measured with high precision, resolving chemical composition up to TV rigidities. At even higher rigidities, direct detection is making contact with indirect observations from air shower arrays. A number of breaks have been found in the nuclear spectrum, which was previously thought to be a pure power law up to the knee. Data from air shower arrays also show interesting features in the arrival directions of cosmic-ray nuclei. On the theoretical side, more sophisticated models are able to explain the various spectral breaks either with transitions between different classes of sources or with changes in the transport regime. Yet, it has become clear that our ignorance of the structure of the Galactic magnetic fields, both on large and small scales, is limiting precision predictions. Turning this problem into an opportunity though, we can use Galactic cosmic rays as a laboratory for the study of Galactic magnetic fields. In this review talk, delivered at the 39th International Cosmic Ray Conference (ICRC2025), I have summarised what is known about the spectrum and anisotropies of Galactic cosmic rays, what is not known yet and what can be learnt in the future.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05035v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05035v1">üìÑ Download PDF</a></p><hr><h3 id=emergence-of-erepr-from-non-local-gravitational-energyhttpsarxivorgabs251205022v1><a href=https://arxiv.org/abs/2512.05022v1>Emergence of ER=EPR from non-local gravitational energy</a><a hidden class=anchor aria-hidden=true href=#emergence-of-erepr-from-non-local-gravitational-energyhttpsarxivorgabs251205022v1>#</a></h3><p><strong>Authors:</strong> Kimet Jusufi, Francisco S. N. Lobo, Emmanuel N. Saridakis, Douglas Singleton
<strong>Venue:</strong> arXiv (2025)</p><p>We construct a class of wormhole geometries supported by the non-local gravitational self-energy that regularizes the particle and black-hole sectors of spacetime. Using this framework, inspired by T-duality, we show that two entangled particles (or particle-black-hole pairs) naturally source an Einstein-Rosen-type geometry in which the required violation of the strong energy condition arises from intrinsic quantum-gravity effects rather than from ad hoc exotic matter, which is matter that violates the null energy condition. We classify the resulting wormholes, analyze their horizons, throat structure and embedding properties, and we identify the exotic energy needed at the minimal surface. Imposing the ER=EPR requirement of non-traversability and the absence of a macroscopic throat, we find that only the zero-throat geometry is compatible with an entanglement-induced Einstein-Rosen bridge, providing a concrete realization of ER=EPR within a fully regular spacetime. Finally, we briefly discuss possible implications for microscopic ER networks from vacuum fluctuations, replica-wormhole interpretations of Hawking radiation, and possible links to entanglement-driven dark-energy scenarios.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05022v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05022v1">üìÑ Download PDF</a></p><hr><h3 id=revealing-stimulus-dependent-dynamics-through-statistical-complexityhttpsarxivorgabs251205007v1><a href=https://arxiv.org/abs/2512.05007v1>Revealing stimulus-dependent dynamics through statistical complexity</a><a hidden class=anchor aria-hidden=true href=#revealing-stimulus-dependent-dynamics-through-statistical-complexityhttpsarxivorgabs251205007v1>#</a></h3><p><strong>Authors:</strong> Edson V. de Paula, Rafael M. Jungmann, Antonio J. Fontenele, Leandro A. A. Aguiar, Pedro V. Carelli, Fernanda S. Matias, Mauro Copelli, Nivaldo A. P. de Vasconcelos
<strong>Venue:</strong> arXiv (2025)</p><p>Advances in large-scale neural recordings have expanded our ability to describe the activity of distributed brain circuits. However, understanding how neural population dynamics differ across regions and behavioral contexts remains challenging. Here, we surveyed neuronal population dynamics across multiple mouse brain areas (visual cortex, hippocampus, thalamus, and midbrain) using spike data from local ensembles. Two complementary measures were used to characterize these dynamics: the coefficient of variation (CV), a classical indicator of spike-time variability, and statistical complexity, an information-theoretic quantifier of organizational structure. To probe stimulus-dependent activity, we segmented and concatenated recordings from behavioral experiments into distinct time series corresponding to natural image presentations, blank screens during visual task, and spontaneous activity. While the CV failed to discriminate between these conditions, statistical complexity revealed clear, stimulus-specific motifs in population activity. These results indicate that information-theoretic measures can uncover structured, stimulus-dependent patterns in neural population dynamics that remain unobserved in traditional variability metrics.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05007v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05007v1">üìÑ Download PDF</a></p><hr><h3 id=generalized-pinching-antenna-systems-a-leaky-coaxial-cable-perspectivehttpsarxivorgabs251204979v1><a href=https://arxiv.org/abs/2512.04979v1>Generalized Pinching-Antenna Systems: A Leaky-Coaxial-Cable Perspective</a><a hidden class=anchor aria-hidden=true href=#generalized-pinching-antenna-systems-a-leaky-coaxial-cable-perspectivehttpsarxivorgabs251204979v1>#</a></h3><p><strong>Authors:</strong> Kaidi Wang, Zhiguo Ding, Lajos Hanzo
<strong>Venue:</strong> arXiv (2025)</p><p>The evolution toward the sixth-generation (6G) wireless networks has flexible reconfigurable antenna architectures capable of adapting their radiation characteristics to the surrounding environment. At the center-stage, while waveguide based pinching antennas have been shown to beneficially ameliorate wireless propagation environments, their applications have remained confined to high-frequency scenarios. As a remedy, we propose a downlink generalized pinching-antenna system that adapts this compelling concept to low-frequency operation through a leaky-coaxial-cable (LCX) implementation. By endowing LCX structures with controllable radiation slots, the system inherits the key capabilities of waveguide based pinching antennas. Explicitly, these include reconfigurable line-of-sight (LoS) links, reduced path loss, and flexible deployment, while supporting a practical implementation of the pinching-antenna concept at low frequencies. A twin-stage propagation model is developed for characterizing both the guided transmission and wireless radiation encountered over LoS and non-line-of-sight (NLoS) paths. Analytical results reveal strong local gain, complemented by rapid distance-dependent decay. Hence, we conceive a matching joint optimization framework, which maximizes throughput by harnessing game-theoretic association and convex power allocation. Simulation results demonstrate substantial performance gains over conventional fixed-antenna benchmarks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04979v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04979v1">üìÑ Download PDF</a></p><hr><h3 id=tracing-the-horizon-of-tetragonal-to-monoclinic-distortion-in-pressurized-trilayer-nickelate-la4ni3o10httpsarxivorgabs251204975v1><a href=https://arxiv.org/abs/2512.04975v1>Tracing the horizon of tetragonal-to-monoclinic distortion in pressurized trilayer nickelate La4Ni3O10</a><a hidden class=anchor aria-hidden=true href=#tracing-the-horizon-of-tetragonal-to-monoclinic-distortion-in-pressurized-trilayer-nickelate-la4ni3o10httpsarxivorgabs251204975v1>#</a></h3><p><strong>Authors:</strong> Sitaram Ramakrishnan, Yingzheng Gao, Valerio Olevano, Elise Pachoud, Abdellali Hadj-Azzem, Gaston Gabarino, Olivier Perez, Alain Pautrat, Diego Valenti, Matthieu Quenot, Sebastien Pairis, Dmitry Chernyshov, Leila Noohinejad, Carsten Paulmann, Sander van Smaalen, Pierre Toulemonde, Marie-Aude Measson, Pierre Rodiere
<strong>Venue:</strong> arXiv (2025)</p><p>The crux of understanding the superconducting mechanism in pressurized Ruddlesden-Popper nickelates hinges on elucidating their structural phases. Under ambient conditions, the trilayer nickelate La4Ni3O10 stabilizes in a twinned monoclinic structure with space group P21/c. Upon heating, it undergoes a structural transition to the tetragonal I4/mmm phase at Ts ~ 1030 K, while a second transition associated with the onset of density-weave (DW) ordering emerges upon cooling below TDW ~ 135 K. Here from pressure-temperature x-ray diffraction on high quality flux-grown single crystals we unequivocally demonstrate a direct tetragonal-to-monoclinic transition with no trace of intermediate orthorhombic Bmab phase. Ab initio density-functional theory calculations as a function of pressure fully corroborate the experimental observations. The transition unfolds as a 2-fold superstructure due to the emergence of commensurate superlattice reflections and can be progressively suppressed from 1030 K down to 20 K under 14 GPa. No discernible structural distortions associated with DW ordering are detected down to 20 K at ambient pressure. This is in contrast to Raman measurements that reveal the appearance of additional phonon modes below 130 K, implying a further reduction in symmetry from monoclinic P21/c and thus indicating the presence of a third structural phase associated with the DW ordering in La4Ni3O10.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04975v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04975v1">üìÑ Download PDF</a></p><hr><h3 id=preliminary-analysis-and-simulation-of-a-compact-variable-stiffness-wristhttpsarxivorgabs251204973v1><a href=https://arxiv.org/abs/2512.04973v1>Preliminary Analysis and Simulation of a Compact Variable Stiffness Wrist</a><a hidden class=anchor aria-hidden=true href=#preliminary-analysis-and-simulation-of-a-compact-variable-stiffness-wristhttpsarxivorgabs251204973v1>#</a></h3><p><strong>Authors:</strong> Giuseppe Milazzo, Manuel G. Catalano, Antonio Bicchi, Giorgio Grioli
<strong>Venue:</strong> arXiv (2025)</p><p>Variable Stiffness Actuators prove invaluable for robotics applications in unstructured environments, fostering safe interactions and enhancing task adaptability. Nevertheless, their mechanical design inevitably results in larger and heavier structures compared to classical rigid actuators. This paper introduces a novel 3 Degrees of Freedom (DoFs) parallel wrist that achieves variable stiffness through redundant elastic actuation. Leveraging its parallel architecture, the device employs only four motors, rendering it compact and lightweight. This characteristic makes it particularly well-suited for applications in prosthetics or humanoid robotics. The manuscript delves into the theoretical model of the device and proposes a sophisticated control strategy for independent regulation of joint position and stiffness. Furthermore, it validates the proposed controller through simulation, utilizing a comprehensive analysis of the system dynamics. The reported results affirm the ability of the device to achieve high accuracy and disturbance rejection in rigid configurations while minimizing interaction forces with its compliant behavior.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04973v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04973v1">üìÑ Download PDF</a></p><hr><h3 id=internal-superfluid-response-and-torque-evolution-in-the-giant-glitch-of-psr-j1718-3718httpsarxivorgabs251204972v1><a href=https://arxiv.org/abs/2512.04972v1>Internal superfluid response and torque evolution in the giant glitch of PSR J1718-3718</a><a hidden class=anchor aria-hidden=true href=#internal-superfluid-response-and-torque-evolution-in-the-giant-glitch-of-psr-j1718-3718httpsarxivorgabs251204972v1>#</a></h3><p><strong>Authors:</strong> Peng Liu, Zhonghao Tu, Jianping Yuan, Ang Li
<strong>Venue:</strong> arXiv (2025)</p><p>We investigate the post-glitch rotational evolution of pulsars by analyzing the 2007 giant glitch of PSR J1718$-$3718 using a vortex creep model that incorporates both inward and outward nonlinear vortex motion, along with a time-varying external torque. A comprehensive fitting framework is developed, constrained by prior knowledge of moment of inertia participation from previous glitch studies. We apply a Markov Chain Monte Carlo approach to quantify uncertainties and parameter correlations. The model reproduces the observed timing data and yields physically consistent values for moment of inertia fractions and creep timescales. Our results indicate that inward creep and a long-term change in external torque dominate the observed increase in spin-down rate, pointing to structural changes within the star-likely triggered by a crustquake that initiated both vortex motion and a change in the moment of inertia. We estimate that the glitch involved approximately $2.4 \times 10^{12}$ inward-moving vortices and $\sim 142$ crustal plates with a typical size of $\sim 0.03$ km. This study demonstrates that detailed post-glitch modeling of sparse timing data can simultaneously constrain internal superfluid dynamics and external torque evolution, providing a quantitative framework to probe the structural properties of neutron star interiors.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04972v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04972v1">üìÑ Download PDF</a></p><hr><h3 id=geopea-unified-geometric-positional-embedding-for-structured-tensorshttpsarxivorgabs251204963v1><a href=https://arxiv.org/abs/2512.04963v1>GeoPE:A Unified Geometric Positional Embedding for Structured Tensors</a><a hidden class=anchor aria-hidden=true href=#geopea-unified-geometric-positional-embedding-for-structured-tensorshttpsarxivorgabs251204963v1>#</a></h3><p><strong>Authors:</strong> Yupu Yao, Bowen Yang
<strong>Venue:</strong> arXiv (2025)</p><p>Standard Vision Transformers flatten 2D images into 1D sequences, disrupting the natural spatial topology. While Rotary Positional Embedding (RoPE) excels in 1D, it inherits this limitation, often treating spatially distant patches (e.g., at row edges) as sequence neighbors. Existing 2D approaches typically treat spatial axes independently, failing to decouple this false sequential proximity from true spatial distance. To restore the 2D spatial manifold, we introduce Geometric Positional Embedding (GeoPE), a framework that extends rotations to 3D Euclidean space using quaternions. To overcome non-commutativity and ensure symmetry, GeoPE constructs a unified rotational operator by computing the geometric mean in the Lie algebra. This creates a geometrically coupled encoding that effectively separates spatial dimensions. Extensive experiments on image classification, object detection, and 3D semantic segmentation demonstrate that GeoPE consistently outperforms existing 2D RoPE variants and significantly enhances shape bias, confirming its ability to capture true geometric structure.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04963v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04963v1">üìÑ Download PDF</a></p><hr><h3 id=existence-and-a-priori-bounds-for-fully-nonlinear-pdes-with-a-harmonic-map-like-structurehttpsarxivorgabs251204961v1><a href=https://arxiv.org/abs/2512.04961v1>Existence and a priori bounds for fully nonlinear PDEs with a harmonic map-like structure</a><a hidden class=anchor aria-hidden=true href=#existence-and-a-priori-bounds-for-fully-nonlinear-pdes-with-a-harmonic-map-like-structurehttpsarxivorgabs251204961v1>#</a></h3><p><strong>Authors:</strong> Gabrielle Nornberg, Ricardo Ziegele
<strong>Venue:</strong> arXiv (2025)</p><p>In this paper, we study a new class of fully nonlinear uniformly elliptic equations with a so-called harmonic map-like structure, whose model case is given by \begin{equation*} \mathcal{M}^{\pm}<em>{Œª,Œõ}(D^2u) \pm b(x) |Du| \pm Œ≤(u)\langle M(x) Du,Du \rangle \pm c(x) u = f(x); \textrm{ in } Œ©, \end{equation*} where $Œ©\subset \mathbb{R}^n$ is a bounded $C^{1,1}$ domain, $\mathcal{M}^{\pm}$ are the Pucci extremal operators, $Œ≤(s) = s^k$ for some $k \in \mathbb{N} $ odd, $b \in L^{q}</em>{+}(Œ©)$, $c,f \in L^p(Œ©)$, and $n \leq p \leq q$, $q>n$.
We obtain existence results under a smallness regime on the coefficients, along with some classical results such as the Aleksandrov&ndash;Bakelman&ndash;Pucci estimate and the comparison principle, as well as a priori bounds for the respective Dirichlet problem in the noncoercive case. We also establish multiplicity results and qualitative behavior, which seem to be new in the case of the Laplacian operator.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04961v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04961v1">üìÑ Download PDF</a></p><hr><h3 id=semantics-lead-the-way-harmonizing-semantic-and-texture-modeling-with-asynchronous-latent-diffusionhttpsarxivorgabs251204926v1><a href=https://arxiv.org/abs/2512.04926v1>Semantics Lead the Way: Harmonizing Semantic and Texture Modeling with Asynchronous Latent Diffusion</a><a hidden class=anchor aria-hidden=true href=#semantics-lead-the-way-harmonizing-semantic-and-texture-modeling-with-asynchronous-latent-diffusionhttpsarxivorgabs251204926v1>#</a></h3><p><strong>Authors:</strong> Yueming Pan, Ruoyu Feng, Qi Dai, Yuqi Wang, Wenfeng Lin, Mingyu Guo, Chong Luo, Nanning Zheng
<strong>Venue:</strong> arXiv (2025)</p><p>Latent Diffusion Models (LDMs) inherently follow a coarse-to-fine generation process, where high-level semantic structure is generated slightly earlier than fine-grained texture. This indicates the preceding semantics potentially benefit texture generation by providing a semantic anchor. Recent advances have integrated semantic priors from pretrained visual encoders to further enhance LDMs, yet they still denoise semantic and VAE-encoded texture synchronously, neglecting such ordering. Observing these, we propose Semantic-First Diffusion (SFD), a latent diffusion paradigm that explicitly prioritizes semantic formation. SFD first constructs composite latents by combining a compact semantic latent, which is extracted from a pretrained visual encoder via a dedicated Semantic VAE, with the texture latent. The core of SFD is to denoise the semantic and texture latents asynchronously using separate noise schedules: semantics precede textures by a temporal offset, providing clearer high-level guidance for texture refinement and enabling natural coarse-to-fine generation. On ImageNet 256x256 with guidance, SFD achieves FID 1.06 (LightningDiT-XL) and FID 1.04 (1.0B LightningDiT-XXL), while achieving up to 100x faster convergence than the original DiT. SFD also improves existing methods like ReDi and VA-VAE, demonstrating the effectiveness of asynchronous, semantics-led modeling. Project page and code: <a href=https://yuemingpan.github.io/SFD.github.io/>https://yuemingpan.github.io/SFD.github.io/</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04926v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04926v1">üìÑ Download PDF</a></p><hr><h3 id=logic-driven-cybersecurity-a-novel-framework-for-system-log-anomaly-detection-using-answer-set-programminghttpsarxivorgabs251204908v1><a href=https://arxiv.org/abs/2512.04908v1>Logic-Driven Cybersecurity: A Novel Framework for System Log Anomaly Detection using Answer Set Programming</a><a hidden class=anchor aria-hidden=true href=#logic-driven-cybersecurity-a-novel-framework-for-system-log-anomaly-detection-using-answer-set-programminghttpsarxivorgabs251204908v1>#</a></h3><p><strong>Authors:</strong> Fang Li, Fei Zuo, Gopal Gupta
<strong>Venue:</strong> arXiv (2025)</p><p>This study explores the application of Answer Set Programming (ASP) for detecting anomalies in system logs, addressing the challenges posed by evolving cyber threats. We propose a novel framework that leverages ASP&rsquo;s declarative nature and logical reasoning capabilities to encode complex security rules as logical predicates. Our ASP-based system was applied to a real-world Linux system log dataset, demonstrating its effectiveness in identifying various anomalies such as potential brute-force attacks, privilege escalations, frequent network connections from specific IPs, and various system-level issues. Key findings highlight ASP&rsquo;s strengths in handling structured log data, rule flexibility, and event correlation. The approach shows promise in providing explainable alerts from real-world data. This research contributes to computer forensics by demonstrating a logic-based paradigm for log analysis on a practical dataset, opening avenues for more nuanced and adaptive cyber intelligence systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04908v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04908v1">üìÑ Download PDF</a></p><hr><h3 id=pvls-a-learning-based-parameter-prediction-technique-for-variational-quantum-linear-solvershttpsarxivorgabs251204909v1><a href=https://arxiv.org/abs/2512.04909v1>PVLS: A Learning-based Parameter Prediction Technique for Variational Quantum Linear Solvers</a><a hidden class=anchor aria-hidden=true href=#pvls-a-learning-based-parameter-prediction-technique-for-variational-quantum-linear-solvershttpsarxivorgabs251204909v1>#</a></h3><p><strong>Authors:</strong> Youla Yang
<strong>Venue:</strong> arXiv (2025)</p><p>Variational Quantum Linear Solvers (VQLS) are a promising method for solving linear systems on near-term quantum devices. However, their performance is often limited by barren plateaus and inefficient parameter initialization, which significantly hinder trainability as the system size increases. In this work, we introduce PVLS, a learning-based parameter prediction framework that uses Graph Neural Networks (GNNs) to generate high-quality initial parameters for VQLS circuits. By leveraging structural information from the coefficient matrix, PVLS predicts expressive and scalable initializations that improve convergence and reduce optimization difficulty. Extensive experiments on matrix sizes ranging from 16 to 1024 show that PVLS provides up to a 2.6x speedup in optimization and requires fewer iterations while maintaining comparable solution accuracy. These results demonstrate the potential of machine-learning-guided initialization strategies for improving the practicality of hybrid quantum-classical algorithms in the NISQ era.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04909v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04909v1">üìÑ Download PDF</a></p><hr><h3 id=optical-readout-of-reconfigurable-layered-magnetic-domain-structure-in-crsbrhttpsarxivorgabs251204887v1><a href=https://arxiv.org/abs/2512.04887v1>Optical Readout of Reconfigurable Layered Magnetic Domain Structure in CrSBr</a><a hidden class=anchor aria-hidden=true href=#optical-readout-of-reconfigurable-layered-magnetic-domain-structure-in-crsbrhttpsarxivorgabs251204887v1>#</a></h3><p><strong>Authors:</strong> Aleksandra ≈Åopion, Pierre-Maurice Piel, Manuel Terbeck, Jan-Hendrik Larusch, Jakob Henz, Marie-Christin Hei√üenb√ºttel, Kseniia Mosina, Thorsten Deilmann, Michael Rohlfing, Zdenek Sofer, Ursula Wurstbauer
<strong>Venue:</strong> arXiv (2025)</p><p>The emergence of intelligent matter has sparked significant interest in next generation technologies. We report on the discovery of a reconfigurable magnetic multilayer domain structure in the van der Waals magnet CrSBr, exhibiting a unique combination of magnetic and optical properties. Applying an external magnetic field along the easy axis drives the hysteretic antiferromagnetic-to-ferromagnetic transition that is not universally binary, but instead develops through a cascade of intermediate magnetic configurations whose multiplicity and stability scale systematically with thickness. This material can be considered as a prototypical intelligent matter, capable of encoding, processing, and storing information through its tunable magnetic structure. The directly linked optical properties of CrSBr, modulated by the magnetic structure, provide a readout mechanism for the stored information compatible with modern information distribution using light. With its adaptive properties, CrSBr is an attractive candidate for neuromorphic circuitries, enabling the design of brain-inspired computing architectures that can learn and evolve in response to changing environments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04887v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04887v1">üìÑ Download PDF</a></p><hr><h3 id=on-hyperbolic-approximations-for-a-class-of-dispersive-and-diffusive-dispersive-equationshttpsarxivorgabs251204882v1><a href=https://arxiv.org/abs/2512.04882v1>On hyperbolic approximations for a class of dispersive and diffusive-dispersive equations</a><a hidden class=anchor aria-hidden=true href=#on-hyperbolic-approximations-for-a-class-of-dispersive-and-diffusive-dispersive-equationshttpsarxivorgabs251204882v1>#</a></h3><p><strong>Authors:</strong> Rahul Barthwal, Firas Dhaouadi, Christian Rohde
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce novel approximate systems for dispersive and diffusive-dispersive equations with nonlinear fluxes. For purely dispersive equations, we construct a first-order, strictly hyperbolic approximation. Local well-posedness of smooth solutions is achieved by constructing a unique symmetrizer that applies to arbitrary smooth fluxes. Under stronger conditions on the fluxes, we provide a strictly convex entropy for the hyperbolic system that corresponds to the energy of the underlying dispersive equation. To approximate diffusive-dispersive equations, we rely on a viscoelastic damped system that is compatible with the found entropy for the hyperbolic approximation of the dispersive evolution. For the resulting hyperbolic-parabolic approximation, we provide a global well-posedness result. Using the relative entropy framework \cite{dafermos2005hyperbolic}, we prove that the solutions of the approximate systems converge to solutions of the original equations. The structure of the new approximate systems allows to apply standard numerical simulation methods from the field of hyperbolic balance laws. We confirm the convergence of our approximations even beyond the validity range of our theoretical findings on set of test cases covering different target equations. We show the applicability of the approach for strong nonlinear effects leading to oscillating or shock-layer-forming behavior.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04882v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04882v1">üìÑ Download PDF</a></p><hr><h3 id=shorting-dynamics-and-structured-kernel-regularizationhttpsarxivorgabs251204874v1><a href=https://arxiv.org/abs/2512.04874v1>Shorting Dynamics and Structured Kernel Regularization</a><a hidden class=anchor aria-hidden=true href=#shorting-dynamics-and-structured-kernel-regularizationhttpsarxivorgabs251204874v1>#</a></h3><p><strong>Authors:</strong> James Tian
<strong>Venue:</strong> arXiv (2025)</p><p>This paper develops a nonlinear operator dynamic that progressively removes the influence of a prescribed feature subspace while retaining maximal structure elsewhere. The induced sequence of positive operators is monotone, admits an exact residual decomposition, and converges to the classical shorted operator. Transporting this dynamic to reproducing kernel Hilbert spaces yields a corresponding family of kernels that converges to the largest kernel dominated by the original one and annihilating the given subspace. In the finite-sample setting, the associated Gram operators inherit a structured residual decomposition that leads to a canonical form of kernel ridge regression and a principled way to enforce nuisance invariance. This gives a unified operator-analytic approach to invariant kernel construction and structured regularization in data analysis.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04874v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04874v1">üìÑ Download PDF</a></p><hr><h3 id=series-of-quasi-uniform-scatterings-with-fast-search-root-systems-and-neural-network-classificationshttpsarxivorgabs251204865v1><a href=https://arxiv.org/abs/2512.04865v1>Series of quasi-uniform scatterings with fast search, root systems and neural network classifications</a><a hidden class=anchor aria-hidden=true href=#series-of-quasi-uniform-scatterings-with-fast-search-root-systems-and-neural-network-classificationshttpsarxivorgabs251204865v1>#</a></h3><p><strong>Authors:</strong> Igor V. Netay
<strong>Venue:</strong> arXiv (2025)</p><p>In this paper we describe an approach to construct large extendable collections of vectors in predefined spaces of given dimensions. These collections are useful for neural network latent space configuration and training. For classification problem with large or unknown number of classes this allows to construct classifiers without classification layer and extend the number of classes without retraining of network from the very beginning. The construction allows to create large well-spaced vector collections in spaces of minimal possible dimension. If the number of classes is known or approximately predictable, one can choose sufficient enough vector collection size. If one needs to significantly extend the number of classes, one can extend the collection in the same latent space, or to incorporate the collection into collection of higher dimensions with same spacing between vectors. Also, regular symmetric structure of constructed vector collections can significantly simplify problems of search for nearest cluster centers or embeddings in the latent space. Construction of vector collections is based on combinatorics and geometry of semi-simple Lie groups irreducible representations with highest weight.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04865v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04865v1">üìÑ Download PDF</a></p><hr><h3 id=penco-a-physics-energy-numerical-consistent-operator-for-3d-phase-field-modelinghttpsarxivorgabs251204863v1><a href=https://arxiv.org/abs/2512.04863v1>PENCO: A Physics-Energy-Numerical-Consistent Operator for 3D Phase Field Modeling</a><a hidden class=anchor aria-hidden=true href=#penco-a-physics-energy-numerical-consistent-operator-for-3d-phase-field-modelinghttpsarxivorgabs251204863v1>#</a></h3><p><strong>Authors:</strong> Mostafa Bamdad, Mohammad Sadegh Eshaghi, Cosmin Anitescu, Navid Valizadeh, Timon Rabczuk
<strong>Venue:</strong> arXiv (2025)</p><p>Accurate and efficient solutions of spatio-temporal partial differential equations (PDEs), such as phase-field models, are fundamental for understanding interfacial dynamics and microstructural evolution in materials science and fluid mechanics. Neural Operators (NOs) have recently emerged as powerful data-driven alternatives to traditional solvers; however, existing architectures often accumulate temporal errors, struggle to generalize in long-horizon simulations, and require large training datasets. To overcome these limitations, we propose PENCO (Physics-Energy-Numerical-Consistent Operator), a hybrid operator-learning framework that integrates physical laws and numerical structure within a data-driven architecture. The formulation introduces an enhanced L^2 Gauss-Lobatto collocation residual around the temporal midpoint that robustly enforces the governing dynamics and significantly improves accuracy, a Fourier-space numerical consistency term that captures the balanced behavior of semi-implicit discretizations, and an energy-dissipation constraint that ensures thermodynamic consistency. Additional low-frequency spectral anchoring and teacher-consistency mechanisms further stabilize learning and suppress long-term error growth. This hybrid design enables PENCO to preserve governing physics while mitigating long-term error growth. Through extensive three-dimensional phase-field benchmarks covering phase ordering, crystallization, epitaxial growth, and complex pattern formation, PENCO demonstrates superior accuracy, stability, and data efficiency compared to state-of-the-art neural operators, including Multi-Head Neural Operator (MHNO) and Fourier Neural Operator (FNO-4D), while maintaining physically consistent evolution. The associated dataset and implementation are available at github.com/MBamdad/PENCO.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04863v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04863v1">üìÑ Download PDF</a></p><hr><h3 id=stochastic-density-functional-theory-through-the-lens-of-multilevel-monte-carlo-methodhttpsarxivorgabs251204860v1><a href=https://arxiv.org/abs/2512.04860v1>Stochastic Density Functional Theory Through the Lens of Multilevel Monte Carlo Method</a><a hidden class=anchor aria-hidden=true href=#stochastic-density-functional-theory-through-the-lens-of-multilevel-monte-carlo-methodhttpsarxivorgabs251204860v1>#</a></h3><p><strong>Authors:</strong> Xue Quan, Huajie Chen
<strong>Venue:</strong> arXiv (2025)</p><p>The stochastic density functional theory (sDFT) has exhibited advantages over the standard Kohn-Sham DFT method and has become an attractive approach for large-scale electronic structure calculations. The sDFT method avoids the expensive matrix diagonalization by introducing a set of random orbitals and approximating the density matrix via Chebyshev expansion of a matrix-valued function. In this work, we study the sDFT with a plane-wave discretization, and discuss variance reduction algorithms in the framework of multilevel Monte Carlo (MLMC) methods. In particular, we show that the density matrix evaluation in sDFT can be decomposed into many levels by increasing the plane-wave cutoffs or the Chebyshev polynomial orders. This decomposition renders the computational cost independent of the discretization size or temperature. To demonstrate the efficiency of the algorithm, we provide rigorous analysis of the statistical errors and present numerical experiments on some material systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04860v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04860v1">üìÑ Download PDF</a></p><hr><h3 id=improving-posterior-inference-of-galaxy-properties-with-image-based-conditional-flow-matchinghttpsarxivorgabs251205078v1><a href=https://arxiv.org/abs/2512.05078v1>Improving Posterior Inference of Galaxy Properties with Image-Based Conditional Flow Matching</a><a hidden class=anchor aria-hidden=true href=#improving-posterior-inference-of-galaxy-properties-with-image-based-conditional-flow-matchinghttpsarxivorgabs251205078v1>#</a></h3><p><strong>Authors:</strong> Mikaeel Yunus, John F. Wu, Benne W. Holwerda
<strong>Venue:</strong> arXiv (2025)</p><p>Estimating physical properties of galaxies from wide-field surveys remains a central challenge in astrophysics. While spectroscopy provides precise measurements, it is observationally expensive, and photometry discards morphological information that correlates with mass, star formation history, metallicity, and dust. We present a conditional flow matching (CFM) framework that leverages pixel-level imaging alongside photometry to improve posterior inference of galaxy properties. Using $\sim10^5$ SDSS galaxies, we compare models trained on photometry alone versus photometry plus images. The image+photometry model outperforms the photometry-only model in posterior inference and more reliably recovers known scaling relations. Morphological information also helps mitigate the dust&ndash;age degeneracy. Our results highlight the potential of integrating morphology into photometric SED fitting pipelines, opening a pathway towards more accurate and physically informed constraints on galaxy properties.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05078v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05078v1">üìÑ Download PDF</a></p><hr><h3 id=on-random-matrix-statistics-of-3d-gravityhttpsarxivorgabs251205045v1><a href=https://arxiv.org/abs/2512.05045v1>On random matrix statistics of 3d gravity</a><a hidden class=anchor aria-hidden=true href=#on-random-matrix-statistics-of-3d-gravityhttpsarxivorgabs251205045v1>#</a></h3><p><strong>Authors:</strong> Daniel L. Jafferis, Liza Rozenberg, Debmalya Sarkar, Diandian Wang
<strong>Venue:</strong> arXiv (2025)</p><p>We show that 3d gravity on manifolds that are topologically a Riemann surface times an interval $Œ£_{g,n}\times I$ with end-of-the-world branes at the ends of the interval is described by a random matrix model, namely the Virasoro minimal string. Because these manifolds have $n$ annular asymptotic boundaries, the path integrals naturally correspond to spectral correlators of open strings upon inverse Fourier transforms. For $g=0$ and $n=2$, we carry out an explicit path integration and find precise agreement with the universal random matrix expression. For Riemann surfaces with negative Euler characteristic, we evaluate the path integral as a gravitational inner product between states prepared by two copies of Virasoro TQFT. Along the way, we clarify the effects of gauging the mapping class group and the connection to chiral 3d gravity.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05045v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05045v1">üìÑ Download PDF</a></p><hr><h3 id=distributed-riemannian-optimization-in-geodesically-non-convex-environmentshttpsarxivorgabs251204915v1><a href=https://arxiv.org/abs/2512.04915v1>Distributed Riemannian Optimization in Geodesically Non-convex Environments</a><a hidden class=anchor aria-hidden=true href=#distributed-riemannian-optimization-in-geodesically-non-convex-environmentshttpsarxivorgabs251204915v1>#</a></h3><p><strong>Authors:</strong> Xiuheng Wang, Ricardo Borsoi, C√©dric Richard, Ali H. Sayed
<strong>Venue:</strong> arXiv (2025)</p><p>This paper studies the problem of distributed Riemannian optimization over a network of agents whose cost functions are geodesically smooth but possibly geodesically non-convex. Extending a well-known distributed optimization strategy called diffusion adaptation to Riemannian manifolds, we show that the resulting algorithm, the Riemannian diffusion adaptation, provably exhibits several desirable behaviors when minimizing a sum of geodesically smooth non-convex functions over manifolds of bounded curvature. More specifically, we establish that the algorithm can approximately achieve network agreement in the sense that Fr√©chet variance of the iterates among the agents is small. Moreover, the algorithm is guaranteed to converge to a first-order stationary point for general geodesically non-convex cost functions. When the global cost function additionally satisfies the Riemannian Polyak-Lojasiewicz (PL) condition, we also show that it converges linearly under a constant step size up to a steady-state error. Finally, we apply this algorithm to a decentralized robust principal component analysis (PCA) problem formulated on the Grassmann manifold and illustrate its convergence and performance through numerical simulations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04915v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04915v1">üìÑ Download PDF</a></p><hr><h3 id=analytical-and-cross-sectional-clinical-validity-of-a-smartphone-based-u-turn-test-in-multiple-sclerosishttpsarxivorgabs251204914v1><a href=https://arxiv.org/abs/2512.04914v1>Analytical and Cross-Sectional Clinical Validity of a Smartphone-Based U-Turn Test in Multiple Sclerosis</a><a hidden class=anchor aria-hidden=true href=#analytical-and-cross-sectional-clinical-validity-of-a-smartphone-based-u-turn-test-in-multiple-sclerosishttpsarxivorgabs251204914v1>#</a></h3><p><strong>Authors:</strong> Marta P≈Çonka, Rafa≈Ç Klimas, Dimitar Stanev, Lorenza Angelini, Natan Napi√≥rkowski, Gabriela Gonz√°lez Chan, Lisa Bunn, Paul S Glazier, Richard Hosking, Jenny Freeman, Jeremy Hobart, Mattia Zanon, Jonathan Marsden, Licinio Craveiro, Mike D Rinderknecht
<strong>Venue:</strong> arXiv (2025)</p><p>The observational GaitLab study (ISRCTN15993728) enrolled adult people with multiple sclerosis (PwMS) with Expanded Disability Status Scale (EDSS) &lt;=6.5. PwMS performed the U-Turn Test (UTT), a smartphone-based assessment of dynamic balance, in a gait laboratory (supervised setting) using 6 smartphones at different body locations and daily during a 2-week remote period (unsupervised setting) using 1 smartphone. In the supervised setting, the accuracy of detecting turns with smartphones was compared against turns detected with a motion capture system (mocap) using F1 scores. Agreement between turn speed measured with smartphones and mocap was assessed by intraclass correlation coefficient (ICC[3,1]) and bias. In the unsupervised setting, test-retest reliability was assessed by ICC(2,1), and correlations with clinical and patient-reported measures by Spearman rank correlation. Ninety-six PwMS were included. In the supervised setting, turns were detected with high accuracy (F1 scores >95% across smartphone wear locations). Smartphone-derived turn speed was comparable across the supervised (1.44 rad/s) and unsupervised settings (1.47 rad/s), and with mocap-derived turn speed (1.47 rad/s). ICC(3,1) revealed high agreement between smartphone- and mocap-derived turn speed (ICC[3,1]: 0.87-0.92 across smartphone wear locations). Bias was minimal (-0.04 to 0.11 rad/s). In the unsupervised setting, test-retest reliability (ICC[2,1]) was >0.90 when aggregating >=2 tests. The UTT correlated with Timed 25-Foot Walk gait speed, EDSS, Ambulation score, 12-item Multiple Sclerosis Walking Scale, and Activities-specific Balance Confidence scale (r=-0.79 to -0.61). The UTT measures turn speed accurately and reproducibly irrespective of smartphone wear location and settings. These findings affirm its potential as a valuable tool in multiple sclerosis trials.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04914v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04914v1">üìÑ Download PDF</a></p><hr><h3 id=fence-flexible-electric-noise-cancellation-endo-shield-for-the-suppression-of-electromagnetic-interference-in-low-field-mrihttpsarxivorgabs251204889v1><a href=https://arxiv.org/abs/2512.04889v1>FENCE: Flexible Electric Noise Cancellation Endo-shield for the Suppression of Electromagnetic Interference in Low-Field MRI</a><a hidden class=anchor aria-hidden=true href=#fence-flexible-electric-noise-cancellation-endo-shield-for-the-suppression-of-electromagnetic-interference-in-low-field-mrihttpsarxivorgabs251204889v1>#</a></h3><p><strong>Authors:</strong> Julia Pfitzer, Martin Uecker, Hermann Scharfetter
<strong>Venue:</strong> arXiv (2025)</p><p>Electromagnetic interference (EMI) is a significant challenge for low-field MRI systems operating without conventional Faraday-shielded rooms. Traditional EMI mitigation approaches include external shields, subject grounding via electrodes, or active noise cancellation requiring synchronized receive channels. These methods either limit portability, introduce patient discomfort, or demand expensive hardware. In this work, we start from the hypothesis that EMI primarily couples capacitively from the body to the RF coil. We investigated two methods of blocking capacitive coupling while preserving inductive MRI signal detection: First, we employed capacitive segmentation of the RF coil and studied its effect on EMI coupling. Second, we present FENCE (Flexible Electromagnetic Noise Cancellation Endo-shield), a novel approach blocking capacitive coupling using flexible PCB shields placed inside the RF coil. FENCE can be retrofitted to existing RF coils. Finite element (FE) simulations were used to estimate the expected shielding performance and the impact on RF coil losses prior to practical implementation. Testing in various realistic scenarios then demonstrated that the combination of FENCE with segmented coils is effective against both environmental noise sources and controlled EMI. In phantom experiments, FENCE increased SNR by up to a factor of 9 and reduced EMI levels to near-baseline levels with 9% reduction in coil quality factor (Q factor), showing good agreement with the predictions from the FE simulations. In-vivo head imaging confirmed these results across diverse electromagnetic environments where SNR increased by up to a factor 2 while showing an 18% decrease in Q factor. FENCE&rsquo;s simple design provides a low-cost solution to EMI in low-field MRI, enhancing image quality while maintaining system portability and accessibility.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04889v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04889v1">üìÑ Download PDF</a></p><hr><h3 id=controlling-carbon-nanostructure-synthesis-in-thermal-plasma-jet-correlation-of-process-parameters-plasma-characteristics-and-product-morphologyhttpsarxivorgabs251204880v1><a href=https://arxiv.org/abs/2512.04880v1>Controlling Carbon Nanostructure Synthesis in Thermal Plasma Jet: Correlation of Process Parameters, Plasma Characteristics, and Product Morphology</a><a hidden class=anchor aria-hidden=true href=#controlling-carbon-nanostructure-synthesis-in-thermal-plasma-jet-correlation-of-process-parameters-plasma-characteristics-and-product-morphologyhttpsarxivorgabs251204880v1>#</a></h3><p><strong>Authors:</strong> Taki Aissou, Jerome Menneveux, Fanny Casteignau, Nadi Braidy, Jocelyn Veilleux
<strong>Venue:</strong> arXiv (2025)</p><p>Thermal plasma has emerged as an effective approach for producing carbon nanostructures without the need for specific catalysts nor substrates. While efforts have focused on the effect of process parameters such as reaction pressure, input power or carbon source, the intricate role and relationship with plasma characteristics like density and temperature are often overlooked due to the complexity of the environment. This study addresses this gap by establishing a correlation between process parameters, plasma characteristics, and product morphology, essential for controlling the growth of carbon nanostructures. We explored the impact of carbon precursor type (CH4 and C2H2), hydrogen, pressure, and flow rate on nanostructure formation. Using in situ optical emission spectroscopy (OES), we mapped the distribution of both temperature and dicarbon molecule (C2) density within the plasma jet. We demonstrate that the growth of low-density nanostructures, such as carbon nanohorns (CNHs), is favoured at dilute C2 local densities and high temperatures, while denser nanostructures, such as onion-like polyhedral graphitic nanocapsules (GNCs), are favoured at higher C2 densities and lower temperatures. The carbon density can be controlled by the flow rate and the pressure, which in turn significantly influence the nanostructure morphology, evolving from graphene nanoflakes (GNFs) to GNCs as either parameter increases. Increasing the H/C ratio from 1 to 8 resulted in a morphological transition from CNHs to GNFs. During the synthesis, the plasma jet temperature surpassed 3,000 K, with crystalline growth occurring 50 to 100 mm below the nozzle.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04880v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04880v1">üìÑ Download PDF</a></p><hr><h3 id=isostructural-phase-transition-and-equation-of-state-of-type-i-and-type-viii-metallic-sodium-borosilicide-clathrateshttpsarxivorgabs251204878v1><a href=https://arxiv.org/abs/2512.04878v1>Isostructural phase transition and equation of state of type-I and type-VIII metallic sodium borosilicide clathrates</a><a hidden class=anchor aria-hidden=true href=#isostructural-phase-transition-and-equation-of-state-of-type-i-and-type-viii-metallic-sodium-borosilicide-clathrateshttpsarxivorgabs251204878v1>#</a></h3><p><strong>Authors:</strong> M. Demoucron, S. Pandolfi, Y. Guarnelli, B. Baptiste, P. Chevignon, N. Guignot, D. Portehault, T. A. Strobel, W. A. Crichton, Y. Le Godec, A. Courac
<strong>Venue:</strong> arXiv (2025)</p><p>Electronic properties of silicon-based clathrates can be tuned by boron incorporation into the silicon cage network. Sodium borosilicides clathrate outstands with uncommon stoichiometry and expected metallic properties, in contrast to other alcali metal semiconductive Zintl borosilicides. In this study, we report an experimental investigation of the high-pressure behavior of type-I and type-VIII sodium borosilicide clathrates. An isostructural phase transition, marked by an abrupt volume collapse at 13 GPa, is observed exclusively in type-I sodium borosilicide clathrates. This transition is attributed to the pressure-induced diffusion of silicon atoms into cationic sites. This mechanism provides the first experimental validation of a transition predicted theoretically for this class of materials. Isostructural phase transitions were only observed in type-I borosilicide. In contrast, the type-VIII borosilicide phase exhibits conventional elastic compression. The metallic character was established using reflectance spectroscopy over a wide energy range, in good agreement with crystallographic data on the boron content.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04878v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04878v1">üìÑ Download PDF</a></p><hr><h3 id=vns-tokamak-openmc-serpent-validation-for-medical-isotope-studieshttpsarxivorgabs251204873v1><a href=https://arxiv.org/abs/2512.04873v1>VNS Tokamak OpenMC-Serpent Validation for Medical Isotope Studies</a><a hidden class=anchor aria-hidden=true href=#vns-tokamak-openmc-serpent-validation-for-medical-isotope-studieshttpsarxivorgabs251204873v1>#</a></h3><p><strong>Authors:</strong> Christopher Ehrich, Christian Bachmann, Pavel Pereslavtsev, Christian Reiter
<strong>Venue:</strong> arXiv (2025)</p><p>The Volumetric Neutron Source (VNS) tokamak is a proposed fusion reactor for testing and qualification of reactor components for future use in a fusion power facility, and has potential use for radioisotope production. The VNS geometry is modeled in the Serpent and OpenMC neutronics codes. Analog neutron-photon coupled simulations are carried out to compare the model&rsquo;s vacuum vessel and blanket components across codes. In the vacuum vessel, neutron and photon flux maps are calculated, while in the blanket region, neutron and photon spectra, (n,T), and (n,2n) reaction rates are calculated and compared between models. The detector response comparisons found the following: neutron flux and (n,T) reactions achieved excellent agreement, the (n,2n) detector response had good agreement, and photon flux had regional discrepancies depending on Serpent tracking used. Hybrid tracking lead to a relative difference of about 20% in the outboard side blanket, where as employment of delta tracking resulted in less than 1% relative difference. On an HPC cluster, Serpent was found to have shorter computation time than OpenMC in neutron photon coupled simulations using both hybrid tracking and delta tracking, but longer in neutron only simulations. An exemplary radioisotope production case is presented for the demonstration of additional VNS capabilities.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04873v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04873v1">üìÑ Download PDF</a></p><hr><h3 id=embodied-co-design-for-rapidly-evolving-agents-taxonomy-frontiers-and-challengeshttpsarxivorgabs251204770v1><a href=https://arxiv.org/abs/2512.04770v1>Embodied Co-Design for Rapidly Evolving Agents: Taxonomy, Frontiers, and Challenges</a><a hidden class=anchor aria-hidden=true href=#embodied-co-design-for-rapidly-evolving-agents-taxonomy-frontiers-and-challengeshttpsarxivorgabs251204770v1>#</a></h3><p><strong>Authors:</strong> Yuxing Wang, Zhiyu Chen, Tiantian Zhang, Qiyue Yin, Yongzhe Chang, Zhiheng Li, Liang Wang, Xueqian Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Brain-body co-evolution enables animals to develop complex behaviors in their environments. Inspired by this biological synergy, embodied co-design (ECD) has emerged as a transformative paradigm for creating intelligent agents-from virtual creatures to physical robots-by jointly optimizing their morphologies and controllers rather than treating control in isolation. This integrated approach facilitates richer environmental interactions and robust task performance. In this survey, we provide a systematic overview of recent advances in ECD. We first formalize the concept of ECD and position it within related fields. We then introduce a hierarchical taxonomy: a lower layer that breaks down agent design into three fundamental components-controlling brain, body morphology, and task environment-and an upper layer that integrates these components into four major ECD frameworks: bi-level, single-level, generative, and open-ended. This taxonomy allows us to synthesize insights from more than one hundred recent studies. We further review notable benchmarks, datasets, and applications in both simulated and real-world scenarios. Finally, we identify significant challenges and offer insights into promising future research directions. A project associated with this survey has been created at <a href=https://github.com/Yuxing-Wang-THU/SurveyBrainBody>https://github.com/Yuxing-Wang-THU/SurveyBrainBody</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04770v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04770v1">üìÑ Download PDF</a></p><hr><h3 id=human-cognitive-biases-in-explanation-based-interaction-the-case-of-within-and-between-session-order-effecthttpsarxivorgabs251204764v1><a href=https://arxiv.org/abs/2512.04764v1>Human Cognitive Biases in Explanation-Based Interaction: The Case of Within and Between Session Order Effect</a><a hidden class=anchor aria-hidden=true href=#human-cognitive-biases-in-explanation-based-interaction-the-case-of-within-and-between-session-order-effecthttpsarxivorgabs251204764v1>#</a></h3><p><strong>Authors:</strong> Dario Pesenti, Alessandro Bogani, Katya Tentori, Stefano Teso
<strong>Venue:</strong> arXiv (2025)</p><p>Explanatory Interactive Learning (XIL) is a powerful interactive learning framework designed to enable users to customize and correct AI models by interacting with their explanations. In a nutshell, XIL algorithms select a number of items on which an AI model made a decision (e.g. images and their tags) and present them to users, together with corresponding explanations (e.g. image regions that drive the model&rsquo;s decision). Then, users supply corrective feedback for the explanations, which the algorithm uses to improve the model. Despite showing promise in debugging tasks, recent studies have raised concerns that explanatory interaction may trigger order effects, a well-known cognitive bias in which the sequence of presented items influences users&rsquo; trust and, critically, the quality of their feedback. We argue that these studies are not entirely conclusive, as the experimental designs and tasks employed differ substantially from common XIL use cases, complicating interpretation. To clarify the interplay between order effects and explanatory interaction, we ran two larger-scale user studies (n = 713 total) designed to mimic common XIL tasks. Specifically, we assessed order effects both within and between debugging sessions by manipulating the order in which correct and wrong explanations are presented to participants. Order effects had a limited, through significant impact on users&rsquo; agreement with the model (i.e., a behavioral measure of their trust), and only when examined withing debugging sessions, not between them. The quality of users&rsquo; feedback was generally satisfactory, with order effects exerting only a small and inconsistent influence in both experiments. Overall, our findings suggest that order effects do not pose a significant issue for the successful employment of XIL approaches. More broadly, our work contributes to the ongoing efforts for understanding human factors in AI.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04764v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04764v1">üìÑ Download PDF</a></p><hr><h3 id=the-next-to-next-to-leading-order-qcd-corrections-to-ee-to-Œ∑_cœá_cjŒ≥-at-b-factorieshttpsarxivorgabs251204758v1><a href=https://arxiv.org/abs/2512.04758v1>The next-to-next-to-leading-order QCD corrections to $e^+e^-\to Œ∑_c/œá_{cJ}+Œ≥$ at B factories</a><a hidden class=anchor aria-hidden=true href=#the-next-to-next-to-leading-order-qcd-corrections-to-ee-to-Œ∑_cœá_cjŒ≥-at-b-factorieshttpsarxivorgabs251204758v1>#</a></h3><p><strong>Authors:</strong> Cong Li, Wen-Long Sang, Hong-Fei Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>We investigate the processes $e^+e^-\to Œ∑_c+Œ≥$ and $e^+e^-\to œá_{cJ}+Œ≥$ at B factories within the NRQCD factorization framework, computing the corresponding helicity amplitudes through $\mathcal{O}(Œ±_s^2)$. The short-distance coefficients are obtained as series expansions in $r=\frac{4m_c^2}{s}$ around $r=0, 1/3, 2/3, 1$, using the method of differential equations. By combining the expansions from all four points, we construct composite asymptotic expressions that reproduce the exact results accurately over the full range $0 \leq r\leq 1$, with relative errors below $0.1%$ over most of the domain and remaining under $1%$ elsewhere. Analytic expressions for the leading and next-to-leading logarithmic terms are extracted in the limit $r\to 0$. Using these results, we compute the unpolarized cross sections and observe that the perturbative corrections are small for $œá_{c0}+Œ≥$, moderate for $œá_{c1}+Œ≥$, and substantial for $Œ∑_c+Œ≥$ and $œá_{c2}+Œ≥$. Theoretical prediction for $œá_{c1}+Œ≥$ is consistent with the {\tt Belle} measurement within $2œÉ$, showing good agreement between theory and experiment. We also predict the angular distribution parameters $Œ±^H_Œ∏$, which are insensitive to NRQCD matrix elements and exhibit small theoretical uncertainties. These parameters further display good stability across different perturbative orders. With the high luminosity anticipated at {\tt Belle 2}, future experimental measurements will thus provide a clear test of NRQCD factorization.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04758v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04758v1">üìÑ Download PDF</a></p><hr><h3 id=static-fission-properties-of-even-even-actinides-within-the-warsaw-macroscopic-microscopic-model-using-fourier-over-spheroid-parameterizationhttpsarxivorgabs251204739v1><a href=https://arxiv.org/abs/2512.04739v1>Static Fission Properties of Even-Even Actinides within the Warsaw Macroscopic-Microscopic Model Using Fourier-over-Spheroid Parameterization</a><a hidden class=anchor aria-hidden=true href=#static-fission-properties-of-even-even-actinides-within-the-warsaw-macroscopic-microscopic-model-using-fourier-over-spheroid-parameterizationhttpsarxivorgabs251204739v1>#</a></h3><p><strong>Authors:</strong> A. Augustyn, T. Cap, R. Capote, M. Kowal, K. Pomorski
<strong>Venue:</strong> arXiv (2025)</p><p>A systematic study of fission barrier heights and static properties of even-even actinide nuclei from Th to Cf has been performed within the Warsaw macroscopic-microscopic model using the five-dimensional Fourier-over-Spheroid (FoS) shape parameterization. The use of a large deformation grid, containing about $1.3\times10^{8}$ points for each nucleus, allows for a refined and numerically complete exploration of the potential energy landscape without dividing the configuration space into subregions or applying interpolation. Barrier heights, extracted via the Immersion Water Flow method, show good agreement with empirical evaluations (including the new IAEA RIPL-4 dataset) with mean deviations below 1 MeV. Special attention is given to the long-debated third, hyperdeformed minimum. For Th isotopes, a shallow but distinct third well appears, whereas it&rsquo;s absent in heavier actinides (U, Pu).</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04739v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04739v1">üìÑ Download PDF</a></p><hr><h3 id=flux-controlled-wall-model-for-large-eddy-simulation-integrating-the-compressible-law-of-the-wallhttpsarxivorgabs251204688v1><a href=https://arxiv.org/abs/2512.04688v1>Flux-controlled wall model for large eddy simulation integrating the compressible law of the wall</a><a hidden class=anchor aria-hidden=true href=#flux-controlled-wall-model-for-large-eddy-simulation-integrating-the-compressible-law-of-the-wallhttpsarxivorgabs251204688v1>#</a></h3><p><strong>Authors:</strong> Youjie Xu, Steffen J. Schmidt, Nikolaus A. Adams
<strong>Venue:</strong> arXiv (2025)</p><p>Recent advances in velocity and temperature transformations have enabled recovery of the law of the wall in compressible wall-bounded turbulent flows. Building on this foundation, a flux-controlled wall model (FCWM) for Large Eddy Simulation (LES) is proposed. Unlike conventional wall-stress models that solve the turbulent boundary layer equations, FCWM formulates the near-wall modeling as a control problem applied directly to the outer LES solution. It consists of three components: (1) the compressible law of the wall, (2) a feedback flux-control strategy, and (3) a shifted boundary condition. The model adjusts the wall shear stress and heat flux based on discrepancies between the computed and target transformed velocity and temperature, respectively, at the matching location. The proposed wall model is evaluated using LES of turbulent channel flows across a broad range of conditions, including quasi-incompressible cases with bulk Mach number (M_b = 0.1) and friction Reynolds number (Re_œÑ= 180 \sim 10{,}000), and compressible cases with (M_b = 0.74 \sim 4.0) and bulk Reynolds number (Re_b = 7667 \sim 34{,}000). The wall-modelled LES reproduce mean velocity and temperature profiles in agreement with direct numerical simulation data. For all tested cases with (M_b \leq 3), the wall model achieves relative errors of (|Œµ_{C_f}| &lt; 4.1%), (|Œµ_{B_q}| &lt; 2.7%), and (|Œµ_{T_c}| &lt; 2.7%) in friction coefficient, non-dimensional heat flux, and centerline temperature, respectively. In the quasi-incompressible regime, the wall model achieves (|Œµ_{C_f}| &lt; 1%). Compared to the conventional equilibrium wall model, the proposed FCWM achieves higher accuracy in compressible turbulent channel flows without solving the boundary layer equations, thereby reducing computational cost.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04688v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04688v1">üìÑ Download PDF</a></p><hr><h3 id=probing-chiral-topological-states-with-permutation-defectshttpsarxivorgabs251204649v1><a href=https://arxiv.org/abs/2512.04649v1>Probing chiral topological states with permutation defects</a><a hidden class=anchor aria-hidden=true href=#probing-chiral-topological-states-with-permutation-defectshttpsarxivorgabs251204649v1>#</a></h3><p><strong>Authors:</strong> Yarden Sheffer, Ruihua Fan, Ady Stern, Erez Berg, Shinsei Ryu
<strong>Venue:</strong> arXiv (2025)</p><p>The hallmark of two-dimensional chiral topological phases is the existence of anomalous gapless modes at the spatial boundary. Yet, the manifestation of this edge anomaly within the bulk ground-state wavefunction itself remains only partially understood. In this work, we introduce a family of multipartite entanglement measures that probe chirality directly from the bulk wavefunction. Our construction involves applying different permutations between replicas of the ground state wavefunction in neighboring spatial regions, creating &ldquo;permutation defects&rdquo; at the boundaries between these regions. We provide general arguments for the robustness of these measures and develop a field-theoretical framework to compute them systematically. While the standard topological field theory prescription misses the chiral contribution, our method correctly identifies it as the chiral conformal field theory partition function on high-genus Riemann surfaces. This feature is a consequence of the bulk-edge correspondence, which dictates that any regularization of the theory at the permutation defects must introduce gapless boundary modes. We numerically verify our results with both free-fermion and strongly-interacting chiral topological states and find excellent agreement. Our results enable the extraction of the chiral central charge and the Hall conductance using a finite number of wavefunction replicas, making these quantities accessible to Monte-Carlo numerical techniques and noisy intermediate-scale quantum devices.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04649v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04649v1">üìÑ Download PDF</a></p><hr><h3 id=contract-governed-training-for-earth-observation-observed-service-agreement-graphs-and-coverage-accuracy-trade-offshttpsarxivorgabs251204644v1><a href=https://arxiv.org/abs/2512.04644v1>Contract-Governed Training for Earth Observation: Observed Service Agreement Graphs and Coverage-Accuracy Trade-offs</a><a hidden class=anchor aria-hidden=true href=#contract-governed-training-for-earth-observation-observed-service-agreement-graphs-and-coverage-accuracy-trade-offshttpsarxivorgabs251204644v1>#</a></h3><p><strong>Authors:</strong> Wenzhang Du
<strong>Venue:</strong> arXiv (2025)</p><p>Earth observation (EO) models are frequently trained under implicit sampling policies that optimize global accuracy but provide no explicit guarantees on who (which regions, classes, or mission-critical strata) is being served throughout training. This paper introduces a contract-governed training paradigm for EO in which training samples are grouped into service contracts &ndash; semantically meaningful units such as (dataset, region, rare-crop indicator) &ndash; and each contract is assigned a target service share. We instantiate this paradigm as an Observed Service Agreement Graph (OSAG), a lightweight governance layer that (i) monitors contract-level exposure (coverage) during optimization, (ii) drives empirical coverage toward target shares via contract-normalized sampling weights, and (iii) exposes explicit accuracy-governance trade-offs through two knobs: a sampling mixture coefficient alpha and a contract-regularization weight lambda_C. We provide a compact theory in a toy setting: OSAG sampling concentrates empirical coverage to targets; coverage deviations upper-bound service-risk deviations; and contract design (coarse vs. fine) modulates governance cost. Experiments on AVIRIS hyperspectral scenes (Indian Pines plus Salinas) and multispectral Sentinel-2 EuroSAT demonstrate that OSAG can substantially reduce priority coverage error while maintaining global accuracy and improving high-priority accuracy. A EuroSAT coarse-vs-fine contract ablation further evidences how semantically refined contracts can reduce the accuracy cost per unit of governance improvement.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04644v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04644v1">üìÑ Download PDF</a></p><hr><h3 id=phase-transitions-on-the-dark-side-of-the-gross-neveu-modelhttpsarxivorgabs251204626v1><a href=https://arxiv.org/abs/2512.04626v1>Phase transitions on the dark side of the Gross-Neveu model</a><a hidden class=anchor aria-hidden=true href=#phase-transitions-on-the-dark-side-of-the-gross-neveu-modelhttpsarxivorgabs251204626v1>#</a></h3><p><strong>Authors:</strong> Gabriel Osiander Rein, Fakher F. Assaad, Igor F. Herbut
<strong>Venue:</strong> arXiv (2025)</p><p>Gross-Neveu model in 2+1 dimensions exhibits a continuous transition from gapless Dirac semimetal to the gapped quantum anomalous Hall (QAH) insulator at a finite (attractive) coupling, at which the inversion and time-reversal symmetry become spontaneously broken, and the flavor O($M$) symmetry remains preserved. A unification of leading order parameters of 2+1 dimensional $N$ four-component Dirac fermions collects all Lorentz-singlet mass-like fermion bilinears, except the one condensing in the QAH state, into an irreducible representation of the O($M=4N$), and predicts another phase transition in the Gross-Neveu model to occur at a strong (repulsive) coupling. Here, a fermionic auxiliary-field quantum Monte Carlo algorithm is employed in order to study a lattice realization of the Gross-Neveu field theory in the repulsive regime, where the sign problem is absent. We indeed find the O($4N$) symmetry breaking transition out of Dirac semimetal to occur and to be weakly first-order for $N=2$, relevant to graphene. The size of the discontinuity and the magnitude of the critical coupling, however, both grow with $N$. Adding a finite chemical potential is found to break the symmetry and cause superconductivity. These results are in broad agreement with the predictions of the unified field theory. Our lattice model also displays an interesting exact O($2N$) symmetry, a subgroup of the low-energy O($4N$), and has the ordered ground state with the order parameter that belongs to its $N(2N-1)$-dimensional representation. Other order parameters are also examined, and a certain hierarchy among those that belong to different representations of the exact $O(2N)$ is observed.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04626v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04626v1">üìÑ Download PDF</a></p><hr><h3 id=the-dynamical-memory-of-tidal-stellar-streams-joint-inference-of-the-galactic-potential-and-the-progenitor-of-gd-1-with-flow-matchinghttpsarxivorgabs251204600v1><a href=https://arxiv.org/abs/2512.04600v1>The dynamical memory of tidal stellar streams: Joint inference of the Galactic potential and the progenitor of GD-1 with flow matching</a><a hidden class=anchor aria-hidden=true href=#the-dynamical-memory-of-tidal-stellar-streams-joint-inference-of-the-galactic-potential-and-the-progenitor-of-gd-1-with-flow-matchinghttpsarxivorgabs251204600v1>#</a></h3><p><strong>Authors:</strong> Giuseppe Viterbo, Tobias Buck
<strong>Venue:</strong> arXiv (2025)</p><p>Stellar streams offer one of the most sensitive probes of the Milky Way`s gravitational potential, as their phase-space morphology encodes both the tidal field of the host galaxy and the internal structure of their progenitors. In this work, we introduce a framework that leverages Flow Matching and Simulation-Based Inference (SBI) to jointly infer the parameters of the GD-1 progenitor and the global properties of the Milky Way potential. Our aim is to move beyond traditional techniques (e.g. orbit-fitting and action-angle methods) by constructing a fully Bayesian, likelihood-free posterior over both host-galaxy parameters and progenitor properties, thereby capturing the intrinsic coupling between tidal stripping dynamics and the underlying potential. To achieve this, we generate a large suite of mock GD-1-like streams using our differentiable N-body code \textsc{\texttt{Odisseo}}, sampling self-consistent initial conditions from a Plummer sphere and evolving them in a flexible Milky Way potential model. We then apply conditional Flow Matching to learn the vector field that transports a base Gaussian distribution into the posterior, enabling efficient, amortized inference directly from stream phase-space data. We demonstrate that our method successfully recovers the true parameters of a fiducial GD-1 simulation, producing well-calibrated posteriors and accurately reproducing parameter degeneracies arising from progenitor-host interactions. Flow Matching provides a powerful, flexible framework for Galactic Archaeology. Our approach enables joint inference on progenitor and Galactic parameters, capturing complex dependencies that are difficult to model with classical likelihood-based methods.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04600v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04600v1">üìÑ Download PDF</a></p><hr><h3 id=a-hybrid-green-kubo-hgk-framework-for-calculating-viscosity-from-short-md-simulationshttpsarxivorgabs251204546v1><a href=https://arxiv.org/abs/2512.04546v1>A hybrid Green-Kubo (hGK) framework for calculating viscosity from short MD simulations</a><a hidden class=anchor aria-hidden=true href=#a-hybrid-green-kubo-hgk-framework-for-calculating-viscosity-from-short-md-simulationshttpsarxivorgabs251204546v1>#</a></h3><p><strong>Authors:</strong> Akash K. Meel, Santosh Mogurampelly
<strong>Venue:</strong> arXiv (2025)</p><p>Viscosity calculation from equilibrium molecular dynamics (MD) simulations relies on the traditional Green-Kubo (GK) framework, which integrates the stress autocorrelation function (SACF) over time. While the formalism is exact in the linear response regime, the traditional approach often suffers from poor convergence and requires extensive phase space sampling, which is computationally demanding for soft matter and polymer systems. In this Letter, we introduce a hybrid Green-Kubo (hGK) framework that alleviates these limitations by partitioning the SACF into two physically meaningful regimes: (i) a short time ballistic component extracted directly from short MD simulations, and (ii) a long time relaxation tail represented using analytically motivated functions, $œÜ(œÑ)$, fitted only to short trajectories. This strategy bypasses the need for extensive sampling while preserving physical rigor. Benchmarking against SPC/E water confirms excellent agreement with established results, and we further demonstrate the efficacy of the method for challenging electrolyte systems (EC-LiTFSI and PEO-LiTFSI), for which the GK framework fails to converge. The computational savings are substantial, with reductions of several orders of magnitude in required sampling, achieved without compromising predictive accuracy. We also discuss the limitations of the hGK framework and outline clear avenues for refinement, including optimal tail selection and robust identification of relaxation regimes in noisy stress data. The hGK framework presented in this Letter provides a conceptually simple, broadly applicable, and computationally efficient route for viscosity prediction in molecular liquids, polymer melts, and ionically conducting soft materials.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04546v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04546v1">üìÑ Download PDF</a></p><hr><h3 id=convergence-dynamics-and-scaling-laws-in-the-dissipative-relativistic-kicked-rotatorhttpsarxivorgabs251204471v1><a href=https://arxiv.org/abs/2512.04471v1>Convergence Dynamics and Scaling Laws in the Dissipative Relativistic Kicked Rotator</a><a hidden class=anchor aria-hidden=true href=#convergence-dynamics-and-scaling-laws-in-the-dissipative-relativistic-kicked-rotatorhttpsarxivorgabs251204471v1>#</a></h3><p><strong>Authors:</strong> Daniel Borin, Danilo S. Rando, Edson D. Leonel, Diego F. M. Oliveira
<strong>Venue:</strong> arXiv (2025)</p><p>We investigate the convergence dynamics of this system near period-doubling bifurcations by combining analytical derivations and large-scale numerical simulations. At the bifurcation threshold ($K = K_c$), the dynamics reduce to a normal form that produces a power-law decay $d(n) \propto n^{-1/2}$, from which the critical exponents $Œ±= 1$, $Œ≤= -1/2$, and $z = -2$ are derived. These analytical predictions are confirmed numerically and shown to satisfy the homogeneous scaling relation $z = Œ±/ Œ≤$. Linearization of the map near the fixed point yields an exponential relaxation law $d_n = d_0 e^{-n/œÑ}$ for $K &lt; K_c$, with $œÑ\propto (K_c - K)^{-1}$, leading to the relaxation exponent $Œ¥= -1$. The remarkable agreement between theory and simulation demonstrates that the dissipative relativistic kicked rotator shares the same universality class as one-dimensional unimodal maps, despite its higher dimensionality and relativistic corrections.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04471v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04471v1">üìÑ Download PDF</a></p><hr><h3 id=biomimetic-liquid-metal-cellhttpsarxivorgabs251204455v1><a href=https://arxiv.org/abs/2512.04455v1>Biomimetic Liquid Metal Cell</a><a hidden class=anchor aria-hidden=true href=#biomimetic-liquid-metal-cellhttpsarxivorgabs251204455v1>#</a></h3><p><strong>Authors:</strong> Jingyi Li, Mengwen Qiao, Minghui Guo, Zerong Xing, Yunlong Bai, Ju Wang, Yujia Song, Ren Xu, Xi Zhao, Jing Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Gallium-based liquid metals, as a broad category of emerging functional materials with unique physical, chemical, and biological properties, offer numerous possibilities for advancing intelligent systems. However, a basic query persistently remains for the complex liquid metal system: Is there a minimal functional unit that can fully capture its diversity of morphology and function? Cells, as the most basic structural and functional units of life, are small in scale but have complex structures, functions, and life activities. Analogous to nature, this article proposes the concept of liquid metal cells, and systematically explores their construction routes, sensing capabilities, motion behaviors, and potential applications. We first construct a multi-phase composite structure with liquid metal as the nucleus, ionic solution as the cytoplasm, and polymer as the cell membrane by developing a layered cryogenic molding method. Furthermore, we reveal that liquid metal cells exhibit inherently versatile responsive characteristics and self-adaptive behaviors to thermal, pressure, chemical, electrical, and magnetic fields, indicating &ldquo;small world, vast potential&rdquo;. Based on these fundamental findings, we finally demonstrate the feasibility of utilizing liquid metal cells as sensors, fluidic valves, and material transport carriers in flow channels through dynamic control.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04455v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04455v1">üìÑ Download PDF</a></p><hr><h3 id=executable-governance-for-ai-translating-policies-into-rules-using-llmshttpsarxivorgabs251204408v1><a href=https://arxiv.org/abs/2512.04408v1>Executable Governance for AI: Translating Policies into Rules Using LLMs</a><a hidden class=anchor aria-hidden=true href=#executable-governance-for-ai-translating-policies-into-rules-using-llmshttpsarxivorgabs251204408v1>#</a></h3><p><strong>Authors:</strong> Gautam Varma Datla, Anudeep Vurity, Tejaswani Dash, Tazeem Ahmad, Mohd Adnan, Saima Rafi
<strong>Venue:</strong> arXiv (2025)</p><p>AI policy guidance is predominantly written as prose, which practitioners must first convert into executable rules before frameworks can evaluate or enforce them. This manual step is slow, error-prone, difficult to scale, and often delays the use of safeguards in real-world deployments. To address this gap, we present Policy-to-Tests (P2T), a framework that converts natural-language policy documents into normalized, machine-readable rules. The framework comprises a pipeline and a compact domain-specific language (DSL) that encodes hazards, scope, conditions, exceptions, and required evidence, yielding a canonical representation of extracted rules. To test the framework beyond a single policy, we apply it across general frameworks, sector guidance, and enterprise standards, extracting obligation-bearing clauses and converting them into executable rules. These AI-generated rules closely match strong human baselines on span-level and rule-level metrics, with robust inter-annotator agreement on the gold set. To evaluate downstream behavioral and safety impact, we add HIPAA-derived safeguards to a generative agent and compare it with an otherwise identical agent without guardrails. An LLM-based judge, aligned with gold-standard criteria, measures violation rates and robustness to obfuscated and compositional prompts. Detailed results are provided in the appendix. We release the codebase, DSL, prompts, and rule sets as open-source resources to enable reproducible evaluation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04408v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04408v1">üìÑ Download PDF</a></p><hr><h3 id=hairy-black-holes-via-gravitational-decoupling-light-rings-absorption-and-spectral-lineshttpsarxivorgabs251204377v1><a href=https://arxiv.org/abs/2512.04377v1>Hairy black holes via gravitational decoupling: light rings, absorption and spectral lines</a><a hidden class=anchor aria-hidden=true href=#hairy-black-holes-via-gravitational-decoupling-light-rings-absorption-and-spectral-lineshttpsarxivorgabs251204377v1>#</a></h3><p><strong>Authors:</strong> Gabriel P. Ribeiro, Renan B. Magalh√£es, Lu√≠s C. B. Crispino
<strong>Venue:</strong> arXiv (2025)</p><p>We investigate the absorption of massless scalar waves by three distinct hairy black hole solutions obtained through the gravitational decoupling method, considering the weak, the strong or the dominant energy conditions. Remarkably, in certain configurations of hairy black holes associated with the fulfillment of the weak energy condition, quasibound states may appear, resulting in Breit-Wigner-like resonances in their absorption profile. These quasibound states (and consequently the spectral lines in the absorption spectrum) can be related to stable light rings in the spacetime, a structure often associated with horizonless exotic compact objects, such as wormholes. We investigate how the gravitational decoupling method introduces novel light ring structures in hairy black holes and influences the absorption spectra through its deformation parameters. Our numerical results show excellent agreement with well-known approximations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04377v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04377v1">üìÑ Download PDF</a></p><hr><h3 id=preparation-and-magnetic-properties-of-ln02la02nd02sm02-eu02mno3-ln--dy-ho-er-high-entropy-perovskite-ceramics-containing-heavy-rare-earth-elementshttpsarxivorgabs251204370v1><a href=https://arxiv.org/abs/2512.04370v1>Preparation and magnetic properties of (Ln0.2La0.2Nd0.2Sm0.2 Eu0.2)MnO3 (Ln = Dy, Ho, Er) high-entropy perovskite ceramics containing heavy rare earth elements</a><a hidden class=anchor aria-hidden=true href=#preparation-and-magnetic-properties-of-ln02la02nd02sm02-eu02mno3-ln--dy-ho-er-high-entropy-perovskite-ceramics-containing-heavy-rare-earth-elementshttpsarxivorgabs251204370v1>#</a></h3><p><strong>Authors:</strong> Jiedong Qin, Xingmin Feng, Zhiqin Wen, Li Tang, Defeng Long, Yuhong Zhao
<strong>Venue:</strong> arXiv (2025)</p><p>Equimolar ratio high-entropy perovskite ceramics (HEPCs) have attracted much attention due to their excellent magnetization intensity. To further enhance their magnetization intensities, (Ln0.2La0.2Nd0.2Sm0.2Eu0.2)MnO3 (Ln = Dy, Ho and Er, labeled as Ln-LNSEMO) HEPCs are designed based on the configuration entropy Sconfig, tolerance factor t, and mismatch degree. Single-phase HEPCs are synthesized by the solid-phase method in this work, in which the effects of the heavy rare-earth elements Dy, Ho and Er on the structure and magnetic properties of Ln-LNSEMO are systematically studied. The results show that all Ln-LNSEMO HEPCs exhibit high crystallinity and maintain excellent structural stability after sintering at 1250 degree centigrade for 16 h. Ln-LNSEMO HEPCs exhibit significant lattice distortion effects, with smooth surface morphology, clearly distinguishable grain boundaries, and irregular polygonal shapes. The three high-entropy ceramic samples exhibit hysteresis behavior at T = 5 K, with the Curie temperature TC decreasing as the radius of the introduced rare-earth ions decreases, while the saturation magnetization and coercivity increase accordingly. When the average ionic radius of A-site decreases, the interaction between their valence electrons and local electrons in the crystal increases, thereby enhancing the conversion of electrons to oriented magnetic moments under an external magnetic field. Thus, Er-LNSEMO HEPC shows a higher saturation magnetization strength (42.8 emu/g) and coercivity (2.09 kOe) than the other samples, which is attributed to the strong magnetic crystal anisotropy, larger lattice distortion (0.00652), smaller average grain size (440.49 plus or minus 22.02 nm), unit cell volume (229.432 A3) and A-site average ion radius (1.24 A) of its magnet. The Er-LNSEMO HEPC has potential applications in magnetic recording materials.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04370v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04370v1">üìÑ Download PDF</a></p><hr><h3 id=catching-ux-flaws-in-code-leveraging-llms-to-identify-usability-flaws-at-the-development-stagehttpsarxivorgabs251204262v1><a href=https://arxiv.org/abs/2512.04262v1>Catching UX Flaws in Code: Leveraging LLMs to Identify Usability Flaws at the Development Stage</a><a hidden class=anchor aria-hidden=true href=#catching-ux-flaws-in-code-leveraging-llms-to-identify-usability-flaws-at-the-development-stagehttpsarxivorgabs251204262v1>#</a></h3><p><strong>Authors:</strong> Nolan Platt, Ethan Luchs, Sehrish Nizamani
<strong>Venue:</strong> arXiv (2025)</p><p>Usability evaluations are essential for ensuring that modern interfaces meet user needs, yet traditional heuristic evaluations by human experts can be time-consuming and subjective, especially early in development. This paper investigates whether large language models (LLMs) can provide reliable and consistent heuristic assessments at the development stage. By applying Jakob Nielsen&rsquo;s ten usability heuristics to thirty open-source websites, we generated over 850 heuristic evaluations in three independent evaluations per site using a pipeline of OpenAI&rsquo;s GPT-4o. For issue detection, the model demonstrated moderate consistency, with an average pairwise Cohen&rsquo;s Kappa of 0.50 and an exact agreement of 84%. Severity judgments showed more variability: weighted Cohen&rsquo;s Kappa averaged 0.63, but exact agreement was just 56%, and Krippendorff&rsquo;s Alpha was near zero. These results suggest that while GPT-4o can produce internally consistent evaluations, especially for identifying the presence of usability issues, its ability to judge severity varies and requires human oversight in practice. Our findings highlight the feasibility and limitations of using LLMs for early-stage, automated usability testing, and offer a foundation for improving consistency in automated User Experience (UX) evaluation. To the best of our knowledge, our work provides one of the first quantitative inter-rater reliability analyses of automated heuristic evaluation and highlights methods for improving model consistency.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04262v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04262v1">üìÑ Download PDF</a></p><hr><h3 id=small-models-achieve-large-language-model-performance-evaluating-reasoning-enabled-ai-for-secure-child-welfare-researchhttpsarxivorgabs251204261v1><a href=https://arxiv.org/abs/2512.04261v1>Small Models Achieve Large Language Model Performance: Evaluating Reasoning-Enabled AI for Secure Child Welfare Research</a><a hidden class=anchor aria-hidden=true href=#small-models-achieve-large-language-model-performance-evaluating-reasoning-enabled-ai-for-secure-child-welfare-researchhttpsarxivorgabs251204261v1>#</a></h3><p><strong>Authors:</strong> Zia Qi, Brian E. Perron, Bryan G. Victor, Dragan Stoll, Joseph P. Ryan
<strong>Venue:</strong> arXiv (2025)</p><p>Objective: This study develops a systematic benchmarking framework for testing whether language models can accurately identify constructs of interest in child welfare records. The objective is to assess how different model sizes and architectures perform on four validated benchmarks for classifying critical risk factors among child welfare-involved families: domestic violence, firearms, substance-related problems generally, and opioids specifically. Method: We constructed four benchmarks for identifying risk factors in child welfare investigation summaries: domestic violence, substance-related problems, firearms, and opioids (n=500 each). We evaluated seven model sizes (0.6B-32B parameters) in standard and extended reasoning modes, plus a mixture-of-experts variant. Cohen&rsquo;s kappa measured agreement with gold standard classifications established by human experts. Results: The benchmarking revealed a critical finding: bigger models are not better. A small 4B parameter model with extended reasoning proved most effective, outperforming models up to eight times larger. It consistently achieved &ldquo;substantial&rdquo; to &ldquo;almost perfect&rdquo; agreement across all four benchmark categories. This model achieved &ldquo;almost perfect&rdquo; agreement (\k{appa} = 0.93-0.96) on three benchmarks (substance-related problems, firearms, and opioids) and &ldquo;substantial&rdquo; agreement (\k{appa} = 0.74) on the most complex task (domestic violence). Small models with extended reasoning rivaled the largest models while being more resource-efficient. Conclusions: Small reasoning-enabled models achieve accuracy levels historically requiring larger architectures, enabling significant time and computational efficiencies. The benchmarking framework provides a method for evidence-based model selection to balance accuracy with practical resource constraints before operational deployment in social work research.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04261v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04261v1">üìÑ Download PDF</a></p><hr><h3 id=reasonx-mllm-guided-intrinsic-image-decompositionhttpsarxivorgabs251204222v1><a href=https://arxiv.org/abs/2512.04222v1>ReasonX: MLLM-Guided Intrinsic Image Decomposition</a><a hidden class=anchor aria-hidden=true href=#reasonx-mllm-guided-intrinsic-image-decompositionhttpsarxivorgabs251204222v1>#</a></h3><p><strong>Authors:</strong> Alara Dirik, Tuanfeng Wang, Duygu Ceylan, Stefanos Zafeiriou, Anna Fr√ºhst√ºck
<strong>Venue:</strong> arXiv (2025)</p><p>Intrinsic image decomposition aims to separate images into physical components such as albedo, depth, normals, and illumination. While recent diffusion- and transformer-based models benefit from paired supervision from synthetic datasets, their generalization to diverse, real-world scenarios remains challenging. We propose ReasonX, a novel framework that leverages a multimodal large language model (MLLM) as a perceptual judge providing relative intrinsic comparisons, and uses these comparisons as GRPO rewards for fine-tuning intrinsic decomposition models on unlabeled, in-the-wild images. Unlike RL methods for generative models, our framework aligns conditional intrinsic predictors by rewarding agreement between the judge&rsquo;s relational assessments and analytically derived relations from the model&rsquo;s outputs. ReasonX is model-agnostic and can be applied to different intrinsic predictors. Across multiple base architectures and modalities, ReasonX yields significant improvements, including 9-25% WHDR reduction on IIW albedo and up to 46% depth accuracy gains on ETH3D, highlighting the promise of MLLM-guided comparative supervision to bridge low- and high-level vision reasoning.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04222v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04222v1">üìÑ Download PDF</a></p><hr><h3 id=confronting-cosmic-shear-astrophysical-uncertainties-des-year-3-revisitedhttpsarxivorgabs251204209v1><a href=https://arxiv.org/abs/2512.04209v1>Confronting cosmic shear astrophysical uncertainties: DES Year 3 revisited</a><a hidden class=anchor aria-hidden=true href=#confronting-cosmic-shear-astrophysical-uncertainties-des-year-3-revisitedhttpsarxivorgabs251204209v1>#</a></h3><p><strong>Authors:</strong> Leah Bigwood, Jamie McCullough, Jared Siegel, Alexandra Amon, George Efstathiou, David Sanchez-Cid, Elisa Legnani, Daniel Gruen, Jonathan Blazek, Cyrille Doux, Aurelio Carnero Rosell, Marco Gatti, Eric Huff, Niall MacCrann, Anna Porredon, Judit Prat Marti, Marcelle Soares dos Santos, Justin Myles, Simon Samuroff, Masaya Yamamoto, Boyan Yin, Joe Zuntz
<strong>Venue:</strong> arXiv (2025)</p><p>Cosmology from weak gravitational lensing has been limited by astrophysical uncertainties in baryonic feedback and intrinsic alignments. By calibrating these effects using external data, we recover non-linear information, achieving a 2% constraint on the clustering amplitude, $S_8$, resulting in a factor of two improvement on the $Œõ$CDM constraints relative to the fiducial Dark Energy Survey Year 3 model. The posterior, $S_8=0.832^{+0.013}_{-0.017}$, shifts by $1.5œÉ$ to higher values, in closer agreement with the cosmic microwave background result for the standard six-parameter $Œõ$CDM cosmology. Our approach uses a star-forming &lsquo;blue&rsquo; galaxy sample with intrinsic alignment model parameters calibrated by direct spectroscopic measurements, together with a baryonic feedback model informed by observations of X-ray gas fractions and kinematic Sunyaev-Zel&rsquo;dovich effect profiles that span a wide range in halo mass and redshift. Our results provide a blueprint for next-generation surveys: leveraging galaxy properties to control intrinsic alignments and external gas probes to calibrate feedback, unlocking a substantial improvement in the precision of weak lensing surveys.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04209v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04209v1">üìÑ Download PDF</a></p><hr><h3 id=a-black-hole-envelope-interpretation-for-cosmological-demographics-of-little-red-dotshttpsarxivorgabs251204208v1><a href=https://arxiv.org/abs/2512.04208v1>A Black-Hole Envelope Interpretation for Cosmological Demographics of Little Red Dots</a><a hidden class=anchor aria-hidden=true href=#a-black-hole-envelope-interpretation-for-cosmological-demographics-of-little-red-dotshttpsarxivorgabs251204208v1>#</a></h3><p><strong>Authors:</strong> Hiroya Umeda, Kohei Inayoshi, Yuichi Harikane, Kohta Murase
<strong>Venue:</strong> arXiv (2025)</p><p>Little red dots (LRDs) newly discovered with JWST are active galactic nuclei (AGN) that may represent black hole (BH) growth at the earliest cosmic epochs. These sources show puzzling features unlike typical AGNs, including red optical continua, weak hot-dust emission, and a lack of detectable X-rays. Previously, LRDs have often been interpreted as dust-reddened AGNs, leading to severe inconsistencies with the luminosity and BH mass densities inferred for previously known AGNs over $0&lt;z&lt;5$. The BH-envelope (BHE) model has been proposed to explain these characteristics, in which an accreting BH is enshrouded by a dense, optically thick gaseous envelope. In this Letter, we reanalyze the SEDs of $\sim 400$ photometric LRDs in the COSMOS-Web survey using the BHE model and reassess their implications for cosmological BH evolution. We find that the optical-NIR spectra of LRDs are well reproduced by blackbody emission with an effective temperatures of $4000-6000~\K$. Within the BHE framework, the inferred bolometric luminosities decrease by $\gtrsim1-2$ orders of magnitude compared to dust-reddened AGN assumptions. As a result, the revised luminosity function, BH accretion density, and BH mass function become consistent with those of AGNs at $z&lt;5$. The stellar masses of LRD hosts are estimated by attributing the UV excesses to star formation. Although the resulting $M_{\rm BH}/M_\star$ ratio remains higher than the local empirical value, the excess is modest. Overall, the BHE model not only resolves the spectral features of LRDs but also brings their statistical properties into agreement with the broader cosmological BH population.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04208v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04208v1">üìÑ Download PDF</a></p><hr><h3 id=stellar-bars-in-jellyfish-galaxies-statistical-insights-into-the-combined-role-of-bars-and-environmenthttpsarxivorgabs251204196v1><a href=https://arxiv.org/abs/2512.04196v1>Stellar Bars in Jellyfish Galaxies: Statistical Insights into the Combined Role of Bars and Environment</a><a hidden class=anchor aria-hidden=true href=#stellar-bars-in-jellyfish-galaxies-statistical-insights-into-the-combined-role-of-bars-and-environmenthttpsarxivorgabs251204196v1>#</a></h3><p><strong>Authors:</strong> Osbaldo S√°nchez-Garc√≠a, Bernardo Cervantes Sodi, Jacopo Fritz, Kar√≠n Men√©ndez-Delmestre, Jacob P. Crossett, Yasmin Cavalcante-Coelho
<strong>Venue:</strong> arXiv (2025)</p><p>Recent observational studies suggest that the interplay between internal and environmental mechanisms, in particular, the combined action of stellar bars and ram pressure stripping (RPS) may influence central star formation activity in jellyfish galaxies. However, current evidence relies on small samples, leaving open whether bars play a significant role during stripping. In this study, we analyse a sample about five times larger than those used in previous works, comprising 176 galaxies identified as RPS candidates based on optical morphological indicators such as asymmetries, debris tails, and displaced star-forming regions. To assess the impact of these processes, we examine radial $u-r$ colour profiles from SDSS imaging as tracers of the specific star formation rate (sSFR). We classify galaxies by bar presence and RPS signatures, and construct comparison samples through stepwise matching in stellar mass and environment to disentangle the individual and combined effects of bars and RPS on stellar population gradients. Our results show that central rejuvenation signals emerge in RPS candidate galaxies, becoming most evident when bars and RPS act together. Barred RPS galaxies are systematically bluer at all radii than their non-RPS counterparts, while unbarred systems display only mild or no central differences, suggesting that the observable outcome of RPS depends on the stripping stage. Furthermore, barred galaxies exhibit flatter central colour profiles than unbarred ones &ndash; a robust signature across all matched configurations. These findings highlight the key role of bars in amplifying environmental effects on the stellar populations of jellyfish galaxies, underscoring how internal structures can modulate the observable signatures of environmental processes in galaxies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04196v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04196v1">üìÑ Download PDF</a></p><hr><h3 id=entanglement-surfaces-for-rotating-cylindrical-black-holeshttpsarxivorgabs251204193v1><a href=https://arxiv.org/abs/2512.04193v1>Entanglement surfaces for rotating cylindrical black holes</a><a hidden class=anchor aria-hidden=true href=#entanglement-surfaces-for-rotating-cylindrical-black-holeshttpsarxivorgabs251204193v1>#</a></h3><p><strong>Authors:</strong> Fabio Billiato, Alessandra Gnecchi
<strong>Venue:</strong> arXiv (2025)</p><p>We construct entanglement surfaces for rotating cylindrical black holes in a double holographic setup, extending previous results to the case of stationary backgrounds. We analyze both the 5d braneworld construction as well as the embedding in 10d type IIB string theory. We couple the rotating cylindrical black hole to a non-gravitating bath, and study island and Hartman-Maldacena surfaces. Properties of island surfaces are characterized by three regimes, bounded by two critical parameters. In addition to the critical value known for the static case, we find that a new one emerges, related to the extremal limit of the rotating black hole. This behaviour is present both for the bottom-up as well as the top-down models, for which we find qualitative agreement.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04193v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04193v1">üìÑ Download PDF</a></p><hr><h3 id=jwst-confirmation-of-a-runaway-supermassive-black-hole-via-its-supersonic-bow-shockhttpsarxivorgabs251204166v1><a href=https://arxiv.org/abs/2512.04166v1>JWST Confirmation of a Runaway Supermassive Black Hole via its Supersonic Bow Shock</a><a hidden class=anchor aria-hidden=true href=#jwst-confirmation-of-a-runaway-supermassive-black-hole-via-its-supersonic-bow-shockhttpsarxivorgabs251204166v1>#</a></h3><p><strong>Authors:</strong> Pieter van Dokkum, Connor Jennings, Imad Pasha, Charlie Conroy, Ish Kaul, Roberto Abraham, Shany Danieli, Aaron J. Romanowsky, Grant Tremblay
<strong>Venue:</strong> arXiv (2025)</p><p>We present JWST/NIRSpec IFU observations of a candidate runaway supermassive black hole at the tip of a 62 kpc-long linear feature at z=0.96. The JWST data show a sharp kinematic discontinuity at the tip, with a radial velocity change of $\approx 600$ km/s across 0.1&rsquo;&rsquo; (1 kpc). The velocity gradient, together with the projected post-shock flow velocity of $\approx 300$ km/s, is well described by a simple shock-compression model of a supersonic object, with a velocity of $v_{BH} = 954^{+110}<em>{-126}$ km/s and an inclination $i=29^{+6}</em>{-3}$ deg. The previously puzzling kinematics along the linear feature, with the observed radial velocity decreasing from $\approx 300$ km/s near the tip to $\approx 100$ km/s closer to the former host galaxy, are naturally explained as gradual downstream mixing of shocked gas with the circumgalactic medium through turbulent entrainment. The runaway black hole interpretation is further supported by the morphology of the gas at the tip of the wake and an analysis of the [OIII]/H$Œ±$, [NII]/H$Œ±$, [SII]/H$Œ±$, and [SIII]/[SII] line ratios. The line ratios are consistent with fast radiative shocks and rapid cooling, with best-fit shock velocities that are in good agreement with expectations from the black hole velocity and the shock geometry. Energy conservation over the lifetime of the wake suggests a SMBH mass of $M_{BH} \gtrsim 10^7$ M$_{\odot}$. These results confirm that the wake is powered by a supersonic runaway supermassive black hole, a long-predicted consequence of gravitational-wave recoil or multi-body ejection from galactic nuclei.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04166v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04166v1">üìÑ Download PDF</a></p><hr><h3 id=popcorn-emris-transient-gravitational-wave-signals-and-their-analysis-in-schwartz-spacehttpsarxivorgabs251204167v1><a href=https://arxiv.org/abs/2512.04167v1>Popcorn EMRIs: Transient Gravitational Wave Signals and Their Analysis in Schwartz Space</a><a hidden class=anchor aria-hidden=true href=#popcorn-emris-transient-gravitational-wave-signals-and-their-analysis-in-schwartz-spacehttpsarxivorgabs251204167v1>#</a></h3><p><strong>Authors:</strong> Pau Amaro Seoane, Kostas Tzanavaris
<strong>Venue:</strong> arXiv (2025)</p><p>We investigate extreme-mass ratio inspirals (EMRIs) with orbital periods exceeding the observational timescale of mHz gravitational wave observatories. In their early, highly eccentric phases, these systems generate transient gravitational wave bursts during pericentre passages, separated by long quiescent intervals; we designate these signals ``popcorn EMRIs.&rsquo;&rsquo; We utilize a steady-state analytical model based on the continuity equation in phase space to estimate the population in a Milky Way-like galaxy. The normalization of this model is linked to the solution of the Fokker-Planck equation describing stellar relaxation. Adopting a conservative one-year observation baseline ($P>1$ year), we estimate the steady-state population of popcorn EMRIs. We forecast an observable burst rate of 5 to 44 events per year. The low duty cycle ($\sim 10^{-4}$) confirms their manifestation as isolated transients. Individual bursts from the Galactic Centre exhibit high detectability. Analyzing these intrinsically transient signals demands a rigorous mathematical framework, as standard windowing techniques distort burst morphology. We establish an analytical foundation using standard smoothing techniques commonly used in real analysis. This yields the mathematically correct definition for the Fourier transform of transient signals, justifying the use of the direct Fourier transform without ad hoc windowing and ensuring the integrity of spectral analysis.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04167v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04167v1">üìÑ Download PDF</a></p><hr><h3 id=galactic-bars-are-already-mature-at-cosmic-noon-bar-strength-and-flatness-at-z--15httpsarxivorgabs251204163v1><a href=https://arxiv.org/abs/2512.04163v1>Galactic bars are already mature at Cosmic Noon: bar strength and flatness at z ~ 1.5</a><a hidden class=anchor aria-hidden=true href=#galactic-bars-are-already-mature-at-cosmic-noon-bar-strength-and-flatness-at-z--15httpsarxivorgabs251204163v1>#</a></h3><p><strong>Authors:</strong> Boris S. Kalita, Luis C. Ho, John D. Silverman, Fr√©d√©ric Bournaud, Miroslava Dessauges-Zavadsky, Emanuele Daddi, Annagrazia Puglisi, Xuheng Ding, Si-Yue Yu
<strong>Venue:</strong> arXiv (2025)</p><p>In this work, we explore the nature of $z>1$ galactic bars. Once thought to be highly transient, our results demonstrate otherwise. Our sample consists of nine massive ($>10^{10.5},\rm M_{\odot}$) star-forming barred-spiral galaxies at $z_{\rm spec} \sim 1.5$. Using rest-frame near-IR (F444W) JWST/NIRCam imaging, we apply ellipse fitting along with 1D and 2D morphological modeling to directly measure bar properties. We find that five galaxies host flat surface brightness profiles (bar S√©rsic index $&lt;0.4$), indicative of highly evolved, &ldquo;mature&rdquo; bars. By contrast, only two galaxies show exponential profiles, characteristic of young bars, and these are also shorter in absolute length than the flat bars. We therefore conclude that a large fraction of bars at this epoch have already matured, thereby indicating the presence of well-settled disks required to facilitate bar formation and sustained evolution well before $z\sim1.5$. To assess the gravitational impact of the bars, we calculate the maximum transverse-to-radial force ratio ($Q_{b}$). We find that $Q_{b}$ values are comparable to, or weaker than, those of bars in the local Universe, Seven of the nine bars show only a marginal increase in strength with maturity (from exponential to flat bars). Contrarily however, the remaining two bars are flat, but have the lowest $Q_{b}$ values in our sample. We hence propose that the mature bars at $z\sim 1.5$ may experience phases of weakening due to rapid gas inflows and/or minor mergers. In conclusion, our work sheds light on the rapidly evolving nature of high-z bars and paves the way for larger statistical studies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04163v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04163v1">üìÑ Download PDF</a></p><hr><h3 id=minuet-a-diffusion-autoencoder-for-compact-semantic-compression-of-multi-band-galaxy-imageshttpsarxivorgabs251204145v1><a href=https://arxiv.org/abs/2512.04145v1>Minuet: A Diffusion Autoencoder for Compact Semantic Compression of Multi-Band Galaxy Images</a><a hidden class=anchor aria-hidden=true href=#minuet-a-diffusion-autoencoder-for-compact-semantic-compression-of-multi-band-galaxy-imageshttpsarxivorgabs251204145v1>#</a></h3><p><strong>Authors:</strong> Alexander T. Gagliano, Yunyi Shen, V. A. Villar
<strong>Venue:</strong> arXiv (2025)</p><p>The Vera C. Rubin Observatory is slated to observe nearly 20 billion galaxies during its decade-long Legacy Survey of Space and Time. The rich imaging data it collects will be an invaluable resource for probing galaxy evolution across cosmic time, characterizing the host galaxies of transient phenomena, and identifying novel populations of anomalous systems. While machine learning models have shown promise for extracting galaxy features from multi-band astronomical imaging, the large dimensionality of the learned latent space presents a challenge for mechanistic interpretability studies. In this work, we present Minuet, a low-dimensional diffusion autoencoder for multi-band galaxy imaging. Minuet is trained to reconstruct 72x72-pixel $grz$ image cutouts of 6M galaxies within $z&lt;1$ from the Dark Energy Camera Legacy Survey using only five latent dimensions. By using a diffusion model conditioned on the transformer-based autoencoder&rsquo;s output for image reconstruction, we achieve semantically-meaningful latent representations of galaxy images while still allowing for high-fidelity, probabilistic reconstructions. We train a series of binary classifiers on Minuet&rsquo;s latent features to quantify their connection to morphological labels from Galaxy Zoo, and a conditional flow to produce posterior distributions of SED-derived redshifts, stellar masses, and star-formation rates. We further show the value of Minuet for nearest neighbor searches in the learned latent space. Minuet provides strong evidence for the low intrinsic dimensionality of galaxy imaging, and introduces a class of astrophysical models that produce highly compact representations for diverse science goals.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04145v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04145v1">üìÑ Download PDF</a></p><hr><h3 id=machine-learning-pipeline-for-denoising-low-signal-to-noise-ratio-and-out-of-distribution-transmission-electron-microscopy-datasetshttpsarxivorgabs251204045v1><a href=https://arxiv.org/abs/2512.04045v1>Machine Learning Pipeline for Denoising Low Signal-To-Noise Ratio and Out-of-Distribution Transmission Electron Microscopy Datasets</a><a hidden class=anchor aria-hidden=true href=#machine-learning-pipeline-for-denoising-low-signal-to-noise-ratio-and-out-of-distribution-transmission-electron-microscopy-datasetshttpsarxivorgabs251204045v1>#</a></h3><p><strong>Authors:</strong> Brian Lee, Meng Li, Judith C Yang, Dmitri N Zakharov, Xiaohui Qu
<strong>Venue:</strong> arXiv (2025)</p><p>High-resolution transmission electron microscopy (HRTEM) is crucial for observing material&rsquo;s structural and morphological evolution at Angstrom scales, but the electron beam can alter these processes. Devices such as CMOS-based direct-electron detectors operating in electron-counting mode can be utilized to substantially reduce the electron dosage. However, the resulting images often lead to low signal-to-noise ratio, which requires frame integration that sacrifices temporal resolution. Several machine learning (ML) models have been recently developed to successfully denoise HRTEM images. Yet, these models are often computationally expensive and their inference speeds on GPUs are outpaced by the imaging speed of advanced detectors, precluding in situ analysis. Furthermore, the performance of these denoising models on datasets with imaging conditions that deviate from the training datasets have not been evaluated. To mitigate these gaps, we propose a new self-supervised ML denoising pipeline specifically designed for time-series HRTEM images. This pipeline integrates a blind-spot convolution neural network with pre-processing and post-processing steps including drift correction and low-pass filtering. Results demonstrate that our model outperforms various other ML and non-ML denoising methods in noise reduction and contrast enhancement, leading to improved visual clarity of atomic features. Additionally, the model is drastically faster than U-Net-based ML models and demonstrates excellent out-of-distribution generalization. The model&rsquo;s computational inference speed is in the order of milliseconds per image, rendering it suitable for application in in-situ HRTEM experiments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04045v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04045v1">üìÑ Download PDF</a></p><hr><h3 id=testing-the-localization-landscape-theory-on-the-bethe-latticehttpsarxivorgabs251204037v1><a href=https://arxiv.org/abs/2512.04037v1>Testing the Localization Landscape Theory on the Bethe Lattice</a><a hidden class=anchor aria-hidden=true href=#testing-the-localization-landscape-theory-on-the-bethe-latticehttpsarxivorgabs251204037v1>#</a></h3><p><strong>Authors:</strong> Lorenzo Tonetti, Leticia F. Cugliandolo, Marco Tarzia
<strong>Venue:</strong> arXiv (2025)</p><p>The Localization Landscape Theory (LLT) provides a classical picture of Anderson localization by introducing an effective confining potential whose percolation is proposed to coincide with the mobility edge. Although this proposal shows remarkable numerical agreement in three dimensions, its fundamental validity remains unsettled. Here we test the LLT analytically on the Bethe lattice, where both the Anderson localization transition and the LLT percolation problem are exactly solvable. We find that the two transitions do not coincide, and their critical behaviors differ markedly. In particular, LLT percolation displays standard mean-field percolation criticality that is fundamentally distinct from the peculiar critical behavior of the Anderson transition on the Bethe lattice. Our results provide an exact benchmark showing that, while geometrically intuitive, the LLT does not capture the true quantum critical properties of localization.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04037v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04037v1">üìÑ Download PDF</a></p><hr><h3 id=pleiades-binary-fraction-revisitedhttpsarxivorgabs251204143v1><a href=https://arxiv.org/abs/2512.04143v1>Pleiades Binary Fraction Revisited</a><a hidden class=anchor aria-hidden=true href=#pleiades-binary-fraction-revisitedhttpsarxivorgabs251204143v1>#</a></h3><p><strong>Authors:</strong> Dmitry Chulkov
<strong>Venue:</strong> arXiv (2025)</p><p>One of the nearest and best studied open clusters, Pleiades is an important cornerstone of stellar astrophysics. Despite its role as reference coeval stellar population, its multiplicity properties remain vaguely determined. The combined use of Gaia DR3 multiband photometry, astrometric parameter RUWE, non-single star solutions along with available ground-based spectroscopic, high angular resolution, and polarimetric observations enable more robust constraints on the binary star population in the cluster. Several conclusions may have broader implications for other stellar populations. Twin binaries, with mass ratio close to $q\sim 1$, tend to have lower RUWE, increasing their membership selection probability, relative to $q\sim 0.5$ systems that are disfavored. The frequently observed peak in mass ratio distribution for $q\sim 1$ binaries may be partially attributed to this bias. Photometrically fitted mass ratio is underestimated for double-lined spectroscopic binaries in agreement with other authors. Differential extinction photometrically mimics stellar binarity. An area of enlarged absorption is traced by increased polarization south of the Merope star and excluded from the analysis to avoid this bias. The fraction of systems with $q>0.6$ companions is measured to be $f=16.4%^{+2.6}<em>{-0.6}$ for $m>0.5~M</em>\odot$ stars, which is larger than recent Gaia-based estimates, but compatible with the pre-Gaia values for Pleiades and the field population. Binary fraction shows no steady increase with stellar mass in the 0.5 $-$ 1.2 $M_\odot$ range, while mass ratio has a bimodal distribution with a minimum near $q\sim 0.7$.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04143v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04143v1">üìÑ Download PDF</a></p><hr><h3 id=the-nuclear-star-cluster-of-m-74-a-fossil-record-of-the-very-early-stages-of-a-star-forming-galaxyhttpsarxivorgabs251203999v1><a href=https://arxiv.org/abs/2512.03999v1>The Nuclear Star Cluster of M 74: a fossil record of the very early stages of a star-forming galaxy</a><a hidden class=anchor aria-hidden=true href=#the-nuclear-star-cluster-of-m-74-a-fossil-record-of-the-very-early-stages-of-a-star-forming-galaxyhttpsarxivorgabs251203999v1>#</a></h3><p><strong>Authors:</strong> Francesca Pinna, Nils Hoyer, Jairo M√©ndez Abreu, Adriana de Lorenzo C√°ceres Rodriguez, Nadine Neumayer, M√©d√©ric Boquien, Salvador Cardona Barrero, Daniel A. Dale, Ivan S. Gerasimov, Kathryn Grasha, Ralf S. Klessen, Carlos Marrero de la Rosa, Miguel Querejeta, Thomas G. Williams, Smita Mathur, Eva Schinnerer
<strong>Venue:</strong> arXiv (2025)</p><p>Nuclear star clusters (NSC) are dense and compact stellar systems, of sizes of few parsecs, located at galactic centers. Their properties and formation mechanisms seem to be tightly linked to the evolution of the host galaxy, with potentially different formation channels for late- and early-type galaxies (respectively, LTGs and ETGs). While most observations target ETGs, here we focus on the NSC in M 74 (NGC 628), a relatively massive, gas-rich and star-forming spiral galaxy, part of the PHANGS survey. We analyzed the central arcmin of the PHANGS-MUSE mosaic, in which the NSC is not spatially resolved. We performed a two-dimensional spectro-photometric decomposition of the MUSE cube, employing a modified version of the C2D code, to disentangle the NSC from the host galaxy. Here we used three components: a bulge, a disk and a NSC approximated to the point spread function (PSF), obtaining three data cubes, one for each component. This allowed us to extract separately the age, metallicity and [Mg/Fe] abundance for the NSC and the host galaxy. Our results show a very old and metal-poor NSC, in contrast to the surrounding regions. While similar properties were found in NSCs hosted by galaxies of different masses and/or morphological types from M 74, they are somewhat unexpected for a relatively massive star-forming spiral galaxy. The spatially resolved stellar populations of the host galaxy display much younger (light-weighted) ages and higher metallicities, especially in the central region (${\sim}500$ pc) surrounding the NSC. This suggests that this NSC formed a long time ago, and evolved passively until today, without any further growth. Our results show that the NSC was not involved in the active recent star-formation history of its host galaxy.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03999v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03999v1">üìÑ Download PDF</a></p><hr><h3 id=fully-quantum-theory-of-strong-field-driven-tunable-entangled-multi-photon-states-in-hhghttpsarxivorgabs251203987v1><a href=https://arxiv.org/abs/2512.03987v1>Fully quantum theory of strong-field driven tunable entangled multi-photon states in HHG</a><a hidden class=anchor aria-hidden=true href=#fully-quantum-theory-of-strong-field-driven-tunable-entangled-multi-photon-states-in-hhghttpsarxivorgabs251203987v1>#</a></h3><p><strong>Authors:</strong> Sebasti√°n de-la-Pe√±a, Heiko Appel, Angel Rubio, Ofer Neufeld
<strong>Venue:</strong> arXiv (2025)</p><p>Quantum high-harmonic generation (HHG) is a growing field of research with capabilities of providing high photon-number entangled states of light. However, there is an open debate regarding the theory level required for correctly describing the quantum aspects of HHG emission, such as squeezing or entanglement. Previous approaches have employed non-interacting classical ensembles of trajectories, or perturbation theory utilizing the classical trajectories as a starting point, missing out key entanglement features. In this Letter, we develop a full quantum theory for entanglement measures in HHG solving exactly the light-matter interaction Hamiltonian and employ it for evaluating the entanglement between emitted photons of different harmonics. For the first time, we reach qualitative agreement of theory with recent experiments showing that the R entanglement parameter decreases with increasing laser power for below-threshold harmonics. Our results indicate that fine-tuning the laser power could enhance HHG entanglement features, which are observed to oscillate with the driving power and exhibit local non-classical maxima structures. Similarly, our theory predicts that the oscillatory behavior of entanglement observed for below-threshold harmonics also appears for entanglement involving above-threshold harmonics. We also show that the long-range behavior of driven electronic trajectories can qualitatively change the resulting entanglement. Lastly, we show that focal averaging over classical degrees of freedom, which has thus far been ignored in quantum HHG theories, plays a key role in entanglement measures and can change the qualitative behavior of observables. Our work establishes the state-of-the art in exploring entanglement features in HHG, and paves way for analysis and engineering of &rsquo;truly-quantum&rsquo; multi-photon states in the XUV and ultrafast regime for more complex matter systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03987v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03987v1">üìÑ Download PDF</a></p><hr><h3 id=x-tra-through-the-eyes-of-matisse-more-evidence-of-clumpy-molecular-layers-around-c-type-asymptotic-giant-branch-starshttpsarxivorgabs251203910v1><a href=https://arxiv.org/abs/2512.03910v1>X TrA through the eyes of MATISSE: More evidence of clumpy molecular layers around C-type asymptotic giant branch stars</a><a hidden class=anchor aria-hidden=true href=#x-tra-through-the-eyes-of-matisse-more-evidence-of-clumpy-molecular-layers-around-c-type-asymptotic-giant-branch-starshttpsarxivorgabs251203910v1>#</a></h3><p><strong>Authors:</strong> V. RƒÉstƒÉu, C. Paladini, J. Drevon, J. Hron, F. Kerschbaum, M. Wittkowski, J. P. Fonfria, M. Montarg√®s, T. Khouri, W. Vlemmings, H. Olofsson, K. Ohnaka, J. Alonso-Hernandez, C. S√°nchez Contreras, L. Velilla-Prieto, W. C. Danchi, G. Rau, F. Lykou, J. Sanchez-Bermudez, B. Lopez, S. H√∂fner, B. Aringer, L. Planquart, P. Cruzal√®bes, G. Weigelt
<strong>Venue:</strong> arXiv (2025)</p><p>Aims. The goal of this study is to further the understanding of the wind formation mechanism in asymptotic giant branch (AGB) stars through the analysis of the close environment (within a few stellar radii) of the carbon star X TrA.
Methods. X TrA was observed for the first time with the Mid-Infrared SpectroScopic Experiment instrument (MATISSE) in the L and N bands in low spectral resolution mode (R=30), and its close surroundings were mapped in specific wavelength ranges corresponding to specific molecules ($C_2H_2$ and HCN, at 3.1 and 3.8 $Œº$m) and dust (amorphous carbon and, for example, Sic at 11.3 $Œº$m), via image reconstruction techniques.
Results. The angular diameter of the star ranges from 10 mas in the L band pseudo-continuum (3.5 $Œº$m) to 20 mas at 3.1 and 11.3 $Œº$m. The reconstructed images show some mild elongated features (along the east-west direction) and asymmetric protrusions, which are most evident around 3.1 $Œº$m. Imaging results highlight the clumpy nature of the circumstellar environment, starting from the photospheric region up to more distant layers.
Conclusions. The angular diameters found for X TrA in the image data are in agreement with previous photospheric diameter estimates (following VLTI/MIDI 8-13 $Œº$m observations), and their wavelength dependence is similar to values found for other carbon stars observed with MATISSE (R Scl and V Hya). The 3.1 $Œº$m images presented here show highly asymmetric features, another case of a C-rich star with irregular morphologies close to the stellar disk; this supports the notion that the $C_2H_2+HCN$ abundance distribution usually originates from a clumpy layer around carbon stars.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03910v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03910v1">üìÑ Download PDF</a></p><hr><h3 id=bernat-basque-encoders-for-representing-natural-textual-diversityhttpsarxivorgabs251203903v1><a href=https://arxiv.org/abs/2512.03903v1>BERnaT: Basque Encoders for Representing Natural Textual Diversity</a><a hidden class=anchor aria-hidden=true href=#bernat-basque-encoders-for-representing-natural-textual-diversityhttpsarxivorgabs251203903v1>#</a></h3><p><strong>Authors:</strong> Ekhi Azurmendi, Joseba Fernandez de Landa, Jaione Bengoetxea, Maite Heredia, Julen Etxaniz, Mikel Zubillaga, Ander Soraluze, Aitor Soroa
<strong>Venue:</strong> arXiv (2025)</p><p>Language models depend on massive text corpora that are often filtered for quality, a process that can unintentionally exclude non-standard linguistic varieties, reduce model robustness and reinforce representational biases. In this paper, we argue that language models should aim to capture the full spectrum of language variation (dialectal, historical, informal, etc.) rather than relying solely on standardized text. Focusing on Basque, a morphologically rich and low-resource language, we construct new corpora combining standard, social media, and historical sources, and pre-train the BERnaT family of encoder-only models in three configurations: standard, diverse, and combined. We further propose an evaluation framework that separates Natural Language Understanding (NLU) tasks into standard and diverse subsets to assess linguistic generalization. Results show that models trained on both standard and diverse data consistently outperform those trained on standard corpora, improving performance across all task types without compromising standard benchmark accuracy. These findings highlight the importance of linguistic diversity in building inclusive, generalizable language models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03903v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03903v1">üìÑ Download PDF</a></p><hr><h3 id=errors-in-pdh-offset-locking-due-to-spurious-spectral-featureshttpsarxivorgabs251203900v1><a href=https://arxiv.org/abs/2512.03900v1>Errors in PDH offset locking due to spurious spectral features</a><a hidden class=anchor aria-hidden=true href=#errors-in-pdh-offset-locking-due-to-spurious-spectral-featureshttpsarxivorgabs251203900v1>#</a></h3><p><strong>Authors:</strong> Roame A. Hildebrand, Wance Wang, Connor Goham, Alessandro Restelli, Joseph W. Britton
<strong>Venue:</strong> arXiv (2025)</p><p>The Pound-Drever-Hall (PDH) technique is widely used to stabilize the frequency of lasers. Here we report on a routinely underestimated source of error in PDH offset-locking: a shift in the lock point due to the unintended interaction between residual optical sidebands and higher-order spatial modes in misaligned Fabry-Perot cavities. Significant frequency deviations-up to 50% of the cavity linewidth-can arise when the optical offset is obtained from a sinusoidally driven EOM. We measure this deviation experimentally, find agreement with a simple model, and show how a spectrally-pure frequency offset can reduce the deviation by an order of magnitude. Our findings draw attention to a systematic effect of importance to precision optical spectroscopy, optical clocks, and quantum information science.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03900v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03900v1">üìÑ Download PDF</a></p><hr><h3 id=an-automated-framework-for-large-scale-graph-based-cerebrovascular-analysishttpsarxivorgabs251203869v1><a href=https://arxiv.org/abs/2512.03869v1>An Automated Framework for Large-Scale Graph-Based Cerebrovascular Analysis</a><a hidden class=anchor aria-hidden=true href=#an-automated-framework-for-large-scale-graph-based-cerebrovascular-analysishttpsarxivorgabs251203869v1>#</a></h3><p><strong>Authors:</strong> Daniele Falcetta, Liane S. Canas, Lorenzo Suppa, Matteo Pentassuglia, Jon Cleary, Marc Modat, S√©bastien Ourselin, Maria A. Zuluaga
<strong>Venue:</strong> arXiv (2025)</p><p>We present CaravelMetrics, a computational framework for automated cerebrovascular analysis that models vessel morphology through skeletonization-derived graph representations. The framework integrates atlas-based regional parcellation, centerline extraction, and graph construction to compute fifteen morphometric, topological, fractal, and geometric features. The features can be estimated globally from the complete vascular network or regionally within arterial territories, enabling multiscale characterization of cerebrovascular organization. Applied to 570 3D TOF-MRA scans from the IXI dataset (ages 20-86), CaravelMetrics yields reproducible vessel graphs capturing age- and sex-related variations and education-associated increases in vascular complexity, consistent with findings reported in the literature. The framework provides a scalable and fully automated approach for quantitative cerebrovascular feature extraction, supporting normative modeling and population-level studies of vascular health and aging.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03869v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03869v1">üìÑ Download PDF</a></p><hr><h3 id=gradient-descent-with-provably-tuned-learning-rate-scheduleshttpsarxivorgabs251205084v1><a href=https://arxiv.org/abs/2512.05084v1>Gradient Descent with Provably Tuned Learning-rate Schedules</a><a hidden class=anchor aria-hidden=true href=#gradient-descent-with-provably-tuned-learning-rate-scheduleshttpsarxivorgabs251205084v1>#</a></h3><p><strong>Authors:</strong> Dravyansh Sharma
<strong>Venue:</strong> arXiv (2025)</p><p>Gradient-based iterative optimization methods are the workhorse of modern machine learning. They crucially rely on careful tuning of parameters like learning rate and momentum. However, one typically sets them using heuristic approaches without formal near-optimality guarantees. Recent work by Gupta and Roughgarden studies how to learn a good step-size in gradient descent. However, like most of the literature with theoretical guarantees for gradient-based optimization, their results rely on strong assumptions on the function class including convexity and smoothness which do not hold in typical applications. In this work, we develop novel analytical tools for provably tuning hyperparameters in gradient-based algorithms that apply to non-convex and non-smooth functions. We obtain matching sample complexity bounds for learning the step-size in gradient descent shown for smooth, convex functions in prior work (up to logarithmic factors) but for a much broader class of functions. Our analysis applies to gradient descent on neural networks with commonly used activation functions (including ReLU, sigmoid and tanh). We extend our framework to tuning multiple hyperparameters, including tuning the learning rate schedule, simultaneously tuning momentum and step-size, and pre-training the initialization vector. Our approach can be used to bound the sample complexity for minimizing both the validation loss as well as the number of gradient descent iterations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05084v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05084v1">üìÑ Download PDF</a></p><hr><h3 id=control-consistency-losses-for-diffusion-bridgeshttpsarxivorgabs251205070v1><a href=https://arxiv.org/abs/2512.05070v1>Control Consistency Losses for Diffusion Bridges</a><a hidden class=anchor aria-hidden=true href=#control-consistency-losses-for-diffusion-bridgeshttpsarxivorgabs251205070v1>#</a></h3><p><strong>Authors:</strong> Samuel Howard, Nikolas N√ºsken, Jakiw Pidstrigach
<strong>Venue:</strong> arXiv (2025)</p><p>Simulating the conditioned dynamics of diffusion processes, given their initial and terminal states, is an important but challenging problem in the sciences. The difficulty is particularly pronounced for rare events, for which the unconditioned dynamics rarely reach the terminal state. In this work, we leverage a self-consistency property of the conditioned dynamics to learn the diffusion bridge in an iterative online manner, and demonstrate promising empirical results in a range of settings.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05070v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05070v1">üìÑ Download PDF</a></p><hr><h3 id=dual-path-region-guided-attention-network-for-ground-reaction-force-and-moment-regressionhttpsarxivorgabs251205030v1><a href=https://arxiv.org/abs/2512.05030v1>Dual-Path Region-Guided Attention Network for Ground Reaction Force and Moment Regression</a><a hidden class=anchor aria-hidden=true href=#dual-path-region-guided-attention-network-for-ground-reaction-force-and-moment-regressionhttpsarxivorgabs251205030v1>#</a></h3><p><strong>Authors:</strong> Xuan Li, Samuel Bello
<strong>Venue:</strong> arXiv (2025)</p><p>Accurate estimation of three-dimensional ground reaction forces and moments (GRFs/GRMs) is crucial for both biomechanics research and clinical rehabilitation evaluation. In this study, we focus on insole-based GRF/GRM estimation and further validate our approach on a public walking dataset. We propose a Dual-Path Region-Guided Attention Network that integrates anatomy-inspired spatial priors and temporal priors into a region-level attention mechanism, while a complementary path captures context from the full sensor field. The two paths are trained jointly and their outputs are combined to produce the final GRF/GRM predictions. Conclusions: Our model outperforms strong baseline models, including CNN and CNN-LSTM architectures on two datasets, achieving the lowest six-component average NRMSE of 5.78% on the insole dataset and 1.42% for the vertical ground reaction force on the public dataset. This demonstrates robust performance for ground reaction force and moment estimation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05030v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05030v1">üìÑ Download PDF</a></p><hr><h3 id=model-free-assessment-of-simulator-fidelity-via-quantile-curveshttpsarxivorgabs251205024v1><a href=https://arxiv.org/abs/2512.05024v1>Model-Free Assessment of Simulator Fidelity via Quantile Curves</a><a hidden class=anchor aria-hidden=true href=#model-free-assessment-of-simulator-fidelity-via-quantile-curveshttpsarxivorgabs251205024v1>#</a></h3><p><strong>Authors:</strong> Garud Iyengar, Yu-Shiou Willy Lin, Kaizheng Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Simulation of complex systems originated in manufacturing and queuing applications. It is now widely used for large-scale, ML-based systems in research, education, and consumer surveys. However, characterizing the discrepancy between simulators and ground truth remains challenging for increasingly complex, machine-learning-based systems. We propose a computationally tractable method to estimate the quantile function of the discrepancy between the simulated and ground-truth outcome distributions. Our approach focuses on output uncertainty and treats the simulator as a black box, imposing no modeling assumptions on its internals, and hence applies broadly across many parameter families, from Bernoulli and multinomial models to continuous, vector-valued settings. The resulting quantile curve supports confidence interval construction for unseen scenarios, risk-aware summaries of sim-to-real discrepancy (e.g., VaR/CVaR), and comparison of simulators&rsquo; performance. We demonstrate our methodology in an application assessing LLM simulation fidelity on the WorldValueBench dataset spanning four LLMs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05024v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05024v1">üìÑ Download PDF</a></p><hr><h3 id=self-supervised-learning-for-transparent-object-depth-completion-using-depth-from-non-transparent-objectshttpsarxivorgabs251205006v1><a href=https://arxiv.org/abs/2512.05006v1>Self-Supervised Learning for Transparent Object Depth Completion Using Depth from Non-Transparent Objects</a><a hidden class=anchor aria-hidden=true href=#self-supervised-learning-for-transparent-object-depth-completion-using-depth-from-non-transparent-objectshttpsarxivorgabs251205006v1>#</a></h3><p><strong>Authors:</strong> Xianghui Fan, Zhaoyu Chen, Mengyang Pan, Anping Deng, Hang Yang
<strong>Venue:</strong> arXiv (2025)</p><p>The perception of transparent objects is one of the well-known challenges in computer vision. Conventional depth sensors have difficulty in sensing the depth of transparent objects due to refraction and reflection of light. Previous research has typically train a neural network to complete the depth acquired by the sensor, and this method can quickly and accurately acquire accurate depth maps of transparent objects. However, previous training relies on a large amount of annotation data for supervision, and the labeling of depth maps is costly. To tackle this challenge, we propose a new self-supervised method for training depth completion networks. Our method simulates the depth deficits of transparent objects within non-transparent regions and utilizes the original depth map as ground truth for supervision. Experiments demonstrate that our method achieves performance comparable to supervised approach, and pre-training with our method can improve the model performance when the training samples are small.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05006v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05006v1">üìÑ Download PDF</a></p><hr><h3 id=towards-a-unified-framework-for-guided-diffusion-modelshttpsarxivorgabs251204985v1><a href=https://arxiv.org/abs/2512.04985v1>Towards a unified framework for guided diffusion models</a><a hidden class=anchor aria-hidden=true href=#towards-a-unified-framework-for-guided-diffusion-modelshttpsarxivorgabs251204985v1>#</a></h3><p><strong>Authors:</strong> Yuchen Jiao, Yuxin Chen, Gen Li
<strong>Venue:</strong> arXiv (2025)</p><p>Guided or controlled data generation with diffusion models\blfootnote{Partial preliminary results of this work appeared in International Conference on Machine Learning 2025 \citep{li2025provable}.} has become a cornerstone of modern generative modeling. Despite substantial advances in diffusion model theory, the theoretical understanding of guided diffusion samplers remains severely limited. We make progress by developing a unified algorithmic and theoretical framework that accommodates both diffusion guidance and reward-guided diffusion. Aimed at fine-tuning diffusion models to improve certain rewards, we propose injecting a reward guidance term &ndash; constructed from the difference between the original and reward-reweighted scores &ndash; into the backward diffusion process, and rigorously quantify the resulting reward improvement over the unguided counterpart. As a key application, our framework shows that classifier-free guidance (CFG) decreases the expected reciprocal of the classifier probability, providing the first theoretical characterization of the specific performance metric that CFG improves for general target distributions. When applied to reward-guided diffusion, our framework yields a new sampler that is easy-to-train and requires no full diffusion trajectories during training. Numerical experiments further corroborate our theoretical findings.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04985v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04985v1">üìÑ Download PDF</a></p><hr><h3 id=federated-learning-for-terahertz-wireless-communicationhttpsarxivorgabs251204984v1><a href=https://arxiv.org/abs/2512.04984v1>Federated Learning for Terahertz Wireless Communication</a><a hidden class=anchor aria-hidden=true href=#federated-learning-for-terahertz-wireless-communicationhttpsarxivorgabs251204984v1>#</a></h3><p><strong>Authors:</strong> O. Tansel Baydas, Ozgur B. Akan
<strong>Venue:</strong> arXiv (2025)</p><p>The convergence of Terahertz (THz) communications and Federated Learning (FL) promises ultra-fast distributed learning, yet the impact of realistic wideband impairments on optimization dynamics remains theoretically uncharacterized. This paper bridges this gap by developing a multicarrier stochastic framework that explicitly couples local gradient updates with frequency-selective THz effects, including beam squint, molecular absorption, and jitter. Our analysis uncovers a critical diversity trap: under standard unbiased aggregation, the convergence error floor is driven by the harmonic mean of subcarrier SNRs. Consequently, a single spectral hole caused by severe beam squint can render the entire bandwidth useless for reliable model updates. We further identify a fundamental bandwidth limit, revealing that expanding the spectrum beyond a critical point degrades convergence due to the integration of thermal noise and gain collapse at band edges. Finally, we demonstrate that an SNR-weighted aggregation strategy is necessary to suppress the variance singularity at these spectral holes, effectively recovering convergence in high-squint regimes where standard averaging fails. Numerical results validate the expected impact of the discussed physical layer parameters&rsquo; on performance of THz-FL systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04984v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04984v1">üìÑ Download PDF</a></p><hr><h3 id=efficient-generative-transformer-operators-for-million-point-pdeshttpsarxivorgabs251204974v1><a href=https://arxiv.org/abs/2512.04974v1>Efficient Generative Transformer Operators For Million-Point PDEs</a><a hidden class=anchor aria-hidden=true href=#efficient-generative-transformer-operators-for-million-point-pdeshttpsarxivorgabs251204974v1>#</a></h3><p><strong>Authors:</strong> Armand Kassa√Ø Koupa√Ø, Lise Le Boudec, Patrick Gallinari
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce ECHO, a transformer-operator framework for generating million-point PDE trajectories. While existing neural operators (NOs) have shown promise for solving partial differential equations, they remain limited in practice due to poor scalability on dense grids, error accumulation during dynamic unrolling, and task-specific design. ECHO addresses these challenges through three key innovations. (i) It employs a hierarchical convolutional encode-decode architecture that achieves a 100 $\times$ spatio-temporal compression while preserving fidelity on mesh points. (ii) It incorporates a training and adaptation strategy that enables high-resolution PDE solution generation from sparse input grids. (iii) It adopts a generative modeling paradigm that learns complete trajectory segments, mitigating long-horizon error drift. The training strategy decouples representation learning from downstream task supervision, allowing the model to tackle multiple tasks such as trajectory generation, forward and inverse problems, and interpolation. The generative model further supports both conditional and unconditional generation. We demonstrate state-of-the-art performance on million-point simulations across diverse PDE systems featuring complex geometries, high-frequency dynamics, and long-term horizons.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04974v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04974v1">üìÑ Download PDF</a></p><hr><h3 id=stable-single-pixel-contrastive-learning-for-semantic-and-geometric-taskshttpsarxivorgabs251204970v1><a href=https://arxiv.org/abs/2512.04970v1>Stable Single-Pixel Contrastive Learning for Semantic and Geometric Tasks</a><a hidden class=anchor aria-hidden=true href=#stable-single-pixel-contrastive-learning-for-semantic-and-geometric-taskshttpsarxivorgabs251204970v1>#</a></h3><p><strong>Authors:</strong> Leonid Pogorelyuk, Niels Bracher, Aaron Verkleeren, Lars K√ºhmichel, Stefan T. Radev
<strong>Venue:</strong> arXiv (2025)</p><p>We pilot a family of stable contrastive losses for learning pixel-level representations that jointly capture semantic and geometric information. Our approach maps each pixel of an image to an overcomplete descriptor that is both view-invariant and semantically meaningful. It enables precise point-correspondence across images without requiring momentum-based teacher-student training. Two experiments in synthetic 2D and 3D environments demonstrate the properties of our loss and the resulting overcomplete representations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04970v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04970v1">üìÑ Download PDF</a></p><hr><h3 id=rethinking-the-use-of-vision-transformers-for-ai-generated-image-detectionhttpsarxivorgabs251204969v1><a href=https://arxiv.org/abs/2512.04969v1>Rethinking the Use of Vision Transformers for AI-Generated Image Detection</a><a hidden class=anchor aria-hidden=true href=#rethinking-the-use-of-vision-transformers-for-ai-generated-image-detectionhttpsarxivorgabs251204969v1>#</a></h3><p><strong>Authors:</strong> NaHyeon Park, Kunhee Kim, Junsuk Choe, Hyunjung Shim
<strong>Venue:</strong> arXiv (2025)</p><p>Rich feature representations derived from CLIP-ViT have been widely utilized in AI-generated image detection. While most existing methods primarily leverage features from the final layer, we systematically analyze the contributions of layer-wise features to this task. Our study reveals that earlier layers provide more localized and generalizable features, often surpassing the performance of final-layer features in detection tasks. Moreover, we find that different layers capture distinct aspects of the data, each contributing uniquely to AI-generated image detection. Motivated by these findings, we introduce a novel adaptive method, termed MoLD, which dynamically integrates features from multiple ViT layers using a gating-based mechanism. Extensive experiments on both GAN- and diffusion-generated images demonstrate that MoLD significantly improves detection performance, enhances generalization across diverse generative models, and exhibits robustness in real-world scenarios. Finally, we illustrate the scalability and versatility of our approach by successfully applying it to other pre-trained ViTs, such as DINOv2.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04969v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04969v1">üìÑ Download PDF</a></p><hr><h3 id=balanced-few-shot-episodic-learning-for-accurate-retinal-disease-diagnosishttpsarxivorgabs251204967v1><a href=https://arxiv.org/abs/2512.04967v1>Balanced Few-Shot Episodic Learning for Accurate Retinal Disease Diagnosis</a><a hidden class=anchor aria-hidden=true href=#balanced-few-shot-episodic-learning-for-accurate-retinal-disease-diagnosishttpsarxivorgabs251204967v1>#</a></h3><p><strong>Authors:</strong> Jasmaine Khale, Ravi Prakash Srivastava
<strong>Venue:</strong> arXiv (2025)</p><p>Automated retinal disease diagnosis is vital given the rising prevalence of conditions such as diabetic retinopathy and macular degeneration. Conventional deep learning approaches require large annotated datasets, which are costly and often imbalanced across disease categories, limiting their reliability in practice. Few-shot learning (FSL) addresses this challenge by enabling models to generalize from only a few labeled samples per class. In this study,we propose a balanced few-shot episodic learning framework tailored to the Retinal Fundus Multi-Disease Image Dataset (RFMiD). Focusing on the ten most represented classes, which still show substantial imbalance between majority diseases (e.g., Diabetic Retinopathy, Macular Hole) and minority ones (e.g., Optic Disc Edema, Branch Retinal Vein Occlusion), our method integrates three key components: (i) balanced episodic sampling, ensuring equal participation of all classes in each 5-way 5-shot episode; (ii) targeted augmentation, including Contrast Limited Adaptive Histogram Equalization (CLAHE) and color/geometry transformations, to improve minority-class di- versity; and (iii) a ResNet-50 encoder pretrained on ImageNet, selected for its superior ability to capture fine-grained retinal features. Prototypes are computed in the embedding space and classification is performed with cosine similarity for improved stability. Trained on 100 episodes and evaluated on 1,000 test episodes, our framework achieves substantial accuracy gains and reduces bias toward majority classes, with notable improvements for underrepresented diseases. These results demonstrate that dataset-aware few-shot pipelines, combined with balanced sampling and CLAHE-enhanced preprocessing, can deliver more robust and clinically fair retinal disease diagnosis under data-constrained conditions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04967v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04967v1">üìÑ Download PDF</a></p><hr><h3 id=the-spectrum-of-n_s-constraints-from-desi-and-cmb-datahttpsarxivorgabs251205108v1><a href=https://arxiv.org/abs/2512.05108v1>The spectrum of $n_s$ constraints from DESI and CMB data</a><a hidden class=anchor aria-hidden=true href=#the-spectrum-of-n_s-constraints-from-desi-and-cmb-datahttpsarxivorgabs251205108v1>#</a></h3><p><strong>Authors:</strong> Evan McDonough, Elisa G. M. Ferreira
<strong>Venue:</strong> arXiv (2025)</p><p>We present the spectrum of $n_s$ constraints from current CMB data (Planck, ACT, SPT-3G) combined with DESI BAO data, and highlight the interplay of $n_s$ with the optical depth to reionization $œÑ$. The spectral index $n_s$ of the primordial power spectrum provides a window into early universe, and constraints on $n_s$ play an important role in discriminating early universe models such as models of cosmic inflation. Historically constrained by cosmic microwave background (CMB) experiments, the constraints on $n_s$ shift upward when CMB data is combined with the latest baryon acoustic oscillation (BAO) data from the Dark Energy Spectroscopic Instrument (DESI). Recent work explained the origin of this and the relation to the BAO-CMB tension between CMB experiments and DESI BAO, and as a case study presented constraints on $n_s$ from the combination of Atacama Cosmology Telescope (ACT) DR6 data and DESI DR2 data. Here we present constraints from Planck (PR3 and PR4), ACT, the South Pole Telescope (SPT), and the combination of all three CMB experiments, CMB-SPA, with and without DESI DR2 BAO data, and with and without CMB lensing data. In all cases the constraint on $n_s$ is shifted upwards when DESI is included, with the largest shift exhibited by ACT. This is accompanied by a commensurate shift in the constraint on the optical depth to reionization $œÑ$, which is again greatest for ACT. When CMB data are combined into CMB-SPA and combined with DESI the $n_s$ constraint disfavors at more than $2œÉ$ the inflation models preferred by Planck alone, such as Higgs, Starobinsky, and exponential $Œ±$-attractors, in favor of other models, such as polynomial $Œ±$-attractors. This work motivates the further study of the tension between CMB and DESI BAO data, and of the rich interplay between $n_s$ and $œÑ$.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05108v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05108v1">üìÑ Download PDF</a></p><hr><h3 id=highly-ionized-gas-in-lensed-z--6027-little-red-dot-seen-through-oiii-88Œºm-with-almahttpsarxivorgabs251205097v1><a href=https://arxiv.org/abs/2512.05097v1>Highly-ionized gas in lensed z = 6.027 Little Red Dot seen through [OIII] 88$Œº$m with ALMA</a><a hidden class=anchor aria-hidden=true href=#highly-ionized-gas-in-lensed-z--6027-little-red-dot-seen-through-oiii-88Œºm-with-almahttpsarxivorgabs251205097v1>#</a></h3><p><strong>Authors:</strong> Kirsten K. Knudsen, Johan Richard, Mathilde Jauzac, Tom J. L. C. Bakx, Thiago S. Goncalves, Eiichi Egami, Kiana Kade, Rahul Rana, Laura Sommovigo, Flora Stanley, Daniel P. Stark
<strong>Venue:</strong> arXiv (2025)</p><p>Determining the physical properties of galaxies during the first billion years after the big bang is key to understanding both early galaxy evolution and how galaxies contributed to the epoch of reionization. We present deep ALMA observations of the redshifted [OIII] 88um line for the gravitationally lensed ($Œº= 11.4\pm1.9$) galaxy A383-5.1 (z=6.027) that has previously been detected in [CII] 158um. Recent James Webb Space Telescope (JWST) imaging identified this sub-L* galaxy as a &lsquo;&lsquo;Little Red Dot&rsquo;&rsquo; (LRD). With a line luminosity of $L_{\rm [OIII]} = (1.29\pm0.24)\times10^8$ L$_\odot$ (corrected for lensing magnification) A383-5.1 is one of the faintest galaxies with combined [CII] and [OIII] detections. The ALMA data reveal no dust continuum emission, consistent with previous observations. The high line luminosity ratio of [OIII]/[CII] $\sim 14\pm5$ is consistent with A383-5.1 being low-metallicity and dust-poor. The non-detection of dust continuum in bands 6 and 8 is consistent with the high [OIII]/[CII] ratio and suggests a presence of a strong ultraviolet radiation field, which would be less affect by dust attenuation, implying that galaxies of this type could contribute significantly to the ionization of the intergalactic medium. The presence of strong ionizing field could provide an important piece of information for understanding the nature of LRDs and their role in cosmic reionization.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05097v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05097v1">üìÑ Download PDF</a></p><hr><h3 id=line-of-sight-shear-in-slacs-strong-lenses-ii-validation-tests-with-an-extended-samplehttpsarxivorgabs251205050v1><a href=https://arxiv.org/abs/2512.05050v1>Line-of-sight shear in SLACS strong lenses II: validation tests with an extended sample</a><a hidden class=anchor aria-hidden=true href=#line-of-sight-shear-in-slacs-strong-lenses-ii-validation-tests-with-an-extended-samplehttpsarxivorgabs251205050v1>#</a></h3><p><strong>Authors:</strong> Natalie B. Hogg, Daniel Johnson, Anowar J. Shajib, Julien Larena
<strong>Venue:</strong> arXiv (2025)</p><p>Strong gravitational lensing images are subject to shape distortions due to inhomogeneities along the line of sight. The leading order shape distortion is shear, which, if measurable, will be a complementary cosmological probe to traditional cosmic shear. In Hogg et al. (2025a), we modelled 23 of the SLACS strong lenses, studying the line-of-sight (LOS) shear under a variety of shear and mass model parametrisations. In this work, we model 27 additional lenses, extending our sample of LOS shear constraints to 45 in total. We find a mean shear magnitude of $0.11\pm 0.024$, showing that a significant fraction of the lenses modelled in this work possess LOS shears with unexpectedly large magnitudes, $|Œ≥_{\rm LOS}| > 0.1$, even when an octupolar distortion is included in the lens mass. We further investigate if factors such as lens and source redshift, filter and PSF, or flux and signal-to-noise ratio in the lensed arcs correlate with shear. We find that none of these features play a statistically significant role in the production of unusually large shear magnitudes.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05050v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05050v1">üìÑ Download PDF</a></p><hr><h3 id=the-critical-role-of-clumping-in-line-driven-disc-windshttpsarxivorgabs251205029v1><a href=https://arxiv.org/abs/2512.05029v1>The critical role of clumping in line-driven disc winds</a><a hidden class=anchor aria-hidden=true href=#the-critical-role-of-clumping-in-line-driven-disc-windshttpsarxivorgabs251205029v1>#</a></h3><p><strong>Authors:</strong> Amin Mosallanezhad, Christian Knigge, Nicolas Scepi, Knox S. Long, James H. Matthews, Stuart A. Sim, Austen Wallis
<strong>Venue:</strong> arXiv (2025)</p><p>Radiation pressure on spectral lines is a promising mechanism for powering disc winds from accreting white dwarfs (AWDs) and active galactic nuclei (AGN). However, in radiation-hydrodynamic simulations, overionization reduces line opacity and quenches the line force, which suppresses outflows. Here, we show that small-scale clumping can resolve this problem. Adopting the microclumping approximation, our new simulations demonstrate that even modest volume filling factors ($f_V \sim 0.1-0.01$) can dramatically increase the wind mass-loss rate by lowering its ionization state &ndash; raising $\dot{M}<em>{\rm wind}$ and yielding $\dot{M}</em>{\rm wind}/\dot{M}_{\rm acc}!\gtrsim!10^{-4}$ for such modest filling factors. Clumpy wind models produce the UV resonance lines that are absent from smooth wind models. They can also reprocess a significant fraction of the disc luminosity and thus dramatically modify the broad-band optical/UV SED. Given that theory and observations indicate that disc winds are intrinsically inhomogeneous, clumping offers a physically motivated solution. Together, these results provide the first robust, self-consistent demonstration that clumping can reconcile line-driven wind theory with observations across AWDs and AGNs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05029v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05029v1">üìÑ Download PDF</a></p><hr><h3 id=convergence-of-sample-based-quantum-diagonalization-on-a-variable-length-cuprate-chainhttpsarxivorgabs251204962v1><a href=https://arxiv.org/abs/2512.04962v1>Convergence of sample-based quantum diagonalization on a variable-length cuprate chain</a><a hidden class=anchor aria-hidden=true href=#convergence-of-sample-based-quantum-diagonalization-on-a-variable-length-cuprate-chainhttpsarxivorgabs251204962v1>#</a></h3><p><strong>Authors:</strong> L. Andrew Wray, Cheng-Ju Lin, Vincent Su, Hrant Gharibyan
<strong>Venue:</strong> arXiv (2025)</p><p>Sample-based quantum diagonalization (SQD) is an algorithm for hybrid quantum-classical molecular simulation that has been of broad interest for application with noisy intermediate scale quantum (NISQ) devices. However, SQD does not always converge on a practical timescale. Here, we explore scaling of the algorithm for a variable-length molecule made up of 2 to 6 copper oxide plaquettes with a minimal molecular orbital basis. The results demonstrate that enabling all-to-all connectivity, instituting a higher expansion order for the SQD algorithm, and adopting a non-Hartree-Fock molecular orbital basis can all play significant roles in overcoming sampling bottlenecks, though with tradeoffs that need to be weighed against the capabilities of quantum and classical hardware. Additionally, we find that noise on a real quantum computer, the Quantinuum H2 trapped ion device, can improve energy convergence beyond expectations based on noise-free statevector simulations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04962v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04962v1">üìÑ Download PDF</a></p><hr><h3 id=realizable-abstractions-near-optimal-hierarchical-reinforcement-learninghttpsarxivorgabs251204958v1><a href=https://arxiv.org/abs/2512.04958v1>Realizable Abstractions: Near-Optimal Hierarchical Reinforcement Learning</a><a hidden class=anchor aria-hidden=true href=#realizable-abstractions-near-optimal-hierarchical-reinforcement-learninghttpsarxivorgabs251204958v1>#</a></h3><p><strong>Authors:</strong> Roberto Cipollone, Luca Iocchi, Matteo Leonetti
<strong>Venue:</strong> arXiv (2025)</p><p>The main focus of Hierarchical Reinforcement Learning (HRL) is studying how large Markov Decision Processes (MDPs) can be more efficiently solved when addressed in a modular way, by combining partial solutions computed for smaller subtasks. Despite their very intuitive role for learning, most notions of MDP abstractions proposed in the HRL literature have limited expressive power or do not possess formal efficiency guarantees. This work addresses these fundamental issues by defining Realizable Abstractions, a new relation between generic low-level MDPs and their associated high-level decision processes. The notion we propose avoids non-Markovianity issues and has desirable near-optimality guarantees. Indeed, we show that any abstract policy for Realizable Abstractions can be translated into near-optimal policies for the low-level MDP, through a suitable composition of options. As demonstrated in the paper, these options can be expressed as solutions of specific constrained MDPs. Based on these findings, we propose RARL, a new HRL algorithm that returns compositional and near-optimal low-level policies, taking advantage of the Realizable Abstraction given in the input. We show that RARL is Probably Approximately Correct, it converges in a polynomial number of samples, and it is robust to inaccuracies in the abstraction.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04958v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04958v1">üìÑ Download PDF</a></p><hr><h3 id=mallorn-many-artificial-lsst-lightcurves-based-on-observations-of-real-nuclear-transientshttpsarxivorgabs251204946v1><a href=https://arxiv.org/abs/2512.04946v1>MALLORN: Many Artificial LSST Lightcurves based on Observations of Real Nuclear transients</a><a hidden class=anchor aria-hidden=true href=#mallorn-many-artificial-lsst-lightcurves-based-on-observations-of-real-nuclear-transientshttpsarxivorgabs251204946v1>#</a></h3><p><strong>Authors:</strong> Dylan Magill, Matt Nicholl, Vysakh Anilkumar, Sjoert van Velzen, Xinyue Sheng, Thai Son Mai, Hung Viet Tran, Ngoc Phu Doan, Thomas Moore, Shubham Srivastav, David R. Young, Charlotte R. Angus, Joshua Weston
<strong>Venue:</strong> arXiv (2025)</p><p>The Vera C. Rubin Observatory&rsquo;s 10-Year Legacy Survey of Space and Time (LSST) is expected to produce a hundredfold increase in the number of transients we observe. However, there are insufficient spectroscopic resources to follow up on all of the wealth of targets that LSST will provide. As such it is necessary to be able to prioritise objects for followup observations or inclusion in sample studies based purely on their LSST photometry. We are particularly keen to identify tidal disruption events (TDEs) with LSST. TDEs are immensely useful for determining black hole parameters and probing our understanding of accretion physics. To assist in these efforts, we present the Many Artificial LSST Lightcurves based on the Observations of Real Nuclear transients (MALLORN) data set and the corresponding classifier challenge for identifying TDEs. MALLORN comprises 10178 simulated LSST light curves, constructed from real Zwicky Transient Facility (ZTF) observations of 64 TDEs, 727 nuclear supernovae and 1407 AGN with spectroscopic labels using Gaussian process fitting, empirically-motivated spectral energy distributions from SNCosmo and the baseline from the Rubin Survey Simulator. Our novel approach can be easily adapted to simulate transients for any photometric survey using observations from another, requiring only the limiting magnitudes and an estimate of the cadence of observations. The MALLORN Astronomical Classification Challenge, launched on Kaggle on 15/10/2025, will allow competitors to test their photometric classifiers on simulated LSST data to find TDEs and improve upon their capabilities prior to the start of LSST.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04946v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04946v1">üìÑ Download PDF</a></p><hr><h3 id=local-mixing-length-theory-with-compositional-effects-first-application-to-asymptotic-giant-branch-evolutionhttpsarxivorgabs251204900v1><a href=https://arxiv.org/abs/2512.04900v1>Local mixing length theory with compositional effects:\ First application to asymptotic giant branch evolution</a><a hidden class=anchor aria-hidden=true href=#local-mixing-length-theory-with-compositional-effects-first-application-to-asymptotic-giant-branch-evolutionhttpsarxivorgabs251204900v1>#</a></h3><p><strong>Authors:</strong> M. M. Ocampo, M. M. Miller Bertolami, A. H. C√≥rsico, L. G. Althaus
<strong>Venue:</strong> arXiv (2025)</p><p>During the evolution of stars on the asymptotic giant branch (AGB), thermal pulses lead to the formation of strongly stratified layers in the outer regions of the CO core, which might lead to inversions in the chemical gradient. Such inversions would produce instabilities beyond the ones predicted by the Schwarzschild criterion and the standard use of mixing length theory (MLT). We used a set of MLT equations that consider the impact of the background chemical gradients. This extension of MLT is referred to in this work as MLT$\sharp$, to make a distinction between both prescriptions. We applied MLT$\sharp$ in tandem with the more general Ledoux instability criterion. We computed the evolution in the AGB phase and compared the chemical profiles resulting from MLT, MLT$\sharp$ and the double diffusive GNA theory. We continued the evolution through a post-AGB thermal pulse and performed a pulsational analysis of the resultant GW Vir models to asses $g$-mode pulsation periods. Finally, we tested our results with pulsation properties of known GW Vir stars derived from recent observations. We find that the much simpler MLT$\sharp$ set of equations closely reproduces the results from the GNA theory. As such, MLT$\sharp$ offers a simple way to include chemically driven convection in stellar evolution computations. Stellar evolution simulations show that Rayleigh-Taylor and thermohaline instabilities can play an important role during the TP-AGB. We obtained significantly different chemical profiles using a standard MLT approach compared to those resulting from our MLT$\sharp$ and GNA computations. Our adiabatic pulsational analysis shows that these differences in the chemical stratification leave clear mode-trapping signatures in the pulsation spectrum of the GW Vir models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04900v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04900v1">üìÑ Download PDF</a></p><hr><h3 id=optimizations-and-extensions-for-fair-join-pattern-matchinghttpsarxivorgabs251204876v1><a href=https://arxiv.org/abs/2512.04876v1>Optimizations and extensions for fair join pattern matching</a><a hidden class=anchor aria-hidden=true href=#optimizations-and-extensions-for-fair-join-pattern-matchinghttpsarxivorgabs251204876v1>#</a></h3><p><strong>Authors:</strong> Ioannis Karras
<strong>Venue:</strong> arXiv (2025)</p><p>Join patterns are an underexplored approach for the programming of concurrent and distributed systems. When applied to the actor model, join patterns offer the novel capability of matching combinations of messages in the mailbox of an actor. Previous work by Philipp Haller et al. in the paper &ldquo;Fair Join Pattern Matching for Actors&rdquo; (ECOOP 2024) explored join patterns with conditional guards in an actor-based setting with a specification of fair and deterministic matching semantics. Nevertheless, the question of time efficiency in fair join pattern matching has remained underexplored. The stateful tree-based matching algorithm of Haller et al. performs worse than an implementation that adapts the Rete algorithm to the regular version of a join pattern matching benchmark, while outperforming on a variant with heavy conditional guards, which take longer to evaluate. Nevertheless, conforming Rete to the problem of join pattern matching requires heavy manual adaptation.
In this thesis, we enhance and optimize the stateful tree-based matching algorithm of Haller et al. to achieve up to tenfold performance improvements on certain benchmarks, approaching the performance of Rete on regular benchmarks while maintaining the advantages of versatility and performance with heavy guards. We also enhance the benchmark suite, adding new features and enhancing its extensibility and user-friendliness. We extend the join pattern implementation with a less ambiguous syntax as well as dynamic pattern switching. Finally, we present a new complex model use case for join patterns, showing their applicability in a microservice web architecture.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04876v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04876v1">üìÑ Download PDF</a></p><hr><h3 id=sp-det-self-prompted-dual-text-fusion-for-generalized-multi-label-lesion-detectionhttpsarxivorgabs251204875v1><a href=https://arxiv.org/abs/2512.04875v1>SP-Det: Self-Prompted Dual-Text Fusion for Generalized Multi-Label Lesion Detection</a><a hidden class=anchor aria-hidden=true href=#sp-det-self-prompted-dual-text-fusion-for-generalized-multi-label-lesion-detectionhttpsarxivorgabs251204875v1>#</a></h3><p><strong>Authors:</strong> Qing Xu, Yanqian Wang, Xiangjian Hea, Yue Li, Yixuan Zhang, Rong Qu, Wenting Duan, Zhen Chen
<strong>Venue:</strong> arXiv (2025)</p><p>Automated lesion detection in chest X-rays has demonstrated significant potential for improving clinical diagnosis by precisely localizing pathological abnormalities. While recent promptable detection frameworks have achieved remarkable accuracy in target localization, existing methods typically rely on manual annotations as prompts, which are labor-intensive and impractical for clinical applications. To address this limitation, we propose SP-Det, a novel self-prompted detection framework that automatically generates rich textual context to guide multi-label lesion detection without requiring expert annotations. Specifically, we introduce an expert-free dual-text prompt generator (DTPG) that leverages two complementary textual modalities: semantic context prompts that capture global pathological patterns and disease beacon prompts that focus on disease-specific manifestations. Moreover, we devise a bidirectional feature enhancer (BFE) that synergistically integrates comprehensive diagnostic context with disease-specific embeddings to significantly improve feature representation and detection accuracy. Extensive experiments on two chest X-ray datasets with diverse thoracic disease categories demonstrate that our SP-Det framework outperforms state-of-the-art detection methods while completely eliminating the dependency on expert-annotated prompts compared to existing promptable architectures.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04875v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04875v1">üìÑ Download PDF</a></p><hr><h3 id=enabling-ethical-ai-a-case-study-in-using-ontological-context-for-justified-agentic-ai-decisionshttpsarxivorgabs251204822v1><a href=https://arxiv.org/abs/2512.04822v1>Enabling Ethical AI: A case study in using Ontological Context for Justified Agentic AI Decisions</a><a hidden class=anchor aria-hidden=true href=#enabling-ethical-ai-a-case-study-in-using-ontological-context-for-justified-agentic-ai-decisionshttpsarxivorgabs251204822v1>#</a></h3><p><strong>Authors:</strong> Liam McGee, James Harvey, Lucy Cull, Andreas Vermeulen, Bart-Floris Visscher, Malvika Sharan
<strong>Venue:</strong> arXiv (2025)</p><p>In this preprint, we present A collaborative human-AI approach to building an inspectable semantic layer for Agentic AI. AI agents first propose candidate knowledge structures from diverse data sources; domain experts then validate, correct, and extend these structures, with their feedback used to improve subsequent models. Authors show how this process captures tacit institutional knowledge, improves response quality and efficiency, and mitigates institutional amnesia. We argue for a shift from post-hoc explanation to justifiable Agentic AI, where decisions are grounded in explicit, inspectable evidence and reasoning accessible to both experts and non-specialists.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04822v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04822v1">üìÑ Download PDF</a></p><hr><h3 id=robustsplat-decoupling-densification-dynamics-and-illumination-for-in-the-wild-3dgshttpsarxivorgabs251204815v1><a href=https://arxiv.org/abs/2512.04815v1>RobustSplat++: Decoupling Densification, Dynamics, and Illumination for In-the-Wild 3DGS</a><a hidden class=anchor aria-hidden=true href=#robustsplat-decoupling-densification-dynamics-and-illumination-for-in-the-wild-3dgshttpsarxivorgabs251204815v1>#</a></h3><p><strong>Authors:</strong> Chuanyu Fu, Guanying Chen, Yuqi Zhang, Kunbin Yao, Yuan Xiong, Chuan Huang, Shuguang Cui, Yasuyuki Matsushita, Xiaochun Cao
<strong>Venue:</strong> arXiv (2025)</p><p>3D Gaussian Splatting (3DGS) has gained significant attention for its real-time, photo-realistic rendering in novel-view synthesis and 3D modeling. However, existing methods struggle with accurately modeling in-the-wild scenes affected by transient objects and illuminations, leading to artifacts in the rendered images. We identify that the Gaussian densification process, while enhancing scene detail capture, unintentionally contributes to these artifacts by growing additional Gaussians that model transient disturbances and illumination variations. To address this, we propose RobustSplat++, a robust solution based on several critical designs. First, we introduce a delayed Gaussian growth strategy that prioritizes optimizing static scene structure before allowing Gaussian splitting/cloning, mitigating overfitting to transient objects in early optimization. Second, we design a scale-cascaded mask bootstrapping approach that first leverages lower-resolution feature similarity supervision for reliable initial transient mask estimation, taking advantage of its stronger semantic consistency and robustness to noise, and then progresses to high-resolution supervision to achieve more precise mask prediction. Third, we incorporate the delayed Gaussian growth strategy and mask bootstrapping with appearance modeling to handling in-the-wild scenes including transients and illuminations. Extensive experiments on multiple challenging datasets show that our method outperforms existing methods, clearly demonstrating the robustness and effectiveness of our method.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04815v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04815v1">üìÑ Download PDF</a></p><hr><h3 id=287872-supermassive-black-holes-masses-deep-learning-approaching-reverberation-mapping-accuracyhttpsarxivorgabs251204803v1><a href=https://arxiv.org/abs/2512.04803v1>287,872 Supermassive Black Holes Masses: Deep Learning Approaching Reverberation Mapping Accuracy</a><a hidden class=anchor aria-hidden=true href=#287872-supermassive-black-holes-masses-deep-learning-approaching-reverberation-mapping-accuracyhttpsarxivorgabs251204803v1>#</a></h3><p><strong>Authors:</strong> Yuhao Lu, HengJian SiTu, Jie Li, Yixuan Li, Yang Liu, Wenbin Lin, Yu Wang
<strong>Venue:</strong> arXiv (2025)</p><p>We present a population-scale catalogue of 287,872 supermassive black hole masses with high accuracy. Using a deep encoder-decoder network trained on optical spectra with reverberation-mapping (RM) based labels of 849 quasars and applied to all SDSS quasars up to $z=4$, our method achieves a root-mean-square error of $0.058$,dex, a relative uncertainty of $\approx 14%$, and coefficient of determination $R^{2}\approx0.91$ with respect to RM-based masses, far surpassing traditional single-line virial estimators. Notably, the high accuracy is maintained for both low ($&lt;10^{7.5},M_\odot$) and high ($>10^{9},M_\odot$) mass quasars, where empirical relations are unreliable.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04803v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04803v1">üìÑ Download PDF</a></p><hr><h3 id=teaching-a-transformer-to-think-like-a-chemist-predicting-nanocluster-stabilityhttpsarxivorgabs251204794v1><a href=https://arxiv.org/abs/2512.04794v1>Teaching a Transformer to Think Like a Chemist: Predicting Nanocluster Stability</a><a hidden class=anchor aria-hidden=true href=#teaching-a-transformer-to-think-like-a-chemist-predicting-nanocluster-stabilityhttpsarxivorgabs251204794v1>#</a></h3><p><strong>Authors:</strong> Jo√£o Marcos T. Palheta, Octavio Rodrigues Filho, Mohammad Soleymanibrojeni, Alexandre Cavalheiro Dias, Diego Guedes-Sobrinho, Wolfgang Wenzel, Roland Aydin, Celso R. C. R√™go, Maur√≠cio Jeomar Piotrowski
<strong>Venue:</strong> arXiv (2025)</p><p>Atomically precise metal nanoclusters bridge the molecular and bulk regimes, but designing bimetallic motifs with targeted stability and reactivity remains challenging. Here we combine density functional theory (DFT) and physics-grounded predictive artificial intelligence to map the configurational landscape of 13-atom icosahedral nanoclusters X$_{12}$TM, with hosts X = (Ti, Zr, Hf), and Fe and a single transition&ndash;metal dopant spanning the 3$d$-5$d$ series. Spin-polarized DFT calculations on 240 bimetallic clusters reveal systematic trends in binding and formation energies, distortion penalties, effective coordination number, d-band centre, and HOMO-LUMO gap that govern the competition between core-shell (in) and surface-segregated (out) arrangements. We then pretrain a transformer architecture on a curated set of 2968 unary clusters from the Quantum Cluster Database and fine-tune it on bimetallic data to predict formation energies and in/out preference, achieving mean absolute errors of about $0.6-0.7$eV and calibrated uncertainty intervals. The resulting model rapidly adapts to an unseen Fe-host domain with only a handful of labelled examples. At the same time, attention patterns and Shapley attributions highlight size mismatch, $d$-electron count, and coordination environment as key descriptors. All data, code, and workflows follow FAIR/TRUE principles, enabling reproducible, interpretable screening of unexplored nanocluster chemistries for catalysis and energy conversion.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04794v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04794v1">üìÑ Download PDF</a></p><hr><h3 id=spontaneous-symmetry-breaking-and-the-higgs-mechanismhttpsarxivorgabs251204741v1><a href=https://arxiv.org/abs/2512.04741v1>Spontaneous Symmetry Breaking and the Higgs Mechanism</a><a hidden class=anchor aria-hidden=true href=#spontaneous-symmetry-breaking-and-the-higgs-mechanismhttpsarxivorgabs251204741v1>#</a></h3><p><strong>Authors:</strong> Gustavo Burdman
<strong>Venue:</strong> arXiv (2025)</p><p>The Higgs sector of the standard model of particle physics plays a central role in the generation of all the masses of elementary particles known so far. Here we give a pedagogical introduction to all the elements leading ot the Higgs mechanism and the Higgs boson, starting with the spontaneous symmetry breaking of global symmetries and the Goldstone theorem. We then consider the case of gauge symmetries, i.e. the Higgs mechanism, and its application to the electroweak sector of the standard model. We close with a reflection on the possible open questions that the very introduction of the Higgs sector in the standard model posses.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04741v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04741v1">üìÑ Download PDF</a></p><hr><h3 id=exact-and-mean-field-analysis-of-the-role-of-hubbard-interactions-on-flux-driven-circular-current-in-a-quantum-ringhttpsarxivorgabs251204736v1><a href=https://arxiv.org/abs/2512.04736v1>Exact and mean-field analysis of the role of Hubbard interactions on flux driven circular current in a quantum ring</a><a hidden class=anchor aria-hidden=true href=#exact-and-mean-field-analysis-of-the-role-of-hubbard-interactions-on-flux-driven-circular-current-in-a-quantum-ringhttpsarxivorgabs251204736v1>#</a></h3><p><strong>Authors:</strong> Rahul Samanta, Santanu K. Maiti, Shreekantha Sil
<strong>Venue:</strong> arXiv (2025)</p><p>We investigate circular current in both ordered and disordered Hubbard quantum rings threaded by magnetic flux, employing exact diagonalization and the Hartree-Fock mean-field approach within the tight-binding framework. The influence of on-site and extended Hubbard interactions, disorder, and electron filling on the persistent current is systematically analyzed. To construct the full many-body Hamiltonian, we introduce a linear table formalism, which, to our knowledge, has been rarely used in this context. In ordered rings, the current decreases monotonically with increasing on-site repulsion, while the impact of the extended interaction depends strongly on the filling factor. At low filling, stronger extended interaction suppresses the current, whereas near half-filling, it enhances the current up to a critical ratio, half of the on-site strength, before reducing it. Disorder significantly modifies these behaviors, notably enhancing the current at less than quarter-filling with increasing extended interaction. The localization properties of eigenstates, examined via the inverse participation ratio, further support the crucial roles of filling and the interplay between on-site and extended interactions in governing persistent current.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04736v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04736v1">üìÑ Download PDF</a></p><hr><h3 id=mt-depth-multi-task-instance-feature-analysis-for-the-depth-completionhttpsarxivorgabs251204734v1><a href=https://arxiv.org/abs/2512.04734v1>MT-Depth: Multi-task Instance feature analysis for the Depth Completion</a><a hidden class=anchor aria-hidden=true href=#mt-depth-multi-task-instance-feature-analysis-for-the-depth-completionhttpsarxivorgabs251204734v1>#</a></h3><p><strong>Authors:</strong> Abdul Haseeb Nizamani, Dandi Zhou, Xinhai Sun
<strong>Venue:</strong> arXiv (2025)</p><p>Depth completion plays a vital role in 3D perception systems, especially in scenarios where sparse depth data must be densified for tasks such as autonomous driving, robotics, and augmented reality. While many existing approaches rely on semantic segmentation to guide depth completion, they often overlook the benefits of object-level understanding. In this work, we introduce an instance-aware depth completion framework that explicitly integrates binary instance masks as spatial priors to refine depth predictions. Our model combines four main components: a frozen YOLO V11 instance segmentation branch, a U-Net-based depth completion backbone, a cross-attention fusion module, and an attention-guided prediction head. The instance segmentation branch generates per-image foreground masks that guide the depth branch via cross-attention, allowing the network to focus on object-centric regions during refinement. We validate our method on the Virtual KITTI 2 dataset, showing that it achieves lower RMSE compared to both a U-Net-only baseline and previous semantic-guided methods, while maintaining competitive MAE. Qualitative and quantitative results demonstrate that the proposed model effectively enhances depth accuracy near object boundaries, occlusions, and thin structures. Our findings suggest that incorporating instance-aware cues offers a promising direction for improving depth completion without relying on dense semantic labels.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04734v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04734v1">üìÑ Download PDF</a></p><hr><h3 id=sequential-enumeration-in-large-language-modelshttpsarxivorgabs251204727v1><a href=https://arxiv.org/abs/2512.04727v1>Sequential Enumeration in Large Language Models</a><a hidden class=anchor aria-hidden=true href=#sequential-enumeration-in-large-language-modelshttpsarxivorgabs251204727v1>#</a></h3><p><strong>Authors:</strong> Kuinan Hou, Marco Zorzi, Alberto Testolin
<strong>Venue:</strong> arXiv (2025)</p><p>Reliably counting and generating sequences of items remain a significant challenge for neural networks, including Large Language Models (LLMs). Indeed, although this capability is readily handled by rule-based symbolic systems based on serial computation, learning to systematically deploy counting procedures is difficult for neural models, which should acquire these skills through learning. Previous research has demonstrated that recurrent architectures can only approximately track and enumerate sequences of events, and it remains unclear whether modern deep learning systems, including LLMs, can deploy systematic counting procedures over sequences of discrete symbols. This paper aims to fill this gap by investigating the sequential enumeration abilities of five state-of-the-art LLMs, including proprietary, open-source, and reasoning models. We probe LLMs in sequential naming and production tasks involving lists of letters and words, adopting a variety of prompting instructions to explore the role of chain-of-thought in the spontaneous emerging of counting strategies. We also evaluate open-source models with the same architecture but increasing size to see whether the mastering of counting principles follows scaling laws, and we analyze the embedding dynamics during sequential enumeration to investigate the emergent encoding of numerosity. We find that some LLMs are indeed capable of deploying counting procedures when explicitly prompted to do so, but none of them spontaneously engage in counting when simply asked to enumerate the number of items in a sequence. Our results suggest that, despite their impressive emergent abilities, LLMs cannot yet robustly and systematically deploy counting procedures, highlighting a persistent gap between neural and symbolic approaches to compositional generalization.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04727v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04727v1">üìÑ Download PDF</a></p><hr><h3 id=playing-the-player-a-heuristic-framework-for-adaptive-poker-aihttpsarxivorgabs251204714v1><a href=https://arxiv.org/abs/2512.04714v1>Playing the Player: A Heuristic Framework for Adaptive Poker AI</a><a hidden class=anchor aria-hidden=true href=#playing-the-player-a-heuristic-framework-for-adaptive-poker-aihttpsarxivorgabs251204714v1>#</a></h3><p><strong>Authors:</strong> Andrew Paterson, Carl Sanders
<strong>Venue:</strong> arXiv (2025)</p><p>For years, the discourse around poker AI has been dominated by the concept of solvers and the pursuit of unexploitable, machine-perfect play. This paper challenges that orthodoxy. It presents Patrick, an AI built on the contrary philosophy: that the path to victory lies not in being unexploitable, but in being maximally exploitative. Patrick&rsquo;s architecture is a purpose-built engine for understanding and attacking the flawed, psychological, and often irrational nature of human opponents. Through detailed analysis of its design, its novel prediction-anchored learning method, and its profitable performance in a 64,267-hand trial, this paper makes the case that the solved myth is a distraction from the real, far more interesting challenge: creating AI that can master the art of human imperfection.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04714v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04714v1">üìÑ Download PDF</a></p><hr><h3 id=llm-srclog-towards-proactive-and-unified-log-template-extraction-via-large-language-modelshttpsarxivorgabs251204474v1><a href=https://arxiv.org/abs/2512.04474v1>LLM-SrcLog: Towards Proactive and Unified Log Template Extraction via Large Language Models</a><a hidden class=anchor aria-hidden=true href=#llm-srclog-towards-proactive-and-unified-log-template-extraction-via-large-language-modelshttpsarxivorgabs251204474v1>#</a></h3><p><strong>Authors:</strong> Jiaqi Sun, Wei Li, Heng Zhang, Chutong Ding, Shiyou Qian, Jian Cao, Guangtao Xue
<strong>Venue:</strong> arXiv (2025)</p><p>Log parsing transforms raw logs into structured templates containing constants and variables. It underpins anomaly detection, failure diagnosis, and other AIOps tasks. Current parsers are mostly reactive and log-centric. They only infer templates from logs, mostly overlooking the source code. This restricts their capacity to grasp dynamic log structures or adjust to evolving systems. Moreover, per-log LLM inference is too costly for practical deployment. In this paper, we propose LLM-SrcLog, a proactive and unified framework for log template parsing. It extracts templates directly from source code prior to deployment and supplements them with data-driven parsing for logs without available code. LLM-SrcLog integrates a cross-function static code analyzer to reconstruct meaningful logging contexts, an LLM-based white-box template extractor with post-processing to distinguish constants from variables, and a black-box template extractor that incorporates data-driven clustering for remaining unmatched logs. Experiments on two public benchmarks (Hadoop and Zookeeper) and a large-scale industrial system (Sunfire-Compute) show that, compared to two LLM-based baselines, LLM-SrcLog improves average F1-score by 2-17% and 8-35%. Meanwhile, its online parsing latency is comparable to data-driven methods and about 1,000 times faster than per-log LLM parsing. LLM-SrcLog achieves a near-ideal balance between speed and accuracy. Finally, we further validate the effectiveness of LLM-SrcLog through practical case studies in a real-world production environment.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04474v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04474v1">üìÑ Download PDF</a></p><hr><h3 id=quantitative-analysis-of-technical-debt-and-pattern-violation-in-large-language-model-architectureshttpsarxivorgabs251204273v1><a href=https://arxiv.org/abs/2512.04273v1>Quantitative Analysis of Technical Debt and Pattern Violation in Large Language Model Architectures</a><a hidden class=anchor aria-hidden=true href=#quantitative-analysis-of-technical-debt-and-pattern-violation-in-large-language-model-architectureshttpsarxivorgabs251204273v1>#</a></h3><p><strong>Authors:</strong> Tyler Slater
<strong>Venue:</strong> arXiv (2025)</p><p>As Large Language Models (LLMs) transition from code completion tools to autonomous system architects, their impact on long-term software maintainability remains unquantified. While existing research benchmarks functional correctness (pass@k), this study presents the first empirical framework to measure &ldquo;Architectural Erosion&rdquo; and the accumulation of Technical Debt in AI-synthesized microservices. We conducted a comparative pilot study of three state-of-the-art models (GPT-5.1, Claude 4.5 Sonnet, and Llama 3 8B) by prompting them to implement a standardized Book Lending Microservice under strict Hexagonal Architecture constraints. Utilizing Abstract Syntax Tree (AST) parsing, we find that while proprietary models achieve high architectural conformance (0% violation rate for GPT-5.1), open-weights models exhibit critical divergence. Specifically, Llama 3 demonstrated an 80% Architectural Violation Rate, frequently bypassing interface adapters to create illegal circular dependencies between Domain and Infrastructure layers. Furthermore, we identified a phenomenon of &ldquo;Implementation Laziness,&rdquo; where open-weights models generated 60% fewer Logical Lines of Code (LLOC) than their proprietary counterparts, effectively omitting complex business logic to satisfy token constraints. These findings suggest that without automated architectural linting, utilizing smaller open-weights models for system scaffolding accelerates the accumulation of structural technical debt.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04273v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04273v1">üìÑ Download PDF</a></p><hr><h3 id=generalized-event-partonomy-inference-with-structured-hierarchical-predictive-learninghttpsarxivorgabs251204219v1><a href=https://arxiv.org/abs/2512.04219v1>Generalized Event Partonomy Inference with Structured Hierarchical Predictive Learning</a><a hidden class=anchor aria-hidden=true href=#generalized-event-partonomy-inference-with-structured-hierarchical-predictive-learninghttpsarxivorgabs251204219v1>#</a></h3><p><strong>Authors:</strong> Zhou Chen, Joe Lin, Sathyanarayanan N. Aakur\
<strong>Venue:</strong> arXiv (2025)</p><p>Humans naturally perceive continuous experience as a hierarchy of temporally nested events, fine-grained actions embedded within coarser routines. Replicating this structure in computer vision requires models that can segment video not just retrospectively, but predictively and hierarchically. We introduce PARSE, a unified framework that learns multiscale event structure directly from streaming video without supervision. PARSE organizes perception into a hierarchy of recurrent predictors, each operating at its own temporal granularity: lower layers model short-term dynamics while higher layers integrate longer-term context through attention-based feedback. Event boundaries emerge naturally as transient peaks in prediction error, yielding temporally coherent, nested partonomies that mirror the containment relations observed in human event perception. Evaluated across three benchmarks, Breakfast Actions, 50 Salads, and Assembly 101, PARSE achieves state-of-the-art performance among streaming methods and rivals offline baselines in both temporal alignment (H-GEBD) and structural consistency (TED, hF1). The results demonstrate that predictive learning under uncertainty provides a scalable path toward human-like temporal abstraction and compositional event understanding.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04219v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04219v1">üìÑ Download PDF</a></p><hr><h3 id=deeprule-an-integrated-framework-for-automated-business-rule-generation-via-deep-predictive-modeling-and-hybrid-search-optimizationhttpsarxivorgabs251203607v1><a href=https://arxiv.org/abs/2512.03607v1>DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization</a><a hidden class=anchor aria-hidden=true href=#deeprule-an-integrated-framework-for-automated-business-rule-generation-via-deep-predictive-modeling-and-hybrid-search-optimizationhttpsarxivorgabs251203607v1>#</a></h3><p><strong>Authors:</strong> Yusen Wu, Xiaotie Deng
<strong>Venue:</strong> arXiv (2025)</p><p>This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints.
Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03607v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03607v1">üìÑ Download PDF</a></p><hr><h3 id=identifying-attributions-of-causality-in-political-texthttpsarxivorgabs251203214v1><a href=https://arxiv.org/abs/2512.03214v1>Identifying attributions of causality in political text</a><a hidden class=anchor aria-hidden=true href=#identifying-attributions-of-causality-in-political-texthttpsarxivorgabs251203214v1>#</a></h3><p><strong>Authors:</strong> Paulina Garcia-Corral
<strong>Venue:</strong> arXiv (2025)</p><p>Explanations are a fundamental element of how people make sense of the political world. Citizens routinely ask and answer questions about why events happen, who is responsible, and what could or should be done differently. Yet despite their importance, explanations remain an underdeveloped object of systematic analysis in political science, and existing approaches are fragmented and often issue-specific. I introduce a framework for detecting and parsing explanations in political text. To do this, I train a lightweight causal language model that returns a structured data set of causal claims in the form of cause-effect pairs for downstream analysis. I demonstrate how causal explanations can be studied at scale, and show the method&rsquo;s modest annotation requirements, generalizability, and accuracy relative to human coding.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03214v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03214v1">üìÑ Download PDF</a></p><hr><h3 id=enhancing-job-matching-occupation-skill-and-qualification-linking-with-the-esco-and-eqf-taxonomieshttpsarxivorgabs251203195v1><a href=https://arxiv.org/abs/2512.03195v1>Enhancing Job Matching: Occupation, Skill and Qualification Linking with the ESCO and EQF taxonomies</a><a hidden class=anchor aria-hidden=true href=#enhancing-job-matching-occupation-skill-and-qualification-linking-with-the-esco-and-eqf-taxonomieshttpsarxivorgabs251203195v1>#</a></h3><p><strong>Authors:</strong> Stylianos Saroglou, Konstantinos Diamantaras, Francesco Preta, Marina Delianidi, Apostolos Benisis, Christian Johannes Meyer
<strong>Venue:</strong> arXiv (2025)</p><p>This study investigates the potential of language models to improve the classification of labor market information by linking job vacancy texts to two major European frameworks: the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy and the European Qualifications Framework (EQF). We examine and compare two prominent methodologies from the literature: Sentence Linking and Entity Linking. In support of ongoing research, we release an open-source tool, incorporating these two methodologies, designed to facilitate further work on labor classification and employment discourse. To move beyond surface-level skill extraction, we introduce two annotated datasets specifically aimed at evaluating how occupations and qualifications are represented within job vacancy texts. Additionally, we examine different ways to utilize generative large language models for this task. Our findings contribute to advancing the state of the art in job entity extraction and offer computational infrastructure for examining work, skills, and labor market narratives in a digitally mediated economy. Our code is made publicly available: <a href=https://github.com/tabiya-tech/tabiya-livelihoods-classifier>https://github.com/tabiya-tech/tabiya-livelihoods-classifier</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03195v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03195v1">üìÑ Download PDF</a></p><hr><h3 id=hierarchical-process-reward-models-are-symbolic-vision-learnershttpsarxivorgabs251203126v1><a href=https://arxiv.org/abs/2512.03126v1>Hierarchical Process Reward Models are Symbolic Vision Learners</a><a hidden class=anchor aria-hidden=true href=#hierarchical-process-reward-models-are-symbolic-vision-learnershttpsarxivorgabs251203126v1>#</a></h3><p><strong>Authors:</strong> Shan Zhang, Aotian Chen, Kai Zou, Jindong Gu, Yuan Xue, Anton van den Hengel
<strong>Venue:</strong> arXiv (2025)</p><p>Symbolic computer vision represents diagrams through explicit logical rules and structured representations, enabling interpretable understanding in machine vision. This requires fundamentally different learning paradigms from pixel-based visual models. Symbolic visual learners parse diagrams into geometric primitives-points, lines, and shapes-whereas pixel-based learners operate on textures and colors. We propose a novel self-supervised symbolic auto-encoder that encodes diagrams into structured primitives and their interrelationships within the latent space, and decodes them through our executable engine to reconstruct the input diagrams. Central to this architecture is Symbolic Hierarchical Process Reward Modeling, which applies hierarchical step-level parsing rewards to enforce point-on-line, line-on-shape, and shape-on-relation consistency. Since vanilla reinforcement learning exhibits poor exploration in the policy space during diagram reconstruction; we thus introduce stabilization mechanisms to balance exploration and exploitation. We fine-tune our symbolic encoder on downstream tasks, developing a neuro-symbolic system that integrates the reasoning capabilities of neural networks with the interpretability of symbolic models through reasoning-grounded visual rewards. Evaluations across reconstruction, perception, and reasoning tasks demonstrate the effectiveness of our approach: achieving a 98.2% reduction in MSE for geometric diagram reconstruction, surpassing GPT-4o by 0.6% with a 7B model on chart reconstruction, and improving by +13% on the MathGlance perception benchmark, and by +3% on MathVerse and GeoQA reasoning benchmarks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03126v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03126v1">üìÑ Download PDF</a></p><hr><h3 id=from-panel-to-pixel-zoom-in-vision-language-pretraining-from-biomedical-scientific-literaturehttpsarxivorgabs251202566v1><a href=https://arxiv.org/abs/2512.02566v1>From Panel to Pixel: Zoom-In Vision-Language Pretraining from Biomedical Scientific Literature</a><a hidden class=anchor aria-hidden=true href=#from-panel-to-pixel-zoom-in-vision-language-pretraining-from-biomedical-scientific-literaturehttpsarxivorgabs251202566v1>#</a></h3><p><strong>Authors:</strong> Kun Yuan, Min Woo Sun, Zhen Chen, Alejandro Lozano, Xiangteng He, Shi Li, Nassir Navab, Xiaoxiao Sun, Nicolas Padoy, Serena Yeung-Levy
<strong>Venue:</strong> arXiv (2025)</p><p>There is a growing interest in developing strong biomedical vision-language models. A popular approach to achieve robust representations is to use web-scale scientific data. However, current biomedical vision-language pretraining typically compresses rich scientific figures and text into coarse figure-level pairs, discarding the fine-grained correspondences that clinicians actually rely on when zooming into local structures. To tackle this issue, we introduce Panel2Patch, a novel data pipeline that mines hierarchical structure from existing biomedical scientific literature, i.e., multi-panel, marker-heavy figures and their surrounding text, and converts them into multi-granular supervision. Given scientific figures and captions, Panel2Patch parses layouts, panels, and visual markers, then constructs hierarchical aligned vision-language pairs at the figure, panel, and patch levels, preserving local semantics instead of treating each figure as a single data sample. Built on this hierarchical corpus, we develop a granularity-aware pretraining strategy that unifies heterogeneous objectives from coarse didactic descriptions to fine region-focused phrases. By applying Panel2Patch to only a small set of the literature figures, we extract far more effective supervision than prior pipelines, enabling substantially better performance with less pretraining data.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02566v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02566v1">üìÑ Download PDF</a></p><hr><h3 id=leveraging-large-language-models-to-bridge-on-chain-and-off-chain-transparency-in-stablecoinshttpsarxivorgabs251202418v1><a href=https://arxiv.org/abs/2512.02418v1>Leveraging Large Language Models to Bridge On-chain and Off-chain Transparency in Stablecoins</a><a hidden class=anchor aria-hidden=true href=#leveraging-large-language-models-to-bridge-on-chain-and-off-chain-transparency-in-stablecoinshttpsarxivorgabs251202418v1>#</a></h3><p><strong>Authors:</strong> Yuexin Xiang, Yuchen Lei, SM Mahir Shazeed Rish, Yuanzhe Zhang, Qin Wang, Tsz Hon Yuen, Jiangshan Yu
<strong>Venue:</strong> arXiv (2025)</p><p>Stablecoins such as USDT and USDC aspire to peg stability by coupling issuance controls with reserve attestations. In practice, however, the transparency is split across two worlds: verifiable on-chain traces and off-chain disclosures locked in unstructured text that are unconnected. We introduce a large language model (LLM)-based automated framework that bridges these two dimensions by aligning on-chain issuance data with off-chain disclosure statements. First, we propose an integrative framework using LLMs to capture and analyze on- and off-chain data through document parsing and semantic alignment, extracting key financial indicators from issuer attestations and mapping them to corresponding on-chain metrics. Second, we integrate multi-chain issuance records and disclosure documents within a model context protocol (MCP) framework that standardizes LLMs access to both quantitative market data and qualitative disclosure narratives. This framework enables unified retrieval and contextual alignment across heterogeneous stablecoin information sources and facilitates consistent analysis. Third, we demonstrate the capability of LLMs to operate across heterogeneous data modalities in blockchain analytics, quantifying discrepancies between reported and observed circulation and examining their implications for cross-chain transparency and price dynamics. Our findings reveal systematic gaps between disclosed and verifiable data, showing that LLM-assisted analysis enhances cross-modal transparency and supports automated, data-driven auditing in decentralized finance (DeFi).</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02418v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02418v1">üìÑ Download PDF</a></p><hr><h3 id=taleframe-an-interactive-story-generation-system-with-fine-grained-control-and-large-language-modelshttpsarxivorgabs251202402v1><a href=https://arxiv.org/abs/2512.02402v1>TaleFrame: An Interactive Story Generation System with Fine-Grained Control and Large Language Models</a><a hidden class=anchor aria-hidden=true href=#taleframe-an-interactive-story-generation-system-with-fine-grained-control-and-large-language-modelshttpsarxivorgabs251202402v1>#</a></h3><p><strong>Authors:</strong> Yunchao Wang, Guodao Sun, Zihang Fu, Zhehao Liu, Kaixing Du, Haidong Gao, Ronghua Liang
<strong>Venue:</strong> arXiv (2025)</p><p>With the advancement of natural language generation (NLG) technologies, creative story generation systems have gained increasing attention. However, current systems often fail to accurately translate user intent into satisfactory story outputs due to a lack of fine-grained control and unclear input specifications, limiting their applicability. To address this, we propose TaleFrame, a system that combines large language models (LLMs) with human-computer interaction (HCI) to generate stories through structured information, enabling precise control over the generation process. The innovation of TaleFrame lies in decomposing the story structure into four basic units: entities, events, relationships, and story outline. We leverage the Tinystories dataset, parsing and constructing a preference dataset consisting of 9,851 JSON-formatted entries, which is then used to fine-tune a local Llama model. By employing this JSON2Story approach, structured data is transformed into coherent stories. TaleFrame also offers an intuitive interface that supports users in creating and editing entities and events and generates stories through the structured framework. Users can control these units through simple interactions (e.g., drag-and-drop, attach, and connect), thus influencing the details and progression of the story. The generated stories can be evaluated across seven dimensions (e.g., creativity, structural integrity), with the system providing suggestions for refinement based on these evaluations. Users can iteratively adjust the story until a satisfactory result is achieved. Finally, we conduct quantitative evaluation and user studies that demonstrate the usefulness of TaleFrame. Dataset available at <a href=https://huggingface.co/datasets/guodaosun/tale-frame>https://huggingface.co/datasets/guodaosun/tale-frame</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02402v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02402v1">üìÑ Download PDF</a></p><hr><h3 id=a-knowledge-based-language-model-deducing-grammatical-knowledge-in-a-multi-agent-language-acquisition-simulationhttpsarxivorgabs251202195v1><a href=https://arxiv.org/abs/2512.02195v1>A Knowledge-Based Language Model: Deducing Grammatical Knowledge in a Multi-Agent Language Acquisition Simulation</a><a hidden class=anchor aria-hidden=true href=#a-knowledge-based-language-model-deducing-grammatical-knowledge-in-a-multi-agent-language-acquisition-simulationhttpsarxivorgabs251202195v1>#</a></h3><p><strong>Authors:</strong> David Ph. Shakouri, Crit Cremers, Niels O. Schiller
<strong>Venue:</strong> arXiv (2025)</p><p>This paper presents an initial study performed by the MODOMA system. The MODOMA is a computational multi-agent laboratory environment for unsupervised language acquisition experiments such that acquisition is based on the interaction between two language models, an adult and a child agent. Although this framework employs statistical as well as rule-based procedures, the result of language acquisition is a knowledge-based language model, which can be used to generate and parse new utterances of the target language. This system is fully parametrized and researchers can control all aspects of the experiments while the results of language acquisition, that is, the acquired grammatical knowledge, are explicitly represented and can be consulted. Thus, this system introduces novel possibilities for conducting computational language acquisition experiments. The experiments presented by this paper demonstrate that functional and content categories can be acquired and represented by the daughter agent based on training and test data containing different amounts of exemplars generated by the adult agent. Interestingly, similar patterns, which are well-established for human-generated data, are also found for these machine-generated data. As the procedures resulted in the successful acquisition of discrete grammatical categories by the child agent, these experiments substantiate the validity of the MODOMA approach to modelling language acquisition.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02195v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02195v1">üìÑ Download PDF</a></p><hr><h3 id=trivia-self-supervised-fine-tuning-of-vision-language-models-for-table-recognitionhttpsarxivorgabs251201248v1><a href=https://arxiv.org/abs/2512.01248v1>TRivia: Self-supervised Fine-tuning of Vision-Language Models for Table Recognition</a><a hidden class=anchor aria-hidden=true href=#trivia-self-supervised-fine-tuning-of-vision-language-models-for-table-recognitionhttpsarxivorgabs251201248v1>#</a></h3><p><strong>Authors:</strong> Junyuan Zhang, Bin Wang, Qintong Zhang, Fan Wu, Zichen Wen, Jialin Lu, Junjie Shan, Ziqi Zhao, Shuya Yang, Ziling Wang, Ziyang Miao, Huaping Zhong, Yuhang Zang, Xiaoyi Dong, Ka-Ho Chow, Conghui He
<strong>Venue:</strong> arXiv (2025)</p><p>Table recognition (TR) aims to transform table images into semi-structured representations such as HTML or Markdown. As a core component of document parsing, TR has long relied on supervised learning, with recent efforts dominated by fine-tuning vision-language models (VLMs) using labeled data. While VLMs have brought TR to the next level, pushing performance further demands large-scale labeled data that is costly to obtain. Consequently, although proprietary models have continuously pushed the performance boundary, open-source models, often trained with limited resources and, in practice, the only viable option for many due to privacy regulations, still lag far behind. To bridge this gap, we introduce TRivia, a self-supervised fine-tuning method that enables pretrained VLMs to learn TR directly from unlabeled table images in the wild. Built upon Group Relative Policy Optimization, TRivia automatically identifies unlabeled samples that most effectively facilitate learning and eliminates the need for human annotations through a question-answering-based reward mechanism. An attention-guided module generates diverse questions for each table image, and the ability to interpret the recognition results and answer them correctly provides feedback to optimize the TR model. This closed-loop process allows the TR model to autonomously learn to recognize, structure, and reason over tables without labeled data. Leveraging this pipeline, we present TRivia-3B, an open-sourced, compact, and state-of-the-art TR model that surpasses existing systems (e.g., Gemini 2.5 Pro, MinerU2.5) on three popular benchmarks. Model and code are released at: <a href=https://github.com/opendatalab/TRivia>https://github.com/opendatalab/TRivia</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01248v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01248v1">üìÑ Download PDF</a></p><hr><h3 id=neural-variable-name-repair-learning-to-rename-identifiers-for-readabilityhttpsarxivorgabs251201141v1><a href=https://arxiv.org/abs/2512.01141v1>Neural Variable Name Repair: Learning to Rename Identifiers for Readability</a><a hidden class=anchor aria-hidden=true href=#neural-variable-name-repair-learning-to-rename-identifiers-for-readabilityhttpsarxivorgabs251201141v1>#</a></h3><p><strong>Authors:</strong> Muhammad Yousuf, Akshat Bagade, Chhittebbayi Penugonda, Maanas Baraya
<strong>Venue:</strong> arXiv (2025)</p><p>Developers routinely work with source files whose variable names are generic or misleading, and with teams moving quickly, many functions are left undocumented. This slows comprehension, increases the risk of subtle bugs, and makes it harder for both humans and large language models (LLMs) to reason about code. We study variable name repair: given a real C++ function where all occurrences of one local or parameter name have been replaced by a placeholder (e.g. ID 1), the goal is to generate a natural, descriptive replacement name. We automatically construct this task from the C++ portion of BigCode&rsquo;s The Stack by parsing functions with Tree-sitter, masking a single identifier, and treating the original name as supervision. On top of Llama 3.1-8B, we build a pipeline with (i) warmup and dropout schedules for more stable fine-tuning, (ii) LoRA adapters for efficient specialization on identifier repair, and (iii) a dual-encoder reranker over top-k generator candidates. We evaluate using exact match, Top-5 Hit, and an embedding-based partial similarity score (0-100) that gives credit for near synonyms and format variants (e.g., jsonValue vs. json). On a held-out set of 200 C++ functions, a zero-shot Llama 3.1 baseline reaches 6.1 percent exact match. Our best LoRA-tuned model (with warmup and dropout) achieves 43.1 percent exact match, 50.2 percent Top-5 Hit, and an 82.03 partial-match score. A dual encoder reranker further improves selection quality without modifying the underlying generator, suggesting that task-specific fine-tuning plus reranking is a promising approach for practical identifier repair tools.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01141v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01141v1">üìÑ Download PDF</a></p><hr><h3 id=sceneprop-combining-neural-network-and-markov-random-field-for-scene-graph-groundinghttpsarxivorgabs251200936v1><a href=https://arxiv.org/abs/2512.00936v1>SceneProp: Combining Neural Network and Markov Random Field for Scene-Graph Grounding</a><a hidden class=anchor aria-hidden=true href=#sceneprop-combining-neural-network-and-markov-random-field-for-scene-graph-groundinghttpsarxivorgabs251200936v1>#</a></h3><p><strong>Authors:</strong> Keita Otani, Tatsuya Harada
<strong>Venue:</strong> arXiv (2025)</p><p>Grounding complex, compositional visual queries with multiple objects and relationships is a fundamental challenge for vision-language models. While standard phrase grounding methods excel at localizing single objects, they lack the structural inductive bias to parse intricate relational descriptions, often failing as queries become more descriptive. To address this structural deficit, we focus on scene-graph grounding, a powerful but less-explored formulation where the query is an explicit graph of objects and their relationships. However, existing methods for this task also struggle, paradoxically showing decreased performance as the query graph grows &ndash; failing to leverage the very information that should make grounding easier. We introduce SceneProp, a novel method that resolves this issue by reformulating scene-graph grounding as a Maximum a Posteriori (MAP) inference problem in a Markov Random Field (MRF). By performing global inference over the entire query graph, SceneProp finds the optimal assignment of image regions to nodes that jointly satisfies all constraints. This is achieved within an end-to-end framework via a differentiable implementation of the Belief Propagation algorithm. Experiments on four benchmarks show that our dedicated focus on the scene-graph grounding formulation allows SceneProp to significantly outperform prior work. Critically, its accuracy consistently improves with the size and complexity of the query graph, demonstrating for the first time that more relational context can, and should, lead to better grounding. Codes are available at <a href=https://github.com/keitaotani/SceneProp>https://github.com/keitaotani/SceneProp</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00936v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00936v1">üìÑ Download PDF</a></p><hr><h3 id=a-taxonomy-of-errors-in-english-as-she-is-spoke-toward-an-ai-based-method-of-error-analysis-for-efl-writing-instructionhttpsarxivorgabs251200392v1><a href=https://arxiv.org/abs/2512.00392v1>A Taxonomy of Errors in English as she is spoke: Toward an AI-Based Method of Error Analysis for EFL Writing Instruction</a><a hidden class=anchor aria-hidden=true href=#a-taxonomy-of-errors-in-english-as-she-is-spoke-toward-an-ai-based-method-of-error-analysis-for-efl-writing-instructionhttpsarxivorgabs251200392v1>#</a></h3><p><strong>Authors:</strong> Damian Heywood, Joseph Andrew Carrier, Kyu-Hong Hwang
<strong>Venue:</strong> arXiv (2025)</p><p>This study describes the development of an AI-assisted error analysis system designed to identify, categorize, and correct writing errors in English. Utilizing Large Language Models (LLMs) like Claude 3.5 Sonnet and DeepSeek R1, the system employs a detailed taxonomy grounded in linguistic theories from Corder (1967), Richards (1971), and James (1998). Errors are classified at both word and sentence levels, covering spelling, grammar, and punctuation. Implemented through Python-coded API calls, the system provides granular feedback beyond traditional rubric-based assessments. Initial testing on isolated errors refined the taxonomy, addressing challenges like overlapping categories. Final testing used &ldquo;English as she is spoke&rdquo; by Jose da Fonseca (1855), a text rich with authentic linguistic errors, to evaluate the system&rsquo;s capacity for handling complex, multi-layered analysis. The AI successfully identified diverse error types but showed limitations in contextual understanding and occasionally generated new error categories when encountering uncoded errors. This research demonstrates AI&rsquo;s potential to transform EFL instruction by automating detailed error analysis and feedback. While promising, further development is needed to improve contextual accuracy and expand the taxonomy to stylistic and discourse-level errors.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00392v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00392v1">üìÑ Download PDF</a></p><hr><h3 id=tree-matching-networks-for-natural-language-inference-parameter-efficient-semantic-understanding-via-dependency-parse-treeshttpsarxivorgabs251200204v1><a href=https://arxiv.org/abs/2512.00204v1>Tree Matching Networks for Natural Language Inference: Parameter-Efficient Semantic Understanding via Dependency Parse Trees</a><a hidden class=anchor aria-hidden=true href=#tree-matching-networks-for-natural-language-inference-parameter-efficient-semantic-understanding-via-dependency-parse-treeshttpsarxivorgabs251200204v1>#</a></h3><p><strong>Authors:</strong> Jason Lunder
<strong>Venue:</strong> arXiv (2025)</p><p>In creating sentence embeddings for Natural Language Inference (NLI) tasks, using transformer-based models like BERT leads to high accuracy, but require hundreds of millions of parameters. These models take in sentences as a sequence of tokens, and learn to encode the meaning of the sequence into embeddings such that those embeddings can be used reliably for NLI tasks. Essentially, every word is considered against every other word in the sequence, and the transformer model is able to determine the relationships between them, entirely from scratch. However, a model that accepts explicit linguistic structures like dependency parse trees may be able to leverage prior encoded information about these relationships, without having to learn them from scratch, thus improving learning efficiency. To investigate this, we adapt Graph Matching Networks (GMN) to operate on dependency parse trees, creating Tree Matching Networks (TMN). We compare TMN to a BERT based model on the SNLI entailment task and on the SemEval similarity task. TMN is able to achieve significantly better results with a significantly reduced memory footprint and much less training time than the BERT based model on the SNLI task, while both models struggled to preform well on the SemEval. Explicit structural representations significantly outperform sequence-based models at comparable scales, but current aggregation methods limit scalability. We propose multi-headed attention aggregation to address this limitation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00204v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00204v1">üìÑ Download PDF</a></p><hr><h3 id=multimode-rf-reflectometry-for-spin-qubit-readout-and-device-characterizationhttpsarxivorgabs251205087v1><a href=https://arxiv.org/abs/2512.05087v1>Multimode RF Reflectometry for Spin Qubit Readout and Device Characterization</a><a hidden class=anchor aria-hidden=true href=#multimode-rf-reflectometry-for-spin-qubit-readout-and-device-characterizationhttpsarxivorgabs251205087v1>#</a></h3><p><strong>Authors:</strong> Joffrey Rivard, Alexis Morel, Olivier Romain, El Bachir Ndiaye, Idris Aboubakari, Christian Lupien, Cl√©ment Godfrin, Julien Jussot, Stefan Kubicek, Kristiaan De Greve, Danny Wan, Claude Rohrbacher, Eva Dupont-Ferrier
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce a multimode superconducting inductor architecture that enables radio-frequency reflectometry at multiple discrete frequencies up to 2 GHz, addressing limitations of conventional single-mode designs. The spiral inductor&rsquo;s distributed inter-turn capacitance yields distinct resonant modes with varied impedance-matching conditions. By probing a quantum dot across several modes, we extract tunneling rates over a broad frequency range and identify signatures of nearby charge defects. Using one of the higher-order modes, we demonstrate single-shot spin readout via a radio-frequency single-electron transistor (RF-SET), achieving singlet-triplet readout with an integration time of 8 us and a readout fidelity of 98%. These results establish multimode inductance as a scalable and flexible component for fast spin-qubit readout and device-quality characterization.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05087v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05087v1">üìÑ Download PDF</a></p><hr><h3 id=first-observation-and-measurement-of-the-198texthg-bosonic-transition-in-an-optical-lattice-clockhttpsarxivorgabs251204920v1><a href=https://arxiv.org/abs/2512.04920v1>First observation and measurement of the ${}^{198}\text{Hg}$ bosonic transition in an optical lattice clock</a><a hidden class=anchor aria-hidden=true href=#first-observation-and-measurement-of-the-198texthg-bosonic-transition-in-an-optical-lattice-clockhttpsarxivorgabs251204920v1>#</a></h3><p><strong>Authors:</strong> Clara Zyskind, Thomas Laupr√™tre, Haosen Shang, Benjamin Pointard, Rodolphe Le Targat, J√©r√¥me Lodewyck
<strong>Venue:</strong> arXiv (2025)</p><p>We report the first observation of the magnetic-field-induced (5d10 6s2)1S0-(5d10 6s6p)3P0 transition in a bosonic isotope of mercury, 198Hg, realized in an optical lattice clock. We characterize this new isotope, determining key features such as the quadratic Zeeman shift, the probe light shift, and the magic frequency. We also report a first comparison between the 198Hg optical lattice clock and 87Sr. In this comparison, the 198Hg clock has a relative frequency stability of 6x10-16/sqrt(tau/s) and a total relative systematic uncertainty of 6.9x10-16. This comparison yields the first direct determination of the 198Hg/87Sr optical frequency ratio: 198Hg/87Sr = 2.629 315 734 684 118 1, with the same relative uncertainty.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04920v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04920v1">üìÑ Download PDF</a></p><hr><h3 id=searching-for-new-physics-with-136xe-double-beta-decay-spectrum-in-pandax-4thttpsarxivorgabs251204849v1><a href=https://arxiv.org/abs/2512.04849v1>Searching for new physics with $^{136}$Xe double beta decay spectrum in PandaX-4T</a><a hidden class=anchor aria-hidden=true href=#searching-for-new-physics-with-136xe-double-beta-decay-spectrum-in-pandax-4thttpsarxivorgabs251204849v1>#</a></h3><p><strong>Authors:</strong> PandaX Collaboration, Zhe Yuan, Zihao Bo, Wei Chen, Xun Chen, Yunhua Chen, Chen Cheng, Xiangyi Cui, Manna Deng, Yingjie Fan, Deqing Fang, Xuanye Fu, Zhixing Gao, Yujie Ge, Lisheng Geng, Karl Giboni, Xunan Guo, Xuyuan Guo, Zichao Guo, Chencheng Han, Ke Han, Changda He, Jinrong He, Houqi Huang, Junting Huang, Yule Huang, Ruquan Hou, Xiangdong Ji, Yonglin Ju, Xiaorun Lan, Chenxiang Li, Jiafu Li, Mingchuan Li, Peiyuan Li, Shuaijie Li, Tao Li, Yangdong Li, Zhiyuan Li, Qing Lin, Jianglai Liu, Yuanchun Liu, Congcong Lu, Xiaoying Lu, Lingyin Luo, Yunyang Luo, Yugang Ma, Yajun Mao, Yue Meng, Binyu Pang, Ningchun Qi, Zhicheng Qian, Xiangxiang Ren, Dong Shan, Xiaofeng Shang, Xiyuan Shao, Guofang Shen, Manbin Shen, Wenliang Sun, Xuyan Sun, Yi Tao, Yueqiang Tian, Yuxin Tian, Anqing Wang, Guanbo Wang, Hao Wang, Haoyu Wang, Jiamin Wang, Lei Wang, Meng Wang, Qiuhong Wang, Shaobo Wang, Shibo Wang, Siguang Wang, Wei Wang, Xu Wang, Zhou Wang, Yuehuan Wei, Weihao Wu, Yuan Wu, Mengjiao Xiao, Xiang Xiao, Kaizhi Xiong, Jianqin Xu, Yifan Xu, Shunyu Yao, Binbin Yan, Xiyu Yan, Yong Yang, Peihua Ye, Chunxu Yu, Ying Yuan, Youhui Yun, Xinning Zeng, Minzhen Zhang, Peng Zhang, Shibo Zhang, Siyuan Zhang, Shu Zhang, Tao Zhang, Wei Zhang, Yang Zhang, Yingxin Zhang, Yuanyuan Zhang, Li Zhao, Kangkang Zhao, Jifang Zhou, Jiaxu Zhou, Jiayi Zhou, Ning Zhou, Xiaopeng Zhou, Zhizhen Zhou, Chenhui Zhu
<strong>Venue:</strong> arXiv (2025)</p><p>The continuous spectrum of double beta decay ($Œ≤Œ≤$) provides a sensitive probe to test the predictions of the Standard Model and to search for signatures of new physics beyond it. We present a comprehensive analysis of the $^{136}$Xe $Œ≤Œ≤$ spectrum utilizing $37.8 \pm 0.6$ kg$\cdot$yr of $^{136}$Xe exposure from the PandaX-4T experiment. The analysis yields the most precise measurement to date of the $^{136}$Xe two-neutrino double beta decay ($2ŒΩŒ≤Œ≤$) half-life, $(2.14 \pm 0.05) \times 10^{21}$ years, the uncertainty of which is reduced by a factor of two compared to our previous result. We measure the parameter $Œæ_{31}^{2ŒΩ}$, defined as the ratio between the subleading and leading components of the $^{136}$Xe $2ŒΩŒ≤Œ≤$ nuclear matrix element, to be $0.59^{+0.41}_{-0.38}$, which is consistent with theoretical predictions. We also search for Majoron-emitting modes of $^{136}$Xe $Œ≤Œ≤$, establishing the most stringent limit for the spectral index $n=7$.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04849v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04849v1">üìÑ Download PDF</a></p><hr><h3 id=spaceflight-kid-readout-electronics-for-primahttpsarxivorgabs251204816v1><a href=https://arxiv.org/abs/2512.04816v1>Spaceflight KID Readout Electronics for PRIMA</a><a hidden class=anchor aria-hidden=true href=#spaceflight-kid-readout-electronics-for-primahttpsarxivorgabs251204816v1>#</a></h3><p><strong>Authors:</strong> Thomas Essinger-Hileman, C. Matt Bradford, Patrick Brown, Sean Bryan, Jesse Coldsmith, Jennifer Corekin, Sumit Dahal, Thomas Devlin, Marc Foote, Draisy Friedman, Alessandro Geist, Jason Glenn, Christopher Green, Tracee Jamison-Hooks, Kevin Horgan, Jared Lucey, Philip Mauskopf, Lynn Miles, Sanetra Bailey Newman, Gerard Quilligan, Cody Roberson, Adrian Sinclair, Salman Sheikh, Eric Weeks, Christopher Wilson, Travis Wise
<strong>Venue:</strong> arXiv (2025)</p><p>We present the design and testing of a prototype multiplexing kinetic inductance detector (KID) readout electronics for the PRobe far-Infrared Mission for Astrophysics (PRIMA) space mission. PRIMA is a Probe-class astrophysics mission concept that will answer fundamental questions about the formation of planetary systems, the co-evolution of stars and supermassive black holes in galaxies, and the rise of heavy elements and dust over cosmic time. The readout electronics for PRIMA must be compatible with operation at Earth-Sun L2 and capable of multiplexing more than 1000 detectors over 2.5 GHz bandwidth while consuming around 30 W per readout chain. The electronics must also be capable of switching between the two instruments, which have different readout bands: the hyperspectral imager (PRIMAger, 2.6-4.9 GHz) and the spectrometer (FIRESS, 0.4-2.4 GHz). The PRIMA readout electronics use high-heritage SpaceCube digital electronics with a build-to-print SpaceCube Mini v3.0 board using a radiation-tolerant Kintex KU060 field programmable gate array (FPGA) and a custom high-speed digitizer board, along with RF electronics that provide filtering and power conditioning. We present the driving requirements for the system, as well as the hardware, firmware, software, and system-level design that meets those requirements.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04816v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04816v1">üìÑ Download PDF</a></p><hr><h3 id=inspiraling-binary-charged-black-holes-in-an-external-magnetic-field-application-of-post-newtonian-dynamics-in-einstein-maxwell-theoryhttpsarxivorgabs251204806v1><a href=https://arxiv.org/abs/2512.04806v1>Inspiraling binary charged black holes in an external magnetic field: Application of post-Newtonian dynamics in Einstein-Maxwell theory</a><a hidden class=anchor aria-hidden=true href=#inspiraling-binary-charged-black-holes-in-an-external-magnetic-field-application-of-post-newtonian-dynamics-in-einstein-maxwell-theoryhttpsarxivorgabs251204806v1>#</a></h3><p><strong>Authors:</strong> RunDong Tang, Lang Liu, Wen-Biao Han
<strong>Venue:</strong> arXiv (2025)</p><p>We present a systematic post-Newtonian treatment of binary charged black holes immersed in external magnetic fields within the framework of Einstein-Maxwell theory. By incorporating a uniform external magnetic field into the two-body Lagrangian expanded to first post-Newtonian order, we derive the complete equations of motion that capture both gravitational and electromagnetic interactions. The magnetic Lorentz force fundamentally alters the orbital dynamics, breaking the conservation of linear and angular momentum and inducing transitions from planar to three-dimensional trajectories. Through numerical integration of these equations, we compute the resulting gravitational waveforms and quantify the magnetic field imprints using matched filtering techniques. Our results demonstrate that strong background magnetic fields can substantially modify the orbital evolution and leave distinctive signatures in the gravitational wave signals. These findings provide a promising avenue for detecting charged black holes and probing magnetic field environments through gravitational wave observations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04806v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04806v1">üìÑ Download PDF</a></p><hr><h3 id=on-the-magnetic-field-evolution-of-interplanetary-coronal-mass-ejections-from-007-to-54-auhttpsarxivorgabs251204730v1><a href=https://arxiv.org/abs/2512.04730v1>On the magnetic field evolution of interplanetary coronal mass ejections from 0.07 to 5.4 au</a><a hidden class=anchor aria-hidden=true href=#on-the-magnetic-field-evolution-of-interplanetary-coronal-mass-ejections-from-007-to-54-auhttpsarxivorgabs251204730v1>#</a></h3><p><strong>Authors:</strong> Christian M√∂stl, Emma E. Davies, Eva Weiler, Ute V. Amerstorfer, Andreas J. Weiss, Hannah T. R√ºdisser, Martin A. Reiss, Satabdwa Majumdar, Timothy S. Horbury, Stuart D. Bale, Daniel Heyner
<strong>Venue:</strong> arXiv (2025)</p><p>A central question for understanding interplanetary coronal mass ejection (ICME) physics and improving space weather forecasting is how ICMEs evolve in interplanetary space. We have updated one of the most comprehensive in situ ICME catalogs to date, which now includes 1976 events from 11 space missions covering over 34 years, from December 1990 to August 2025. We have combined existing catalogs including magnetic obstacles and identified and added boundaries of an additional 807 (40.8%) events ourselves. With this catalog, we demonstrate the most extensive analysis to date of total ICME magnetic field values as a function of heliocentric distance. Parker Solar Probe has observed 6 ICMEs at $&lt; 0.23$ au (until April 2025), and Solar Orbiter and BepiColombo have added more events near 0.3~au, bridging the major observational gap towards the solar corona. Our main result is that a single power law can describe the evolution of the mean total magnetic field (exponent value of $k=-1.57$) and maximum field ($k=-1.53$) in the magnetic obstacle (MO), from 0.07 to 5.4 au. Extending the power law to the solar photosphere reveals a strong inconsistency with magnetic field magnitudes observed in the quiet Sun and active regions by 2 and 4 orders of magnitude, respectively. We introduce a multipole-type power law with two exponents, $k_1=-1.57$, and $k_2=-6$, relating the ICME magnetic field magnitude to an average solar active region field strength. These results present important observational constraints for the evolution of ICMEs from the Sun to the heliosphere.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04730v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04730v1">üìÑ Download PDF</a></p><hr><h3 id=cross-task-benchmarking-and-evaluation-of-general-purpose-and-code-specific-large-language-modelshttpsarxivorgabs251204673v1><a href=https://arxiv.org/abs/2512.04673v1>Cross-Task Benchmarking and Evaluation of General-Purpose and Code-Specific Large Language Models</a><a hidden class=anchor aria-hidden=true href=#cross-task-benchmarking-and-evaluation-of-general-purpose-and-code-specific-large-language-modelshttpsarxivorgabs251204673v1>#</a></h3><p><strong>Authors:</strong> Gunjan Das, Paheli Bhattacharya, Rishabh Gupta
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Models (LLMs) have revolutionized both general natural language processing and domain-specific applications such as code synthesis, legal reasoning, and finance. However, while prior studies have explored individual model capabilities, a systematic cross-domain comparison that unifies linguistic, reasoning, and code understanding abilities remains underexplored. In this work, we present a comprehensive evaluation of five general-purpose and three code-specific state-of-the-art LLMs across six diverse benchmarks encompassing linguistic competence, mathematical reasoning, and trustworthiness. Additionally, we analyze model behavior on the CoNaLa dataset for code explanation, comparing natural language and code-specialized LLMs. Our findings reveal that models optimized for code (e.g., CodeLLaMA variants) exhibit strong reasoning and syntactic precision, that even for non-coding tasks can show measurable performance gains, in contrast to general-purpose models like Mistral-7B and Llama-3-8B.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04673v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04673v1">üìÑ Download PDF</a></p><hr><h3 id=characterizing-the-low-mass-pre-main-sequence-population-in-the-low-metallicity-star-forming-region-dolidze-25-using-vlt-musehttpsarxivorgabs251204645v1><a href=https://arxiv.org/abs/2512.04645v1>Characterizing the Low-Mass Pre-Main-Sequence Population in the Low-Metallicity Star-Forming Region Dolidze 25 Using VLT-MUSE</a><a hidden class=anchor aria-hidden=true href=#characterizing-the-low-mass-pre-main-sequence-population-in-the-low-metallicity-star-forming-region-dolidze-25-using-vlt-musehttpsarxivorgabs251204645v1>#</a></h3><p><strong>Authors:</strong> Mizna Ashraf, Jessy Jose, Gregory J. Herczeg, Min Fang, Varsha Ramachandran, Carlo F. Manara, Christian Schneider, Megan Reiter, Kiran Kumar Sunil
<strong>Venue:</strong> arXiv (2025)</p><p>The metallicity of the star-forming environment is a fundamental parameter shaping the evolution of protoplanetary disks and the formation of planetary systems, yet its influence remains poorly constrained. We present a spectroscopic study of low-mass pre-main sequence (PMS) stars ($M &lt; 1 , M_\odot$) in the exceptionally metal-poor cluster Dolidze~25 ($Z \approx 0.2 , Z_\odot$), using VLT/MUSE observations to probe accretion processes and disk evolution in a subsolar environment. We identify 132 cluster members using a combination of \textit{Gaia} astrometry and spectroscopic youth indicators, including lithium absorption and Balmer emission. The stellar parameters are derived using low-metallicity BT-Settl models yielding effective temperatures, extinctions, luminosities enabling robust estimates of stellar masses and ages. Mass accretion rates ($\dot{M}<em>\mathrm{acc}$) derived from H$Œ±$ emission span $10^{-10}$&ndash;$10^{-8} , M</em>\odot,\mathrm{yr}^{-1}$ with a median value of (8 \times 10^{-10},M_\odot,\mathrm{yr}^{-1}). These rates are comparable to those in solar-metallicity regions of similar age, such as Lupus and Orion, indicating minimal metallicity dependence in accretion processes. Our analysis shows that using solar-metallicity templates to fit low-metallicity stars leads to systematic overestimations of (T_\mathrm{eff}) (by approximately (300,\mathrm{K})) and (A_V) (by around (0.5,\mathrm{mag})), underscoring the importance of employing metallicity-matched models for reliable characterization in low-(Z) environments. We present flux-calibrated, extinction-corrected spectra of these metal-poor PMS stars as a valuable resource for future investigations of disk evolution in subsolar regimes.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04645v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04645v1">üìÑ Download PDF</a></p><hr><h3 id=probing-false-vacuum-decay-and-bubble-nucleation-in-a-rydberg-atom-arrayhttpsarxivorgabs251204637v1><a href=https://arxiv.org/abs/2512.04637v1>Probing false vacuum decay and bubble nucleation in a Rydberg atom array</a><a hidden class=anchor aria-hidden=true href=#probing-false-vacuum-decay-and-bubble-nucleation-in-a-rydberg-atom-arrayhttpsarxivorgabs251204637v1>#</a></h3><p><strong>Authors:</strong> Yu-Xin Chao, Peiyun Ge, Zhen-Xing Hua, Chen Jia, Xiao Wang, Xinhui Liang, Zongpei Yue, Rong Lu, Meng Khoon Tey, Xiao Wang, Li You
<strong>Venue:</strong> arXiv (2025)</p><p>In quantum field theory (QFT), the &ldquo;vacuum&rdquo; is not just empty space but the lowest-energy state of a quantum field. If the energy landscape has multiple local minima, the local ground states are the false vacuum (FV) which can tunnel towards the global ground state (true vacuum, TV). This process exhibits signature akin to classical supercooled gas transitions and many-body tunneling in discrete quantum systems. Here, we study the FV decay and bubble nucleation in a Rydberg atom ring. The long-range van-der-Waals interactions and individual-site addressability allow us to explore physics beyond the standard Ising model. We observe that the FV decay rate decreases exponentially with the inverse of the symmetry-breaking field, directly mirroring QFT predictions. Moreover, we demonstrate that even minor deviations from the ideal metastable state can cause a stark departure from this universal scaling law. Extending beyond short-time decay dynamics, we also examine resonant bubble nucleation, a feature distinctive to systems with discrete energy spectra. Our findings and methods open avenues for future studies of many-body tunneling in higher dimensions or more complex geometries.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04637v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04637v1">üìÑ Download PDF</a></p><hr><h3 id=ground-state-energy-and-phase-transitions-of-long-range-xxz-using-vqehttpsarxivorgabs251204615v1><a href=https://arxiv.org/abs/2512.04615v1>Ground state energy and phase transitions of Long-range XXZ using VQE</a><a hidden class=anchor aria-hidden=true href=#ground-state-energy-and-phase-transitions-of-long-range-xxz-using-vqehttpsarxivorgabs251204615v1>#</a></h3><p><strong>Authors:</strong> Mrinal Dev, Shraddha Sharma
<strong>Venue:</strong> arXiv (2025)</p><p>The variational quantum eigen solver (VQE), has been widely used to find the ground state energy of different Hamiltonians with no analytical solutions and are classically difficult to compute. In our work, we have used VQE to identify the phase transition boundary for an infinite order phase transition. We use long-range XXZ (LRXXZ) chain for our study. In order to probe infinite order phase transition, we propose to utilise the ground state energy obtained from VQE. The idea rests on the argument that VQE requires an ansatz circuit; therefore, the accuracy of the VQE will rely on this ansatz circuit. We have designed this circuit such that the estimated ground state energy is sensitive to the phase it is evaluated in. It is achieved by applying the constraint that the net spin remains constant throughout the optimisation process. Consequently, the ansatz works in a certain phase where it gives relatively small random error, as it should, when compared to the error in ground state energy calculations of the other phases, where the ansatz fails. By identifying these changes in the behaviour of the error in ground state energy using VQE, we were able to determine the phase boundaries. Using exact diagonalisation, we also compare the behaviour of the energy gradient and energy gap across both the phase transition boundaries for this model. Further, by increasing the depth of the optimisation circuit, we also accurately evaluate the ground energy of the LRXXZ chain for the value of coupling constant, J equal to -1</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04615v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04615v1">üìÑ Download PDF</a></p><hr><h3 id=probing-hard-scattering-processes-via-multiple-weak-gauge-boson-production-at-the-future-collidershttpsarxivorgabs251204553v1><a href=https://arxiv.org/abs/2512.04553v1>Probing Hard Scattering Processes via Multiple Weak Gauge Boson Production at the Future Colliders</a><a hidden class=anchor aria-hidden=true href=#probing-hard-scattering-processes-via-multiple-weak-gauge-boson-production-at-the-future-collidershttpsarxivorgabs251204553v1>#</a></h3><p><strong>Authors:</strong> Ijaz Ahmed, M. S. Amjad, Jamil Muhammad
<strong>Venue:</strong> arXiv (2025)</p><p>One of the possible ways to detect the new physics phenomena particles is to investigate the weak gauge boson production as a result of hadron-hadron scattering. This study comprises the production of multiple weak gauge bosons as a result of hard scattering between the proton-proton beams at multi-TeV energies and integrated luminosity $\mathcal L =$ 3000 $fb ^{-1}$. The effective production cross-sections for pair, triple, and quartic scattering mechanisms have been computed as a function of $\sqrt s$. The center of mass energy has been varied from 8 TeV to 100 TeV to encompass the future collider capabilities. Out of all the studied processes, the triple scattering process $W^+W^-W^+$ has been chosen as the signal process based on the dominant cross-section. The background channels ZZZ, ZZZZ, $W^-ZZ$, $W^+ZZ$, $W^+W^-Z$, $W^+W^-ZZ$, $W^+W^-W^+W^-$, having comparatively lower cross-sections, have been selected from possible scattering mechanisms to investigate the effect of higher luminosity on the low production cross-section processes. We have investigated the different decay modes. For both lepton and hadron-specific decays of W and Z, the cumulative efficiencies for each signal and background process have been computed. In this study, we have successfully demonstrated an effective methodology for background suppression by systematically optimizing the signal-to-background ratio. The results indicate that, despite lower cross-sections for higher-order scattering, the distinct kinematic features enable effective signal isolation at future colliders.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04553v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04553v1">üìÑ Download PDF</a></p><hr><h3 id=a-morpho-kinematic-study-of-galactic-high-adf-pne-based-on-the-vltuves-deep-spectroscopyhttpsarxivorgabs251204533v1><a href=https://arxiv.org/abs/2512.04533v1>A Morpho-kinematic Study of Galactic High-ADF PNe Based on the VLT/UVES Deep Spectroscopy</a><a hidden class=anchor aria-hidden=true href=#a-morpho-kinematic-study-of-galactic-high-adf-pne-based-on-the-vltuves-deep-spectroscopyhttpsarxivorgabs251204533v1>#</a></h3><p><strong>Authors:</strong> Haomiao Huang, Xuan Fang, Jorge Garcia-Rojas, Zhijun Tu, Jifeng Liu, Xiaowei Liu
<strong>Venue:</strong> arXiv (2025)</p><p>We report detailed analyses of deep, high-resolution spectra of three Galactic planetary nebulae (PNe) with high abundance discrepancy factors (ADFs), Hf2-2, M1-42 and NGC6153, obtained with the Ultraviolet and Visual Echelle Spectrograph (UVES) on the 8.2m Very Large Telescope (VLT). These spectra were carefully reduced, including rigorous absolute flux calibration, yielding detections of ~410-800 emission lines in each PN. Plasma diagnostics and abundance calculations were critically performed using nebular lines. In all three PNe, the electron temperatures derived using the collisionally excited lines (CELs) are higher than those yielded by the HI Balmer and Paschen jumps, while the temperatures yielded by the OII and NII optical recombination lines (ORLs) are very low, &lt;2000 K, indicating that the heavy-element ORLs probe cold nebular regions. The ORL abundances of N, O and Ne are systematically higher than the corresponding CEL values, confirming high ADFs in the three objects. Position-velocity (PV) diagrams were created, and spatio-kinematical studies show that CELs come from the outer nebular regions, while the ORL-emitting regions are close to nebular center. Additionally, the velocity indicated by CEL line-splitting decreases with ionization potential, which was not obvious in ORLs. These spatial and kinematic differences support two distinct components of ionized gas: a cold, metal-rich component and a warmer component with normal metallicity. Heavy elements are strongly enriched in the cold gas, while its H^+ fraction is low but still produces significant HI emission, affecting CEL abundance estimates.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04533v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04533v1">üìÑ Download PDF</a></p><hr><h3 id=sub-cycle-pulse-control-of-holographic-and-non-holographic-electron-interferenceshttpsarxivorgabs251204503v1><a href=https://arxiv.org/abs/2512.04503v1>Sub-cycle pulse control of holographic and non-holographic electron interferences</a><a hidden class=anchor aria-hidden=true href=#sub-cycle-pulse-control-of-holographic-and-non-holographic-electron-interferenceshttpsarxivorgabs251204503v1>#</a></h3><p><strong>Authors:</strong> Rambabu Rajpoot, Eiji J. Takahashi
<strong>Venue:</strong> arXiv (2025)</p><p>We investigate the influence of sub-cycle laser pulses on holographic and non-holographic intracycle interferences by analyzing the photoelectron momentum distributions of helium using TDSE simulations supported by classical trajectory calculations. The results show that the forward-scattering holographic (FSH), backward-scattering holographic (BSH), and time double-slit (TDS) structures are found to be highly sensitive to the pulse duration, carrier-envelope phase (CEP), and temporal envelope in the sub-cycle regime. Sub-cycle pulses with CEP values of $0^\circ$ and $90^\circ$ selectively enhance or suppress distinct features, isolating holographic patterns and enhancing BSH fringes. Classical analysis reveals that the intrinsic chirp inherent to sub-cycle fields shortens the recollision time for scattering trajectories, thereby increasing the fringe spacing in FSH and BSH patterns, while simultaneously enlarging the ATI peak spacing associated with TDS interference. Pulse envelope variations, even at fixed FWHM duration, further reshape the fringe spacings by modifying the instantaneous frequency and vector potential slope near ionization times. These results demonstrate that sub-cycle pulses enable precise temporal control of holographic interference, offering new opportunities for probing and manipulating attosecond electron dynamics.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04503v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04503v1">üìÑ Download PDF</a></p><hr><h3 id=predicting-time-dependent-flow-over-complex-geometries-using-operator-networkshttpsarxivorgabs251204434v1><a href=https://arxiv.org/abs/2512.04434v1>Predicting Time-Dependent Flow Over Complex Geometries Using Operator Networks</a><a hidden class=anchor aria-hidden=true href=#predicting-time-dependent-flow-over-complex-geometries-using-operator-networkshttpsarxivorgabs251204434v1>#</a></h3><p><strong>Authors:</strong> Ali Rabeh, Suresh Murugaiyan, Adarsh Krishnamurthy, Baskar Ganapathysubramanian
<strong>Venue:</strong> arXiv (2025)</p><p>Fast, geometry-generalizing surrogates for unsteady flow remain challenging. We present a time-dependent, geometry-aware Deep Operator Network that predicts velocity fields for moderate-Re flows around parametric and non-parametric shapes. The model encodes geometry via a signed distance field (SDF) trunk and flow history via a CNN branch, trained on 841 high-fidelity simulations. On held-out shapes, it attains $\sim 5%$ relative L2 single-step error and up to 1000X speedups over CFD. We provide physics-centric rollout diagnostics, including phase error at probes and divergence norms, to quantify long-horizon fidelity. These reveal accurate near-term transients but error accumulation in fine-scale wakes, most pronounced for sharp-cornered geometries. We analyze failure modes and outline practical mitigations. Code, splits, and scripts are openly released at: <a href=https://github.com/baskargroup/TimeDependent-DeepONet>https://github.com/baskargroup/TimeDependent-DeepONet</a> to support reproducibility and benchmarking.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04434v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04434v1">üìÑ Download PDF</a></p><hr><h3 id=explainable-parkinsons-disease-gait-recognition-using-multimodal-rgb-d-fusion-and-large-language-modelshttpsarxivorgabs251204425v1><a href=https://arxiv.org/abs/2512.04425v1>Explainable Parkinsons Disease Gait Recognition Using Multimodal RGB-D Fusion and Large Language Models</a><a hidden class=anchor aria-hidden=true href=#explainable-parkinsons-disease-gait-recognition-using-multimodal-rgb-d-fusion-and-large-language-modelshttpsarxivorgabs251204425v1>#</a></h3><p><strong>Authors:</strong> Manar Alnaasan, Md Selim Sarowar, Sungho Kim
<strong>Venue:</strong> arXiv (2025)</p><p>Accurate and interpretable gait analysis plays a crucial role in the early detection of Parkinsons disease (PD),yet most existing approaches remain limited by single-modality inputs, low robustness, and a lack of clinical transparency. This paper presents an explainable multimodal framework that integrates RGB and Depth (RGB-D) data to recognize Parkinsonian gait patterns under realistic conditions. The proposed system employs dual YOLOv11-based encoders for modality-specific feature extraction, followed by a Multi-Scale Local-Global Extraction (MLGE) module and a Cross-Spatial Neck Fusion mechanism to enhance spatial-temporal representation. This design captures both fine-grained limb motion (e.g., reduced arm swing) and overall gait dynamics (e.g., short stride or turning difficulty), even in challenging scenarios such as low lighting or occlusion caused by clothing. To ensure interpretability, a frozen Large Language Model (LLM) is incorporated to translate fused visual embeddings and structured metadata into clinically meaningful textual explanations. Experimental evaluations on multimodal gait datasets demonstrate that the proposed RGB-D fusion framework achieves higher recognition accuracy, improved robustness to environmental variations, and clear visual-linguistic reasoning compared with single-input baselines. By combining multimodal feature learning with language-based interpretability, this study bridges the gap between visual recognition and clinical understanding, offering a novel vision-language paradigm for reliable and explainable Parkinsons disease gait analysis. Code:https://github.com/manaralnaasan/RGB-D_parkinson-LLM</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04425v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04425v1">üìÑ Download PDF</a></p><hr><h3 id=an-analysis-of-a-coronal-mass-ejection-leading-edge-by-means-of-multi-spacecraft-in-beam-phase-scintillationhttpsarxivorgabs251204337v1><a href=https://arxiv.org/abs/2512.04337v1>An Analysis of a Coronal Mass Ejection Leading Edge by Means of Multi-Spacecraft-in-Beam Phase Scintillation</a><a hidden class=anchor aria-hidden=true href=#an-analysis-of-a-coronal-mass-ejection-leading-edge-by-means-of-multi-spacecraft-in-beam-phase-scintillationhttpsarxivorgabs251204337v1>#</a></h3><p><strong>Authors:</strong> Jasper Edwards, Guifr√© Molera Calv√©s, John Morgan, Mark Cheung
<strong>Venue:</strong> arXiv (2025)</p><p>A Coronal Mass Ejection (CME) was detected crossing the radio signals transmitted by the Mars Express (MEX) and Tianwen-1 (TIW) spacecraft at a solar elongation of $4.4^{o}$. The impact of the CME was clearly identifiable in the spacecraft signal SNR, Doppler noise and phase residuals observed at the University of Tasmania&rsquo;s Very Long Baseline Interferometry (VLBI) antenna in Ceduna, South Australia. The residual phases observed from the spacecraft were highly correlated with each other during the transit of the CME across the radio ray-path despite the spacecraft signals having substantially different Doppler trends. We analyse the auto- and cross-correlations between the spacecraft phase residuals, finding time-lags ranging between 3.18-14.43 seconds depending on whether the imprinted fluctuations were stronger on the uplink or the downlink radio ray-paths. We also examine the temporal evolution of the phase fluctuations to probe the finer structure of the CME and demonstrate that there was a clear difference in the turbulence regime of the CME leading edge and the background solar wind conditions several hours prior to the CME radio occultation. Finally, autocorrelation of the MEX two-way radio Doppler noise data from Ceduna and closed-loop Doppler data from ESA&rsquo;s New Norcia ground station antenna were used to constrain the location of the CME impact along the radio ray-path \add{to a region 0.2 AU from the Sun, at a heliospheric longitude consistent with CME origin at the Sun. The results presented demonstrate the potential of the multi-spacecraft-in-beam technique for studying CME structures in great detail, and providing measurements that complement the capabilities of future solar monitoring instruments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04337v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04337v1">üìÑ Download PDF</a></p><hr><h3 id=lhc-shines-on-positivityhttpsarxivorgabs251204336v1><a href=https://arxiv.org/abs/2512.04336v1>LHC Shines on Positivity</a><a hidden class=anchor aria-hidden=true href=#lhc-shines-on-positivityhttpsarxivorgabs251204336v1>#</a></h3><p><strong>Authors:</strong> Zhen Liu, Kun-Feng Lyu, Tong Arthur Wu
<strong>Venue:</strong> arXiv (2025)</p><p>We show that hadron colliders have an excellent reach for positivity tests on a class of diphoton operators. Due to the helicity selection rules, the relevant dimension-6 operators either do not contribute or are highly constrained by other experimental observables. We show, for the first time, that the LHC can probe the positivity of the dimension-8 operators involving colored particles. The kinematic differential distributions of the diphoton final states are exploited to perform the $œá^2$ analysis. Through a global fit, the effective scale for these operators can be inclusively probed up to around 2 TeV at HL-LHC and over 5 TeV at future 100 TeV FCC-hh at 95% C.L., providing a powerful test of the positivity bounds up to multi-TeV scale.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04336v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04336v1">üìÑ Download PDF</a></p><hr><h3 id=exploring-the-qcd-phase-diagram-through-correlations-and-fluctuationshttpsarxivorgabs251204288v1><a href=https://arxiv.org/abs/2512.04288v1>Exploring the QCD phase diagram through correlations and fluctuations</a><a hidden class=anchor aria-hidden=true href=#exploring-the-qcd-phase-diagram-through-correlations-and-fluctuationshttpsarxivorgabs251204288v1>#</a></h3><p><strong>Authors:</strong> Volker Koch, Volodymyr Vovchenko
<strong>Venue:</strong> arXiv (2025)</p><p>The exploration of the Quantum Chromodynamics (QCD) phase diagram is a central goal of relativistic heavy-ion collision experiments. This review focuses on the role of fluctuations and correlations as sensitive probes of the phase structure. We discuss theoretical advancements and experimental methodologies employed to map the QCD phase diagram, highlighting constraints derived from both lattice QCD calculations and existing experimental data. Key observables such as cumulants and factorial cumulants of conserved charges (e.g., net-proton, net-charge) are explored as promising signatures of phase transitions and the QCD critical point. We discuss how these quantities are measured experimentally and compared with theoretical predictions, addressing challenges and best practices for meaningful comparisons. Special attention is given to predictions and current experimental results at high baryon density, including recent findings from the STAR collaboration at RHIC. Finally, we identify open issues and future directions for fluctuation and correlation studies at lower collision energies, relevant for future measurements, for example by the CBM experiment.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04288v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04288v1">üìÑ Download PDF</a></p><hr><h3 id=gravitational-waves-from-isocurvature-perturbations-of-spectator-scalar-fieldshttpsarxivorgabs251204240v1><a href=https://arxiv.org/abs/2512.04240v1>Gravitational Waves from Isocurvature Perturbations of Spectator Scalar Fields</a><a hidden class=anchor aria-hidden=true href=#gravitational-waves-from-isocurvature-perturbations-of-spectator-scalar-fieldshttpsarxivorgabs251204240v1>#</a></h3><p><strong>Authors:</strong> Marcos A. G. Garcia, Sarunas Verner
<strong>Venue:</strong> arXiv (2025)</p><p>We present a mechanism for gravitational wave (GW) production from isocurvature perturbations in spectator scalar fields during inflation. These energetically subdominant fields develop blue-tilted power spectra through inflationary dynamics, generating second-order scalar perturbations that source a stochastic GW background. The mechanism naturally satisfies CMB constraints at large scales while producing enhanced signals at smaller scales across a broad frequency range $10^{-20} - 1$ Hz. We perform comprehensive numerical and analytical calculations of the complete isocurvature spectrum evolution, including gravitational particle production, reheating dynamics, and scalar-induced GW generation. For spectator fields with effective masses $0.5 \lesssim m_{œá,\mathrm{eff}}/H_I$, the resulting GW energy density reaches $Œ©_{\text{GW}} h^2 \sim 10^{-20}$-$10^{-12}$, accessible to pulsar timing arrays, space-based interferometers, and next-generation CMB experiments. Our analysis reveals that GW-induced constraints exceed current isocurvature bounds. We examine both unstable (curvaton-like) and stable (dark matter) spectator fields, demonstrating strong sensitivity to reheating temperature, inflaton-spectator coupling, and decay dynamics. This framework establishes isocurvature-sourced GWs as a powerful probe of early universe physics, enabling simultaneous constraints on inflationary dynamics, dark matter production, and reheating through coordinated multi-frequency GW observations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04240v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04240v1">üìÑ Download PDF</a></p><hr><h3 id=detecting-light-axions-from-supernovae-in-nearby-galaxieshttpsarxivorgabs251204185v1><a href=https://arxiv.org/abs/2512.04185v1>Detecting light axions from supernovae in nearby galaxies</a><a hidden class=anchor aria-hidden=true href=#detecting-light-axions-from-supernovae-in-nearby-galaxieshttpsarxivorgabs251204185v1>#</a></h3><p><strong>Authors:</strong> Francesca Lecce, Alessandro Lella, Giuseppe Lucente, Maurizio Giannotti, Alessandro Mirizzi
<strong>Venue:</strong> arXiv (2025)</p><p>Axion-like particles (ALPs) coupled to nucleons can be efficiently produced in core-collapse supernovae (SNe) and then, if they couple to photons, convert into gamma rays in cosmic magnetic fields, generating short gamma-ray bursts. Though ALPs from a Galactic SN would induce an intense and easily detectable gamma-ray signal, such events are exceedingly rare. In contrast, a few SNe per year are expected in nearby galaxies within $\mathcal{O}(10)$ Mpc, where strong magnetic fields can enable more efficient ALP-photon conversions than in the Milky Way, offering a promising extragalactic target. This circumstance motivates full-sky gamma-ray monitoring, ideally combined with deci-hertz gravitational-wave detectors to enable time-triggered searches from nearby galaxies. We show that, under realistic conditions, a decade of coverage could reach sensitivities to ALP-photon coupling $g_{a Œ≥} \gtrsim 10^{-16} \rm{GeV}^{-1}$ for ALP masses $m_a \lesssim 10^{-9} $ eV and assuming an ALP-nucleon coupling close to SN 1987A cooling bound. This sensitivity would allow one to probe a large, currently-unexplored region of the parameter space below the longstanding SN 1987A bound.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04185v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04185v1">üìÑ Download PDF</a></p><hr><h3 id=electroweak-phase-transition-in-smeft-gravitational-wave-and-collider-complementarityhttpsarxivorgabs251204168v1><a href=https://arxiv.org/abs/2512.04168v1>Electroweak phase transition in SMEFT: Gravitational wave and collider complementarity</a><a hidden class=anchor aria-hidden=true href=#electroweak-phase-transition-in-smeft-gravitational-wave-and-collider-complementarityhttpsarxivorgabs251204168v1>#</a></h3><p><strong>Authors:</strong> Sahabub Jahedi, Indrajit Saha, Abhik Sarkar
<strong>Venue:</strong> arXiv (2025)</p><p>We study the electroweak first-order electroweak phase transition (FO-EWPT) within the Standard Model Effective Field Theory (SMEFT) framework induced by dimension-6 operators. Such phenomena can be probed independently via \textit{di}-Higgs production at the collider experiments as well as via the detection of gravitational waves (GW). There are three dimension-6 SMEFT operators that simultaneously modify the Higgs potential at tree level and contribute to the \textit{di}-Higgs production at the hadron colliders. With \textit{di}-Higgs production being suppressed at current LHC runs, we aim to probe this production at high luminosity (HL) and high energy (HE) runs of the LHC to achieve better sensitivity of dimension-6 SMEFT operators. The correlations among these operators are analyzed in the context of probing FO-EWPT, emphasizing the complementarity between future GW observations and upgraded LHC searches.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04168v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04168v1">üìÑ Download PDF</a></p><hr><h3 id=a-new-connection-between-wimp-dark-matter-and-the-hierarchy-problemhttpsarxivorgabs251204158v1><a href=https://arxiv.org/abs/2512.04158v1>A new connection between WIMP dark matter and the hierarchy problem</a><a hidden class=anchor aria-hidden=true href=#a-new-connection-between-wimp-dark-matter-and-the-hierarchy-problemhttpsarxivorgabs251204158v1>#</a></h3><p><strong>Authors:</strong> Maximilian Detering, Thomas Steingasser, Tevong You
<strong>Venue:</strong> arXiv (2025)</p><p>This work proposes a direct link between the hierarchy problem and Weakly Interacting Massive Particles (WIMPs): we suggest that the small mass of the Higgs boson arises from being dynamically driven to the scale of the WIMP. Such a special electroweak vacuum is singled out by lying close to the critical boundary of a phase transition, as recently explored in a new class of cosmological solutions to the hierarchy problem. They generically predict the Higgs potential to be destabilised just above the weak scale. Intriguingly, the requirement for new physics to achieve this coincides with two independently well-motivated expectations: a split spectrum of light fermions and heavy bosons, as anticipated from naturalness, and the so-called &ldquo;WIMP miracle&rdquo;. A WIMP with mass around the weak scale not only happens to have the correct thermal relic abundance to be the dark matter (DM), it can also give rise to the necessary critical boundary at the TeV scale through its Yukawa couplings to the Higgs. We use a higgsino-like singlet-doublet model to illustrate our Higgs-DM criticality scenario and show that if this WIMP DM mass is observed to be greater than ~1.2 TeV then it necessarily implies a strong bound on the Higgs mass and an upper bound on the scale of heavy new physics that restores vacuum stability. It can be thoroughly probed in direct detection experiments, astrophysical signals and future collider searches, further motivating a comprehensive exploration of the remaining heavy WIMP parameter space.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04158v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04158v1">üìÑ Download PDF</a></p><hr><h3 id=effective-delta-sources-and-newtonian-limit-in-nonlocal-gravityhttpsarxivorgabs251205061v1><a href=https://arxiv.org/abs/2512.05061v1>Effective delta sources and Newtonian limit in nonlocal gravity</a><a hidden class=anchor aria-hidden=true href=#effective-delta-sources-and-newtonian-limit-in-nonlocal-gravityhttpsarxivorgabs251205061v1>#</a></h3><p><strong>Authors:</strong> Thomas M. Sangy, Nicol√≤ Burzill√†, Breno L. Giacchini, Tib√©rio de Paula Netto
<strong>Venue:</strong> arXiv (2025)</p><p>We investigate the Newtonian limit of a class of nonlocal gravity models with exponential form factors $f_s (\Box) = \exp [(-\Box/Œº_s^2)^{N_s}]$. Our main goal is to identify similarities and differences between models in this family in regard to weak-field solutions. To this end, we use the effective source formalism to compare the related effective delta sources, mass functions, and Newtonian potentials. We obtain a variety of representations for these quantities in terms of series, integrals, and special functions, as well as simple approximations that capture the relevant dependence on the parameters $N_s$ and $Œº_s$ - which can be used to explore the weak-field phenomenology of nonlocal gravity. We explain why only for $N_s>1$ the Newtonian potential oscillates and prove that, despite the oscillations, the effective masses are positive. Moreover, we verify that these linearized solutions are regular (without curvature singularities). Finally, we also calculate the form of the leading logarithmic quantum correction to the Newtonian potential in these models. In all our considerations, we assume that $N_s$ is a positive real parameter. The cases of non-integer $N_s$ might be applied beyond nonlocal gravity, in effective approaches to implement quantum corrections in the weak field regime.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05061v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05061v1">üìÑ Download PDF</a></p><hr><h3 id=on-six-loop-scaling-dimensions-of-œÜ2n-operators-in-d3httpsarxivorgabs251205059v1><a href=https://arxiv.org/abs/2512.05059v1>On six-loop scaling dimensions of $(œÜ^2)^n$ operators in $d=3$</a><a hidden class=anchor aria-hidden=true href=#on-six-loop-scaling-dimensions-of-œÜ2n-operators-in-d3httpsarxivorgabs251205059v1>#</a></h3><p><strong>Authors:</strong> A. V. Bednyakov, M. V. Kompaniets, A. V. Trenogin
<strong>Venue:</strong> arXiv (2025)</p><p>We consider a class of singlet operators $(œÜ^2)^n$ in the three-dimensional $O(N)$ model with $Œª^2 œÜ^6$ interaction. Recently, the corresponding anomalous dimensions $Œ≥_{2n}$ were computed by semiclassical methods and the all-loop result for the leading-$n$ corrections in the small $Œª$ limit was found. In this letter, we obtain the six-loop expressions not only for the leading-$n$ contribution but also for the subleading one. While the leading correction confirms the predictions of recent semiclassical calculation, the subleading one is a new result and will serve as a future welcome check for the all-loop expressions. As an important by-product of our calculation, we provide a full dependence on $n$ of the four-loop $Œ≥_{2n}$ in the $O(N)$ case.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05059v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05059v1">üìÑ Download PDF</a></p><hr><h3 id=the-position-and-resolvability-of-blended-point-sourceshttpsarxivorgabs251205047v1><a href=https://arxiv.org/abs/2512.05047v1>The position and resolvability of blended point sources</a><a hidden class=anchor aria-hidden=true href=#the-position-and-resolvability-of-blended-point-sourceshttpsarxivorgabs251205047v1>#</a></h3><p><strong>Authors:</strong> Zephyr Penoyre
<strong>Venue:</strong> arXiv (2025)</p><p>In this work we derive analytic expressions and numerical recipes for finding the effective observed position of sources close enough on sky that their Point Spread Functions (PSF), modelled as Gaussian profiles, overlap. In particularly we derive these for an elongated PSF, with a long and short axis, such as we would see from an instrument with a rectangular or elliptical mirror (relevant, for example, for the Gaia mission). We show that in this case the problem can be reduced to a one dimensional brightness profile with extrema along the line connecting the two sources, with an effective PSF width that depends on the relative orientation of the PSF and its degree of elongation. The problem can then be expressed in units of this effective width to be a function of the relative separation and light ratio alone (thus reducing to a rescaling of the un-elongated case). We derive the minimum light ratio, for a given separation and effective width, above which two sources will be resolved. We map out numerical procedures for finding the positions of these extrema across all possible cases. Finally we derive the positional offset and deviance associated with observing a fixed pair of blended sources from a variety of orientations, showing that this can be a significant source of excess noise.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05047v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05047v1">üìÑ Download PDF</a></p><hr><h3 id=dust-destruction-by-the-supernova-remnant-forward-shock-in-a-turbulent-interstellar-mediumhttpsarxivorgabs251205046v1><a href=https://arxiv.org/abs/2512.05046v1>Dust destruction by the supernova remnant forward shock in a turbulent interstellar medium</a><a hidden class=anchor aria-hidden=true href=#dust-destruction-by-the-supernova-remnant-forward-shock-in-a-turbulent-interstellar-mediumhttpsarxivorgabs251205046v1>#</a></h3><p><strong>Authors:</strong> Tassilo Scheffler, Nina S. Sartorio, Florian Kirchschlager, Ilse De Looze, Michael J. Barlow, Franziska D. Schmidt
<strong>Venue:</strong> arXiv (2025)</p><p>Context. While supernova remnants (SNRs) are observed to produce up to 1 M$<em>\odot$ of dust, the amount of dust destroyed by the forward shock (FS) is poorly constrained, raising the question whether they are net dust producers or destroyers. Aims. We aim to estimate the dust destruction efficiency of SNR FSs in a realistically turbulent interstellar medium (ISM) during their most destructive phase, and assess dust shielding by high density filaments during this period. Methods. We run 3D turbulence simulations for different turbulent Mach numbers (0-3) and average ISM densities (1-100 cm$^{-3}$) to resemble observations of the turbulent ISM. We then set off a supernova to trace its 3D magnetohydrodynamical evolution for 10 kyr. Finally, we run post-processing simulations to study the dust transport and destruction by the SNR FS, considering gas and plasma drag, kinetic and thermal sputtering, and grain-grain collisions, and either silicate or carbonaceous dust. Results. The dust destruction rate of the FS strongly depends on the average ISM density and turbulence strength, varying between 27-92% (0.85-11.0 M$</em>\odot$) in the studied 10 kyr. Overall, dust is less efficiently destroyed in a low density medium (1 cm$^{-3}$, 27-57%) than in intermediate (10 cm$^{-3}$, 46-92%) and high densities (100 cm$^{-3}$, 73-87%). The FS destroys 8-34% less dust in high Mach turbulence compared to a homogeneous medium. Furthermore, carbonaceous grains are more robust (up to 21% more) than silicates. Conclusions. Filaments can partly shield dust from destruction in the first 10 kyr, however, always more than 0.85 M$<em>\odot$ of dust is destroyed, making most SNRs dust sinks under the conditions explored in this work. The destruction efficiency of the SNRs with less than 1 M$</em>\odot$ of destroyed dust has not yet plateaued so that they are most likely also net dust destroyers by the end of their lifetime.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05046v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05046v1">üìÑ Download PDF</a></p><hr><h3 id=analytic-dependence-of-the-lyapunov-moment-function-and-the-projective-stationary-measure-for-random-matrix-productshttpsarxivorgabs251205034v1><a href=https://arxiv.org/abs/2512.05034v1>Analytic Dependence of the Lyapunov Moment Function and the Projective Stationary Measure for Random Matrix Products</a><a hidden class=anchor aria-hidden=true href=#analytic-dependence-of-the-lyapunov-moment-function-and-the-projective-stationary-measure-for-random-matrix-productshttpsarxivorgabs251205034v1>#</a></h3><p><strong>Authors:</strong> Christopher Chalhoub, Vincent P. H. Goverse, Jeroen S. W. Lamb, Martin Rasmussen
<strong>Venue:</strong> arXiv (2025)</p><p>We consider the product of i.i.d. random matrices sampled according to a probability measure $Œº$ supported on a strongly irreducible and proximal subset of a compact set $S\subset GL(d,\mathbb{R})$. We establish the local analyticity of the Lyapunov moment function and the unique stationary measure on the projective space with respect to $Œº$ in the total variation topology. As a consequence, we obtain the analyticity of the asymptotic variance and all higher-order Lyapunov moments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05034v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05034v1">üìÑ Download PDF</a></p><hr><h3 id=frequency-and-intensity-noise-of-a-grating-tuned-external-cavity-quantum-cascade-laserhttpsarxivorgabs251205002v1><a href=https://arxiv.org/abs/2512.05002v1>Frequency and intensity noise of a grating-tuned external-cavity quantum cascade laser</a><a hidden class=anchor aria-hidden=true href=#frequency-and-intensity-noise-of-a-grating-tuned-external-cavity-quantum-cascade-laserhttpsarxivorgabs251205002v1>#</a></h3><p><strong>Authors:</strong> Irene La Penna, Tecla Gabbrielli, Cristina Rimoldi, Davide Mazzotti, J√©r√¥me Faist, Luigi Consolino, Simone Borri, Paolo De Natale, Francesco Cappelli
<strong>Venue:</strong> arXiv (2025)</p><p>Quantum cascade lasers (QCLs) are semiconductor-heterostructure devices known for their emission in the mid-infrared and THz spectral regions. Due to their operating regime, their intrinsic linewidth is significantly narrower compared to bipolar semiconductor lasers. Here, we demonstrate that by implementing an external-cavity (EC) configuration based on a commercial diffraction grating, we have successfully induced a Fabry-Perot QCL to emit on a single mode with a broadly-tunable wavelength in the range 4.29-4.44 Œºm. This very simple setup enhances the laser&rsquo;s performance in terms of threshold current and emitted power. We further prove that the EC configuration positively impacts the laser&rsquo;s noise properties. In particular, the intrinsic linewidth is substantially reduced, the full linewidth is also decreased (depending on the integration timescale), and the relative intensity noise is slightly reduced. These characteristics, which hold within the whole tuning range, make the EC-QCL a good candidate for spectroscopy applications where broad tunability and narrow linewidth are highly demanded.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05002v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05002v1">üìÑ Download PDF</a></p><hr><h3 id=partial-section-i-Œ±-recurrence-and-equivariant-lyapunov-mapshttpsarxivorgabs251204994v1><a href=https://arxiv.org/abs/2512.04994v1>Partial section I: $Œ±$-recurrence and equivariant Lyapunov maps</a><a hidden class=anchor aria-hidden=true href=#partial-section-i-Œ±-recurrence-and-equivariant-lyapunov-mapshttpsarxivorgabs251204994v1>#</a></h3><p><strong>Authors:</strong> Th√©o Marty
<strong>Venue:</strong> arXiv (2025)</p><p>This is the first article in a series that aims at classifying partial sections of flows, that is a general family of transverse surfaces. In this part, we deal with the dynamical aspect of the question.
Given a flow on a compact manifold $M$ and a cohomology class $Œ±$ of rank 1, we give a criterion for the existence of an $Œ±$-equivariant Lyapunov map on an Abelian covering of $M$ associated to $Œ±$.
One important aspect of the existence of such Lyapunov maps, and of the classification of partial sections, is a type of recurrence set relative to $Œ±$. We describe how that set depends on $Œ±$.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04994v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04994v1">üìÑ Download PDF</a></p><hr><h3 id=introduction-to-quantum-control-from-basic-concepts-to-applications-in-quantum-technologieshttpsarxivorgabs251204990v1><a href=https://arxiv.org/abs/2512.04990v1>Introduction to quantum control: From basic concepts to applications in quantum technologies</a><a hidden class=anchor aria-hidden=true href=#introduction-to-quantum-control-from-basic-concepts-to-applications-in-quantum-technologieshttpsarxivorgabs251204990v1>#</a></h3><p><strong>Authors:</strong> Christiane P. Koch
<strong>Venue:</strong> arXiv (2025)</p><p>Quantum control refers to our ability to manipulate quantum systems. This tutorial-style chapter focuses on the use of classical electromagnetic fields to steer the system dynamics. In this approach, the quantum nature of the control stems solely from the underlying dynamics, through the exploitation of destructive and constructive interference to reach the control target. We first discuss two basic control principles &ndash; coherent control which uses manipulation in frequency or time to design these interferences, and adiabatic following where access to the control target is enabled by tracking the time-dependent ground state. For complex control targets and system dynamics that exceed the scope of these basic principles, optimal control theory provides a powerful suite of tools to design the necessary protocols. A key consideration for the successful application of optimal control theory is a proper choice of the optimization functional. All concepts are illustrated using recent work from my research group, with a focus on controlling atoms and superconducting qubits. The chapter concludes with an outlook on integrating coherent control with engineered dissipation and a discussion of open questions in the field.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04990v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04990v1">üìÑ Download PDF</a></p><hr><h3 id=thermodynamics-vs-teleodynamics-a-cosmological-dividehttpsarxivorgabs251204977v1><a href=https://arxiv.org/abs/2512.04977v1>Thermodynamics vs Teleodynamics: A Cosmological Divide?</a><a hidden class=anchor aria-hidden=true href=#thermodynamics-vs-teleodynamics-a-cosmological-dividehttpsarxivorgabs251204977v1>#</a></h3><p><strong>Authors:</strong> Oem Trivedi, Venkat Venkatasubramanian
<strong>Venue:</strong> arXiv (2025)</p><p>We show that stationary black holes and the evolving universe belong to fundamentally different thermodynamic regimes: black holes obey ordinary Bekenstein Hawking thermodynamics, whereas cosmology necessarily follows memory-bearing teleodynamics. We show that teleodynamics is not valid for black holes, but is unavoidable in an expanding cosmology. This provides a dynamical, semi-classical realization of the thermodynamic split conjecture and identifies memory accumulation as the natural source of deviations from the area law in cosmology. Our results suggest that quantum gravity should not seek to extrapolate black hole thermodynamics to the universe, but instead must incorporate horizon memory as a fundamental microscopic ingredient and consider cosmological constructions consistent with that.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04977v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04977v1">üìÑ Download PDF</a></p><hr><h3 id=characterization-of-thin-optical-filters-for-high-purity-cherenkov-light-readout-from-scintillating-crystalshttpsarxivorgabs251204965v1><a href=https://arxiv.org/abs/2512.04965v1>Characterization of thin optical filters for high purity Cherenkov light readout from scintillating crystals</a><a hidden class=anchor aria-hidden=true href=#characterization-of-thin-optical-filters-for-high-purity-cherenkov-light-readout-from-scintillating-crystalshttpsarxivorgabs251204965v1>#</a></h3><p><strong>Authors:</strong> Andrea Benaglia, Flavia Cetorelli, Marco Toliman Lucchini, Etiennette Auffray, Louis Roux, Julie Delenne
<strong>Venue:</strong> arXiv (2025)</p><p>A hybrid dual-readout calorimeter concept, comprising both electromagnetic and hadronic sections, has recently been proposed to meet the performance requirements of experiments at future e$^{+}$e$^{-}$ colliders. The front compartment consists of a homogeneous electromagnetic calorimeter made of high-density crystals, each coupled to a pair of Silicon Photomultipliers (SiPMs) providing the simultaneous readout of scintillation and Cherenkov light. To efficiently detect Cherenkov photons in the presence of dominant scintillation signals, an optical filter is placed in front of one of the two SiPMs to suppress photons in the wavelength region corresponding to that of scintillation emission. % In this study, PWO, BGO, and BSO crystals with different dimensions were tested to measure their scintillation light yield and decay time, as well as their transmission and emission spectra. A set of $\sim 100~\rm Œºm$-thick optical filters was also characterized by measuring their transmittance curves. The experimental results were used to model and estimate the expected filter performance in attenuating scintillation light for the various crystals. % The performance of each filter was experimentally validated by measuring the crystal light output with and without the filter using a $^{22}$Na radioactive source and a LYSO:Ce crystal, confirming the accuracy of the calculations. % The results show that interference filters are unsuitable for this application because their transmittance strongly depends on the photon incidence angle. Conversely, two absorptive long-pass filters with cutoff wavelengths around 590~nm were found to block more than 99% of the scintillation light from PWO crystals, satisfying the calorimeter specifications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04965v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04965v1">üìÑ Download PDF</a></p><hr><h3 id=triplec-learning-and-lightweight-speech-enhancement-for-multi-condition-target-speech-extractionhttpsarxivorgabs251204945v1><a href=https://arxiv.org/abs/2512.04945v1>TripleC Learning and Lightweight Speech Enhancement for Multi-Condition Target Speech Extraction</a><a hidden class=anchor aria-hidden=true href=#triplec-learning-and-lightweight-speech-enhancement-for-multi-condition-target-speech-extractionhttpsarxivorgabs251204945v1>#</a></h3><p><strong>Authors:</strong> Ziling Huang
<strong>Venue:</strong> arXiv (2025)</p><p>In our recent work, we proposed Lightweight Speech Enhancement Guided Target Speech Extraction (LGTSE) and demonstrated its effectiveness in multi-speaker-plus-noise scenarios. However, real-world applications often involve more diverse and complex conditions, such as one-speaker-plus-noise or two-speaker-without-noise. To address this challenge, we extend LGTSE with a Cross-Condition Consistency learning strategy, termed TripleC Learning. This strategy is first validated under multi-speaker-plus-noise condition and then evaluated for its generalization across diverse scenarios. Moreover, building upon the lightweight front-end denoiser in LGTSE, which can flexibly process both noisy and clean mixtures and shows strong generalization to unseen conditions, we integrate TripleC learning with a proposed parallel universal training scheme that organizes batches containing multiple scenarios for the same target speaker. By enforcing consistent extraction across different conditions, easier cases can assist harder ones, thereby fully exploiting diverse training data and fostering a robust universal model. Experimental results on the Libri2Mix three-condition tasks demonstrate that the proposed LGTSE with TripleC learning achieves superior performance over condition-specific models, highlighting its strong potential for universal deployment in real-world speech applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04945v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04945v1">üìÑ Download PDF</a></p><hr><h3 id=multi-agent-reinforcement-learning-for-intraday-operating-rooms-scheduling-under-uncertaintyhttpsarxivorgabs251204918v1><a href=https://arxiv.org/abs/2512.04918v1>Multi-Agent Reinforcement Learning for Intraday Operating Rooms Scheduling under Uncertainty</a><a hidden class=anchor aria-hidden=true href=#multi-agent-reinforcement-learning-for-intraday-operating-rooms-scheduling-under-uncertaintyhttpsarxivorgabs251204918v1>#</a></h3><p><strong>Authors:</strong> Kailiang Liu, Ying Chen, Ralf Bornd√∂rfer, Thorsten Koch
<strong>Venue:</strong> arXiv (2025)</p><p>Intraday surgical scheduling is a multi-objective decision problem under uncertainty-balancing elective throughput, urgent and emergency demand, delays, sequence-dependent setups, and overtime. We formulate the problem as a cooperative Markov game and propose a multi-agent reinforcement learning (MARL) framework in which each operating room (OR) is an agent trained with centralized training and decentralized execution. All agents share a policy trained via Proximal Policy Optimization (PPO), which maps rich system states to actions, while a within-epoch sequential assignment protocol constructs conflict-free joint schedules across ORs. A mixed-integer pre-schedule provides reference starting times for electives; we impose type-specific quadratic delay penalties relative to these references and a terminal overtime penalty, yielding a single reward that captures throughput, timeliness, and staff workload. In simulations reflecting a realistic hospital mix (six ORs, eight surgery types, random urgent and emergency arrivals), the learned policy outperforms six rule-based heuristics across seven metrics and three evaluation subsets, and, relative to an ex post MIP oracle, quantifies optimality gaps. Policy analytics reveal interpretable behavior-prioritizing emergencies, batching similar cases to reduce setups, and deferring lower-value electives. We also derive a suboptimality bound for the sequential decomposition under simplifying assumptions. We discuss limitations-including OR homogeneity and the omission of explicit staffing constraints-and outline extensions. Overall, the approach offers a practical, interpretable, and tunable data-driven complement to optimization for real-time OR scheduling.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04918v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04918v1">üìÑ Download PDF</a></p><hr><h3 id=communicating-properties-of-quantum-states-over-classical-noisy-channelshttpsarxivorgabs251204913v1><a href=https://arxiv.org/abs/2512.04913v1>Communicating Properties of Quantum States over Classical Noisy Channels</a><a hidden class=anchor aria-hidden=true href=#communicating-properties-of-quantum-states-over-classical-noisy-channelshttpsarxivorgabs251204913v1>#</a></h3><p><strong>Authors:</strong> Nikhitha Nunavath, Jiechen Chen, Osvaldo Simeone, Riccardo Bassoli, Frank H. P. Fitzek
<strong>Venue:</strong> arXiv (2025)</p><p>Transmitting information about quantum states over classical noisy channels is an important problem with applications to science, computing, and sensing. This task, however, poses fundamental challenges due to the exponential scaling of state space with system size. We introduce shadow tomography-based transmission with unequal error protection (STT-UEP), a novel communication protocol that enables efficient transmission of properties of quantum states, allowing decoder-side estimation of arbitrary observables. Unlike conventional approaches requiring the transmission of a number of bits that is exponential in the number of qubits, STT-UEP achieves communication complexity that scales logarithmically with the number of observables, depending on the observable weight. The protocol exploits classical shadow tomography for measurement efficiency, and applies unequal error protection by encoding measurement bases with stronger channel codes than measurement outcomes. We provide theoretical guarantees on estimation accuracy as a function of the bit error probability of the classical channel, and validate the approach against several benchmarks via numerical results.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04913v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04913v1">üìÑ Download PDF</a></p><hr><h3 id=long-term-mid-infrared-color-variations-of-narrow-line-seyfert-1-galaxieshttpsarxivorgabs251204906v1><a href=https://arxiv.org/abs/2512.04906v1>Long-term Mid-infrared Color Variations of Narrow-Line Seyfert 1 Galaxies</a><a hidden class=anchor aria-hidden=true href=#long-term-mid-infrared-color-variations-of-narrow-line-seyfert-1-galaxieshttpsarxivorgabs251204906v1>#</a></h3><p><strong>Authors:</strong> Jiahua Wu, Huifang Xie, Liming Dou, Yanli Ai, Tinggui Wang, Xinwen Shu, Ning Jiang, Luis C. Ho, Junhui Fan
<strong>Venue:</strong> arXiv (2025)</p><p>We present a systematic investigation of long-term mid-infrared (MIR) color variability in 1,718 Narrow-Line Seyfert 1 galaxies (NLSy1s) using 14-year \textit{WISE}/NEOWISE monitoring data. Through Pearson correlation analysis between photometric magnitude and color, we identify: (1) a radio-quiet NLSy1 (RQ-NLSy1) population comprising 230 bluer-when-brighter (BWB) sources, 131 redder-when-brighter (RWB) sources, and 1,323 objects showing weak or statistically insignificant color variations; and (2) a radio-loud NLSy1 (RL-NLSy1) population containing 5 BWBs, 2 RWBs, and 27 sources with weak/no color variations. Our analysis reveals that the BWB tendency strengthens significantly in galaxies with redder mean MIR colors $\rm \left&lt;W1-W2\right>$ and lower starlight contamination. Furthermore, this color-change pattern demonstrates that the most bolometric luminous sources exhibit the most pronounced BWB behavior. While similar trends exist for black hole mass and Eddington ratio, bolometric luminosity appears to be the primary physical driver. Potential origins of these variations (e.g., host galaxy contribution, accretion disk variability, and dust reprocessing) are discussed. We conclude that temperature-dependent dust reprocessing dominates the observed BWB, RWB, and no/weak variation patterns. This interpretation may also apply to similar MIR color variations observed in other extragalactic MIR transients, such as tidal disruption events, ambiguous nuclear transients, and changing-look AGNs. In addition, we find no significant difference in long-term MIR color variations between RL-NLSy1s and RQ-NLSy1s, however, RL-NLSy1s show significantly greater dispersion in intrinsic variability amplitude compared to RQ-NLSy1s due to jet-induced complexity, where non-thermal synchrotron emission from relativistic jets obscures thermal dust signatures.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04906v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04906v1">üìÑ Download PDF</a></p><hr><h3 id=adaptive-optics-enhanced-michelson-interferometer-for-spectroscopy-of-narrow-band-light-sourceshttpsarxivorgabs251204901v1><a href=https://arxiv.org/abs/2512.04901v1>Adaptive Optics-Enhanced Michelson Interferometer for Spectroscopy of Narrow-Band Light Sources</a><a hidden class=anchor aria-hidden=true href=#adaptive-optics-enhanced-michelson-interferometer-for-spectroscopy-of-narrow-band-light-sourceshttpsarxivorgabs251204901v1>#</a></h3><p><strong>Authors:</strong> Jesneil Lauren Lewis, Ayan Banerjee
<strong>Venue:</strong> arXiv (2025)</p><p>Adaptive optics enables the deployment of interferometer-based spectroscopy without the need for moving parts necessary for scanning the interferometer arms. Here, we employ a Michelson Interferometer in conjunction with a Spatial Light Modulator (SLM) for determining the spectral profile of a narrow-band light source. Interestingly, we observe that the fringes across the interferometer output beam are inherently shifted in wavelength even when a constant phase profile is provided to the SLM. We calibrate the spectral shifts as a function of fringe spatial location by measuring the incident light spectrum at various points across the fringe pattern, and observe that the spectral peak traces out a `teardrop&rsquo; shape, whose width is dependent on the spectral bandwidth of the source, the relative tilt and path difference between the two arms of the interferometer, and the divergence of the beam. Next, we demonstrate that this inherent spectral variation of the fringes can be used to perform fast single-snapshot spectroscopy of narrow-band light sources, while a time-varied phase profile provided to the SLM leads to multi-step spectroscopy with lower noise, higher resolution, and better contrast. Our findings establish that the Michelson Interferometer can be used to perform spectroscopy of any source within a certain spectral range from simple images of the fringe pattern, so as to facilitate exciting applications towards hyperspectral imaging.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04901v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04901v1">üìÑ Download PDF</a></p><hr><h3 id=bayesian-stepwise-estimation-of-qubit-rotationshttpsarxivorgabs251204898v1><a href=https://arxiv.org/abs/2512.04898v1>Bayesian stepwise estimation of qubit rotations</a><a hidden class=anchor aria-hidden=true href=#bayesian-stepwise-estimation-of-qubit-rotationshttpsarxivorgabs251204898v1>#</a></h3><p><strong>Authors:</strong> Mylenne Manrique, Marco Barbieri, Assunta Di Vizio, Miranda Parisi, Gabriele Bizzarri, Ilaria Gianani, Matteo G. A. Paris
<strong>Venue:</strong> arXiv (2025)</p><p>This work investigates Bayesian stepwise estimation (Se) for measuring the two parameters of a unitary qubit rotation. While asymptotic analysis predicts a precision advantage for SE over joint estimation (JE) in regimes where the quantum Fisher information matrix is near-singular (&ldquo;sloppy&rdquo; models), we demonstrate that this advantage is mitigated within a practical Bayesian framework with limited resources. We experimentally implement a SE protocol using polarisation qubits, achieving uncertainties close to the classical Van Trees bounds. However, comparing the total error to the ultimate quantum Van Trees bound for JE reveals that averaging over prior distributions erases the asymptotic SE advantage. Nevertheless, the stepwise strategy retains a significant practical benefit as it operates effectively with simple, fixed measurements, whereas saturating the JE bound typically requires complex, parameter-dependent operations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04898v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04898v1">üìÑ Download PDF</a></p><hr><h3 id=the-malatang-survey-star-formation-dense-gas-and-agn-feedback-in-ngc-1068httpsarxivorgabs251204891v1><a href=https://arxiv.org/abs/2512.04891v1>The MALATANG survey: star formation, dense gas, and AGN feedback in NGC 1068</a><a hidden class=anchor aria-hidden=true href=#the-malatang-survey-star-formation-dense-gas-and-agn-feedback-in-ngc-1068httpsarxivorgabs251204891v1>#</a></h3><p><strong>Authors:</strong> Shuting Lin, Siyi Feng, Zhi-Yu Zhang, Chunyi Zhang, Qing-Hua Tan, Junzhi Wang, Yu Gao, Xue-Jian Jiang, Yang Gao, Xiao-Long Wang, Junfeng Wang, Jian-Fa Wang, Satoki Matsushita, Aeree Chung, Kotaro Kohno, Tosaki Tomoka, Thomas R. Greve
<strong>Venue:</strong> arXiv (2025)</p><p>We aim to investigate the interplay between dense molecular gas, star formation, and active galactic nucleus (AGN) feedback in the luminous infrared galaxy (LIRG) NGC 1068 at sub-kiloparsec scales. We present the HCN (4-3) and HCO$^+$ (4-3) maps of NGC 1068, obtained with JCMT as part of the Mapping the dense molecular gas in the strongest star-forming galaxies (MALATANG) project, and perform spatially resolved analyses of their correlations with infrared luminosity and soft X-ray emission. Spatially resolved relations between the luminosities of infrared dust emission and dense molecular gas tracers ($L_{\rm IR}-L&rsquo;<em>{\rm dense}$) are found to be nearly linear, without clear evidence of excess contributions from AGN activity. The spatially resolved X-ray emission ($L^{\rm gas}</em>{0.5-2,\mathrm{keV}}$) displays a radially-dependent twofold correlation with the star formation rate (SFR), suggesting distinct gas-heating mechanisms between the galaxy center and the outer regions. A super-linear scaling is obtained in galactic center regions with SFR surface density ($Œ£_{\rm SFR}$) $>$ 8.2 $\times$ 10$^{-6}$ $M_\odot$ yr$^{-1}$ kpc$^{-2}$: log($L^{\rm gas}<em>{0.5-2,\mathrm{keV}}$/erg s$^{-1}$) = 2.2 log(SFR/$M</em>\odot$ yr$^{-1}$) + 39.1. We further found a statistically significant super-linear correlation ($Œ≤= 1.34$ $\pm$ 0.86) between $L^{\rm gas}_{0.5-2,\mathrm{keV}}$/SFR and HCN(4-3)/CO(1-0) intensity ratio, whereas no such trend is seen for HCO$^+$(4-3)/CO(1-0) or CO(3-2)/CO(1-0). These findings indicate that AGN feedback does not dominate star formation regulation on sub-kiloparsec scales, and that the excitation of dense gas traced by HCN (4-3) may be more directly influenced by high-energy feedback processes compared to HCO$^+$ (4-3) and CO (3-2).</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04891v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04891v1">üìÑ Download PDF</a></p><hr><h3 id=developing-a-general-personal-tutor-for-educationhttpsarxivorgabs251204869v1><a href=https://arxiv.org/abs/2512.04869v1>Developing a General Personal Tutor for Education</a><a hidden class=anchor aria-hidden=true href=#developing-a-general-personal-tutor-for-educationhttpsarxivorgabs251204869v1>#</a></h3><p><strong>Authors:</strong> Jaan Aru, Kristjan-Julius Laak
<strong>Venue:</strong> arXiv (2025)</p><p>The vision of a universal AI tutor has remained elusive, despite decades of effort. Could LLMs be the game-changer? We overview novel issues arising from developing a nationwide AI tutor. We highlight the practical questions that point to specific gaps in our scientific understanding of the learning process.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04869v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04869v1">üìÑ Download PDF</a></p><hr><h3 id=degrees-of-universality-in-wave-turbulencehttpsarxivorgabs251204866v1><a href=https://arxiv.org/abs/2512.04866v1>Degrees of universality in wave turbulence</a><a hidden class=anchor aria-hidden=true href=#degrees-of-universality-in-wave-turbulencehttpsarxivorgabs251204866v1>#</a></h3><p><strong>Authors:</strong> Jiasheng Liu, Vladimir Rosenhaus, Gregory Falkovich
<strong>Venue:</strong> arXiv (2025)</p><p>Turbulence of weakly interacting waves displays a great deal of universality: independence of the details of the interaction and of the pumping and dissipation scales. Here we study how inverse turbulent cascades (from small to large scales) transition from weak to strong. We find that while one-loop corrections can be dependent on excitation and dissipation scales, new types of universality appear in strong turbulence. We contrast turbulence of spin waves in ferromagnets with turbulent cascades in the Nonlinear Schr√∂dinger Equation (NSE) and in an MMT-like model in higher dimensions having a multiplicative interaction vertex: vertex renormalization gives rise to dependence on the pumping (UV scale) in the former but not in the latter. As a result of this spectral nonlocality, spin-wave turbulence stops being weak if one is sufficiently far from the pumping scale, even when the interaction of waves with comparable wavenumbers is weak. We paraphrase this as: nonlocality enhances nonlinearity.
We then describe strong turbulence in a multi-component version of these models with a large number of components. We argue that strong spin-wave turbulence is similar to turbulence of the focusing NSE, as it realizes a critical-balance state. However, UV nonlocality causes the level of spin-wave turbulence at large scales to decrease with increasing pumping level, culminating in a state that is independent of the level of pumping.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04866v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04866v1">üìÑ Download PDF</a></p><hr><h3 id=concentration-bounds-for-intrinsic-dimension-estimation-using-gaussian-kernelshttpsarxivorgabs251204861v1><a href=https://arxiv.org/abs/2512.04861v1>Concentration bounds for intrinsic dimension estimation using Gaussian kernels</a><a hidden class=anchor aria-hidden=true href=#concentration-bounds-for-intrinsic-dimension-estimation-using-gaussian-kernelshttpsarxivorgabs251204861v1>#</a></h3><p><strong>Authors:</strong> Martin Andersson
<strong>Venue:</strong> arXiv (2025)</p><p>We prove finite-sample concentration and anti-concentration bounds for dimension estimation using Gaussian kernel sums. Our bounds provide explicit dependence on sample size, bandwidth, and local geometric and distributional parameters, characterizing precisely how regularity conditions govern statistical performance. We also propose a bandwidth selection heuristic using derivative information, which shows promise in numerical experiments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04861v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04861v1">üìÑ Download PDF</a></p><hr><h3 id=autoregressive-image-generation-needs-only-a-few-lines-of-cached-tokenshttpsarxivorgabs251204857v1><a href=https://arxiv.org/abs/2512.04857v1>Autoregressive Image Generation Needs Only a Few Lines of Cached Tokens</a><a hidden class=anchor aria-hidden=true href=#autoregressive-image-generation-needs-only-a-few-lines-of-cached-tokenshttpsarxivorgabs251204857v1>#</a></h3><p><strong>Authors:</strong> Ziran Qin, Youru Lv, Mingbao Lin, Zeren Zhang, Chanfan Gan, Tieyuan Chen, Weiyao Lin
<strong>Venue:</strong> arXiv (2025)</p><p>Autoregressive (AR) visual generation has emerged as a powerful paradigm for image and multimodal synthesis, owing to its scalability and generality. However, existing AR image generation suffers from severe memory bottlenecks due to the need to cache all previously generated visual tokens during decoding, leading to both high storage requirements and low throughput. In this paper, we introduce \textbf{LineAR}, a novel, training-free progressive key-value (KV) cache compression pipeline for autoregressive image generation. By fully exploiting the intrinsic characteristics of visual attention, LineAR manages the cache at the line level using a 2D view, preserving the visual dependency regions while progressively evicting less-informative tokens that are harmless for subsequent line generation, guided by inter-line attention. LineAR enables efficient autoregressive (AR) image generation by utilizing only a few lines of cache, achieving both memory savings and throughput speedup, while maintaining or even improving generation quality. Extensive experiments across six autoregressive image generation models, including class-conditional and text-to-image generation, validate its effectiveness and generality. LineAR improves ImageNet FID from 2.77 to 2.68 and COCO FID from 23.85 to 22.86 on LlamaGen-XL and Janus-Pro-1B, while retaining only 1/6 KV cache. It also improves DPG on Lumina-mGPT-768 with just 1/8 KV cache. Additionally, LineAR achieves significant memory and throughput gains, including up to 67.61% memory reduction and 7.57x speedup on LlamaGen-XL, and 39.66% memory reduction and 5.62x speedup on Janus-Pro-7B.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04857v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04857v1">üìÑ Download PDF</a></p><hr><h3 id=safe-model-based-reinforcement-learning-via-model-predictive-control-and-control-barrier-functionshttpsarxivorgabs251204856v1><a href=https://arxiv.org/abs/2512.04856v1>Safe model-based Reinforcement Learning via Model Predictive Control and Control Barrier Functions</a><a hidden class=anchor aria-hidden=true href=#safe-model-based-reinforcement-learning-via-model-predictive-control-and-control-barrier-functionshttpsarxivorgabs251204856v1>#</a></h3><p><strong>Authors:</strong> Kerim Dzhumageldyev, Filippo Airaldi, Azita Dabiri
<strong>Venue:</strong> arXiv (2025)</p><p>Optimal control strategies are often combined with safety certificates to ensure both performance and safety in safety-critical systems. A prominent example is combining Model Predictive Control (MPC) with Control Barrier Functions (CBF). Yet, efficient tuning of MPC parameters and choosing an appropriate class $\mathcal{K}$ function in the CBF is challenging and problem dependent. This paper introduces a safe model-based Reinforcement Learning (RL) framework where a parametric MPC controller incorporates a CBF constraint with a parameterized class $\mathcal{K}$ function and serves as a function approximator to learn improved safe control policies from data. Three variations of the framework are introduced, distinguished by the way the optimization problem is formulated and the class $\mathcal{K}$ function is parameterized, including neural architectures. Numerical experiments on a discrete double-integrator with static and dynamic obstacles demonstrate that the proposed methods improve performance while ensuring safety.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04856v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04856v1">üìÑ Download PDF</a></p><hr><h3 id=the-stagnant-persistence-paradox-survival-analysis-and-temporal-efficiency-in-exact-sciences-and-engineering-educationhttpsarxivorgabs251204828v1><a href=https://arxiv.org/abs/2512.04828v1>The Stagnant Persistence Paradox: Survival Analysis and Temporal Efficiency in Exact Sciences and Engineering Education</a><a hidden class=anchor aria-hidden=true href=#the-stagnant-persistence-paradox-survival-analysis-and-temporal-efficiency-in-exact-sciences-and-engineering-educationhttpsarxivorgabs251204828v1>#</a></h3><p><strong>Authors:</strong> H. R. Paz
<strong>Venue:</strong> arXiv (2025)</p><p>Research on student progression in higher education has traditionally focused on vertical outcomes such as persistence and dropout, often reducing complex academic histories to binary indicators. While the structural component of horizontal mobility (major switching, plan changes, re-entries) has recently been recognised as a core feature of contemporary university systems, the temporal cost and efficiency of these pathways remain largely unquantified. Using forty years of administrative records from a large faculty of engineering and exact sciences in Argentina (N = 24,016), this study applies a dual-outcome survival analysis framework to two key outcomes: definitive dropout and first major switch. We reconstruct academic trajectories as sequences of enrolment spells and typed transitions under the CAPIRE protocol, and then deploy non-parametric Kaplan-Meier estimators to model time-to-event under right-censoring. Results uncover a critical systemic inefficiency: a global median survival time of 4.33 years prior to definitive dropout, with a pronounced long tail of extended enrolment. This pattern reveals a phenomenon of stagnant persistence, where students remain formally enrolled for long periods without commensurate curricular progression. In contrast, major switching follows an early-event regime, with a median time of 1.0 year among switchers and most switches concentrated within the first academic year. We argue that academic failure in rigid engineering curricula is not a sudden outcome but a long-tail process that generates high opportunity costs, and that institutional indicators should shift from static retention metrics towards measures of curricular velocity based on time-to-event analysis.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04828v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04828v1">üìÑ Download PDF</a></p><hr><h3 id=statistical-insight-into-the-correlation-of-geometry-and-spectral-emission-in-network-lasershttpsarxivorgabs251204811v1><a href=https://arxiv.org/abs/2512.04811v1>Statistical Insight into the Correlation of Geometry and Spectral Emission in Network Lasers</a><a hidden class=anchor aria-hidden=true href=#statistical-insight-into-the-correlation-of-geometry-and-spectral-emission-in-network-lasershttpsarxivorgabs251204811v1>#</a></h3><p><strong>Authors:</strong> Camillo Tassi, Riccardo Mannella, Andrea Tomadin, Andrea Camposeo, Dario Pisignano
<strong>Venue:</strong> arXiv (2025)</p><p>Optically active networks show feature-rich emission that depends on the fine details of their geometry, and find diverse applications in random lasers, sensing devices and photonics processors. In these and other systems, a thorough and predictive characterization of how the network geometry correlates with the resulting emission spectrum would be highly important, however such outright description is still lacking. In this work, we take a step toward filling this gap, by using the well-known Steady-State ab Initio Laser Theory (SALT) equations [L. Ge et al., Phys. Rev. A 82, 063824 (2010)] to carry out an extensive set of statistical analyses and establish connections between the random network geometry and their ultimate emission spectrum. Our results show that edge crowding is key to tune the uniformity of the modal intensity distribution of the emission spectrum. A statistical framework for the comprehensive understanding of the network statistical properties is highly significant to establish precise design rules for network-based photonic devices and intelligent systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04811v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04811v1">üìÑ Download PDF</a></p><hr><h3 id=existence-and-uniqueness-of-the-canonical-brownian-motion-in-non-simple-conformal-loop-ensemble-gasketshttpsarxivorgabs251204807v1><a href=https://arxiv.org/abs/2512.04807v1>Existence and uniqueness of the canonical Brownian motion in non-simple conformal loop ensemble gaskets</a><a hidden class=anchor aria-hidden=true href=#existence-and-uniqueness-of-the-canonical-brownian-motion-in-non-simple-conformal-loop-ensemble-gasketshttpsarxivorgabs251204807v1>#</a></h3><p><strong>Authors:</strong> Jason Miller, Yizheng Yuan
<strong>Venue:</strong> arXiv (2025)</p><p>We construct the canonical Brownian motion on the gasket of conformal loop ensembles (CLE$_Œ∫$) for $Œ∫\in (4,8)$ (which is the range of parameter values in which loops of the CLE$_Œ∫$ can intersect themselves, each other, and the domain boundary). More precisely, we show that there is a unique diffusion process on the CLE$_Œ∫$ gasket whose law depends locally on the CLE$_Œ∫$ and satisfies certain natural properties such as translation-invariance and scale-invariance (modulo time change). We characterize the diffusion process by its resistance form and show in particular that there is a unique resistance form on the CLE$_Œ∫$ gasket that is locally determined by the CLE$_Œ∫$ and satisfies certain natural properties such as translation-invariance and scale-covariance. We conjecture that the CLE$_Œ∫$ Brownian motion describes the scaling limit of simple random walk on statistical mechanics models in two dimensions that converge to CLE$_Œ∫$. In future work the results of this paper will be used to show that this is the case with $Œ∫=6$ for critical percolation on the triangular lattice.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04807v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04807v1">üìÑ Download PDF</a></p><hr><h3 id=yingmusic-svc-real-world-robust-zero-shot-singing-voice-conversion-with-flow-grpo-and-singing-specific-inductive-biaseshttpsarxivorgabs251204793v1><a href=https://arxiv.org/abs/2512.04793v1>YingMusic-SVC: Real-World Robust Zero-Shot Singing Voice Conversion with Flow-GRPO and Singing-Specific Inductive Biases</a><a hidden class=anchor aria-hidden=true href=#yingmusic-svc-real-world-robust-zero-shot-singing-voice-conversion-with-flow-grpo-and-singing-specific-inductive-biaseshttpsarxivorgabs251204793v1>#</a></h3><p><strong>Authors:</strong> Gongyu Chen, Xiaoyu Zhang, Zhenqiang Weng, Junjie Zheng, Da Shen, Chaofan Ding, Wei-Qiang Zhang, Zihao Chen
<strong>Venue:</strong> arXiv (2025)</p><p>Singing voice conversion (SVC) aims to render the target singer&rsquo;s timbre while preserving melody and lyrics. However, existing zero-shot SVC systems remain fragile in real songs due to harmony interference, F0 errors, and the lack of inductive biases for singing. We propose YingMusic-SVC, a robust zero-shot framework that unifies continuous pre-training, robust supervised fine-tuning, and Flow-GRPO reinforcement learning. Our model introduces a singing-trained RVC timbre shifter for timbre-content disentanglement, an F0-aware timbre adaptor for dynamic vocal expression, and an energy-balanced rectified flow matching loss to enhance high-frequency fidelity. Experiments on a graded multi-track benchmark show that YingMusic-SVC achieves consistent improvements over strong open-source baselines in timbre similarity, intelligibility, and perceptual naturalness, especially under accompanied and harmony-contaminated conditions, demonstrating its effectiveness for real-world SVC deployment.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04793v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04793v1">üìÑ Download PDF</a></p><hr><h3 id=tensorial-permanence-of-k-stability-for-diagonal-ah-algebrashttpsarxivorgabs251204780v1><a href=https://arxiv.org/abs/2512.04780v1>Tensorial Permanence of $K$-Stability for Diagonal AH-Algebras</a><a hidden class=anchor aria-hidden=true href=#tensorial-permanence-of-k-stability-for-diagonal-ah-algebrashttpsarxivorgabs251204780v1>#</a></h3><p><strong>Authors:</strong> Apurva Seth
<strong>Venue:</strong> arXiv (2025)</p><p>We study $K$-stability for tensor products of diagonal AH-algebras with arbitrary C*-algebras. Our main result provides a characterization of $K$-stability: for a diagonal AH-algebra $A = \varinjlim (A_i, \varphi_i)$, $A \otimes B$ is $K$-stable for every C*-algebra $B$ if and only if the sizes of the matrix blocks in the inductive system grow without bound. As applications, we show that non-$\mathcal{Z}$-stable Villadsen algebras of the first kind are $K$-stable when tensored with any C*-algebra. Moreover, any simple, unital, infinite-dimensional diagonal AH-algebra automatically satisfies this growth condition, and therefore its tensor product with arbitrary C*-algebras is always $K$-stable.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04780v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04780v1">üìÑ Download PDF</a></p><hr><h3 id=superconductivity-onset-above-60-k-in-ambient-pressure-nickelate-filmshttpsarxivorgabs251204708v1><a href=https://arxiv.org/abs/2512.04708v1>Superconductivity onset above 60 K in ambient-pressure nickelate films</a><a hidden class=anchor aria-hidden=true href=#superconductivity-onset-above-60-k-in-ambient-pressure-nickelate-filmshttpsarxivorgabs251204708v1>#</a></h3><p><strong>Authors:</strong> Guangdi Zhou, Heng Wang, Haoliang Huang, Yaqi Chen, Fei Peng, Wei Lv, Zihao Nie, Wei Wang, Qi-Kun Xue, Zhuoyu Chen
<strong>Venue:</strong> arXiv (2025)</p><p>Ambient-pressure superconductivity in nickelates has been capped at an onset transition temperature (Tc) of ~40 K, a value that remains lower than the cuprate (~133 K) and iron-based (~55 K) counterparts, despite the promise shown under high pressure. Here, we report ambient-pressure superconductivity onset at ~63 K in epitaxial (La,Pr)3Ni2O7 thin films grown under compressive strain on SrLaAlO4 substrates. This Tc leap is enabled by pushing our gigantic-oxidative atomic-layer-by-layer epitaxy (GAE) method into an extreme non-equilibrium growth regime. It leverages powerful in situ oxidation to simultaneously enhance kinetics via higher temperatures and achieve full oxygenation without post-annealing. Synchrotron X-ray diffraction and scanning transmission electron microscopy confirm that this approach yields films of large-scale crystalline purity, overcoming the inherent metastability of the strained superconducting phase. These films exhibit a systematic evolution in their normal-state resistivity-temperature curve: the power-law exponent $Œ±$ evolves from Fermi-liquid-like ($Œ±$ ~2) at lower Tc to strange-metal-like ($Œ±$ ~1) in higher Tc samples, directly linking the enhanced superconductivity to non-Fermi liquid behavior. Mapping the vortex melting phase diagram by the mutual inductance technique further reveals 2D melting limit suppressed to near zero, which demonstrates significantly stronger interlayer coupling than that of cuprates. These results identify the nickelates as an anisotropic-3D high-Tc system exhibiting strange-metal behavior, presenting an alternative framework to the quasi-2D cuprate paradigm.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04708v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04708v1">üìÑ Download PDF</a></p><hr><h3 id=targeted-testing-of-compiler-optimizations-via-grammar-level-composition-styleshttpsarxivorgabs251204344v1><a href=https://arxiv.org/abs/2512.04344v1>Targeted Testing of Compiler Optimizations via Grammar-Level Composition Styles</a><a hidden class=anchor aria-hidden=true href=#targeted-testing-of-compiler-optimizations-via-grammar-level-composition-styleshttpsarxivorgabs251204344v1>#</a></h3><p><strong>Authors:</strong> Zitong Zhou, Ben Limpanukorn, Hong Jin Kang, Jiyuan Wang, Yaoxuan Wu, Akos Kiss, Renata Hodovan, Miryung Kim
<strong>Venue:</strong> arXiv (2025)</p><p>Ensuring the correctness of compiler optimizations is critical, but existing fuzzers struggle to test optimizations effectively. First, most fuzzers use optimization pipelines (heuristics-based, fixed sequences of passes) as their harness. The phase-ordering problem can enable or preempt transformations, so pipelines inevitably miss optimization interactions; moreover, many optimizations are not scheduled, even at aggressive levels. Second, optimizations typically fire only when inputs satisfy specific structural relationships, which existing generators and mutations struggle to produce. We propose targeted fuzzing of individual optimizations to complement pipeline-based testing. Our key idea is to exploit composition styles - structural relations over program constructs (adjacency, nesting, repetition, ordering) - that optimizations look for. We build a general-purpose, grammar-based mutational fuzzer, TargetFuzz, that (i) mines composition styles from an optimization-relevant corpus, then (ii) rebuilds them inside different contexts offered by a larger, generic corpus via synthesized mutations to test variations of optimization logic. TargetFuzz is adaptable to a new programming language by lightweight, grammar-based, construct annotations - and it automatically synthesizes mutators and crossovers to rebuild composition styles. No need for hand-coded generators or language-specific mutators, which is particularly useful for modular frameworks such as MLIR, whose dialect-based, rapidly evolving ecosystem makes optimizations difficult to fuzz. Our evaluation on LLVM and MLIR shows that TargetFuzz improves coverage by 8% and 11% and triggers optimizations 2.8$\times$ and 2.6$\times$, compared to baseline fuzzers under the targeted fuzzing mode. We show that targeted fuzzing is complementary: it effectively tests all 37 sampled LLVM optimizations, while pipeline-fuzzing missed 12.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04344v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04344v1">üìÑ Download PDF</a></p><hr><h3 id=network-of-theseus-like-the-shiphttpsarxivorgabs251204198v1><a href=https://arxiv.org/abs/2512.04198v1>Network of Theseus (like the ship)</a><a hidden class=anchor aria-hidden=true href=#network-of-theseus-like-the-shiphttpsarxivorgabs251204198v1>#</a></h3><p><strong>Authors:</strong> Vighnesh Subramaniam, Colin Conwell, Boris Katz, Andrei Barbu, Brian Cheung
<strong>Venue:</strong> arXiv (2025)</p><p>A standard assumption in deep learning is that the inductive bias introduced by a neural network architecture must persist from training through inference. The architecture you train with is the architecture you deploy. This assumption constrains the community from selecting architectures that may have desirable efficiency or design properties due to difficulties with optimization. We challenge this assumption with Network of Theseus (NoT), a method for progressively converting a trained, or even untrained, guide network architecture part-by-part into an entirely different target network architecture while preserving the performance of the guide network. At each stage, components in the guide network architecture are incrementally replaced with target architecture modules and aligned via representational similarity metrics. This procedure largely preserves the functionality of the guide network even under substantial architectural changes-for example, converting a convolutional network into a multilayer perceptron, or GPT-2 into a recurrent neural network. By decoupling optimization from deployment, NoT expands the space of viable inference-time architectures, opening opportunities for better accuracy-efficiency tradeoffs and enabling more directed exploration of the architectural design space.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04198v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04198v1">üìÑ Download PDF</a></p><hr><h3 id=skillfactory-self-distillation-for-learning-cognitive-behaviorshttpsarxivorgabs251204072v1><a href=https://arxiv.org/abs/2512.04072v1>SkillFactory: Self-Distillation For Learning Cognitive Behaviors</a><a hidden class=anchor aria-hidden=true href=#skillfactory-self-distillation-for-learning-cognitive-behaviorshttpsarxivorgabs251204072v1>#</a></h3><p><strong>Authors:</strong> Zayne Sprague, Jack Lu, Manya Wadhwa, Sedrick Keh, Mengye Ren, Greg Durrett
<strong>Venue:</strong> arXiv (2025)</p><p>Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforcement learning (RL) can learn to leverage them. How can we get models to leverage skills that aren&rsquo;t exhibited by base models? Our work, SkillFactory, is a method for fine-tuning models to roughly learn these skills during a supervised fine-tuning (SFT) stage prior to RL. Our approach does not rely on distillation from a stronger model, but instead uses samples from the model itself, rearranged to provide training data in the format of those skills. These &ldquo;silver&rdquo; SFT traces may be imperfect, but are nevertheless effective for priming a model to acquire skills during RL. Our evaluation shows that (1) starting from SkillFactory SFT initialization helps a model to generalize to harder variants of a task post-RL, despite lower performance pre-RL; (2) cognitive skills are indeed used by the model; (3) RLed SkillFactory models are more robust to regression on out-of-domain tasks than RLed base models. Our work suggests that inductive biases learned prior to RL help models learn robust cognitive skill use.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04072v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04072v1">üìÑ Download PDF</a></p><hr><h3 id=the-loss-landscape-of-powder-x-ray-diffraction-based-structure-optimization-is-too-rough-for-gradient-descenthttpsarxivorgabs251204036v1><a href=https://arxiv.org/abs/2512.04036v1>The Loss Landscape of Powder X-Ray Diffraction-Based Structure Optimization Is Too Rough for Gradient Descent</a><a hidden class=anchor aria-hidden=true href=#the-loss-landscape-of-powder-x-ray-diffraction-based-structure-optimization-is-too-rough-for-gradient-descenthttpsarxivorgabs251204036v1>#</a></h3><p><strong>Authors:</strong> Nofit Segal, Akshay Subramanian, Mingda Li, Benjamin Kurt Miller, Rafael Gomez-Bombarelli
<strong>Venue:</strong> arXiv (2025)</p><p>Solving crystal structures from powder X-ray diffraction (XRD) is a central challenge in materials characterization. In this work, we study the powder XRD-to-structure mapping using gradient descent optimization, with the goal of recovering the correct structure from moderately distorted initial states based solely on XRD similarity. We show that commonly used XRD similarity metrics result in a highly non-convex landscape, complicating direct optimization. Constraining the optimization to the ground-truth crystal family significantly improves recovery, yielding higher match rates and increased mutual information and correlation scores between structural similarity and XRD similarity. Nevertheless, the landscape may remain non-convex along certain symmetry axes. These findings suggest that symmetry-aware inductive biases could play a meaningful role in helping learning models navigate the inverse mapping from diffraction to structure.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04036v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04036v1">üìÑ Download PDF</a></p><hr><h3 id=from-flops-to-footprints-the-resource-cost-of-artificial-intelligencehttpsarxivorgabs251204142v1><a href=https://arxiv.org/abs/2512.04142v1>From FLOPs to Footprints: The Resource Cost of Artificial Intelligence</a><a hidden class=anchor aria-hidden=true href=#from-flops-to-footprints-the-resource-cost-of-artificial-intelligencehttpsarxivorgabs251204142v1>#</a></h3><p><strong>Authors:</strong> Sophia Falk, Nicholas Kluge Corr√™a, Sasha Luccioni, Lisa Biber-Freudenberger, Aimee van Wynsberghe
<strong>Venue:</strong> arXiv (2025)</p><p>As computational demands continue to rise, assessing the environmental footprint of AI requires moving beyond energy and water consumption to include the material demands of specialized hardware. This study quantifies the material footprint of AI training by linking computational workloads to physical hardware needs. The elemental composition of the Nvidia A100 SXM 40 GB graphics processing unit (GPU) was analyzed using inductively coupled plasma optical emission spectroscopy, which identified 32 elements. The results show that AI hardware consists of about 90% heavy metals and only trace amounts of precious metals. The elements copper, iron, tin, silicon, and nickel dominate the GPU composition by mass. In a multi-step methodology, we integrate these measurements with computational throughput per GPU across varying lifespans, accounting for the computational requirements of training specific AI models at different training efficiency regimes. Scenario-based analyses reveal that, depending on Model FLOPs Utilization (MFU) and hardware lifespan, training GPT-4 requires between 1,174 and 8,800 A100 GPUs, corresponding to the extraction and eventual disposal of up to 7 tons of toxic elements. Combined software and hardware optimization strategies can reduce material demands: increasing MFU from 20% to 60% lowers GPU requirements by 67%, while extending lifespan from 1 to 3 years yields comparable savings; implementing both measures together reduces GPU needs by up to 93%. Our findings highlight that incremental performance gains, such as those observed between GPT-3.5 and GPT-4, come at disproportionately high material costs. The study underscores the necessity of incorporating material resource considerations into discussions of AI scalability, emphasizing that future progress in AI must align with principles of resource efficiency and environmental responsibility.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04142v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04142v1">üìÑ Download PDF</a></p><hr><h3 id=a-polyharmonic-liouville-hierarchy-on-complete-manifolds-of-nonnegative-ricci-curvaturehttpsarxivorgabs251204141v1><a href=https://arxiv.org/abs/2512.04141v1>A Polyharmonic Liouville Hierarchy on Complete Manifolds of Nonnegative Ricci Curvature</a><a hidden class=anchor aria-hidden=true href=#a-polyharmonic-liouville-hierarchy-on-complete-manifolds-of-nonnegative-ricci-curvaturehttpsarxivorgabs251204141v1>#</a></h3><p><strong>Authors:</strong> John E. Bravo, Jean C. Cortissoz
<strong>Venue:</strong> arXiv (2025)</p><p>In this paper, we establish a complete Liouville&ndash;type hierarchy for polyharmonic functions on a broad class of Riemannian manifolds with nonnegative Ricci curvature. Extending Yau&rsquo;s classical result for harmonic functions and our recent biharmonic Liouville theorem, we prove that on any complete manifold of nonnegative Ricci curvature with a pole, every $k$&ndash;polyharmonic function of growth $o(r^{2(k-1)})$ must in fact be $(k-1)$&ndash;polyharmonic. Iterating this procedure yields the result that all polyharmonic functions of sublinear growth are constant.The key innovation is a new $L^{2}$ estimate for the Laplacian of a polyharmonic function, obtained by induction through a delicate cutoff construction combined with a hole&ndash;filling argument. This provides the first sharp geometric extension of the Euclidean classification of polyharmonic functions to manifolds of nonnegative Ricci curvature, and completes a natural hierarchy of Yau&ndash;type Liouville theorems for iterates of the Laplacian.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04141v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04141v1">üìÑ Download PDF</a></p><hr><h3 id=bi-isolated-dce-degrees-and-œÉ_1-inductionhttpsarxivorgabs251203778v2><a href=https://arxiv.org/abs/2512.03778v2>Bi-Isolated d.c.e. Degrees and $Œ£_1$ Induction</a><a hidden class=anchor aria-hidden=true href=#bi-isolated-dce-degrees-and-œÉ_1-inductionhttpsarxivorgabs251203778v2>#</a></h3><p><strong>Authors:</strong> Yong Liu, Cheng Peng
<strong>Venue:</strong> arXiv (2025)</p><p>A Turing degree is d.c.e. if it contains a set that is the difference of two c.e. sets. A d.c.e. degree $\mathbf{d}$ is isolated if there exists a c.e. degree $\mathbf{a}&lt;\mathbf{d}$ such that every c.e. degree below $\mathbf{d}$ is also below $\mathbf{a}$; $\mathbf{d}$ is upper isolated if there exists a c.e. degree $\mathbf{a}>\mathbf{d}$ such that every c.e. degree above $\mathbf{d}$ is also above $\mathbf{a}$; $\mathbf{d}$ is bi-isolated if it is both isolated and upper isolated. In this paper, we prove the existence of bi-isolated d.c.e. degrees in models of $\mathsf{I}Œ£_1$.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03778v2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03778v2">üìÑ Download PDF</a></p><hr><h3 id=universally-converging-representations-of-matter-across-scientific-foundation-modelshttpsarxivorgabs251203750v1><a href=https://arxiv.org/abs/2512.03750v1>Universally Converging Representations of Matter Across Scientific Foundation Models</a><a hidden class=anchor aria-hidden=true href=#universally-converging-representations-of-matter-across-scientific-foundation-modelshttpsarxivorgabs251203750v1>#</a></h3><p><strong>Authors:</strong> Sathya Edamadaka, Soojung Yang, Ju Li, Rafael G√≥mez-Bombarelli
<strong>Venue:</strong> arXiv (2025)</p><p>Machine learning models of vastly different modalities and architectures are being trained to predict the behavior of molecules, materials, and proteins. However, it remains unclear whether they learn similar internal representations of matter. Understanding their latent structure is essential for building scientific foundation models that generalize reliably beyond their training domains. Although representational convergence has been observed in language and vision, its counterpart in the sciences has not been systematically explored. Here, we show that representations learned by nearly sixty scientific models, spanning string-, graph-, 3D atomistic, and protein-based modalities, are highly aligned across a wide range of chemical systems. Models trained on different datasets have highly similar representations of small molecules, and machine learning interatomic potentials converge in representation space as they improve in performance, suggesting that foundation models learn a common underlying representation of physical reality. We then show two distinct regimes of scientific models: on inputs similar to those seen during training, high-performing models align closely and weak models diverge into local sub-optima in representation space; on vastly different structures from those seen during training, nearly all models collapse onto a low-information representation, indicating that today&rsquo;s models remain limited by training data and inductive bias and do not yet encode truly universal structure. Our findings establish representational alignment as a quantitative benchmark for foundation-level generality in scientific models. More broadly, our work can track the emergence of universal representations of matter as models scale, and for selecting and distilling models whose learned representations transfer best across modalities, domains of matter, and scientific tasks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03750v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03750v1">üìÑ Download PDF</a></p><hr><h3 id=multi-scale-visual-prompting-for-lightweight-small-image-classificationhttpsarxivorgabs251203663v1><a href=https://arxiv.org/abs/2512.03663v1>Multi-Scale Visual Prompting for Lightweight Small-Image Classification</a><a hidden class=anchor aria-hidden=true href=#multi-scale-visual-prompting-for-lightweight-small-image-classificationhttpsarxivorgabs251203663v1>#</a></h3><p><strong>Authors:</strong> Salim Khazem
<strong>Venue:</strong> arXiv (2025)</p><p>Visual prompting has recently emerged as an efficient strategy to adapt vision models using lightweight, learnable parameters injected into the input space. However, prior work mainly targets large Vision Transformers and high-resolution datasets such as ImageNet. In contrast, small-image benchmarks like MNIST, Fashion-MNIST, and CIFAR-10 remain widely used in education, prototyping, and research, yet have received little attention in the context of prompting. In this paper, we introduce \textbf{Multi-Scale Visual Prompting (MSVP)}, a simple and generic module that learns a set of global, mid-scale, and local prompt maps fused with the input image via a lightweight $1 \times 1$ convolution. MSVP is backbone-agnostic, adds less than $0.02%$ parameters, and significantly improves performance across CNN and Vision Transformer backbones.
We provide a unified benchmark on MNIST, Fashion-MNIST, and CIFAR-10 using a simple CNN, ResNet-18, and a small Vision Transformer. Our method yields consistent improvements with negligible computational overhead. We further include ablations on prompt scales, fusion strategies, and backbone architectures, along with qualitative analyzes using prompt visualizations and Grad-CAM. Our results demonstrate that multi-scale prompting provides an effective inductive bias even on low-resolution images.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03663v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03663v1">üìÑ Download PDF</a></p><hr><h3 id=nas-lora-empowering-parameter-efficient-fine-tuning-for-visual-foundation-models-with-searchable-adaptationhttpsarxivorgabs251203499v1><a href=https://arxiv.org/abs/2512.03499v1>NAS-LoRA: Empowering Parameter-Efficient Fine-Tuning for Visual Foundation Models with Searchable Adaptation</a><a hidden class=anchor aria-hidden=true href=#nas-lora-empowering-parameter-efficient-fine-tuning-for-visual-foundation-models-with-searchable-adaptationhttpsarxivorgabs251203499v1>#</a></h3><p><strong>Authors:</strong> Renqi Chen, Haoyang Su, Shixiang Tang
<strong>Venue:</strong> arXiv (2025)</p><p>The Segment Anything Model (SAM) has emerged as a powerful visual foundation model for image segmentation. However, adapting SAM to specific downstream tasks, such as medical and agricultural imaging, remains a significant challenge. To address this, Low-Rank Adaptation (LoRA) and its variants have been widely employed to enhancing SAM&rsquo;s adaptation performance on diverse domains. Despite advancements, a critical question arises: can we integrate inductive bias into the model? This is particularly relevant since the Transformer encoder in SAM inherently lacks spatial priors within image patches, potentially hindering the acquisition of high-level semantic information. In this paper, we propose NAS-LoRA, a new Parameter-Efficient Fine-Tuning (PEFT) method designed to bridge the semantic gap between pre-trained SAM and specialized domains. Specifically, NAS-LoRA incorporates a lightweight Neural Architecture Search (NAS) block between the encoder and decoder components of LoRA to dynamically optimize the prior knowledge integrated into weight updates. Furthermore, we propose a stage-wise optimization strategy to help the ViT encoder balance weight updates and architectural adjustments, facilitating the gradual learning of high-level semantic information. Various Experiments demonstrate our NAS-LoRA improves existing PEFT methods, while reducing training cost by 24.14% without increasing inference cost, highlighting the potential of NAS in enhancing PEFT for visual foundation models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03499v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03499v1">üìÑ Download PDF</a></p><hr><h3 id=modal-logical-neural-networkshttpsarxivorgabs251203491v1><a href=https://arxiv.org/abs/2512.03491v1>Modal Logical Neural Networks</a><a hidden class=anchor aria-hidden=true href=#modal-logical-neural-networkshttpsarxivorgabs251203491v1>#</a></h3><p><strong>Authors:</strong> Antonin Sulc
<strong>Venue:</strong> arXiv (2025)</p><p>We propose Modal Logical Neural Networks (MLNNs), a neurosymbolic framework that integrates deep learning with the formal semantics of modal logic, enabling reasoning about necessity and possibility. Drawing on Kripke semantics, we introduce specialized neurons for the modal operators $\Box$ and $\Diamond$ that operate over a set of possible worlds, enabling the framework to act as a differentiable ``logical guardrail.&rsquo;&rsquo; The architecture is highly flexible: the accessibility relation between worlds can either be fixed by the user to enforce known rules or, as an inductive feature, be parameterized by a neural network. This allows the model to optionally learn the relational structure of a logical system from data while simultaneously performing deductive reasoning within that structure.
This versatile construction is designed for flexibility. The entire framework is differentiable from end to end, with learning driven by minimizing a logical contradiction loss. This not only makes the system resilient to inconsistent knowledge but also enables it to learn nonlinear relationships that can help define the logic of a problem space. We illustrate MLNNs on four case studies: grammatical guardrailing, axiomatic detection of the unknown, multi-agent epistemic trust, and detecting constructive deception in natural language negotiation. These experiments demonstrate how enforcing or learning accessibility can increase logical consistency and interpretability without changing the underlying task architecture.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03491v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03491v1">üìÑ Download PDF</a></p><hr><h3 id=hybridized-mode-parametric-amplifier-in-kinetic-inductance-circuitshttpsarxivorgabs251203362v1><a href=https://arxiv.org/abs/2512.03362v1>Hybridized-Mode Parametric Amplifier in Kinetic-Inductance Circuits</a><a hidden class=anchor aria-hidden=true href=#hybridized-mode-parametric-amplifier-in-kinetic-inductance-circuitshttpsarxivorgabs251203362v1>#</a></h3><p><strong>Authors:</strong> Danial Davoudi, Abdul Mohamed, Shabir Barzanjeh
<strong>Venue:</strong> arXiv (2025)</p><p>Parametric amplification is essential for quantum measurement, enabling the amplification of weak microwave signals with minimal added noise. While Josephson-junction-based amplifiers have become standard in superconducting quantum circuits, their magnetic sensitivity, limited saturation power, and sub-kelvin operating requirements motivate the development of alternative nonlinear platforms. Here we demonstrate a two-mode kinetic-inductance parametric amplifier based on a pair of capacitively coupled Kerr-nonlinear resonators fabricated from NbTiN and NbN thin films. The distributed Kerr nonlinearity of these materials enables nondegenerate four-wave-mixing amplification with gains approaching 40 dB, gain-bandwidth products up to 6.9 MHz, and 1-dB compression powers two to three orders of magnitude higher than those of state-of-the-art Josephson amplifiers. A coupled-mode theoretical model accurately captures the pump-induced modification of the hybridized modes and quantitatively reproduces the observed signal and idler responses. The NbN device exhibits a significantly larger Kerr coefficient and superior gain-bandwidth performance, highlighting the advantages of high-kinetic-inductance materials. Our results establish coupled kinetic-inductance resonators as a robust platform for broadband, high-power, and magnetically resilient quantum-limited amplification, offering a scalable route for advanced readout in superconducting qubits, spin ensembles, quantum dots, and other microwave-quantum technologies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03362v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03362v1">üìÑ Download PDF</a></p><hr><h3 id=hierarchical-attention-for-sparse-volumetric-anomaly-detection-in-subclinical-keratoconushttpsarxivorgabs251203346v1><a href=https://arxiv.org/abs/2512.03346v1>Hierarchical Attention for Sparse Volumetric Anomaly Detection in Subclinical Keratoconus</a><a hidden class=anchor aria-hidden=true href=#hierarchical-attention-for-sparse-volumetric-anomaly-detection-in-subclinical-keratoconushttpsarxivorgabs251203346v1>#</a></h3><p><strong>Authors:</strong> Lynn Kandakji, William Woof, Nikolas Pontikos
<strong>Venue:</strong> arXiv (2025)</p><p>The detection of weak, spatially distributed anomalies in volumetric medical imaging remains a major challenge. The subtle, non-adjacent nature of early disease signals is often lost due to suboptimal architectural inductive biases: 2D/3D CNNs impose strong locality, while ViTs diffuse unconstrained global attention. This conflict leaves the optimal inductive structure for robust, sparse volumetric pattern recognition unresolved. This study presents a controlled comparison of sixteen modern deep learning architectures spanning 2D/3D convolutional, hybrid, and volumetric transformer families for subclinical keratoconus (SKC) detection from 3D anterior segment OCT volumes. We demonstrate that hierarchical attention models offer a superior and more parameter-efficient inductive bias, surpassing the performance of both 2D and 3D CNNs and ViTs. Our results show 21-23% higher sensitivity and specificity in the sparse anomaly (subclinical) regime. Mechanistic analyses reveal that this advantage stems from precise spatial scale alignment: hierarchical windowing produces effective receptive fields matched to the intermediate, multi-slice extent of subclinical abnormalities. This avoids excessive CNN locality and diffuse global attention. Attention-distance measurements confirm a key insight into architectural adaptation: the required spatial integration length shifts significantly based on the signal strength, with subclinical cases necessitating longer integration compared to both healthy and manifest disease states. Representational similarity and auxiliary age/sex prediction tasks further support the generalizability of these inductive principles. The findings provide design guidance for future volumetric anomaly detection systems, establishing hierarchical attention as a principled and effective approach for early pathological change analysis in 3D medical imaging.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03346v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03346v1">üìÑ Download PDF</a></p><hr><h3 id=the-seifert-van-kampen-theorem-via-computational-paths-a-formalized-approach-to-computing-fundamental-groupshttpsarxivorgabs251203175v1><a href=https://arxiv.org/abs/2512.03175v1>The Seifert-van Kampen Theorem via Computational Paths: A Formalized Approach to Computing Fundamental Groups</a><a hidden class=anchor aria-hidden=true href=#the-seifert-van-kampen-theorem-via-computational-paths-a-formalized-approach-to-computing-fundamental-groupshttpsarxivorgabs251203175v1>#</a></h3><p><strong>Authors:</strong> Arthur F. Ramos, Tiago M. L. de Veras, Ruy J. G. B. de Queiroz, Anjolina G. de Oliveira
<strong>Venue:</strong> arXiv (2025)</p><p>The Seifert-van Kampen theorem computes the fundamental group of a space from the fundamental groups of its constituents. We formalize this theorem within the framework of computational paths, an approach to equality where witnesses are explicit sequences of rewrites governed by the confluent, terminating LNDEQ-TRS. Our contributions are: (i) pushouts as higher-inductive types with explicit path constructors; (ii) free products and amalgamated free products as quotients of word representations; (iii) an encode-decode proof establishing pi_1(Pushout(A, B, C), f, g) cong pi_1(A) *_{pi_1(C)} pi_1(B); and (iv) applications to the figure-eight (pi_1(S^1 v S^1) cong Z * Z) and 2-sphere (pi_1(S^2) cong 1). The framework makes coherence witnesses explicit as rewrite derivations. The development is formalized in Lean 4, where the pushout axioms and the encode map are assumed, while the decode map, amalgamation compatibility, and applications are fully mechanized (2050 lines). This demonstrates that the encode-decode method for higher-inductive types becomes fully constructive when path equality is decidable via normalization.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03175v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03175v1">üìÑ Download PDF</a></p><hr><h3 id=fluxlab-creating-3d-printable-shape-changing-devices-with-integrated-deformation-sensinghttpsarxivorgabs251202911v1><a href=https://arxiv.org/abs/2512.02911v1>FluxLab: Creating 3D Printable Shape-Changing Devices with Integrated Deformation Sensing</a><a hidden class=anchor aria-hidden=true href=#fluxlab-creating-3d-printable-shape-changing-devices-with-integrated-deformation-sensinghttpsarxivorgabs251202911v1>#</a></h3><p><strong>Authors:</strong> Hsuanling Lee, Jiakun Yu, Shurui Zheng, Te-Yan Wu, Liang He
<strong>Venue:</strong> arXiv (2025)</p><p>We present FluxLab, a system comprising interactive tools for creating custom 3D-printable shape-changing devices with integrated deformation sensing. To achieve this, we propose a 3D printable nesting structure, consisting of a central SMA channel for sensing and actuation, lattice-based padding in the middle for structural support and controllable elasticity, and parallel helix-based surface wires that preserve the overall form and provide anchoring struts for guided deformation. We developed a design editor to embed these structures into custom 3D models for printing with elastic silicone resin on a consumer-grade SLA 3D printer and minimal post-printing assembly. A deformation authoring tool was also developed for users to build a machine learning-based classifier that distinguishes desired deformation behaviors using inductive sensing. Finally, we demonstrate the potential of our system through example applications, including a self-deformable steamer bowl clip, a remotely controllable gripper, and an interactive desk lamp.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02911v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02911v1">üìÑ Download PDF</a></p><hr><h3 id=vessel-network-topology-in-molecular-communication-insights-from-experiments-and-theoryhttpsarxivorgabs251202811v1><a href=https://arxiv.org/abs/2512.02811v1>Vessel Network Topology in Molecular Communication: Insights from Experiments and Theory</a><a hidden class=anchor aria-hidden=true href=#vessel-network-topology-in-molecular-communication-insights-from-experiments-and-theoryhttpsarxivorgabs251202811v1>#</a></h3><p><strong>Authors:</strong> Timo Jakumeit, Lukas Brand, Jens Kirchner, Robert Schober, Sebastian Lotter
<strong>Venue:</strong> arXiv (2025)</p><p>The notion of synthetic molecular communication (MC) refers to the transmission of information via signaling molecules and is foreseen to enable innovative medical applications in the human cardiovascular system (CVS). Crucially, the design of such applications requires accurate and experimentally validated channel models that characterize the propagation of signaling molecules, not just in individual blood vessels, but in complex vessel networks (VNs), as prevalent in the CVS. However, experimentally validated models for MC in VNs remain scarce. To address this gap, we propose a novel channel model for MC in complex VN topologies, which captures molecular transport via advection, molecular and turbulent diffusion, as well as adsorption and desorption at the vessel walls. We specialize this model for superparamagnetic iron-oxide nanoparticles (SPIONs) as signaling molecules by introducing a new receiver (RX) model for planar coil inductive sensors, enabling end-to-end experimental validation with a dedicated SPION testbed. Validation covers a range of channel topologies, from single-vessel topologies to branched VNs with multiple paths between transmitter (TX) and RX. Additionally, to quantify how the VN topology impacts signal quality, and inspired by multi-path propagation models in conventional wireless communications, we introduce two metrics, namely molecule delay and multi-path spread. We show that these metrics link the VN structure to molecule dispersion induced by the VN and mediately to the resulting signal-to-noise ratio (SNR) at the RX. The proposed VN structure-SNR link is validated experimentally, demonstrating that the proposed framework can support tasks such as optimal sensor placement in the CVS or the identification of suitable testbed topologies for specific SNR requirements. All experimental data are openly available on Zenodo.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02811v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02811v1">üìÑ Download PDF</a></p><hr><h3 id=df-mamba-deformable-state-space-modeling-for-3d-hand-pose-estimation-in-interactionshttpsarxivorgabs251202727v1><a href=https://arxiv.org/abs/2512.02727v1>DF-Mamba: Deformable State Space Modeling for 3D Hand Pose Estimation in Interactions</a><a hidden class=anchor aria-hidden=true href=#df-mamba-deformable-state-space-modeling-for-3d-hand-pose-estimation-in-interactionshttpsarxivorgabs251202727v1>#</a></h3><p><strong>Authors:</strong> Yifan Zhou, Takehiko Ohkawa, Guwenxiao Zhou, Kanoko Goto, Takumi Hirose, Yusuke Sekikawa, Nakamasa Inoue
<strong>Venue:</strong> arXiv (2025)</p><p>Modeling daily hand interactions often struggles with severe occlusions, such as when two hands overlap, which highlights the need for robust feature learning in 3D hand pose estimation (HPE). To handle such occluded hand images, it is vital to effectively learn the relationship between local image features (e.g., for occluded joints) and global context (e.g., cues from inter-joints, inter-hands, or the scene). However, most current 3D HPE methods still rely on ResNet for feature extraction, and such CNN&rsquo;s inductive bias may not be optimal for 3D HPE due to its limited capability to model the global context. To address this limitation, we propose an effective and efficient framework for visual feature extraction in 3D HPE using recent state space modeling (i.e., Mamba), dubbed Deformable Mamba (DF-Mamba). DF-Mamba is designed to capture global context cues beyond standard convolution through Mamba&rsquo;s selective state modeling and the proposed deformable state scanning. Specifically, for local features after convolution, our deformable scanning aggregates these features within an image while selectively preserving useful cues that represent the global context. This approach significantly improves the accuracy of structured 3D HPE, with comparable inference speed to ResNet-50. Our experiments involve extensive evaluations on five divergent datasets including single-hand and two-hand scenarios, hand-only and hand-object interactions, as well as RGB and depth-based estimation. DF-Mamba outperforms the latest image backbones, including VMamba and Spatial-Mamba, on all datasets and achieves state-of-the-art performance.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02727v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02727v1">üìÑ Download PDF</a></p><hr><h3 id=popsim-social-network-simulation-for-social-media-popularity-predictionhttpsarxivorgabs251202533v1><a href=https://arxiv.org/abs/2512.02533v1>PopSim: Social Network Simulation for Social Media Popularity Prediction</a><a hidden class=anchor aria-hidden=true href=#popsim-social-network-simulation-for-social-media-popularity-predictionhttpsarxivorgabs251202533v1>#</a></h3><p><strong>Authors:</strong> Yijun Liu, Wu Liu, Xiaoyan Gu, Allen He, Weiping Wang, Yongdong Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>Accurately predicting the popularity of user-generated content (UGC) is essential for advancing social media analytics and recommendation systems. Existing approaches typically follow an inductive paradigm, where researchers train static models on historical data for popularity prediction. However, the UGC propagation is inherently a dynamic process, and static modeling based on historical features fails to capture the complex interactions and nonlinear evolution. In this paper, we propose PopSim, a novel simulation-based paradigm for social media popularity prediction (SMPP). Unlike the inductive paradigm, PopSim leverages the large language models (LLMs)-based multi-agent social network sandbox to simulate UGC propagation dynamics for popularity prediction. Specifically, to effectively model the UGC propagation process in the network, we design a social-mean-field-based agent interaction mechanism, which models the dual-channel and bidirectional individual-population interactions, enhancing agents&rsquo; global perception and decision-making capabilities. In addition, we propose a multi-source information aggregation module that transforms heterogeneous social metadata into a uniform formulation for LLMs. Finally, propagation dynamics with multimodal information are fused to provide comprehensive popularity prediction. Extensive experiments on real-world datasets demonstrate that SimPop consistently outperforms the state-of-the-art methods, reducing prediction error by an average of 8.82%, offering a new perspective for research on the SMPP task.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02533v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02533v1">üìÑ Download PDF</a></p><hr><h3 id=inductive-limits-of-partial-crossed-productshttpsarxivorgabs251202525v1><a href=https://arxiv.org/abs/2512.02525v1>Inductive limits of partial crossed products</a><a hidden class=anchor aria-hidden=true href=#inductive-limits-of-partial-crossed-productshttpsarxivorgabs251202525v1>#</a></h3><p><strong>Authors:</strong> Md Amir Hossain
<strong>Venue:</strong> arXiv (2025)</p><p>Let $\big((A^{(i)}, G, Œ±^{(i)}), œÜ_i\big)<em>{i \in \mathbb{N}}$ be an inductive sequence of partial dynamical systems. We prove the existence of an induced partial action $Œ±$ of $G$ on the inductive limit $A=\varinjlim A^{(i)}$. We call $Œ±$ the inductive limit partial action. Furthermore, we show the corresponding partial crossed product $A\rtimes_Œ±G$ is canonically isomorphic to $\varinjlim A^{(i)}\rtimes</em>{Œ±^{(i)}}G$. We also study the globalization of the inductive limit partial action $Œ±$, its finite Rokhlin dimension and tracial states on $A\rtimes_Œ±G$.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02525v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02525v1">üìÑ Download PDF</a></p><hr><h3 id=representations-of-finite-matrix-monoidshttpsarxivorgabs251202226v1><a href=https://arxiv.org/abs/2512.02226v1>Representations of finite matrix monoids</a><a hidden class=anchor aria-hidden=true href=#representations-of-finite-matrix-monoidshttpsarxivorgabs251202226v1>#</a></h3><p><strong>Authors:</strong> Nate Harman, Andrew Snowden, Elad Zelingher
<strong>Venue:</strong> arXiv (2025)</p><p>Let $\mathfrak{M}_n$ be the multiplicative monoid of $n \times n$ matrices over a finite field. The monoid algebra $\mathbf{C}[\mathfrak{M}_n]$ has been studied for several decades. One of the important early results is Kov√°cs&rsquo; theorem that the two-sided ideal spanned by matrices of rank at most $r$ has a unit. Our most significant result is an explicit formula for this unit. Prior to our work, such a formula was only known in a few examples. We also study the module theory of $\mathbf{C}[\mathfrak{M}_n]$. We explicitly describe the simple modules, and establish induction and restriction rules. We show that the simple decomposition of an arbitrary module can be determined using character theory of finite general linear groups; this relies on a Pieri rule of Gurevich&ndash;Howe. We also establish a version of Schur&ndash;Weyl duality for $\mathbf{C}[\mathfrak{M}_n]$. Many of these results hold over more general coefficient fields.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02226v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02226v1">üìÑ Download PDF</a></p><hr><h3 id=multifractal-recalibration-of-neural-networks-for-medical-imaging-segmentationhttpsarxivorgabs251202198v1><a href=https://arxiv.org/abs/2512.02198v1>Multifractal Recalibration of Neural Networks for Medical Imaging Segmentation</a><a hidden class=anchor aria-hidden=true href=#multifractal-recalibration-of-neural-networks-for-medical-imaging-segmentationhttpsarxivorgabs251202198v1>#</a></h3><p><strong>Authors:</strong> Miguel L. Martins, Miguel T. Coimbra, Francesco Renna
<strong>Venue:</strong> arXiv (2025)</p><p>Multifractal analysis has revealed regularities in many self-seeding phenomena, yet its use in modern deep learning remains limited. Existing end-to-end multifractal methods rely on heavy pooling or strong feature-space decimation, which constrain tasks such as semantic segmentation. Motivated by these limitations, we introduce two inductive priors: Monofractal and Multifractal Recalibration. These methods leverage relationships between the probability mass of the exponents and the multifractal spectrum to form statistical descriptions of encoder embeddings, implemented as channel-attention functions in convolutional networks.
Using a U-Net-based framework, we show that multifractal recalibration yields substantial gains over a baseline equipped with other channel-attention mechanisms that also use higher-order statistics. Given the proven ability of multifractal analysis to capture pathological regularities, we validate our approach on three public medical-imaging datasets: ISIC18 (dermoscopy), Kvasir-SEG (endoscopy), and BUSI (ultrasound).
Our empirical analysis also provides insights into the behavior of these attention layers. We find that excitation responses do not become increasingly specialized with encoder depth in U-Net architectures due to skip connections, and that their effectiveness may relate to global statistics of instance variability.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02198v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02198v1">üìÑ Download PDF</a></p><hr><h3 id=dynamo-and-jet-interconnections-in-grmhd-simulations-of-black-hole-accretion-diskshttpsarxivorgabs251202129v1><a href=https://arxiv.org/abs/2512.02129v1>Dynamo and Jet interconnections in GRMHD simulations of black hole accretion disks</a><a hidden class=anchor aria-hidden=true href=#dynamo-and-jet-interconnections-in-grmhd-simulations-of-black-hole-accretion-diskshttpsarxivorgabs251202129v1>#</a></h3><p><strong>Authors:</strong> P. S. Santhiya, Pallavi Bhat, Prayush Kumar, Tushar Mondal, Indu K. Dihingia
<strong>Venue:</strong> arXiv (2025)</p><p>We present global 3D GRMHD simulations of black hole (BH) accretion disks designed to investigate how MRI-driven dynamo action regulates jet formation and evolution. Unlike standard SANE/MAD setups that impose a coherent large-scale poloidal loop, our &ldquo;sub-SANE&rdquo; initial conditions use multiple same-polarity small-scale magnetic loops. Rapid reconnection erases magnetic memory and enables large-scale dynamo to emerge early from MRI turbulence. We perform two such sub-SANE simulations at different BH spins ($a = 0.5, 0.9375$) and compare them with conventional SANE runs. The sub-SANE disks show regular large-scale dynamo cycles with periods of about ten orbits. Decomposition of the induction equation shows that the turbulent dynamo term is stronger in 3D compared to 2.5D and balances advection in the saturated state, confirming sustained large-scale field generation. These dynamo-generated fields are advected inward with minimal time lag, producing correlated peaks in both poloidal and toroidal field strengths from $r_{\rm max}$ to the horizon. Early in the evolution, these peaks imprint directly onto the jet&rsquo;s electromagnetic energy flux, indicating that the jet mirrors the dynamo wave. Though jets form at early times, the sub-SANE runs eventually undergo jet shutdown. We show that this occurs when the magnetic field at the horizon loses coherence, as quantified by a decline in the signed-to-unsigned flux ratio $\mathcal{C}_{\rm BH}$ below $\approx 0.6$. In contrast, the SANE reference case with similar accretion rate and horizon magnetic flux maintains high magnetic coherence because its initial large-scale field persists, allowing its jet to survive. Our results show that both dynamo-driven field evolution and horizon magnetic-field coherence critically regulate jet longevity, establishing a direct dynamo-jet connection in GRMHD disks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02129v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02129v1">üìÑ Download PDF</a></p><hr><h3 id=bounded-treewidth-multiple-context-free-grammars-and-downward-closureshttpsarxivorgabs251201973v2><a href=https://arxiv.org/abs/2512.01973v2>Bounded treewidth, multiple context-free grammars, and downward closures</a><a hidden class=anchor aria-hidden=true href=#bounded-treewidth-multiple-context-free-grammars-and-downward-closureshttpsarxivorgabs251201973v2>#</a></h3><p><strong>Authors:</strong> C. Aiswarya, Pascal Baumann, Prakash Saivasan, Lia Sch√ºtze, Georg Zetzsche
<strong>Venue:</strong> arXiv (2025)</p><p>The reachability problem in multi-pushdown automata (MPDA) has many applications in static analysis of recursive programs. An example is safety verification of multi-threaded recursive programs with shared memory. Since these problems are undecidable, the literature contains many decidable (and efficient) underapproximations of MPDA.
A uniform framework that captures many of these underapproximations is that of bounded treewidth (tw): To each execution of the MPDA, we associate a graph; then we consider the subset of all graphs that have a wt at most $k$, for some constant $k$. In fact, bounding tw is a generic approach to obtain classes of systems with decidable reachability, even beyond MPDA underapproximations. The resulting systems are also called MSO-definable bounded-tw systems.
While bounded tw is a powerful tool for reachability and similar types of analysis, the word languages (i.e. action sequences corresponding to executions) of these systems remain far from understood.
For the slight restriction of bounded special tw, or &ldquo;bounded-stw&rdquo; (which is equivalent to bounded tw on MPDA, and even includes all bounded-tw systems studied in the literature), this work reveals a connection with multiple context-free languages (MCFL), a concept from computational linguistics. We show that the word languages of MSO-definable bounded-stw systems are exactly the MCFL.
We exploit this connection to provide an optimal algorithm for computing downward closures (dcl) for MSO-definable bounded-stw systems. Computing dcl is a notoriously difficult task that has many applications in the verification of complex systems: As an example application, we show that in programs with dynamic spawning of MSO-definable bounded-stw processes, safety verification has the same complexity as in the case of processes with sequential recursive processes.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01973v2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01973v2">üìÑ Download PDF</a></p><hr><h3 id=exploring-human-perceptions-of-ai-responses-insights-from-a-mixed-methods-study-on-risk-mitigation-in-generative-modelshttpsarxivorgabs251201892v1><a href=https://arxiv.org/abs/2512.01892v1>Exploring Human Perceptions of AI Responses: Insights from a Mixed-Methods Study on Risk Mitigation in Generative Models</a><a hidden class=anchor aria-hidden=true href=#exploring-human-perceptions-of-ai-responses-insights-from-a-mixed-methods-study-on-risk-mitigation-in-generative-modelshttpsarxivorgabs251201892v1>#</a></h3><p><strong>Authors:</strong> Heloisa Candello, Muneeza Azmat, Uma Sushmitha Gunturi, Raya Horesh, Rogerio Abreu de Paula, Heloisa Pimentel, Marcelo Carpinette Grave, Aminat Adebiyi, Tiago Machado, Maysa Malfiza Garcia de Macedo
<strong>Venue:</strong> arXiv (2025)</p><p>With the rapid uptake of generative AI, investigating human perceptions of generated responses has become crucial. A major challenge is their `aptitude&rsquo; for hallucinating and generating harmful contents. Despite major efforts for implementing guardrails, human perceptions of these mitigation strategies are largely unknown. We conducted a mixed-method experiment for evaluating the responses of a mitigation strategy across multiple-dimensions: faithfulness, fairness, harm-removal capacity, and relevance. In a within-subject study design, 57 participants assessed the responses under two conditions: harmful response plus its mitigation and solely mitigated response. Results revealed that participants&rsquo; native language, AI work experience, and annotation familiarity significantly influenced evaluations. Participants showed high sensitivity to linguistic and contextual attributes, penalizing minor grammar errors while rewarding preserved semantic contexts. This contrasts with how language is often treated in the quantitative evaluation of LLMs. We also introduced new metrics for training and evaluating mitigation strategies and insights for human-AI evaluation studies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01892v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01892v1">üìÑ Download PDF</a></p><hr><h3 id=tahr-the-generative-attribute-grammar-frameworkhttpsarxivorgabs251201872v1><a href=https://arxiv.org/abs/2512.01872v1>Tahr: The Generative Attribute Grammar Framework</a><a hidden class=anchor aria-hidden=true href=#tahr-the-generative-attribute-grammar-frameworkhttpsarxivorgabs251201872v1>#</a></h3><p><strong>Authors:</strong> Matteo Ciccaglione, Pierciro Caliandro, Alessandro Pellegrini
<strong>Venue:</strong> arXiv (2025)</p><p>In this article, we present Tahr, a framework that allows taking attribute grammar specifications and generating a set of software artefacts that can be used programmatically to operate on text compliant with the grammars. Tahr can be used as an algorithmic workbench to test different manipulations of attribute grammars and support translation between different languages out of the box. We describe the framework&rsquo;s organisation, how the user can specify an attribute grammar, and the generated software artefacts. We also discuss how Tahr deals with ambiguous grammar specifications, and how this ambiguity can be effectively exploited when using attribute grammars for text generation. We test the correctness of Tahr by showing the practical possibility of translating MIPS programs into their corresponding equivalents for x86 architectures and a custom virtual machine.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01872v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01872v1">üìÑ Download PDF</a></p><hr><h3 id=testing-transformer-learnability-on-the-arithmetic-sequence-of-rooted-treeshttpsarxivorgabs251201870v1><a href=https://arxiv.org/abs/2512.01870v1>Testing Transformer Learnability on the Arithmetic Sequence of Rooted Trees</a><a hidden class=anchor aria-hidden=true href=#testing-transformer-learnability-on-the-arithmetic-sequence-of-rooted-treeshttpsarxivorgabs251201870v1>#</a></h3><p><strong>Authors:</strong> Alessandro Breccia, Federica Gerace, Marco Lippi, Gabriele Sicuro, Pierluigi Contucci
<strong>Venue:</strong> arXiv (2025)</p><p>We study whether a Large Language Model can learn the deterministic sequence of trees generated by the iterated prime factorization of the natural numbers. Each integer is mapped into a rooted planar tree and the resulting sequence $ \mathbb{N}\mathcal{T}$ defines an arithmetic text with measurable statistical structure. A transformer network (the GPT-2 architecture) is trained from scratch on the first $10^{11}$ elements to subsequently test its predictive ability under next-word and masked-word prediction tasks. Our results show that the model partially learns the internal grammar of $\mathbb{N}\mathcal{T}$, capturing non-trivial regularities and correlations. This suggests that learnability may extend beyond empirical data to the very structure of arithmetic.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01870v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01870v1">üìÑ Download PDF</a></p><hr><h3 id=vanishing-h1-for-hurwitz-spaces-of-fully-marked-admissible-covers-of-degree-3httpsarxivorgabs251201553v1><a href=https://arxiv.org/abs/2512.01553v1>Vanishing $H^1$ for Hurwitz spaces of fully-marked admissible covers of degree 3</a><a hidden class=anchor aria-hidden=true href=#vanishing-h1-for-hurwitz-spaces-of-fully-marked-admissible-covers-of-degree-3httpsarxivorgabs251201553v1>#</a></h3><p><strong>Authors:</strong> Amy Q. Li
<strong>Venue:</strong> arXiv (2025)</p><p>We show that the first cohomology group of the Hurwitz space of fully-marked admissible covers $H^1(\overline{\mathcal{H}}<em>{\underline{d},\underline{g}}(\underlineŒº))$ vanishes for covers of degree $ d = 3$ and deduce the same result for the classical Hurwitz space of simply-branched covers. In degree 4, we compute examples where $H^1(\overline{\mathcal{H}}</em>{\underline{4},\underline{g}}(\underlineŒº))$ is nonzero, which implies that $H^1(\overline{\mathcal{H}}<em>{\underline{d},\underline{g}}(\underlineŒº))$ is nonvanishing for $d \geq 4$. We describe the stratification of the boundary of $\overline{\mathcal{H}}</em>{\underline{d},\underline{g}}(\underlineŒº)$ by lower-dimensional $\overline{\mathcal{H}}<em>{\underline{d&rsquo;},\underline{g&rsquo;}}(\underline{Œº&rsquo;})$, and set up an inductive framework which may be used for future arguments involving the odd cohomology of $\overline{\mathcal{H}}</em>{\underline{d},\underline{g}}(\underlineŒº)$.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01553v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01553v1">üìÑ Download PDF</a></p><hr><h3 id=masked-symbol-modeling-for-demodulation-of-oversampled-baseband-communication-signals-in-impulsive-noise-dominated-channelshttpsarxivorgabs251201428v1><a href=https://arxiv.org/abs/2512.01428v1>Masked Symbol Modeling for Demodulation of Oversampled Baseband Communication Signals in Impulsive Noise-Dominated Channels</a><a hidden class=anchor aria-hidden=true href=#masked-symbol-modeling-for-demodulation-of-oversampled-baseband-communication-signals-in-impulsive-noise-dominated-channelshttpsarxivorgabs251201428v1>#</a></h3><p><strong>Authors:</strong> Oguz Bedir, Nurullah Sevim, Mostafa Ibrahim, Sabit Ekin
<strong>Venue:</strong> arXiv (2025)</p><p>Recent breakthroughs in natural language processing show that attention mechanism in Transformer networks, trained via masked-token prediction, enables models to capture the semantic context of the tokens and internalize the grammar of language. While the application of Transformers to communication systems is a burgeoning field, the notion of context within physical waveforms remains under-explored. This paper addresses that gap by re-examining inter-symbol contribution (ISC) caused by pulse-shaping overlap. Rather than treating ISC as a nuisance, we view it as a deterministic source of contextual information embedded in oversampled complex baseband signals. We propose Masked Symbol Modeling (MSM), a framework for the physical (PHY) layer inspired by Bidirectional Encoder Representations from Transformers methodology. In MSM, a subset of symbol aligned samples is randomly masked, and a Transformer predicts the missing symbol identifiers using the surrounding &ldquo;in-between&rdquo; samples. Through this objective, the model learns the latent syntax of complex baseband waveforms. We illustrate MSM&rsquo;s potential by applying it to the task of demodulating signals corrupted by impulsive noise, where the model infers corrupted segments by leveraging the learned context. Our results suggest a path toward receivers that interpret, rather than merely detect communication signals, opening new avenues for context-aware PHY layer design.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01428v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01428v1">üìÑ Download PDF</a></p><hr><h3 id=inductive-van-der-waals-force-between-two-quantum-loopshttpsarxivorgabs251201263v1><a href=https://arxiv.org/abs/2512.01263v1>Inductive van der Waals Force between Two Quantum Loops</a><a hidden class=anchor aria-hidden=true href=#inductive-van-der-waals-force-between-two-quantum-loopshttpsarxivorgabs251201263v1>#</a></h3><p><strong>Authors:</strong> Kicheon Kang
<strong>Venue:</strong> arXiv (2025)</p><p>We study the van der Waals-London force, which is typically associated with fluctuating dipoles in atoms, in a mesoscopic circuit consisting of two inductively coupled superconducting loops. We investigate the ``inductive" van der Waals-London interaction using both semiclassical and quantum electrodynamic (QED) approaches. The semiclassical model predicts a repulsive interaction due to anticorrelated current fluctuations. In contrast, the QED framework, which incorporates virtual photon exchange, reveals a predominantly attractive force. A key contribution comes from a state-independent two-photon exchange, which is absent in the semiclassical description and undetectable by spectroscopy. Our study introduces a new experimental platform for measuring the van der Waals force between individual artificial atoms via controlled mesoscopic circuits.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01263v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01263v1">üìÑ Download PDF</a></p><hr><h3 id=parameter-reduction-improves-vision-transformers-a-comparative-study-of-sharing-and-width-reductionhttpsarxivorgabs251201059v1><a href=https://arxiv.org/abs/2512.01059v1>Parameter Reduction Improves Vision Transformers: A Comparative Study of Sharing and Width Reduction</a><a hidden class=anchor aria-hidden=true href=#parameter-reduction-improves-vision-transformers-a-comparative-study-of-sharing-and-width-reductionhttpsarxivorgabs251201059v1>#</a></h3><p><strong>Authors:</strong> Anantha Padmanaban Krishna Kumar
<strong>Venue:</strong> arXiv (2025)</p><p>Although scaling laws and many empirical results suggest that increasing the size of Vision Transformers often improves performance, model accuracy and training behavior are not always monotonically increasing with scale. Focusing on ViT-B/16 trained on ImageNet-1K, we study two simple parameter-reduction strategies applied to the MLP blocks, each removing 32.7% of the baseline parameters. Our \emph{GroupedMLP} variant shares MLP weights between adjacent transformer blocks and achieves 81.47% top-1 accuracy while maintaining the baseline computational cost. Our \emph{ShallowMLP} variant halves the MLP hidden dimension and reaches 81.25% top-1 accuracy with a 38% increase in inference throughput. Both models outperform the 86.6M-parameter baseline (81.05%) and exhibit substantially improved training stability, reducing peak-to-final accuracy degradation from 0.47% to the range 0.03% to 0.06%. These results suggest that, for ViT-B/16 on ImageNet-1K with a standard training recipe, the model operates in an overparameterized regime in which MLP capacity can be reduced without harming performance and can even slightly improve it. More broadly, our findings suggest that architectural constraints such as parameter sharing and reduced width may act as useful inductive biases, and highlight the importance of how parameters are allocated when designing Vision Transformers. All code is available at: <a href=https://github.com/AnanthaPadmanaban-KrishnaKumar/parameter-efficient-vit-mlps>https://github.com/AnanthaPadmanaban-KrishnaKumar/parameter-efficient-vit-mlps</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01059v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01059v1">üìÑ Download PDF</a></p><hr><h3 id=a-word-sampler-for-well-typed-functionshttpsarxivorgabs251201036v1><a href=https://arxiv.org/abs/2512.01036v1>A Word Sampler for Well-Typed Functions</a><a hidden class=anchor aria-hidden=true href=#a-word-sampler-for-well-typed-functionshttpsarxivorgabs251201036v1>#</a></h3><p><strong>Authors:</strong> Breandan Considine
<strong>Venue:</strong> arXiv (2025)</p><p>We describe an exact sampler for a simply-typed, first-order functional programming language. Given an acyclic finite automaton, $Œ±_{\varnothing}$, it samples a random function uniformly without replacement from well-typed functions in $\mathcal{L}(Œ±_{\varnothing})$. This is achieved via a fixed-parameter tractable reduction from a syntax-directed type system to a context-free grammar, preserving type soundness and completeness w.r.t. $\mathcal{L}(Œ±_{\varnothing})$, while retaining the robust metatheory of formal languages.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01036v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01036v1">üìÑ Download PDF</a></p><hr><h3 id=triangular-arrays-using-context-free-grammarhttpsarxivorgabs251201005v1><a href=https://arxiv.org/abs/2512.01005v1>Triangular Arrays using context-free grammar</a><a hidden class=anchor aria-hidden=true href=#triangular-arrays-using-context-free-grammarhttpsarxivorgabs251201005v1>#</a></h3><p><strong>Authors:</strong> Voalaza Mahavily Romuald Aubert, Benjamin Randrianirina
<strong>Venue:</strong> arXiv (2025)</p><p>In this work, the grammar of Hao [ G={, u\rightarrow u^{b_1+b_2+1} v^{a_1+a_2},\quad v\rightarrow u^{b_2}v^{a_2+1} ,}, ] together with the correspondence between grammars and Combinatorial Differential Equations, is employed to obtain an interpretation of any triangular array of the form [ T(n,k)=(a_2 n + a_1 k + a_0),T(n-1,k) + (b_2 n + b_1 k + b_0),T(n-1,k-1). ] Explicit formulas and structural properties are then derived through Analytic Differential Equations. In particular, the $r$-Whitney&ndash;Eulerian numbers and the cases where $b_2n+b_1k+b_0=1$ are obtained explicitly. Applications include new interpretation formulas for the $r$-Eulerian numbers with generating function for a special case.
Keywords: triangular recurrence, formal grammar, Combinatorial operators, differential equations,$r$-Eulerian, combinatorial interpretation, $r$-Whitney&ndash;Eulerian.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01005v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01005v1">üìÑ Download PDF</a></p><hr><h3 id=games-with-infinite-pasthttpsarxivorgabs251201001v1><a href=https://arxiv.org/abs/2512.01001v1>Games with infinite past</a><a hidden class=anchor aria-hidden=true href=#games-with-infinite-pasthttpsarxivorgabs251201001v1>#</a></h3><p><strong>Authors:</strong> Galit Ashkenazi-Golan, J√°nos Flesch, Eilon Solan
<strong>Venue:</strong> arXiv (2025)</p><p>We study multi-player games with perfect information and general payoff function, where the set of stages is the set of non-positive integers ${\ldots,-2,-1,0}$. We define two related equilibrium concepts: one considering only deviations at finitely many stages and another considering all deviations. We show that (i) The sets of equilibrium plays coincide for the two equilibrium concepts, provided that at least two players are active along each infinite play. (ii) In win-lose games, the game has an equilibrium if the winning sets have Borel-rank at most 2, and we provide a counter-example showing that this is no longer true for Borel-rank 3. (iii) In general non-zero-sum games, the game has an equilibrium if the payoff functions are continuous, for example, with reversed-time discounted payoffs. The challenge for all these results is that not all strategy profiles admit a consistent infinite play, hampering the use of backward induction arguments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01001v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01001v1">üìÑ Download PDF</a></p><hr><h3 id=lahnet-local-attentive-hashing-network-for-point-cloud-registrationhttpsarxivorgabs251200927v1><a href=https://arxiv.org/abs/2512.00927v1>LAHNet: Local Attentive Hashing Network for Point Cloud Registration</a><a hidden class=anchor aria-hidden=true href=#lahnet-local-attentive-hashing-network-for-point-cloud-registrationhttpsarxivorgabs251200927v1>#</a></h3><p><strong>Authors:</strong> Wentao Qu, Xiaoshui Huang, Liang Xiao
<strong>Venue:</strong> arXiv (2025)</p><p>Most existing learning-based point cloud descriptors for point cloud registration focus on perceiving local information of point clouds to generate distinctive features. However, a reasonable and broader receptive field is essential for enhancing feature distinctiveness. In this paper, we propose a Local Attentive Hashing Network for point cloud registration, called LAHNet, which introduces a local attention mechanism with the inductive bias of locality of convolution-like operators into point cloud descriptors. Specifically, a Group Transformer is designed to capture reasonable long-range context between points. This employs a linear neighborhood search strategy, Locality-Sensitive Hashing, enabling uniformly partitioning point clouds into non-overlapping windows. Meanwhile, an efficient cross-window strategy is adopted to further expand the reasonable feature receptive field. Furthermore, building on this effective windowing strategy, we propose an Interaction Transformer to enhance the feature interactions of the overlap regions within point cloud pairs. This computes an overlap matrix to match overlap regions between point cloud pairs by representing each window as a global signal. Extensive results demonstrate that LAHNet can learn robust and distinctive features, achieving significant registration results on real-world indoor and outdoor benchmarks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00927v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00927v1">üìÑ Download PDF</a></p><hr><h3 id=partially-equivariant-reinforcement-learning-in-symmetry-breaking-environmentshttpsarxivorgabs251200915v1><a href=https://arxiv.org/abs/2512.00915v1>Partially Equivariant Reinforcement Learning in Symmetry-Breaking Environments</a><a hidden class=anchor aria-hidden=true href=#partially-equivariant-reinforcement-learning-in-symmetry-breaking-environmentshttpsarxivorgabs251200915v1>#</a></h3><p><strong>Authors:</strong> Junwoo Chang, Minwoo Park, Joohwan Seo, Roberto Horowitz, Jongmin Lee, Jongeun Choi
<strong>Venue:</strong> arXiv (2025)</p><p>Group symmetries provide a powerful inductive bias for reinforcement learning (RL), enabling efficient generalization across symmetric states and actions via group-invariant Markov Decision Processes (MDPs). However, real-world environments almost never realize fully group-invariant MDPs; dynamics, actuation limits, and reward design usually break symmetries, often only locally. Under group-invariant Bellman backups for such cases, local symmetry-breaking introduces errors that propagate across the entire state-action space, resulting in global value estimation errors. To address this, we introduce Partially group-Invariant MDP (PI-MDP), which selectively applies group-invariant or standard Bellman backups depending on where symmetry holds. This framework mitigates error propagation from locally broken symmetries while maintaining the benefits of equivariance, thereby enhancing sample efficiency and generalizability. Building on this framework, we present practical RL algorithms &ndash; Partially Equivariant (PE)-DQN for discrete control and PE-SAC for continuous control &ndash; that combine the benefits of equivariance with robustness to symmetry-breaking. Experiments across Grid-World, locomotion, and manipulation benchmarks demonstrate that PE-DQN and PE-SAC significantly outperform baselines, highlighting the importance of selective symmetry exploitation for robust and sample-efficient RL.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00915v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00915v1">üìÑ Download PDF</a></p><hr><h3 id=higher-derivative-estimates-for-stokes-equations-with-closely-spaced-rigid-inclusions-in-three-dimensionshttpsarxivorgabs251200866v1><a href=https://arxiv.org/abs/2512.00866v1>Higher derivative estimates for Stokes equations with closely spaced rigid inclusions in three dimensions</a><a hidden class=anchor aria-hidden=true href=#higher-derivative-estimates-for-stokes-equations-with-closely-spaced-rigid-inclusions-in-three-dimensionshttpsarxivorgabs251200866v1>#</a></h3><p><strong>Authors:</strong> Hongjie Dong, Haigang Li, Huaijun Teng, Peihao Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>In this paper, we establish higher-order derivative estimates for the Stokes equations in a three-dimensional domain containing two closely spaced rigid inclusions. We construct a sequence of auxiliary functions via an inductive process to isolate the leading singular terms of higher-order derivatives within the narrow region between the inclusions. For a class of convex inclusions of general shapes, the construction of three-dimensional auxiliary functions &ndash; unlike the two-dimensional case &ndash; relies on the decay properties of solutions to a class of two-dimensional partial differential equations with singular coefficients. Taking advantage of this, we obtain pointwise upper bounds of derivatives up to the seventh order for general inclusions. Under additional symmetry conditions, we derive optimal estimates for derivatives of arbitrary order. Consequently, we obtain precise blow-up rates for the Cauchy stress and its higher-order derivatives in the narrow region between the inclusions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00866v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00866v1">üìÑ Download PDF</a></p><hr><h3 id=charts-are-not-images-on-the-challenges-of-scientific-chart-editinghttpsarxivorgabs251200752v1><a href=https://arxiv.org/abs/2512.00752v1>Charts Are Not Images: On the Challenges of Scientific Chart Editing</a><a hidden class=anchor aria-hidden=true href=#charts-are-not-images-on-the-challenges-of-scientific-chart-editinghttpsarxivorgabs251200752v1>#</a></h3><p><strong>Authors:</strong> Shawn Li, Ryan Rossi, Sungchul Kim, Sunav Choudhary, Franck Dernoncourt, Puneet Mathur, Zhengzhong Tu, Yue Zhao
<strong>Venue:</strong> arXiv (2025)</p><p>Generative models, such as diffusion and autoregressive approaches, have demonstrated impressive capabilities in editing natural images. However, applying these tools to scientific charts rests on a flawed assumption: a chart is not merely an arrangement of pixels but a visual representation of structured data governed by a graphical grammar. Consequently, chart editing is not a pixel-manipulation task but a structured transformation problem. To address this fundamental mismatch, we introduce \textit{FigEdit}, a large-scale benchmark for scientific figure editing comprising over 30,000 samples. Grounded in real-world data, our benchmark is distinguished by its diversity, covering 10 distinct chart types and a rich vocabulary of complex editing instructions. The benchmark is organized into five distinct and progressively challenging tasks: single edits, multi edits, conversational edits, visual-guidance-based edits, and style transfer. Our evaluation of a range of state-of-the-art models on this benchmark reveals their poor performance on scientific figures, as they consistently fail to handle the underlying structured transformations required for valid edits. Furthermore, our analysis indicates that traditional evaluation metrics (e.g., SSIM, PSNR) have limitations in capturing the semantic correctness of chart edits. Our benchmark demonstrates the profound limitations of pixel-level manipulation and provides a robust foundation for developing and evaluating future structure-aware models. By releasing \textit{FigEdit} (<a href=https://github.com/adobe-research/figure-editing%29>https://github.com/adobe-research/figure-editing)</a>, we aim to enable systematic progress in structure-aware figure editing, provide a common ground for fair comparison, and encourage future research on models that understand both the visual and semantic layers of scientific charts.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00752v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00752v1">üìÑ Download PDF</a></p><hr><h3 id=ms-ppo-morphological-symmetry-equivariant-policy-for-legged-robot-locomotionhttpsarxivorgabs251200727v1><a href=https://arxiv.org/abs/2512.00727v1>MS-PPO: Morphological-Symmetry-Equivariant Policy for Legged Robot Locomotion</a><a hidden class=anchor aria-hidden=true href=#ms-ppo-morphological-symmetry-equivariant-policy-for-legged-robot-locomotionhttpsarxivorgabs251200727v1>#</a></h3><p><strong>Authors:</strong> Sizhe Wei, Xulin Chen, Fengze Xie, Garrett Ethan Katz, Zhenyu Gan, Lu Gan
<strong>Venue:</strong> arXiv (2025)</p><p>Reinforcement learning has recently enabled impressive locomotion capabilities on legged robots; however, most policy architectures remain morphology- and symmetry-agnostic, leading to inefficient training and limited generalization. This work introduces MS-PPO, a morphological-symmetry-equivariant policy learning framework that encodes robot kinematic structure and morphological symmetries directly into the policy network. We construct a morphology-informed graph neural architecture that is provably equivariant with respect to the robot&rsquo;s morphological symmetry group actions, ensuring consistent policy responses under symmetric states while maintaining invariance in value estimation. This design eliminates the need for tedious reward shaping or costly data augmentation, which are typically required to enforce symmetry. We evaluate MS-PPO in simulation on Unitree Go2 and Xiaomi CyberDog2 robots across diverse locomotion tasks, including trotting, pronking, slope walking, and bipedal turning, and further deploy the learned policies on hardware. Extensive experiments show that MS-PPO achieves superior training stability, symmetry generalization ability, and sample efficiency in challenging locomotion tasks, compared to state-of-the-art baselines. These findings demonstrate that embedding both kinematic structure and morphological symmetry into policy learning provides a powerful inductive bias for legged robot locomotion control. Our code will be made publicly available at <a href=https://lunarlab-gatech.github.io/MS-PPO/>https://lunarlab-gatech.github.io/MS-PPO/</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00727v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00727v1">üìÑ Download PDF</a></p><hr><h3 id=extended-abstract-synthesizable-low-overhead-circuit-level-countermeasures-and-pro-active-detection-techniques-for-power-and-em-scahttpsarxivorgabs251200635v1><a href=https://arxiv.org/abs/2512.00635v1>Extended Abstract: Synthesizable Low-overhead Circuit-level Countermeasures and Pro-Active Detection Techniques for Power and EM SCA</a><a hidden class=anchor aria-hidden=true href=#extended-abstract-synthesizable-low-overhead-circuit-level-countermeasures-and-pro-active-detection-techniques-for-power-and-em-scahttpsarxivorgabs251200635v1>#</a></h3><p><strong>Authors:</strong> Archisman Ghosh
<strong>Venue:</strong> arXiv (2025)</p><p>The gamut of todays internet-connected embedded devices has led to increased concerns regarding the security and confidentiality of data. Most internet-connected embedded devices employ mathematically secure cryptographic algorithms to address security vulnerabilities. Despite such mathematical guarantees, as these algorithms are often implemented in silicon, they leak critical information in terms of power consumption, electromagnetic (EM) radiation, timing, cache hits and misses, photonic emission and so on, leading to side-channel analysis (SCA) attacks. This thesis focuses on low overhead generic circuit-level yet synthesizable countermeasures against power and EM SCA. Existing countermeasures (including proposed) still have relatively high overhead which bars them from being used in energy-constraint IoT devices. We propose a zero-overhead integrated inductive sensor which is able to detect i)EM SCA ii) Clock glitch-based Fault Injection Attack (FIA), and iii) Voltage-glitch based Fault Injection Attack by using a simple ML algorithm. Advent of quantum computer research will open new possibilities for theoretical attacks against existing cryptographic protocols. National Institute of Standard & Technology (NIST) has standardized post-quantum cryptographic algorithms to secure crypto-systems against quantum adversary. I contribute to the standardization procedure by introducing the first silicon-verified Saber (a NIST finalist modulo Learning with Rounding scheme) which consumes lowest energy and area till date amongst all the candidates.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00635v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00635v1">üìÑ Download PDF</a></p><hr><h3 id=prism-a-minimal-compositional-metalanguage-for-specifying-agent-behaviorhttpsarxivorgabs251200611v1><a href=https://arxiv.org/abs/2512.00611v1>Prism: A Minimal Compositional Metalanguage for Specifying Agent Behavior</a><a hidden class=anchor aria-hidden=true href=#prism-a-minimal-compositional-metalanguage-for-specifying-agent-behaviorhttpsarxivorgabs251200611v1>#</a></h3><p><strong>Authors:</strong> Franck Binard, Vanja Kljajevic
<strong>Venue:</strong> arXiv (2025)</p><p>Prism is a small, compositional metalanguage for specifying the behaviour of tool-using software agents. Rather than introducing ad hoc control constructs, Prism is built around a fixed core context, Core1, which provides a minimal background grammar of categories numbers, strings, user prompts, tools together with abstract combinators for booleans, predicates, pairs, and lists. Agent policies are written as ordinary expressions using a single abstraction operator so that conditionals appear as selections between alternatives instead of imperative if-else blocks. Domains extend the core by defining their own context-mini-grammars that introduce new categories, predicates, and external tools while reusing the same compositional machinery. We illustrate this with worked examples from thermostat control, home security, e-commerce recommendation, and medical monitoring, showing how natural language decision rules can be mapped to inspectable, executable policies. From a linguistic perspective, Prism enforces a clear separation between a reusable grammar-like core and domain specific lexicons and treats tools as bridges between internal policy representations and the external world. From an engineering perspective, it offers a compact interface language for agent control, making the space of possible actions explicit and amenable to analysis, verification, and safety constraints.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.00611v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.00611v1">üìÑ Download PDF</a></p><hr><h2 id=-psycholinguistics>üîç psycholinguistics<a hidden class=anchor aria-hidden=true href=#-psycholinguistics>#</a></h2><h3 id=high-fidelity-qubit-control-in-a-natural-si-mos-quantum-dot-using-a-300-mm-silicon-on-insulator-waferhttpsarxivorgabs251205052v1><a href=https://arxiv.org/abs/2512.05052v1>High Fidelity Qubit Control in a Natural Si-MOS Quantum Dot using a 300 mm Silicon on Insulator Wafer</a><a hidden class=anchor aria-hidden=true href=#high-fidelity-qubit-control-in-a-natural-si-mos-quantum-dot-using-a-300-mm-silicon-on-insulator-waferhttpsarxivorgabs251205052v1>#</a></h3><p><strong>Authors:</strong> Xander Peetroons, Xunyao Luo, Tsung-Yeh Yang, Normann Mertig, Sofie Beyne, Julien Jussot, Yosuke Shimura, Clement Godfrin, Bart Raes, Ruoyu Li, Roger Loo, Sylvain Baudot, Stefan Kubicek, Shuchi Kaushik, Danny Wan, Takeru Utsugi, Takuma Kuno, Noriyuki Lee, Itaru Yanagi, Toshiyuki Mine, Satoshi Muraoka, Shinichi Saito, Digh Hisamoto, Ryuta Tsuchiya, Hiroyuki Mizuno, Kristiaan De Greve, Charles Smith, Helena Knowles, Andrew Ramsay
<strong>Venue:</strong> arXiv (2025)</p><p>We demonstrate high-fidelity single qubit control in a natural Si-MOS quantum dot fabricated in an industrial 300 mm wafer process on a silicon on insulator (SOI) wafer using electron spin resonance. A relatively high optimal Rabi frequency of 5 MHz is achieved, dynamically decoupling the electron spin from its 29-Si environment. Tracking the qubit frequency reduces the impact of low frequency noise in the qubit frequency and improves the $T^{Rabi}$ from 7 to 11 $Œº$s at a Rabi frequency of 5 MHz, resulting in Q-factors exceeding 50. Randomized benchmarking returns an average single gate control fidelity of 99.5 $\pm$ 0.3%. As a result of pulse-area calibration, this fidelity is limited by the Rabi Q-factor. These results show that a fast Rabi frequency, low charge noise, and a feedback protocol enable high fidelity in these Si-MOS devices, despite the low-frequency magnetic noise.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05052v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05052v1">üìÑ Download PDF</a></p><hr><h3 id=expanding-the-neutral-atom-gate-set-native-iswap-and-exchange-gates-from-dipolar-rydberg-interactionshttpsarxivorgabs251205037v1><a href=https://arxiv.org/abs/2512.05037v1>Expanding the Neutral Atom Gate Set: Native iSWAP and Exchange Gates from Dipolar Rydberg Interactions</a><a hidden class=anchor aria-hidden=true href=#expanding-the-neutral-atom-gate-set-native-iswap-and-exchange-gates-from-dipolar-rydberg-interactionshttpsarxivorgabs251205037v1>#</a></h3><p><strong>Authors:</strong> Pedro Ildefonso, Andrew Byun, Aleksei Konovalov, Javad Kazemi, Michael Schuler, Wolfgang Lechner
<strong>Venue:</strong> arXiv (2025)</p><p>We present a native realization of iSWAP and parameterized exchange gates for neutral atom quantum processing units. Our approach leverages strong dipole-dipole interactions between two dipole-coupled Rydberg states, and employs optimal control techniques to design time-efficient, high-fidelity gate protocols. To minimize experimental complexity, we utilize global driving terms acting identically on all atoms. We implement a noise-aware pulse selection strategy to identify candidate protocols with reduced susceptibility to certain noise sources, then analyze their performance under realistic noise sources &ndash; including atomic motion, Rydberg decay, and experimentally motivated laser phase and intensity noise. For a $^{88}$Sr-based architecture, we demonstrate fast iSWAP gate protocols which exceed fidelities of $99.9%$ under realistic experimental conditions. These results pave the way for expanding the neutral atom gate set beyond typical Rydberg blockade-based entangling gates.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05037v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05037v1">üìÑ Download PDF</a></p><hr><h3 id=engineered-inclined-energy-landscapes-enabling-free-flow-of-magnetic-microstructures-for-artificial-neuron-applicationshttpsarxivorgabs251205020v1><a href=https://arxiv.org/abs/2512.05020v1>Engineered Inclined Energy Landscapes Enabling Free Flow of Magnetic Microstructures for Artificial Neuron Applications</a><a hidden class=anchor aria-hidden=true href=#engineered-inclined-energy-landscapes-enabling-free-flow-of-magnetic-microstructures-for-artificial-neuron-applicationshttpsarxivorgabs251205020v1>#</a></h3><p><strong>Authors:</strong> Anmol Sharma, Ranjeet Kumar Brajpuriya, Vivek K. Malik, Vishakha Kaushik, Sachin Pathak
<strong>Venue:</strong> arXiv (2025)</p><p>Spintronic-based brain-inspired neuromorphic computing has recently attracted significant attention due to the exceptional properties of magnetic microstructures, including nanoscale dimensions, high stability, and low energy consumption. Despite these advantages, the practical integration of such microstructures into functional devices remains challenging. Fabrication processes are often complex and prone to stochastic effects, such as unwanted pinning and thermal-induced instabilities, which limit device reliability and scalability. Addressing these challenges is crucial for advancing spintronic neuromorphic architectures toward real-world applications. Thus, to reduce these effects we have proposed a design which is experimentally feasible and require less energy as compared to existing one. By engineering the system anisotropy into a sawtooth-type energy landscape, we have achieved free flow of these microstructures and successfully emulated integrate and fire (IF) function of biological neuron. Thus, proposed design presents an experimentally reliable and energy efficient external stimuli approach for tailoring magnetic microstructures dynamic behaviours, resulting in low energy consumption of 23.66 fJ per spike paving the way for the development of skyrmion-based futuristic neuromorphic computing device applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05020v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05020v1">üìÑ Download PDF</a></p><hr><h3 id=risk-aversion-of-insider-and-dynamic-asymmetric-informationhttpsarxivorgabs251205011v1><a href=https://arxiv.org/abs/2512.05011v1>Risk aversion of insider and dynamic asymmetric information</a><a hidden class=anchor aria-hidden=true href=#risk-aversion-of-insider-and-dynamic-asymmetric-informationhttpsarxivorgabs251205011v1>#</a></h3><p><strong>Authors:</strong> Albina Danilova, Valentin Lizhdvoy
<strong>Venue:</strong> arXiv (2025)</p><p>This paper studies a Kyle-Back model with a risk-averse insider possessing exponential utility and a dynamic stochastic signal about the asset&rsquo;s terminal fundamental value. While the existing literature considers either risk-neutral insiders with dynamic signals or risk-averse insiders with static signals, we establish equilibrium when both features are present. Our approach imposes no restrictions on the magnitude of the risk aversion parameter, extending beyond previous work that requires sufficiently small risk aversion. We employ a weak conditioning methodology to construct a Schr√∂dinger bridge between the insider&rsquo;s signal and the asset price process, an approach that naturally accommodates stochastic signal evolution and removes risk aversion constraints.
We derive necessary conditions for equilibrium, showing that the optimal insider strategy must be continuous with bounded variation. Under these conditions, we characterize the market-maker pricing rule and insider strategy that achieve equilibrium. We obtain explicit closed-form solutions for important cases including deterministic and quadratic signal volatilities, demonstrating the tractability of our framework.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05011v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05011v1">üìÑ Download PDF</a></p><hr><h3 id=a-dynamic-memory-assignment-strategy-for-dilation-based-icp-algorithm-on-embedded-gpushttpsarxivorgabs251204996v1><a href=https://arxiv.org/abs/2512.04996v1>A dynamic memory assignment strategy for dilation-based ICP algorithm on embedded GPUs</a><a hidden class=anchor aria-hidden=true href=#a-dynamic-memory-assignment-strategy-for-dilation-based-icp-algorithm-on-embedded-gpushttpsarxivorgabs251204996v1>#</a></h3><p><strong>Authors:</strong> Qiong Chang, Weimin Wang, Junpei Zhong, Jun Miyazaki
<strong>Venue:</strong> arXiv (2025)</p><p>This paper proposes a memory-efficient optimization strategy for the high-performance point cloud registration algorithm VANICP, enabling lightweight execution on embedded GPUs with constrained hardware resources. VANICP is a recently published acceleration framework that significantly improves the computational efficiency of point-cloud-based applications. By transforming the global nearest neighbor search into a localized process through a dilation-based information propagation mechanism, VANICP greatly reduces the computational complexity of the NNS. However, its original implementation demands a considerable amount of memory, which restricts its deployment in resource-constrained environments such as embedded systems. To address this issue, we propose a GPU-oriented dynamic memory assignment strategy that optimizes the memory usage of the dilation operation. Furthermore, based on this strategy, we construct an enhanced version of the VANICP framework that achieves over 97% reduction in memory consumption while preserving the original performance. Source code is published on: <a href=https://github.com/changqiong/VANICP4Em.git>https://github.com/changqiong/VANICP4Em.git</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04996v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04996v1">üìÑ Download PDF</a></p><hr><h3 id=parametric-disjunctive-timed-networkshttpsarxivorgabs251204991v1><a href=https://arxiv.org/abs/2512.04991v1>Parametric disjunctive timed networks</a><a hidden class=anchor aria-hidden=true href=#parametric-disjunctive-timed-networkshttpsarxivorgabs251204991v1>#</a></h3><p><strong>Authors:</strong> √âtienne Andr√©, Swen Jacobs, Engel Lefaucheux
<strong>Venue:</strong> arXiv (2025)</p><p>We consider distributed systems with an arbitrary number of processes, modelled by timed automata that communicate through location guards: a process can take a guarded transition if at least one other process is in a given location. In this work, we introduce parametric disjunctive timed networks, where each timed automaton may contain timing parameters, i.e. unknown constants. We investigate two problems: deciding the emptiness of the set of parameter valuations for which</p><ol><li>a given location is reachable for at least one process (local property), and</li><li>a global state is reachable where all processes are in a given location (global property).
Our main positive result is that the first problem is decidable for networks of processes with a single clock and without invariants; this result holds for arbitrarily many timing parameters &ndash; a setting with few known decidability results. However, it becomes undecidable when invariants are allowed, or when considering global properties, even for systems with a single parameter. This highlights the significant expressive power of invariants in these networks. Additionally, we exhibit further decidable subclasses by restraining the syntax of guards and invariants.</li></ol><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04991v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04991v1">üìÑ Download PDF</a></p><hr><h3 id=towards-a-fully-automated-differential-textnnlo_textew-generator-for-lepton-collidershttpsarxivorgabs251204959v1><a href=https://arxiv.org/abs/2512.04959v1>Towards a Fully Automated Differential $\text{NNLO}_\text{EW}$ Generator for Lepton Colliders</a><a hidden class=anchor aria-hidden=true href=#towards-a-fully-automated-differential-textnnlo_textew-generator-for-lepton-collidershttpsarxivorgabs251204959v1>#</a></h3><p><strong>Authors:</strong> Alan Price, Frank Krauss
<strong>Venue:</strong> arXiv (2025)</p><p>Future proposed lepton collider experiments will reach unprecedented levels of accuracy. To ensure the success of these experiments, and to fully exploit their wealth of data, the precision of theory calculations must reach comparable or even better levels. One bottleneck in achieving this precision target lies in the systematic, process-independent inclusion of higher-order corrections at Next-to-Next-to-Leading Order in the electroweak coupling $\text{NNLO}_\text{EW}$ while ensuring the correct matching with modern all-orders resummation techniques. Here, we present a solution to this problem, based on the Yennie-Frautschi-Suura theorem, which employs a local infrared (IR) subtraction to remove divergences and its matching to an all-order resummation of the soft and soft-collinear logarithms.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04959v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04959v1">üìÑ Download PDF</a></p><hr><h3 id=bounds-on-maximal-leakage-over-bayesian-networkshttpsarxivorgabs251204955v1><a href=https://arxiv.org/abs/2512.04955v1>Bounds on Maximal Leakage over Bayesian Networks</a><a hidden class=anchor aria-hidden=true href=#bounds-on-maximal-leakage-over-bayesian-networkshttpsarxivorgabs251204955v1>#</a></h3><p><strong>Authors:</strong> Anuran Makur, Japneet Singh
<strong>Venue:</strong> arXiv (2025)</p><p>Maximal leakage quantifies the leakage of information from data $X \in \mathcal{X}$ due to an observation $Y$. While fundamental properties of maximal leakage, such as data processing, sub-additivity, and its connection to mutual information, are well-established, its behavior over Bayesian networks is not well-understood and existing bounds are primarily limited to binary $\mathcal{X}$. In this paper, we investigate the behavior of maximal leakage over Bayesian networks with finite alphabets. Our bounds on maximal leakage are established by utilizing coupling-based characterizations which exist for channels satisfying certain conditions. Furthermore, we provide more general conditions under which such coupling characterizations hold for $|\mathcal{X}| = 4$. In the course of our analysis, we also present a new simultaneous coupling result on maximal leakage exponents. Finally, we illustrate the effectiveness of the proposed bounds with some examples.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04955v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04955v1">üìÑ Download PDF</a></p><hr><h3 id=oxygen-isotope-constraints-on-the-importance-of-photochemical-processing-in-protoplanetary-diskshttpsarxivorgabs251204944v1><a href=https://arxiv.org/abs/2512.04944v1>Oxygen Isotope Constraints on the Importance of Photochemical Processing in Protoplanetary Disks</a><a hidden class=anchor aria-hidden=true href=#oxygen-isotope-constraints-on-the-importance-of-photochemical-processing-in-protoplanetary-diskshttpsarxivorgabs251204944v1>#</a></h3><p><strong>Authors:</strong> Fred J. Ciesla, Eric Van Clepper, Jennifer Bergner, Edwin Bergin
<strong>Venue:</strong> arXiv (2025)</p><p>Observations have revealed evidence of photochemical processing in protoplanetary disks. This processing occurs in the photon dominated layer, the optically thin regions of the disk high above the disk midplane. It remains unclear, however, how much this photochemical processing impacts the compositions of the planets and their building blocks within the disk. Here we use the oxygen isotopic compositions of Solar System solids, which has been attributed to photochemistry in the solar nebula, to quantitatively evaluate whether this processing could have produced the conditions needed to provide the diversity of compositions seen in the Solar System. We do this by modeling the chemical evolution while fine dust grows into the building blocks of the planets. We find that the oxygen isotopic evolution cannot be attributed to processing in the solar nebula and must instead be inherited from the parent molecular cloud. Further, our results indicate that the observed photochemical processing in protoplanetary disks does not significantly impact the compositions of planets that form within.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04944v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04944v1">üìÑ Download PDF</a></p><hr><h3 id=exploring-vibronic-dynamics-near-a-sloped-conical-intersection-with-trapped-rydberg-ionshttpsarxivorgabs251204941v1><a href=https://arxiv.org/abs/2512.04941v1>Exploring vibronic dynamics near a sloped conical intersection with trapped Rydberg ions</a><a hidden class=anchor aria-hidden=true href=#exploring-vibronic-dynamics-near-a-sloped-conical-intersection-with-trapped-rydberg-ionshttpsarxivorgabs251204941v1>#</a></h3><p><strong>Authors:</strong> Abdessamad Belfakir, Weibin Li
<strong>Venue:</strong> arXiv (2025)</p><p>We study spin-phonon coupled dynamics in the vicinity of a sloped conical intersection created by laser coupling the electronic (spin) and vibrational degrees of freedom of a pair of trapped Rydberg ions. We show that the shape of the potential energy surfaces can be engineered and controlled by exploiting the sideband transitions of the crystal vibration and dipole-dipole interactions between Rydberg ions in the Lamb-Dicke regime. Using the sideband transition, we realize a sloped conical intersection whose cone axis is only tilted along one spatial axis. When the phonon wavepacket is located in the potential minimum of the lower potential surface, the spin and phonon dynamics are largely frozen owing to the geometric phase effect. When starting from the upper potential surface, the electronic and phonon states tunnel to the lower potential surface, leading to a partial revival of the initial state. In contrast, the dynamics drastically change when the initial wavepackets are away from the conical intersection. The initial state is revived, and is almost entirely irrelevant to whether it is from the lower or upper potential surface. Complete Rabi oscillations of the adiabatic states are found when the wavepacket is initialized on the upper potential surface. The dynamics occur on the microsecond and nanometer scales, implying that Rydberg ions provide a platform for simulating nonadiabatic processes in the vicinity of a sloped conical intersection.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04941v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04941v1">üìÑ Download PDF</a></p><hr><h3 id=litevggt-boosting-vanilla-vggt-via-geometry-aware-cached-token-merginghttpsarxivorgabs251204939v1><a href=https://arxiv.org/abs/2512.04939v1>LiteVGGT: Boosting Vanilla VGGT via Geometry-aware Cached Token Merging</a><a hidden class=anchor aria-hidden=true href=#litevggt-boosting-vanilla-vggt-via-geometry-aware-cached-token-merginghttpsarxivorgabs251204939v1>#</a></h3><p><strong>Authors:</strong> Zhijian Shu, Cheng Lin, Tao Xie, Wei Yin, Ben Li, Zhiyuan Pu, Weize Li, Yao Yao, Xun Cao, Xiaoyang Guo, Xiao-Xiao Long
<strong>Venue:</strong> arXiv (2025)</p><p>3D vision foundation models like Visual Geometry Grounded Transformer (VGGT) have advanced greatly in geometric perception. However, it is time-consuming and memory-intensive for long sequences, limiting application to large-scale scenes beyond hundreds of images. To address this, we propose LiteVGGT, achieving up to 10x speedup and substantial memory reduction, enabling efficient processing of 1000-image scenes. We derive two key insights for 3D reconstruction: (1) tokens from local image regions have inherent geometric correlations, leading to high similarity and computational redundancy; (2) token similarity across adjacent network layers remains stable, allowing for reusable merge decisions. Guided by these, we design a simple yet efficient strategy, dubbed geometry-aware cached token merging. We analyze each token&rsquo;s geometric importance, optimizing anchor token selection to better preserve key information for reconstruction. We also cache and reuse merge indices across layers, substantially reducing latency with minimal accuracy impact. This strategy retains VGGT&rsquo;s core performance, enabling efficient fine-tuning and FP8 quantization for further gains. Extensive experiments validate LiteVGGT&rsquo;s effectiveness, scalability, and robustness. Project page: <a href=https://garlicba.github.io/LiteVGGT/>https://garlicba.github.io/LiteVGGT/</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04939v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04939v1">üìÑ Download PDF</a></p><hr><h3 id=distributional-properties-of-first-jump-times-of-cbi-processes-with-jump-sizes-in-given-borel-setshttpsarxivorgabs251204935v1><a href=https://arxiv.org/abs/2512.04935v1>Distributional properties of first jump times of CBI processes with jump sizes in given Borel sets</a><a hidden class=anchor aria-hidden=true href=#distributional-properties-of-first-jump-times-of-cbi-processes-with-jump-sizes-in-given-borel-setshttpsarxivorgabs251204935v1>#</a></h3><p><strong>Authors:</strong> Matyas Barczy, Sandra Palau, Yao Xue
<strong>Venue:</strong> arXiv (2025)</p><p>We derive an expression for the joint distribution function of the first jump times of a continuous state and continuous time branching process with immigration (CBI process) with jump sizes in given Borel sets having finite total L√©vy measures, which is defined as the sum of the measures appearing in the branching and immigration mechanisms of the CBI process in question. Our result generalizes a corresponding result of He and Li (2016), who considered this problem in case of a single Borel set having finite total L√©vy measure.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04935v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04935v1">üìÑ Download PDF</a></p><hr><h3 id=markov-renewal-single-photon-lidar-simulatorhttpsarxivorgabs251204924v1><a href=https://arxiv.org/abs/2512.04924v1>Markov-Renewal Single-Photon LiDAR Simulator</a><a hidden class=anchor aria-hidden=true href=#markov-renewal-single-photon-lidar-simulatorhttpsarxivorgabs251204924v1>#</a></h3><p><strong>Authors:</strong> Weijian Zhang, Prateek Chennuri, Hashan K. Weerasooriya, Bole Ma, Stanley H. Chan
<strong>Venue:</strong> arXiv (2025)</p><p>Single-photon LiDAR (SP-LiDAR) simulators face a dilemma: fast but inaccurate Poisson models or accurate but prohibitively slow sequential models. This paper breaks that compromise. We present a simulator that achieves both fidelity and speed by focusing on the critical, yet overlooked, component of simulation: the photon count statistics. Our key contribution is a Markov-renewal process (MRP) formulation that, for the first time, analytically predicts the mean and variance of registered photon counts under dead time. To make this MRP model computationally tractable, we introduce a spectral truncation rule that efficiently computes the complex covariance statistics. By proving the shift-invariance of the process, we extend this per-pixel model to full histogram cube generation via a precomputed lookup table. Our method generates 3D cubes indistinguishable from the sequential gold-standard, yet is orders of magnitude faster. This finally enables large-scale, physically-faithful data generation for learning-based SP-LiDAR reconstruction.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04924v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04924v1">üìÑ Download PDF</a></p><hr><h3 id=instantons-meet-resonances-unifying-two-seemingly-distinct-approaches-to-quantum-tunnelinghttpsarxivorgabs251204907v1><a href=https://arxiv.org/abs/2512.04907v1>Instantons meet resonances: Unifying two seemingly distinct approaches to quantum tunneling</a><a hidden class=anchor aria-hidden=true href=#instantons-meet-resonances-unifying-two-seemingly-distinct-approaches-to-quantum-tunnelinghttpsarxivorgabs251204907v1>#</a></h3><p><strong>Authors:</strong> Bj√∂rn Garbrecht, Nils Wagner
<strong>Venue:</strong> arXiv (2025)</p><p>In the study of quantum-mechanical tunneling processes, numerous approaches have been developed to determine the decay rate of states initially confined within a metastable potential region. Virtually all analytical treatments, however, fall into one of two superficially unrelated conceptual frameworks: the resonant-state approach and the instanton method. Whereas the concept of resonant states and their associated decay widths is grounded in physical reasoning by capturing the regime of uniform probability decay, the instanton method lacks a comparably clear physical interpretation. We demonstrate the equivalence of the two approaches, revealing that the contour-deformation prescription in the functional integral put forward by Callan and Coleman directly corresponds to the outgoing Gamow&ndash;Siegert boundary conditions defining resonant states.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04907v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04907v1">üìÑ Download PDF</a></p><hr><h3 id=channel-aware-multi-domain-feature-extraction-for-automatic-modulation-recognition-in-mimo-systemshttpsarxivorgabs251204899v1><a href=https://arxiv.org/abs/2512.04899v1>Channel-Aware Multi-Domain Feature Extraction for Automatic Modulation Recognition in MIMO Systems</a><a hidden class=anchor aria-hidden=true href=#channel-aware-multi-domain-feature-extraction-for-automatic-modulation-recognition-in-mimo-systemshttpsarxivorgabs251204899v1>#</a></h3><p><strong>Authors:</strong> Yunpeng Qu, Yazhou Sun, Bingyu Hui, Jintao Wang, Jian Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Automatic modulation recognition (AMR) is a key technology in non-cooperative communication systems, aiming to identify the modulation scheme from signals without prior information. Deep learning (DL)-based methods have gained wide attention due to their excellent performance, but research mainly focuses on single-input single-output (SISO) systems, with limited exploration for multiple-input multiple-output (MIMO) systems. The confounding effects of multi-antenna channels can interfere with the statistical properties of MIMO signals, making identification particularly challenging. To overcome these limitations, we propose a Channel-Aware Multi-Domain feature extraction (CAMD) framework for AMR in MIMO systems. Our CAMD framework reconstructs the transmitted signal through an efficient channel compensation module and achieves a more robust representation capability against channel interference by extracting and integrating multi-domain features, including intra-antenna temporal correlations and inter-antenna channel correlations. We have verified our method on the widely-used dataset, MIMOSig-Ref, with complex mobile channel environments. Extensive experiments confirm the performance advantages of CAMD over previous state-of-the-art methods.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04899v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04899v1">üìÑ Download PDF</a></p><hr><h3 id=anomaly-cancellation-and-one-loop-finiteness-of-6d-half-maximal-supergravitieshttpsarxivorgabs251205082v1><a href=https://arxiv.org/abs/2512.05082v1>Anomaly cancellation and one-loop finiteness of 6D half-maximal supergravities</a><a hidden class=anchor aria-hidden=true href=#anomaly-cancellation-and-one-loop-finiteness-of-6d-half-maximal-supergravitieshttpsarxivorgabs251205082v1>#</a></h3><p><strong>Authors:</strong> Renata Kallosh
<strong>Venue:</strong> arXiv (2025)</p><p>We explain why the surprising one-loop finiteness of 6D half-maximal supergravities recently discovered by Huang et al [1] is the result of the cancellation of the six-dimensional gravitational and gauge anomalies in (2,0) supergravity with 21 tensor multiplets and (1,1) supergravity with 20 vector multiplets.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05082v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05082v1">üìÑ Download PDF</a></p><hr><h3 id=an-elementary-approach-to-wehrl-type-entropy-bounds-in-quantitative-formhttpsarxivorgabs251204245v1><a href=https://arxiv.org/abs/2512.04245v1>An elementary approach to Wehrl-type entropy bounds in quantitative form</a><a hidden class=anchor aria-hidden=true href=#an-elementary-approach-to-wehrl-type-entropy-bounds-in-quantitative-formhttpsarxivorgabs251204245v1>#</a></h3><p><strong>Authors:</strong> Fabio Nicola, Federico Riccardi, Paolo Tilli
<strong>Venue:</strong> arXiv (2025)</p><p>We consider the problem of the stability (with sharp exponent) of the Lieb&ndash;Solovej inequality for symmetric $SU(N)$ coherent states, which was obtained only recently by the authors. Here, we propose an elementary proof of this result, based on reformulating the Wehrl-type entropy as a function defined on the unit sphere in $\mathbb{C}^d$, for some suitable $d$, and on some explicit (and somewhat surprising) computations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04245v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04245v1">üìÑ Download PDF</a></p><hr><h3 id=counting-ads-vacuahttpsarxivorgabs251204151v1><a href=https://arxiv.org/abs/2512.04151v1>Counting AdS Vacua</a><a hidden class=anchor aria-hidden=true href=#counting-ads-vacuahttpsarxivorgabs251204151v1>#</a></h3><p><strong>Authors:</strong> Zihni Kaan Baykara, Alessandro Tomasiello, Cumrun Vafa
<strong>Venue:</strong> arXiv (2025)</p><p>We study the &rsquo;number&rsquo; $\mathfrak{N}(Œº)$ of AdS vacua with a UV cut off $ Œº$. It has been proposed that this number is finite. We find evidence that $\mathfrak{N}(Œº)\lesssim a \ Œº^{-b}$ as $Œº\rightarrow 0$ for some constants $a$ and $b$ of $O(1)$ in Planck units that may depend on dimension and the number of supercharges. For this result to hold it is crucial to integrate over the volume of massless and tachyonic directions of AdS which corresponds to the volume of the space of marginal and relevant deformations of the dual CFT. We are led to the surprising prediction that theories with large number of light moduli contribute very little to the volume measure among all theories. We also speculate about the dS case leading to the number of quasi-dS vacua of the order of $Œõ^{-Œ±}$ for some $O(1)$ parameter $Œ±$.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04151v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04151v1">üìÑ Download PDF</a></p><hr><h3 id=structure-theorems-for-the-heart-of-lcahttpsarxivorgabs251203338v1><a href=https://arxiv.org/abs/2512.03338v1>Structure theorems for the heart of LCA</a><a hidden class=anchor aria-hidden=true href=#structure-theorems-for-the-heart-of-lcahttpsarxivorgabs251203338v1>#</a></h3><p><strong>Authors:</strong> Oliver Braunling, Fei Ren
<strong>Venue:</strong> arXiv (2025)</p><p>Cohomology theories with values in LCA (locally compact abelian) groups suffer from the problem that the latter do not form an abelian category. However, the category LCA has a canonical abelian category envelope, the heart of a suitable t-structure. It adds formal cokernel objects. We show the surprising result that these abstract cokernels can also be interpreted as Hausdorff topological abelian groups, at least up to lattice isogenies. These need not be locally compact.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03338v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03338v1">üìÑ Download PDF</a></p><hr><h3 id=svrg-and-beyond-via-posterior-correctionhttpsarxivorgabs251201930v1><a href=https://arxiv.org/abs/2512.01930v1>SVRG and Beyond via Posterior Correction</a><a hidden class=anchor aria-hidden=true href=#svrg-and-beyond-via-posterior-correctionhttpsarxivorgabs251201930v1>#</a></h3><p><strong>Authors:</strong> Nico Daheim, Thomas M√∂llenhoff, Ming Liang Ang, Mohammad Emtiyaz Khan
<strong>Venue:</strong> arXiv (2025)</p><p>Stochastic Variance Reduced Gradient (SVRG) and its variants aim to speed-up training by using gradient corrections, but have seen limited success in deep learning. Here, we show surprising new foundational connections of SVRG to a recently proposed Bayesian method called posterior correction. Specifically, we show that SVRG is recovered as a special case of posterior correction over the isotropic-Gaussian family, while novel extensions are automatically obtained by using more flexible exponential families. We derive two new SVRG variants by using Gaussian families: First, a Newton-like variant that employs novel Hessian corrections, and second, an Adam-like extension that improves pretraining and finetuning of Transformer language models. This is the first work to connect SVRG to Bayes and use it to boost variational training for deep networks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01930v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01930v1">üìÑ Download PDF</a></p><hr><h3 id=graph-distance-as-surprise-free-energy-minimization-in-knowledge-graph-reasoninghttpsarxivorgabs251201878v1><a href=https://arxiv.org/abs/2512.01878v1>Graph Distance as Surprise: Free Energy Minimization in Knowledge Graph Reasoning</a><a hidden class=anchor aria-hidden=true href=#graph-distance-as-surprise-free-energy-minimization-in-knowledge-graph-reasoninghttpsarxivorgabs251201878v1>#</a></h3><p><strong>Authors:</strong> Gaganpreet Jhajj, Fuhua Lin
<strong>Venue:</strong> arXiv (2025)</p><p>In this work, we propose that reasoning in knowledge graph (KG) networks can be guided by surprise minimization. Entities that are close in graph distance will have lower surprise than those farther apart. This connects the Free Energy Principle (FEP) from neuroscience to KG systems, where the KG serves as the agent&rsquo;s generative model. We formalize surprise using the shortest-path distance in directed graphs and provide a framework for KG-based agents. Graph distance appears in graph neural networks as message passing depth and in model-based reinforcement learning as world model trajectories. This work-in-progress study explores whether distance-based surprise can extend recent work showing that syntax minimizes surprise and free energy via tree structures.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01878v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01878v1">üìÑ Download PDF</a></p><hr><h3 id=an-hybrid-stochastic-newton-algorithm-for-logistic-regressionhttpsarxivorgabs251201790v1><a href=https://arxiv.org/abs/2512.01790v1>An hybrid stochastic Newton algorithm for logistic regression</a><a hidden class=anchor aria-hidden=true href=#an-hybrid-stochastic-newton-algorithm-for-logistic-regressionhttpsarxivorgabs251201790v1>#</a></h3><p><strong>Authors:</strong> Bernard Bercu, Luis Fredes, Em√©ric Gbaguidi
<strong>Venue:</strong> arXiv (2025)</p><p>In this paper, we investigate a second-order stochastic algorithm for solving large-scale binary classification problems. We propose to make use of a new hybrid stochastic Newton algorithm that includes two weighted components in the Hessian matrix estimation: the first one coming from the natural Hessian estimate and the second associated with the stochastic gradient information. Our motivation comes from the fact that both parts evaluated at the true parameter of logistic regression, are equal to the Hessian matrix. This new formulation has several advantages and it enables us to prove the almost sure convergence of our stochastic algorithm to the true parameter. Moreover, we significantly improve the almost sure rate of convergence to the Hessian matrix. Furthermore, we establish the central limit theorem for our hybrid stochastic Newton algorithm. Finally, we show a surprising result on the almost sure convergence of the cumulative excess risk.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01790v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01790v1">üìÑ Download PDF</a></p><hr><h3 id=spatial-structure-and-magnetism-of-a-spin-orbit-entangled-spin-1-coherent-spin-center-the-manganese-neutral-acceptor-in-a-iii-v-semiconductorhttpsarxivorgabs251201158v1><a href=https://arxiv.org/abs/2512.01158v1>Spatial structure and magnetism of a spin-orbit entangled spin-1 coherent spin center: the manganese neutral acceptor in a III-V semiconductor</a><a hidden class=anchor aria-hidden=true href=#spatial-structure-and-magnetism-of-a-spin-orbit-entangled-spin-1-coherent-spin-center-the-manganese-neutral-acceptor-in-a-iii-v-semiconductorhttpsarxivorgabs251201158v1>#</a></h3><p><strong>Authors:</strong> Julian Zanon, Michael E. Flatt√©
<strong>Venue:</strong> arXiv (2025)</p><p>A Mn dopant in a III-V semiconductor produces a highly-entangled, coherent triplet ground state not fully captured by single-determinant theories of electron structure. We directly construct an analytic form for its ground-state wavefunction, finding surprising spin-charge correlations not revealed by semiclassical calculations. Spin-correlated circulating currents associated with the dopant yield remarkably large magnetic fringe fields of $\sim$1$,Œº$T at distances of $\sim 10$~nm from Mn in GaAs, potentially detectable by NV-diamond magnetometry while the dopant spin coherently precesses.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01158v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01158v1">üìÑ Download PDF</a></p><hr><h3 id=a-sudden-fine-scale-bright-kernel-captured-by-hi-c-flare-during-an-m16-class-solar-flares-post-maximum-phasehttpsarxivorgabs251201140v1><a href=https://arxiv.org/abs/2512.01140v1>A sudden fine-scale bright kernel captured by Hi-C Flare during an M1.6-class solar flare&rsquo;s post-maximum phase</a><a hidden class=anchor aria-hidden=true href=#a-sudden-fine-scale-bright-kernel-captured-by-hi-c-flare-during-an-m16-class-solar-flares-post-maximum-phasehttpsarxivorgabs251201140v1>#</a></h3><p><strong>Authors:</strong> Sanjiv K. Tiwari, Navdeep K. Panesar, Ronald L. Moore, Sabrina L. Savage, Amy R. Winebarger, Genevieve D. Vigil, Juraj Lorincik, Vanessa Polito, Bart De Pontieu, Leon Golub, Ken Kobayashi, Patrick Champey, Jenna Samra, Anna Rankin, Robert W. Walsh, Crisel Suarez, Christopher S. Moore, Adam R. Kobelski, Jeffery W. Reep, Charles Kankelborg
<strong>Venue:</strong> arXiv (2025)</p><p>On April 17, 2024, the third successful Hi-C sounding rocket flight, Hi-C Flare, recorded coronal images in Fe XXI 129 A emission from 11 MK plasma during the post-maximum phase of an M1.6-class solar flare, achieving unprecedented spatial (~300 km) and temporal (1.3 s) resolutions. The flare started at 21:55 UT, peaked at 22:08 UT, and lasted ~40 minutes. Hi-C observed for over five minutes (22:15:45 to 22:21:25), starting roughly eight minutes after flare maximum. A sudden compact bright burst - 875 +/- 25 km wide, lasting 90 +/- 1.3 s, displaying a plane-of-sky motion of ~50 km/s toward the loop apex, and splitting into two toward the end - occurs near the foot of some post-flare loops. Its size and brightness are reminiscent of flare-ribbon kernels during a flare&rsquo;s rapid rise phase, kernels marking sites of sudden heating and hot plasma upflow, making its occurrence during the late phase surprising. Such isolated brightenings in a flare&rsquo;s post-maximum phase are rare, and have not been previously reported. The kernel was detected in all SDO/AIA channels. Its 1600 A light curve peaked ~50 s earlier than its 131 A light curve, similar to that of flare-ribbon kernels, albeit with a smaller delay of ~25 s, during the impulsive phase of the flare. In SDO/HMI magnetograms, the kernel sits in unipolar positive magnetic flux near an embedded clump of negative flux. Although localized magnetic reconnection within the kernel (a microflare) cannot be ruled out for its cause, the observations favor the localized brightening being an isolated, exceptionally late flare-ribbon kernel, resulting from an exceptionally late burst of the flare&rsquo;s coronal reconnection.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01140v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01140v1">üìÑ Download PDF</a></p><hr><h3 id=global-banks-spillovers-to-emerging-markets-macro-to-micro-transmissionhttpsarxivorgabs251201132v1><a href=https://arxiv.org/abs/2512.01132v1>Global Banks&rsquo; Spillovers to Emerging Markets: Macro to Micro Transmission</a><a hidden class=anchor aria-hidden=true href=#global-banks-spillovers-to-emerging-markets-macro-to-micro-transmissionhttpsarxivorgabs251201132v1>#</a></h3><p><strong>Authors:</strong> Luis Rodrigo Arnabal, Santiago Camara, Cecilia Dassatti
<strong>Venue:</strong> arXiv (2025)</p><p>This paper studies how shocks to global banks&rsquo; net worth transmit to Emerging Market Economies. Using the identification strategy of Ottonello and Song (2022), which isolates high-frequency surprises to banks&rsquo; credit supply capacity, we show that positive shocks appreciate local currencies, lower external borrowing costs, increase capital flows to domestic banking sectors, and raise investment, credit, and real activity across EMEs. These effects are highly robust across specifications and samples. Using administrative credit-registry data from Uruguay, we find that better capitalized banks transmit global credit easing more strongly. At the firm level, responses are weaker for more leveraged firms, especially those with foreign-currency debt, short maturities, or collateral not priced to market.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01132v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01132v1">üìÑ Download PDF</a></p><hr><h3 id=world-model-robustness-via-surprise-recognitionhttpsarxivorgabs251201119v1><a href=https://arxiv.org/abs/2512.01119v1>World Model Robustness via Surprise Recognition</a><a hidden class=anchor aria-hidden=true href=#world-model-robustness-via-surprise-recognitionhttpsarxivorgabs251201119v1>#</a></h3><p><strong>Authors:</strong> Geigh Zollicoffer, Tanush Chopra, Mingkuan Yan, Xiaoxu Ma, Kenneth Eaton, Mark Riedl
<strong>Venue:</strong> arXiv (2025)</p><p>AI systems deployed in the real world must contend with distractions and out-of-distribution (OOD) noise that can destabilize their policies and lead to unsafe behavior. While robust training can reduce sensitivity to some forms of noise, it is infeasible to anticipate all possible OOD conditions. To mitigate this issue, we develop an algorithm that leverages a world model&rsquo;s inherent measure of surprise to reduce the impact of noise in world model&ndash;based reinforcement learning agents. We introduce both multi-representation and single-representation rejection sampling, enabling robustness to settings with multiple faulty sensors or a single faulty sensor. While the introduction of noise typically degrades agent performance, we show that our techniques preserve performance relative to baselines under varying types and levels of noise across multiple environments within self-driving simulation domains (CARLA and Safety Gymnasium). Furthermore, we demonstrate that our methods enhance the stability of two state-of-the-art world models with markedly different underlying architectures: Cosmos and DreamerV3. Together, these results highlight the robustness of our approach across world modeling domains. We release our code at <a href=https://github.com/Bluefin-Tuna/WISER>https://github.com/Bluefin-Tuna/WISER</a> .</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01119v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01119v1">üìÑ Download PDF</a></p><hr><h3 id=non-reciprocal-interactions-between-condensates-in-chemically-active-mixtureshttpsarxivorgabs251123425v1><a href=https://arxiv.org/abs/2511.23425v1>Non-reciprocal interactions between condensates in chemically active mixtures</a><a hidden class=anchor aria-hidden=true href=#non-reciprocal-interactions-between-condensates-in-chemically-active-mixtureshttpsarxivorgabs251123425v1>#</a></h3><p><strong>Authors:</strong> Jacopo Romano, Martin Kj√∏llesdal Johnsrud, Beno√Æt Mahault, Ramin Golestanian
<strong>Venue:</strong> arXiv (2025)</p><p>We study the behaviour of catalytically active droplets in multi-component conserved mixtures affected by noise. Working in the thin interface limit, we analytically determine the state diagram of the system, characterized by multiple dynamical regimes, and verify our findings using numerical simulations. In particular, we show the emergence of a non-reciprocal, chemically-mediated interaction between the droplets, which leads to the formation of (meta-)stable clusters of droplets of different species. We find that the clusters can display self-propulsion in a large part of the parameter space, including regions where the non-reciprocal interactions between the droplets are purely attractive. This surprising feature arises from the non-local nature of the chemical interactions, and points to locality violations as a general mechanism for energy dissipation and emergence of out-of-equilibrium steady states in active matter.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2511.23425v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2511.23425v1">üìÑ Download PDF</a></p><hr><h3 id=splannequin-freezing-monocular-mannequin-challenge-footage-with-dual-detection-splattinghttpsarxivorgabs251205113v1><a href=https://arxiv.org/abs/2512.05113v1>Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting</a><a hidden class=anchor aria-hidden=true href=#splannequin-freezing-monocular-mannequin-challenge-footage-with-dual-detection-splattinghttpsarxivorgabs251205113v1>#</a></h3><p><strong>Authors:</strong> Hao-Jen Chien, Yi-Chuan Huang, Chung-Ho Wu, Wei-Lun Chao, Yu-Lun Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Synthesizing high-fidelity frozen 3D scenes from monocular Mannequin-Challenge (MC) videos is a unique problem distinct from standard dynamic scene reconstruction. Instead of focusing on modeling motion, our goal is to create a frozen scene while strategically preserving subtle dynamics to enable user-controlled instant selection. To achieve this, we introduce a novel application of dynamic Gaussian splatting: the scene is modeled dynamically, which retains nearby temporal variation, and a static scene is rendered by fixing the model&rsquo;s time parameter. However, under this usage, monocular capture with sparse temporal supervision introduces artifacts like ghosting and blur for Gaussians that become unobserved or occluded at weakly supervised timestamps. We propose Splannequin, an architecture-agnostic regularization that detects two states of Gaussian primitives, hidden and defective, and applies temporal anchoring. Under predominantly forward camera motion, hidden states are anchored to their recent well-observed past states, while defective states are anchored to future states with stronger supervision. Our method integrates into existing dynamic Gaussian pipelines via simple loss terms, requires no architectural changes, and adds zero inference overhead. This results in markedly improved visual quality, enabling high-fidelity, user-selectable frozen-time renderings, validated by a 96% user preference. Project page: <a href=https://chien90190.github.io/splannequin/>https://chien90190.github.io/splannequin/</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05113v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05113v1">üìÑ Download PDF</a></p><hr><h3 id=global-phase-diagram-of-two-dimensional-dirty-hyperbolic-dirac-liquidshttpsarxivorgabs251205109v1><a href=https://arxiv.org/abs/2512.05109v1>Global phase diagram of two-dimensional dirty hyperbolic Dirac liquids</a><a hidden class=anchor aria-hidden=true href=#global-phase-diagram-of-two-dimensional-dirty-hyperbolic-dirac-liquidshttpsarxivorgabs251205109v1>#</a></h3><p><strong>Authors:</strong> Christopher A. Leong, Daniel J. Salib, Bitan Roy
<strong>Venue:</strong> arXiv (2025)</p><p>Within the framework of the canonical nearest-neighbor tight-binding model for spinless fermions, a family of two-dimensional bipartite hyperbolic lattices hosts massless Diraclike excitations near half-filling with the iconic vanishing density of states (DOS) near zero energy. We show that a collection of such ballistic quasiparticles remains stable against sufficiently weak pointlike charge impurities, a feature captured by the vanishing average [$œÅ_{a}(0)$] and typical [$œÅ_{t}(0)$] DOS at zero energy, computed by employing the kernel polynomial method in sufficiently large ${ 10, 3}$ hyperbolic lattices (Schl√§fli symbol) with more than $10^8$ and $10^5$ sites, respectively, with open boundary conditions. However, at moderate disorder the system enters a metallic state via a continuous quantum phase transition where both $œÅ_{a}(0)$ and $œÅ_{t}(0)$ become finite. With increasing strength of disorder, ultimately an Anderson insulator sets in, where only $œÅ_{t}(0) \to 0$. The resulting phase diagram for dirty Dirac fermions living on a hyperbolic space solely stems from the background negative spatial curvature, as confirmed from the vanishing $œÅ_{t}(0)$ for arbitrarily weak disorder on honeycomb lattices, fostering relativistic fermions on a flatland, as the thermodynamic limit is approached.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05109v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05109v1">üìÑ Download PDF</a></p><hr><h3 id=measurement-of-the-branching-fractions-and-longitudinal-polarisations-of-b0_s-to-k0-kern-018em-overlinekern--018em-k0-decayshttpsarxivorgabs251205102v1><a href=https://arxiv.org/abs/2512.05102v1>Measurement of the branching fractions and longitudinal polarisations of $B^0_{(s)} \to K^{*0} \kern 0.18em \overline{\kern -0.18em K}{}^{*0}$ decays</a><a hidden class=anchor aria-hidden=true href=#measurement-of-the-branching-fractions-and-longitudinal-polarisations-of-b0_s-to-k0-kern-018em-overlinekern--018em-k0-decayshttpsarxivorgabs251205102v1>#</a></h3><p><strong>Authors:</strong> LHCb collaboration, R. Aaij, A. S. W. Abdelmotteleb, C. Abellan Beteta, F. Abudin√©n, T. Ackernley, A. A. Adefisoye, B. Adeva, M. Adinolfi, P. Adlarson, C. Agapopoulou, C. A. Aidala, Z. Ajaltouni, S. Akar, K. Akiba, P. Albicocco, J. Albrecht, R. Aleksiejunas, F. Alessio, P. Alvarez Cartelle, R. Amalric, S. Amato, J. L. Amey, Y. Amhis, L. An, L. Anderlini, M. Andersson, P. Andreola, M. Andreotti, S. Andres Estrada, A. Anelli, D. Ao, C. Arata, F. Archilli, Z. Areg, M. Argenton, S. Arguedas Cuendis, L. Arnone, A. Artamonov, M. Artuso, E. Aslanides, R. Ata√≠de Da Silva, M. Atzeni, B. Audurier, J. A. Authier, D. Bacher, I. Bachiller Perea, S. Bachmann, M. Bachmayer, J. J. Back, P. Baladron Rodriguez, V. Balagura, A. Balboni, W. Baldini, Z. Baldwin, L. Balzani, H. Bao, J. Baptista de Souza Leite, C. Barbero Pretel, M. Barbetti, I. R. Barbosa, R. J. Barlow, M. Barnyakov, S. Barsuk, W. Barter, J. Bartz, S. Bashir, B. Batsukh, P. B. Battista, A. Bay, A. Beck, M. Becker, F. Bedeschi, I. B. Bediaga, N. A. Behling, S. Belin, A. Bellavista, K. Belous, I. Belov, I. Belyaev, G. Benane, G. Bencivenni, E. Ben-Haim, A. Berezhnoy, R. Bernet, S. Bernet Andres, A. Bertolin, F. Betti, J. Bex, O. Bezshyyko, S. Bhattacharya, J. Bhom, M. S. Bieker, N. V. Biesuz, A. Biolchini, M. Birch, F. C. R. Bishop, A. Bitadze, A. Bizzeti, T. Blake, F. Blanc, J. E. Blank, S. Blusk, V. Bocharnikov, J. A. Boelhauve, O. Boente Garcia, T. Boettcher, A. Bohare, A. Boldyrev, C. Bolognani, R. Bolzonella, R. B. Bonacci, N. Bondar, A. Bordelius, F. Borgato, S. Borghi, M. Borsato, J. T. Borsuk, E. Bottalico, S. A. Bouchiba, M. Bovill, T. J. V. Bowcock, A. Boyer, C. Bozzi, J. D. Brandenburg, A. Brea Rodriguez, N. Breer, J. Brodzicka, J. Brown, D. Brundu, E. Buchanan, M. Burgos Marcos, A. T. Burke, C. Burr, C. Buti, J. S. Butter, J. Buytaert, W. Byczynski, S. Cadeddu, H. Cai, Y. Cai, A. Caillet, R. Calabrese, S. Calderon Ramirez, L. Calefice, M. Calvi, M. Calvo Gomez, P. Camargo Magalhaes, J. I. Cambon Bouzas, P. Campana, A. F. Campoverde Quezada, S. Capelli, M. Caporale, L. Capriotti, R. Caravaca-Mora, A. Carbone, L. Carcedo Salgado, R. Cardinale, A. Cardini, P. Carniti, L. Carus, A. Casais Vidal, R. Caspary, G. Casse, M. Cattaneo, G. Cavallero, V. Cavallini, S. Celani, I. Celestino, S. Cesare, A. J. Chadwick, I. Chahrour, H. Chang, M. Charles, Ph. Charpentier, E. Chatzianagnostou, R. Cheaib, M. Chefdeville, C. Chen, J. Chen, S. Chen, Z. Chen, A. Chen Hu, M. Cherif, A. Chernov, S. Chernyshenko, X. Chiotopoulos, V. Chobanova, M. Chrzaszcz, A. Chubykin, V. Chulikov, P. Ciambrone, X. Cid Vidal, G. Ciezarek, P. Cifra, P. E. L. Clarke, M. Clemencic, H. V. Cliff, J. Closier, C. Cocha Toapaxi, V. Coco, J. Cogan, E. Cogneras, L. Cojocariu, S. Collaviti, P. Collins, T. Colombo, M. Colonna, A. Comerma-Montells, L. Congedo, J. Connaughton, A. Contu, N. Cooke, G. Cordova, C. Coronel, I. Corredoira, A. Correia, G. Corti, J. Cottee Meldrum, B. Couturier, D. C. Craik, M. Cruz Torres, E. Curras Rivera, R. Currie, C. L. Da Silva, S. Dadabaev, X. Dai, E. Dall&rsquo;Occo, J. Dalseno, C. D&rsquo;Ambrosio, J. Daniel, G. Darze, A. Davidson, J. E. Davies, O. De Aguiar Francisco, C. De Angelis, F. De Benedetti, J. de Boer, K. De Bruyn, S. De Capua, M. De Cian, U. De Freitas Carneiro Da Graca, E. De Lucia, J. M. De Miranda, L. De Paula, M. De Serio, P. De Simone, F. De Vellis, J. A. de Vries, F. Debernardis, D. Decamp, S. Dekkers, L. Del Buono, B. Delaney, H. -P. Dembinski, J. Deng, V. Denysenko, O. Deschamps, F. Dettori, B. Dey, P. Di Nezza, I. Diachkov, S. Didenko, S. Ding, Y. Ding, L. Dittmann, V. Dobishuk, A. D. Docheva, A. Doheny, C. Dong, A. M. Donohoe, F. Dordei, A. C. dos Reis, A. D. Dowling, L. Dreyfus, W. Duan, P. Duda, L. Dufour, V. Duk, P. Durante, M. M. Duras, J. M. Durham, O. D. Durmus, A. Dziurda, A. Dzyuba, S. Easo, E. Eckstein, U. Egede, A. Egorychev, V. Egorychev, S. Eisenhardt, E. Ejopu, L. Eklund, M. Elashri, D. Elizondo Blanco, J. Ellbracht, S. Ely, A. Ene, J. Eschle, S. Esen, T. Evans, F. Fabiano, S. Faghih, L. N. Falcao, B. Fang, R. Fantechi, L. Fantini, M. Faria, K. Farmer, F. Fassin, D. Fazzini, L. Felkowski, M. Feng, A. Fernandez Casani, M. Fernandez Gomez, A. D. Fernez, F. Ferrari, F. Ferreira Rodrigues, M. Ferrillo, M. Ferro-Luzzi, S. Filippov, R. A. Fini, M. Fiorini, M. Firlej, K. L. Fischer, D. S. Fitzgerald, C. Fitzpatrick, T. Fiutowski, F. Fleuret, A. Fomin, M. Fontana, L. A. Foreman, R. Forty, D. Foulds-Holt, V. Franco Lima, M. Franco Sevilla, M. Frank, E. Franzoso, G. Frau, C. Frei, D. A. Friday, J. Fu, Q. F√ºhring, T. Fulghesu, G. Galati, M. D. Galati, A. Gallas Torreira, D. Galli, S. Gambetta, M. Gandelman, P. Gandini, B. Ganie, H. Gao, R. Gao, T. Q. Gao, Y. Gao, Y. Gao, Y. Gao, L. M. Garcia Martin, P. Garcia Moreno, J. Garc√≠a Pardi√±as, P. Gardner, L. Garrido, C. Gaspar, A. Gavrikov, L. L. Gerken, E. Gersabeck, M. Gersabeck, T. Gershon, S. Ghizzo, Z. Ghorbanimoghaddam, F. I. Giasemis, V. Gibson, H. K. Giemza, A. L. Gilman, M. Giovannetti, A. Giovent√π, L. Girardey, M. A. Giza, F. C. Glaser, V. V. Gligorov, C. G√∂bel, L. Golinka-Bezshyyko, E. Golobardes, D. Golubkov, A. Golutvin, S. Gomez Fernandez, W. Gomulka, I. Gon√ßales Vaz, F. Goncalves Abrantes, M. Goncerz, G. Gong, J. A. Gooding, I. V. Gorelov, C. Gotti, E. Govorkova, J. P. Grabowski, L. A. Granado Cardoso, E. Graug√©s, E. Graverini, L. Grazette, G. Graziani, A. T. Grecu, N. A. Grieser, L. Grillo, S. Gromov, C. Gu, M. Guarise, L. Guerry, A. -K. Guseinov, E. Gushchin, Y. Guz, T. Gys, K. Habermann, T. Hadavizadeh, C. Hadjivasiliou, G. Haefeli, C. Haen, S. Haken, G. Hallett, P. M. Hamilton, J. Hammerich, Q. Han, X. Han, S. Hansmann-Menzemer, L. Hao, N. Harnew, T. H. Harris, M. Hartmann, S. Hashmi, J. He, N. Heatley, A. Hedes, F. Hemmer, C. Henderson, R. Henderson, R. D. L. Henderson, A. M. Hennequin, K. Hennessy, L. Henry, J. Herd, P. Herrero Gascon, J. Heuel, A. Heyn, A. Hicheur, G. Hijano Mendizabal, J. Horswill, R. Hou, Y. Hou, D. C. Houston, N. Howarth, W. Hu, X. Hu, W. Hulsbergen, R. J. Hunter, M. Hushchyn, D. Hutchcroft, M. Idzik, D. Ilin, P. Ilten, A. Iniukhin, A. Iohner, A. Ishteev, K. Ivshin, H. Jage, S. J. Jaimes Elles, S. Jakobsen, T. Jakoubek, E. Jans, B. K. Jashal, A. Jawahery, C. Jayaweera, V. Jevtic, Z. Jia, E. Jiang, X. Jiang, Y. Jiang, Y. J. Jiang, E. Jimenez Moya, N. Jindal, M. John, A. John Rubesh Rajan, D. Johnson, C. R. Jones, S. Joshi, B. Jost, J. Juan Castella, N. Jurik, I. Juszczak, K. Kalecinska, D. Kaminaris, S. Kandybei, M. Kane, Y. Kang, C. Kar, M. Karacson, A. Kauniskangas, J. W. Kautz, M. K. Kazanecki, F. Keizer, M. Kenzie, T. Ketel, B. Khanji, A. Kharisova, S. Kholodenko, G. Khreich, T. Kirn, V. S. Kirsebom, S. Klaver, N. Kleijne, A. Kleimenova, D. K. Klekots, K. Klimaszewski, M. R. Kmiec, T. Knospe, R. Kolb, S. Koliiev, L. Kolk, A. Konoplyannikov, P. Kopciewicz, P. Koppenburg, A. Korchin, M. Korolev, I. Kostiuk, O. Kot, S. Kotriakhova, E. Kowalczyk, A. Kozachuk, P. Kravchenko, L. Kravchuk, O. Kravcov, M. Kreps, P. Krokovny, W. Krupa, W. Krzemien, O. Kshyvanskyi, S. Kubis, M. Kucharczyk, V. Kudryavtsev, E. Kulikova, A. Kupsc, V. Kushnir, B. Kutsenko, J. Kvapil, I. Kyryllin, D. Lacarrere, P. Laguarta Gonzalez, A. Lai, A. Lampis, D. Lancierini, C. Landesa Gomez, J. J. Lane, G. Lanfranchi, C. Langenbruch, J. Langer, T. Latham, F. Lazzari, C. Lazzeroni, R. Le Gac, H. Lee, R. Lef√®vre, A. Leflat, S. Legotin, M. Lehuraux, E. Lemos Cid, O. Leroy, T. Lesiak, E. D. Lesser, B. Leverington, A. Li, C. Li, C. Li, H. Li, J. Li, K. Li, L. Li, M. Li, P. Li, P. -R. Li, Q. Li, T. Li, T. Li, Y. Li, Y. Li, Y. Li, Z. Lian, Q. Liang, X. Liang, Z. Liang, S. Libralon, A. Lightbody, C. Lin, T. Lin, R. Lindner, H. Linton, R. Litvinov, D. Liu, F. L. Liu, G. Liu, K. Liu, S. Liu, W. Liu, Y. Liu, Y. Liu, Y. L. Liu, G. Loachamin Ordonez, I. Lobo, A. Lobo Salvia, A. Loi, T. Long, F. C. L. Lopes, J. H. Lopes, A. Lopez Huertas, C. Lopez Iribarnegaray, S. L√≥pez Soli√±o, Q. Lu, C. Lucarelli, D. Lucchesi, M. Lucio Martinez, Y. Luo, A. Lupato, E. Luppi, K. Lynch, X. -R. Lyu, G. M. Ma, H. Ma, S. Maccolini, F. Machefert, F. Maciuc, B. Mack, I. Mackay, L. M. Mackey, L. R. Madhan Mohan, M. J. Madurai, D. Magdalinski, D. Maisuzenko, J. J. Malczewski, S. Malde, L. Malentacca, A. Malinin, T. Maltsev, G. Manca, G. Mancinelli, C. Mancuso, R. Manera Escalero, F. M. Manganella, D. Manuzzi, D. Marangotto, J. F. Marchand, R. Marchevski, U. Marconi, E. Mariani, S. Mariani, C. Marin Benito, J. Marks, A. M. Marshall, L. Martel, G. Martelli, G. Martellotti, L. Martinazzoli, M. Martinelli, D. Martinez Gomez, D. Martinez Santos, F. Martinez Vidal, A. Martorell i Granollers, A. Massafferri, R. Matev, A. Mathad, V. Matiunin, C. Matteuzzi, K. R. Mattioli, A. Mauri, E. Maurice, J. Mauricio, P. Mayencourt, J. Mazorra de Cos, M. Mazurek, M. McCann, N. T. McHugh, A. McNab, R. McNulty, B. Meadows, G. Meier, D. Melnychuk, D. Mendoza Granada, P. Menendez Valdes Perez, F. M. Meng, M. Merk, A. Merli, L. Meyer Garcia, D. Miao, H. Miao, M. Mikhasenko, D. A. Milanes, A. Minotti, E. Minucci, T. Miralles, B. Mitreska, D. S. Mitzel, R. Mocanu, A. Modak, L. Moeser, R. D. Moise, E. F. Molina Cardenas, T. Momb√§cher, M. Monk, T. Monnard, S. Monteil, A. Morcillo Gomez, G. Morello, M. J. Morello, M. P. Morgenthaler, A. Moro, J. Moron, W. Morren, A. B. Morris, A. G. Morris, R. Mountain, Z. M. Mu, E. Muhammad, F. Muheim, M. Mulder, K. M√ºller, F. Mu√±oz-Rojas, R. Murta, V. Mytrochenko, P. Naik, T. Nakada, R. Nandakumar, T. Nanut, G. Napoletano, I. Nasteva, M. Needham, E. Nekrasova, N. Neri, S. Neubert, N. Neufeld, P. Neustroev, J. Nicolini, D. Nicotra, E. M. Niel, N. Nikitin, L. Nisi, Q. Niu, P. Nogarolli, P. Nogga, C. Normand, J. Novoa Fernandez, G. Nowak, C. Nunez, H. N. Nur, A. Oblakowska-Mucha, V. Obraztsov, T. Oeser, A. Okhotnikov, O. Okhrimenko, R. Oldeman, F. Oliva, E. Olivart Pino, M. Olocco, R. H. O&rsquo;Neil, J. S. Ordonez Soto, D. Osthues, J. M. Otalora Goicochea, P. Owen, A. Oyanguren, O. Ozcelik, F. Paciolla, A. Padee, K. O. Padeken, B. Pagare, T. Pajero, A. Palano, L. Palini, M. Palutan, C. Pan, X. Pan, S. Panebianco, S. Paniskaki, G. Panshin, L. Paolucci, A. Papanestis, M. Pappagallo, L. L. Pappalardo, C. Pappenheimer, C. Parkes, D. Parmar, G. Passaleva, D. Passaro, A. Pastore, M. Patel, J. Patoc, C. Patrignani, A. Paul, C. J. Pawley, A. Pellegrino, J. Peng, X. Peng, M. Pepe Altarelli, S. Perazzini, D. Pereima, H. Pereira Da Costa, M. Pereira Martinez, A. Pereiro Castro, C. Perez, P. Perret, A. Perrevoort, A. Perro, M. J. Peters, K. Petridis, A. Petrolini, S. Pezzulo, J. P. Pfaller, H. Pham, L. Pica, M. Piccini, L. Piccolo, B. Pietrzyk, G. Pietrzyk, R. N. Pilato, D. Pinci, F. Pisani, M. Pizzichemi, V. M. Placinta, M. Plo Casasus, T. Poeschl, F. Polci, M. Poli Lener, A. Poluektov, N. Polukhina, I. Polyakov, E. Polycarpo, S. Ponce, D. Popov, K. Popp, S. Poslavskii, K. Prasanth, C. Prouve, D. Provenzano, V. Pugatch, A. Puicercus Gomez, G. Punzi, J. R. Pybus, Q. Q. Qian, W. Qian, N. Qin, R. Quagliani, R. I. Rabadan Trejo, R. Racz, J. H. Rademacker, M. Rama, M. Ram√≠rez Garc√≠a, V. Ramos De Oliveira, M. Ramos Pernas, M. S. Rangel, F. Ratnikov, G. Raven, M. Rebollo De Miguel, F. Redi, J. Reich, F. Reiss, Z. Ren, P. K. Resmi, M. Ribalda Galvez, R. Ribatti, G. Ricart, D. Riccardi, S. Ricciardi, K. Richardson, M. Richardson-Slipper, F. Riehn, K. Rinnert, P. Robbe, G. Robertson, E. Rodrigues, A. Rodriguez Alvarez, E. Rodriguez Fernandez, J. A. Rodriguez Lopez, E. Rodriguez Rodriguez, J. Roensch, A. Rogachev, A. Rogovskiy, D. L. Rolf, P. Roloff, V. Romanovskiy, A. Romero Vidal, G. Romolini, F. Ronchetti, T. Rong, M. Rotondo, S. R. Roy, M. S. Rudolph, M. Ruiz Diaz, R. A. Ruiz Fernandez, J. Ruiz Vidal, J. J. Saavedra-Arias, J. J. Saborido Silva, S. E. R. Sacha Emile R., N. Sagidova, D. Sahoo, N. Sahoo, B. Saitta, M. Salomoni, I. Sanderswood, R. Santacesaria, C. Santamarina Rios, M. Santimaria, L. Santoro, E. Santovetti, A. Saputi, D. Saranin, A. Sarnatskiy, G. Sarpis, M. Sarpis, C. Satriano, A. Satta, M. Saur, D. Savrina, H. Sazak, F. Sborzacchi, A. Scarabotto, S. Schael, S. Scherl, M. Schiller, H. Schindler, M. Schmelling, B. Schmidt, N. Schmidt, S. Schmitt, H. Schmitz, O. Schneider, A. Schopper, N. Schulte, M. H. Schune, G. Schwering, B. Sciascia, A. Sciuccati, G. Scriven, I. Segal, S. Sellam, A. Semennikov, T. Senger, M. Senghi Soares, A. Sergi, N. Serra, L. Sestini, A. Seuthe, B. Sevilla Sanjuan, Y. Shang, D. M. Shangase, M. Shapkin, R. S. Sharma, I. Shchemerov, L. Shchutska, T. Shears, L. Shekhtman, Z. Shen, S. Sheng, V. Shevchenko, B. Shi, Q. Shi, W. S. Shi, Y. Shimizu, E. Shmanin, R. Shorkin, J. D. Shupperd, R. Silva Coutinho, G. Simi, S. Simone, M. Singha, N. Skidmore, T. Skwarnicki, M. W. Slater, E. Smith, K. Smith, M. Smith, L. Soares Lavra, M. D. Sokoloff, F. J. P. Soler, A. Solomin, A. Solovev, K. Solovieva, N. S. Sommerfeld, R. Song, Y. Song, Y. Song, Y. S. Song, F. L. Souza De Almeida, B. Souza De Paula, K. M. Sowa, E. Spadaro Norella, E. Spedicato, J. G. Speer, P. Spradlin, F. Stagni, M. Stahl, S. Stahl, S. Stanislaus, M. Stefaniak, E. N. Stein, O. Steinkamp, D. Strekalina, Y. Su, F. Suljik, J. Sun, J. Sun, L. Sun, D. Sundfeld, W. Sutcliffe, P. Svihra, V. Svintozelskyi, K. Swientek, F. Swystun, A. Szabelski, T. Szumlak, Y. Tan, Y. Tang, Y. T. Tang, M. D. Tat, J. A. Teijeiro Jimenez, A. Terentev, F. Terzuoli, F. Teubert, E. Thomas, D. J. D. Thompson, A. R. Thomson-Strong, H. Tilquin, V. Tisserand, S. T&rsquo;Jampens, M. Tobin, T. T. Todorov, L. Tomassetti, G. Tonani, X. Tong, T. Tork, D. Torres Machado, L. Toscano, D. Y. Tou, C. Trippl, G. Tuci, N. Tuning, L. H. Uecker, A. Ukleja, D. J. Unverzagt, A. Upadhyay, B. Urbach, A. Usachov, A. Ustyuzhanin, U. Uwer, V. Vagnoni, A. Vaitkevicius, V. Valcarce Cadenas, G. Valenti, N. Valls Canudas, J. van Eldik, H. Van Hecke, E. van Herwijnen, C. B. Van Hulse, R. Van Laak, M. van Veghel, G. Vasquez, R. Vazquez Gomez, P. Vazquez Regueiro, C. V√°zquez Sierra, S. Vecchi, J. Velilla Serna, J. J. Velthuis, M. Veltri, A. Venkateswaran, M. Verdoglia, M. Vesterinen, W. Vetens, D. Vico Benet, P. Vidrier Villalba, M. Vieites Diaz, X. Vilasis-Cardona, E. Vilella Figueras, A. Villa, P. Vincent, B. Vivacqua, F. C. Volle, D. vom Bruch, N. Voropaev, K. Vos, C. Vrahas, J. Wagner, J. Walsh, E. J. Walton, G. Wan, A. Wang, B. Wang, C. Wang, G. Wang, H. Wang, J. Wang, J. Wang, J. Wang, J. Wang, M. Wang, N. W. Wang, R. Wang, X. Wang, X. Wang, X. W. Wang, Y. Wang, Y. Wang, Y. H. Wang, Z. Wang, Z. Wang, J. A. Ward, M. Waterlaat, N. K. Watson, D. Websdale, Y. Wei, Z. Weida, J. Wendel, B. D. C. Westhenry, C. White, M. Whitehead, E. Whiter, A. R. Wiederhold, D. Wiedner, M. A. Wiegertjes, C. Wild, G. Wilkinson, M. K. Wilkinson, M. Williams, M. J. Williams, M. R. J. Williams, R. Williams, S. Williams, Z. Williams, F. F. Wilson, M. Winn, W. Wislicki, M. Witek, L. Witola, T. Wolf, E. Wood, G. Wormser, S. A. Wotton, H. Wu, J. Wu, X. Wu, Y. Wu, Z. Wu, K. Wyllie, S. Xian, Z. Xiang, Y. Xie, T. X. Xing, A. Xu, L. Xu, M. Xu, Z. Xu, Z. Xu, Z. Xu, S. Yadav, K. Yang, X. Yang, Y. Yang, Y. Yang, Z. Yang, V. Yeroshenko, H. Yeung, H. Yin, X. Yin, C. Y. Yu, J. Yu, X. Yuan, Y Yuan, J. A. Zamora Saa, M. Zavertyaev, M. Zdybal, F. Zenesini, C. Zeng, M. Zeng, C. Zhang, D. Zhang, J. Zhang, L. Zhang, R. Zhang, S. Zhang, S. L. Zhang, Y. Zhang, Y. Z. Zhang, Z. Zhang, Y. Zhao, A. Zhelezov, S. Z. Zheng, X. Z. Zheng, Y. Zheng, T. Zhou, X. Zhou, Y. Zhou, V. Zhovkovska, L. Z. Zhu, X. Zhu, X. Zhu, Y. Zhu, V. Zhukov, J. Zhuo, Q. Zou, D. Zuliani, G. Zunica
<strong>Venue:</strong> arXiv (2025)</p><p>A time- and flavour-integrated amplitude analysis of $B^0$ and $B^0_s$ decays to the $(K^+œÄ^-)(K^-œÄ^+)$ final state in the $K^<em>(892)^0 \kern 0.18em \overline{\kern -0.18em K}{}^{</em>}(892)^0$ region is presented, using $pp$ collision data recorded with the LHCb detector in 2011&ndash;2018, corresponding to an integrated luminosity of $9,\text{fb}^{-1}$. The branching fractions of the $B^0$ and $B^0_s$ decays are measured relative to the $B^0 \to D^-œÄ^+$ and $B^0_s \to D^-<em>s œÄ^+$ modes, respectively. The corresponding longitudinal polarisation fractions are found to be $f_L^{d} = 0.600 \pm 0.022 \pm 0.017$ and $f_L^{s} = 0.159 \pm 0.010 \pm 0.007$, where the uncertainties are statistical and systematic, respectively. The theory-motivated $L</em>{K^{*0} \kern 0.18em \overline{\kern -0.18em K}{}^{*0}}$ observable is found to be $L_{K^{*0} \kern 0.18em \overline{\kern -0.18em K}{}^{*0}} = 4.92 \pm 0.55 \pm 0.47 \pm 0.02 \pm 0.10$, where the uncertainties are statistical, systematic, due to uncertainty of external mass and lifetime measurements, and due to knowledge of the fragmentation fraction ratio, respectively. This confirms the previously reported tension between experimental determinations and theoretical predictions of longitudinal polarisation in $B \to VV$ decays.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05102v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05102v1">üìÑ Download PDF</a></p><hr><h3 id=phase-transitions-and-black-hole-stability-in-gauged-n--8-supergravityhttpsarxivorgabs251205088v1><a href=https://arxiv.org/abs/2512.05088v1>Phase Transitions and Black Hole Stability in Gauged N = 8 Supergravity</a><a hidden class=anchor aria-hidden=true href=#phase-transitions-and-black-hole-stability-in-gauged-n--8-supergravityhttpsarxivorgabs251205088v1>#</a></h3><p><strong>Authors:</strong> Andres Anabalon, Dumitru Astefanesei, Julio Oliva, Gabriel Ortega, Jorge Urbina
<strong>Venue:</strong> arXiv (2025)</p><p>It is well known that there is a region of parameter space where all purely electric, static, dilatonic black holes are unstable within the STU models of maximal supergravity. We show that, for planar black holes, it is possible to complete the thermal phase space with AdS solitons, in such a way that the instability of the black holes signals the onset of confinement in the dual field theory. The analysis is done for the $D=4$ STU model of maximal gauged supergravity which naturally uplift to M-theory on the $S^7$.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05088v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05088v1">üìÑ Download PDF</a></p><hr><h3 id=singularity-of-the-loops-within-a-cable-graph-loop-soup-conditioned-by-its-occupation-timehttpsarxivorgabs251205086v1><a href=https://arxiv.org/abs/2512.05086v1>Singularity of the loops within a cable-graph loop-soup conditioned by its occupation time</a><a hidden class=anchor aria-hidden=true href=#singularity-of-the-loops-within-a-cable-graph-loop-soup-conditioned-by-its-occupation-timehttpsarxivorgabs251205086v1>#</a></h3><p><strong>Authors:</strong> Arthur Dremaux
<strong>Venue:</strong> arXiv (2025)</p><p>In this note, we show the following feature of the relation between Brownian loop-soups on cable-graphs and their total occupation time-field $Œõ$: When conditioned on $Œõ$, the conditional law of individual loops becomes singular with respect to that of unconditioned loops. The idea of the proof is to see that some type of fast points on the curve $Œõ$ impose an exceptional behaviour of all the loops when they go through these points.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05086v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05086v1">üìÑ Download PDF</a></p><hr><h3 id=mean-curvature-flow-near-a-peanut-solutionhttpsarxivorgabs251205077v1><a href=https://arxiv.org/abs/2512.05077v1>Mean curvature flow near a peanut solution</a><a hidden class=anchor aria-hidden=true href=#mean-curvature-flow-near-a-peanut-solutionhttpsarxivorgabs251205077v1>#</a></h3><p><strong>Authors:</strong> Sigurd Angenent, Panagiota Daskalopoulos, Natasa Sesum
<strong>Venue:</strong> arXiv (2025)</p><p>It was shown by Angenent, Altschuler and Giga, and by Angenent and Velazquez that there exist closed mean curvature flow solutions that extinct to a point in finite time, without ever becoming convex prior to their extinction. These solutions develop a degenerate neckpinch singularity, meaning that the tangent flow at a singularity is a round cylinder, but at the same time for each of these solutions there exists a sequence of points in space and time, so that the pointed blow up limit around this sequence is the Bowl soliton. These solutions are called peanut solutions and they were first conjectured to exist by Richard Hamilton, while the existence of those solutions was shown by Angenent, Altschuler and Giga. In this paper we show that this type of solutions are highly unstable, in the sense that in every small neighborhood of any such peanut solution we can find a perturbation so that the mean curvature flow starting at that perturbation develops spherical singularity, and at the same time we can find a perturbation so that the mean curvature flow starting at that perturbation develops a nondegenerate neckpinch singularity. We also show that appropriately rescaled subsequence of any sequence of solutions whose initial data converge to the peanut solution, and all of which develop spherical singularities, converges to the Ancient oval solution.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05077v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05077v1">üìÑ Download PDF</a></p><hr><h3 id=atomic-decompositions-for-derived-categories-of-g-surfaceshttpsarxivorgabs251205064v1><a href=https://arxiv.org/abs/2512.05064v1>Atomic decompositions for derived categories of G-surfaces</a><a hidden class=anchor aria-hidden=true href=#atomic-decompositions-for-derived-categories-of-g-surfaceshttpsarxivorgabs251205064v1>#</a></h3><p><strong>Authors:</strong> Alexey Elagin, Julia Schneider, Evgeny Shinder
<strong>Venue:</strong> arXiv (2025)</p><p>We construct canonical semi-orthogonal decompositions for derived categories of smooth projective surfaces. These decompositions are compatible with the operations in the minimal model program, such as blow-ups and conic bundles. Therefore our construction confirms a conjecture of Kontsevich in dimension two. We work in the G-equivariant setting and over an arbitrary perfect field, and canonical decompositions are consistent with group change and algebraic field extensions. Our method is based on the G-minimal model program for surfaces and on the Sarkisov link factorisation of birational maps between Mori fibre spaces. We characterise rationality of surfaces, and in certain cases, birationality between surfaces in terms of the pieces of these decompositions, which we call atoms.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05064v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05064v1">üìÑ Download PDF</a></p><hr><h3 id=sensitivity-of-hongmeng-21cm-experiment-on-scattering-dark-matterhttpsarxivorgabs251205056v1><a href=https://arxiv.org/abs/2512.05056v1>Sensitivity of Hongmeng 21cm experiment on scattering dark matter</a><a hidden class=anchor aria-hidden=true href=#sensitivity-of-hongmeng-21cm-experiment-on-scattering-dark-matterhttpsarxivorgabs251205056v1>#</a></h3><p><strong>Authors:</strong> Junsong Cang, Yu Gao, Yin-Zhe Ma
<strong>Venue:</strong> arXiv (2025)</p><p>Scattering between dark matter and baryon can cool intergalactic medium temperature and deepen the 21cm signal. Such interactions have been proposed to explain the unusually deep 21cm absorption signal reported by EDGES in 2018. This paper explores the potential to detect dark matter - baryon scattering with the Hongmeng project, an upcoming lunar orbiting satellite experiment dedicated to measuring global 21cm signal between redshifts $11-46$. We self-consistently forward-model the simulated sky temperature data, jointly varying both the astrophysical and foreground models. We show that even with a very conservative observational strategy in which the experiment only takes data when both the Earth and the Sun are shielded by the Moon, Hongmeng can tighten the current constraints on dark matter - baryon scattering cross-section $œÉ_0$ by a factor of 21 after the full mission which lasts for five years. The prospective upper limit on $œÉ_0$ can reach $4 \times 10^{-43} {\rm cm^2}$ for dark matter masses between 0.1 MeV and 0.4 GeV. Even after only one month of observation, a factor of 3 improvement relative to current $œÉ_0$ limits can be expected.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05056v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05056v1">üìÑ Download PDF</a></p><hr><h3 id=the-evolving-landscape-of-interactive-surface-sensing-technologieshttpsarxivorgabs251205071v1><a href=https://arxiv.org/abs/2512.05071v1>The Evolving Landscape of Interactive Surface Sensing Technologies</a><a hidden class=anchor aria-hidden=true href=#the-evolving-landscape-of-interactive-surface-sensing-technologieshttpsarxivorgabs251205071v1>#</a></h3><p><strong>Authors:</strong> David Wang, Wilson Chen, Tianju Wang, Jiale Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>Interactive surfaces have evolved from capacitive touch and IR based systems into a diverse ecosystem of sensing technologies that support rich and expressive human computer interaction. This survey traces that progression, beginning with infrared vision based approaches, such as FTIR and diffuse illumination, and the rise of capacitive touch as the dominant technology in modern devices, to focusing on contemporary modalities including vision and acoustic sensing. New technologies under development are also discussed, including mmWave radar, and vibration based techniques. Each sensing technique is examined in terms of its operating principles, resolution, scalability, and applications, along with discussions of multimodal integration. By comparing tradeoffs between sensing modalities, the survey highlights the technical and design factors that shape interactive surface performance and user experience. The review concludes by identifying persistent challenges, including sensing accuracy, power constraints, and privacy concerns, and outlines how emerging sensing modalities can enable future interactive environments to be ubiquitous and intelligent.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05071v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05071v1">üìÑ Download PDF</a></p><hr><h3 id=virtually-unrolling-the-herculaneum-papyri-by-diffeomorphic-spiral-fittinghttpsarxivorgabs251204927v1><a href=https://arxiv.org/abs/2512.04927v1>Virtually Unrolling the Herculaneum Papyri by Diffeomorphic Spiral Fitting</a><a hidden class=anchor aria-hidden=true href=#virtually-unrolling-the-herculaneum-papyri-by-diffeomorphic-spiral-fittinghttpsarxivorgabs251204927v1>#</a></h3><p><strong>Authors:</strong> Paul Henderson
<strong>Venue:</strong> arXiv (2025)</p><p>The Herculaneum Papyri are a collection of rolled papyrus documents that were charred and buried by the famous eruption of Mount Vesuvius. They promise to contain a wealth of previously unseen Greek and Latin texts, but are extremely fragile and thus most cannot be unrolled physically. A solution to access these texts is virtual unrolling, where the papyrus surface is digitally traced out in a CT scan of the scroll, to create a flattened representation. This tracing is very laborious to do manually in gigavoxel-sized scans, so automated approaches are desirable. We present the first top-down method that automatically fits a surface model to a CT scan of a severely damaged scroll. We take a novel approach that globally fits an explicit parametric model of the deformed scroll to existing neural network predictions of where the rolled papyrus likely passes. Our method guarantees the resulting surface is a single continuous 2D sheet, even passing through regions where the surface is not detectable in the CT scan. We conduct comprehensive experiments on high-resolution CT scans of two scrolls, showing that our approach successfully unrolls large regions, and exceeds the performance of the only existing automated unrolling method suitable for this data.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04927v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04927v1">üìÑ Download PDF</a></p><hr><h3 id=latentfm-a-latent-flow-matching-approach-for-generative-medical-image-segmentationhttpsarxivorgabs251204821v1><a href=https://arxiv.org/abs/2512.04821v1>LatentFM: A Latent Flow Matching Approach for Generative Medical Image Segmentation</a><a hidden class=anchor aria-hidden=true href=#latentfm-a-latent-flow-matching-approach-for-generative-medical-image-segmentationhttpsarxivorgabs251204821v1>#</a></h3><p><strong>Authors:</strong> Huynh Trinh Ngoc, Hoang Anh Nguyen Kim, Toan Nguyen Hai, Long Tran Quoc
<strong>Venue:</strong> arXiv (2025)</p><p>Generative models have achieved remarkable progress with the emergence of flow matching (FM). It has demonstrated strong generative capabilities and attracted significant attention as a simulation-free flow-based framework capable of learning exact data densities. Motivated by these advances, we propose LatentFM, a flow-based model operating in the latent space for medical image segmentation. To model the data distribution, we first design two variational autoencoders (VAEs) to encode both medical images and their corresponding masks into a lower-dimensional latent space. We then estimate a conditional velocity field that guides the flow based on the input image. By sampling multiple latent representations, our method synthesizes diverse segmentation outputs whose pixel-wise variance reliably captures the underlying data distribution, enabling both highly accurate and uncertainty-aware predictions. Furthermore, we generate confidence maps that quantify the model certainty, providing clinicians with richer information for deeper analysis. We conduct experiments on two datasets, ISIC-2018 and CVC-Clinic, and compare our method with several prior baselines, including both deterministic and generative approach models. Through comprehensive evaluations, both qualitative and quantitative results show that our approach achieves superior segmentation accuracy while remaining highly efficient in the latent space.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04821v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04821v1">üìÑ Download PDF</a></p><hr><h3 id=cnn-on-top-in-search-of-scalable--lightweight-image-based-jet-taggershttpsarxivorgabs251205031v1><a href=https://arxiv.org/abs/2512.05031v1>CNN on `Top&rsquo;: In Search of Scalable & Lightweight Image-based Jet Taggers</a><a hidden class=anchor aria-hidden=true href=#cnn-on-top-in-search-of-scalable--lightweight-image-based-jet-taggershttpsarxivorgabs251205031v1>#</a></h3><p><strong>Authors:</strong> Rajneil Baruah, Subhadeep Mondal, Sunando Kumar Patra, Satyajit Roy
<strong>Venue:</strong> arXiv (2025)</p><p>While Transformer-based and standard Graph Neural Networks (GNNs) have proven to be the best performers in classifying different types of jets, they require substantial computational power. We explore the scope of using a lightweight and scalable version of the EfficientNet architecture, along with global features of the jet. The end product is computationally inexpensive but is capable of competitive performance. We showcase the efficacy of our network for tagging top-quark jets in a sea of other light-quark and gluon jets.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05031v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05031v1">üìÑ Download PDF</a></p><hr><h3 id=inflationary-relics-from-an-ultra-slow-roll-plateauhttpsarxivorgabs251204986v1><a href=https://arxiv.org/abs/2512.04986v1>Inflationary relics from an Ultra-Slow-Roll plateau</a><a hidden class=anchor aria-hidden=true href=#inflationary-relics-from-an-ultra-slow-roll-plateauhttpsarxivorgabs251204986v1>#</a></h3><p><strong>Authors:</strong> Albert Escriv√†, Jaume Garriga, Shi Pi
<strong>Venue:</strong> arXiv (2025)</p><p>We investigate the formation of primordial black holes (PBHs) in inflationary scenarios featuring an ultra-slow-roll (USR) plateau, focusing on two coexisting production channels: PBHs originating from relic vacuum bubbles where the inflaton got trapped on the plateau, and PBHs arising from standard adiabatic density perturbations. From detailed numerical simulations we find that the bubbles are generically surrounded by type-II curvature fluctuations. Special attention is given to the distribution of initial conditions, including the relevant mean profiles and shape dispersion around them. For the adiabatic channel, we extend the logarithmic template formula $Œ∂[Œ∂_G]$, which maps the Gaussian curvature perturbation to the fully non-Gaussian one while incorporating mode evolution, and we compare this with numerical results obtained using the $Œ¥N$ formalism. While the template departs from numerical results near its logarithmic divergence, it still provides accurate threshold values for PBH formation in the parameter range relevant to our analysis. Finally, we compute the PBH mass functions for both channels. We find that the adiabatic channel dominates over the bubble-induced channel by a factor $\sim \mathcal{O}(10-10^{2})$, and that both contributions are largely dominated by the mean profiles.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04986v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04986v1">üìÑ Download PDF</a></p><hr><h3 id=more-on-the-sum-product-problem-for-integers-with-few-prime-factorshttpsarxivorgabs251204931v1><a href=https://arxiv.org/abs/2512.04931v1>More on the sum-product problem for integers with few prime factors</a><a hidden class=anchor aria-hidden=true href=#more-on-the-sum-product-problem-for-integers-with-few-prime-factorshttpsarxivorgabs251204931v1>#</a></h3><p><strong>Authors:</strong> Thomas F. Bloom
<strong>Venue:</strong> arXiv (2025)</p><p>We show that if $A\subset \mathbb{Z}$ is a finite set of integers in which every integer is divisible by $O(1)$ many primes then [\max(\lvert A+A\rvert,\lvert AA\rvert) \geq \lvert A\rvert^{17/10-o(1)}] and, for any $m\geq 2$, [\max(\lvert mA\rvert, \lvert A^m\rvert) \geq \lvert A\rvert^{\frac{2}{3}m+\frac{1}{3}-o(1)}.]</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04931v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04931v1">üìÑ Download PDF</a></p><hr><h3 id=monochromatic-products-in-random-integer-setshttpsarxivorgabs251204916v1><a href=https://arxiv.org/abs/2512.04916v1>Monochromatic products in random integer sets</a><a hidden class=anchor aria-hidden=true href=#monochromatic-products-in-random-integer-setshttpsarxivorgabs251204916v1>#</a></h3><p><strong>Authors:</strong> Roger Lid√≥n, Dar√≠o Mart√≠nez, Patrick Morris, Miquel Ortega
<strong>Venue:</strong> arXiv (2025)</p><p>A well-known consequence of Schur&rsquo;s theorem is that for $r\in \mathbb{N}$, if $n$ is sufficiently large, then any $r$-colouring of $[n]$ results in monochromatic $a,b,c\in [n]$ such that $ab=c$. In this paper we are interested in the threshold at which the binomial random set $[n]_p$ almost surely inherits this Ramsey-type property. In particular for $r=2$ colours, we show that this threshold lies between $n^{-1/9-o(1)}$ and $n^{-1/11}$. Whilst analogous questions for solutions to (sets of) linear equations are now well understood, our work suggests that both the behaviour of the thresholds and the proof methods needed to determine them differ substantially in the non-linear setting.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04916v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04916v1">üìÑ Download PDF</a></p><hr><h3 id=you-only-train-once-yoto-a-retraining-free-object-detection-frameworkhttpsarxivorgabs251204888v1><a href=https://arxiv.org/abs/2512.04888v1>You Only Train Once (YOTO): A Retraining-Free Object Detection Framework</a><a hidden class=anchor aria-hidden=true href=#you-only-train-once-yoto-a-retraining-free-object-detection-frameworkhttpsarxivorgabs251204888v1>#</a></h3><p><strong>Authors:</strong> Priyanto Hidayatullah, Nurjannah Syakrani, Yudi Widhiyasana, Muhammad Rizqi Sholahuddin, Refdinal Tubagus, Zahri Al Adzani Hidayat, Hanri Fajar Ramadhan, Dafa Alfarizki Pratama, Farhan Muhammad Yasin
<strong>Venue:</strong> arXiv (2025)</p><p>Object detection constitutes the primary task within the domain of computer vision. It is utilized in numerous domains. Nonetheless, object detection continues to encounter the issue of catastrophic forgetting. The model must be retrained whenever new products are introduced, utilizing not only the new products dataset but also the entirety of the previous dataset. The outcome is obvious: increasing model training expenses and significant time consumption. In numerous sectors, particularly retail checkout, the frequent introduction of new products presents a great challenge. This study introduces You Only Train Once (YOTO), a methodology designed to address the issue of catastrophic forgetting by integrating YOLO11n for object localization with DeIT and Proxy Anchor Loss for feature extraction and metric learning. For classification, we utilize cosine similarity between the embedding features of the target product and those in the Qdrant vector database. In a case study conducted in a retail store with 140 products, the experimental results demonstrate that our proposed framework achieves encouraging accuracy, whether for detecting new or existing products. Furthermore, without retraining, the training duration difference is significant. We achieve almost 3 times the training time efficiency compared to classical object detection approaches. This efficiency escalates as additional new products are added to the product database. The average inference time is 580 ms per image containing multiple products, on an edge device, validating the proposed framework&rsquo;s feasibility for practical use.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04888v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04888v1">üìÑ Download PDF</a></p><hr><h3 id=balancing-information-and-dissipation-with-partially-observed-fluctuating-signalshttpsarxivorgabs251204877v1><a href=https://arxiv.org/abs/2512.04877v1>Balancing information and dissipation with partially observed fluctuating signals</a><a hidden class=anchor aria-hidden=true href=#balancing-information-and-dissipation-with-partially-observed-fluctuating-signalshttpsarxivorgabs251204877v1>#</a></h3><p><strong>Authors:</strong> Giorgio Nicoletti, Ivan Di Terlizzi, Daniel Maria Busiello
<strong>Venue:</strong> arXiv (2025)</p><p>Biological systems sense and extract information from fluctuating signals while operating under energetic constraints and limited resolution. We introduce a general chemical model in which a sensor, coupled to a signaling pathway activated by hidden signals, can allosterically tune the production of a readout molecule. We propose viable strategies for the sensor to estimate, and eventually balance, information gathering on the hidden process and the associated dissipative cost relying solely on counting statistics of observed trajectories. We show that these strategies can be successfully implemented to adapt the readout production even with finite-time measurements and limited dynamic resolution, and remain effective in the presence of inhibitory regulatory mechanisms. Our study provides a plausible mechanism to actively balance information and dissipation, paving the way for an implementable design principle underpinning biological and biochemical adaptation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04877v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04877v1">üìÑ Download PDF</a></p><hr><h3 id=cute-but-cunning-effective-closed-form-alternatives-to-the-exact-lognormal-statisticshttpsarxivorgabs251204872v1><a href=https://arxiv.org/abs/2512.04872v1>Cute but Cunning: Effective Closed-Form Alternatives to the Exact Lognormal Statistics</a><a hidden class=anchor aria-hidden=true href=#cute-but-cunning-effective-closed-form-alternatives-to-the-exact-lognormal-statisticshttpsarxivorgabs251204872v1>#</a></h3><p><strong>Authors:</strong> Carlos Rafael Nogueira da Silva, Maria Cecilia Luna Alvarado, Fernando Dar√≠o Almeida Garc√≠a, Michel Daoud Yacoub
<strong>Venue:</strong> arXiv (2025)</p><p>The Lognormal distribution is a fundamental statistical model widely used in different fields of science, including biology, finance, economics, engineering, etc. In wireless communications, it is the primary statistic for large-scale fading modeling. However, its known analytical intractability presents persistent channel characterization and performance analysis challenges. This paper introduces two effective and mathematically tractable surrogate models for the Lognormal distribution, constructed from the product of Nakagami-$m$ and Inverse Nakagami-$m$ (I-Nakagami-$m$) variates. These models yield asymptotically exact closed-form expressions for key performance metrics &ndash; including the characteristic function, bit error rate, and Shannon&rsquo;s capacity &ndash; and enable analytically tractable expressions for the probability density function and cumulative distribution function of the composite $Œ±$-$Œº$-Lognormal fading model. To facilitate implementation, a moment-matching framework is developed to map the Lognormal parameters to the surrogate model parameters. In addition, a random mixture approach is proposed to enhance convergence by exploiting the complementary approximation properties of the Nakagami-$m$ and I-Nakagami-$m$ distributions. The methodology is further extended to heterogeneous cascaded fading channels comprising arbitrary combinations of $Œ±$-$Œº$, $Œ∫$-$Œº$, and $Œ∑$-$Œº$ variates, for which moment-based mappings to the equivalent Lognormal distributions are derived. Numerical results confirm the accuracy and efficiency of the proposed approach, positioning it as a practical and reliable alternative to exact Lognormal statistics.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04872v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04872v1">üìÑ Download PDF</a></p><hr><h3 id=opacity-problems-in-multi-energy-timed-automatahttpsarxivorgabs251204950v1><a href=https://arxiv.org/abs/2512.04950v1>Opacity problems in multi-energy timed automata</a><a hidden class=anchor aria-hidden=true href=#opacity-problems-in-multi-energy-timed-automatahttpsarxivorgabs251204950v1>#</a></h3><p><strong>Authors:</strong> √âtienne Andr√©, Lydia Bakiri
<strong>Venue:</strong> arXiv (2025)</p><p>Cyber-physical systems can be subject to information leakage; in the presence of continuous variables such as time and energy, these leaks can be subtle to detect. We study here the verification of opacity problems over systems with observation over both timing and energy information. We introduce guarded multi-energy timed automata as an extension of timed automata with multiple energy variables and guards over such variables. Despite undecidability of this general formalism, we establish positive results over a number of subclasses, notably when the attacker observes the final energy and/or the execution time, but also when they have access to the value of the energy variables every time unit.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04950v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04950v1">üìÑ Download PDF</a></p><hr><h3 id=robust-precoding-designs-of-rsma-for-multiuser-mimo-systemshttpsarxivorgabs251204750v1><a href=https://arxiv.org/abs/2512.04750v1>Robust Precoding Designs of RSMA for Multiuser MIMO Systems</a><a hidden class=anchor aria-hidden=true href=#robust-precoding-designs-of-rsma-for-multiuser-mimo-systemshttpsarxivorgabs251204750v1>#</a></h3><p><strong>Authors:</strong> Wentao Zhou, Yijie Mao, Di Zhang, M√©rouane Debbah, Inkyu Lee
<strong>Venue:</strong> arXiv (2025)</p><p>Rate-splitting multiple access (RSMA) has been studied for multiuser multiple-input multiple-output (MUMIMO) systems especially in the presence of imperfect channel state information (CSI) at the transmitter. However, its precoding designs that maximize the sum rate normally have high computational complexity. To implement an efficient RSMA scheme for the MU-MIMO system, in this work, we propose a novel robust precoding design, which can handle imperfect CSI. Specifically, we first adopt the generalized mutual information to construct a lower bound of the objective function in the sum rate maximization problem. Then, we apply a smooth lower bound of the non-smooth sum rate objective function to construct a new optimization problem. By revealing the relationship between the generalized signal-to-interference-plus-noise ratio and the minimum mean square error matrices, we transform the constructed problem into a tractable one. After decomposing the transformed problem into three subproblems, we investigate a new alternating precoding design based on sequential solutions. Simulation results demonstrate that the proposed precoding scheme achieves comparable performance to conventional methods, while significantly reducing the computational complexity.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04750v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04750v1">üìÑ Download PDF</a></p><hr><h3 id=rotatable-antenna-enhanced-cell-free-communicationhttpsarxivorgabs251204742v1><a href=https://arxiv.org/abs/2512.04742v1>Rotatable Antenna-Enhanced Cell-Free Communication</a><a hidden class=anchor aria-hidden=true href=#rotatable-antenna-enhanced-cell-free-communicationhttpsarxivorgabs251204742v1>#</a></h3><p><strong>Authors:</strong> Kecheng Pan, Beixiong Zheng, Yanhua Tan, Emil Bj√∂rnson, Robert Schober, Rui Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>Rotatable antenna (RA) is a promising technology that can exploit new spatial degrees-of-freedom (DoFs) by flexibly adjusting the three-dimensional (3D) boresight direction of antennas. In this letter, we investigate an RA-enhanced cell-free system for downlink transmission, where multiple RA-equipped access points (APs) cooperatively serve multiple single-antenna users over the same time-frequency resource. Specifically, we aim to maximize the sum rate of all users by jointly optimizing the AP-user associations and the RA boresight directions. Accordingly, we propose a two-stage strategy to solve the AP-user association problem, and then employ fractional programming (FP) and successive convex approximation (SCA) techniques to optimize the RA boresight directions. Numerical results demonstrate that the proposed RA-enhanced cell-free system significantly outperforms various benchmark schemes.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04742v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04742v1">üìÑ Download PDF</a></p><hr><h3 id=topology-matters-measuring-memory-leakage-in-multi-agent-llmshttpsarxivorgabs251204668v1><a href=https://arxiv.org/abs/2512.04668v1>Topology Matters: Measuring Memory Leakage in Multi-Agent LLMs</a><a hidden class=anchor aria-hidden=true href=#topology-matters-measuring-memory-leakage-in-multi-agent-llmshttpsarxivorgabs251204668v1>#</a></h3><p><strong>Authors:</strong> Jinbo Liu, Defu Cao, Yifei Wei, Tianyao Su, Yuan Liang, Yushun Dong, Yue Zhao, Xiyang Hu
<strong>Venue:</strong> arXiv (2025)</p><p>Graph topology is a fundamental determinant of memory leakage in multi-agent LLM systems, yet its effects remain poorly quantified. We introduce MAMA (Multi-Agent Memory Attack), a framework that measures how network structure shapes leakage. MAMA operates on synthetic documents containing labeled Personally Identifiable Information (PII) entities, from which we generate sanitized task instructions. We execute a two-phase protocol: Engram (seeding private information into a target agent&rsquo;s memory) and Resonance (multi-round interaction where an attacker attempts extraction). Over up to 10 interaction rounds, we quantify leakage as the fraction of ground-truth PII recovered from attacking agent outputs via exact matching. We systematically evaluate six common network topologies (fully connected, ring, chain, binary tree, star, and star-ring), varying agent counts $n\in{4,5,6}$, attacker-target placements, and base models. Our findings reveal consistent patterns: fully connected graphs exhibit maximum leakage while chains provide strongest protection; shorter attacker-target graph distance and higher target centrality significantly increase vulnerability; leakage rises sharply in early rounds before plateauing; model choice shifts absolute leakage rates but preserves topology rankings; temporal/locational PII attributes leak more readily than identity credentials or regulated identifiers. These results provide the first systematic mapping from architectural choices to measurable privacy risk, yielding actionable guidance: prefer sparse or hierarchical connectivity, maximize attacker-target separation, limit node degree and network radius, avoid shortcuts bypassing hubs, and implement topology-aware access controls.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04668v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04668v1">üìÑ Download PDF</a></p><hr><h3 id=fx-market-making-with-internal-liquidityhttpsarxivorgabs251204603v1><a href=https://arxiv.org/abs/2512.04603v1>FX Market Making with Internal Liquidity</a><a hidden class=anchor aria-hidden=true href=#fx-market-making-with-internal-liquidityhttpsarxivorgabs251204603v1>#</a></h3><p><strong>Authors:</strong> Alexander Barzykin, Robert Boyce, Eyal Neuman
<strong>Venue:</strong> arXiv (2025)</p><p>As the FX markets continue to evolve, many institutions have started offering passive access to their internal liquidity pools. Market makers act as principal and have the opportunity to fill those orders as part of their risk management, or they may choose to adjust pricing to their external OTC franchise to facilitate the matching flow. It is, a priori, unclear how the strategies managing internal liquidity should depend on market condions, the market maker&rsquo;s risk appetite, and the placement algorithms deployed by participating clients. The market maker&rsquo;s actions in the presence of passive orders are relevant not only for their own objectives, but also for those liquidity providers who have certain expectations of the execution speed. In this work, we investigate the optimal multi-objective strategy of a market maker with an option to take liquidity on an internal exchange, and draw important qualitative insights for real-world trading.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04603v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04603v1">üìÑ Download PDF</a></p><hr><h3 id=a-light-weight-large-language-model-file-format-for-highly-secure-model-distributionhttpsarxivorgabs251204580v1><a href=https://arxiv.org/abs/2512.04580v1>A Light-Weight Large Language Model File Format for Highly-Secure Model Distribution</a><a hidden class=anchor aria-hidden=true href=#a-light-weight-large-language-model-file-format-for-highly-secure-model-distributionhttpsarxivorgabs251204580v1>#</a></h3><p><strong>Authors:</strong> Huifeng Zhu, Shijie Li, Qinfeng Li, Yier Jin
<strong>Venue:</strong> arXiv (2025)</p><p>To enhance the performance of large language models (LLMs) in various domain-specific applications, sensitive data such as healthcare, law, and finance are being used to privately customize or fine-tune these models. Such privately adapted LLMs are regarded as either personal privacy assets or corporate intellectual property. Therefore, protecting model weights and maintaining strict confidentiality during deployment and distribution have become critically important. However, existing model formats and deployment frameworks provide little to no built-in support for confidentiality, access control, or secure integration with trusted hardware. Current methods for securing model deployment either rely on computationally expensive cryptographic techniques or tightly controlled private infrastructure. Although these approaches can be effective in specific scenarios, they are difficult and costly for widespread deployment.
In this paper, we introduce CryptoTensors, a secure and format-compatible file structure for confidential LLM distribution. Built as an extension to the widely adopted Safetensors format, CryptoTensors incorporates tensor-level encryption and embedded access control policies, while preserving critical features such as lazy loading and partial deserialization. It enables transparent decryption and automated key management, supporting flexible licensing and secure model execution with minimal overhead. We implement a proof-of-concept library, benchmark its performance across serialization and runtime scenarios, and validate its compatibility with existing inference frameworks, including Hugging Face Transformers and vLLM. Our results highlight CryptoTensors as a light-weight, efficient, and developer-friendly solution for safeguarding LLM weights in real-world and widespread deployments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04580v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04580v1">üìÑ Download PDF</a></p><hr><h3 id=reliable-statistical-guarantees-for-conformal-predictors-with-small-datasetshttpsarxivorgabs251204566v1><a href=https://arxiv.org/abs/2512.04566v1>Reliable Statistical Guarantees for Conformal Predictors with Small Datasets</a><a hidden class=anchor aria-hidden=true href=#reliable-statistical-guarantees-for-conformal-predictors-with-small-datasetshttpsarxivorgabs251204566v1>#</a></h3><p><strong>Authors:</strong> Miguel S√°nchez-Dom√≠nguez, Lucas Lacasa, Javier de Vicente, Gonzalo Rubio, Eusebio Valero
<strong>Venue:</strong> arXiv (2025)</p><p>Surrogate models (including deep neural networks and other machine learning algorithms in supervised learning) are capable of approximating arbitrarily complex, high-dimensional input-output problems in science and engineering, but require a thorough data-agnostic uncertainty quantification analysis before these can be deployed for any safety-critical application. The standard approach for data-agnostic uncertainty quantification is to use conformal prediction (CP), a well-established framework to build uncertainty models with proven statistical guarantees that do not assume any shape for the error distribution of the surrogate model. However, since the classic statistical guarantee offered by CP is given in terms of bounds for the marginal coverage, for small calibration set sizes (which are frequent in realistic surrogate modelling that aims to quantify error at different regions), the potentially strong dispersion of the coverage distribution around its average negatively impacts the reliability of the uncertainty model, often obtaining coverages below the expected value, resulting in a less applicable framework. After providing a gentle presentation of uncertainty quantification for surrogate models for machine learning practitioners, in this paper we bridge the gap by proposing a new statistical guarantee that offers probabilistic information for the coverage of a single conformal predictor. We show that the proposed framework converges to the standard solution offered by CP for large calibration set sizes and, unlike the classic guarantee, still offers reliable information about the coverage of a conformal predictor for small data sizes. We illustrate and validate the methodology in a suite of examples, and implement an open access software solution that can be used alongside common conformal prediction libraries to obtain uncertainty models that fulfil the new guarantee.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04566v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04566v1">üìÑ Download PDF</a></p><hr><h3 id=gtm-simulating-the-world-of-tools-for-ai-agentshttpsarxivorgabs251204535v1><a href=https://arxiv.org/abs/2512.04535v1>GTM: Simulating the World of Tools for AI Agents</a><a hidden class=anchor aria-hidden=true href=#gtm-simulating-the-world-of-tools-for-ai-agentshttpsarxivorgabs251204535v1>#</a></h3><p><strong>Authors:</strong> Zhenzhen Ren, Xinpeng Zhang, Zhenxing Qian, Yan Gao, Yu Shi, Shuxin Zheng, Jiyan He
<strong>Venue:</strong> arXiv (2025)</p><p>The integration of external tools is pivotal for empowering Large Language Model (LLM) agents with real-world capabilities. However, training these agents through direct, continuous interaction with diverse tools is often prohibitively expensive, slow, and introduces additional development and maintenance overhead. To address this challenge, we introduce the Generalist Tool Model (GTM), a 1.5-billion-parameter model that learns to act as a universal tool simulator. With only prompt-level configuration, GTM accesses tool functionalities along with input arguments and generates outputs that faithfully mimic real tool execution, providing a fast and cost-effective solution that eliminates development overhead. To build GTM, we propose the Context-Aware Response Generation (CARG) pipeline, which synthesizes comprehensive training data covering over 20,000 tools across 300 domains including physics, medicine, robotics, and finance. Through this pipeline, GTM learns to produce not only syntactically correct outputs but also logically coherent and contextually appropriate responses. Experiments demonstrate that GTM produces high-quality outputs with strong consistency and reliability. Besides when used in real reinforcement learning scenarios for agent training, GTM exhibits significantly faster simulation speed compared to real tools while maintaining comparable output quality, along with remarkable generalization and domain adaptability. Our results establish GTM as a foundational component for developing future AI agents, enabling efficient and scalable training of tool-augmented systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04535v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04535v1">üìÑ Download PDF</a></p><hr><h3 id=not-all-birds-look-the-same-identity-preserving-generation-for-birdshttpsarxivorgabs251204485v1><a href=https://arxiv.org/abs/2512.04485v1>Not All Birds Look The Same: Identity-Preserving Generation For Birds</a><a hidden class=anchor aria-hidden=true href=#not-all-birds-look-the-same-identity-preserving-generation-for-birdshttpsarxivorgabs251204485v1>#</a></h3><p><strong>Authors:</strong> Aaron Sun, Oindrila Saha, Subhransu Maji
<strong>Venue:</strong> arXiv (2025)</p><p>Since the advent of controllable image generation, increasingly rich modes of control have enabled greater customization and accessibility for everyday users. Zero-shot, identity-preserving models such as Insert Anything and OminiControl now support applications like virtual try-on without requiring additional fine-tuning. While these models may be fitting for humans and rigid everyday objects, they still have limitations for non-rigid or fine-grained categories. These domains often lack accessible, high-quality data &ndash; especially videos or multi-view observations of the same subject &ndash; making them difficult both to evaluate and to improve upon. Yet, such domains are essential for moving beyond content creation toward applications that demand accuracy and fine detail. Birds are an excellent domain for this task: they exhibit high diversity, require fine-grained cues for identification, and come in a wide variety of poses. We introduce the NABirds Look-Alikes (NABLA) dataset, consisting of 4,759 expert-curated image pairs. Together with 1,073 pairs collected from multi-image observations on iNaturalist and a small set of videos, this forms a benchmark for evaluating identity-preserving generation of birds. We show that state-of-the-art baselines fail to maintain identity on this dataset, and we demonstrate that training on images grouped by species, age, and sex &ndash; used as a proxy for identity &ndash; substantially improves performance on both seen and unseen species.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04485v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04485v1">üìÑ Download PDF</a></p><hr><h3 id=towards-6g-native-ai-edge-networks-a-semantic-aware-and-agentic-intelligence-paradigmhttpsarxivorgabs251204405v1><a href=https://arxiv.org/abs/2512.04405v1>Towards 6G Native-AI Edge Networks: A Semantic-Aware and Agentic Intelligence Paradigm</a><a hidden class=anchor aria-hidden=true href=#towards-6g-native-ai-edge-networks-a-semantic-aware-and-agentic-intelligence-paradigmhttpsarxivorgabs251204405v1>#</a></h3><p><strong>Authors:</strong> Chenyuan Feng, Anbang Zhang, Geyong Min, Yongming Huang, Tony Q. S. Quek, Xiaohu You
<strong>Venue:</strong> arXiv (2025)</p><p>The evolution toward sixth-generation wireless systems positions intelligence as a native network capability, fundamentally transforming the design of radio access networks (RANs). Within this vision, Semantic-native communication and agentic intelligence are expected to play central roles. SemCom departs from bit-level fidelity and instead emphasizes task-oriented meaning exchange, enabling compact SC and introducing new performance measures such as semantic fidelity and task success rate. Agentic intelligence endows distributed RAN entities with goal-driven autonomy, reasoning, planning, and multi-agent collaboration, increasingly supported by foundation models and knowledge graphs. In this work, we first introduce the conceptual foundations of SemCom and agentic networking, and discuss why existing AI-driven O-RAN solutions remain largely bit-centric and task-siloed. We then present a unified taxonomy that organizes recent research along three axes: i) semantic abstraction level (symbol/feature/intent/knowledge), ii) agent autonomy and coordination granularity (single-, multi-, and hierarchical-agent), and iii) RAN control placement across PHY/MAC, near-real-time RIC, and non-real-time RIC. Based on this taxonomy, we systematically introduce enabling technologies including task-oriented semantic encoders/decoders, multi-agent reinforcement learning, foundation-model-assisted RAN agents, and knowledge-graph-based reasoning for cross-layer awareness. Representative 6G use cases, such as immersive XR, vehicular V2X, and industrial digital twins, are analyzed to illustrate the semantic-agentic convergence in practice. Finally, we identify open challenges in semantic representation standardization, scalable trustworthy agent coordination, O-RAN interoperability, and energy-efficient AI deployment, and outline research directions toward operational semantic-agentic AI-RAN.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04405v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04405v1">üìÑ Download PDF</a></p><hr><h3 id=agentbay-a-hybrid-interaction-sandbox-for-seamless-human-ai-intervention-in-agentic-systemshttpsarxivorgabs251204367v1><a href=https://arxiv.org/abs/2512.04367v1>AgentBay: A Hybrid Interaction Sandbox for Seamless Human-AI Intervention in Agentic Systems</a><a hidden class=anchor aria-hidden=true href=#agentbay-a-hybrid-interaction-sandbox-for-seamless-human-ai-intervention-in-agentic-systemshttpsarxivorgabs251204367v1>#</a></h3><p><strong>Authors:</strong> Yun Piao, Hongbo Min, Hang Su, Leilei Zhang, Lei Wang, Yue Yin, Xiao Wu, Zhejing Xu, Liwei Qu, Hang Li, Xinxin Zeng, Wei Tian, Fei Yu, Xiaowei Li, Jiayi Jiang, Tongxu Liu, Hao Tian, Yufei Que, Xiaobing Tu, Bing Suo, Yuebing Li, Xiangting Chen, Zeen Zhao, Jiaming Tang, Wei Huang, Xuguang Li, Jing Zhao, Jin Li, Jie Shen, Jinkui Ren, Xiantao Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>The rapid advancement of Large Language Models (LLMs) is catalyzing a shift towards autonomous AI Agents capable of executing complex, multi-step tasks. However, these agents remain brittle when faced with real-world exceptions, making Human-in-the-Loop (HITL) supervision essential for mission-critical applications. In this paper, we present AgentBay, a novel sandbox service designed from the ground up for hybrid interaction. AgentBay provides secure, isolated execution environments spanning Windows, Linux, Android, Web Browsers, and Code interpreters. Its core contribution is a unified session accessible via a hybrid control interface: An AI agent can interact programmatically via mainstream interfaces (MCP, Open Source SDK), while a human operator can, at any moment, seamlessly take over full manual control. This seamless intervention is enabled by Adaptive Streaming Protocol (ASP). Unlike traditional VNC/RDP, ASP is specifically engineered for this hybrid use case, delivering an ultra-low-latency, smoother user experience that remains resilient even in weak network environments. It achieves this by dynamically blending command-based and video-based streaming, adapting its encoding strategy based on network conditions and the current controller (AI or human). Our evaluation demonstrates strong results in security, performance, and task completion rates. In a benchmark of complex tasks, the AgentBay (Agent + Human) model achieved more than 48% success rate improvement. Furthermore, our ASP protocol reduces bandwidth consumption by up to 50% compared to standard RDP, and in end-to-end latency with around 5% reduction, especially under poor network conditions. We posit that AgentBay provides a foundational primitive for building the next generation of reliable, human-supervised autonomous systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04367v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04367v1">üìÑ Download PDF</a></p><hr><h3 id=rram-based-analog-matrix-computing-for-massive-mimo-signal-processing-a-reviewhttpsarxivorgabs251204365v1><a href=https://arxiv.org/abs/2512.04365v1>RRAM-Based Analog Matrix Computing for Massive MIMO Signal Processing: A Review</a><a hidden class=anchor aria-hidden=true href=#rram-based-analog-matrix-computing-for-massive-mimo-signal-processing-a-reviewhttpsarxivorgabs251204365v1>#</a></h3><p><strong>Authors:</strong> Pushen Zuo, Zhong Sun
<strong>Venue:</strong> arXiv (2025)</p><p>Resistive random-access memory (RRAM) provides an excellent platform for analog matrix computing (AMC), enabling both matrix-vector multiplication (MVM) and the solution of matrix equations through open-loop and closed-loop circuit architectures. While RRAM-based AMC has been widely explored for accelerating neural networks, its application to signal processing in massive multiple-input multiple-output (MIMO) wireless communication is rapidly emerging as a promising direction. In this Review, we summarize recent advances in applying AMC to massive MIMO, including DFT/IDFT computation for OFDM modulation and demodulation using MVM circuits; MIMO detection and precoding using MVM-based iterative algorithms; and rapid one-step solutions enabled by matrix inversion (INV) and generalized inverse (GINV) circuits. We also highlight additional opportunities, such as AMC-based compressed-sensing recovery for channel estimation and eigenvalue circuits for leakage-based precoding. Finally, we outline key challenges, including RRAM device reliability, analog circuit precision, array scalability, and data conversion bottlenecks, and discuss the opportunities for overcoming these barriers. With continued progress in device-circuit-algorithm co-design, RRAM-based AMC holds strong promise for delivering high-efficiency, high-reliability solutions to (ultra)massive MIMO signal processing in the 6G era.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04365v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04365v1">üìÑ Download PDF</a></p><hr><h3 id=human-controllable-ai-meaningful-human-controlhttpsarxivorgabs251204334v1><a href=https://arxiv.org/abs/2512.04334v1>Human-controllable AI: Meaningful Human Control</a><a hidden class=anchor aria-hidden=true href=#human-controllable-ai-meaningful-human-controlhttpsarxivorgabs251204334v1>#</a></h3><p><strong>Authors:</strong> Chengke Liu, Wei Xu
<strong>Venue:</strong> arXiv (2025)</p><p>Developing human-controllable artificial intelligence (AI) and achieving meaningful human control (MHC) has become a vital principle to address these challenges, ensuring ethical alignment and effective governance in AI. MHC is also a critical focus in human-centered AI (HCAI) research and application. This chapter systematically examines MHC in AI, articulating its foundational principles and future trajectory. MHC is not simply the right to operate, but the unity of human understanding, intervention, and the traceablity of responsibility in AI decision-making, which requires technological design, AI governance, and humans to play a role together. MHC ensures AI autonomy serves humans without constraining technological progress. The mode of human control needs to match the levels of technology, and human supervision should balance the trust and doubt of AI. For future AI systems, MHC mandates human controllability as a prerequisite, requiring: (1) technical architectures with embedded mechanisms for human control; (2) human-AI interactions optimized for better access to human understanding; and (3) the evolution of AI systems harmonizing intelligence and human controllability. Governance must prioritize HCAI strategies: policies balancing innovation and risk mitigation, human-centered participatory frameworks transcending technical elite dominance, and global promotion of MHC as a universal governance paradigm to safeguard HCAI development. Looking ahead, there is a need to strengthen interdisciplinary research on the controllability of AI systems, enhance ethical and legal awareness among stakeholders, moving beyond simplistic technology design perspectives, focus on the knowledge construction, complexity interpretation, and influencing factors surrounding human control. By fostering MHC, the development of human-controllable AI can be further advanced, delivering HCAI systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04334v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04334v1">üìÑ Download PDF</a></p><hr><h3 id=vlcs-managing-parallelism-with-virtualized-librarieshttpsarxivorgabs251204320v1><a href=https://arxiv.org/abs/2512.04320v1>VLCs: Managing Parallelism with Virtualized Libraries</a><a hidden class=anchor aria-hidden=true href=#vlcs-managing-parallelism-with-virtualized-librarieshttpsarxivorgabs251204320v1>#</a></h3><p><strong>Authors:</strong> Yineng Yan, William Ruys, Hochan Lee, Ian Henriksen, Arthur Peters, Sean Stephens, Bozhi You, Henrique Fingler, Martin Burtscher, Milos Gligoric, Keshav Pingali, Mattan Erez, George Biros, Christopher J. Rossbach
<strong>Venue:</strong> arXiv (2025)</p><p>As the complexity and scale of modern parallel machines continue to grow, programmers increasingly rely on composition of software libraries to encapsulate and exploit parallelism. However, many libraries are not designed with composition in mind and assume they have exclusive access to all resources. Using such libraries concurrently can result in contention and degraded performance. Prior solutions involve modifying the libraries or the OS, which is often infeasible.
We propose Virtual Library Contexts (VLCs), which are process subunits that encapsulate sets of libraries and associated resource allocations. VLCs control the resource utilization of these libraries without modifying library code. This enables the user to partition resources between libraries to prevent contention, or load multiple copies of the same library to allow parallel execution of otherwise thread-unsafe code within the same process.
In this paper, we describe and evaluate C++ and Python prototypes of VLCs. Experiments show VLCs enable a speedup up to 2.85x on benchmarks including applications using OpenMP, OpenBLAS, and LibTorch.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04320v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04320v1">üìÑ Download PDF</a></p><hr><h3 id=breaking-isolation-a-new-perspective-on-hypervisor-exploitation-via-cross-domain-attackshttpsarxivorgabs251204260v1><a href=https://arxiv.org/abs/2512.04260v1>Breaking Isolation: A New Perspective on Hypervisor Exploitation via Cross-Domain Attacks</a><a hidden class=anchor aria-hidden=true href=#breaking-isolation-a-new-perspective-on-hypervisor-exploitation-via-cross-domain-attackshttpsarxivorgabs251204260v1>#</a></h3><p><strong>Authors:</strong> Gaoning Pan, Yiming Tao, Qinying Wang, Chunming Wu, Mingde Hu, Yizhi Ren, Shouling Ji
<strong>Venue:</strong> arXiv (2025)</p><p>Hypervisors are under threat by critical memory safety vulnerabilities, with pointer corruption being one of the most prevalent and severe forms. Existing exploitation frameworks depend on identifying highly-constrained structures in the host machine and accurately determining their runtime addresses, which is ineffective in hypervisor environments where such structures are rare and further obfuscated by Address Space Layout Randomization (ASLR). We instead observe that modern virtualization environments exhibit weak memory isolation &ndash; guest memory is fully attacker-controlled yet accessible from the host, providing a reliable primitive for exploitation. Based on this observation, we present the first systematic characterization and taxonomy of Cross-Domain Attacks (CDA), a class of exploitation techniques that enable capability escalation through guest memory reuse. To automate this process, we develop a system that identifies cross-domain gadgets, matches them with corrupted pointers, synthesizes triggering inputs, and assembles complete exploit chains. Our evaluation on 15 real-world vulnerabilities across QEMU and VirtualBox shows that CDA is widely applicable and effective.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04260v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04260v1">üìÑ Download PDF</a></p><hr><h3 id=hey-gpt-oss-looks-like-you-got-it----now-walk-me-through-it-an-assessment-of-the-reasoning-language-models-chain-of-thought-mechanism-for-digital-forensicshttpsarxivorgabs251204254v1><a href=https://arxiv.org/abs/2512.04254v1>Hey GPT-OSS, Looks Like You Got It &ndash; Now Walk Me Through It! An Assessment of the Reasoning Language Models Chain of Thought Mechanism for Digital Forensics</a><a hidden class=anchor aria-hidden=true href=#hey-gpt-oss-looks-like-you-got-it----now-walk-me-through-it-an-assessment-of-the-reasoning-language-models-chain-of-thought-mechanism-for-digital-forensicshttpsarxivorgabs251204254v1>#</a></h3><p><strong>Authors:</strong> Ga√´tan Michelet, Janine Schneider, Aruna Withanage, Frank Breitinger
<strong>Venue:</strong> arXiv (2025)</p><p>The use of large language models in digital forensics has been widely explored. Beyond identifying potential applications, research has also focused on optimizing model performance for forensic tasks through fine-tuning. However, limited result explainability reduces their operational and legal usability. Recently, a new class of reasoning language models has emerged, designed to handle logic-based tasks through an `internal reasoning&rsquo; mechanism. Yet, users typically see only the final answer, not the underlying reasoning. One of these reasoning models is gpt-oss, which can be deployed locally, providing full access to its underlying reasoning process. This article presents the first investigation into the potential of reasoning language models for digital forensics. Four test use cases are examined to assess the usability of the reasoning component in supporting result explainability. The evaluation combines a new quantitative metric with qualitative analysis. Findings show that the reasoning component aids in explaining and validating language model outputs in digital forensics at medium reasoning levels, but this support is often limited, and higher reasoning levels do not enhance response quality.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04254v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04254v1">üìÑ Download PDF</a></p><hr><h3 id=decentralized-social-media-and-artificial-intelligence-in-digital-public-health-monitoringhttpsarxivorgabs251204232v1><a href=https://arxiv.org/abs/2512.04232v1>Decentralized Social Media and Artificial Intelligence in Digital Public Health Monitoring</a><a hidden class=anchor aria-hidden=true href=#decentralized-social-media-and-artificial-intelligence-in-digital-public-health-monitoringhttpsarxivorgabs251204232v1>#</a></h3><p><strong>Authors:</strong> Marcel Salath√©, Sharada P. Mohanty
<strong>Venue:</strong> arXiv (2025)</p><p>Digital public health monitoring has long relied on data from major social media platforms. Twitter was once an indispensable resource for tracking disease outbreaks and public sentiment in real time. Researchers used Twitter to monitor everything from influenza spread to vaccine hesitancy, demonstrating that social media data can serve as an early-warning system for emerging health threats. However, recent shifts in the social media landscape have challenged this data-driven paradigm. Platform policy changes, exemplified by Twitter&rsquo;s withdrawal of free data access, now restrict the very data that fueled a decade of digital public health research. At the same time, advances in artificial intelligence, particularly large language models (LLMs), have dramatically expanded our capacity to analyze large-scale textual data across languages and contexts. This presents a paradox: we possess powerful new AI tools to extract insights from social media, but face dwindling access to the data. In this viewpoint, we examine how digital public health monitoring is navigating these countervailing trends. We discuss the rise of decentralized social networks like Mastodon and Bluesky as alternative data sources, weighing their openness and ethical alignment with research against their smaller scale and potential biases. Ultimately, we argue that digital public health surveillance must adapt by embracing new platforms and methodologies, focusing on common diseases and broad signals that remain detectable, while advocating for policies that preserve researchers&rsquo; access to public data in privacy-respective ways.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04232v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04232v1">üìÑ Download PDF</a></p><hr><h3 id=onsight-pathology-a-real-time-platform-agnostic-computational-pathology-companion-for-histopathologyhttpsarxivorgabs251204187v1><a href=https://arxiv.org/abs/2512.04187v1>OnSight Pathology: A real-time platform-agnostic computational pathology companion for histopathology</a><a hidden class=anchor aria-hidden=true href=#onsight-pathology-a-real-time-platform-agnostic-computational-pathology-companion-for-histopathologyhttpsarxivorgabs251204187v1>#</a></h3><p><strong>Authors:</strong> Jinzhen Hu, Kevin Faust, Parsa Babaei Zadeh, Adrienn Bourkas, Shane Eaton, Andrew Young, Anzar Alvi, Dimitrios George Oreopoulos, Ameesha Paliwal, Assem Saleh Alrumeh, Evelyn Rose Kamski-Hennekam, Phedias Diamandis
<strong>Venue:</strong> arXiv (2025)</p><p>The microscopic examination of surgical tissue remains a cornerstone of disease classification but relies on subjective interpretations and access to highly specialized experts, which can compromise accuracy and clinical care. While emerging breakthroughs in artificial intelligence (AI) offer promise for automated histological analysis, the growing number of proprietary digital pathology solutions has created barriers to real-world deployment. To address these challenges, we introduce OnSight Pathology, a platform-agnostic computer vision software that uses continuous custom screen captures to provide real-time AI inferences to users as they review digital slide images. Accessible as a single, self-contained executable file (<a href=https://onsightpathology.github.io/>https://onsightpathology.github.io/</a> ), OnSight Pathology operates locally on consumer-grade personal computers without complex software integration, enabling cost-effective and secure deployment in research and clinical workflows. Here we demonstrate the utility of OnSight Pathology using over 2,500 publicly available whole slide images across different slide viewers, as well as cases from our clinical digital pathology setup. The software&rsquo;s robustness is highlighted across routine histopathological tasks, including the classification of common brain tumor types, mitosis detection, and the quantification of immunohistochemical stains. A built-in multi-modal chat assistant provides verifiable descriptions of images, free of rigid class labels, for added quality control. Lastly, we show compatibility with live microscope camera feeds, including from personal smartphones, offering potential for deployment in more analog, inter-operative, and telepathology settings. Together, we highlight how OnSight Pathology can deliver real-time AI inferences across a broad range of pathology pipelines, removing key barriers to the adoption of AI tools in histopathology.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04187v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04187v1">üìÑ Download PDF</a></p><hr><h3 id=minimal-flavor-protection-for-tev-scale-new-physicshttpsarxivorgabs251204159v1><a href=https://arxiv.org/abs/2512.04159v1>Minimal Flavor Protection for TeV-scale New Physics</a><a hidden class=anchor aria-hidden=true href=#minimal-flavor-protection-for-tev-scale-new-physicshttpsarxivorgabs251204159v1>#</a></h3><p><strong>Authors:</strong> Admir Greljo, Ajdin Palavriƒá, Ben A. Stefanek
<strong>Venue:</strong> arXiv (2025)</p><p>We determine how much TeV-scale new physics can deviate from flavor universality, $U(3)^5$, while respecting stringent bounds on flavor-changing neutral currents. The minimal continuous subgroup that must be approximately preserved is identified as $SU(2)<em>{q} \times U(1)</em>{X}$. With only a few symmetry-breaking spurions of $\mathcal{O}(10^{-2})$, all observed fermion hierarchies may be reproduced, offering a new perspective on the SM flavor puzzle. Remarkably, this framework provides structural flavor protection for generic TeV-scale new physics within the SMEFT, enlarging the space of collider-accessible scenarios beyond MFV and $U(2)^5$ and allowing for richer patterns of flavor violation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04159v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04159v1">üìÑ Download PDF</a></p><hr><h3 id=fare-comparison-app-of-uber-ola-and-rapidohttpsarxivorgabs251204065v1><a href=https://arxiv.org/abs/2512.04065v1>Fare Comparison App of Uber, Ola and Rapido</a><a hidden class=anchor aria-hidden=true href=#fare-comparison-app-of-uber-ola-and-rapidohttpsarxivorgabs251204065v1>#</a></h3><p><strong>Authors:</strong> Ashlesha Gopinath Sawant, Sahil S. Jadhav, Vidhan R. Jain, Shriraj S. Jagtap, Prachi Jadhav, Soham Jadhav, Ichha Raina
<strong>Venue:</strong> arXiv (2025)</p><p>In todays increasing world, it is very important to have good hailing services like Ola, Uber, and Rapido as it is very essential for our daily transportation. Users often face difficulties in choosing the most appropriate and efficient ride that would lead to both cost-effective and would take us to our destination in less time. This project provides you with the web application that helps you to select the most beneficial ride for you by providing users with the fare comparison between Ola, Uber, Rapido for the destination entered by the user. The backend is use to fetch the data, providing users with the fare comparison for the ride and finally providing with the best option using Python. This research paper also addresses the problem and challenges faced in accessing the data using APIs, Android Studios emulator, Appium and location comparison. Thus, the aim of the project is to provide transparency to the users in ride-hailing services and increase efficiency and provide users with better experience.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04065v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04065v1">üìÑ Download PDF</a></p><hr><h3 id=a-chronological-analysis-of-the-evolution-of-smartnicshttpsarxivorgabs251204054v1><a href=https://arxiv.org/abs/2512.04054v1>A Chronological Analysis of the Evolution of SmartNICs</a><a hidden class=anchor aria-hidden=true href=#a-chronological-analysis-of-the-evolution-of-smartnicshttpsarxivorgabs251204054v1>#</a></h3><p><strong>Authors:</strong> Olasupo Ajayi, Ryan Grant
<strong>Venue:</strong> arXiv (2025)</p><p>Network Interface Cards (NICs) are one of the key enablers of the modern Internet. They serve as gateways for connecting computing devices to networks for the exchange of data with other devices. Recently, the pervasive nature of Internet-enabled devices coupled with the growing demands for faster network access have necessitated the enhancement of NICs to Smart NICs (SNICs), capable of processing enormous volumes of data at near real-time speed. However, despite their popularity, the exact use and applicability of SNICs remains an ongoing debate. These debates are exacerbated by the incorporation of accelerators into SNIC, allowing them to relieve their host&rsquo;s CPUs of various tasks. In this work, we carry out a chronological analysis of SNICs, using 370 articles published in the past 15 years, from 2010 to 2024, to gain some insight into SNICs; and shed some light on their evolution, manufacturers, use cases, and application domains.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04054v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04054v1">üìÑ Download PDF</a></p><hr><h3 id=marktune-improving-the-quality-detectability-trade-off-in-open-weight-llm-watermarkinghttpsarxivorgabs251204044v1><a href=https://arxiv.org/abs/2512.04044v1>MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking</a><a hidden class=anchor aria-hidden=true href=#marktune-improving-the-quality-detectability-trade-off-in-open-weight-llm-watermarkinghttpsarxivorgabs251204044v1>#</a></h3><p><strong>Authors:</strong> Yizhou Zhao, Zhiwei Steven Wu, Adam Block
<strong>Venue:</strong> arXiv (2025)</p><p>Watermarking aims to embed hidden signals in generated text that can be reliably detected when given access to a secret key. Open-weight language models pose acute challenges for such watermarking schemes because the inference-time interventions that dominate contemporary approaches cannot be enforced once model weights are public. Existing watermaking techniques for open-weight models, such as the recently proposed GaussMark, typically rely on small modifications to model weights, which can yield signals detectable to those equipped with a secret key, but achieving detection power comparable to inference-time watermarks generally requires weight perturbations that noticeably reduce generation quality. We introduce MarkTune, a theoretically principled, on-policy fine-tuning framework that treats the GaussMark signal as a reward while simultaneously regularizing against degradation in text quality. We derive MarkTune as an improvement on GaussMark and demonstrate that MarkTune consistently improves the quality-detectability trade-off over GaussMark by steering finer-grained, watermark-aware weight updates within the model&rsquo;s representation space while preserving generation quality. Empirically, we show that MarkTune pushes the quality-detectability frontier of GaussMark close to that of inference-time watermarking, remains robust to paraphrasing and fine-tuning attacks, and exhibits strong generalization: a model fine-tuned on one dataset retains substantial watermark detection power on unseen datasets. Together, these results establish MarkTune as a general strategy for embedding robust, high-quality watermarks into open-weight LMs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04044v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04044v1">üìÑ Download PDF</a></p><hr><h3 id=oopredictor-predicting-object-oriented-accesses-using-static-analysishttpsarxivorgabs251203972v1><a href=https://arxiv.org/abs/2512.03972v1>OOPredictor: Predicting Object-Oriented Accesses using Static Analysis</a><a hidden class=anchor aria-hidden=true href=#oopredictor-predicting-object-oriented-accesses-using-static-analysishttpsarxivorgabs251203972v1>#</a></h3><p><strong>Authors:</strong> Hassan Arafat, David Bremner, Kenneth B. Kent, Julian Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Object-oriented Programming has become one of the most dominant design paradigms as the separation of concerns and adaptability of design reduce development and maintenance costs. However, the convenience is not without cost. The added indirection inherent in such designs causes excessive pointer chasing, negatively affecting locality, which in turn degrades the performance of cache structures. Furthermore, modern hardware prefetchers are mostly stride prefetchers that are ill-equipped to handle the unpredictability of access patterns generated by pointer chasing. Most software approaches that seek to address this problem resort to profiling the program as it runs, which comes with a significant run-time overhead or requires data from previous runs. In this paper, we propose the use of compile-time static analysis to predict the most common access patterns displayed by a program during run time. Since Java is one of the most popular object-oriented languages, we implement our prototype within the OpenJ9 JVM, inside the OMR optimizer infrastructure. The outputs of our proposed predictor are Markov chains that model the expected behavior of the program. The effectiveness of the proposed predictor is evaluated by comparing the model with the actual run-time behavior of the program measured using an instrumented interpreter. Our experiments show that the proposed predictor exhibits good accuracy and can be used to inform minimally intrusive load stall mitigation strategies, e.g. informing copying GCs on more locality-friendly copying orders</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03972v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03972v1">üìÑ Download PDF</a></p><hr><h3 id=integrating-high-performance-in-memory-data-streaming-and-in-situ-visualization-in-hybrid-mpiopenmp-pic-mc-simulations-towards-exascalehttpsarxivorgabs251203914v2><a href=https://arxiv.org/abs/2512.03914v2>Integrating High Performance In-Memory Data Streaming and In-Situ Visualization in Hybrid MPI+OpenMP PIC MC Simulations Towards Exascale</a><a hidden class=anchor aria-hidden=true href=#integrating-high-performance-in-memory-data-streaming-and-in-situ-visualization-in-hybrid-mpiopenmp-pic-mc-simulations-towards-exascalehttpsarxivorgabs251203914v2>#</a></h3><p><strong>Authors:</strong> Jeremy J. Williams, Stefan Costea, Daniel Medeiros, Jordy Trilaksono, Pratibha Hegde, David Tskhakaya, Leon Kos, Ales Podolnik, Jakub Hromadka, Kevin A. Huck, Allen D. Malony, Frank Jenko, Erwin Laure, Stefano Markidis
<strong>Venue:</strong> arXiv (2025)</p><p>Efficient simulation of complex plasma dynamics is crucial for advancing fusion energy research. Particle-in-Cell (PIC) Monte Carlo (MC) simulations provide insights into plasma behavior, including turbulence and confinement, which are essential for optimizing fusion reactor performance. Transitioning to exascale simulations introduces significant challenges, with traditional file input/output (I/O) inefficiencies remaining a key bottleneck. This work advances BIT1, an electrostatic PIC MC code, by improving the particle mover with OpenMP task-based parallelism, integrating the openPMD streaming API, and enabling in-memory data streaming with ADIOS2&rsquo;s Sustainable Staging Transport (SST) engine to enhance I/O performance, computational efficiency, and system storage utilization. We employ profiling tools such as gprof, perf, IPM and Darshan, which provide insights into computation, communication, and I/O operations. We implement time-dependent data checkpointing with the openPMD API enabling seamless data movement and in-situ visualization for real-time analysis without interrupting the simulation. We demonstrate improvements in simulation runtime, data accessibility and real-time insights by comparing traditional file I/O with the ADIOS2 BP4 and SST backends. The proposed hybrid BIT1 openPMD SST enhancement introduces a new paradigm for real-time scientific discovery in plasma simulations, enabling faster insights and more efficient use of exascale computing resources.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03914v2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03914v2">üìÑ Download PDF</a></p><hr><h3 id=prostate-biopsy-whole-slide-image-dataset-from-an-underrepresented-middle-eastern-populationhttpsarxivorgabs251203854v1><a href=https://arxiv.org/abs/2512.03854v1>Prostate biopsy whole slide image dataset from an underrepresented Middle Eastern population</a><a hidden class=anchor aria-hidden=true href=#prostate-biopsy-whole-slide-image-dataset-from-an-underrepresented-middle-eastern-populationhttpsarxivorgabs251203854v1>#</a></h3><p><strong>Authors:</strong> Peshawa J. Muhammad Ali, Navin Vincent, Saman S. Abdulla, Han N. Mohammed Fadhl, Anders Blilie, Kelvin Szolnoky, Julia Anna Mielcarz, Xiaoyi Ji, Kimmo Kartasalo, Abdulbasit K. Al-Talabani, Nita Mulliqi
<strong>Venue:</strong> arXiv (2025)</p><p>Artificial intelligence (AI) is increasingly used in digital pathology. Publicly available histopathology datasets remain scarce, and those that do exist predominantly represent Western populations. Consequently, the generalizability of AI models to populations from less digitized regions, such as the Middle East, is largely unknown. This motivates the public release of our dataset to support the development and validation of pathology AI models across globally diverse populations. We present 339 whole-slide images of prostate core needle biopsies from a consecutive series of 185 patients collected in Erbil, Iraq. The slides are associated with Gleason scores and International Society of Urological Pathology grades assigned independently by three pathologists. Scanning was performed using two high-throughput scanners (Leica and Hamamatsu) and one compact scanner (Grundium). All slides were de-identified and are provided in their native formats without further conversion. The dataset enables grading concordance analyses, color normalization, and cross-scanner robustness evaluations. Data will be deposited in the Bioimage Archive (BIA) under accession code: to be announced (TBA), and released under a CC BY 4.0 license.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03854v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03854v1">üìÑ Download PDF</a></p><hr><h3 id=robust-algorithms-for-path-and-cycle-problems-in-geometric-intersection-graphshttpsarxivorgabs251203843v1><a href=https://arxiv.org/abs/2512.03843v1>Robust Algorithms for Path and Cycle Problems in Geometric Intersection Graphs</a><a hidden class=anchor aria-hidden=true href=#robust-algorithms-for-path-and-cycle-problems-in-geometric-intersection-graphshttpsarxivorgabs251203843v1>#</a></h3><p><strong>Authors:</strong> Malory Marin, Jean-Florent Raymond, R√©mi Watrigant
<strong>Venue:</strong> arXiv (2025)</p><p>We study the design of robust subexponential algorithms for classical connectivity problems on intersection graphs of similarly sized fat objects in $\mathbb{R}^d$. In this setting, each vertex corresponds to a geometric object, and two vertices are adjacent if and only if their objects intersect. We introduce a new tool for designing such algorithms, which we call a $Œª$-linked partition. This is a partition of the vertex set into groups of highly connected vertices. Crucially, such a partition can be computed in polynomial time and does not require access to the geometric representation of the graph. We apply this framework to problems related to paths and cycles in graphs. First, we obtain the first robust ETH-tight algorithms for Hamiltonian Path and Hamiltonian Cycle, running in time $2^{O(n^{1-1/d})}$ on intersection graphs of similarly sized fat objects in $\mathbb{R}^d$. This resolves an open problem of de Berg et al. [STOC 2018] and completes the study of these problems on geometric intersection graphs from the viewpoint of ETH-tight exact algorithms. We further extend our approach to the parameterized setting and design the first robust subexponential parameterized algorithm for Long Path in any fixed dimension $d$. More precisely, we obtain a randomized robust algorithm running in time $2^{O(k^{1-1/d}\log^2 k)}, n^{O(1)}$ on intersection graphs of similarly sized fat objects in $\mathbb{R}^d$, where $k$ is the natural parameter. Besides $Œª$-linked partitions, our algorithm also relies on a low-treewidth pattern covering theorem that we establish for geometric intersection graphs, which may be viewed as a refinement of a result of Marx-Pilipczuk [ESA 2017]. This structural result may be of independent interest.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03843v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03843v1">üìÑ Download PDF</a></p><hr><h3 id=a-robust-camera-based-method-for-breath-rate-measurementhttpsarxivorgabs251203827v1><a href=https://arxiv.org/abs/2512.03827v1>A Robust Camera-based Method for Breath Rate Measurement</a><a hidden class=anchor aria-hidden=true href=#a-robust-camera-based-method-for-breath-rate-measurementhttpsarxivorgabs251203827v1>#</a></h3><p><strong>Authors:</strong> Alexey Protopopov
<strong>Venue:</strong> arXiv (2025)</p><p>Proliferation of cheap and accessible cameras makes it possible to measure a subject&rsquo;s breath rate from video footage alone. Recent works on this topic have proposed a variety of approaches for accurately measuring human breath rate, however they are either tested in near-ideal conditions, or produce results that are not sufficiently accurate. The present study proposes a more robust method to measure breath rate in humans with minimal hardware requirements using a combination of mathematical transforms with a relative deviation from the ground truth of less than 5%. The method was tested on videos taken from 14 volunteers with a total duration of over 2 hours 30 minutes. The obtained results were compared to reference data and the average mean absolute error was found to be at 0.57 respirations per minute, which is noticeably better than the results from previous works. The breath rate measurement method proposed in the present article is more resistant to distortions caused by subject movement and thus allows one to remotely measure the subject&rsquo;s breath rate without any significant limitations on the subject&rsquo;s behavior.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03827v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03827v1">üìÑ Download PDF</a></p><hr><h3 id=hidden-charm-and--bottom-tetraquark-states-with-jpc1--via-qcd-sum-ruleshttpsarxivorgabs251203800v1><a href=https://arxiv.org/abs/2512.03800v1>Hidden-charm and -bottom tetraquark states with $J^{PC}=1^{-+}$ via QCD sum rules</a><a hidden class=anchor aria-hidden=true href=#hidden-charm-and--bottom-tetraquark-states-with-jpc1--via-qcd-sum-ruleshttpsarxivorgabs251203800v1>#</a></h3><p><strong>Authors:</strong> Bing-Dong Wan, Yan Zhang, Jun-Hao Zhang, Ming-Yang Yuan
<strong>Venue:</strong> arXiv (2025)</p><p>We investigate the $1^{-+}$ hidden-charm and hidden-bottom tetraquark states within the framework of QCD sum rules. The mass spectra are computed by including condensates up to dimension eight in the operator product expansion. Our results indicate the possible existence of four $1^{-+}$ hidden-charm tetraquark states, with predicted masses of $(4.83 \pm 0.15)$ GeV, $(4.88 \pm 0.18)$ GeV, $(4.72 \pm 0.16)$ GeV, and $(4.79 \pm 0.12)$ GeV, while their hidden-bottom counterparts are estimated to have masses of $(11.08 \pm 0.16)$ GeV, $(11.16 \pm 0.14)$ GeV, $(10.99 \pm 0.16)$ GeV, and $(11.03 \pm 0.15)$ GeV, respectively. We also analyze the possible decay modes of these tetraquark states, which may be accessible in future experiments at BESIII, Belle~II, and LHCb. These findings provide valuable guidance for the experimental search for exotic $1^{-+}$ tetraquark states in both the charm and bottom sectors.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03800v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03800v1">üìÑ Download PDF</a></p><hr><h3 id=sleep-modulation-the-challenge-of-transitioning-from-open-loop-to-closed-loophttpsarxivorgabs251203784v1><a href=https://arxiv.org/abs/2512.03784v1>Sleep Modulation: The Challenge of Transitioning from Open Loop to Closed Loop</a><a hidden class=anchor aria-hidden=true href=#sleep-modulation-the-challenge-of-transitioning-from-open-loop-to-closed-loophttpsarxivorgabs251203784v1>#</a></h3><p><strong>Authors:</strong> Guisong Liu, Jiansong Zhang, Yinpei Luo, Guoliang Wei, Shuqing Sun, Shiyang Deng, Pengfei Wei, Nanxi Chen
<strong>Venue:</strong> arXiv (2025)</p><p>Sleep disorders have emerged as a critical global health issue, highlighting the urgent need for effective and widely accessible intervention technologies. Non-invasive brain stimulation has garnered attention as it enables direct or indirect modulation of neural activity, thereby promoting sleep enhancement in a safe and unobtrusive manner. This class of approaches is collectively referred to as sleep modulation. To date, the majority of sleep modulation research relies on open-loop paradigms with empirically determined parameters, while achieving individual adaptation and modulation accuracy remains a distant objective. The paradigm-specific constraints inherent to open-loop designs represent a major obstacle to clinical translation and large-scale deployment in home environments. In this paper, we delineate fundamental paradigms of sleep modulation, critically examine the intrinsic limitations of open-loop approaches, and formally conceptualize sleep closed-loop modulation. We further provide a comprehensive synthesis of prior studies involving five commonly employed modulation techniques, evaluating their potential integration within a closed-loop framework. Finally, we identify three primary challenges in constructing an effective sleep closed-loop modulation system: sensor solution selection, monitoring model design, and modulation strategy design, while also proposing potential solutions. Collectively, this work aims to advance the paradigm shift of sleep modulation from open-loop toward closed-loop systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03784v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03784v1">üìÑ Download PDF</a></p><hr><h3 id=caftra-frequency-domain-correlation-aware-feedback-free-mimo-transmission-and-resource-allocation-for-6g-and-beyondhttpsarxivorgabs251203767v2><a href=https://arxiv.org/abs/2512.03767v2>CaFTRA: Frequency-Domain Correlation-Aware Feedback-Free MIMO Transmission and Resource Allocation for 6G and Beyond</a><a hidden class=anchor aria-hidden=true href=#caftra-frequency-domain-correlation-aware-feedback-free-mimo-transmission-and-resource-allocation-for-6g-and-beyondhttpsarxivorgabs251203767v2>#</a></h3><p><strong>Authors:</strong> Bo Qian, Hanlin Wu, Jiacheng Chen, Yunting Xu, Xiaoyu Wang, Haibo Zhou, Yusheng Ji
<strong>Venue:</strong> arXiv (2025)</p><p>The fundamental design of wireless systems toward AI-native 6G and beyond is driven by the need for ever-increasing demand of mobile data traffic, extreme spectral efficiency, and adaptability across diverse service scenarios. To overcome the limitations posed by feedback-based multiple-input and multiple-output (MIMO) transmission, we propose a novel frequency-domain Correlation-aware Feedback-free MIMO Transmission and Resource Allocation (CaFTRA) framework tailored for fully-decoupled radio access networks (FD-RAN) to meet the emerging requirements of AI-Native 6G and beyond. By leveraging artificial intelligence (AI), CaFTRA effectively eliminates real-time uplink feedback by predicting channel state information (CSI) based solely on user geolocation. We introduce a Learnable Queries-driven Transformer Network for CSI mapping from user geolocation, which utilizes multi-head attention and learnable query embeddings to accurately capture frequency-domain correlations among resource blocks (RBs), thereby significantly improving the precision of CSI prediction. Once base stations (BSs) adopt feedback-free transmission, their downlink transmission coverage can be significantly expanded due to the elimination of frequent uplink feedback. To enable efficient resource scheduling under such extensive-coverage scenarios, we apply a low-complexity many-to-one matching theory-based algorithm for efficient multi-BS association and multi-RB resource allocation, which is proven to converge to a stable matching within limited iterations. Simulation results demonstrate that CaFTRA achieves stable matching convergence and significant gains in spectral efficiency and user fairness compared to 5G, underscoring its potential value for 6G standardization efforts.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03767v2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03767v2">üìÑ Download PDF</a></p><hr><h3 id=inaccessibility-in-public-transit-networkshttpsarxivorgabs251203766v1><a href=https://arxiv.org/abs/2512.03766v1>Inaccessibility in Public Transit Networks</a><a hidden class=anchor aria-hidden=true href=#inaccessibility-in-public-transit-networkshttpsarxivorgabs251203766v1>#</a></h3><p><strong>Authors:</strong> Katherine Betz
<strong>Venue:</strong> arXiv (2025)</p><p>The study of networks derived from infrastructure systems has received considerable attention, yet the accessibility of such systems, particularly within public transit networks, remains comparatively underexplored. Accessibility encompasses a broad range of considerations, from infrastructure-based features such as elevators and step-free access to spatial factors such as the geographic distribution of accessible stations. In this work, we investigate infrastructure-based accessibility in two major transit systems: the London Underground and the New York City Subway. We construct network models in which nodes represent accessible stations and edges represent adjacency along transit lines. Using tools from network analysis, we examine the structural properties of these accessibility networks, including clustering patterns and the spatial distribution of accessible nodes. We further employ centrality measures to identify stations that serve as major accessible hubs. Finally, we analyze socioeconomic and tourism-related variables to assess the influence of neighborhood wealth and popularity on the prevalence of accessible stations. Our findings highlight significant disparities in accessibility across both systems and demonstrate the utility of mathematical and network-theoretic methods in understanding and improving modern transit infrastructure.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03766v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03766v1">üìÑ Download PDF</a></p><hr><h3 id=setting-up-for-failure-automatic-discovery-of-the-neural-mechanisms-of-cognitive-errorshttpsarxivorgabs251204808v1><a href=https://arxiv.org/abs/2512.04808v1>Setting up for failure: automatic discovery of the neural mechanisms of cognitive errors</a><a hidden class=anchor aria-hidden=true href=#setting-up-for-failure-automatic-discovery-of-the-neural-mechanisms-of-cognitive-errorshttpsarxivorgabs251204808v1>#</a></h3><p><strong>Authors:</strong> Puria Radmard, Paul M. Bays, M√°t√© Lengyel
<strong>Venue:</strong> arXiv (2025)</p><p>Discovering the neural mechanisms underpinning cognition is one of the grand challenges of neuroscience. However, previous approaches for building models of RNN dynamics that explain behaviour required iterative refinement of architectures and/or optimisation objectives, resulting in a piecemeal, and mostly heuristic, human-in-the-loop process. Here, we offer an alternative approach that automates the discovery of viable RNN mechanisms by explicitly training RNNs to reproduce behaviour, including the same characteristic errors and suboptimalities, that humans and animals produce in a cognitive task. Achieving this required two main innovations. First, as the amount of behavioural data that can be collected in experiments is often too limited to train RNNs, we use a non-parametric generative model of behavioural responses to produce surrogate data for training RNNs. Second, to capture all relevant statistical aspects of the data, we developed a novel diffusion model-based approach for training RNNs. To showcase the potential of our approach, we chose a visual working memory task as our test-bed, as behaviour in this task is well known to produce response distributions that are patently multimodal (due to swap errors). The resulting network dynamics correctly qualitative features of macaque neural data. Importantly, these results were not possible to obtain with more traditional approaches, i.e., when only a limited set of behavioural signatures (rather than the full richness of behavioural response distributions) were fitted, or when RNNs were trained for task optimality (instead of reproducing behaviour). Our approach also yields novel predictions about the mechanism of swap errors, which can be readily tested in experiments. These results suggest that fitting RNNs to rich patterns of behaviour provides a powerful way to automatically discover mechanisms of important cognitive functions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04808v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04808v1">üìÑ Download PDF</a></p><hr><h3 id=neural-policy-composition-from-free-energy-minimizationhttpsarxivorgabs251204745v1><a href=https://arxiv.org/abs/2512.04745v1>Neural Policy Composition from Free Energy Minimization</a><a hidden class=anchor aria-hidden=true href=#neural-policy-composition-from-free-energy-minimizationhttpsarxivorgabs251204745v1>#</a></h3><p><strong>Authors:</strong> Francesca Rossi, Veronica Centorrino, Francesco Bullo, Giovanni Russo
<strong>Venue:</strong> arXiv (2025)</p><p>The ability to compose acquired skills to plan and execute behaviors is a hallmark of natural intelligence. Yet, despite remarkable cross-disciplinary efforts, a principled account of how task structure shapes gating and how such computations could be delivered in neural circuits, remains elusive. Here we introduce GateMod, an interpretable theoretically grounded computational model linking the emergence of gating to the underlying decision-making task, and to a neural circuit architecture. We first develop GateFrame, a normative framework casting policy gating into the minimization of the free energy. This framework, relating gating rules to task, applies broadly across neuroscience, cognitive and computational sciences. We then derive GateFlow, a continuous-time energy based dynamics that provably converges to GateFrame optimal solution. Convergence, exponential and global, follows from a contractivity property that also yields robustness and other desirable properties. Finally, we derive a neural circuit from GateFlow, GateNet. This is a soft-competitive recurrent circuit whose components perform local and contextual computations consistent with known dendritic and neural processing motifs. We evaluate GateMod across two different settings: collective behaviors in multi-agent systems and human decision-making in multi-armed bandits. In all settings, GateMod provides interpretable mechanistic explanations of gating and quantitatively matches or outperforms established models. GateMod offers a unifying framework for neural policy gating, linking task objectives, dynamical computation, and circuit-level mechanisms. It provides a framework to understand gating in natural agents beyond current explanations and to equip machines with this ability.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04745v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04745v1">üìÑ Download PDF</a></p><hr><h3 id=interactive-communication----cross-disciplinary-perspectives-from-psychology-acoustics-and-media-technologyhttpsarxivorgabs251204692v1><a href=https://arxiv.org/abs/2512.04692v1>Interactive Communication &ndash; cross-disciplinary perspectives from psychology, acoustics, and media technology</a><a hidden class=anchor aria-hidden=true href=#interactive-communication----cross-disciplinary-perspectives-from-psychology-acoustics-and-media-technologyhttpsarxivorgabs251204692v1>#</a></h3><p><strong>Authors:</strong> Mareike Daeglau, Stephan Getzmann, Moritz Bender, Janina Fels, Rainer Martin, Alexander Raake, Isabel S. Schiller, Sabine J. Schlittmeier, Katrin Schoenenberg, Felix St√§rz, Leon O. H. Kroczek
<strong>Venue:</strong> arXiv (2025)</p><p>Interactive communication (IC), i.e., the reciprocal exchange of information between two or more interactive partners, is a fundamental part of human nature. As such, it has been studied across multiple scientific disciplines with different goals and methods. This article provides a cross-disciplinary primer on contemporary IC that integrates psychological mechanisms with acoustic and media-technological constraints across theory, measurement, and applications. First, we outline theoretical frameworks that account for verbal, nonverbal and multimodal aspects of IC, including distinctions between face-to-face and computer-mediated communication. Second, we summarize key methodological approaches, including behavioral, cognitive, and experiential measures of communicative synchrony and acoustic signal quality. Third, we discuss selected applications, i.e. assistive listening technologies, conversational agents, alongside ethical considerations. Taken together, this review highlights how human capacities and technical systems jointly shape IC, consolidating concepts, findings, and challenges that have often been discussed in separate lines of research.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04692v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04692v1">üìÑ Download PDF</a></p><hr><h3 id=towards-cross-view-point-correspondence-in-vision-language-modelshttpsarxivorgabs251204686v1><a href=https://arxiv.org/abs/2512.04686v1>Towards Cross-View Point Correspondence in Vision-Language Models</a><a hidden class=anchor aria-hidden=true href=#towards-cross-view-point-correspondence-in-vision-language-modelshttpsarxivorgabs251204686v1>#</a></h3><p><strong>Authors:</strong> Yipu Wang, Yuheng Ji, Yuyang Liu, Enshen Zhou, Ziqiang Yang, Yuxuan Tian, Ziheng Qin, Yue Liu, Huajie Tan, Cheng Chi, Zhiyuan Ma, Daniel Dajun Zeng, Xiaolong Zheng
<strong>Venue:</strong> arXiv (2025)</p><p>Cross-view correspondence is a fundamental capability for spatial understanding and embodied AI. However, it is still far from being realized in Vision-Language Models (VLMs), especially in achieving precise point-level correspondence, which is crucial for precise affordance interaction. So we propose the Cross-View Point Correspondence (CVPC) task and CrossPoint-Bench, a comprehensive benchmark with hierarchical design, inspired by the human cognitive process of &ldquo;perceive&rdquo;, &ldquo;reason&rdquo;, and &ldquo;correspond&rdquo;. Our evaluation shows the state-of-the-art models (e.g., Gemini-2.5-Pro) still fall far behind humans, with a gap of over 54.65% in overall accuracy, exposing a challenge in transitioning from coarse-grained judgement to fine-grained coordinate prediction. To address this problem, we construct CrossPoint-378K, a dataset with 378K question-answering pairs across 900 scenes, focused on actionable affordance regions that better reflect real-world manipulation and interaction scenarios. Furthermore, we propose CroPond that trained on the CrossPoint-378K dataset. Our CroPond achieves state-of-the-art performance on CrossPoint-Bench, surpassing Gemini-2.5-Pro by 39.7% accuracy, which offers a foundation for advancing future work on cross-view correspondence. The benchmark, dataset, and model are publicly available at <a href=https://github.com/WangYipu2002/CrossPoint>https://github.com/WangYipu2002/CrossPoint</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04686v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04686v1">üìÑ Download PDF</a></p><hr><h3 id=limit-cycles-for-speechhttpsarxivorgabs251204642v1><a href=https://arxiv.org/abs/2512.04642v1>Limit cycles for speech</a><a hidden class=anchor aria-hidden=true href=#limit-cycles-for-speechhttpsarxivorgabs251204642v1>#</a></h3><p><strong>Authors:</strong> Adamantios I. Gafos, Stephan R. Kuberski
<strong>Venue:</strong> arXiv (2025)</p><p>Rhythmic fluctuations in acoustic energy and accompanying neuronal excitations in cortical oscillations are characteristic of human speech, yet whether a corresponding rhythmicity inheres in the articulatory movements that generate speech remains unclear. The received understanding of speech movements as discrete, goal-oriented actions struggles to make contact with the rhythmicity findings. In this work, we demonstrate that an unintuitive &ndash; but no less principled than the conventional &ndash; representation for discrete movements reveals a pervasive limit cycle organization and unlocks the recovery of previously inaccessible rhythmic structure underlying the motor activity of speech. These results help resolve a time-honored tension between the ubiquity of biological rhythmicity and discreteness in speech, the quintessential human higher function, by revealing a rhythmic organization at the most fundamental level of individual articulatory actions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04642v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04642v1">üìÑ Download PDF</a></p><hr><h3 id=when-robots-should-say-i-dont-know-benchmarking-abstention-in-embodied-question-answeringhttpsarxivorgabs251204597v1><a href=https://arxiv.org/abs/2512.04597v1>When Robots Should Say &ldquo;I Don&rsquo;t Know&rdquo;: Benchmarking Abstention in Embodied Question Answering</a><a hidden class=anchor aria-hidden=true href=#when-robots-should-say-i-dont-know-benchmarking-abstention-in-embodied-question-answeringhttpsarxivorgabs251204597v1>#</a></h3><p><strong>Authors:</strong> Tao Wu, Chuhao Zhou, Guangyu Zhao, Haozhi Cao, Yewen Pu, Jianfei Yang
<strong>Venue:</strong> arXiv (2025)</p><p>Embodied Question Answering (EQA) requires an agent to interpret language, perceive its environment, and navigate within 3D scenes to produce responses. Existing EQA benchmarks assume that every question must be answered, but embodied agents should know when they do not have sufficient information to answer. In this work, we focus on a minimal requirement for EQA agents, abstention: knowing when to withhold an answer. From an initial study of 500 human queries, we find that 32.4% contain missing or underspecified context. Drawing on this initial study and cognitive theories of human communication errors, we derive five representative categories requiring abstention: actionability limitation, referential underspecification, preference dependence, information unavailability, and false presupposition. We augment OpenEQA by having annotators transform well-posed questions into ambiguous variants outlined by these categories. The resulting dataset, AbstainEQA, comprises 1,636 annotated abstention cases paired with 1,636 original OpenEQA instances for balanced evaluation. Evaluating on AbstainEQA, we find that even the best frontier model only attains 42.79% abstention recall, while humans achieve 91.17%. We also find that scaling, prompting, and reasoning only yield marginal gains, and that fine-tuned models overfit to textual cues. Together, these results position abstention as a fundamental prerequisite for reliable interaction in embodied settings and as a necessary basis for effective clarification.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04597v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04597v1">üìÑ Download PDF</a></p><hr><h3 id=evoedit-lifelong-free-text-knowledge-editing-through-latent-perturbation-augmentation-and-knowledge-driven-parameter-fusionhttpsarxivorgabs251204545v1><a href=https://arxiv.org/abs/2512.04545v1>EvoEdit: Lifelong Free-Text Knowledge Editing through Latent Perturbation Augmentation and Knowledge-driven Parameter Fusion</a><a hidden class=anchor aria-hidden=true href=#evoedit-lifelong-free-text-knowledge-editing-through-latent-perturbation-augmentation-and-knowledge-driven-parameter-fusionhttpsarxivorgabs251204545v1>#</a></h3><p><strong>Authors:</strong> Pengfei Cao, Zeao Ji, Daojian Zeng, Jun Zhao, Kang Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Adjusting the outdated knowledge of large language models (LLMs) after deployment remains a major challenge. This difficulty has spurred the development of knowledge editing, which seeks to accurately and efficiently modify a model&rsquo;s internal (parametric) knowledge without retraining it from scratch. However, existing methods suffer from two limitations. First, they depend on structured triplets that are misaligned with the free-text nature of LLM pretraining and fail to capture the nuanced relationships among facts. Second, they typically support one-time knowledge updates, with relatively limited research on the problem of sequential or lifelong editing. To address these gaps, we propose a new task, Lifelong Free-text Knowledge Editing (LF-Edit), which enables models to incorporate updates expressed in natural language and supports continual editing over time. Despite its promise, LF-Edit faces the dual challenge of integrating new knowledge while mitigating the forgetting of prior information. To foster research on this new task, we construct a large-scale benchmark, Multi-Rank Lifelong Free-text Editing Benchmark (MRLF-Bench), containing 16,835 free-text edit requests. We further design a cognitively inspired multi-rank evaluation framework encompassing four levels: memorization, understanding, constrained comprehension, and reasoning. To tackle the challenges inherent in LF-Edit, we introduce a novel approach named EvoEdit that enhances knowledge injection through Latent Perturbation Augmentation and preserves prior information via Knowledge-driven Parameter Fusion. Experimental results demonstrate that EvoEdit substantially outperforms existing knowledge editing methods on the proposed LF-Edit task.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04545v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04545v1">üìÑ Download PDF</a></p><hr><h3 id=a-modular-cognitive-architecture-for-assisted-reasoning-the-nemosine-frameworkhttpsarxivorgabs251204500v1><a href=https://arxiv.org/abs/2512.04500v1>A Modular Cognitive Architecture for Assisted Reasoning: The Nemosine Framework</a><a hidden class=anchor aria-hidden=true href=#a-modular-cognitive-architecture-for-assisted-reasoning-the-nemosine-frameworkhttpsarxivorgabs251204500v1>#</a></h3><p><strong>Authors:</strong> Edervaldo Melo
<strong>Venue:</strong> arXiv (2025)</p><p>This paper presents the Nemosine Framework, a modular cognitive architecture designed to support assisted reasoning, structured thinking, and systematic analysis. The model operates through functional cognitive modules (&ldquo;personas&rdquo;) that organize tasks such as planning, evaluation, cross-checking, and narrative synthesis. The framework combines principles from metacognition, distributed cognition, and modular cognitive systems to offer an operational structure for assisted problem-solving and decision support. The architecture is documented through formal specification, internal consistency criteria, and reproducible structural components. The goal is to provide a clear conceptual basis for future computational implementations and to contribute to the study of symbolic-modular architectures for reasoning.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04500v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04500v1">üìÑ Download PDF</a></p><hr><h3 id=units-unified-time-series-generative-model-for-remote-sensinghttpsarxivorgabs251204461v1><a href=https://arxiv.org/abs/2512.04461v1>UniTS: Unified Time Series Generative Model for Remote Sensing</a><a hidden class=anchor aria-hidden=true href=#units-unified-time-series-generative-model-for-remote-sensinghttpsarxivorgabs251204461v1>#</a></h3><p><strong>Authors:</strong> Yuxiang Zhang, Shunlin Liang, Wenyuan Li, Han Ma, Jianglei Xu, Yichuan Ma, Jiangwei Xie, Wei Li, Mengmeng Zhang, Ran Tao, Xiang-Gen Xia
<strong>Venue:</strong> arXiv (2025)</p><p>One of the primary objectives of satellite remote sensing is to capture the complex dynamics of the Earth environment, which encompasses tasks such as reconstructing continuous cloud-free time series images, detecting land cover changes, and forecasting future surface evolution. However, existing methods typically require specialized models tailored to different tasks, lacking unified modeling of spatiotemporal features across multiple time series tasks. In this paper, we propose a Unified Time Series Generative Model (UniTS), a general framework applicable to various time series tasks, including time series reconstruction, time series cloud removal, time series semantic change detection, and time series forecasting. Based on the flow matching generative paradigm, UniTS constructs a deterministic evolution path from noise to targets under the guidance of task-specific conditions, achieving unified modeling of spatiotemporal representations for multiple tasks. The UniTS architecture consists of a diffusion transformer with spatio-temporal blocks, where we design an Adaptive Condition Injector (ACor) to enhance the model&rsquo;s conditional perception of multimodal inputs, enabling high-quality controllable generation. Additionally, we design a Spatiotemporal-aware Modulator (STM) to improve the ability of spatio-temporal blocks to capture complex spatiotemporal dependencies. Furthermore, we construct two high-quality multimodal time series datasets, TS-S12 and TS-S12CR, filling the gap of benchmark datasets for time series cloud removal and forecasting tasks. Extensive experiments demonstrate that UniTS exhibits exceptional generative and cognitive capabilities in both low-level and high-level time series tasks. It significantly outperforms existing methods, particularly when facing challenges such as severe cloud contamination, modality absence, and forecasting phenological variations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04461v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04461v1">üìÑ Download PDF</a></p><hr><h3 id=minddrive-an-all-in-one-framework-bridging-world-models-and-vision-language-model-for-end-to-end-autonomous-drivinghttpsarxivorgabs251204441v1><a href=https://arxiv.org/abs/2512.04441v1>MindDrive: An All-in-One Framework Bridging World Models and Vision-Language Model for End-to-End Autonomous Driving</a><a hidden class=anchor aria-hidden=true href=#minddrive-an-all-in-one-framework-bridging-world-models-and-vision-language-model-for-end-to-end-autonomous-drivinghttpsarxivorgabs251204441v1>#</a></h3><p><strong>Authors:</strong> Bin Suna, Yaoguang Caob, Yan Wanga, Rui Wanga, Jiachen Shanga, Xiejie Fenga, Jiayi Lu, Jia Shi, Shichun Yang, Xiaoyu Yane, Ziying Song
<strong>Venue:</strong> arXiv (2025)</p><p>End-to-End autonomous driving (E2E-AD) has emerged as a new paradigm, where trajectory planning plays a crucial role. Existing studies mainly follow two directions: trajectory generation oriented, which focuses on producing high-quality trajectories with simple decision mechanisms, and trajectory selection oriented, which performs multi-dimensional evaluation to select the best trajectory yet lacks sufficient generative capability. In this work, we propose MindDrive, a harmonized framework that integrates high-quality trajectory generation with comprehensive decision reasoning. It establishes a structured reasoning paradigm of &ldquo;context simulation - candidate generation - multi-objective trade-off&rdquo;. In particular, the proposed Future-aware Trajectory Generator (FaTG), based on a World Action Model (WaM), performs ego-conditioned &ldquo;what-if&rdquo; simulations to predict potential future scenes and generate foresighted trajectory candidates. Building upon this, the VLM-oriented Evaluator (VLoE) leverages the reasoning capability of a large vision-language model to conduct multi-objective evaluations across safety, comfort, and efficiency dimensions, leading to reasoned and human-aligned decision making. Extensive experiments on the NAVSIM-v1 and NAVSIM-v2 benchmarks demonstrate that MindDrive achieves state-of-the-art performance across multi-dimensional driving metrics, significantly enhancing safety, compliance, and generalization. This work provides a promising path toward interpretable and cognitively guided autonomous driving.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04441v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04441v1">üìÑ Download PDF</a></p><hr><h3 id=what-is-beyond-presence-dimensionality-control-and-information-spaceshttpsarxivorgabs251204398v1><a href=https://arxiv.org/abs/2512.04398v1>What is Beyond Presence? Dimensionality, Control, and Information Spaces</a><a hidden class=anchor aria-hidden=true href=#what-is-beyond-presence-dimensionality-control-and-information-spaceshttpsarxivorgabs251204398v1>#</a></h3><p><strong>Authors:</strong> E. Ch&rsquo;ng
<strong>Venue:</strong> arXiv (2025)</p><p>What is after presence? Spatial presence, the sense of &ldquo;being there&rdquo;, is becoming less of a primary objective and more of a baseline expectation of virtual reality. More than six decades after its invention, VR is shifting from a technical system into a cultural, social, and phenomenological medium, offering experiences that function as distinct modes of reality. Existing theories that focus primarily on perceptual illusions are no longer sufficient to account for these emerging forms of experience. A new framework is needed to guide the design and evaluation of immersive environments by identifying the key technical and abstract dimensions afforded by virtual worlds. These dimensions include spatial, placeness, temporal, social, cultural, cognitive, and psychological parameters. The central argument is that immersive environments must move beyond the technical dimension to leverage richer information channels that shape user experience. This shift from presence to experience orchestration invites creators across disciplines to contribute to the design and assessment of meaningful immersive worlds.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04398v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04398v1">üìÑ Download PDF</a></p><hr><h3 id=mind-to-face-neural-driven-photorealistic-avatar-synthesis-via-eeg-decodinghttpsarxivorgabs251204313v1><a href=https://arxiv.org/abs/2512.04313v1>Mind-to-Face: Neural-Driven Photorealistic Avatar Synthesis via EEG Decoding</a><a hidden class=anchor aria-hidden=true href=#mind-to-face-neural-driven-photorealistic-avatar-synthesis-via-eeg-decodinghttpsarxivorgabs251204313v1>#</a></h3><p><strong>Authors:</strong> Haolin Xiong, Tianwen Fu, Pratusha Bhuvana Prasad, Yunxuan Cai, Haiwei Chen, Wenbin Teng, Hanyuan Xiao, Yajie Zhao
<strong>Venue:</strong> arXiv (2025)</p><p>Current expressive avatar systems rely heavily on visual cues, failing when faces are occluded or when emotions remain internal. We present Mind-to-Face, the first framework that decodes non-invasive electroencephalogram (EEG) signals directly into high-fidelity facial expressions. We build a dual-modality recording setup to obtain synchronized EEG and multi-view facial video during emotion-eliciting stimuli, enabling precise supervision for neural-to-visual learning. Our model uses a CNN-Transformer encoder to map EEG signals into dense 3D position maps, capable of sampling over 65k vertices, capturing fine-scale geometry and subtle emotional dynamics, and renders them through a modified 3D Gaussian Splatting pipeline for photorealistic, view-consistent results. Through extensive evaluation, we show that EEG alone can reliably predict dynamic, subject-specific facial expressions, including subtle emotional responses, demonstrating that neural signals contain far richer affective and geometric information than previously assumed. Mind-to-Face establishes a new paradigm for neural-driven avatars, enabling personalized, emotion-aware telepresence and cognitive interaction in immersive environments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04313v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04313v1">üìÑ Download PDF</a></p><hr><h3 id=rnns-perform-task-computations-by-dynamically-warping-neural-representationshttpsarxivorgabs251204310v1><a href=https://arxiv.org/abs/2512.04310v1>RNNs perform task computations by dynamically warping neural representations</a><a hidden class=anchor aria-hidden=true href=#rnns-perform-task-computations-by-dynamically-warping-neural-representationshttpsarxivorgabs251204310v1>#</a></h3><p><strong>Authors:</strong> Arthur Pellegrino, Angus Chadwick
<strong>Venue:</strong> arXiv (2025)</p><p>Analysing how neural networks represent data features in their activations can help interpret how they perform tasks. Hence, a long line of work has focused on mathematically characterising the geometry of such &ldquo;neural representations.&rdquo; In parallel, machine learning has seen a surge of interest in understanding how dynamical systems perform computations on time-varying input data. Yet, the link between computation-through-dynamics and representational geometry remains poorly understood. Here, we hypothesise that recurrent neural networks (RNNs) perform computations by dynamically warping their representations of task variables. To test this hypothesis, we develop a Riemannian geometric framework that enables the derivation of the manifold topology and geometry of a dynamical system from the manifold of its inputs. By characterising the time-varying geometry of RNNs, we show that dynamic warping is a fundamental feature of their computations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04310v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04310v1">üìÑ Download PDF</a></p><hr><h3 id=covering-relations-in-the-poset-of-combinatorial-neural-codeshttpsarxivorgabs251204241v1><a href=https://arxiv.org/abs/2512.04241v1>Covering Relations in the Poset of Combinatorial Neural Codes</a><a hidden class=anchor aria-hidden=true href=#covering-relations-in-the-poset-of-combinatorial-neural-codeshttpsarxivorgabs251204241v1>#</a></h3><p><strong>Authors:</strong> R. Amzi Jeffs, Trong-Thuc Trang
<strong>Venue:</strong> arXiv (2025)</p><p>A combinatorial neural code is a subset of the power set $2^{[n]}$ on $[n]={1,\dots, n}$, in which each $1\leq i\leq n$ represents a neuron and each element (codeword) represents the co-firing event of some neurons. Consider a space $X\subseteq\mathbb{R}^d$, simulating an animal&rsquo;s environment, and a collection $\mathcal{U}={U_1,\dots,U_n}$ of open subsets of $X$. Each $U_i\subseteq X$ simulates a place field which is a specific region where a place cell $i$ is active. Then, the code of $\mathcal{U}$ in $X$ is defined as $\text{code}(\mathcal{U},X)=\left{œÉ\subseteq[n]\bigg|\bigcap_{i\inœÉ} U_i\setminus\bigcup_{j\notinœÉ}U_j\neq\varnothing\right}$. If a neural code $\mathcal{C}=\text{code}(\mathcal{U},X)$ for some $X$ and $\mathcal{U}$, we say $\mathcal{C}$ has a realization of open subsets of some space $X$. Although every combinatorial neural code obviously has a realization by some open subsets, determining whether it has a realization by some open convex subsets remains unsolved. Many studies attempted to tackle this decision problem, but only partial results were achieved. In fact, a previous study showed that the decision problem of convex neural codes is NP-hard. Furthermore, the authors of this study conjectured that every convex neural code can be realized as a minor of a neural code arising from a representable oriented matroid, which can lead to an equivalence between convex and polytope convex neural codes. Even though this conjecture has been confirmed in dimension two, its validity in higher dimensions is still unknown. To advance the investigation of this conjecture, we provide a complete characterization of the covering relations within the poset $\mathbf{P_{Code}}$ of neural codes.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04241v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04241v1">üìÑ Download PDF</a></p><hr><h3 id=addressing-logical-fallacies-in-scientific-reasoning-from-large-language-models-towards-a-dual-inference-training-frameworkhttpsarxivorgabs251204228v1><a href=https://arxiv.org/abs/2512.04228v1>Addressing Logical Fallacies In Scientific Reasoning From Large Language Models: Towards a Dual-Inference Training Framework</a><a hidden class=anchor aria-hidden=true href=#addressing-logical-fallacies-in-scientific-reasoning-from-large-language-models-towards-a-dual-inference-training-frameworkhttpsarxivorgabs251204228v1>#</a></h3><p><strong>Authors:</strong> Peter B. Walker, Hannah Davidson, Aiden Foster, Matthew Lienert, Thomas Pardue, Dale Russell
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Models (LLMs) have transformed natural language processing and hold growing promise for advancing science, healthcare, and decision-making. Yet their training paradigms remain dominated by affirmation-based inference, akin to \textit{modus ponens}, where accepted premises yield predicted consequents. While effective for generative fluency, this one-directional approach leaves models vulnerable to logical fallacies, adversarial manipulation, and failures in causal reasoning. This paper makes two contributions. First, it demonstrates how existing LLMs from major platforms exhibit systematic weaknesses when reasoning in scientific domains with negation, counterexamples, or faulty premises \footnote{Code to recreate these experiments are at <a href=https://github.com/hannahdavidsoncollege-maker/ScientificReasoningForEnvironment-MedicineWithLLMs>https://github.com/hannahdavidsoncollege-maker/ScientificReasoningForEnvironment-MedicineWithLLMs</a>. Second, it introduces a dual-reasoning training framework that integrates affirmative generation with structured counterfactual denial. Grounded in formal logic, cognitive science, and adversarial training, this training paradigm formalizes a computational analogue of ``denying the antecedent&rsquo;&rsquo; as a mechanism for disconfirmation and robustness. By coupling generative synthesis with explicit negation-aware objectives, the framework enables models that not only affirm valid inferences but also reject invalid ones, yielding systems that are more resilient, interpretable, and aligned with human reasoning.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04228v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04228v1">üìÑ Download PDF</a></p><hr><h3 id=parsimonious-clustering-of-covariance-matriceshttpsarxivorgabs251203912v1><a href=https://arxiv.org/abs/2512.03912v1>Parsimonious Clustering of Covariance Matrices</a><a hidden class=anchor aria-hidden=true href=#parsimonious-clustering-of-covariance-matriceshttpsarxivorgabs251203912v1>#</a></h3><p><strong>Authors:</strong> Yixi Xu, Yi Zhao
<strong>Venue:</strong> arXiv (2025)</p><p>Functional connectivity (FC) derived from functional magnetic resonance imaging (fMRI) data offers vital insights for understanding brain function and neurological and psychiatric disorders. Unsupervised clustering methods are desired to group individuals based on shared features, facilitating clinical diagnosis. In this study, a parsimonious clustering model is proposed, which integrates the Mixture-of-Experts (MoE) and covariance regression framework, to cluster individuals based on FC captured by data covariance matrices in resting-state fMRI studies. The model assumes common linear projections across covariance matrices and a generalized linear model with covariates, allowing for flexible yet interpretable projection-specific clustering solutions. To evaluate the performance of the proposed framework, extensive simulation studies are conducted to assess clustering accuracy and robustness. The approach is applied to resting-state fMRI data from the Alzheimer&rsquo;s Disease Neuroimaging Initiative (ADNI). Subgroups are identified based on brain coherence and simultaneously uncover the association with demographic factors and cognitive functions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03912v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03912v1">üìÑ Download PDF</a></p><hr><h3 id=emergent-spatiotemporal-dynamics-in-large-scale-brain-networks-with-next-generation-neural-mass-modelshttpsarxivorgabs251203907v1><a href=https://arxiv.org/abs/2512.03907v1>Emergent Spatiotemporal Dynamics in Large-Scale Brain Networks with Next Generation Neural Mass Models</a><a hidden class=anchor aria-hidden=true href=#emergent-spatiotemporal-dynamics-in-large-scale-brain-networks-with-next-generation-neural-mass-modelshttpsarxivorgabs251203907v1>#</a></h3><p><strong>Authors:</strong> Rosa Maria Delicado, Gemma Huguet, Pau Clusella
<strong>Venue:</strong> arXiv (2025)</p><p>Understanding the dynamics of large-scale brain models remains a central challenge due to the inherent complexity of these systems. In this work, we explore the emergence of complex spatiotemporal patterns in a large scale-brain model composed of 90 interconnected brain regions coupled through empirically derived anatomical connectivity. An important aspect of our formulation is that the local dynamics of each brain region are described by a next-generation neural mass model, which explicitly captures the macroscopic gamma activity of coupled excitatory and inhibitory neural populations (PING mechanism). We first identify the system&rsquo;s homogeneous states-both resting and oscillatory-and analyze their stability under uniform perturbations. Then, we determine the stability against non-uniform perturbations by obtaining dispersion relations for the perturbation growth rate. This analysis enables us to link unstable directions of the homogeneous solutions to the emergence of rich spatiotemporal patterns, that we characterize by means of Lyapunov exponents and frequency spectrum analysis. Our results show that, compared to previous studies with classical neural mass models, next-generation neural mass models provide a broader dynamical repertoire, both within homogeneous states and in the heterogeneous regime. Additionally, we identify a key role for anatomical connectivity in cross-frequency coupling, allowing for the emergence of gamma oscillations with amplitude modulated by slower rhythms. These findings suggest that such models are not only more biophysically grounded but also particularly well-suited to capture the full complexity of large-scale brain dynamics. Overall, our study advances the analytical understanding of emerging spatiotemporal patterns in whole-brain models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03907v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03907v1">üìÑ Download PDF</a></p><hr><h3 id=equalizer-or-amplifier-how-ai-may-reshape-human-cognitive-differenceshttpsarxivorgabs251203902v1><a href=https://arxiv.org/abs/2512.03902v1>Equalizer or amplifier? How AI may reshape human cognitive differences</a><a hidden class=anchor aria-hidden=true href=#equalizer-or-amplifier-how-ai-may-reshape-human-cognitive-differenceshttpsarxivorgabs251203902v1>#</a></h3><p><strong>Authors:</strong> Maria Bigoni, Andrea Ichino, Aldo Rustichini, Giulio Zanella
<strong>Venue:</strong> arXiv (2025)</p><p>Machines have at times equalized physical strength by substituting for human effort, and at other times amplified these differences. Artificial intelligence (AI) may likewise narrow or widen disparities in cognitive ability. Recent evidence from the Information and Communication Technology (ICT) revolution suggests that computers increased inequality by education but reduced it by cognitive ability. Early research on generative AI shows larger productivity gains for less-skilled than for high-skilled workers. Whether AI ultimately acts as an equalizer or an amplifier of human cognitive differences is especially crucial for education systems, which must decide whether &ndash; and how &ndash; to allow students to use AI in coursework and exams. This decision is urgent because employers value workers who can leverage AI effectively rather than operate independently of it.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03902v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03902v1">üìÑ Download PDF</a></p><hr><h3 id=im-here-interaction-model-for-human-effort-based-robot-engagementhttpsarxivorgabs251203828v1><a href=https://arxiv.org/abs/2512.03828v1>IM HERE: Interaction Model for Human Effort Based Robot Engagement</a><a hidden class=anchor aria-hidden=true href=#im-here-interaction-model-for-human-effort-based-robot-engagementhttpsarxivorgabs251203828v1>#</a></h3><p><strong>Authors:</strong> Dominykas Strazdas, Magnus Jung, Jan Marquenie, Ingo Siegert, Ayoub Al-Hamadi
<strong>Venue:</strong> arXiv (2025)</p><p>The effectiveness of human-robot interaction often hinges on the ability to cultivate engagement - a dynamic process of cognitive involvement that supports meaningful exchanges. Many existing definitions and models of engagement are either too vague or lack the ability to generalize across different contexts. We introduce IM HERE, a novel framework that models engagement effectively in human-human, human-robot, and robot-robot interactions. By employing an effort-based description of bilateral relationships between entities, we provide an accurate breakdown of relationship patterns, simplifying them to focus placement and four key states. This framework captures mutual relationships, group behaviors, and actions conforming to social norms, translating them into specific directives for autonomous systems. By integrating both subjective perceptions and objective states, the model precisely identifies and describes miscommunication. The primary objective of this paper is to automate the analysis, modeling, and description of social behavior, and to determine how autonomous systems can behave in accordance with social norms for full social integration while simultaneously pursuing their own social goals.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03828v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03828v1">üìÑ Download PDF</a></p><hr><h3 id=origin-conditional-trajectory-encoding-measuring-urban-configurational-asymmetries-through-neural-decompositionhttpsarxivorgabs251203755v1><a href=https://arxiv.org/abs/2512.03755v1>Origin-Conditional Trajectory Encoding: Measuring Urban Configurational Asymmetries through Neural Decomposition</a><a hidden class=anchor aria-hidden=true href=#origin-conditional-trajectory-encoding-measuring-urban-configurational-asymmetries-through-neural-decompositionhttpsarxivorgabs251203755v1>#</a></h3><p><strong>Authors:</strong> Stephen Law, Tao Yang, Nanjiang Chen, Xuhui Lin
<strong>Venue:</strong> arXiv (2025)</p><p>Urban analytics increasingly relies on AI-driven trajectory analysis, yet current approaches suffer from methodological fragmentation: trajectory learning captures movement patterns but ignores spatial context, while spatial embedding methods encode street networks but miss temporal dynamics. Three gaps persist: (1) lack of joint training that integrates spatial and temporal representations, (2) origin-agnostic treatment that ignores directional asymmetries in navigation ($A \to B \ne B \to A$), and (3) over-reliance on auxiliary data (POIs, imagery) rather than fundamental geometric properties of urban space. We introduce a conditional trajectory encoder that jointly learns spatial and movement representations while preserving origin-dependent asymmetries using geometric features. This framework decomposes urban navigation into shared cognitive patterns and origin-specific spatial narratives, enabling quantitative measurement of cognitive asymmetries across starting locations. Our bidirectional LSTM processes visibility ratio and curvature features conditioned on learnable origin embeddings, decomposing representations into shared urban patterns and origin-specific signatures through contrastive learning. Results from six synthetic cities and real-world validation on Beijing&rsquo;s Xicheng District demonstrate that urban morphology creates systematic cognitive inequalities. This provides urban planners quantitative tools for assessing experiential equity, offers architects insights into layout decisions&rsquo; cognitive impacts, and enables origin-aware analytics for navigation systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03755v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03755v1">üìÑ Download PDF</a></p><hr><h3 id=knowing-oneself-with-and-through-ai-from-self-tracking-to-chatbotshttpsarxivorgabs251203682v1><a href=https://arxiv.org/abs/2512.03682v1>Knowing oneself with and through AI: From self-tracking to chatbots</a><a hidden class=anchor aria-hidden=true href=#knowing-oneself-with-and-through-ai-from-self-tracking-to-chatbotshttpsarxivorgabs251203682v1>#</a></h3><p><strong>Authors:</strong> Lucy Osler
<strong>Venue:</strong> arXiv (2025)</p><p>This chapter examines how algorithms and artificial intelligence are transforming our practices of self-knowledge, self-understanding, and self-narration. Drawing on frameworks from distributed cognition, I analyse three key domains where AI shapes how and what we come to know about ourselves: self-tracking applications, technologically-distributed autobiographical memories, and narrative co-construction with Large Language Models (LLMs). While self-tracking devices promise enhanced self-knowledge through quantified data, they also impose particular frameworks that can crowd out other forms of self-understanding and promote self-optimization. Digital technologies increasingly serve as repositories for our autobiographical memories and self-narratives, offering benefits such as detailed record-keeping and scaffolding during difficult periods, but also creating vulnerabilities to algorithmic manipulation. Finally, conversational AI introduces new possibilities for interactive narrative construction that mimics interpersonal dialogue. While LLMs can provide valuable support for self-exploration, they also present risks of narrative deference and the construction of self-narratives that are detached from reality.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03682v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03682v1">üìÑ Download PDF</a></p><hr><h3 id=a-descriptive-model-for-modelling-attacker-decision-making-in-cyber-deceptionhttpsarxivorgabs251203641v1><a href=https://arxiv.org/abs/2512.03641v1>A Descriptive Model for Modelling Attacker Decision-Making in Cyber-Deception</a><a hidden class=anchor aria-hidden=true href=#a-descriptive-model-for-modelling-attacker-decision-making-in-cyber-deceptionhttpsarxivorgabs251203641v1>#</a></h3><p><strong>Authors:</strong> B. R. Turner, O. Guidetti, N. M. Karie, R. Ryan, Y. Yan
<strong>Venue:</strong> arXiv (2025)</p><p>Cyber-deception is an increasingly important defensive strategy, shaping adversarial decision making through controlled misinformation, uncertainty, and misdirection. Although game-theoretic, Bayesian, Markov decision process, and reinforcement learning models offer insight into deceptive interactions, they typically assume an attacker has already chosen to engage. Such approaches overlook cognitive and perceptual factors that influence an attacker&rsquo;s initial decision to engage or withdraw. This paper presents a descriptive model that incorporates the psychological and strategic elements shaping this decision. The model defines five components, belief (B), scepticism (S), deception fidelity (D), reconnaissance (R), and experience (E), which interact to capture how adversaries interpret deceptive cues and assess whether continued engagement is worthwhile. The framework provides a structured method for analysing engagement decisions in cyber-deception scenarios. A series of experiments has been designed to evaluate this model through Capture the Flag activities incorporating varying levels of deception, supported by behavioural and biometric observations. These experiments have not yet been conducted, and no experimental findings are presented in this paper. These experiments will combine behavioural observations with biometric indicators to produce a multidimensional view of adversarial responses. Findings will improve understanding of the factors influencing engagement decisions and refine the model&rsquo;s relevance to real-world cyber-deception settings. By addressing the gap in existing models that presume engagement, this work supports more cognitively realistic and strategically effective cyber-deception practices.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03641v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03641v1">üìÑ Download PDF</a></p><hr><h3 id=artificial-intelligence--human-intelligence-who-controls-whomhttpsarxivorgabs251204131v1><a href=https://arxiv.org/abs/2512.04131v1>Artificial Intelligence / Human Intelligence: Who Controls Whom?</a><a hidden class=anchor aria-hidden=true href=#artificial-intelligence--human-intelligence-who-controls-whomhttpsarxivorgabs251204131v1>#</a></h3><p><strong>Authors:</strong> Charlotte Jacquemot
<strong>Venue:</strong> arXiv (2025)</p><p>Using the example of the film 2001: A Space Odyssey, this chapter illustrates the challenges posed by an AI capable of making decisions that go against human interests. But are human decisions always rational and ethical? In reality, the cognitive decision-making process is influenced by cognitive biases that affect our behavior and choices. AI not only reproduces these biases, but can also exploit them, with the potential to shape our decisions and judgments. Behind IA algorithms, there are sometimes individuals who show little concern for fundamental rights and impose their own rules. To address the ethical and societal challenges raised by AI and its governance, the regulation of digital platforms and education are keys levers. Regulation must reflect ethical, legal, and political choices, while education must strengthen digital literacy and teach people to make informed and critical choices when facing digital technologies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04131v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04131v1">üìÑ Download PDF</a></p><hr><h3 id=fine-grained-narrative-classification-in-biased-news-articleshttpsarxivorgabs251203582v1><a href=https://arxiv.org/abs/2512.03582v1>Fine-grained Narrative Classification in Biased News Articles</a><a hidden class=anchor aria-hidden=true href=#fine-grained-narrative-classification-in-biased-news-articleshttpsarxivorgabs251203582v1>#</a></h3><p><strong>Authors:</strong> Zeba Afroz, Harsh Vardhan, Pawan Bhakuni, Aanchal Punia, Rajdeep Kumar, Md. Shad Akhtar
<strong>Venue:</strong> arXiv (2025)</p><p>Narratives are the cognitive and emotional scaffolds of propaganda. They organize isolated persuasive techniques into coherent stories that justify actions, attribute blame, and evoke identification with ideological camps. In this paper, we propose a novel fine-grained narrative classification in biased news articles. We also explore article-bias classification as the precursor task to narrative classification and fine-grained persuasive technique identification. We develop INDI-PROP, the first ideologically grounded fine-grained narrative dataset with multi-level annotation for analyzing propaganda in Indian news media. Our dataset INDI-PROP comprises 1,266 articles focusing on two polarizing socio-political events in recent times: CAA and the Farmers&rsquo; protest. Each article is annotated at three hierarchical levels: (i) ideological article-bias (pro-government, pro-opposition, neutral), (ii) event-specific fine-grained narrative frames anchored in ideological polarity and communicative intent, and (iii) persuasive techniques. We propose FANTA and TPTC, two GPT-4o-mini guided multi-hop prompt-based reasoning frameworks for the bias, narrative, and persuasive technique classification. FANTA leverages multi-layered communicative phenomena by integrating information extraction and contextual framing for hierarchical reasoning. On the other hand, TPTC adopts systematic decomposition of persuasive cues via a two-stage approach. Our evaluation suggests substantial improvement over underlying baselines in each case.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03582v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03582v1">üìÑ Download PDF</a></p><hr><h3 id=synthetic-cognitive-walkthrough-aligning-large-language-model-performance-with-human-cognitive-walkthroughhttpsarxivorgabs251203568v1><a href=https://arxiv.org/abs/2512.03568v1>Synthetic Cognitive Walkthrough: Aligning Large Language Model Performance with Human Cognitive Walkthrough</a><a hidden class=anchor aria-hidden=true href=#synthetic-cognitive-walkthrough-aligning-large-language-model-performance-with-human-cognitive-walkthroughhttpsarxivorgabs251203568v1>#</a></h3><p><strong>Authors:</strong> Ruican Zhong, David W. McDonald, Gary Hsieh
<strong>Venue:</strong> arXiv (2025)</p><p>Conducting usability testing like cognitive walkthrough (CW) can be costly. Recent developments in large language models (LLMs), with visual reasoning and UI navigation capabilities, present opportunities to automate CW. We explored whether LLMs (GPT-4 and Gemini-2.5-pro) can simulate human behavior in CW by comparing their walkthroughs with human participants. While LLMs could navigate interfaces and provide reasonable rationales, their behavior differed from humans. LLM-prompted CW achieved higher task completion rates than humans and followed more optimal navigation paths, while identifying fewer potential failure points. However, follow-up studies demonstrated that with additional prompting, LLMs can predict human-identified failure points, aligning their performance with human participants. Our work highlights that while LLMs may not replicate human behaviors exactly, they can be leveraged for scaling usability walkthroughs and providing UI insights, offering a valuable complement to traditional usability testing.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03568v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03568v1">üìÑ Download PDF</a></p><hr><h3 id=optimal-griffiths-phase-in-heterogeneous-human-brain-networks-brain-criticality-embracing-stability-and-flexibility-across-individualshttpsarxivorgabs251203409v1><a href=https://arxiv.org/abs/2512.03409v1>Optimal Griffiths Phase in Heterogeneous Human Brain Networks: Brain Criticality Embracing Stability and Flexibility across Individuals</a><a hidden class=anchor aria-hidden=true href=#optimal-griffiths-phase-in-heterogeneous-human-brain-networks-brain-criticality-embracing-stability-and-flexibility-across-individualshttpsarxivorgabs251203409v1>#</a></h3><p><strong>Authors:</strong> Kejian Wu, Dante R. Chialvo, Changsong Zhou, Lianchun Yu
<strong>Venue:</strong> arXiv (2025)</p><p>A prominent hypothesis in neuroscience proposes that brains achieve optimal performance by operating near a critical point. However, this framework, which often assumes a universal critical point, fails to account for the extensive individual variability observed in neural dynamics and cognitive functions. These variabilities are not noise but rather an inherent manifestation of a fundamental systems-biology principle: the necessary trade-off between robustness and flexibility in human populations. Here, we propose that the Griffiths phase (GP), an extended critical regime synergically induced by two kinds of heterogeneities in brain network region and connectivity, offers a unified framework for brain criticality that better reconciles robustness and flexibility and accounts for individual variability. Using Human Connectome Project data and whole-brain modeling, we demonstrated that the synergic interplay between structural network modularity and regional heterogeneity in local excitability yields biologically viable GP featured with widely extended global excitability ranges, with an embedded optimal point that balances global/local information transmission. Crucially, an individua&rsquo;s position within the GP gives rise to unique global network dynamics, which in turn confer a distinctive cognitive profile via flexible configuration of functional connectivity for segregation, integration, and balance between them. These results establish GP as an evolved adaptive mechanism resolving the robustness-flexibility trade-off, fulfilling diverse cognitive demands through individualized criticality landscapes, providing a new framework of brain criticality.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03409v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03409v1">üìÑ Download PDF</a></p><hr><h3 id=llm-generated-ads-from-personalization-parity-to-persuasion-superiorityhttpsarxivorgabs251203373v1><a href=https://arxiv.org/abs/2512.03373v1>LLM-Generated Ads: From Personalization Parity to Persuasion Superiority</a><a hidden class=anchor aria-hidden=true href=#llm-generated-ads-from-personalization-parity-to-persuasion-superiorityhttpsarxivorgabs251203373v1>#</a></h3><p><strong>Authors:</strong> Elyas Meguellati, Stefano Civelli, Lei Han, Abraham Bernstein, Shazia Sadiq, Gianluca Demartini
<strong>Venue:</strong> arXiv (2025)</p><p>As large language models (LLMs) become increasingly capable of generating persuasive content, understanding their effectiveness across different advertising strategies becomes critical. This paper presents a two-part investigation examining LLM-generated advertising through complementary lenses: (1) personality-based and (2) psychological persuasion principles.
In our first study (n=400), we tested whether LLMs could generate personalized advertisements tailored to specific personality traits (openness and neuroticism) and how their performance compared to human experts. Results showed that LLM-generated ads achieved statistical parity with human-written ads (51.1% vs. 48.9%, p > 0.05), with no significant performance differences for matched personalities.
Building on these insights, our second study (n=800) shifted focus from individual personalization to universal persuasion, testing LLM performance across four foundational psychological principles: authority, consensus, cognition, and scarcity. AI-generated ads significantly outperformed human-created content, achieving a 59.1% preference rate (vs. 40.9%, p &lt; 0.001), with the strongest performance in authority (63.0%) and consensus (62.5%) appeals. Qualitative analysis revealed AI&rsquo;s advantage stems from crafting more sophisticated, aspirational messages and achieving superior visual-narrative coherence. Critically, this quality advantage proved robust: even after applying a 21.2 percentage point detection penalty when participants correctly identified AI-origin, AI ads still outperformed human ads, and 29.4% of participants chose AI content despite knowing its origin. These findings demonstrate LLMs&rsquo; evolution from parity in personalization to superiority in persuasive storytelling, with significant implications for advertising practice given LLMs&rsquo; near-zero marginal cost and time requirements compared to human experts.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03373v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03373v1">üìÑ Download PDF</a></p><hr><h3 id=prior-preferences-in-active-inference-agents-soft-hard-and-goal-shapinghttpsarxivorgabs251203293v1><a href=https://arxiv.org/abs/2512.03293v1>Prior preferences in active inference agents: soft, hard, and goal shaping</a><a hidden class=anchor aria-hidden=true href=#prior-preferences-in-active-inference-agents-soft-hard-and-goal-shapinghttpsarxivorgabs251203293v1>#</a></h3><p><strong>Authors:</strong> Filippo Torresan, Ryota Kanai, Manuel Baltieri
<strong>Venue:</strong> arXiv (2025)</p><p>Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent&rsquo;s goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment&rsquo;s transition dynamics (i.e., it hampers exploration).</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03293v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03293v1">üìÑ Download PDF</a></p><hr><h3 id=video4spatial-towards-visuospatial-intelligence-with-context-guided-video-generationhttpsarxivorgabs251203040v1><a href=https://arxiv.org/abs/2512.03040v1>Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation</a><a hidden class=anchor aria-hidden=true href=#video4spatial-towards-visuospatial-intelligence-with-context-guided-video-generationhttpsarxivorgabs251203040v1>#</a></h3><p><strong>Authors:</strong> Zeqi Xiao, Yiwei Zhao, Lingxiao Li, Yushi Lan, Yu Ning, Rahul Garg, Roshni Cooper, Mohammad H. Taghavi, Xingang Pan
<strong>Venue:</strong> arXiv (2025)</p><p>We investigate whether video generative models can exhibit visuospatial intelligence, a capability central to human cognition, using only visual data. To this end, we present Video4Spatial, a framework showing that video diffusion models conditioned solely on video-based scene context can perform complex spatial tasks. We validate on two tasks: scene navigation - following camera-pose instructions while remaining consistent with 3D geometry of the scene, and object grounding - which requires semantic localization, instruction following, and planning. Both tasks use video-only inputs, without auxiliary modalities such as depth or poses. With simple yet effective design choices in the framework and data curation, Video4Spatial demonstrates strong spatial understanding from video context: it plans navigation and grounds target objects end-to-end, follows camera-pose instructions while maintaining spatial consistency, and generalizes to long contexts and out-of-domain environments. Taken together, these results advance video generative models toward general visuospatial reasoning.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03040v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03040v1">üìÑ Download PDF</a></p><hr><h3 id=inex-hallucination-mitigation-via-introspection-and-cross-modal-multi-agent-collaborationhttpsarxivorgabs251202981v1><a href=https://arxiv.org/abs/2512.02981v1>InEx: Hallucination Mitigation via Introspection and Cross-Modal Multi-Agent Collaboration</a><a hidden class=anchor aria-hidden=true href=#inex-hallucination-mitigation-via-introspection-and-cross-modal-multi-agent-collaborationhttpsarxivorgabs251202981v1>#</a></h3><p><strong>Authors:</strong> Zhongyu Yang, Yingfang Yuan, Xuanming Jiang, Baoyi An, Wei Pang
<strong>Venue:</strong> arXiv (2025)</p><p>Hallucination remains a critical challenge in large language models (LLMs), hindering the development of reliable multimodal LLMs (MLLMs). Existing solutions often rely on human intervention or underutilize the agent&rsquo;s ability to autonomously mitigate hallucination. To address these limitations, we draw inspiration from how humans make reliable decisions in the real world. They begin with introspective reasoning to reduce uncertainty and form an initial judgment, then rely on external verification from diverse perspectives to reach a final decision. Motivated by this cognitive paradigm, we propose InEx, a training-free, multi-agent framework designed to autonomously mitigate hallucination. InEx introduces internal introspective reasoning, guided by entropy-based uncertainty estimation, to improve the reliability of the decision agent&rsquo;s reasoning process. The agent first generates a response, which is then iteratively verified and refined through external cross-modal multi-agent collaboration with the editing agent and self-reflection agents, further enhancing reliability and mitigating hallucination. Extensive experiments show that InEx consistently outperforms existing methods, achieving 4%-27% gains on general and hallucination benchmarks, and demonstrating strong robustness.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02981v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02981v1">üìÑ Download PDF</a></p><hr><h3 id=rethinking-generalized-bcis-benchmarking-340000-unique-algorithmic-configurations-for-eeg-mental-command-decodinghttpsarxivorgabs251202978v1><a href=https://arxiv.org/abs/2512.02978v1>Rethinking Generalized BCIs: Benchmarking 340,000+ Unique Algorithmic Configurations for EEG Mental Command Decoding</a><a hidden class=anchor aria-hidden=true href=#rethinking-generalized-bcis-benchmarking-340000-unique-algorithmic-configurations-for-eeg-mental-command-decodinghttpsarxivorgabs251202978v1>#</a></h3><p><strong>Authors:</strong> Paul Barbaste, Olivier Oullier, Xavier Vasques
<strong>Venue:</strong> arXiv (2025)</p><p>Robust decoding and classification of brain patterns measured with electroencephalography (EEG) remains a major challenge for real-world (i.e. outside scientific lab and medical facilities) brain-computer interface (BCI) applications due to well documented inter- and intra-participant variability. Here, we present a large-scale benchmark evaluating over 340,000+ unique combinations of spatial and nonlinear EEG classification. Our methodological pipeline consists in combinations of Common Spatial Patterns (CSP), Riemannian geometry, functional connectivity, and fractal- or entropy-based features across three open-access EEG datasets. Unlike prior studies, our analysis operates at the per-participant level and across multiple frequency bands (8-15 Hz and 8-30 Hz), enabling direct assessment of both group-level performance and individual variability. Covariance tangent space projection (cov-tgsp) and CSP consistently achieved the highest average classification accuracies. However, their effectiveness was strongly dataset-dependent, and marked participant-level differences persisted, particularly in the most heterogeneous of the datasets. Importantly, nonlinear methods outperformed spatial approaches for specific individuals, underscoring the need for personalized pipeline selection. Our findings highlight that no universal &lsquo;one-size-fits-all&rsquo; method can optimally decode EEG motor imagery patterns across all users or datasets. Future work will require adaptive, multimodal, and possibly novel approaches to fully address neurophysiological variability in practical BCI applications where the system can automatically adapt to what makes each user unique.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02978v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02978v1">üìÑ Download PDF</a></p><hr><h3 id=the-future-of-ai-in-critical-mineral-explorationhttpsarxivorgabs251202879v1><a href=https://arxiv.org/abs/2512.02879v1>The future of AI in critical mineral exploration</a><a hidden class=anchor aria-hidden=true href=#the-future-of-ai-in-critical-mineral-explorationhttpsarxivorgabs251202879v1>#</a></h3><p><strong>Authors:</strong> Jef Caers
<strong>Venue:</strong> arXiv (2025)</p><p>The energy transition through increased electrification has put the worlds attention on critical mineral exploration Even with increased investments a decrease in new discoveries has taken place over the last two decades Here I propose a solution to this problem where AI is implemented as the enabler of a rigorous scientific method for mineral exploration that aims to reduce cognitive bias and false positives drive down the cost of exploration I propose a new scientific method that is based on a philosophical approach founded on the principles of Bayesianism and falsification In this approach data acquisition is in the first place seen as a means to falsify human generated hypothesis Decision of what data to acquire next is quantified with verifiable metrics and based on rational decision making A practical protocol is provided that can be used as a template in any exploration campaign However in order to make this protocol practical various form of artificial intelligence are needed I will argue that the most important form are one novel unsupervised learning methods that collaborate with domain experts to better understand data and generate multiple competing geological hypotheses and two humanintheloop AI algorithms that can optimally plan various geological geophysical geochemical and drilling data acquisition where uncertainty reduction of geological hypothesis precedes the uncertainty reduction on grade and tonnage</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02879v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02879v1">üìÑ Download PDF</a></p><hr><h3 id=learning-science-and-the-illusion-of-understanding-exploring-the-effects-of-integrating-learning-tasks-after-explainer-videoshttpsarxivorgabs251202824v1><a href=https://arxiv.org/abs/2512.02824v1>Learning Science and the Illusion of Understanding: Exploring the Effects of Integrating Learning Tasks after Explainer Videos</a><a hidden class=anchor aria-hidden=true href=#learning-science-and-the-illusion-of-understanding-exploring-the-effects-of-integrating-learning-tasks-after-explainer-videoshttpsarxivorgabs251202824v1>#</a></h3><p><strong>Authors:</strong> Madeleine H√∂rnlein, Christoph Kulgemeyer
<strong>Venue:</strong> arXiv (2025)</p><p>Explainer videos are increasingly used to support science learning. While prior research has demonstrated their potential, studies have also identified limitations - particularly their tendency to foster an illusion of understanding, where learners overestimate their grasp of a topic despite gaps in their actual knowledge. Pairing explainer videos with cognitively engaging elements may help mitigate this effect. This paper reports two experimental studies examining the immediate and long-term effects of learning tasks following a physics explainer video on learners&rsquo; illusion of understanding. Study 1 (N = 244 learners) compared high-level learning tasks with watching the video alone. Study 2 (N = 175) compared high-level and low-level tasks. Results show that high-level learning tasks significantly reduce the illusion of understanding immediately after the intervention compared to watching the video alone (t(88) = 6.50, p &lt; .001, d = 0.69). Over the long term, both high-and low-level tasks are similarly effective. Learners with lower prior content knowledge are more susceptible to an illusion of understanding. We conclude that explainer videos should not be used in isolation in science classrooms. To prevent misjudged understanding - particularly among students with limited prior knowledge - they should be combined with cognitively demanding follow-up activities.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02824v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02824v1">üìÑ Download PDF</a></p><hr><h3 id=responsible-discovery-in-astrobiology-lessons-from-four-controversial-claimshttpsarxivorgabs251204122v1><a href=https://arxiv.org/abs/2512.04122v1>Responsible Discovery in Astrobiology: Lessons from Four Controversial Claims</a><a hidden class=anchor aria-hidden=true href=#responsible-discovery-in-astrobiology-lessons-from-four-controversial-claimshttpsarxivorgabs251204122v1>#</a></h3><p><strong>Authors:</strong> Daliah Raquel Bibas, Cl√©ment Vidal
<strong>Venue:</strong> arXiv (2025)</p><p>This paper examines four case studies of life-detection claims in astrobiology, covering both biosignatures and technosignatures: the 1877 &ldquo;canals&rdquo; on Mars, the 1976 Mars Viking landers experiments, the 2020 phosphine detection on Venus, and the 2020 Breakthrough Listen Candidate 1 (BLC1) signal. We analyse the process of discovery for each case, including how they were detected, the media reception, the ensuing scientific debate, the correction processes, and the time it took until an expert consensus was reached. We identify lessons learned while providing scientists, the scientific community, and science communicators with recommendations for approaching future claims of astrobiological discoveries. To avoid potential cognitive biases and mitigate premature conclusions, we stress the need for clear communication of uncertainties, as well as thorough debate and verification processes among the scientific community. These responsible approaches can strengthen the credibility of scientists, cultivate a supportive scientific community, and help astrobiology flourish as a field.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04122v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04122v1">üìÑ Download PDF</a></p><hr><h3 id=cogdrive-cognition-driven-multimodal-prediction-planning-fusion-for-safe-autonomyhttpsarxivorgabs251202777v1><a href=https://arxiv.org/abs/2512.02777v1>CogDrive: Cognition-Driven Multimodal Prediction-Planning Fusion for Safe Autonomy</a><a hidden class=anchor aria-hidden=true href=#cogdrive-cognition-driven-multimodal-prediction-planning-fusion-for-safe-autonomyhttpsarxivorgabs251202777v1>#</a></h3><p><strong>Authors:</strong> Heye Huang, Yibin Yang, Mingfeng Fan, Haoran Wang, Xiaocong Zhao, Jianqiang Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Safe autonomous driving in mixed traffic requires a unified understanding of multimodal interactions and dynamic planning under uncertainty. Existing learning based approaches struggle to capture rare but safety critical behaviors, while rule based systems often lack adaptability in complex interactions. To address these limitations, CogDrive introduces a cognition driven multimodal prediction and planning framework that integrates explicit modal reasoning with safety aware trajectory optimization. The prediction module adopts cognitive representations of interaction modes based on topological motion semantics and nearest neighbor relational encoding. With a differentiable modal loss and multimodal Gaussian decoding, CogDrive learns sparse and unbalanced interaction behaviors and improves long horizon trajectory prediction. The planning module incorporates an emergency response concept and optimizes safety stabilized trajectories, where short term consistent branches ensure safety during replanning cycles and long term branches support smooth and collision free motion under low probability switching modes. Experiments on Argoverse2 and INTERACTION datasets show that CogDrive achieves strong performance in trajectory accuracy and miss rate, while closed loop simulations confirm adaptive behavior in merge and intersection scenarios. By combining cognitive multimodal prediction with safety oriented planning, CogDrive offers an interpretable and reliable paradigm for safe autonomy in complex traffic.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02777v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02777v1">üìÑ Download PDF</a></p><hr><h3 id=emergent-bayesian-behaviour-and-optimal-cue-combination-in-llmshttpsarxivorgabs251202719v1><a href=https://arxiv.org/abs/2512.02719v1>Emergent Bayesian Behaviour and Optimal Cue Combination in LLMs</a><a hidden class=anchor aria-hidden=true href=#emergent-bayesian-behaviour-and-optimal-cue-combination-in-llmshttpsarxivorgabs251202719v1>#</a></h3><p><strong>Authors:</strong> Julian Ma, Jun Wang, Zafeirios Fountas
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) excel at explicit reasoning, but their implicit computational strategies remain underexplored. Decades of psychophysics research show that humans intuitively process and integrate noisy signals using near-optimal Bayesian strategies in perceptual tasks. We ask whether LLMs exhibit similar behaviour and perform optimal multimodal integration without explicit training or instruction. Adopting the psychophysics paradigm, we infer computational principles of LLMs from systematic behavioural studies. We introduce a behavioural benchmark - BayesBench: four magnitude estimation tasks (length, location, distance, and duration) over text and image, inspired by classic psychophysics, and evaluate a diverse set of nine LLMs alongside human judgments for calibration. Through controlled ablations of noise, context, and instruction prompts, we measure performance, behaviour and efficiency in multimodal cue-combination. Beyond accuracy and efficiency metrics, we introduce a Bayesian Consistency Score that detects Bayes-consistent behavioural shifts even when accuracy saturates. Our results show that while capable models often adapt in Bayes-consistent ways, accuracy does not guarantee robustness. Notably, GPT-5 Mini achieves perfect text accuracy but fails to integrate visual cues efficiently. This reveals a critical dissociation between capability and strategy, suggesting accuracy-centric benchmarks may over-index on performance while missing brittle uncertainty handling. These findings reveal emergent principled handling of uncertainty and highlight the correlation between accuracy and Bayesian tendencies. We release our psychophysics benchmark and consistency metric (<a href=https://bayes-bench.github.io>https://bayes-bench.github.io</a>) as evaluation tools and to inform future multimodal architecture designs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02719v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02719v1">üìÑ Download PDF</a></p><hr><h3 id=translating-measures-onto-mechanisms-the-cognitive-relevance-of-higher-order-informationhttpsarxivorgabs251202671v1><a href=https://arxiv.org/abs/2512.02671v1>Translating Measures onto Mechanisms: The Cognitive Relevance of Higher-Order Information</a><a hidden class=anchor aria-hidden=true href=#translating-measures-onto-mechanisms-the-cognitive-relevance-of-higher-order-informationhttpsarxivorgabs251202671v1>#</a></h3><p><strong>Authors:</strong> D. Rebbin, K. J. A. Down, T. F. Varley, R. Ince, A. Canales-Johnson
<strong>Venue:</strong> arXiv (2025)</p><p>Higher-order information theory has become a rapidly growing toolkit in computational neuroscience, motivated by the idea that multivariate dependencies can reveal aspects of neural computation and communication that are invisible to pairwise analyses. Yet functional interpretations of synergy and redundancy often outpace principled arguments for how statistical quantities map onto mechanistic cognitive processes. Here we review the main families of higher-order measures with the explicit goal of translating mathematical properties into defensible mechanistic inferences. First, we systematize Shannon-based multivariate metrics and demonstrate that higher-order dependence is parsimoniously characterized by two largely independent axes: interaction strength and redundancy-synergy balance. We argue that balanced layering of synergistic integration and redundant broadcasting optimizes multiscale complexity, formalizing a computation-communication tradeoff. We then examine the partial information decomposition and outline pragmatic considerations for its deployment in neural data. Equipped with the relevant mathematical essentials, we connect redundancy-synergy balance to cognitive function by progressively embedding their mathematical properties in real-world constraints, starting with small synthetic systems before gradually building up to neuroimaging. We close by identifying key future directions for mechanistic insight: cross-scale bridging, intervention-based validation, and thermodynamically grounded unification of information dynamics.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02671v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02671v1">üìÑ Download PDF</a></p><hr><h3 id=real-time-multimodal-data-collection-using-smartwatches-and-its-visualization-in-educationhttpsarxivorgabs251202651v1><a href=https://arxiv.org/abs/2512.02651v1>Real-Time Multimodal Data Collection Using Smartwatches and Its Visualization in Education</a><a hidden class=anchor aria-hidden=true href=#real-time-multimodal-data-collection-using-smartwatches-and-its-visualization-in-educationhttpsarxivorgabs251202651v1>#</a></h3><p><strong>Authors:</strong> Alvaro Becerra, Pablo Villegas, Ruth Cobos
<strong>Venue:</strong> arXiv (2025)</p><p>Wearable sensors, such as smartwatches, have become increasingly prevalent across domains like healthcare, sports, and education, enabling continuous monitoring of physiological and behavioral data. In the context of education, these technologies offer new opportunities to study cognitive and affective processes such as engagement, attention, and performance. However, the lack of scalable, synchronized, and high-resolution tools for multimodal data acquisition continues to be a significant barrier to the widespread adoption of Multimodal Learning Analytics in real-world educational settings. This paper presents two complementary tools developed to address these challenges: Watch-DMLT, a data acquisition application for Fitbit Sense 2 smartwatches that enables real-time, multi-user monitoring of physiological and motion signals; and ViSeDOPS, a dashboard-based visualization system for analyzing synchronized multimodal data collected during oral presentations. We report on a classroom deployment involving 65 students and up to 16 smartwatches, where data streams including heart rate, motion, gaze, video, and contextual annotations were captured and analyzed. Results demonstrate the feasibility and utility of the proposed system for supporting fine-grained, scalable, and interpretable Multimodal Learning Analytics in real learning environments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02651v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02651v1">üìÑ Download PDF</a></p><hr><h3 id=contact-implicit-modeling-and-simulation-of-a-snake-robot-on-compliant-and-granular-terrainhttpsarxivorgabs251205008v1><a href=https://arxiv.org/abs/2512.05008v1>Contact-Implicit Modeling and Simulation of a Snake Robot on Compliant and Granular Terrain</a><a hidden class=anchor aria-hidden=true href=#contact-implicit-modeling-and-simulation-of-a-snake-robot-on-compliant-and-granular-terrainhttpsarxivorgabs251205008v1>#</a></h3><p><strong>Authors:</strong> Haroon Hublikar
<strong>Venue:</strong> arXiv (2025)</p><p>This thesis presents a unified modeling and simulation framework for analyzing sidewinding and tumbling locomotion of the COBRA snake robot across rigid, compliant, and granular terrains. A contact-implicit formulation is used to model distributed frictional interactions during sidewinding, and validated through MATLAB Simscape simulations and physical experiments on rigid ground and loose sand. To capture terrain deformation effects, Project Chrono&rsquo;s Soil Contact Model (SCM) is integrated with the articulated multibody dynamics, enabling prediction of slip, sinkage, and load redistribution that reduce stride efficiency on deformable substrates. For high-energy rolling locomotion on steep slopes, the Chrono DEM Engine is used to simulate particle-resolved granular interactions, revealing soil failure, intermittent lift-off, and energy dissipation mechanisms not captured by rigid models. Together, these methods span real-time control-oriented simulation and high-fidelity granular physics. Results demonstrate that rigid-ground models provide accurate short-horizon motion prediction, while continuum and particle-based terrain modeling becomes necessary for reliable mobility analysis in soft and highly dynamic environments. This work establishes a hierarchical simulation pipeline that advances robust, terrain-aware locomotion for robots operating in challenging unstructured settings.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05008v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05008v1">üìÑ Download PDF</a></p><hr><h3 id=recurrent-neural-networks-with-linear-structures-for-electricity-price-forecastinghttpsarxivorgabs251204690v1><a href=https://arxiv.org/abs/2512.04690v1>Recurrent Neural Networks with Linear Structures for Electricity Price Forecasting</a><a hidden class=anchor aria-hidden=true href=#recurrent-neural-networks-with-linear-structures-for-electricity-price-forecastinghttpsarxivorgabs251204690v1>#</a></h3><p><strong>Authors:</strong> Souhir Ben Amor, Florian Ziel
<strong>Venue:</strong> arXiv (2025)</p><p>We present a novel recurrent neural network architecture designed explicitly for day-ahead electricity price forecasting, aimed at improving short-term decision-making and operational management in energy systems. Our combined forecasting model embeds linear structures, such as expert models and Kalman filters, into recurrent networks, enabling efficient computation and enhanced interpretability. The design leverages the strengths of both linear and non-linear model structures, allowing it to capture all relevant stylised price characteristics in power markets, including calendar and autoregressive effects, as well as influences from load, renewable energy, and related fuel and carbon markets. For empirical testing, we use hourly data from the largest European electricity market spanning 2018 to 2025 in a comprehensive forecasting study, comparing our model against state-of-the-art approaches, particularly high-dimensional linear and neural network models. The proposed model achieves approximately 12% higher accuracy than leading benchmarks. We evaluate the contributions of the interpretable model components and conclude on the impact of combining linear and non-linear structures.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04690v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04690v1">üìÑ Download PDF</a></p><hr><h3 id=learning-single-image-super-resolution-in-the-jpeg-compressed-domainhttpsarxivorgabs251204284v1><a href=https://arxiv.org/abs/2512.04284v1>Learning Single-Image Super-Resolution in the JPEG Compressed Domain</a><a hidden class=anchor aria-hidden=true href=#learning-single-image-super-resolution-in-the-jpeg-compressed-domainhttpsarxivorgabs251204284v1>#</a></h3><p><strong>Authors:</strong> Sruthi Srinivasan, Elham Shakibapour, Rajy Rawther, Mehdi Saeedi
<strong>Venue:</strong> arXiv (2025)</p><p>Deep learning models have grown increasingly complex, with input data sizes scaling accordingly. Despite substantial advances in specialized deep learning hardware, data loading continues to be a major bottleneck that limits training and inference speed. To address this challenge, we propose training models directly on encoded JPEG features, reducing the computational overhead associated with full JPEG decoding and significantly improving data loading efficiency. While prior works have focused on recognition tasks, we investigate the effectiveness of this approach for the restoration task of single-image super-resolution (SISR). We present a lightweight super-resolution pipeline that operates on JPEG discrete cosine transform (DCT) coefficients in the frequency domain. Our pipeline achieves a 2.6x speedup in data loading and a 2.5x speedup in training, while preserving visual quality comparable to standard SISR approaches.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04284v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04284v1">üìÑ Download PDF</a></p><hr><h3 id=pinn-vs-lstm-a-comparative-study-for-steam-temperature-control-in-heat-recovery-steam-generatorshttpsarxivorgabs251204183v1><a href=https://arxiv.org/abs/2512.04183v1>PINN vs LSTM: A Comparative Study for Steam Temperature Control in Heat Recovery Steam Generators</a><a hidden class=anchor aria-hidden=true href=#pinn-vs-lstm-a-comparative-study-for-steam-temperature-control-in-heat-recovery-steam-generatorshttpsarxivorgabs251204183v1>#</a></h3><p><strong>Authors:</strong> Mojtaba Fanoodi, Farzaneh Abdollahi, Mahdi Aliyari Shoorehdeli
<strong>Venue:</strong> arXiv (2025)</p><p>This paper introduces a direct comparative study of Physics-Informed Neural Networks (PINNs) and Long Short-Term Memory (LSTM) networks for adaptive steam temperature control in Heat Recovery Steam Generators (HRSGs), particularly under valve leakage faults. Maintaining precise steam temperature in HRSGs is critical for efficiency and safety, yet traditional control strategies struggle with nonlinear, fault-induced dynamics. Both architectures are designed to adaptively tune the gains of a PI-plus-feedforward control law in real-time. The LSTM controller, a purely data-driven approach, was trained offline on historical operational data, while the PINN controller integrates fundamental thermodynamic laws directly into its online learning process through a physics-based loss function. Their performance was evaluated using a model validated with data from a combined cycle power plant, under normal load changes and a challenging valve leakage fault scenario. Results demonstrate that while the LSTM controller offers significant improvement over conventional methods, its performance degrades under the unseen fault. The PINN controller consistently delivered superior robustness and performance, achieving a 54% reduction in integral absolute error compared to the LSTM under fault conditions. This study concludes that embedding physical knowledge into data-driven control is essential for developing reliable, fault-tolerant autonomous control systems in complex industrial applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04183v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04183v1">üìÑ Download PDF</a></p><hr><h3 id=augserve-adaptive-request-scheduling-for-augmented-large-language-model-inference-servinghttpsarxivorgabs251204013v1><a href=https://arxiv.org/abs/2512.04013v1>AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving</a><a hidden class=anchor aria-hidden=true href=#augserve-adaptive-request-scheduling-for-augmented-large-language-model-inference-servinghttpsarxivorgabs251204013v1>#</a></h3><p><strong>Authors:</strong> Ying Wang, Zhen Jin, Jiexiong Xu, Wenhai Lin, Yiquan Chen, Wenzhi Chen
<strong>Venue:</strong> arXiv (2025)</p><p>As augmented large language models (LLMs) with external tools become increasingly popular in web applications, improving augmented LLM inference serving efficiency and optimizing service-level objectives (SLOs) are critical for enhancing user experience. To achieve this, inference systems must maximize request handling within latency constraints, referred to as increasing effective throughput. However, existing systems face two major challenges: (i) reliance on first-come-first-served (FCFS) scheduling causes severe head-of-line blocking, leading to queuing delays exceeding the SLOs for many requests; and (ii) static batch token limit, which fails to adapt to fluctuating loads and hardware conditions. Both of these factors degrade effective throughput and service quality.
This paper presents AugServe, an efficient inference framework designed to reduce queueing latency and enhance effective throughput for augmented LLM inference services. The core idea of AugServe is a two-stage adaptive request scheduling strategy. Specifically, AugServe combines the inference features of augmented LLM requests to optimize the order of scheduling decisions (stage I). These decisions are continuously refined with runtime information (stage II), adapting to both request characteristics and system capabilities. In addition, AugServe dynamically adjusts the token batching mechanism based on hardware status and real-time load, further enhancing throughput performance. Experimental results show that AugServe achieves 4.7-33.1x and 3.3-13.2x higher effective throughput than vLLM and InferCept, while reducing time-to-first-token (TTFT) by up to 96.3% and 95.0%, respectively.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04013v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04013v1">üìÑ Download PDF</a></p><hr><h3 id=od-moe-on-demand-expert-loading-for-cacheless-edge-distributed-moe-inferencehttpsarxivorgabs251203927v1><a href=https://arxiv.org/abs/2512.03927v1>OD-MoE: On-Demand Expert Loading for Cacheless Edge-Distributed MoE Inference</a><a hidden class=anchor aria-hidden=true href=#od-moe-on-demand-expert-loading-for-cacheless-edge-distributed-moe-inferencehttpsarxivorgabs251203927v1>#</a></h3><p><strong>Authors:</strong> Liujianfu Wang, Yuyang Du, Yuchen Pan, Soung Chang Liew, Jiacheng Liu, Kexin Chen
<strong>Venue:</strong> arXiv (2025)</p><p>Mixture-of-Experts (MoE), while offering significant advantages as a Large Language Model (LLM) architecture, faces substantial challenges when deployed on low-cost edge devices with tight memory constraints. Expert offloading mitigates this issue by storing expert parameters in CPU memory and caching a subset of popular experts in GPU memory. Although this approach improves GPU memory utilization by caching only the likely-used experts, the GPU memory reserved for expert caching is underutilized compared with dense LLMs. This paper presents OD-MoE, a distributed MoE inference framework that obviates the need for expert caches via fully on-demand expert loading. OD-MoE is built upon two key mechanisms: 1) parallelizing expert loading and expert computation across distributed edge nodes, and 2) an ultra-accurate emulative predictor that forecasts expert activations multiple layers ahead while expert computation is ongoing. With these innovations, OD-MoE dynamically loads each target expert to one of the distributed nodes just-in-time before its activation and promptly evicts it afterward, freeing GPU memory for subsequent experts. We comprehensively benchmark OD-MoE against state-of-the-art MoE offloading systems on a ten-node testbed. Experimental results show that: 1) OD-MoE achieves 99.94% expert activation prediction accuracy, substantially surpassing all existing methods; and 2) OD-MoE delivers approximately 75% of the decoding speed of a fully GPU-cached MoE deployment while using only 1/3 of the GPU memory. More importantly, by eliminating the need for expert caches, OD-MoE enables MoE inference on edge nodes with less-than-1GB GPU memory, paving the way for practical MoE deployment of low-cost IoT devices at the edge in the LLM era.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03927v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03927v1">üìÑ Download PDF</a></p><hr><h3 id=a-theoretical-framework-for-auxiliary-loss-free-load-balancing-of-sparse-mixture-of-experts-in-large-scale-ai-modelshttpsarxivorgabs251203915v2><a href=https://arxiv.org/abs/2512.03915v2>A Theoretical Framework for Auxiliary-Loss-Free Load Balancing of Sparse Mixture-of-Experts in Large-Scale AI Models</a><a hidden class=anchor aria-hidden=true href=#a-theoretical-framework-for-auxiliary-loss-free-load-balancing-of-sparse-mixture-of-experts-in-large-scale-ai-modelshttpsarxivorgabs251203915v2>#</a></h3><p><strong>Authors:</strong> X. Y. Han, Yuan Zhong
<strong>Venue:</strong> arXiv (2025)</p><p>In large-scale AI training, Sparse Mixture-of-Experts (s-MoE) layers enable scaling by activating only a small subset of experts per token. An operational challenge in this design is load balancing: routing tokens to minimize the number of idle experts, which is important for the efficient utilization of (costly) GPUs. We provide a theoretical framework for analyzing the Auxiliary-Loss-Free Load Balancing (ALF-LB) procedure &ndash; proposed by DeepSeek&rsquo;s Wang et al. (2024) &ndash; by casting it as a one-step-per-iteration primal-dual method for an assignment problem. First, in a stylized deterministic setting, our framework yields several insightful structural properties: (i) a monotonic improvement of a Lagrangian objective, (ii) a preference rule that moves tokens from overloaded to underloaded experts, and (iii) an approximate-balancing guarantee. Then, we incorporate the stochastic and dynamic nature of AI training using a generalized online optimization formulation. In the online setting, we derive a strong convexity property of the objective that leads to a logarithmic expected regret bound under certain step-size choices. Additionally, we present real experiments on 1B-parameter DeepSeekMoE models to complement our theoretical findings. Together, these results build a principled framework for analyzing the Auxiliary-Loss-Free Load Balancing of s-MoE in AI models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03915v2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03915v2">üìÑ Download PDF</a></p><hr><h3 id=lightweight-design-and-analysis-of-optical-cover-plate-for-exoplanet-imaging-coronagraphhttpsarxivorgabs251203700v1><a href=https://arxiv.org/abs/2512.03700v1>Lightweight design and analysis of optical cover plate for exoplanet imaging coronagraph</a><a hidden class=anchor aria-hidden=true href=#lightweight-design-and-analysis-of-optical-cover-plate-for-exoplanet-imaging-coronagraphhttpsarxivorgabs251203700v1>#</a></h3><p><strong>Authors:</strong> Lingyi Kong, Mingming Xu, Wei Guo, Jiangpei Dou, Bo Chen, Shu Jiang
<strong>Venue:</strong> arXiv (2025)</p><p>In order to reduce the load mass and solve the problem that the aluminum alloy optical cover plate of exoplanet imaging coronagraph was easy to deform, based on the equal generation design method, this paper designed and determined the configuration of the carbon fiber optical cover plate. Through the simulation of layup by finite element analysis, this paper researched the influence of different layering angles and sequences on the stiffness of optical cover plate. Finally, the carbon fiber layup method was determined as [15/-75/-15/75]s. The dynamic response analysis show that all the indexes satisfy the system requirements, and verify the feasibility of carbon fiber optical cover plate.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03700v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03700v1">üìÑ Download PDF</a></p><hr><h3 id=fftrainer-fast-failover-in-large-language-model-training-with-almost-free-state-managementhttpsarxivorgabs251203644v1><a href=https://arxiv.org/abs/2512.03644v1>FFTrainer: Fast Failover in Large-Language Model Training with Almost-Free State Management</a><a hidden class=anchor aria-hidden=true href=#fftrainer-fast-failover-in-large-language-model-training-with-almost-free-state-managementhttpsarxivorgabs251203644v1>#</a></h3><p><strong>Authors:</strong> Bohan Zhao, Yuanhong Wang, Chenglin Liu, Jiagi Pan, Guang Yang, Ruitao Liu, Tingrui Zhang, Kai Luo, Wei Xu
<strong>Venue:</strong> arXiv (2025)</p><p>Recent developments in large language models (LLMs) have introduced new requirements for efficient and robust training. As LLM clusters scale, node failures, lengthy recoveries, and bulky checkpoints erode efficiency. Infrequent asynchronous checkpoints trigger costly rollbacks, yet higher frequencies add prohibitive overhead. To address these challenges, we propose FFTrainer, a system designed for robust LLM training. FFTrainer leverages surplus network capacity to quickly save and load states, thereby preventing rollbacks and accelerating recovery. Compared with prior checkpointing approaches, FFTrainer reduces recovery time by up to 98% and mitigates GPU utilization loss by up to 68% without hindering normal training.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03644v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03644v1">üìÑ Download PDF</a></p><hr><h3 id=drag-reduction-via-separation-control-using-plasma-actuators-on-a-truck-cabin-sidehttpsarxivorgabs251203613v1><a href=https://arxiv.org/abs/2512.03613v1>Drag reduction via separation control using plasma actuators on a truck cabin side</a><a hidden class=anchor aria-hidden=true href=#drag-reduction-via-separation-control-using-plasma-actuators-on-a-truck-cabin-sidehttpsarxivorgabs251203613v1>#</a></h3><p><strong>Authors:</strong> Lucas Schneeberger, Stefano Discetti, Andrea Ianiro
<strong>Venue:</strong> arXiv (2025)</p><p>We investigated the drag reduction on a heavy-duty vehicle by means of dielectric-barrier discharge plasma actuators located on the A-pillars. An experimental campaign is carried out on a generalized truck model, the Ground Transportation System (GTS). Measurements were performed for several values of the side-wind angle, up to 7.5¬∞. Actuation was performed individually on the leeward and windward side as well as simultaneously. We measured both axial and side force components with a load cell. A laminar separation bubble on both sides of the truck&rsquo;s cabin is identified with particle image velocimetry. The plasma actuators effectively reduce the axial force on the GTS, and higher force reduction is achieved with symmetric actuation. The leeward actuation is found to have a greater control authority than the windward one; at large side-wind angle the latter has a negligible effect on the axial force. Concerning the side force, the leeward actuation produces a drop in its magnitude while windward actuation produces an increase. Interestingly, actuating symmetrically also augments the side force. The plasma actuator causes a reduction in the length and width of the separation bubble on the cabin side, reducing the apparent frontal area of the truck and thus its drag. Under side wind conditions, the leeward actuator has stronger authority since reduces the size of the larger separation bubble. The side force is also weakened via the diminution of the larger recirculation region, reducing its lateral suction force.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03613v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03613v1">üìÑ Download PDF</a></p><hr><h3 id=kvnand-efficient-on-device-large-language-model-inference-using-dram-free-in-flash-computinghttpsarxivorgabs251203608v1><a href=https://arxiv.org/abs/2512.03608v1>KVNAND: Efficient On-Device Large Language Model Inference Using DRAM-Free In-Flash Computing</a><a hidden class=anchor aria-hidden=true href=#kvnand-efficient-on-device-large-language-model-inference-using-dram-free-in-flash-computinghttpsarxivorgabs251203608v1>#</a></h3><p><strong>Authors:</strong> Lishuo Deng, Shaojie Xu, Jinwu Chen, Changwei Yan, Jiajie Wang, Zhe Jiang, Weiwei Shan
<strong>Venue:</strong> arXiv (2025)</p><p>Deploying large language models (LLMs) on edge devices enables personalized agents with strong privacy and low cost. However, with tens to hundreds of billions of parameters, single-batch autoregressive inference suffers from extremely low arithmetic intensity, creating severe weight-loading and bandwidth pressures on resource-constrained platforms. Recent in-flash computing (IFC) solutions alleviate this bottleneck by co-locating weight-related linear computations in the decode phase with flash, yet still rely on DRAM for the key-value (KV) cache. As context length grows, the KV cache can exceed model weights in size, imposing prohibitive DRAM cost and capacity requirements. Attempts to offload KV cache to flash suffer from severe performance penalties.
We propose KVNAND, the first DRAM-free, IFC-based architecture that stores both model weights and KV cache entirely in compute-enabled 3D NAND flash. KVNAND addresses the fundamental performance challenges of flash under intensive KV cache access by leveraging IFC for all memory-bound operations to reduce data transfer overhead, introducing head-group parallelism to boost throughput, and employing page-level KV cache mapping to align token access patterns with flash organization. In addition, we propose a design space exploration framework that evaluates discrete and compact KVNAND variants to balance weight and KV placement, automatically identifying the optimal design trade-off. These techniques mitigate latency, energy, and reliability concerns, turning flash into a practical medium for long-context KV storage. Evaluations on MHA 7B and GQA 70B LLMs show that KVNAND achieves 1.98(\times)/1.94(\times)/2.05(\times) geomean speedup at 128/1K/10K-token contexts compared to DRAM-equipped IFC designs and addresses out-of-memory failures at 100K context length.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03608v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03608v1">üìÑ Download PDF</a></p><hr><h3 id=tuning-of-vectorization-parameters-for-molecular-dynamics-simulations-in-autopashttpsarxivorgabs251203565v1><a href=https://arxiv.org/abs/2512.03565v1>Tuning of Vectorization Parameters for Molecular Dynamics Simulations in AutoPas</a><a hidden class=anchor aria-hidden=true href=#tuning-of-vectorization-parameters-for-molecular-dynamics-simulations-in-autopashttpsarxivorgabs251203565v1>#</a></h3><p><strong>Authors:</strong> Luis Gall, Samuel James Newcome, Fabio Alexander Gratl, Markus M√ºhlh√§u√üer, Manish Kumar Mishra, Hans-Joachim Bungartz
<strong>Venue:</strong> arXiv (2025)</p><p>Molecular Dynamics simulations can help scientists to gather valuable insights for physical processes on an atomic scale. This work explores various techniques for SIMD vectorization to improve the pairwise force calculation between molecules in the scope of the particle simulation library AutoPas. The focus lies on the order in which particle values are loaded into vector registers to achieve the most optimal performance regarding execution time or energy consumption.
As previous work indicates that the optimal MD algorithm can change during runtime, this paper investigates simulation-specific parameters like particle density and the impact of the neighbor identification algorithms, which distinguishes this work from related projects. Furthermore, AutoPas&rsquo; dynamic tuning mechanism is extended to choose the optimal vectorization order during runtime.
The benchmarks show that considering different particle interaction orders during runtime can lead to a considerable performance improvement for the force calculation compared to AutoPas&rsquo; previous approach.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03565v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03565v1">üìÑ Download PDF</a></p><hr><h3 id=tokenscale-timely-and-accurate-autoscaling-for-disaggregated-llm-serving-with-token-velocityhttpsarxivorgabs251203416v1><a href=https://arxiv.org/abs/2512.03416v1>TokenScale: Timely and Accurate Autoscaling for Disaggregated LLM Serving with Token Velocity</a><a hidden class=anchor aria-hidden=true href=#tokenscale-timely-and-accurate-autoscaling-for-disaggregated-llm-serving-with-token-velocityhttpsarxivorgabs251203416v1>#</a></h3><p><strong>Authors:</strong> Ruiqi Lai, Hongrui Liu, Chengzhi Lu, Zonghao Liu, Siyu Cao, Siyang Shao, Yixin Zhang, Luo Mai, Dmitrii Ustiugov
<strong>Venue:</strong> arXiv (2025)</p><p>The architectural shift to prefill/decode (PD) disaggregation in LLM serving improves resource utilization but struggles with the bursty nature of modern workloads. Existing autoscaling policies, often retrofitted from monolithic systems like those in AIBrix and DistServe, rely on lagging indicators such as GPU utilization or coarse-grained request counts. This results in slow reactions to load spikes, leading to significant Time-to First-Token (TTFT) and Time-Per-Output-Token (TPOT) SLO violations and costly over-provisioning. We introduce TokenScale, an autoscaling framework that resolves this performance mismatch through two innovations. First, we propose Token Velocity, a novel metric that unifies the prefill, network, and decode stages by quantifying their rate of work. As a leading indicator of system backpressure, it enables proactive scaling. Second, Convertible Decoders allow decoder GPUs to dynamically execute prefill tasks during traffic spikes, creating a rapid-response buffer that absorbs bursts and eliminates the initialization latency of new prefillers. Our evaluation on a GPU cluster with production traces shows TokenScale improves SLO attainment from 50-88% to 80-96% and reduces costs by 4-14% over state-of-the-art systems, including DistServe, BlitzScale, and AIBrix. By uniting a predictive metric with a flexible system design, TokenScale significantly boosts the performance and efficiency of disaggregated LLM serving infrastructure.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03416v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03416v1">üìÑ Download PDF</a></p><hr><h3 id=getting-the-most-out-of-your-storage-hierarchy-with-mirror-optimized-storage-tieringhttpsarxivorgabs251203279v1><a href=https://arxiv.org/abs/2512.03279v1>Getting the MOST out of your Storage Hierarchy with Mirror-Optimized Storage Tiering</a><a hidden class=anchor aria-hidden=true href=#getting-the-most-out-of-your-storage-hierarchy-with-mirror-optimized-storage-tieringhttpsarxivorgabs251203279v1>#</a></h3><p><strong>Authors:</strong> Kaiwei Tu, Kan Wu, Andrea C. Arpaci-Dusseau, Remzi H. Arpaci-Dusseau
<strong>Venue:</strong> arXiv (2025)</p><p>We present Mirror-Optimized Storage Tiering (MOST), a novel tiering-based approach optimized for modern storage hierarchies. The key idea of MOST is to combine the load balancing advantages of mirroring with the space-efficiency advantages of tiering. Specifically, MOST dynamically mirrors a small amount of hot data across storage tiers to efficiently balance load, avoiding costly migrations. As a result, MOST is as space-efficient as classic tiering while achieving better bandwidth utilization under I/O-intensive workloads. We implement MOST in Cerberus, a user-level storage management layer based on CacheLib. We show the efficacy of Cerberus through a comprehensive empirical study: across a range of static and dynamic workloads, Cerberus achieves better throughput than competing approaches on modern storage hierarchies especially under I/O-intensive and dynamic workloads.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03279v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03279v1">üìÑ Download PDF</a></p><hr><h3 id=estimation-of-semiparametric-factor-models-with-missing-datahttpsarxivorgabs251203235v1><a href=https://arxiv.org/abs/2512.03235v1>Estimation of Semiparametric Factor Models with Missing Data</a><a hidden class=anchor aria-hidden=true href=#estimation-of-semiparametric-factor-models-with-missing-datahttpsarxivorgabs251203235v1>#</a></h3><p><strong>Authors:</strong> Sijie Zheng
<strong>Venue:</strong> arXiv (2025)</p><p>We study semiparametric factor models in high-dimensional panels where the factor loadings consist of a nonparametric component explained by observed covariates and an idiosyncratic component capturing unobserved heterogeneity. A key challenge in empirical applications is the presence of missing observations, which can distort both factor recovery and loading estimation. To address this issue, we develop a projected principal component analysis (PPCA) procedure that accommodates general missing-at-random mechanisms through inverse-probability weighting. We establish consistency and derive the asymptotic distributions of the estimated factors and loading functions, allowing the sieve dimension to diverge and permitting the time dimension to be either fixed or growing. Unlike classical PCA, PPCA achieves consistent factor estimation even when T is fixed, and the limiting distributions under missing data exhibit mixture normality with enlarged asymptotic variances. Theoretical results are supported by simulations and an empirical application. Our findings demonstrate that PPCA provides an effective and robust framework for estimating semiparametric factor models in the presence of missing data.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03235v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03235v1">üìÑ Download PDF</a></p><hr><h3 id=three-dimensional-third-medium-contact-model-for-hyperelastic-contact-and-pneumatically-actuated-systemshttpsarxivorgabs251203181v1><a href=https://arxiv.org/abs/2512.03181v1>Three-dimensional third medium contact model for hyperelastic contact and pneumatically actuated systems</a><a hidden class=anchor aria-hidden=true href=#three-dimensional-third-medium-contact-model-for-hyperelastic-contact-and-pneumatically-actuated-systemshttpsarxivorgabs251203181v1>#</a></h3><p><strong>Authors:</strong> Bing-Bing Xu, Tianju Xue, Peter Wriggers
<strong>Venue:</strong> arXiv (2025)</p><p>This work presents a comprehensive three-dimensional third-medium contact framework for modeling complex contact interactions in hyperelastic solids and pneumatically actuated systems. The proposed third-medium formulation embeds a fictitious medium (or third medium) between potentially interacting bodies, enabling a unified and robust treatment of hyperelastic contact and self-contact without the need for discretization of the contact interface. Unlike the widely studied two-dimensional problem, this paper extends the new regularization term given in Reference \cite{TMCWriggers2} to three-dimensional problems and ensures element quality in a third medium. Due to the need for higher-order elements for the regularization term, this paper details the linearization process of this problem within the finite element framework. In addition, pneumatically actuated systems are considered by introducing a pneumatic term to represent pneumatic loading (pressure or suction) and inducing contact caused by internal inflation. This approach is suitable for complex hyperelastic contact and self-contact, and has potential applications in the fields of soft robotics and flexible mechanisms. The framework is developed in a fully three-dimensional setting, making it also suitable for isogeometric methods and meshless methods. Several benchmark and application-level simulations demonstrate the accuracy, robustness, and versatility of the proposed approach. The results highlight the capability of the three-dimensional third-medium model to handle challenging nonlinear contact scenarios relevant to soft materials, soft actuators, and emerging multifunctional structures.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03181v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03181v1">üìÑ Download PDF</a></p><hr><h2 id=-llm>üîç llm<a hidden class=anchor aria-hidden=true href=#-llm>#</a></h2><h3 id=reflection-removal-through-efficient-adaptation-of-diffusion-transformershttpsarxivorgabs251205000v1><a href=https://arxiv.org/abs/2512.05000v1>Reflection Removal through Efficient Adaptation of Diffusion Transformers</a><a hidden class=anchor aria-hidden=true href=#reflection-removal-through-efficient-adaptation-of-diffusion-transformershttpsarxivorgabs251205000v1>#</a></h3><p><strong>Authors:</strong> Daniyar Zakarin, Thiemo Wandel, Anton Obukhov, Dengxin Dai
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce a diffusion-transformer (DiT) framework for single-image reflection removal that leverages the generalization strengths of foundation diffusion models in the restoration setting. Rather than relying on task-specific architectures, we repurpose a pre-trained DiT-based foundation model by conditioning it on reflection-contaminated inputs and guiding it toward clean transmission layers. We systematically analyze existing reflection removal data sources for diversity, scalability, and photorealism. To address the shortage of suitable data, we construct a physically based rendering (PBR) pipeline in Blender, built around the Principled BSDF, to synthesize realistic glass materials and reflection effects. Efficient LoRA-based adaptation of the foundation model, combined with the proposed synthetic data, achieves state-of-the-art performance on in-domain and zero-shot benchmarks. These results demonstrate that pretrained diffusion transformers, when paired with physically grounded data synthesis and efficient adaptation, offer a scalable and high-fidelity solution for reflection removal. Project page: <a href=https://hf.co/spaces/huawei-bayerlab/windowseat-reflection-removal-web>https://hf.co/spaces/huawei-bayerlab/windowseat-reflection-removal-web</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05000v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05000v1">üìÑ Download PDF</a></p><hr><h3 id=a-systemic-pathological-network-model-and-combinatorial-intervention-strategies-for-alzheimers-diseasehttpsarxivorgabs251204937v1><a href=https://arxiv.org/abs/2512.04937v1>A Systemic Pathological Network Model and Combinatorial Intervention Strategies for Alzheimer&rsquo;s Disease</a><a hidden class=anchor aria-hidden=true href=#a-systemic-pathological-network-model-and-combinatorial-intervention-strategies-for-alzheimers-diseasehttpsarxivorgabs251204937v1>#</a></h3><p><strong>Authors:</strong> She Xutong
<strong>Venue:</strong> arXiv (2025)</p><p>Alzheimer&rsquo;s disease (AD) persists as a paramount challenge in neurological research, characterized by the pathological hallmarks of amyloid-$Œ≤$ (A$Œ≤$) plaques and neurofibrillary tangles composed of hyperphosphorylated tau. This review synthesizes the evolving understanding of AD pathogenesis, moving beyond the linear amyloid cascade hypothesis to conceptualize the disease as a cross-talk of intricately interacting pathologies, encompassing A$Œ≤$, tau, and neuroinflammation as the foundation of phase-adapted pathological network model. This evolving pathophysiological understanding parallels a transformation in diagnostic paradigms, where biomarker-based strategies such as the AT(N) framework enable early disease detection during preclinical or prodromal stages. Within this new landscape, while anti-A$Œ≤$ monoclonal antibodies (e.g., lecanemab, donanemab), represent a breakthrough as the first disease-modifying therapies, their modest efficacy underscores the limitation of single-target approaches. Therefore, I explore the compelling rationale for combination therapies that simultaneously target A$Œ≤$ pathology, aberrant tau, and neuroinflammation. Looking forward, I emphasize emerging technological platforms such as gene editing and biophysical neuromodulation in advancing precision medicine. Ultimately, the integration of early biomarker detection, multi-target therapeutic strategies, and AI-driven patient stratification charts a promising roadmap toward fundamentally altering the trajectory of AD. The future of AD management will be defined by preemptive, biomarker-guided, and personalized combination interventions.
Keywords: Alzheimer&rsquo;s disease, amyloid-$Œ≤$, tau pathology, neuroinflammation, combination therapy, multi-target therapy, precision medicine, biomarkers</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04937v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04937v1">üìÑ Download PDF</a></p><hr><h3 id=exact-3-d-channel-impulse-response-for-spherical-receivers-with-arbitrary-drift-directionshttpsarxivorgabs251204858v1><a href=https://arxiv.org/abs/2512.04858v1>Exact 3-D Channel Impulse Response for Spherical Receivers with Arbitrary Drift Directions</a><a hidden class=anchor aria-hidden=true href=#exact-3-d-channel-impulse-response-for-spherical-receivers-with-arbitrary-drift-directionshttpsarxivorgabs251204858v1>#</a></h3><p><strong>Authors:</strong> Yen-Chi Lee, Ping-Cheng Yeh, Chia-Han Lee
<strong>Venue:</strong> arXiv (2025)</p><p>Accurate channel modeling for spherical absorbing receivers is fundamental to the design of realistic molecular multiple-input multiple-output (MIMO) systems. While advanced modulation schemes have been proposed to mitigate interference, determining the channel impulse response (CIR) under arbitrary flow directions remains a challenge; existing exact solutions are restricted to either 1-D/no-drift scenarios or planar receiver geometries. Addressing this gap, we derive the first exact analytical CIR for a spherical receiver in a 3-D molecular communication system with uniform drift in an arbitrary direction. Unlike prior approximations that ignore the angle between the drift and the transmission axis, our approach utilizes the Girsanov theorem to analytically transform the hitting-time distribution from a stationary medium to a drifted one. The proposed closed-form expression not only eliminates modeling errors inherent in previous approximations for off-axis receivers but also enables efficient parameter-space exploration of critical system metrics (e.g., peak time and amplitude), a task that would be computationally costly with pure simulation-based approaches.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04858v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04858v1">üìÑ Download PDF</a></p><hr><h3 id=long-term-x-ray-variability-of-the-multiple-planet-host-l-98-59-hints-of-an-activity-cyclehttpsarxivorgabs251204817v1><a href=https://arxiv.org/abs/2512.04817v1>Long-term X-ray variability of the multiple-planet host L 98-59: Hints of an activity cycle</a><a hidden class=anchor aria-hidden=true href=#long-term-x-ray-variability-of-the-multiple-planet-host-l-98-59-hints-of-an-activity-cyclehttpsarxivorgabs251204817v1>#</a></h3><p><strong>Authors:</strong> I. Pillitteri, S. Bellotti, S. Benatti, S. Boro Saikia, A. Garc√≠a Mu√±oz, K. G. Kislyakova, A. Maggio, G. Micela, K. Vida, A. A. Vidotto
<strong>Venue:</strong> arXiv (2025)</p><p>High-energy irradiation in X-rays and UV (XUV) can transform the planetary atmospheres through photoevaporation and photochemistry. This is more crucial for M stars, whose habitable zones for Earth-like planets are located within a few percent of an AU. Transiting exoplanets around M dwarfs offer the opportunity to study their characteristics and habitability conditions. L 98-59 is an M3 dwarf hosting six Earth-like planets, with two of them in the habitable zone of the star. X-ray observations made in 2020 and 2021 detected significant flares above a quiescent luminosity of 4-10 x 10^26 erg/s. We present the results from two short XMM-Newton observations of L 98-59, which are part of a monitoring survey to detect long-term X-ray variability and activity cycles. In October 2024 the X-ray quiescent luminosity of the star was about 5.9 x 10^25 erg/s, and it was about 6.3 x 10^26 erg/s in February 2025. We speculate that in late 2024 the star had a minimum of activity; in 2021 the star was near a maximum of an activity cycle, and in 2025 it was at the middle of the cycle. We suggest a coarse estimate of the period of about 2 years and a peak-to-peak amplitude of about 10, which is the highest among the stars with a known X-ray cycle other than the Sun. We also infer that even the outer planet in the habitable zone, L 98-59f, is exposed to an X-ray dose between 100 and 1600 times the X-ray irradiation of the Earth in the XMM band.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04817v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04817v1">üìÑ Download PDF</a></p><hr><h3 id=crystal-formation-in-systems-of-pseudo-forced-swarmalatorshttpsarxivorgabs251204724v1><a href=https://arxiv.org/abs/2512.04724v1>Crystal formation in systems of pseudo-forced swarmalators</a><a hidden class=anchor aria-hidden=true href=#crystal-formation-in-systems-of-pseudo-forced-swarmalatorshttpsarxivorgabs251204724v1>#</a></h3><p><strong>Authors:</strong> Brennan J. H. Hughes, Christoph Bruder, Tobias Kehrer
<strong>Venue:</strong> arXiv (2025)</p><p>Swarmalators are active agents that move in position space and exhibit internal degrees of freedom. Due to interactions of their positions and phases of oscillation, they show on the one hand swarming, similar to the effect of flocking of birds. In addition, they exhibit synchronization behavior, analogous to what has been observed in fireflies. Previous works studied scenarios in which the phases are forced externally. Here, we consider a pseudo-force that acts on the positions of the swarmalators. Due to the resulting attraction towards the center of position space, transitions from the splintered and active phase-wave state to the static antisynchronized state are found. To quantify the crystal order of swarmalators, we introduce an order parameter that is based on the Fourier transform of their positions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04724v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04724v1">üìÑ Download PDF</a></p><hr><h3 id=infinity-of-solutions-to-initial-boundary-value-problems-for-linear-constant-coefficient-evolution-pdes-on-semi-infinite-intervalshttpsarxivorgabs251204670v1><a href=https://arxiv.org/abs/2512.04670v1>Infinity of solutions to initial-boundary value problems for linear constant-coefficient evolution PDEs on semi-infinite intervals</a><a hidden class=anchor aria-hidden=true href=#infinity-of-solutions-to-initial-boundary-value-problems-for-linear-constant-coefficient-evolution-pdes-on-semi-infinite-intervalshttpsarxivorgabs251204670v1>#</a></h3><p><strong>Authors:</strong> Andreas Chatziafratis, Spyridon Kamvissis
<strong>Venue:</strong> arXiv (2025)</p><p>In this short communication, we announce an algorithmic procedure for constructing non-uniqueness counter-examples of classical solutions to initial-boundary-value problems for a wide class of linear evolution partial differential equations, of any order and with constant coefficients, formulated in a quarter-plane. Our approach relies on analysis of regularity and asymptotic properties, near the boundary of the spatio-temporal domain, of closed-form integral-representation formulae derived via complex-analytic techniques and rigorous implementation of the modern PDE technique known as Fokas unified transform method. In order to elucidate the novel idea and demonstrate the proposed technique in a self-contained fashion, we explicitly present its application to two concrete examples, namely the heat equation and the linear KdV equation with Dirichlet data. New uniqueness theorems for these two models are also presented herein.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04670v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04670v1">üìÑ Download PDF</a></p><hr><h3 id=fermionic-neural-gibbs-stateshttpsarxivorgabs251204663v1><a href=https://arxiv.org/abs/2512.04663v1>Fermionic neural Gibbs states</a><a hidden class=anchor aria-hidden=true href=#fermionic-neural-gibbs-stateshttpsarxivorgabs251204663v1>#</a></h3><p><strong>Authors:</strong> Jannes Nys, Juan Carrasquilla
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce fermionic neural Gibbs states (fNGS), a variational framework for modeling finite-temperature properties of strongly interacting fermions. fNGS starts from a reference mean-field thermofield-double state and uses neural-network transformations together with imaginary-time evolution to systematically build strong correlations. Applied to the doped Fermi-Hubbard model, a minimal lattice model capturing essential features of strong electronic correlations, fNGS accurately reproduces thermal energies over a broad range of temperatures, interaction strengths, even at large dopings, for system sizes beyond the reach of exact methods. These results demonstrate a scalable route to studying finite-temperature properties of strongly correlated fermionic systems beyond one dimension with neural-network representations of quantum states.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04663v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04663v1">üìÑ Download PDF</a></p><hr><h3 id=denoise-to-track-harnessing-video-diffusion-priors-for-robust-correspondencehttpsarxivorgabs251204619v1><a href=https://arxiv.org/abs/2512.04619v1>Denoise to Track: Harnessing Video Diffusion Priors for Robust Correspondence</a><a hidden class=anchor aria-hidden=true href=#denoise-to-track-harnessing-video-diffusion-priors-for-robust-correspondencehttpsarxivorgabs251204619v1>#</a></h3><p><strong>Authors:</strong> Tianyu Yuan, Yuanbo Yang, Lin-Zhuo Chen, Yao Yao, Zhuzhong Qian
<strong>Venue:</strong> arXiv (2025)</p><p>In this work, we introduce HeFT (Head-Frequency Tracker), a zero-shot point tracking framework that leverages the visual priors of pretrained video diffusion models. To better understand how they encode spatiotemporal information, we analyze the internal representations of Video Diffusion Transformer (VDiT). Our analysis reveals that attention heads act as minimal functional units with distinct specializations for matching, semantic understanding, and positional encoding. Additionally, we find that the low-frequency components in VDiT features are crucial for establishing correspondences, whereas the high-frequency components tend to introduce noise. Building on these insights, we propose a head- and frequency-aware feature selection strategy that jointly selects the most informative attention head and low-frequency components to enhance tracking performance. Specifically, our method extracts discriminative features through single-step denoising, applies feature selection, and employs soft-argmax localization with forward-backward consistency checks for correspondence estimation. Extensive experiments on TAP-Vid benchmarks demonstrate that HeFT achieves state-of-the-art zero-shot tracking performance, approaching the accuracy of supervised methods while eliminating the need for annotated training data. Our work further underscores the promise of video diffusion models as powerful foundation models for a wide range of downstream tasks, paving the way toward unified visual foundation models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04619v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04619v1">üìÑ Download PDF</a></p><hr><h3 id=neural-decoding-of-overt-speech-from-ecog-using-vision-transformers-and-contrastive-representation-learninghttpsarxivorgabs251204618v1><a href=https://arxiv.org/abs/2512.04618v1>Neural Decoding of Overt Speech from ECoG Using Vision Transformers and Contrastive Representation Learning</a><a hidden class=anchor aria-hidden=true href=#neural-decoding-of-overt-speech-from-ecog-using-vision-transformers-and-contrastive-representation-learninghttpsarxivorgabs251204618v1>#</a></h3><p><strong>Authors:</strong> Mohamed Baha Ben Ticha, Xingchen Ran, Guillaume Saldanha, Ga√´l Le Godais, Phil√©mon Roussel, Marc Aubert, Amina Fontanell, Thomas Costecalde, Lucas Struber, Serpil Karakas, Shaomin Zhang, Philippe Kahane, Guillaume Charvet, St√©phan Chabard√®s, Blaise Yvert
<strong>Venue:</strong> arXiv (2025)</p><p>Speech Brain Computer Interfaces (BCIs) offer promising solutions to people with severe paralysis unable to communicate. A number of recent studies have demonstrated convincing reconstruction of intelligible speech from surface electrocorticographic (ECoG) or intracortical recordings by predicting a series of phonemes or words and using downstream language models to obtain meaningful sentences. A current challenge is to reconstruct speech in a streaming mode by directly regressing cortical signals into acoustic speech. While this has been achieved recently using intracortical data, further work is needed to obtain comparable results with surface ECoG recordings. In particular, optimizing neural decoders becomes critical in this case. Here we present an offline speech decoding pipeline based on an encoder-decoder deep neural architecture, integrating Vision Transformers and contrastive learning to enhance the direct regression of speech from ECoG signals. The approach is evaluated on two datasets, one obtained with clinical subdural electrodes in an epileptic patient, and another obtained with the fully implantable WIMAGINE epidural system in a participant of a motor BCI trial. To our knowledge this presents a first attempt to decode speech from a fully implantable and wireless epidural recording system offering perspectives for long-term use.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04618v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04618v1">üìÑ Download PDF</a></p><hr><h3 id=tensor-neyman-pearson-classification-theory-algorithms-and-error-controlhttpsarxivorgabs251204583v1><a href=https://arxiv.org/abs/2512.04583v1>Tensor Neyman-Pearson Classification: Theory, Algorithms, and Error Control</a><a hidden class=anchor aria-hidden=true href=#tensor-neyman-pearson-classification-theory-algorithms-and-error-controlhttpsarxivorgabs251204583v1>#</a></h3><p><strong>Authors:</strong> Lingchong Liu, Elynn Chen, Yuefeng Han, Lucy Xia
<strong>Venue:</strong> arXiv (2025)</p><p>Biochemical discovery increasingly relies on classifying molecular structures when the consequences of different errors are highly asymmetric. In mutagenicity and carcinogenicity, misclassifying a harmful compound as benign can trigger substantial scientific, regulatory, and health risks, whereas false alarms primarily increase laboratory workload. Modern representations transform molecular graphs into persistence image tensors that preserve multiscale geometric and topological structure, yet existing tensor classifiers and deep tensor neural networks provide no finite-sample guarantees on type I error and often exhibit severe error inflation in practice.
We develop the first Tensor Neyman-Pearson (Tensor-NP) classification framework that achieves finite-sample control of type I error while exploiting the multi-mode structure of tensor data. Under a tensor-normal mixture model, we derive the oracle NP discriminant, characterize its Tucker low-rank manifold geometry, and establish tensor-specific margin and conditional detection conditions enabling high-probability bounds on excess type II error. We further propose a Discriminant Tensor Iterative Projection estimator and a Tensor-NP Neural Classifier combining deep learning with Tensor-NP umbrella calibration, yielding the first distribution-free NP-valid methods for multiway data. Across four biochemical datasets, Tensor-NP classifiers maintain type I errors at prespecified levels while delivering competitive type II error performance, providing reliable tools for asymmetric-risk decisions with complex molecular tensors.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04583v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04583v1">üìÑ Download PDF</a></p><hr><h3 id=a-rocq-formalization-of-monomial-and-graded-ordershttpsarxivorgabs251204573v1><a href=https://arxiv.org/abs/2512.04573v1>A Rocq Formalization of Monomial and Graded Orders</a><a hidden class=anchor aria-hidden=true href=#a-rocq-formalization-of-monomial-and-graded-ordershttpsarxivorgabs251204573v1>#</a></h3><p><strong>Authors:</strong> Sylvie Boldo, Fran√ßois Cl√©ment, Vincent Martin, Micaela Mayero
<strong>Venue:</strong> arXiv (2025)</p><p>Even if binary relations and orders are a common formalization topic, we need to formalize specific orders (namely monomial and graded) in the process of formalizing in Rocq the finite element method. This article is therefore definitions, operators, and proofs of properties about relations and orders, thus providing a comprehensive Rocq library. We especially focus on monomial orders, that are total orders compatible with the monoid operation. More than its definition and proved properties, we define several of them, among them the lexicographic and grevlex orders. For the sake of genericity, we formalize the grading of an order, a high-level operator that transforms a binary relation into another one, and we prove that grading an order preserves many of its properties, such as the monomial order property. This leads us to the definition and properties of four different graded orders, with very factorized proofs. We therefore provide a comprehensive and user-friendly library in Rocq about orders, including monomial and graded orders, that contains more than 700 lemmas.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04573v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04573v1">üìÑ Download PDF</a></p><hr><h3 id=counterfeit-answers-adversarial-forgery-against-ocr-free-document-visual-question-answeringhttpsarxivorgabs251204554v1><a href=https://arxiv.org/abs/2512.04554v1>Counterfeit Answers: Adversarial Forgery against OCR-Free Document Visual Question Answering</a><a hidden class=anchor aria-hidden=true href=#counterfeit-answers-adversarial-forgery-against-ocr-free-document-visual-question-answeringhttpsarxivorgabs251204554v1>#</a></h3><p><strong>Authors:</strong> Marco Pintore, Maura Pintor, Dimosthenis Karatzas, Battista Biggio
<strong>Venue:</strong> arXiv (2025)</p><p>Document Visual Question Answering (DocVQA) enables end-to-end reasoning grounded on information present in a document input. While recent models have shown impressive capabilities, they remain vulnerable to adversarial attacks. In this work, we introduce a novel attack scenario that aims to forge document content in a visually imperceptible yet semantically targeted manner, allowing an adversary to induce specific or generally incorrect answers from a DocVQA model. We develop specialized attack algorithms that can produce adversarially forged documents tailored to different attackers&rsquo; goals, ranging from targeted misinformation to systematic model failure scenarios. We demonstrate the effectiveness of our approach against two end-to-end state-of-the-art models: Pix2Struct, a vision-language transformer that jointly processes image and text through sequence-to-sequence modeling, and Donut, a transformer-based model that directly extracts text and answers questions from document images. Our findings highlight critical vulnerabilities in current DocVQA systems and call for the development of more robust defenses.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04554v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04554v1">üìÑ Download PDF</a></p><hr><h3 id=intertwined-birth-and-death-a-herbig-haro-outflow-resolves-the-distance-to-vela-juniorhttpsarxivorgabs251204956v1><a href=https://arxiv.org/abs/2512.04956v1>Intertwined birth and death: a Herbig-Haro outflow resolves the distance to Vela Junior</a><a hidden class=anchor aria-hidden=true href=#intertwined-birth-and-death-a-herbig-haro-outflow-resolves-the-distance-to-vela-juniorhttpsarxivorgabs251204956v1>#</a></h3><p><strong>Authors:</strong> Janette Suherli, Ivo R. Seitenzahl, Samar Safi-Harb, Fr√©d√©ric P. A. Vogt, Wynn C. G. Ho, Parviz Ghavamian, Chuan-Jui Li, Ashley J. Ruiter, Roland M. Crocker, Arpita Roy, Ralph Sutherland
<strong>Venue:</strong> arXiv (2025)</p><p>The distance to the Vela Junior supernova remnant (RX J0852.0-4622 or G266.2-1.2) has long remained uncertain, limiting our understanding of its physical properties. Using VLT/MUSE integral field spectroscopy, we uncover chemical and kinematic connections between the nebula surrounding its Central Compact Object (CXOU J085201.4-461753) and the nearby Herbig-Haro outflow of Ve 7-27 (Wray 16-30), indicating a shared nitrogen-rich, Fe-peak-enhanced environment. This link ties stellar birth and death, with the young star Ve 7-27 embedded in material expelled by Vela Junior&rsquo;s massive progenitor, and the remnant&rsquo;s blast wave is expanding through the same medium. Adopting the Gaia-based distance to Ve 7-27, we revise Vela Junior&rsquo;s distance to $1.41\pm0.14$ kpc. At this distance, the remnant&rsquo;s physical radius is $23.3\pm2.3$ pc, and X-ray proper motions of the northwestern rim correspond to shock speeds of $(2.8\pm0.7)\times10^3$ to $(5.6\pm1.5)\times10^3$ km s$^{-1}$. These imply an age of $\sim$1.6-3.3 kyr and a very low ambient density, indicating that Vela Junior is expanding within a highly rarefied wind-blown cavity carved by a massive progenitor &ndash; consistent with the non-detection of strong thermal X-ray emission. This distance update also resolves long-standing inconsistencies, with major implications for its energy budget, particle acceleration efficiency, and compact object evolution.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04956v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04956v1">üìÑ Download PDF</a></p><hr><h3 id=on-disturbance-aware-minimum-time-trajectory-planning-evidence-from-tests-on-a-dynamic-driving-simulatorhttpsarxivorgabs251204917v1><a href=https://arxiv.org/abs/2512.04917v1>On Disturbance-Aware Minimum-Time Trajectory Planning: Evidence from Tests on a Dynamic Driving Simulator</a><a hidden class=anchor aria-hidden=true href=#on-disturbance-aware-minimum-time-trajectory-planning-evidence-from-tests-on-a-dynamic-driving-simulatorhttpsarxivorgabs251204917v1>#</a></h3><p><strong>Authors:</strong> Matteo Masoni, Vincenzo Palermo, Marco Gabiccini, Martino Gulisano, Giorgio Previati, Massimiliano Gobbi, Francesco Comolli, Gianpiero Mastinu, Massimo Guiggiani
<strong>Venue:</strong> arXiv (2025)</p><p>This work investigates how disturbance-aware, robustness-embedded reference trajectories translate into driving performance when executed by professional drivers in a dynamic simulator. Three planned reference trajectories are compared against a free-driving baseline (NOREF) to assess trade-offs between lap time (LT) and steering effort (SE): NOM, the nominal time-optimal trajectory; TLC, a track-limit-robust trajectory obtained by tightening margins to the track edges; and FLC, a friction-limit-robust trajectory obtained by tightening against axle and tire saturation. All trajectories share the same minimum lap-time objective with a small steering-smoothness regularizer and are evaluated by two professional drivers using a high-performance car on a virtual track. The trajectories derive from a disturbance-aware minimum-lap-time framework recently proposed by the authors, where worst-case disturbance growth is propagated over a finite horizon and used to tighten tire-friction and track-limit constraints, preserving performance while providing probabilistic safety margins. LT and SE are used as performance indicators, while RMS lateral deviation, speed error, and drift angle characterize driving style. Results show a Pareto-like LT-SE trade-off: NOM yields the shortest LT but highest SE; TLC minimizes SE at the cost of longer LT; FLC lies near the efficient frontier, substantially reducing SE relative to NOM with only a small LT increase. Removing trajectory guidance (NOREF) increases both LT and SE, confirming that reference trajectories improve pace and control efficiency. Overall, the findings highlight reference-based and disturbance-aware planning, especially FLC, as effective tools for training and for achieving fast yet stable trajectories.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04917v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04917v1">üìÑ Download PDF</a></p><hr><h3 id=from-task-executors-to-research-partners-evaluating-ai-co-pilots-through-workflow-integration-in-biomedical-researchhttpsarxivorgabs251204854v1><a href=https://arxiv.org/abs/2512.04854v1>From Task Executors to Research Partners: Evaluating AI Co-Pilots Through Workflow Integration in Biomedical Research</a><a hidden class=anchor aria-hidden=true href=#from-task-executors-to-research-partners-evaluating-ai-co-pilots-through-workflow-integration-in-biomedical-researchhttpsarxivorgabs251204854v1>#</a></h3><p><strong>Authors:</strong> Lukas Weidener, Marko Brkiƒá, Chiara Bacci, Mihailo Jovanoviƒá, Emre Ulgac, Alex Dobrin, Johannes Weniger, Martin Vlas, Ritvik Singh, Aakaash Meduri
<strong>Venue:</strong> arXiv (2025)</p><p>Artificial intelligence systems are increasingly deployed in biomedical research. However, current evaluation frameworks may inadequately assess their effectiveness as research collaborators. This rapid review examines benchmarking practices for AI systems in preclinical biomedical research. Three major databases and two preprint servers were searched from January 1, 2018 to October 31, 2025, identifying 14 benchmarks that assess AI capabilities in literature understanding, experimental design, and hypothesis generation. The results revealed that all current benchmarks assess isolated component capabilities, including data analysis quality, hypothesis validity, and experimental protocol design. However, authentic research collaboration requires integrated workflows spanning multiple sessions, with contextual memory, adaptive dialogue, and constraint propagation. This gap implies that systems excelling on component benchmarks may fail as practical research co-pilots. A process-oriented evaluation framework is proposed that addresses four critical dimensions absent from current benchmarks: dialogue quality, workflow orchestration, session continuity, and researcher experience. These dimensions are essential for evaluating AI systems as research co-pilots rather than as isolated task executors.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04854v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04854v1">üìÑ Download PDF</a></p><hr><h3 id=extreme-mass-ratio-inspirals-embedded-in-dark-matter-halo-ii-chaotic-imprints-in-gravitational-waveshttpsarxivorgabs251204848v1><a href=https://arxiv.org/abs/2512.04848v1>Extreme-Mass-Ratio Inspirals Embedded in Dark Matter Halo II: Chaotic Imprints in Gravitational Waves</a><a hidden class=anchor aria-hidden=true href=#extreme-mass-ratio-inspirals-embedded-in-dark-matter-halo-ii-chaotic-imprints-in-gravitational-waveshttpsarxivorgabs251204848v1>#</a></h3><p><strong>Authors:</strong> Surajit Das, Surojit Dalui, Bum-Hoon Lee, Yi-Fu Cai
<strong>Venue:</strong> arXiv (2025)</p><p>We investigate the imprints of chaos in gravitational waves from extreme-mass-ratio inspirals configuration, where a stellar massive object, confined in a harmonic potential, orbits a supermassive Schwarzschild-like black hole embedded in a Dehnen-type dark matter halo. In our first paper [1], we demonstrated the system&rsquo;s transition from non-chaotic to chaotic dynamics by analyzing Poincar√© sections, orbital evolution, and Lyapunov exponents across different energies and dark matter halo parameters. In this work, we compute the gravitational waveforms of the small celestial object along different chaotic and non-chaotic orbits by implementing the numerical kludge scheme. We further perform a spectral analysis of the gravitational waveforms from such orbits. In particular, we show that when the system is in a chaotic state, the gravitational wave signals are characterized by broader frequency spectra with finite widths, enhanced amplitude and energy emission rate, distinctly differentiating them from the signals generated during the system&rsquo;s non-chaotic state. Through recurrence analysis we also show that the time series of gravitational waveforms strain carry unique information on the motion of chaotic dynamics, which can be used to distinctly differentiate from non-chaotic to chaotic motion of the source. Furthermore, we discuss the potential detectability of these orbits for upcoming observatories like LISA, TianQin, and Taiji, emphasizing the significant potential for detecting chaotic imprints in gravitational waves to substantially enhance our understanding of chaotic dynamics in black hole physics and the dark matter environments of galactic nuclei.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04848v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04848v1">üìÑ Download PDF</a></p><hr><h3 id=large-speech-model-enabled-semantic-communicationhttpsarxivorgabs251204711v1><a href=https://arxiv.org/abs/2512.04711v1>Large Speech Model Enabled Semantic Communication</a><a hidden class=anchor aria-hidden=true href=#large-speech-model-enabled-semantic-communicationhttpsarxivorgabs251204711v1>#</a></h3><p><strong>Authors:</strong> Yun Tian, Zhijin Qin, Guocheng Lv, Ye Jin, Kaibin Huang, Zhu Han
<strong>Venue:</strong> arXiv (2025)</p><p>Existing speech semantic communication systems mainly based on Joint Source-Channel Coding (JSCC) architectures have demonstrated impressive performance, but their effectiveness remains limited by model structures specifically designed for particular tasks and datasets. Recent advances indicate that generative large models pre-trained on massive datasets, can achieve outstanding performance arexhibit exceptional performance across diverse downstream tasks with minimal fine-tuning. To exploit the rich semantic knowledge embedded in large models and enable adaptive transmission over lossy channels, we propose a Large Speech Model enabled Semantic Communication (LargeSC) system. Simultaneously achieving adaptive compression and robust transmission over lossy channels remains challenging, requiring trade-offs among compression efficiency, speech quality, and latency. In this work, we employ the Mimi as a speech codec, converting speech into discrete tokens compatible with existing network architectures. We propose an adaptive controller module that enables adaptive transmission and in-band Unequal Error Protection (UEP), dynamically adjusting to both speech content and packet loss probability under bandwidth constraints. Additionally, we employ Low-Rank Adaptation (LoRA) to finetune the Moshi foundation model for generative recovery of lost speech tokens. Simulation results show that the proposed system supports bandwidths ranging from 550 bps to 2.06 kbps, outperforms conventional baselines in speech quality under high packet loss rates and achieves an end-to-end latency of approximately 460 ms, thereby demonstrating its potential for real-time deployment.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04711v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04711v1">üìÑ Download PDF</a></p><hr><h3 id=hardware-aware-neural-architecture-search-of-early-exiting-networks-on-edge-acceleratorshttpsarxivorgabs251204705v1><a href=https://arxiv.org/abs/2512.04705v1>Hardware-aware Neural Architecture Search of Early Exiting Networks on Edge Accelerators</a><a hidden class=anchor aria-hidden=true href=#hardware-aware-neural-architecture-search-of-early-exiting-networks-on-edge-acceleratorshttpsarxivorgabs251204705v1>#</a></h3><p><strong>Authors:</strong> Alaa Zniber, Arne Symons, Ouassim Karrakchou, Marian Verhelst, Mounir Ghogho
<strong>Venue:</strong> arXiv (2025)</p><p>Advancements in high-performance computing and cloud technologies have enabled the development of increasingly sophisticated Deep Learning (DL) models. However, the growing demand for embedded intelligence at the edge imposes stringent computational and energy constraints, challenging the deployment of these large-scale models. Early Exiting Neural Networks (EENN) have emerged as a promising solution, allowing dynamic termination of inference based on input complexity to enhance efficiency. Despite their potential, EENN performance is highly influenced by the heterogeneity of edge accelerators and the constraints imposed by quantization, affecting accuracy, energy efficiency, and latency. Yet, research on the automatic optimization of EENN design for edge hardware remains limited. To bridge this gap, we propose a hardware-aware Neural Architecture Search (NAS) framework that systematically integrates the effects of quantization and hardware resource allocation to optimize the placement of early exit points within a network backbone. Experimental results on the CIFAR-10 dataset demonstrate that our NAS framework can discover architectures that achieve over a 50% reduction in computational costs compared to conventional static networks, making them more suitable for deployment in resource-constrained edge environments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04705v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04705v1">üìÑ Download PDF</a></p><hr><h3 id=the-ejection-velocities-of-interstellar-objects-signpost-their-progenitor-system-architectureshttpsarxivorgabs251204700v1><a href=https://arxiv.org/abs/2512.04700v1>The ejection velocities of interstellar objects signpost their progenitor system architectures</a><a hidden class=anchor aria-hidden=true href=#the-ejection-velocities-of-interstellar-objects-signpost-their-progenitor-system-architectureshttpsarxivorgabs251204700v1>#</a></h3><p><strong>Authors:</strong> Leah Albrow, Michele T. Bannister, John C. Forbes, David Nesvorn√Ω
<strong>Venue:</strong> arXiv (2025)</p><p>Interstellar objects (ISOs) ejected from planetary systems carry kinematic signatures of their formation environments. The properties of these velocity distributions govern the ISOs&rsquo; propagation and dynamical evolution in the Galactic potential. We investigate how planetary system architecture influences ISO production during post-gas-disc dynamical instabilities using N-body simulations. We explore the ISO production outcomes of 2461 randomly generated systems spanning total system masses of 300-800 Earth masses and multiplicities of 3-7 planets. By integrating planets embedded in a disc of test particles for 10 Myr, we find that evolving systems can be broadly divided into two distinct classes based on their initial architectures. Catastrophic systems are characterized by high multiplicities and orbitally compact configurations, or by high-mass planets in systems with large mass asymmetries. These systems eject a large fraction of their planetesimals (median 59 percent) and, depending on the ejection pathway, produce high-speed ISOs (median 2.9 km/s). In contrast, quiet systems have lower masses and multiplicities and do not undergo significant orbital rearrangement, yet still eject a median of 28 percent of planetesimals at lower velocities (median 1.6 km/s). This dichotomy points to distinct ejection pathways, involving either violent global instabilities or more gradual, diffusive processes. Overall, we find that ISO ejection velocities are typically low, on the order of a few km/s. Although ISOs subsequently experience dynamical heating as they orbit the Galaxy, their velocity distributions retain signatures of their progenitor systems&rsquo; architectures and histories, underscoring the potential use of ISOs in Galactic archaeology.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04700v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04700v1">üìÑ Download PDF</a></p><hr><h3 id=trinity-an-evolved-llm-coordinatorhttpsarxivorgabs251204695v1><a href=https://arxiv.org/abs/2512.04695v1>TRINITY: An Evolved LLM Coordinator</a><a hidden class=anchor aria-hidden=true href=#trinity-an-evolved-llm-coordinatorhttpsarxivorgabs251204695v1>#</a></h3><p><strong>Authors:</strong> Jinglue Xu, Qi Sun, Peter Schwendeman, Stefan Nielsen, Edoardo Cetin, Yujin Tang
<strong>Venue:</strong> arXiv (2025)</p><p>Combining diverse foundation models is promising, but weight-merging is limited by mismatched architectures and closed APIs. Trinity addresses this with a lightweight coordinator that orchestrates collaboration among large language models (LLMs). The coordinator, comprising a compact language model (approximately $0.6$B parameters) and a lightweight head (approximately $10$K parameters), is optimized with an evolutionary strategy for efficient and adaptive delegation. Trinity processes queries over multiple turns, where at each turn the coordinator assigns one of three roles (Thinker, Worker, or Verifier) to a selected LLM, effectively offloading complex skill acquisition from the coordinator itself. Experiments show that Trinity consistently outperforms individual models and existing methods across coding, math, reasoning, and domain knowledge tasks, and generalizes robustly to out-of-distribution tasks. On standard benchmarks, Trinity achieves state-of-the-art results, including a score of 86.2% on LiveCodeBench. Theoretical and empirical analyses identify two main factors behind this performance: (1) the coordinator&rsquo;s hidden-state representations provide rich contextualization of inputs, and (2) under high dimensionality and strict budget constraints, the separable Covariance Matrix Adaptation Evolution Strategy offers advantages over reinforcement learning, imitation learning, and random search by exploiting potential block-epsilon-separability.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04695v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04695v1">üìÑ Download PDF</a></p><hr><h3 id=faust-xxix-ocs-line-emission-a-new-method-for-measuring-the-luminosity-of-embedded-protostars-in-binary-systemshttpsarxivorgabs251204674v1><a href=https://arxiv.org/abs/2512.04674v1>FAUST XXIX. OCS line emission: a new method for measuring the luminosity of embedded protostars in binary systems</a><a hidden class=anchor aria-hidden=true href=#faust-xxix-ocs-line-emission-a-new-method-for-measuring-the-luminosity-of-embedded-protostars-in-binary-systemshttpsarxivorgabs251204674v1>#</a></h3><p><strong>Authors:</strong> Guillaume Saury, Vittorio Bariosco, Cecilia Ceccarelli, Ana L√≥pez-Sepulcre, Layal Chahine, Marta De Simone, Albert Rimola, Piero Ugliengo, Claire J. Chandler, Nami Sakai, Claudio Codella, Eleonora Bianchi, Lise Boitard&ndash;Cr√©peau, Mathilde Bouvier, Romane Le Gal, Laurent Loinard, Yoko Oya, Linda Podio, Giovanni Sabatini, Charlotte Vastel, Ziwei E. Zhang, Satoshi Yamamoto
<strong>Venue:</strong> arXiv (2025)</p><p>The luminosity of embedded protostars is commonly measured via observations of the dust continuum spectral energy distribution from millimetre to infrared wavelengths. However, this method cannot be applied to embedded protostars in binary or multiple systems, where their components are usually unresolved over this extended wavelength range. We propose a new method, based on the idea that a molecule formed (mainly) on the grain surfaces only emits lines in the region where it thermally sublimates from the grain mantles, heated by the photons emitted by the embedded source. In this respect, carbonyl sulfide (OCS) is an optimal molecule, because of its low binding energy and rotational lines in the millimetre. We apply the method to the protobinary system NGC1333 IRAS4A, using ALMA high-spatial resolution ($\sim$50 au) observations of the OCS(19-18) line as part of the ALMA Large Program FAUST. We also present new quantum mechanics calculations of the OCS binding energy distribution, essential for the application of the method. We found that the two binary components, A1 and A2, have a comparable luminosity within the error bars, 7.5$\pm$2.5 and 7$\pm$1 L$_\odot$, respectively. We discuss the reliability of the estimated luminosities and the potential of this new method for measuring the luminosity of embedded protostars in binary and multiple systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04674v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04674v1">üìÑ Download PDF</a></p><hr><h3 id=spectral-micro-ct-for-quantitative-analysis-of-calcification-in-fibrocartilagehttpsarxivorgabs251204662v1><a href=https://arxiv.org/abs/2512.04662v1>Spectral micro-CT for quantitative analysis of calcification in fibrocartilage</a><a hidden class=anchor aria-hidden=true href=#spectral-micro-ct-for-quantitative-analysis-of-calcification-in-fibrocartilagehttpsarxivorgabs251204662v1>#</a></h3><p><strong>Authors:</strong> Vittoria Mazzini, Paolo Cardarelli, Andrew L. Coathup, Eleonora Olivotto, Francesco Grassi, Enrico Tassinari, Simone Velardita, Angelo Taibi, Luca Brombal
<strong>Venue:</strong> arXiv (2025)</p><p>This work introduces a quantitative method for assessing calcification in fibrocartilage using spectral micro-computed tomography ($Œº$CT). Tissue samples of hip acetabular labrum from patients with osteoarthritis and femoroacetabular impingement were imaged with a laboratory-based spectral $Œº$CT system equipped with a small-pixel photon-counting detector. The detector operated with two energy thresholds, allowing the simultaneous acquisition of two CT datasets at different X-ray energies. A material decomposition algorithm accounting for the system&rsquo;s spectral response was applied to separate calcium- and water-like components, yielding three-dimensional visualization and quantification of calcified regions within intact paraffin-embedded samples. Unlike the conventional method for calcification assessment based on histology, this spectral ŒºCT approach offers volumetric quantification of calcium structures without physical sectioning or staining. The method achieved a voxel size of 20 $Œº$m for samples up to ~3 cm, with a calcium detection threshold of ~0.3 g/cm$^3$ for structures down to 50 $Œº$m. Quantification accuracy was estimated to be 5% by using a calibration phantom. Further comparison with histology demonstrated the correct localization of calcium spatial distributions and a match in the calcium crystal deposition score by providing non-destructive, quantitative 3D calcium maps of preserved tissue samples. This technique complements histology and could enhance the characterization of pathological fibrocartilage calcification in hip joint disorders.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04662v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04662v1">üìÑ Download PDF</a></p><hr><h3 id=qosdiff-an-implicit-topological-embedding-learning-framework-leveraging-denoising-diffusion-and-adversarial-attention-for-robust-qos-predictionhttpsarxivorgabs251204596v1><a href=https://arxiv.org/abs/2512.04596v1>QoSDiff: An Implicit Topological Embedding Learning Framework Leveraging Denoising Diffusion and Adversarial Attention for Robust QoS Prediction</a><a hidden class=anchor aria-hidden=true href=#qosdiff-an-implicit-topological-embedding-learning-framework-leveraging-denoising-diffusion-and-adversarial-attention-for-robust-qos-predictionhttpsarxivorgabs251204596v1>#</a></h3><p><strong>Authors:</strong> Guanchen Du, Jianlong Xu, Wei Wei
<strong>Venue:</strong> arXiv (2025)</p><p>Accurate Quality of Service (QoS) prediction is fundamental to service computing, providing essential data-driven guidance for service selection and ensuring superior user experiences. However, prevalent approaches, particularly Graph Neural Networks (GNNs), heavily rely on constructing explicit user&ndash;service interaction graphs. This dependency introduces severe scalability bottlenecks and limits performance when explicit connections are sparse or corrupted by noise. To address these challenges, this paper introduces \emph{QoSDiff}, a novel embedding learning framework that bypasses the prerequisite of explicit graph construction. Specifically, it leverages a denoising diffusion probabilistic model to recover intrinsic latent structures from noisy initializations. To further capture high-order interactions, we propose an adversarial interaction module that integrates a bidirectional hybrid attention mechanism. This adversarial paradigm dynamically distinguishes informative patterns from noise, enabling a dual-perspective modeling of intricate user&ndash;service associations. Extensive experiments on two large-scale real-world datasets demonstrate that QoSDiff significantly outperforms state-of-the-art baselines. Notably, the results highlight the framework&rsquo;s superior cross-dataset generalization capability and exceptional robustness against data sparsity and observational noise.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04596v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04596v1">üìÑ Download PDF</a></p><hr><h3 id=a-qudit-native-framework-for-discrete-time-crystalshttpsarxivorgabs251204577v1><a href=https://arxiv.org/abs/2512.04577v1>A Qudit-native Framework for Discrete Time Crystals</a><a hidden class=anchor aria-hidden=true href=#a-qudit-native-framework-for-discrete-time-crystalshttpsarxivorgabs251204577v1>#</a></h3><p><strong>Authors:</strong> Wei-Guo Ma, Heng Fan, Shi-Xin Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce a qudit-native framework for engineering robust discrete time crystals (DTCs) by leveraging their internal multilevel structure. Our approach confines the periodic drive to specified on-site subspaces, creating an embedded kick that suppresses heating by preventing population leakage to inactive levels. We underpin DTC stability with a normal-form analysis that decomposes the effective dynamics into distinct components: the carrier locks the subharmonic frequency, neutral terms govern the slow decay and dephasing of the subharmonic response, and charged terms scatter spectral weight away from the locked modes. This framework&rsquo;s predictive power is demonstrated across various qudit platforms: in spin-1 chains, we enhance the stability of DTC by confining the drive to a subspace; in spin-3/2 systems, we show that robustness is dictated by the symmetry of the subspace partition; and in spin-2 platforms, we realize concurrent 2T and 3T DTCs under a unified drive. These findings establish a systematic, hardware-efficient methodology for designing stable and multifunctional Floquet phases of matter on modern qudit-based quantum processors.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04577v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04577v1">üìÑ Download PDF</a></p><hr><h3 id=tardis-time-attenuated-representation-disentanglement-for-incomplete-multi-modal-tumor-segmentation-and-classificationhttpsarxivorgabs251204576v1><a href=https://arxiv.org/abs/2512.04576v1>TARDis: Time Attenuated Representation Disentanglement for Incomplete Multi-Modal Tumor Segmentation and Classification</a><a hidden class=anchor aria-hidden=true href=#tardis-time-attenuated-representation-disentanglement-for-incomplete-multi-modal-tumor-segmentation-and-classificationhttpsarxivorgabs251204576v1>#</a></h3><p><strong>Authors:</strong> Zishuo Wan, Qinqin Kang, Yi Huang, Yun Bian, Dawei Ding, Ke Yan
<strong>Venue:</strong> arXiv (2025)</p><p>Tumor segmentation and diagnosis in contrast-enhanced Computed Tomography (CT) rely heavily on the physiological dynamics of contrast agents. However, obtaining a complete multi-phase series is often clinically unfeasible due to radiation concerns or scanning limitations, leading to the &ldquo;missing modality&rdquo; problem. Existing deep learning approaches typically treat missing phases as absent independent channels, ignoring the inherent temporal continuity of hemodynamics. In this work, we propose Time Attenuated Representation Disentanglement (TARDis), a novel physics-aware framework that redefines missing modalities as missing sample points on a continuous Time-Attenuation Curve. TARDis explicitly disentangles the latent feature space into a time-invariant static component (anatomy) and a time-dependent dynamic component (perfusion). We achieve this via a dual-path architecture: a quantization-based path using a learnable embedding dictionary to extract consistent anatomical structures, and a probabilistic path using a Conditional Variational Autoencoder to model dynamic enhancement conditioned on the estimated scan time. This design allows the network to hallucinate missing hemodynamic features by sampling from the learned latent distribution. Extensive experiments on a large-scale private abdominal CT dataset (2,282 cases) and two public datasets demonstrate that TARDis significantly outperforms state-of-the-art incomplete modality frameworks. Notably, our method maintains robust diagnostic performance even in extreme data-sparsity scenarios, highlighting its potential for reducing radiation exposure while maintaining diagnostic precision.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04576v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04576v1">üìÑ Download PDF</a></p><hr><h3 id=identity-clue-refinement-and-enhancement-for-visible-infrared-person-re-identificationhttpsarxivorgabs251204522v1><a href=https://arxiv.org/abs/2512.04522v1>Identity Clue Refinement and Enhancement for Visible-Infrared Person Re-Identification</a><a hidden class=anchor aria-hidden=true href=#identity-clue-refinement-and-enhancement-for-visible-infrared-person-re-identificationhttpsarxivorgabs251204522v1>#</a></h3><p><strong>Authors:</strong> Guoqing Zhang, Zhun Wang, Hairui Wang, Zhonglin Ye, Yuhui Zheng
<strong>Venue:</strong> arXiv (2025)</p><p>Visible-Infrared Person Re-Identification (VI-ReID) is a challenging cross-modal matching task due to significant modality discrepancies. While current methods mainly focus on learning modality-invariant features through unified embedding spaces, they often focus solely on the common discriminative semantics across modalities while disregarding the critical role of modality-specific identity-aware knowledge in discriminative feature learning. To bridge this gap, we propose a novel Identity Clue Refinement and Enhancement (ICRE) network to mine and utilize the implicit discriminative knowledge inherent in modality-specific attributes. Initially, we design a Multi-Perception Feature Refinement (MPFR) module that aggregates shallow features from shared branches, aiming to capture modality-specific attributes that are easily overlooked. Then, we propose a Semantic Distillation Cascade Enhancement (SDCE) module, which distills identity-aware knowledge from the aggregated shallow features and guide the learning of modality-invariant features. Finally, an Identity Clues Guided (ICG) Loss is proposed to alleviate the modality discrepancies within the enhanced features and promote the learning of a diverse representation space. Extensive experiments across multiple public datasets clearly show that our proposed ICRE outperforms existing SOTA methods.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04522v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04522v1">üìÑ Download PDF</a></p><hr><h3 id=adaptive-time-domain-harmonic-control-for-noise-vibration-harshness-reduction-of-electric-driveshttpsarxivorgabs251204512v1><a href=https://arxiv.org/abs/2512.04512v1>Adaptive Time-Domain Harmonic Control for Noise-Vibration-Harshness Reduction of Electric Drives</a><a hidden class=anchor aria-hidden=true href=#adaptive-time-domain-harmonic-control-for-noise-vibration-harshness-reduction-of-electric-driveshttpsarxivorgabs251204512v1>#</a></h3><p><strong>Authors:</strong> Klaus Herburger, Fabian Jakob, David G√§nzle, Maximilian Manderla, Andrea Iannelli
<strong>Venue:</strong> arXiv (2025)</p><p>Reducing Noise, Vibration, and Harshness (NVH) in electric drives is crucial for applications such as electric vehicle drivetrains and heat-pump compressors, where strict NVH requirements directly affect user satisfaction and component longevity. This work presents the integration of an adaptive time-domain harmonic controller into an existing electric-drive control loop to attenuate harmonic disturbances. Three control structures are proposed and analyzed, along with a modified parameter-estimation scheme that reduces computational effort while preserving estimation accuracy, making the method suitable for embedded real-time implementation. To cope with fast operating-point changes, a delta-learning approach combines adaptive control with a lookup-table-based feedforward estimator, ensuring fast convergence and robustness. The proposed controller architectures are validated through simulation and testbench experiments on a permanent-magnet synchronous machine drive, demonstrating substantial NVH reductions across operating conditions. The results confirm that time-domain adaptive harmonic control offers a practical and theoretically grounded solution for real-time NVH mitigation in electric drives.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04512v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04512v1">üìÑ Download PDF</a></p><hr><h3 id=ultraimage-rethinking-resolution-extrapolation-in-image-diffusion-transformershttpsarxivorgabs251204504v1><a href=https://arxiv.org/abs/2512.04504v1>UltraImage: Rethinking Resolution Extrapolation in Image Diffusion Transformers</a><a hidden class=anchor aria-hidden=true href=#ultraimage-rethinking-resolution-extrapolation-in-image-diffusion-transformershttpsarxivorgabs251204504v1>#</a></h3><p><strong>Authors:</strong> Min Zhao, Bokai Yan, Xue Yang, Hongzhou Zhu, Jintao Zhang, Shilong Liu, Chongxuan Li, Jun Zhu
<strong>Venue:</strong> arXiv (2025)</p><p>Recent image diffusion transformers achieve high-fidelity generation, but struggle to generate images beyond these scales, suffering from content repetition and quality degradation. In this work, we present UltraImage, a principled framework that addresses both issues. Through frequency-wise analysis of positional embeddings, we identify that repetition arises from the periodicity of the dominant frequency, whose period aligns with the training resolution. We introduce a recursive dominant frequency correction to constrain it within a single period after extrapolation. Furthermore, we find that quality degradation stems from diluted attention and thus propose entropy-guided adaptive attention concentration, which assigns higher focus factors to sharpen local attention for fine detail and lower ones to global attention patterns to preserve structural consistency. Experiments show that UltraImage consistently outperforms prior methods on Qwen-Image and Flux (around 4K) across three generation scenarios, reducing repetition and improving visual fidelity. Moreover, UltraImage can generate images up to 6K*6K without low-resolution guidance from a training resolution of 1328p, demonstrating its extreme extrapolation capability. Project page is available at \href{https://thu-ml.github.io/ultraimage.github.io/}{https://thu-ml.github.io/ultraimage.github.io/}.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04504v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04504v1">üìÑ Download PDF</a></p><hr><h3 id=ai-assisted-game-management-decisions-a-fuzzy-logic-approach-to-real-time-substituitionshttpsarxivorgabs251204480v1><a href=https://arxiv.org/abs/2512.04480v1>AI-Assisted Game Management Decisions: A Fuzzy Logic Approach to Real-Time Substituitions</a><a hidden class=anchor aria-hidden=true href=#ai-assisted-game-management-decisions-a-fuzzy-logic-approach-to-real-time-substituitionshttpsarxivorgabs251204480v1>#</a></h3><p><strong>Authors:</strong> Pedro Passos
<strong>Venue:</strong> arXiv (2025)</p><p>In elite soccer, substitution decisions entail significant financial and sporting consequences yet remain heavily reliant on intuition or predictive models that merely mimic historical biases. This paper introduces a Fuzzy Logic based Decision Support System (DSS) designed for real time, prescriptive game management. Unlike traditional Machine Learning approaches that encounter a predictive ceiling by attempting to replicate human behavior, our system audits performance through an objective, rule based inference engine. We propose a methodological advancement by reformulating the PlayeRank metric into a Cumulative Mean with Role Aware Normalization, eliminating the play time exposure bias inherent in cumulative sum models to enable accurate intra match comparison. The system integrates this refined metric with physiological proxies (fatigue) and contextual variables (disciplinary risk modulated by tactical role) to calculate a dynamic Substitution Priority (P final). Validation via a case study of the 2018 FIFA World Cup match between Brazil and Belgium demonstrates the system&rsquo;s ecological validity: it not only aligned with expert consensus on executed substitutions (for example Gabriel Jesus) but, crucially, identified high risk scenarios ignored by human decision makers. Specifically, the model flagged the &ldquo;FAGNER Paradox&rdquo; - a maximum priority defensive risk - minutes before a critical yellow card, and detected the &ldquo;Lukaku Paradox&rdquo;, where an isolated assist masked a severe drop in participation. These results confirm that Fuzzy Logic offers a transparent, explainable, and superior alternative to black box models for optimizing real time tactical decisions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04480v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04480v1">üìÑ Download PDF</a></p><hr><h3 id=quantum-accelerated-deep-reinforcement-learning-for-frequency-regulation-enhancementhttpsarxivorgabs251204439v1><a href=https://arxiv.org/abs/2512.04439v1>Quantum-Accelerated Deep Reinforcement Learning for Frequency Regulation Enhancement</a><a hidden class=anchor aria-hidden=true href=#quantum-accelerated-deep-reinforcement-learning-for-frequency-regulation-enhancementhttpsarxivorgabs251204439v1>#</a></h3><p><strong>Authors:</strong> Amin Masoumi, Mert Korkali
<strong>Venue:</strong> arXiv (2025)</p><p>In modern power systems, frequency regulation is a fundamental prerequisite for ensuring system reliability and assessing the robustness of expansion projects. Conventional feedback control schemes, however, exhibit limited accuracy under varying operating conditions because their gains remain static. Consequently, deep reinforcement learning methods are increasingly employed to design adaptive controllers that can be generalized to diverse frequency control tasks. At the same time, recent advances in quantum computing provide avenues for embedding quantum capabilities into such critical applications. In particular, the potential of quantum algorithms can be more effectively explored and harnessed on near-term quantum devices by leveraging insights from active controller design. In this work, we incorporate a quantum circuit together with an ansatz into the operation of a deep deterministic policy gradient agent. The simulation results of the IEEE 14-bus test system demonstrate the potential of this integrated approach that can achieve reliable, robust performance across diverse real-world challenges.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04439v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04439v1">üìÑ Download PDF</a></p><hr><h3 id=refuzz-reusing-tests-for-processor-fuzzing-with-contextual-banditshttpsarxivorgabs251204436v1><a href=https://arxiv.org/abs/2512.04436v1>ReFuzz: Reusing Tests for Processor Fuzzing with Contextual Bandits</a><a hidden class=anchor aria-hidden=true href=#refuzz-reusing-tests-for-processor-fuzzing-with-contextual-banditshttpsarxivorgabs251204436v1>#</a></h3><p><strong>Authors:</strong> Chen Chen, Zaiyan Xu, Mohamadreza Rostami, David Liu, Dileep Kalathil, Ahmad-Reza Sadeghi, Jeyavijayan, Rajendran
<strong>Venue:</strong> arXiv (2025)</p><p>Processor designs rely on iterative modifications and reuse well-established designs. However, this reuse of prior designs also leads to similar vulnerabilities across multiple processors. As processors grow increasingly complex with iterative modifications, efficiently detecting vulnerabilities from modern processors is critical. Inspired by software fuzzing, hardware fuzzing has recently demonstrated its effectiveness in detecting processor vulnerabilities. Yet, to our best knowledge, existing processor fuzzers fuzz each design individually, lacking the capability to understand known vulnerabilities in prior processors to fine-tune fuzzing to identify similar or new variants of vulnerabilities.
To address this gap, we present ReFuzz, an adaptive fuzzing framework that leverages contextual bandit to reuse highly effective tests from prior processors to fuzz a processor-under-test (PUT) within a given ISA. By intelligently mutating tests that trigger vulnerabilities in prior processors, ReFuzz effectively detects similar and new variants of vulnerabilities in PUTs. ReFuzz uncovered three new security vulnerabilities and two new functional bugs. ReFuzz detected one vulnerability by reusing a test that triggers a known vulnerability in a prior processor. One functional bug exists across three processors that share design modules. The second bug has two variants. Additionally, ReFuzz reuses highly effective tests to enhance efficiency in coverage, achieving an average 511.23x coverage speedup and up to 9.33% more total coverage, compared to existing fuzzers.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04436v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04436v1">üìÑ Download PDF</a></p><hr><h3 id=self-paced-and-self-corrective-masked-prediction-for-movie-trailer-generationhttpsarxivorgabs251204426v1><a href=https://arxiv.org/abs/2512.04426v1>Self-Paced and Self-Corrective Masked Prediction for Movie Trailer Generation</a><a hidden class=anchor aria-hidden=true href=#self-paced-and-self-corrective-masked-prediction-for-movie-trailer-generationhttpsarxivorgabs251204426v1>#</a></h3><p><strong>Authors:</strong> Sidan Zhu, Hongteng Xu, Dixin Luo
<strong>Venue:</strong> arXiv (2025)</p><p>As a challenging video editing task, movie trailer generation involves selecting and reorganizing movie shots to create engaging trailers. Currently, most existing automatic trailer generation methods employ a &ldquo;selection-then-ranking&rdquo; paradigm (i.e., first selecting key shots and then ranking them), which suffers from inevitable error propagation and limits the quality of the generated trailers. Beyond this paradigm, we propose a new self-paced and self-corrective masked prediction method called SSMP, which achieves state-of-the-art results in automatic trailer generation via bi-directional contextual modeling and progressive self-correction. In particular, SSMP trains a Transformer encoder that takes the movie shot sequences as prompts and generates corresponding trailer shot sequences accordingly. The model is trained via masked prediction, reconstructing each trailer shot sequence from its randomly masked counterpart. The mask ratio is self-paced, allowing the task difficulty to adapt to the model and thereby improving model performance. When generating a movie trailer, the model fills the shot positions with high confidence at each step and re-masks the remaining positions for the next prediction, forming a progressive self-correction mechanism that is analogous to how human editors work. Both quantitative results and user studies demonstrate the superiority of SSMP in comparison to existing automatic movie trailer generation methods. Demo is available at: <a href=https://github.com/Dixin-Lab/SSMP>https://github.com/Dixin-Lab/SSMP</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04426v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04426v1">üìÑ Download PDF</a></p><hr><h3 id=falcon-actively-decoupled-visuomotor-policies-for-loco-manipulation-with-foundation-model-based-coordinationhttpsarxivorgabs251204381v1><a href=https://arxiv.org/abs/2512.04381v1>FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination</a><a hidden class=anchor aria-hidden=true href=#falcon-actively-decoupled-visuomotor-policies-for-loco-manipulation-with-foundation-model-based-coordinationhttpsarxivorgabs251204381v1>#</a></h3><p><strong>Authors:</strong> Chengyang He, Ge Sun, Yue Bai, Junkai Lu, Jiadong Zhao, Guillaume Sartoretti
<strong>Venue:</strong> arXiv (2025)</p><p>We present FoundAtion-model-guided decoupled LoCO-maNipulation visuomotor policies (FALCON), a framework for loco-manipulation that combines modular diffusion policies with a vision-language foundation model as the coordinator. Our approach explicitly decouples locomotion and manipulation into two specialized visuomotor policies, allowing each subsystem to rely on its own observations. This mitigates the performance degradation that arise when a single policy is forced to fuse heterogeneous, potentially mismatched observations from locomotion and manipulation. Our key innovation lies in restoring coordination between these two independent policies through a vision-language foundation model, which encodes global observations and language instructions into a shared latent embedding conditioning both diffusion policies. On top of this backbone, we introduce a phase-progress head that uses textual descriptions of task stages to infer discrete phase and continuous progress estimates without manual phase labels. To further structure the latent space, we incorporate a coordination-aware contrastive loss that explicitly encodes cross-subsystem compatibility between arm and base actions. We evaluate FALCON on two challenging loco-manipulation tasks requiring navigation, precise end-effector placement, and tight base-arm coordination. Results show that it surpasses centralized and decentralized baselines while exhibiting improved robustness and generalization to out-of-distribution scenarios.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04381v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04381v1">üìÑ Download PDF</a></p><hr><h3 id=mafnetmulti-frequency-adaptive-fusion-network-for-real-time-stereo-matchinghttpsarxivorgabs251204358v1><a href=https://arxiv.org/abs/2512.04358v1>MAFNet:Multi-frequency Adaptive Fusion Network for Real-time Stereo Matching</a><a hidden class=anchor aria-hidden=true href=#mafnetmulti-frequency-adaptive-fusion-network-for-real-time-stereo-matchinghttpsarxivorgabs251204358v1>#</a></h3><p><strong>Authors:</strong> Ao Xu, Rujin Zhao, Xiong Xu, Boceng Huang, Yujia Jia, Hongfeng Long, Fuxuan Chen, Zilong Cao, Fangyuan Chen
<strong>Venue:</strong> arXiv (2025)</p><p>Existing stereo matching networks typically rely on either cost-volume construction based on 3D convolutions or deformation methods based on iterative optimization. The former incurs significant computational overhead during cost aggregation, whereas the latter often lacks the ability to model non-local contextual information. These methods exhibit poor compatibility on resource-constrained mobile devices, limiting their deployment in real-time applications. To address this, we propose a Multi-frequency Adaptive Fusion Network (MAFNet), which can produce high-quality disparity maps using only efficient 2D convolutions. Specifically, we design an adaptive frequency-domain filtering attention module that decomposes the full cost volume into high-frequency and low-frequency volumes, performing frequency-aware feature aggregation separately. Subsequently, we introduce a Linformer-based low-rank attention mechanism to adaptively fuse high- and low-frequency information, yielding more robust disparity estimation. Extensive experiments demonstrate that the proposed MAFNet significantly outperforms existing real-time methods on public datasets such as Scene Flow and KITTI 2015, showing a favorable balance between accuracy and real-time performance.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04358v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04358v1">üìÑ Download PDF</a></p><hr><h3 id=ledds-portable-lbm-dem-simulations-on-gpushttpsarxivorgabs251204997v1><a href=https://arxiv.org/abs/2512.04997v1>LEDDS: Portable LBM-DEM simulations on GPUs</a><a hidden class=anchor aria-hidden=true href=#ledds-portable-lbm-dem-simulations-on-gpushttpsarxivorgabs251204997v1>#</a></h3><p><strong>Authors:</strong> Raphael Maggio-Aprile, Maxime Rambosson, Christophe Coreixas, Jonas Latt
<strong>Venue:</strong> arXiv (2025)</p><p>Algorithmic formulations of GPU programs provide a high-level alternative to device-specific code by expressing computations as compositions of well-defined parallel primitives (e.g., map, sort, reduce), rather than through handcrafted GPU kernels. In this work, we demonstrate that this paradigm can be extended to complex and challenging problems in computational physics: the simulation of granular flows and fluid-particle interactions.
LEDDS, our open-source framework, performs fully coupled Lattice Boltzmann &ndash; Discrete Element Method (LBM-DEM) simulations using only algorithmic primitives, and runs efficiently on single-GPU platforms. The entire workflow, including neighbor search, collision detection, and fluid-particle coupling, is expressed as a sequence of portable primitives. While the current implementation illustrates these principles primarily through algorithms from the C++ Standard Library, with selective use of Thrust primitives for performance, the underlying concept is compatible with any HPC environment offering a rich set of parallel algorithms and is therefore applicable across a wide range of modern GPU systems and future accelerators.
LEDDS is validated through benchmarks spanning both DEM and LBM-DEM configurations, including sphere and ellipsoid collisions, wall friction tests, single-particle settling, Jeffery&rsquo;s orbits, and particle-laden shear flows. Despite its high level of abstraction, LEDDS achieves performances comparable to those of hand-tuned CUDA solvers, while maintaining portability and code clarity. These results show that high-performance LBM-DEM coupling can be achieved without sacrificing generality or readability, establishing LEDDS as a blueprint for portable multiphysics frameworks based on algorithmic primitives.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04997v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04997v1">üìÑ Download PDF</a></p><hr><h3 id=amortized-inference-of-multi-modal-posteriors-using-likelihood-weighted-normalizing-flowshttpsarxivorgabs251204954v1><a href=https://arxiv.org/abs/2512.04954v1>Amortized Inference of Multi-Modal Posteriors using Likelihood-Weighted Normalizing Flows</a><a hidden class=anchor aria-hidden=true href=#amortized-inference-of-multi-modal-posteriors-using-likelihood-weighted-normalizing-flowshttpsarxivorgabs251204954v1>#</a></h3><p><strong>Authors:</strong> Rajneil Baruah
<strong>Venue:</strong> arXiv (2025)</p><p>We present a novel technique for amortized posterior estimation using Normalizing Flows trained with likelihood-weighted importance sampling. This approach allows for the efficient inference of theoretical parameters in high-dimensional inverse problems without the need for posterior training samples. We implement the method on multi-modal benchmark tasks in 2D and 3D to check for the efficacy. A critical observation of our study is the impact of the topology of the base distributions on the modelled posteriors. We find that standard unimodal base distributions fail to capture disconnected support, resulting in spurious probability bridges between modes. We demonstrate that initializing the flow with a Gaussian Mixture Model that matches the cardinality of the target modes significantly improves reconstruction fidelity, as measured by some distance and divergence metrics.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04954v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04954v1">üìÑ Download PDF</a></p><hr><h3 id=towards-adaptive-fusion-of-multimodal-deep-networks-for-human-action-recognitionhttpsarxivorgabs251204943v1><a href=https://arxiv.org/abs/2512.04943v1>Towards Adaptive Fusion of Multimodal Deep Networks for Human Action Recognition</a><a hidden class=anchor aria-hidden=true href=#towards-adaptive-fusion-of-multimodal-deep-networks-for-human-action-recognitionhttpsarxivorgabs251204943v1>#</a></h3><p><strong>Authors:</strong> Novanto Yudistira
<strong>Venue:</strong> arXiv (2025)</p><p>This study introduces a pioneering methodology for human action recognition by harnessing deep neural network techniques and adaptive fusion strategies across multiple modalities, including RGB, optical flows, audio, and depth information. Employing gating mechanisms for multimodal fusion, we aim to surpass limitations inherent in traditional unimodal recognition methods while exploring novel possibilities for diverse applications. Through an exhaustive investigation of gating mechanisms and adaptive weighting-based fusion architectures, our methodology enables the selective integration of relevant information from various modalities, thereby bolstering both accuracy and robustness in action recognition tasks. We meticulously examine various gated fusion strategies to pinpoint the most effective approach for multimodal action recognition, showcasing its superiority over conventional unimodal methods. Gating mechanisms facilitate the extraction of pivotal features, resulting in a more holistic representation of actions and substantial enhancements in recognition performance. Our evaluations across human action recognition, violence action detection, and multiple self-supervised learning tasks on benchmark datasets demonstrate promising advancements in accuracy. The significance of this research lies in its potential to revolutionize action recognition systems across diverse fields. The fusion of multimodal information promises sophisticated applications in surveillance and human-computer interaction, especially in contexts related to active assisted living.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04943v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04943v1">üìÑ Download PDF</a></p><hr><h3 id=valley-splittings-in-sisige-heterostructures-from-first-principleshttpsarxivorgabs251204879v1><a href=https://arxiv.org/abs/2512.04879v1>Valley Splittings in Si/SiGe Heterostructures from First Principles</a><a hidden class=anchor aria-hidden=true href=#valley-splittings-in-sisige-heterostructures-from-first-principleshttpsarxivorgabs251204879v1>#</a></h3><p><strong>Authors:</strong> Lukas Cvitkovich, Tancredi Salamone, Christoph Wilhelmer, Biel Martinez, Tibor Grasser, Yann-Michel Niquet
<strong>Venue:</strong> arXiv (2025)</p><p>We compute valley splittings in Si/SiGe superlattices using ab initio density functional theory (DFT). This first-principle approach is expected to provide an excellent description of interfaces, strains, and atomistic disorder without empirically fitted parameters. We benchmark atomistic tight- binding (TB) and the ``$2k_0$&rsquo;&rsquo; theory within the effective mass (EM) approximation against DFT. We show that DFT supports the main conclusions of the 2$k_0$ theory, but reveals some limitations of semi-empirical methods such as the EM and TB, in particular about the description of atomistic disorder. The DFT calculations also highlight the effects of strong valley-orbit mixing at large valley splittings. Nevertheless, TB and the 2$k_0$ theory shall provide reasonable valley splitting statistics in many heterostructures of interest for spin qubit devices.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04879v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04879v1">üìÑ Download PDF</a></p><hr><h3 id=the-single-differential-cross-sections-sdcs-for-h3s-ionization-in-the-first-born-approximation-by-electron-and-positron-impacthttpsarxivorgabs251204870v1><a href=https://arxiv.org/abs/2512.04870v1>The Single Differential Cross Sections (SDCS) for H(3s) Ionization in the First-Born Approximation by Electron and Positron Impact</a><a hidden class=anchor aria-hidden=true href=#the-single-differential-cross-sections-sdcs-for-h3s-ionization-in-the-first-born-approximation-by-electron-and-positron-impacthttpsarxivorgabs251204870v1>#</a></h3><p><strong>Authors:</strong> Fahadul Islam, Sunil Dhar
<strong>Venue:</strong> arXiv (2025)</p><p>A theoretical study was conducted on the impact of electron and positron impact ionization of excited hydrogen atoms that were in the 3s state; this study was conducted within the First-Born Approximation (FBA), which provides an analytical expression for the transition matrix in terms of the Bethe-Lewis Integral Formalism. This formalism utilized both Coulomb continuum and confluent hypergeometric functions to describe the scattering states involved. Single Differential Cross Sections (SDCS) were calculated for incident energies of 100, 150, 200, and 250 eV. The data obtained indicated a peak in the ionization rates approximately at 200 eV, with the ionization rate decreasing as the incident energy increased further. The diffuse radial nature of the 3s wave function is shown to increase the sensitivity of the ionization dynamics to the incident particle energy. Asymmetries in charge were also detected; specifically, at low energy of the ejected electron, the SDCS values for positrons were greater than the corresponding values for electrons; however, as the energy of the incident particles was increased, these differences disappeared, thereby demonstrating the applicability of the FBA at high energy limits. The residual differences at low energy were due to the omission of exchange and post-collision interactions from the model. The results of this work can be used as benchmarking for the development of more complex distorted wave and multi-scattering theories in excited state ionization processes.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04870v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04870v1">üìÑ Download PDF</a></p><hr><h3 id=optimal-transport-event-representation-for-anomaly-detectionhttpsarxivorgabs251204839v1><a href=https://arxiv.org/abs/2512.04839v1>Optimal Transport Event Representation for Anomaly Detection</a><a hidden class=anchor aria-hidden=true href=#optimal-transport-event-representation-for-anomaly-detectionhttpsarxivorgabs251204839v1>#</a></h3><p><strong>Authors:</strong> Aditya Bhargava, Tianji Cai, Benjamin Nachman
<strong>Venue:</strong> arXiv (2025)</p><p>We introduce optimal transport (OT) as a physics-based intermediate event representation for weakly supervised anomaly detection. With only $0.5%$ injection of resonant signals in the LHC Olympics benchmark datasets, the OT-augmented feature set achieves nearly twice the significance improvement of standard high-level observables, while end-to-end deep learning on low-level four-momenta struggles in the low-signal regime. The gains persist across signal types and classifiers, underscoring the value of structured representations in machine learning for anomaly detection.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04839v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04839v1">üìÑ Download PDF</a></p><hr><h3 id=model-based-and-sample-efficient-ai-assisted-math-discovery-in-sphere-packinghttpsarxivorgabs251204829v1><a href=https://arxiv.org/abs/2512.04829v1>Model-Based and Sample-Efficient AI-Assisted Math Discovery in Sphere Packing</a><a hidden class=anchor aria-hidden=true href=#model-based-and-sample-efficient-ai-assisted-math-discovery-in-sphere-packinghttpsarxivorgabs251204829v1>#</a></h3><p><strong>Authors:</strong> Rasul Tutunov, Alexandre Maraval, Antoine Grosnit, Xihan Li, Jun Wang, Haitham Bou-Ammar
<strong>Venue:</strong> arXiv (2025)</p><p>Sphere packing, Hilbert&rsquo;s eighteenth problem, asks for the densest arrangement of congruent spheres in n-dimensional Euclidean space. Although relevant to areas such as cryptography, crystallography, and medical imaging, the problem remains unresolved: beyond a few special dimensions, neither optimal packings nor tight upper bounds are known. Even a major breakthrough in dimension $n=8$, later recognised with a Fields Medal, underscores its difficulty. A leading technique for upper bounds, the three-point method, reduces the problem to solving large, high-precision semidefinite programs (SDPs). Because each candidate SDP may take days to evaluate, standard data-intensive AI approaches are infeasible. We address this challenge by formulating SDP construction as a sequential decision process, the SDP game, in which a policy assembles SDP formulations from a set of admissible components. Using a sample-efficient model-based framework that combines Bayesian optimisation with Monte Carlo Tree Search, we obtain new state-of-the-art upper bounds in dimensions $4-16$, showing that model-based search can advance computational progress in longstanding geometric problems. Together, these results demonstrate that sample-efficient, model-based search can make tangible progress on mathematically rigid, evaluation limited problems, pointing towards a complementary direction for AI-assisted discovery beyond large-scale LLM-driven exploration.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04829v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04829v1">üìÑ Download PDF</a></p><hr><h3 id=small-signal-stability-oriented-real-time-operation-of-power-systems-with-a-high-penetration-of-inverter-based-resourceshttpsarxivorgabs251204892v1><a href=https://arxiv.org/abs/2512.04892v1>Small-Signal Stability Oriented Real-Time Operation of Power Systems with a High Penetration of Inverter-Based Resources</a><a hidden class=anchor aria-hidden=true href=#small-signal-stability-oriented-real-time-operation-of-power-systems-with-a-high-penetration-of-inverter-based-resourceshttpsarxivorgabs251204892v1>#</a></h3><p><strong>Authors:</strong> Francesca Rossi, Juan Carlos Olives-Camps, Eduardo Prieto-Araujo, Oriol Gomis-Bellmunt
<strong>Venue:</strong> arXiv (2025)</p><p>This study proposes a control strategy to ensure the safe operation of modern power systems with high penetration of inverter-based resources (IBRs) within an optimal operation framework. The objective is to obtain operating points that satisfy the optimality conditions of a predefined problem while guaranteeing small-signal stability. The methodology consists of two stages. First, an offline analysis of a set of operating points is performed to derive a data-driven regression-based expression that captures a damping-based stability index as a function of the operating conditions. Second, an Online Feedback Optimization (OFO) controller is employed to drive the system toward an optimal operating point while maintaining a secure distance from the instability region. The proposed strategy is evaluated on an academic test case based on a modified version of the IEEE 9-bus system, in which synchronous generators are replaced by IBRs operating under both grid-following and grid-forming control modes. The results demonstrate the effectiveness of the method and are discussed in detail.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04892v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04892v1">üìÑ Download PDF</a></p><hr><h3 id=high-performance-dbmss-with-io_uring-when-and-how-to-use-ithttpsarxivorgabs251204859v1><a href=https://arxiv.org/abs/2512.04859v1>High-Performance DBMSs with io_uring: When and How to use it</a><a hidden class=anchor aria-hidden=true href=#high-performance-dbmss-with-io_uring-when-and-how-to-use-ithttpsarxivorgabs251204859v1>#</a></h3><p><strong>Authors:</strong> Matthias Jasny, Muhammad El-Hindi, Tobias Ziegler, Viktor Leis, Carsten Binnig
<strong>Venue:</strong> arXiv (2025)</p><p>We study how modern database systems can leverage the Linux io_uring interface for efficient, low-overhead I/O. io_uring is an asynchronous system call batching interface that unifies storage and network operations, addressing limitations of existing Linux I/O interfaces. However, naively replacing traditional I/O interfaces with io_uring does not necessarily yield performance benefits. To demonstrate when io_uring delivers the greatest benefits and how to use it effectively in modern database systems, we evaluate it in two use cases: Integrating io_uring into a storage-bound buffer manager and using it for high-throughput data shuffling in network-bound analytical workloads. We further analyze how advanced io_uring features, such as registered buffers and passthrough I/O, affect end-to-end performance. Our study shows when low-level optimizations translate into tangible system-wide gains and how architectural choices influence these benefits. Building on these insights, we derive practical guidelines for designing I/O-intensive systems using io_uring and validate their effectiveness in a case study of PostgreSQL&rsquo;s recent io_uring integration, where applying our guidelines yields a performance improvement of 14%.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04859v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04859v1">üìÑ Download PDF</a></p><hr><h3 id=from-symptoms-to-systems-an-expert-guided-approach-to-understanding-risks-of-generative-ai-for-eating-disordershttpsarxivorgabs251204843v1><a href=https://arxiv.org/abs/2512.04843v1>From Symptoms to Systems: An Expert-Guided Approach to Understanding Risks of Generative AI for Eating Disorders</a><a hidden class=anchor aria-hidden=true href=#from-symptoms-to-systems-an-expert-guided-approach-to-understanding-risks-of-generative-ai-for-eating-disordershttpsarxivorgabs251204843v1>#</a></h3><p><strong>Authors:</strong> Amy Winecoff, Kevin Klyman
<strong>Venue:</strong> arXiv (2025)</p><p>Generative AI systems may pose serious risks to individuals vulnerable to eating disorders. Existing safeguards tend to overlook subtle but clinically significant cues, leaving many risks unaddressed. To better understand the nature of these risks, we conducted semi-structured interviews with 15 clinicians, researchers, and advocates with expertise in eating disorders. Using abductive qualitative analysis, we developed an expert-guided taxonomy of generative AI risks across seven categories: (1) providing generalized health advice; (2) encouraging disordered behaviors; (3) supporting symptom concealment; (4) creating thinspiration; (5) reinforcing negative self-beliefs; (6) promoting excessive focus on the body; and (7) perpetuating narrow views about eating disorders. Our results demonstrate how certain user interactions with generative AI systems intersect with clinical features of eating disorders in ways that may intensify risk. We discuss implications of our work, including approaches for risk assessment, safeguard design, and participatory evaluation practices with domain experts.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04843v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04843v1">üìÑ Download PDF</a></p><hr><h2 id=-neuroscience>üîç neuroscience<a hidden class=anchor aria-hidden=true href=#-neuroscience>#</a></h2><h3 id=a-high-order-discretization-scheme-for-surface-integral-equations-for-analyzing-the-electroencephalography-forward-problemhttpsarxivorgabs251204845v1><a href=https://arxiv.org/abs/2512.04845v1>A High-Order Discretization Scheme for Surface Integral Equations for Analyzing the Electroencephalography Forward Problem</a><a hidden class=anchor aria-hidden=true href=#a-high-order-discretization-scheme-for-surface-integral-equations-for-analyzing-the-electroencephalography-forward-problemhttpsarxivorgabs251204845v1>#</a></h3><p><strong>Authors:</strong> Rui Chen, Viviana Giunzioni, Adrien Merlini, Francesco P. Andriulli
<strong>Venue:</strong> arXiv (2025)</p><p>A Nystrom-based high-order (HO) discretization scheme for surface integral equations (SIEs) for analyzing the electroencephalography (EEG) forward problem is proposed in this work. We use HO surface elements and interpolation functions for the discretization of the interfaces of the head volume and the unknowns on the elements, respectively. The advantage of this work over existing isoparametric HO discretization schemes resides in the fact that the interpolation points are different from the mesh nodes, allowing for the flexible manipulation of the order of the basis functions without regenerating the mesh of the interfaces. Moreover, the interpolation points are chosen from the quadrature rules with the same number of points on the elements simplifying the numerical computation of the surface integrals for the far-interaction case. In this contribution, we extend the implementation of the HO discretization scheme to the double-layer and the adjoint double-layer formulations, as well as to the isolated-skull-approach for the double-layer formulation and to the indirect adjoint double-layer formulation, employed to improve the solution accuracy in case of high conductivity contrast models, which requires the development of different techniques for the singularity treatment. Numerical experiments are presented to demonstrate the accuracy, flexibility, and efficiency of the proposed scheme for the four SIEs for analyzing the EEG forward problem.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04845v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04845v1">üìÑ Download PDF</a></p><hr><h3 id=plug-and-play-homeostatic-spark-zero-cost-acceleration-for-snn-training-across-paradigmshttpsarxivorgabs251205015v1><a href=https://arxiv.org/abs/2512.05015v1>Plug-and-Play Homeostatic Spark: Zero-Cost Acceleration for SNN Training Across Paradigms</a><a hidden class=anchor aria-hidden=true href=#plug-and-play-homeostatic-spark-zero-cost-acceleration-for-snn-training-across-paradigmshttpsarxivorgabs251205015v1>#</a></h3><p><strong>Authors:</strong> Rui Chen, Xingyu Chen, Yaoqing Hu, Shihan Kong, Zhiheng Wu, Junzhi Yu
<strong>Venue:</strong> arXiv (2025)</p><p>Spiking neural networks offer event driven computation, sparse activation, and hardware efficiency, yet training often converges slowly and lacks stability. We present Adaptive Homeostatic Spiking Activity Regulation (AHSAR), an extremely simple plug in and training paradigm agnostic method that stabilizes optimization and accelerates convergence without changing the model architecture, loss, or gradients. AHSAR introduces no trainable parameters. It maintains a per layer homeostatic state during the forward pass, maps centered firing rate deviations to threshold scales through a bounded nonlinearity, uses lightweight cross layer diffusion to avoid sharp imbalance, and applies a slow across epoch global gain that combines validation progress with activity energy to tune the operating point. The computational cost is negligible. Across diverse training methods, SNN architectures of different depths, widths, and temporal steps, and both RGB and DVS datasets, AHSAR consistently improves strong baselines and enhances out of distribution robustness. These results indicate that keeping layer activity within a moderate band is a simple and effective principle for scalable and efficient SNN training.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05015v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05015v1">üìÑ Download PDF</a></p><hr><h3 id=the-clifford-defect-of-a-numerical-semigrouphttpsarxivorgabs251204925v1><a href=https://arxiv.org/abs/2512.04925v1>The Clifford defect of a numerical semigroup</a><a hidden class=anchor aria-hidden=true href=#the-clifford-defect-of-a-numerical-semigrouphttpsarxivorgabs251204925v1>#</a></h3><p><strong>Authors:</strong> Eduardo Camps-Moreno, Adri√°n Fidalgo-D√≠az, Umberto Mart√≠nez-Pe√±as, Gretchen L. Matthews
<strong>Venue:</strong> arXiv (2025)</p><p>The Clifford defect is a rational number associated to the Weierstrass semigroup at a given point of an algebraic curve. It describes the error-correcting capability of the so-called Modified Algorithm for decoding the corresponding one-point codes defined at the point. This defect also finds applications in other contexts involving one-point codes. We study the Clifford defect of some numerical semigroups arising from curves and give explicit formulas for them.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04925v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04925v1">üìÑ Download PDF</a></p><hr><h3 id=a-result-relating-convex-n-widths-to-covering-numbers-with-some-applications-to-neural-networkshttpsarxivorgabs251204912v1><a href=https://arxiv.org/abs/2512.04912v1>A result relating convex n-widths to covering numbers with some applications to neural networks</a><a hidden class=anchor aria-hidden=true href=#a-result-relating-convex-n-widths-to-covering-numbers-with-some-applications-to-neural-networkshttpsarxivorgabs251204912v1>#</a></h3><p><strong>Authors:</strong> Jonathan Baxter, Peter Bartlett
<strong>Venue:</strong> arXiv (2025)</p><p>In general, approximating classes of functions defined over high-dimensional input spaces by linear combinations of a fixed set of basis functions or <code>features'' is known to be hard. Typically, the worst-case error of the best basis set decays only as fast as $Œò\(n^{-1/d}\)$, where $n$ is the number of basis functions and $d$ is the input dimension. However, there are many examples of high-dimensional pattern recognition problems (such as face recognition) where linear combinations of small sets of features do solve the problem well. Hence these function classes do not suffer from the </code>curse of dimensionality&rsquo;&rsquo; associated with more general classes. It is natural then, to look for characterizations of high-dimensional function classes that nevertheless are approximated well by linear combinations of small sets of features. In this paper we give a general result relating the error of approximation of a function class to the covering number of its ``convex core&rsquo;&rsquo;. For one-hidden-layer neural networks, covering numbers of the class of functions computed by a single hidden node upper bound the covering numbers of the convex core. Hence, using standard results we obtain upper bounds on the approximation rate of neural network classes.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04912v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04912v1">üìÑ Download PDF</a></p><hr><h3 id=data-driven-methods-for-delay-differential-equationshttpsarxivorgabs251204894v1><a href=https://arxiv.org/abs/2512.04894v1>Data-driven Methods for Delay Differential Equations</a><a hidden class=anchor aria-hidden=true href=#data-driven-methods-for-delay-differential-equationshttpsarxivorgabs251204894v1>#</a></h3><p><strong>Authors:</strong> Dimitri Breda, Xunbi A. Ji, G√°bor Orosz, Muhammad Tanveer
<strong>Venue:</strong> arXiv (2025)</p><p>Data-driven methodologies are nowadays ubiquitous. Their rapid development and spread have led to applications even beyond the traditional fields of science. As far as dynamical systems and differential equations are concerned, neural networks and sparse identification tools have emerged as powerful approaches to recover the governing equations from available temporal data series. In this chapter we first illustrate possible extensions of the sparse identification of nonlinear dynamics (SINDy) algorithm, originally developed for ordinary differential equations (ODEs), to delay differential equations (DDEs) with discrete, possibly multiple and unknown delays. Two methods are presented for SINDy, one directly tackles the underlying DDE and the other acts on the system of ODEs approximating the DDE through pseudospectral collocation. We also introduce another way of capturing the dynamics of DDEs using neural networks and trainable delays in continuous time, and present the training algorithms developed for these neural delay differential equations (NDDEs). The relevant MATLAB implementations for both the SINDy approach and for the NDDE approach are provided. These approaches are tested on several examples, including classical systems such as the delay logistic and the Mackey-Glass equation, and directly compared to each other on the delayed R√∂ssler system. We provide insights on the connection between the approaches and future directions on developing data-driven methods for time delay systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04894v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04894v1">üìÑ Download PDF</a></p><hr><h3 id=pick-to-learn-for-systems-and-control-data-driven-synthesis-with-state-of-the-art-safety-guaranteeshttpsarxivorgabs251204781v1><a href=https://arxiv.org/abs/2512.04781v1>Pick-to-Learn for Systems and Control: Data-driven Synthesis with State-of-the-art Safety Guarantees</a><a hidden class=anchor aria-hidden=true href=#pick-to-learn-for-systems-and-control-data-driven-synthesis-with-state-of-the-art-safety-guaranteeshttpsarxivorgabs251204781v1>#</a></h3><p><strong>Authors:</strong> Dario Paccagnan, Daniel Marks, Marco C. Campi, Simone Garatti
<strong>Venue:</strong> arXiv (2025)</p><p>Data-driven methods have become paramount in modern systems and control problems characterized by growing levels of complexity. In safety-critical environments, deploying these methods requires rigorous guarantees, a need that has motivated much recent work at the interface of statistical learning and control. However, many existing approaches achieve this goal at the cost of sacrificing valuable data for testing and calibration, or by constraining the choice of learning algorithm, thus leading to suboptimal performances. In this paper, we describe Pick-to-Learn (P2L) for Systems and Control, a framework that allows any data-driven control method to be equipped with state-of-the-art safety and performance guarantees. P2L enables the use of all available data to jointly synthesize and certify the design, eliminating the need to set aside data for calibration or validation purposes. In presenting a comprehensive version of P2L for systems and control, this paper demonstrates its effectiveness across a range of core problems, including optimal control, reachability analysis, safe synthesis, and robust control. In many of these applications, P2L delivers designs and certificates that outperform commonly employed methods, and shows strong potential for broad applicability in diverse practical settings.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04781v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04781v1">üìÑ Download PDF</a></p><hr><h3 id=demonstration-of-surface-engineered-oxidation-resistant-nb-nb-thermocompression-bonding-toward-scalable-superconducting-quantum-computing-architectureshttpsarxivorgabs251204712v1><a href=https://arxiv.org/abs/2512.04712v1>Demonstration of surface-engineered oxidation-resistant Nb-Nb thermocompression bonding toward scalable superconducting quantum computing architectures</a><a hidden class=anchor aria-hidden=true href=#demonstration-of-surface-engineered-oxidation-resistant-nb-nb-thermocompression-bonding-toward-scalable-superconducting-quantum-computing-architectureshttpsarxivorgabs251204712v1>#</a></h3><p><strong>Authors:</strong> Harsh Mishra, Yusuke Kozuka, Sathish Bonam, Jun Uzuhashi, Praveenkumar Suggisetti, Tadakatsu Ohkubo, Shiv Govind Singh
<strong>Venue:</strong> arXiv (2025)</p><p>Scalable quantum computing currently requires a large array of qubit integration, but present two-dimensional interconnects face challenges such as wiring congestion, electromagnetic interference, and limited cryogenic space. To overcome this challenge, implementing three-dimensional (3D) vertical architectures becomes crucial. Niobium (Nb), due to its excellent superconducting characteristics and strong fabrication process compatibility, stands out as a prime material choice. The main challenge in Nb-Nb bonding is the presence of an oxide layer at the interface, even after post-bonding annealing across various bonding methods. The native Nb oxide forms rapidly in air, creating a resistive barrier to supercurrent flow and introducing two-level system losses that degrade qubit coherence while increasing the overall thermal budget. These issues show the need for effective surface engineering to suppress oxidation during bonding. This study introduces an ultrathin gold (Au) capping layer as a passivation strategy to prevent oxygen incorporation at the Nb surface. This approach enables low-temperature Nb-Nb thermocompression bonding at 350 ¬∞C under a reduced bonding pressure of 0.495 MPa. Detailed microstructural and interfacial analyses confirm that Au passivation effectively suppresses oxide formation and hence enhances bonding uniformity and strength with keeping the superconductivity, establishing a robust route toward low-temperature, low-pressure Nb-Nb bonding for scalable 3D superconducting quantum computing architectures.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04712v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04712v1">üìÑ Download PDF</a></p><hr><h3 id=interface-layers-and-coupling-conditions-for-discrete-kinetic-models-on-networks-a-spectral-approachttpsarxivorgabs251204634v1><a href=https://arxiv.org/abs/2512.04634v1>Interface layers and coupling conditions for discrete kinetic models on networks: a spectral approac</a><a hidden class=anchor aria-hidden=true href=#interface-layers-and-coupling-conditions-for-discrete-kinetic-models-on-networks-a-spectral-approachttpsarxivorgabs251204634v1>#</a></h3><p><strong>Authors:</strong> Raul Borsche, Tobias Damm, Axel Klar, Yizhou Zhou
<strong>Venue:</strong> arXiv (2025)</p><p>We consider kinetic and related macroscopic equations on networks. A class of linear kinetic BGK models is considered, where the limit equation for small Knudsen numbers is given by the wave equation. Coupling conditions for the macroscopic equations are obtained from the kinetic coupling conditions via an asymptotic analysis near the nodes of the network and the consideration of coupled solutions of kinetic half-space problems. Analytical results are obtained for a discrete velocity version of the coupled half-space problems. Moreover, an efficient spectral method is developed to solve the coupled discrete velocity half-space problems. In particular, this allows to determine the relevant coefficients in the coupling conditions for the macroscopic equations
from the underlying kinetic network problem. These coefficients correspond to the so-called extrapolation length for kinetic boundary value problems. Numerical results show the accuracy and fast convergence of the approach. Moreover, a comparison of the kinetic solution on the network with the macroscopic solution is presented.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04634v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04634v1">üìÑ Download PDF</a></p><hr><h3 id=on-the-construction-of-high-order-and-exact-pressure-equilibrium-schemes-for-arbitrary-equations-of-statehttpsarxivorgabs251204450v1><a href=https://arxiv.org/abs/2512.04450v1>On the Construction of High-Order and Exact Pressure Equilibrium Schemes for Arbitrary Equations of State</a><a hidden class=anchor aria-hidden=true href=#on-the-construction-of-high-order-and-exact-pressure-equilibrium-schemes-for-arbitrary-equations-of-statehttpsarxivorgabs251204450v1>#</a></h3><p><strong>Authors:</strong> Christopher DeGrendele, Nguyen Ly, Francois Cadieux, Michael Barad, Dongwook Lee, Jared Duensing
<strong>Venue:</strong> arXiv (2025)</p><p>Typical fully conservative discretizations of the Euler compressible single or multi-component fluid equations governed by a real-fluid equation of state exhibit spurious pressure oscillations due to the nonlinearity of the thermodynamic relation between pressure, density, and internal energy. A fully conservative, pressure-equilibrium preserving method and a high-order, fully conservative, approximate pressure-equilibrium preserving method are presented. Both methods are general and can handle an arbitrary equation of state and arbitrary number of species. Unlike existing approaches to discretize the multi-component Euler equations, we do not introduce non conservative updates, overspecified equations, or design for a specific equation of state. The proposed methods are demonstrated on inviscid smooth interface advection problems governed by three equations of state: ideal-gas, stiffened-gas, and van der Waals where we show orders of magnitude reductions in spurious pressure oscillations compared to existing schemes.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04450v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04450v1">üìÑ Download PDF</a></p><hr><h3 id=uncertainty-quantification-of-the-fresh-saltwater-interface-from-time-domain-electromagnetic-datahttpsarxivorgabs251204437v1><a href=https://arxiv.org/abs/2512.04437v1>Uncertainty Quantification of the Fresh-Saltwater Interface from Time-Domain Electromagnetic Data</a><a hidden class=anchor aria-hidden=true href=#uncertainty-quantification-of-the-fresh-saltwater-interface-from-time-domain-electromagnetic-datahttpsarxivorgabs251204437v1>#</a></h3><p><strong>Authors:</strong> Arsalan Ahmed, Thomas Hermans, David Dudal, Wouter Deleersnyder
<strong>Venue:</strong> arXiv (2025)</p><p>Geophysical methods provide a cost-effective way to characterize the subsurface for hydrogeological projects, but they rely on solving an inverse problem. Traditionally, deterministic approaches are used, which face challenges due to non-uniqueness. Stochastic methods offer uncertainty quantification but demand high computational resources. Bayesian Evidential Learning (BEL) bypasses full stochastic inversion by approximating the posterior distribution at lower cost. However, as with Monte Carlo techniques, efficiency depends on the number of inversion parameters. We show that incorporating prior knowledge into parameterization reduces unknowns and computational burden. Using time-domain electromagnetic data, we identify fresh - saltwater interfaces in the Flemish coastal aquifer. Conventional blocky or smooth deterministic inversions often misrepresent this transition zone as too sharp or too gradual. To address this, we parameterize the zone with two variables - depth and thickness - assuming a linear transition. This retains the compactness of parametric inversion while allowing sharp or gradual interfaces like voxel-based methods. To assess reliability, we invert these parameters stochastically using BEL with Thresholding (BEL1D-T). Results indicate this approach effectively captures uncertainty for synthetic and field data. The transition zone remains uncertain due to survey design and inherent non-uniqueness, yet our probabilistic method achieves this without the heavy computational cost of traditional stochastic approaches.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04437v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04437v1">üìÑ Download PDF</a></p><hr><h3 id=toward-enhanced-inertial-sensing-via-dynamically-soft-topological-states-in-piezoelectric-microacoustic-metamaterialshttpsarxivorgabs251204382v1><a href=https://arxiv.org/abs/2512.04382v1>Toward Enhanced Inertial Sensing via Dynamically Soft Topological States in Piezoelectric Microacoustic Metamaterials</a><a hidden class=anchor aria-hidden=true href=#toward-enhanced-inertial-sensing-via-dynamically-soft-topological-states-in-piezoelectric-microacoustic-metamaterialshttpsarxivorgabs251204382v1>#</a></h3><p><strong>Authors:</strong> Onurcan Kaya, Niccolo Scalise Pantuso, Marco Galli, Jacopo M. De Ponti, Tommaso Maggioli, Davide Pavesi, Siddhartha Ghosh, Attilio Frangi, Luca Colombo, Benyamin Davaji, Matteo Rinaldi, David Horsley, Cristian Cassella
<strong>Venue:</strong> arXiv (2025)</p><p>In recent decades, microelectromechanical systems (MEMS)-based gyroscopes have been employed to meet positioning and navigation demands of a plethora of commercially available devices. Most of such gyroscopes rely on electrostatic actuators with nanometer-scale air gaps$\unicode{x2013}$an architecture that enables large particle velocities in a proof mass and, consequently, high Coriolis-force sensitivity to angular velocity$\unicode{x2013}$but is inherently susceptible to damage under shock and vibration. This vulnerability is typically mitigated by purposely reducing gyroscopic sensitivity, thereby compromising readout accuracy. Microacoustic gyroscopes, by contrast, offer greater resilience to shock and vibration but currently exhibit significantly lower sensitivities. This limitation stems from the low dynamic compliance of the modes they employ$\unicode{x2013}$typically Lamb or Rayleigh modes$\unicode{x2013}$which restricts their maximum achievable particle velocity. This work presents a piezoelectric microacoustic device that overcomes this fundamental constraint by harnessing a topological interface state at the boundary between two microscale metamaterial structures. We theoretically and experimentally show that this state exhibits much higher modal compliance than Lamb or Rayleigh modes. This enables record-high particle velocities (>51 m/s) never reached, due to material limits, by any previously demonstrated piezoelectric gyroscope.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04382v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04382v1">üìÑ Download PDF</a></p><hr><h3 id=smartalert-implementing-machine-learning-driven-clinical-decision-support-for-inpatient-lab-utilization-reductionhttpsarxivorgabs251204354v1><a href=https://arxiv.org/abs/2512.04354v1>SmartAlert: Implementing Machine Learning-Driven Clinical Decision Support for Inpatient Lab Utilization Reduction</a><a hidden class=anchor aria-hidden=true href=#smartalert-implementing-machine-learning-driven-clinical-decision-support-for-inpatient-lab-utilization-reductionhttpsarxivorgabs251204354v1>#</a></h3><p><strong>Authors:</strong> April S. Liang, Fatemeh Amrollahi, Yixing Jiang, Conor K. Corbin, Grace Y. E. Kim, David Mui, Trevor Crowell, Aakash Acharya, Sreedevi Mony, Soumya Punnathanam, Jack McKeown, Margaret Smith, Steven Lin, Arnold Milstein, Kevin Schulman, Jason Hom, Michael A. Pfeffer, Tho D. Pham, David Svec, Weihan Chu, Lisa Shieh, Christopher Sharp, Stephen P. Ma, Jonathan H. Chen
<strong>Venue:</strong> arXiv (2025)</p><p>Repetitive laboratory testing unlikely to yield clinically useful information is a common practice that burdens patients and increases healthcare costs. Education and feedback interventions have limited success, while general test ordering restrictions and electronic alerts impede appropriate clinical care. We introduce and evaluate SmartAlert, a machine learning (ML)-driven clinical decision support (CDS) system integrated into the electronic health record that predicts stable laboratory results to reduce unnecessary repeat testing. This case study describes the implementation process, challenges, and lessons learned from deploying SmartAlert targeting complete blood count (CBC) utilization in a randomized controlled pilot across 9270 admissions in eight acute care units across two hospitals between August 15, 2024, and March 15, 2025. Results show significant decrease in number of CBC results within 52 hours of SmartAlert display (1.54 vs 1.82, p &lt;0.01) without adverse effect on secondary safety outcomes, representing a 15% relative reduction in repetitive testing. Implementation lessons learned include interpretation of probabilistic model predictions in clinical contexts, stakeholder engagement to define acceptable model behavior, governance processes for deploying a complex model in a clinical environment, user interface design considerations, alignment with clinical operational priorities, and the value of qualitative feedback from end users. In conclusion, a machine learning-driven CDS system backed by a deliberate implementation and governance process can provide precision guidance on inpatient laboratory testing to safely reduce unnecessary repetitive testing.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04354v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04354v1">üìÑ Download PDF</a></p><hr><h3 id=collective-adsorption-of-pheromones-at-the-water-air-interfacehttpsarxivorgabs251204340v1><a href=https://arxiv.org/abs/2512.04340v1>Collective adsorption of pheromones at the water-air interface</a><a hidden class=anchor aria-hidden=true href=#collective-adsorption-of-pheromones-at-the-water-air-interfacehttpsarxivorgabs251204340v1>#</a></h3><p><strong>Authors:</strong> Ludovic Jami, Bertrand Siboulet, Thomas Zemb, J√©r√¥me Casas, Jean-Fran√ßois Dufr√™che
<strong>Venue:</strong> arXiv (2025)</p><p>Understanding the phase behaviour of pheromones and other messaging molecules remains a significant and largely unexplored challenge, even though it plays a central role in chemical communication. Here, we present all-atom molecular dynamics simulations to investigate the behavior of bombykol, a model insect pheromone, adsorbed at the water-air interface. This system serves as a proxy for studying the amphiphilic nature of pheromones and their interactions with aerosol particles in the atmosphere. Our simulations reveal the molecular organization of the bombykol monolayer and its adsorption isotherm. A soft-sticky particle equation of state accurately describes the monolayer&rsquo;s behavior. The analysis uncovers a two-dimensional liquid-gas phase transition within the monolayer. Collective adsorption stabilises the molecules at the interface and the calculated free energy gain is approximately $2:k_\mathrm{B}T$. This value increases under lower estimates of the condensing surface concentration, thereby enhancing pheromone adsorption onto aerosols. Overall, our findings hold broad relevance for molecular interface science, atmospheric chemistry, and organismal chemical communication, particularly in highlighting the critical role of phase transition phenomena.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04340v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04340v1">üìÑ Download PDF</a></p><hr><h3 id=consentdiff-at-scale-longitudinal-audits-of-web-privacy-policy-changes-and-ui-frictionshttpsarxivorgabs251204316v1><a href=https://arxiv.org/abs/2512.04316v1>ConsentDiff at Scale: Longitudinal Audits of Web Privacy Policy Changes and UI Frictions</a><a hidden class=anchor aria-hidden=true href=#consentdiff-at-scale-longitudinal-audits-of-web-privacy-policy-changes-and-ui-frictionshttpsarxivorgabs251204316v1>#</a></h3><p><strong>Authors:</strong> Haoze Guo
<strong>Venue:</strong> arXiv (2025)</p><p>Web privacy is experienced via two public artifacts: site utterances in policy texts, and the actions users are required to take during consent interfaces. In the extensive cross-section audits we&rsquo;ve studied, there is a lack of longitudinal data detailing how these artifacts are changing together, and if interfaces are actually doing what they promise in policy. ConsentDiff provides that longitudinal view. We build a reproducible pipeline that snapshots sites every month, semantically aligns policy clauses to track clause-level churn, and classifies consent-UI patterns by pulling together DOM signals with cues provided by screenshots. We introduce a novel weighted claim-UI alignment score, connecting common policy claims to observable predicates, and enabling comparisons over time, regions, and verticals. Our measurements suggest continued policy churn, systematic changes to eliminate a higher-friction banner design, and significantly higher alignment where rejecting is visible and lower friction.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04316v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04316v1">üìÑ Download PDF</a></p><hr><h3 id=enhancing-solar-cell-efficiency-of-alxin1-xnsi-heterojunctions-using-an-a-si-buffer-a-study-of-material-interface-and-device-propertieshttpsarxivorgabs251204243v1><a href=https://arxiv.org/abs/2512.04243v1>Enhancing solar cell efficiency of AlxIn1-xN/Si heterojunctions using an a-Si buffer: A study of material, interface and device properties</a><a hidden class=anchor aria-hidden=true href=#enhancing-solar-cell-efficiency-of-alxin1-xnsi-heterojunctions-using-an-a-si-buffer-a-study-of-material-interface-and-device-propertieshttpsarxivorgabs251204243v1>#</a></h3><p><strong>Authors:</strong> M. Sun, R. G. Cornejo, M. de la Mata, S. I. Molina, B. Damilano, S. Valdueza-Felip, F. B. Naranjo
<strong>Venue:</strong> arXiv (2025)</p><p>This study explores the impact of an optimized amorphous silicon (a-Si) buffer layer on AlxIn1-xN-on-Si(100) heterojunction solar cells, with Al content varying from 0% (InN) to 55%. The buffer layer improves the structural quality of the AlInN layer, as evidenced by reduced full width at half maximum values in X-ray diffraction rocking curves around the AlInN (0002) peak. Atomic force microscopy reveals that the buffer layer does not alter surface roughness. The effectiveness of the a-Si buffer is demonstrated by an enhancement of the conversion efficiency under AM1.5G illumination from 3.3 % to 3.9 % for devices with 35 % Al. Looking at the effect of the Al content in devices with the a-Si buffer, the device with 22% Al shows the best photovoltaic performance, with a conversion efficiency of 4.1 % and a VOC of 0.42 V, JSC of 15.4 mA/cm2, and FF of 63.3%. However, performance declines for Al contents above 36% due to increased resistivity and reduced carrier concentration. These findings highlight the critical role of the novel a-Si buffer layer developed by RF-sputtering and the Al content in optimizing AlInN/Si heterojunction solar cell performance.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04243v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04243v1">üìÑ Download PDF</a></p><hr><h3 id=maestro-intelligent-execution-for-quantum-circuit-simulationhttpsarxivorgabs251204216v1><a href=https://arxiv.org/abs/2512.04216v1>Maestro: Intelligent Execution for Quantum Circuit Simulation</a><a hidden class=anchor aria-hidden=true href=#maestro-intelligent-execution-for-quantum-circuit-simulationhttpsarxivorgabs251204216v1>#</a></h3><p><strong>Authors:</strong> Oriol Bertomeu, Hamzah Ghayas, Adrian Roman, Stephen DiAdamo
<strong>Venue:</strong> arXiv (2025)</p><p>Quantum circuit simulation remains essential for developing and validating quantum algorithms, especially as current quantum hardware is limited in scale and quality. However, the growing diversity of simulation methods and software tools creates a high barrier to selecting the most suitable backend for a given circuit. We introduce Maestro, a unified interface for quantum circuit simulation that integrates multiple simulation paradigms - state vector, MPS, tensor network, stabilizer, GPU-accelerated, and p-block methods - under a single API. Maestro includes a predictive runtime model that automatically selects the optimal simulator based on circuit structure and available hardware, and applies backend-specific optimizations such as multiprocessing, GPU execution, and improved sampling. Benchmarks across heterogeneous workloads demonstrate that Maestro outperforms individual simulators in both single-circuit and large batched settings, particularly in high-performance computing environments. Maestro provides a scalable, extensible platform for quantum algorithm research, hybrid quantum-classical workflows, and emerging distributed quantum computing architectures.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04216v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04216v1">üìÑ Download PDF</a></p><hr><h3 id=configurable-antiferromagnetic-domains-and-lateral-exchange-bias-in-atomically-thin-crps4httpsarxivorgabs251204055v1><a href=https://arxiv.org/abs/2512.04055v1>Configurable antiferromagnetic domains and lateral exchange bias in atomically thin CrPS4</a><a hidden class=anchor aria-hidden=true href=#configurable-antiferromagnetic-domains-and-lateral-exchange-bias-in-atomically-thin-crps4httpsarxivorgabs251204055v1>#</a></h3><p><strong>Authors:</strong> Yu-Xuan Wang, Thomas K. M. Graham, Ricardo Rama-Eiroa, Md Ariful Islam, Mohammad H. Badarneh, Rafael Nunes Gontijo, Ganesh Prasad Tiwari, Tibendra Adhikari, Xin-Yue Zhang, Kenji Watanabe, Takashi Taniguchi, Claire Besson, Elton J. G. Santos, Zhong Lin, Brian B. Zhou
<strong>Venue:</strong> arXiv (2025)</p><p>Interfacial exchange coupling between antiferromagnets (AFMs) and ferromagnets (FMs) crucially makes it possible to shift the FM hysteresis, known as exchange bias, and to switch AFM states. Two-dimensional magnets unlock opportunities to combine AFM and FM materials; however, the buried AFM-FM interfaces obtained by stacking remains challenging to understand. Here we demonstrate interfacial control via intralayer exchange coupling in the layered AFM CrPS$_4$, where connected even and odd layers realize pristine lateral interfaces between AFM-like and FM-like regions. We distinguish antiphase even-layer states by scanning nitrogen-vacancy centre (NV) magnetometry due to a weak surface magnetization. This surface magnetization enables control over the even-layer state, with different regions switching at distinct fields due to their own lateral couplings. We toggle three AFM domains adjacent to a FM-like region and demonstrate a tunable multilevel exchange bias. Our nanoscale visualization unveils the microscopic origins of exchange bias and advances single two-dimensional crystals for hybrid AFM-FM technologies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04055v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04055v1">üìÑ Download PDF</a></p><hr><h3 id=affordances-of-digital-and-blockchain-based-community-currencies-the-case-of-sarafu-network-in-kenyahttpsarxivorgabs251204030v1><a href=https://arxiv.org/abs/2512.04030v1>Affordances of Digital and Blockchain-based Community Currencies: The Case of Sarafu Network in Kenya</a><a hidden class=anchor aria-hidden=true href=#affordances-of-digital-and-blockchain-based-community-currencies-the-case-of-sarafu-network-in-kenyahttpsarxivorgabs251204030v1>#</a></h3><p><strong>Authors:</strong> Patricia Marcella Evite
<strong>Venue:</strong> arXiv (2025)</p><p>Community currencies (CCs) have been adopting innovative systems to overcome implementational hurdles from issuing paper currencies. Using a qualitative approach, this paper examined this digital transition of Sarafu Network in Kenya and its predecessor CCs as a case study. From the original vouchers launched in 2010, the foundation Grassroots Economics introduced a digital interface in 2016 that operates on a feature phone, and then integrated blockchain technology starting in 2018, undergoing several migrations before becoming settling on its current iteration called Community Asset Vouchers on the Celo blockchain since 2023. Using affordances from human-computer interaction, the research shows that digitalization and blockchain improved the facilitation of economic activities of the local communities, both their typical market transactions as well as traditional reciprocal labor exchanges, by offering more functionalities compared to the analog version of Sarafu. The unique contributions of blockchain include enabling automation of holding tax calculations and linking the vouchers to the mainstream monetary system via stablecoins facilitated by a series of smart contracts also known as the liquidity pool. The study also finds that there is an inherent trade-off between blockchain benefits and user interface complexity. Hence, balancing innovation and community needs remains a challenge.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04030v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04030v1">üìÑ Download PDF</a></p><hr><h3 id=negative-index-makes-a-perfect-time-domain-lens-generating-slow-playback-of-ultrafast-eventshttpsarxivorgabs251203985v1><a href=https://arxiv.org/abs/2512.03985v1>Negative Index Makes a Perfect Time-Domain Lens, Generating Slow Playback of Ultrafast Events</a><a hidden class=anchor aria-hidden=true href=#negative-index-makes-a-perfect-time-domain-lens-generating-slow-playback-of-ultrafast-eventshttpsarxivorgabs251203985v1>#</a></h3><p><strong>Authors:</strong> Oded Schiller, Yonatan Plotnik, Guy Bartal, Mordechai Segev
<strong>Venue:</strong> arXiv (2025)</p><p>We explore the effects of incorporating negative index materials into the physics of time-varying media and find that changing the refractive index from positive to negative creates a perfect time-reversed wave: a perfect time-domain lens. Unlike other mechanisms of phase conjugation, the perfect time-domain lens time-reverses both the propagating waves and the evanescent part of the spectrum. Moreover, we find that the time-reversed wave can be slowed down or accelerated, depending on the refractive index ratio. We show that this effect remains strong even when the refractive index varies arbitrarily slow, in sharp contradistinction to time-reflection which necessitates large index changes at sub-cycle rates. This is the first avenue found to yield significant negative-frequency waves using a temporal interface without the need for sub-cycle modulation or impedance matching. The effect can be used to record extreme ultrafast information and subsequently play it backwards at a slow rate, and vice-versa.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03985v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03985v1">üìÑ Download PDF</a></p><hr><h3 id=benchmark-for-planning-and-control-with-large-language-model-agents-blocksworld-with-model-context-protocolhttpsarxivorgabs251203955v1><a href=https://arxiv.org/abs/2512.03955v1>Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol</a><a hidden class=anchor aria-hidden=true href=#benchmark-for-planning-and-control-with-large-language-model-agents-blocksworld-with-model-context-protocolhttpsarxivorgabs251203955v1>#</a></h3><p><strong>Authors:</strong> Niklas Jobs, Luis Miguel Vieira da Silva, Jayanth Somashekaraiah, Maximilian Weigand, David Kube, Felix Gehlhoff
<strong>Venue:</strong> arXiv (2025)</p><p>Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark&rsquo;s applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03955v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03955v1">üìÑ Download PDF</a></p><hr><h3 id=modelling-the-impact-of-device-imperfections-on-electron-shuttling-in-simos-deviceshttpsarxivorgabs251203853v1><a href=https://arxiv.org/abs/2512.03853v1>Modelling the Impact of Device Imperfections on Electron Shuttling in SiMOS devices</a><a hidden class=anchor aria-hidden=true href=#modelling-the-impact-of-device-imperfections-on-electron-shuttling-in-simos-deviceshttpsarxivorgabs251203853v1>#</a></h3><p><strong>Authors:</strong> Jack J. Turner, Christian W. Binder, Guido Burkard, Andrew J. Fisher
<strong>Venue:</strong> arXiv (2025)</p><p>Extensive theoretical and experimental work has established high-fidelity electron shuttling in Si/SiGe systems, whereas demonstrations in Si/SiO2 (SiMOS) remain at an early stage. To help address this, we perform full 3D simulations of conveyor-belt charge shuttling in a realistic SiMOS device, building on earlier 2D modelling. We solve the Poisson and time-dependent Schrodinger equations for varying shuttling speeds and gate voltages, focusing on potential pitfalls of typical SiMOS devices such as oxide-interface roughness, gate fabrication imperfections, and charge defects along the transport path. The simulations reveal that for low clavier-gate voltages, the additional oxide screening in multi-layer gate architectures causes conveyor-belt shuttling to collapse to the bucket-brigade mode, inducing considerable orbital excitation in the process. Increasing the confinement restores conveyor-belt operation, which we find to be robust against interface roughness, gate misalignment, and charge defects buried in the oxide. However, our results indicate that defects located at the Si/SiO2-interface can induce considerable orbital excitation. For lower conveyor gate biases, positive defects in the transport channel can even capture passing electrons. Hence we identify key challenges and find operating regimes for reliable charge transport in SiMOS architectures.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03853v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03853v1">üìÑ Download PDF</a></p><hr><h3 id=shell-formation-and-two-dimensional-nanofriction-in-three-dimensional-ion-coulomb-crystalshttpsarxivorgabs251203833v2><a href=https://arxiv.org/abs/2512.03833v2>Shell formation and two-dimensional nanofriction in three-dimensional ion Coulomb crystals</a><a hidden class=anchor aria-hidden=true href=#shell-formation-and-two-dimensional-nanofriction-in-three-dimensional-ion-coulomb-crystalshttpsarxivorgabs251203833v2>#</a></h3><p><strong>Authors:</strong> L. -A. R√ºffert, T. E. Mehlst√§ubler
<strong>Venue:</strong> arXiv (2025)</p><p>Self-organized three-dimensional (3D) ion Coulomb crystals in linear Paul traps naturally form concentric shells that provide a curved, atomically resolved interface for studying two-dimensional (2D) nanofriction. Building on prior work that used 2D ion crystals to investigate one-dimensional (1D) nanofriction and orientational melting, we leverage this foundation to extend friction studies from linear ion chains and planar rings to 3D shell structures. Using molecular-dynamics simulations, we first map shell formation as a function of ion number $N$ and the trapping aspect ratio, yielding a simple relation that can aid ion-number estimation in experiments. We compute a Peierls&ndash;Nabarro-type energy landscape for the rotation of the outer shell against the inner core, showing drastic changes in the effective energy barrier up to a factor of about 60 with only small changes in $N$. Using dynamical simulations, we apply rotational torques to the outer shell of selected systems and show that small changes in $N$ impact the commensurability between shells and can, in some cases, induce a hysteretic response due to torque-induced metastable states. We find that spatially varying coupling to the inner-core corrugation can create coexisting fast and slow moving domains within the rotating outer shell, realizing multidimensional friction where intra-shell shear and inter-shell nanofriction act simultaneously. Our results have implications for stabilizing many-body systems and for the development of ultra-low-friction nanomechanical devices such as ion-based nanorotors and torque sensors.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03833v2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03833v2">üìÑ Download PDF</a></p><hr><h3 id=terahertz-emission-from-interdigitated-photoconductive-antennas-based-on-ge-on-sihttpsarxivorgabs251203820v1><a href=https://arxiv.org/abs/2512.03820v1>Terahertz emission from interdigitated photoconductive antennas based on Ge-on-Si</a><a hidden class=anchor aria-hidden=true href=#terahertz-emission-from-interdigitated-photoconductive-antennas-based-on-ge-on-sihttpsarxivorgabs251203820v1>#</a></h3><p><strong>Authors:</strong> Dhanashree Chemate, Abhishek Singh, Ruturaj Puranik, Utkarsh Pandey, Dipti Gupta, Siddhartha P. Duttagupta, Shriganesh S. Prabhu
<strong>Venue:</strong> arXiv (2025)</p><p>An interdigitated photoconductive antenna (i-PCA) for terahertz (THz) emission with a novel metal-insulator-semiconductor interface is designed with the aim of developing compact and scalable THz devices. The photoconductive material is an amorphous germanium (Ge) film deposited using DC magnetron sputtering. The antenna electrodes are composed of gold-germanium (AuGe). With the integration of a silicon dioxide (SiO2) layer that acts as an electrical mask on alternate active areas, we present a simple approach to fabricate a large-area i-PCA. Along with a simplified fabrication compared to other existing designs, our approach increases the electrical robustness of the emitter and reduces the inactive gap area on the device. The i-PCA is capable of THz emission up to 2.5 THz and 36 dB signal-to-noise ratio (SNR), and is promising for applications in CMOS technologies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03820v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03820v1">üìÑ Download PDF</a></p><hr><h3 id=interfacial-control-of-orbital-occupancy-and-spin-state-in-lacoo_3httpsarxivorgabs251203785v1><a href=https://arxiv.org/abs/2512.03785v1>Interfacial Control of Orbital Occupancy and Spin State in LaCoO$_3$</a><a hidden class=anchor aria-hidden=true href=#interfacial-control-of-orbital-occupancy-and-spin-state-in-lacoo_3httpsarxivorgabs251203785v1>#</a></h3><p><strong>Authors:</strong> Ellen M. Kiens, Nicolas Gauquelin, Arno Annys, Emma van der Minne, Iris C. G. van den Bosch, Matthijs A. van Spronsen, Zezhong Zhang, Annick de Backer, Sandra van Aert, Jo Verbeeck, Gertjan Koster, Bastian Mei, Frank M. F. de Groot, Christoph Baeumer
<strong>Venue:</strong> arXiv (2025)</p><p>Transition metal oxides exhibit a wide range of tunable electronic properties arising from the complex interplay of charge, spin, and lattice degrees of freedom, governed by their $d$ orbital configurations, making them particularly interesting for oxide electronics and (electro)catalysis. Perovskite oxide heterointerfaces offer a promising route to engineer these orbital states. In this work, we tune the Co $3d$ orbital occupancy in LaCoO$_3$ from a partial $d^7$ to a partial $d^5$ state through interfacial engineering with LaTiO$_3$, LaMnO$_3$, LaAlO$_3$ and LaNiO$_3$. Using X-ray absorption spectroscopy combined with charge transfer multiplet calculations, we identify differences in the Co valence and spin state for the series of oxide heterostructures. LaTiO$_3$ and LaMnO$_3$ interfaces result in interfacial charge transfer towards LaCoO$_3$, resulting in a partial $d^7$ orbital occupancy, while a LaNiO$_3$ interface results in a partial Co $d^5$ occupancy. Strikingly, a LaAlO$_3$ spacer layer between LaNiO$_3$ and LaCoO$_3$ results in a Co $d^6$ low spin state. These results indicate that the Co spin state, like the valence state, is governed by the interfacial environment. High-resolution scanning transmission electron microscopy imaging reveals a clear connection between strain and spin configuration, emphasizing the importance of structural control at oxide interfaces. Overall, this work demonstrates that interfacial engineering simultaneously governs orbital occupancy and spin state in correlated oxides, advancing spin-engineering strategies in correlated oxides and offering new insights for the rational design of functional oxide heterostructures.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03785v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03785v1">üìÑ Download PDF</a></p><hr><h3 id=mcp-does-not-stand-for-misuse-cryptography-protocol-uncovering-cryptographic-misuse-in-model-context-protocol-at-scalehttpsarxivorgabs251203775v1><a href=https://arxiv.org/abs/2512.03775v1>&ldquo;MCP Does Not Stand for Misuse Cryptography Protocol&rdquo;: Uncovering Cryptographic Misuse in Model Context Protocol at Scale</a><a hidden class=anchor aria-hidden=true href=#mcp-does-not-stand-for-misuse-cryptography-protocol-uncovering-cryptographic-misuse-in-model-context-protocol-at-scalehttpsarxivorgabs251203775v1>#</a></h3><p><strong>Authors:</strong> Biwei Yan, Yue Zhang, Minghui Xu, Hao Wu, Yechao Zhang, Kun Li, Guoming Zhang, Xiuzhen Cheng
<strong>Venue:</strong> arXiv (2025)</p><p>The Model Context Protocol (MCP) is rapidly emerging as the middleware for LLM-based applications, offering a standardized interface for tool integration. However, its built-in security mechanisms are minimal: while schemas and declarations prevent malformed requests, MCP provides no guarantees of authenticity or confidentiality, forcing developers to implement cryptography themselves. Such ad hoc practices are historically prone to misuse, and within MCP they threaten sensitive data and services. We present MICRYSCOPE, the first domain-specific framework for detecting cryptographic misuses in MCP implementations. MICRYSCOPE combines three key innovations: a cross-language intermediate representation that normalizes cryptographic APIs across diverse ecosystems, a hybrid dependency analysis that uncovers explicit and implicit function relationships (including insecure runtime compositions orchestrated by LLMs) and a taint-based misuse detector that tracks sensitive data flows and flags violations of established cryptographic rules. Applying MICRYSCOPE to 9,403 MCP servers, we identified 720 with cryptographic logic, of which 19.7% exhibited misuses. These flaws are concentrated in certain markets (e.g., Smithery Registry with 42% insecure servers), languages (Python at 34% misuse rate), and categories (Developer Tools and Data Science & ML accounting for over 50% of all misuses). Case studies reveal real-world consequences, including leaked API keys, insecure DES/ECB tools, and MD5-based authentication bypasses. Our study establishes the first ecosystem-wide view of cryptographic misuse in MCP and provides both tools and insights to strengthen the security foundations of this rapidly growing protocol.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03775v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03775v1">üìÑ Download PDF</a></p><hr><h3 id=thinking-with-programming-vision-towards-a-unified-view-for-thinking-with-imageshttpsarxivorgabs251203746v1><a href=https://arxiv.org/abs/2512.03746v1>Thinking with Programming Vision: Towards a Unified View for Thinking with Images</a><a hidden class=anchor aria-hidden=true href=#thinking-with-programming-vision-towards-a-unified-view-for-thinking-with-imageshttpsarxivorgabs251203746v1>#</a></h3><p><strong>Authors:</strong> Zirun Guo, Minjie Hong, Feng Zhang, Kai Jia, Tao Jin
<strong>Venue:</strong> arXiv (2025)</p><p>Multimodal large language models (MLLMs) that think with images can interactively use tools to reason about visual inputs, but current approaches often rely on a narrow set of tools with limited real-world necessity and scalability. In this work, we first reveal a critical and previously overlooked weakness: even state-of-the-art MLLMs are surprisingly brittle, showing significant performance degradation on images with simple orientation changes or natural corruptions, underscoring the need for more robust tool-based reasoning. To address this, we propose CodeVision, a flexible and scalable code-as-tool framework where the model generates code as a universal interface to invoke any image operation, moving beyond fixed tool registries. We train our model using a two-stage methodology, beginning with Supervised Fine-Tuning (SFT) on a high-quality dataset curated for complex, multi-turn tool composition and error recovery, followed by Reinforcement Learning (RL) with a novel and dense process reward function to encourage strategic and efficient tool use. To facilitate this research, we construct new SFT and RL datasets and introduce a challenging new benchmark suite designed to rigorously evaluate robustness to orientation changes and multi-tool reasoning. Experiments on Qwen2.5-VL and Qwen3-VL series show that our approach significantly improves model performance and fosters emergent capabilities such as flexible tool composition, efficient chained execution, and robust error recovery from runtime feedback. Code is available at <a href=https://github.com/ByteDance-BandAI/CodeVision>https://github.com/ByteDance-BandAI/CodeVision</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03746v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03746v1">üìÑ Download PDF</a></p><hr><h3 id=revealing-nanoscale-molecular-organization-in-liquid-crystals-via-cryogenic-atom-probe-tomographhttpsarxivorgabs251203734v1><a href=https://arxiv.org/abs/2512.03734v1>Revealing Nanoscale Molecular Organization in Liquid Crystals via Cryogenic Atom Probe Tomograph</a><a hidden class=anchor aria-hidden=true href=#revealing-nanoscale-molecular-organization-in-liquid-crystals-via-cryogenic-atom-probe-tomographhttpsarxivorgabs251203734v1>#</a></h3><p><strong>Authors:</strong> Kuan Meng, Kang&rsquo;an Wang, Sebastian Eich, Pierre Nacke, Johanna R. Bruckner, Patrick Stender, Frank Giesselmann, Guido Schmitz
<strong>Venue:</strong> arXiv (2025)</p><p>While liquid crystals (LCs) have been extensively studied, obtaining a comprehensive nanoscale picture of their molecular organization remains challenging, as conventional techniques face an intrinsic trade-off between spatial and chemical resolution. Here, cryogenic atom probe tomography (cryo-APT) is introduced as a new analytical approach for LC materials, using 4&rsquo;-Pentyl-4-cyanobiphenyl (5CB) and 4&rsquo;-Octyl-4-cyanobiphenyl (8CB) as representative model compounds. This was enabled by a tailored cryogenic focused ion beam (cryo-FIB) protocol optimized for small organic molecules. The method enables controlled field evaporation of both intact molecules and diagnostic fragments, achieving over 90% molecular retention while preserving four characteristic dissociation patterns. By spatially correlating these fragmentation profiles with the local electric field derived from the tip geometry, we reveal field-directed dissociation pathways of CB molecules. In parallel, the distribution of intact molecular ions enables nanoscale visualization of material structure: we resolve homogeneous mixing of 5CB and 8CB in the nematic phase and directly observe the sub-nanometer crystalline layering in a supercooled 8CB sample, with contrast to the surrounding amorphous matrix suggesting the presence of a solid-liquid interface. This work establishes cryo-APT as a new powerful analytical platform for LC research and reveals its broad potential for application in soft matter systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03734v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03734v1">üìÑ Download PDF</a></p><hr><h3 id=generative-ai-practices-literacy-and-divides-an-empirical-analysis-in-the-italian-contexthttpsarxivorgabs251203671v1><a href=https://arxiv.org/abs/2512.03671v1>Generative AI Practices, Literacy, and Divides: An Empirical Analysis in the Italian Context</a><a hidden class=anchor aria-hidden=true href=#generative-ai-practices-literacy-and-divides-an-empirical-analysis-in-the-italian-contexthttpsarxivorgabs251203671v1>#</a></h3><p><strong>Authors:</strong> Beatrice Savoldi, Giuseppe Attanasio, Olga Gorodetskaya, Marta Marchiori Manerba, Elisa Bassignana, Silvia Casola, Matteo Negri, Tommaso Caselli, Luisa Bentivogli, Alan Ramponi, Arianna Muti, Nicoletta Balbo, Debora Nozza
<strong>Venue:</strong> arXiv (2025)</p><p>The rise of Artificial Intelligence (AI) language technologies, particularly generative AI (GenAI) chatbots accessible via conversational interfaces, is transforming digital interactions. While these tools hold societal promise, they also risk widening digital divides due to uneven adoption and low awareness of their limitations. This study presents the first comprehensive empirical mapping of GenAI adoption, usage patterns, and literacy in Italy, based on newly collected survey data from 1,906 Italian-speaking adults. Our findings reveal widespread adoption for both work and personal use, including sensitive tasks like emotional support and medical advice. Crucially, GenAI is supplanting other technologies to become a primary information source: this trend persists despite low user digital literacy, posing a risk as users struggle to recognize errors or misinformation. Moreover, we identify a significant gender divide &ndash; particularly pronounced in older generations &ndash; where women are half as likely to adopt GenAI and use it less frequently than men. While we find literacy to be a key predictor of adoption, it only partially explains this disparity, suggesting that other barriers are at play. Overall, our data provide granular insights into the multipurpose usage of GenAI, highlighting the dual need for targeted educational initiatives and further investigation into the underlying barriers to equitable participation that competence alone cannot explain.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03671v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03671v1">üìÑ Download PDF</a></p><hr><h3 id=lamp-language-assisted-motion-planning-for-controllable-video-generationhttpsarxivorgabs251203619v1><a href=https://arxiv.org/abs/2512.03619v1>LAMP: Language-Assisted Motion Planning for Controllable Video Generation</a><a hidden class=anchor aria-hidden=true href=#lamp-language-assisted-motion-planning-for-controllable-video-generationhttpsarxivorgabs251203619v1>#</a></h3><p><strong>Authors:</strong> Muhammed Burak Kizil, Enes Sanli, Niloy J. Mitra, Erkut Erdem, Aykut Erdem, Duygu Ceylan
<strong>Venue:</strong> arXiv (2025)</p><p>Video generation has achieved remarkable progress in visual fidelity and controllability, enabling conditioning on text, layout, or motion. Among these, motion control - specifying object dynamics and camera trajectories - is essential for composing complex, cinematic scenes, yet existing interfaces remain limited. We introduce LAMP that leverages large language models (LLMs) as motion planners to translate natural language descriptions into explicit 3D trajectories for dynamic objects and (relatively defined) cameras. LAMP defines a motion domain-specific language (DSL), inspired by cinematography conventions. By harnessing program synthesis capabilities of LLMs, LAMP generates structured motion programs from natural language, which are deterministically mapped to 3D trajectories. We construct a large-scale procedural dataset pairing natural text descriptions with corresponding motion programs and 3D trajectories. Experiments demonstrate LAMP&rsquo;s improved performance in motion controllability and alignment with user intent compared to state-of-the-art alternatives establishing the first framework for generating both object and camera motions directly from natural language specifications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03619v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03619v1">üìÑ Download PDF</a></p><hr><h3 id=hamiltonian-active-matter-in-incompressible-fluid-membraneshttpsarxivorgabs251203609v1><a href=https://arxiv.org/abs/2512.03609v1>Hamiltonian Active Matter in Incompressible Fluid Membranes</a><a hidden class=anchor aria-hidden=true href=#hamiltonian-active-matter-in-incompressible-fluid-membraneshttpsarxivorgabs251203609v1>#</a></h3><p><strong>Authors:</strong> Sneha Krishnan, Rickmoy Samanta
<strong>Venue:</strong> arXiv (2025)</p><p>Active proteins and membrane-bound motors exert force dipole flows along fluid interfaces and lipid bilayers. We develop a unified hydrodynamic and Hamiltonian framework for the interactions of pusher and puller dipoles embedded in an incompressible two-dimensional membrane supported by a shallow viscous subphase. Beginning from the screened Stokes equations of the membrane&ndash;subphase composite, we derive the real-space incompressible Green&rsquo;s tensor, obtain its near- and far-field asymptotics, and construct the resulting dipolar velocity and stream functions. Although generic dipoles reorient under the local membrane vorticity, we show that the far-field dipolar flow is vorticity-free; force-free motors therefore retain fixed orientation and obey a Hamiltonian dynamics in which the positions of $N$ dipoles evolve via an effective Hamiltonian built from the dipolar stream function. In the near field, where the flow possesses finite vorticity, a Hamiltonian formulation is recovered in the quenched-orientation limit. Exploiting this structure, we simulate ensembles of pusher and puller dipoles and compare the dynamics generated by the $1/r$ near-field kernel and the subphase screened $1/r^{3}$ far-field kernel. For identical dipoles, the far-field Hamiltonian produces rapid clustering from random initial conditions, whereas the near-field Hamiltonian suppresses collapse and yields extended, non-aggregating configurations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03609v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03609v1">üìÑ Download PDF</a></p><hr><h3 id=a-convolutional-framework-for-mapping-imagined-auditory-meg-into-listened-brain-responseshttpsarxivorgabs251203458v1><a href=https://arxiv.org/abs/2512.03458v1>A Convolutional Framework for Mapping Imagined Auditory MEG into Listened Brain Responses</a><a hidden class=anchor aria-hidden=true href=#a-convolutional-framework-for-mapping-imagined-auditory-meg-into-listened-brain-responseshttpsarxivorgabs251203458v1>#</a></h3><p><strong>Authors:</strong> Maryam Maghsoudi, Mohsen Rezaeizadeh, Shihab Shamma
<strong>Venue:</strong> arXiv (2025)</p><p>Decoding imagined speech engages complex neural processes that are difficult to interpret due to uncertainty in timing and the limited availability of imagined-response datasets. In this study, we present a Magnetoencephalography (MEG) dataset collected from trained musicians as they imagined and listened to musical and poetic stimuli. We show that both imagined and perceived brain responses contain consistent, condition-specific information. Using a sliding-window ridge regression model, we first mapped imagined responses to listened responses at the single-subject level, but found limited generalization across subjects. At the group level, we developed an encoder-decoder convolutional neural network with a subject-specific calibration layer that produced stable and generalizable mappings. The CNN consistently outperformed the null model, yielding significantly higher correlations between predicted and true listened responses for nearly all held-out subjects. Our findings demonstrate that imagined neural activity can be transformed into perception-like responses, providing a foundation for future brain-computer interface applications involving imagined speech and music.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03458v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03458v1">üìÑ Download PDF</a></p><hr><h3 id=enterprise-data-science-platform-a-unified-architecture-for-federated-data-accesshttpsarxivorgabs251203401v1><a href=https://arxiv.org/abs/2512.03401v1>Enterprise Data Science Platform: A Unified Architecture for Federated Data Access</a><a hidden class=anchor aria-hidden=true href=#enterprise-data-science-platform-a-unified-architecture-for-federated-data-accesshttpsarxivorgabs251203401v1>#</a></h3><p><strong>Authors:</strong> Ryoto Miyamoto, Akira Kasuga
<strong>Venue:</strong> arXiv (2025)</p><p>Organizations struggle to share data across departments that have adopted different data analytics platforms. If n datasets must serve m environments, up to n*m replicas can emerge, increasing inconsistency and cost. Traditional warehouses copy data into vendor-specific stores; cross-platform access is hard. This study proposes the Enterprise Data Science Platform (EDSP), which builds on data lakehouse architecture and follows a Write-Once, Read-Anywhere principle. EDSP enables federated data access for multi-query engine environments, targeting data science workloads with periodic data updates and query response times ranging from seconds to minutes. By providing centralized data management with federated access from multiple query engines to the same data sources, EDSP eliminates data duplication and vendor lock-in inherent in traditional data warehouses. The platform employs a four-layer architecture: Data Preparation, Data Store, Access Interface, and Query Engines. This design enforces separation of concerns and reduces the need for data migration when integrating additional analytical environments. Experimental results demonstrate that major cloud data warehouses and programming environments can directly query EDSP-managed datasets. We implemented and deployed EDSP in production, confirming interoperability across multiple query engines. For data sharing across different analytical environments, EDSP achieves a 33-44% reduction in operational steps compared with conventional approaches requiring data migration. Although query latency may increase by up to a factor of 2.6 compared with native tables, end-to-end completion times remain on the order of seconds, maintaining practical performance for analytical use cases. Based on our production experience, EDSP provides practical design guidelines for addressing the data-silo problem in multi-query engine environments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03401v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03401v1">üìÑ Download PDF</a></p><hr><h3 id=push-broom-mapping-of-galaxies-and-supernova-remnants-with-the-sprite-cubesathttpsarxivorgabs251203329v1><a href=https://arxiv.org/abs/2512.03329v1>Push-broom Mapping of Galaxies and Supernova Remnants with the SPRITE CubeSat</a><a hidden class=anchor aria-hidden=true href=#push-broom-mapping-of-galaxies-and-supernova-remnants-with-the-sprite-cubesathttpsarxivorgabs251203329v1>#</a></h3><p><strong>Authors:</strong> Elena Carlson, Brian Fleming, Yi Hang Valerie Wong, Briana Indahl, Dmitry Vorobiev, Maitland Bowen, Donal O&rsquo;Sullivan, Kevin France, Anne Jaskot, Jason Tumlinson, Sanchayeeta Borthakur, Michael Rutkowski, Stephan McCandliss, Ravi Sankrit, John M. O&rsquo;Meara
<strong>Venue:</strong> arXiv (2025)</p><p>Supernovae (SNe) enrich and energize the surrounding interstellar medium (ISM) and are a key mechanism in the galaxy feedback cycle. The heating of the ISM by supernova shocks, and its subsequent cooling is critical to future star formation. The cooling of the diffuse shock-heated ISM is dominated by ultraviolet (UV) emission lines. These cooling regions and interfaces have complex spatial structure on sub-parsec scales. Mapping this cooling process is essential to understanding the feedback cycle of galaxies, a major goal of the 2020 Astrophysics Decadal Survey. The Supernova remnants and Proxies for ReIonization Testbed Experiment (SPRITE) CubeSat Mission will house the first long-slit orbital spectrograph with sub-arcminute angular resolution covering far ultraviolet wavelengths (FUV; 1000 - 1750 angstroms) and access to the Lyman UV (lambda &lt; 1216 angstroms). SPRITE aims to provide new insights into the stellar feedback that drives galaxy evolution by mapping key FUV emission lines at the interaction lines between supernova remnants (SNRs) and the ambient interstellar medium (ISM). SPRITE will also measure the ionizing escape from approximately 50 low-redshift (0.16 &lt; z &lt; 0.4) star-forming galaxies. Current models predict SPRITE capable of detecting strong O VI, O IV], and C IV emission lines with angular resolution from 10 - 20 arcseconds. The SPRITE SNR survey will use push-broom mapping of its long-slit on extended sources to produce the first large sample of sub-arcminute 3D data cubes of extended sources in the FUV. In this paper, we present simulated SPRITE observations of Large Magellanic Cloud (LMC) SNRs to demonstrate the efficacy of the SPRITE instrument ahead of launch and instrument commissioning. These models serve as critical planning tools and incorporate the final pre-flight predicted performance of the instrument and the early extended source data reduction pipeline.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03329v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03329v1">üìÑ Download PDF</a></p><hr><h3 id=dawzy-a-new-addition-to-ai-powered-human-in-the-loop-music-co-creationhttpsarxivorgabs251203289v1><a href=https://arxiv.org/abs/2512.03289v1>DAWZY: A New Addition to AI powered &ldquo;Human in the Loop&rdquo; Music Co-creation</a><a hidden class=anchor aria-hidden=true href=#dawzy-a-new-addition-to-ai-powered-human-in-the-loop-music-co-creationhttpsarxivorgabs251203289v1>#</a></h3><p><strong>Authors:</strong> Aaron C Elkins, Sanchit Singh, Adrian Kieback, Sawyer Blankenship, Uyiosa Philip Amadasun, Aman Chadha
<strong>Venue:</strong> arXiv (2025)</p><p>Digital Audio Workstations (DAWs) offer fine control, but mapping high-level intent (e.g., &ldquo;warm the vocals&rdquo;) to low-level edits breaks creative flow. Existing artificial intelligence (AI) music generators are typically one-shot, limiting opportunities for iterative development and human contribution. We present DAWZY, an open-source assistant that turns natural-language (text/voice/hum) requests into reversible actions in REAPER. DAWZY keeps the DAW as the creative hub with a minimal GUI and voice-first interface. DAWZY uses LLM-based code generation as a novel way to significantly reduce the time users spend familiarizing themselves with large interfaces, replacing hundreds of buttons and drop-downs with a chat box. DAWZY also uses three Model Context Protocol tools for live state queries, parameter adjustment, and AI beat generation. It maintains grounding by refreshing state before mutation and ensures safety and reversibility with atomic scripts and undo. In evaluations, DAWZY performed reliably on common production tasks and was rated positively by users across Usability, Control, Learning, Collaboration, and Enjoyment.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03289v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03289v1">üìÑ Download PDF</a></p><hr><h3 id=tunable-thin-elasto-dropshttpsarxivorgabs251203218v1><a href=https://arxiv.org/abs/2512.03218v1>Tunable Thin Elasto-Drops</a><a hidden class=anchor aria-hidden=true href=#tunable-thin-elasto-dropshttpsarxivorgabs251203218v1>#</a></h3><p><strong>Authors:</strong> Antonin Eddi, St√©phane Perrard, Jishen Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>We present an experimental method to fabricate centimetric thin elastic capsules with highly uniform thickness and negligible bending stiffness using silicone elastomers. In our experiments, the capsules thickness is tunable at fabrication, while internal pressure and hoop (circumferential) stress are adjustable via hydrostatic inflation once the capsules are filled and immersed in water. Capsules mechanics are probed through hydro-elastic waves generated by weak mechanical perturbations at the capsule interface. By analyzing the surface wave dynamics in the Fourier domain, we extract the in-plane stress and demonstrate that the hydro-elastic waves are exclusively governed by hoop stress. This establishes a direct analogy with liquid drops characterised by an effective surface tension, allowing the capsules to be modeled as large-scale &ldquo;elasto-drops&rdquo; with an inflation and thickness tunable effective surface tension. Our work demonstrates that elasto-drops serve as a robust model system for parametric studies of large-scale liquid drops with experimentally adjustable surface tension.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03218v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03218v1">üìÑ Download PDF</a></p><hr><h3 id=digital-alloy-based-bragg-mirrors-in-high-q-microcavities-for-polariton-lasinghttpsarxivorgabs251203203v1><a href=https://arxiv.org/abs/2512.03203v1>Digital-Alloy-Based Bragg Mirrors in High-Q Microcavities for Polariton Lasing</a><a hidden class=anchor aria-hidden=true href=#digital-alloy-based-bragg-mirrors-in-high-q-microcavities-for-polariton-lasinghttpsarxivorgabs251203203v1>#</a></h3><p><strong>Authors:</strong> V. A. Stolyarov, A. S. Kurdyubov, A. V. Trifonov, M. Yu. Petrov, I. V. Ignatiev, V. A. Lovtcius, S. A. Eliseev, Yu. P. Efimov, M. S. Lozhkin, A. V. Kavokin
<strong>Venue:</strong> arXiv (2025)</p><p>We present an approach to the molecular-beam epitaxy of high-Q planar GaAs-based microcavities in which the AlGaAs high-index layers of the distributed Bragg reflectors (DBRs) are replaced by short-period GaAs/AlAs superlattices (digital alloys) with similar optical properties. This design enables a significant reduction of interface roughness, precise control of the quarter-wavelength optical thickness and the effective Al content, suppression of the propagation of structural defects, and efficient tuning of intrinsic absorption at the polariton emission wavelength via optimization of the superlattice parameters.
Using this approach, we fabricate a microcavity with a low polariton-lasing threshold of approximately 200 W/cm$^2$ and a high experimental quality factor of about 5.4 x $10^4$. This value exceeds by almost a factor of two the theoretical estimate obtained within an equivalent ternary-alloy model. We demonstrate that accurate modeling of the stop-band characteristics and the Q factor requires incorporating the modified electronic density of states in the superlattice, including quantum-confinement and excitonic effects.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03203v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03203v1">üìÑ Download PDF</a></p><hr><h3 id=interfacial-thermal-conductance-between-a-polyethylene-glycol-polymer-chain-and-water-a-molecular-dynamics-studyhttpsarxivorgabs251203174v1><a href=https://arxiv.org/abs/2512.03174v1>Interfacial Thermal Conductance Between a Polyethylene Glycol Polymer Chain and Water: A Molecular Dynamics Study</a><a hidden class=anchor aria-hidden=true href=#interfacial-thermal-conductance-between-a-polyethylene-glycol-polymer-chain-and-water-a-molecular-dynamics-studyhttpsarxivorgabs251203174v1>#</a></h3><p><strong>Authors:</strong> Shadi Babaei, Yekta Cheraghali, Claire Loison, Ali Rajabpour, Samy Merabia
<strong>Venue:</strong> arXiv (2025)</p><p>Understanding interfacial heat transfer between polymers and water is crucial for the design of biomaterials, drug delivery platforms, and nanofluidic systems. In this study, we employed all atom molecular dynamics (MD) simulations to quantify the interfacial thermal conductance between a polyethylene glycol (PEG) 36mer chain and explicit water over the temperature range of 280-350 K. To compare the conformational behavior of the PEG chain, we examined its radius of gyration and observed a temperature dependent chain collapse consistent with previous coarse grained models. By employing a transient non equilibrium MD approach, we imposed temperature difference across the interface and analyzed the energy relaxation behavior to compute heat transfer across the polymer water interfaces. Our results demonstrate that both temperature and interfacial interaction strength influence interfacial thermal conductance, with temperature playing the dominant role. Structural factors such as chain conformation and interfacial area were found to mediate the effect of interfacial interaction. Additional analysis of the vibrational density of states (VDOS) and the mean square displacement (MSD) reveal that vibrational coupling has minimal impact on thermal conductance across interfaces, whereas increased water thermal motion enhances energy transfer. These findings highlight the structural and dynamical origins of interfacial thermal conductance and provide atomistic insights into the tuning of interfacial heat transport in molecular systems through temperature and solvent interactions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03174v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03174v1">üìÑ Download PDF</a></p><hr><h3 id=energy-reflection-and-transmission-of-interfaces-in-tbart-deformed-cfthttpsarxivorgabs251203167v1><a href=https://arxiv.org/abs/2512.03167v1>Energy Reflection and Transmission of Interfaces in $T\bar{T}$-deformed CFT</a><a hidden class=anchor aria-hidden=true href=#energy-reflection-and-transmission-of-interfaces-in-tbart-deformed-cfthttpsarxivorgabs251203167v1>#</a></h3><p><strong>Authors:</strong> Avik Banerjee, Giuseppe Policastro
<strong>Venue:</strong> arXiv (2025)</p><p>Conformal interfaces gluing a pair of two-dimensional conformal field theories enjoy a large degree of universality in terms of the coefficients of reflection and transmission of energy, that describe the scattering of conformal matter at the interface. In this article, we study these coefficients beyond conformality, by gluing a pair of $T\bar T$-deformed 2D CFTs across an interface, which requires the condition $c_L Œº_L = c_R Œº_R $ to be obeyed. We show that, at least when the interface admits a holographic description, the $T\bar T$ deformation of the CFTs can be extended to the interface. We propose a generalization of the linear matching condition in the universal sector of the undeformed ICFT to a non-linear one, which is captured by a universal antisymmetric \emph{transmission function} of the incoming fluxes. We employ the flow equations of the $T\bar T$-deformed CFTs to compute this function in two special classes of states, namely the non-equilibrium steady state (NESS) and scattering state. We show that the results can also be reproduced using holographic techniques in the bulk dual of these states.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03167v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03167v1">üìÑ Download PDF</a></p><hr><h3 id=a-wind-driven-origin-for-the-firework-morphology-of-the-supernova-remnant-pa-30httpsarxivorgabs251203140v1><a href=https://arxiv.org/abs/2512.03140v1>A Wind-Driven Origin for the Firework Morphology of the Supernova Remnant Pa 30</a><a hidden class=anchor aria-hidden=true href=#a-wind-driven-origin-for-the-firework-morphology-of-the-supernova-remnant-pa-30httpsarxivorgabs251203140v1>#</a></h3><p><strong>Authors:</strong> Eric R. Coughlin, Greg Salvesen, Dheeraj R. Pasham
<strong>Venue:</strong> arXiv (2025)</p><p>Pa 30 &ndash; the likely remnant of the Galactic type Iax supernova of 1181 AD &ndash; displays an unusual, firework-like morphology, consisting of radial filaments extending from a common center, where a white dwarf (WD) currently drives a very fast wind (speed $\gtrsim 10^{4}$ km s$^{-1}$). We propose the filaments arose from the Rayleigh-Taylor-unstable nature of the interface between the circumstellar medium (CSM) and the shocked wind launched by the natal WD; the filaments then elongated intact due to the Kelvin-Helmholtz-stable nature of the large initial density contrast between the wind and CSM, supplemented by the slowly declining wind density profile (relative to homologously expanding ejecta). To support this interpretation, we present two-dimensional hydrodynamical simulations and derive the filament properties, including their speed, density, and temperature, all of which are consistent with observations. We suggest the filaments elongate until the wind and CSM densities become comparable at the contact discontinuity, which occurs within 1&ndash;10 years, and then truncate because the RTI halts. The subsequent KHI growth timescale across the current width of the filaments is longer than the age of Pa 30, so they remain intact. The filament-less central region in Pa 30 is therefore more likely a consequence of the finite timescale over which the RTI operates, rather than a wind termination shock. In general, firework-like filaments may form in other systems, provided there is a sufficiently large density contrast between the ejecta and its surroundings.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03140v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03140v1">üìÑ Download PDF</a></p><hr><h2 id=-data_resources>üîç data_resources<a hidden class=anchor aria-hidden=true href=#-data_resources>#</a></h2><h3 id=configuration-defects-in-kuberneteshttpsarxivorgabs251205062v1><a href=https://arxiv.org/abs/2512.05062v1>Configuration Defects in Kubernetes</a><a hidden class=anchor aria-hidden=true href=#configuration-defects-in-kuberneteshttpsarxivorgabs251205062v1>#</a></h3><p><strong>Authors:</strong> Yue Zhang, Uchswas Paul, Marcelo d&rsquo;Amorim, Akond Rahman
<strong>Venue:</strong> arXiv (2025)</p><p>Kubernetes is a tool that facilitates rapid deployment of software. Unfortunately, configuring Kubernetes is prone to errors. Configuration defects are not uncommon and can result in serious consequences. This paper reports an empirical study about configuration defects in Kubernetes with the goal of helping practitioners detect and prevent these defects. We study 719 defects that we extract from 2,260 Kubernetes configuration scripts using open source repositories. Using qualitative analysis, we identify 15 categories of defects. We find 8 publicly available static analysis tools to be capable of detecting 8 of the 15 defect categories. We find that the highest precision and recall of those tools are for defects related to data fields. We develop a linter to detect two categories of defects that cause serious consequences, which none of the studied tools are able to detect. Our linter revealed 26 previously-unknown defects that have been confirmed by practitioners, 19 of which have already been fixed. We conclude our paper by providing recommendations on how defect detection and repair techniques can be used for Kubernetes configuration scripts. The datasets and source code used for the paper are publicly available online.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05062v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05062v1">üìÑ Download PDF</a></p><hr><h3 id=reflexflow-rethinking-learning-objective-for-exposure-bias-alleviation-in-flow-matchinghttpsarxivorgabs251204904v1><a href=https://arxiv.org/abs/2512.04904v1>ReflexFlow: Rethinking Learning Objective for Exposure Bias Alleviation in Flow Matching</a><a hidden class=anchor aria-hidden=true href=#reflexflow-rethinking-learning-objective-for-exposure-bias-alleviation-in-flow-matchinghttpsarxivorgabs251204904v1>#</a></h3><p><strong>Authors:</strong> Guanbo Huang, Jingjia Mao, Fanding Huang, Fengkai Liu, Xiangyang Luo, Yaoyuan Liang, Jiasheng Lu, Xiaoe Wang, Pei Liu, Ruiliu Fu, Shao-Lun Huang
<strong>Venue:</strong> arXiv (2025)</p><p>Despite tremendous recent progress, Flow Matching methods still suffer from exposure bias due to discrepancies in training and inference. This paper investigates the root causes of exposure bias in Flow Matching, including: (1) the model lacks generalization to biased inputs during training, and (2) insufficient low-frequency content captured during early denoising, leading to accumulated bias. Based on these insights, we propose ReflexFlow, a simple and effective reflexive refinement of the Flow Matching learning objective that dynamically corrects exposure bias. ReflexFlow consists of two components: (1) Anti-Drift Rectification (ADR), which reflexively adjusts prediction targets for biased inputs utilizing a redesigned loss under training-time scheduled sampling; and (2) Frequency Compensation (FC), which reflects on missing low-frequency components and compensates them by reweighting the loss using exposure bias. ReflexFlow is model-agnostic, compatible with all Flow Matching frameworks, and improves generation quality across datasets. Experiments on CIFAR-10, CelebA-64, and ImageNet-256 show that ReflexFlow outperforms prior approaches in mitigating exposure bias, achieving a 35.65% reduction in FID on CelebA-64.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04904v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04904v1">üìÑ Download PDF</a></p><hr><h3 id=equivariant-symmetry-aware-head-pose-estimation-for-fetal-mrihttpsarxivorgabs251204890v1><a href=https://arxiv.org/abs/2512.04890v1>Equivariant Symmetry-Aware Head Pose Estimation for Fetal MRI</a><a hidden class=anchor aria-hidden=true href=#equivariant-symmetry-aware-head-pose-estimation-for-fetal-mrihttpsarxivorgabs251204890v1>#</a></h3><p><strong>Authors:</strong> Ramya Muthukrishnan, Borjan Gagoski, Aryn Lee, P. Ellen Grant, Elfar Adalsteinsson, Polina Golland, Benjamin Billot
<strong>Venue:</strong> arXiv (2025)</p><p>We present E(3)-Pose, a novel fast pose estimation method that jointly and explicitly models rotation equivariance and object symmetry. Our work is motivated by the challenging problem of accounting for fetal head motion during a diagnostic MRI scan. We aim to enable automatic adaptive prescription of 2D diagnostic MRI slices with 6-DoF head pose estimation, supported by 3D MRI volumes rapidly acquired before each 2D slice. Existing methods struggle to generalize to clinical volumes, due to pose ambiguities induced by inherent anatomical symmetries, as well as low resolution, noise, and artifacts. In contrast, E(3)-Pose captures anatomical symmetries and rigid pose equivariance by construction, and yields robust estimates of the fetal head pose. Our experiments on publicly available and representative clinical fetal MRI datasets demonstrate the superior robustness and generalization of our method across domains. Crucially, E(3)-Pose achieves state-of-the-art accuracy on clinical MRI volumes, paving the way for clinical translation. Our implementation is available at github.com/ramyamut/E3-Pose.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04890v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04890v1">üìÑ Download PDF</a></p><hr><h3 id=contact-aware-refinement-of-human-pose-pseudo-ground-truth-via-bioimpedance-sensinghttpsarxivorgabs251204862v1><a href=https://arxiv.org/abs/2512.04862v1>Contact-Aware Refinement of Human Pose Pseudo-Ground Truth via Bioimpedance Sensing</a><a hidden class=anchor aria-hidden=true href=#contact-aware-refinement-of-human-pose-pseudo-ground-truth-via-bioimpedance-sensinghttpsarxivorgabs251204862v1>#</a></h3><p><strong>Authors:</strong> Maria-Paola Forte, Nikos Athanasiou, Giulia Ballardini, Jan Ulrich Bartels, Katherine J. Kuchenbecker, Michael J. Black
<strong>Venue:</strong> arXiv (2025)</p><p>Capturing accurate 3D human pose in the wild would provide valuable data for training pose estimation and motion generation methods. While video-based estimation approaches have become increasingly accurate, they often fail in common scenarios involving self-contact, such as a hand touching the face. In contrast, wearable bioimpedance sensing can cheaply and unobtrusively measure ground-truth skin-to-skin contact. Consequently, we propose a novel framework that combines visual pose estimators with bioimpedance sensing to capture the 3D pose of people by taking self-contact into account. Our method, BioTUCH, initializes the pose using an off-the-shelf estimator and introduces contact-aware pose optimization during measured self-contact: reprojection error and deviations from the input estimate are minimized while enforcing vertex proximity constraints. We validate our approach using a new dataset of synchronized RGB video, bioimpedance measurements, and 3D motion capture. Testing with three input pose estimators, we demonstrate an average of 11.7% improvement in reconstruction accuracy. We also present a miniature wearable bioimpedance sensor that enables efficient large-scale collection of contact-aware training data for improving pose estimation and generation using BioTUCH. Code and data are available at biotuch.is.tue.mpg.de</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04862v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04862v1">üìÑ Download PDF</a></p><hr><h3 id=freegen-feed-forward-reconstruction-generation-co-training-for-free-viewpoint-driving-scene-synthesishttpsarxivorgabs251204830v1><a href=https://arxiv.org/abs/2512.04830v1>FreeGen: Feed-Forward Reconstruction-Generation Co-Training for Free-Viewpoint Driving Scene Synthesis</a><a hidden class=anchor aria-hidden=true href=#freegen-feed-forward-reconstruction-generation-co-training-for-free-viewpoint-driving-scene-synthesishttpsarxivorgabs251204830v1>#</a></h3><p><strong>Authors:</strong> Shijie Chen, Peixi Peng
<strong>Venue:</strong> arXiv (2025)</p><p>Closed-loop simulation and scalable pre-training for autonomous driving require synthesizing free-viewpoint driving scenes. However, existing datasets and generative pipelines rarely provide consistent off-trajectory observations, limiting large-scale evaluation and training. While recent generative models demonstrate strong visual realism, they struggle to jointly achieve interpolation consistency and extrapolation realism without per-scene optimization. To address this, we propose FreeGen, a feed-forward reconstruction-generation co-training framework for free-viewpoint driving scene synthesis. The reconstruction model provides stable geometric representations to ensure interpolation consistency, while the generation model performs geometry-aware enhancement to improve realism at unseen viewpoints. Through co-training, generative priors are distilled into the reconstruction model to improve off-trajectory rendering, and the refined geometry in turn offers stronger structural guidance for generation. Experiments demonstrate that FreeGen achieves state-of-the-art performance for free-viewpoint driving scene synthesis.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04830v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04830v1">üìÑ Download PDF</a></p><hr><h3 id=move-a-simple-motion-based-data-collection-paradigm-for-spatial-generalization-in-robotic-manipulationhttpsarxivorgabs251204813v1><a href=https://arxiv.org/abs/2512.04813v1>MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation</a><a hidden class=anchor aria-hidden=true href=#move-a-simple-motion-based-data-collection-paradigm-for-spatial-generalization-in-robotic-manipulationhttpsarxivorgabs251204813v1>#</a></h3><p><strong>Authors:</strong> Huanqian Wang, Chi Bene Chen, Yang Yue, Danhua Tao, Tong Guo, Shaoxuan Xie, Denghang Huang, Shiji Song, Guocai Yao, Gao Huang
<strong>Venue:</strong> arXiv (2025)</p><p>Imitation learning method has shown immense promise for robotic manipulation, yet its practical deployment is fundamentally constrained by the data scarcity. Despite prior work on collecting large-scale datasets, there still remains a significant gap to robust spatial generalization. We identify a key limitation: individual trajectories, regardless of their length, are typically collected from a \emph{single, static spatial configuration} of the environment. This includes fixed object and target spatial positions as well as unchanging camera viewpoints, which significantly restricts the diversity of spatial information available for learning. To address this critical bottleneck in data efficiency, we propose \textbf{MOtion-Based Variability Enhancement} (\emph{MOVE}), a simple yet effective data collection paradigm that enables the acquisition of richer spatial information from dynamic demonstrations. Our core contribution is an augmentation strategy that injects motion into any movable objects within the environment for each demonstration. This process implicitly generates a dense and diverse set of spatial configurations within a single trajectory. We conduct extensive experiments in both simulation and real-world environments to validate our approach. For example, in simulation tasks requiring strong spatial generalization, \emph{MOVE} achieves an average success rate of 39.1%, a 76.1% relative improvement over the static data collection paradigm (22.2%), and yields up to 2&ndash;5$\times$ gains in data efficiency on certain tasks. Our code is available at <a href=https://github.com/lucywang720/MOVE>https://github.com/lucywang720/MOVE</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04813v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04813v1">üìÑ Download PDF</a></p><hr><h3 id=towards-predicting-binaural-audio-quality-in-listeners-with-normal-and-impaired-hearinghttpsarxivorgabs251204792v1><a href=https://arxiv.org/abs/2512.04792v1>Towards predicting binaural audio quality in listeners with normal and impaired hearing</a><a hidden class=anchor aria-hidden=true href=#towards-predicting-binaural-audio-quality-in-listeners-with-normal-and-impaired-hearinghttpsarxivorgabs251204792v1>#</a></h3><p><strong>Authors:</strong> Thomas Biberger, Stephan D. Ewert
<strong>Venue:</strong> arXiv (2025)</p><p>Eurich et al. (2024) recently introduced the computationally efficient monaural and binaural audio quality model (eMoBi-Q). This model integrates both monaural and binaural auditory features and has been validated across six audio datasets encompassing quality ratings for music and speech, processed via algorithms commonly employed in modern hearing devices (e.g., acoustic transparency, feedback cancellation, and binaural beamforming) or presented via loudspeakers. In the current study, we expand eMoBi-Q to account for perceptual effects of sensorineural hearing loss (HL) on audio quality. For this, the model was extended by a nonlinear auditory filterbank. Given that altered loudness perception is a prevalent issue among listeners with hearing impairment, our goal is to incorporate loudness as a sub-dimension for predicting audio quality in both normal-hearing and hearing-impaired populations. While predicting loudness itself is important in the context of loudness-based hearing aid fitting, loudness as audio quality sub-measure may be helpful for the selection of reliable auditory features in hearing impaired listeners. The parameters of the filterbank and subsequent processing stages were informed by the physiologically-based (binaural) loudness model proposed by Pieper et al. (2018). This study presents and discusses the initial implementation of the extended binaural quality model.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04792v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04792v1">üìÑ Download PDF</a></p><hr><h3 id=sarcasm-detection-on-reddit-using-classical-machine-learning-and-feature-engineeringhttpsarxivorgabs251204396v1><a href=https://arxiv.org/abs/2512.04396v1>Sarcasm Detection on Reddit Using Classical Machine Learning and Feature Engineering</a><a hidden class=anchor aria-hidden=true href=#sarcasm-detection-on-reddit-using-classical-machine-learning-and-feature-engineeringhttpsarxivorgabs251204396v1>#</a></h3><p><strong>Authors:</strong> Subrata Karmaker
<strong>Venue:</strong> arXiv (2025)</p><p>Sarcasm is common in online discussions, yet difficult for machines to identify because the intended meaning often contradicts the literal wording. In this work, I study sarcasm detection using only classical machine learning methods and explicit feature engineering, without relying on neural networks or context from parent comments. Using a 100,000-comment subsample of the Self-Annotated Reddit Corpus (SARC 2.0), I combine word-level and character-level TF-IDF features with simple stylistic indicators. Four models are evaluated: logistic regression, a linear SVM, multinomial Naive Bayes, and a random forest. Naive Bayes and logistic regression perform the strongest, achieving F1-scores around 0.57 for sarcastic comments. Although the lack of conversational context limits performance, the results offer a clear and reproducible baseline for sarcasm detection using lightweight and interpretable methods.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04396v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04396v1">üìÑ Download PDF</a></p><hr><h3 id=tempr1-improving-temporal-understanding-of-mllms-via-temporal-aware-multi-task-reinforcement-learninghttpsarxivorgabs251203963v2><a href=https://arxiv.org/abs/2512.03963v2>TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning</a><a hidden class=anchor aria-hidden=true href=#tempr1-improving-temporal-understanding-of-mllms-via-temporal-aware-multi-task-reinforcement-learninghttpsarxivorgabs251203963v2>#</a></h3><p><strong>Authors:</strong> Tao Wu, Li Yang, Gen Zhan, Yabin Zhang, Yiting Liao, Junlin Li, Deliang Fu, Li Zhang, Limin Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Enhancing the temporal understanding of Multimodal Large Language Models (MLLMs) is essential for advancing long-form video analysis, enabling tasks such as temporal localization, action detection, and time-sensitive question answering. While reinforcement learning (RL) has recently been explored for improving temporal reasoning, existing approaches are often confined to limited task types and data, restricting their generalization across diverse temporal understanding scenarios. To address this challenge, we present TempR1, a temporal-aware multi-task reinforcement learning framework that systematically strengthens MLLMs&rsquo; temporal comprehension. We curate a multi-task corpus that exposes the model to diverse temporal structures and semantics, and build upon the Group Relative Policy Optimization (GRPO) algorithm to achieve stable and effective cross-task optimization. Specifically, we categorize temporal tasks into three correspondence types between predicted intervals and ground-truth instances, and design tailored localization rewards for each, enabling TempR1 to capture fine-grained temporal dependencies and adapt to different temporal patterns. Extensive experiments demonstrate that TempR1 attains state-of-the-art performance across multiple benchmarks. Moreover, its joint optimization over complementary tasks yields a strong synergistic effect, enhancing both generalization and single-task performance, establishing a scalable and principled paradigm for temporal reasoning in MLLMs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03963v2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03963v2">üìÑ Download PDF</a></p><hr><h3 id=state-space-models-for-bioacoustics-a-comparative-evaluation-with-transformershttpsarxivorgabs251203563v1><a href=https://arxiv.org/abs/2512.03563v1>State Space Models for Bioacoustics: A comparative Evaluation with Transformers</a><a hidden class=anchor aria-hidden=true href=#state-space-models-for-bioacoustics-a-comparative-evaluation-with-transformershttpsarxivorgabs251203563v1>#</a></h3><p><strong>Authors:</strong> Chengyu Tang, Sanjeev Baskiyar
<strong>Venue:</strong> arXiv (2025)</p><p>In this study, we evaluate the efficacy of the Mamba model in the field of bioacoustics. We first pretrain a Mamba-based audio large language model (LLM) on a large corpus of audio data using self-supervised learning. We fine-tune and evaluate BioMamba on the BEANS benchmark, a collection of diverse bioacoustic tasks including classification and detection, and compare its performance and efficiency with multiple baseline models, including AVES, a state-of-the-art Transformer-based model. The results show that BioMamba achieves comparable performance with AVES while consumption significantly less VRAM, demonstrating its potential in this domain.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03563v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03563v1">üìÑ Download PDF</a></p><hr><h3 id=pretrainzero-reinforcement-active-pretraininghttpsarxivorgabs251203442v1><a href=https://arxiv.org/abs/2512.03442v1>PretrainZero: Reinforcement Active Pretraining</a><a hidden class=anchor aria-hidden=true href=#pretrainzero-reinforcement-active-pretraininghttpsarxivorgabs251203442v1>#</a></h3><p><strong>Authors:</strong> Xingrun Xing, Zhiyuan Fan, Jie Lou, Guoqi Li, Jiajun Zhang, Debing Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>Mimicking human behavior to actively learning from general experience and achieve artificial general intelligence has always been a human dream. Recent reinforcement learning (RL) based large-thinking models demonstrate impressive expert-level abilities, i.e., software and math, but still rely heavily on verifiable rewards in specific domains, placing a significant bottleneck to extend the performance boundary of general reasoning capabilities. In this work, we propose PretrainZero, a reinforcement active learning framework built on the pretraining corpus to extend RL from domain-specific post-training to general pretraining. PretrainZero features the following characteristics: 1) Active pretraining: inspired by the active learning ability of humans, PretrainZero learns a unified reasoning policy to actively identify reasonable and informative contents from pretraining corpus, and reason to predict these contents by RL. 2) Self-supervised learning: without any verifiable labels, pretrained reward models, or supervised fine-tuning, we directly pretrain reasoners from 3 to 30B base models on the general Wikipedia corpus using RL, significantly breaking the verification data-wall for general reasoning. 3) Verification scaling: by tackling increasingly challenging masked spans, PretrainZero substantially enhances the general reasoning abilities of pretrained base models. In reinforcement pretraining, PretrainZero improves Qwen3-4B-Base for 8.43, 5.96 and 10.60 on MMLU-Pro, SuperGPQA and math average benchmarks. In post-training, the pretrained models can also serve as reasoning foundation models for downstream RLVR tasks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03442v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03442v1">üìÑ Download PDF</a></p><hr><h3 id=characterizing-language-use-in-a-collaborative-situated-gamehttpsarxivorgabs251203381v1><a href=https://arxiv.org/abs/2512.03381v1>Characterizing Language Use in a Collaborative Situated Game</a><a hidden class=anchor aria-hidden=true href=#characterizing-language-use-in-a-collaborative-situated-gamehttpsarxivorgabs251203381v1>#</a></h3><p><strong>Authors:</strong> Nicholas Tomlin, Naitian Zhou, Eve Fleisig, Liangyuan, Chen, T√©a Wright, Lauren Vinh, Laura X. Ma, Seun Eisape, Ellie French, Tingting Du, Tianjiao Zhang, Alexander Koller, Alane Suhr
<strong>Venue:</strong> arXiv (2025)</p><p>Cooperative video games, where multiple participants must coordinate by communicating and reasoning under uncertainty in complex environments, yield a rich source of language data. We collect the Portal Dialogue Corpus: a corpus of 11.5 hours of spoken human dialogue in the co-op mode of the popular Portal 2 virtual puzzle game, comprising 24.5K total utterances. We analyze player language and behavior, identifying a number of linguistic phenomena that rarely appear in most existing chitchat or task-oriented dialogue corpora, including complex spatial reference, clarification and repair, and ad-hoc convention formation. To support future analyses of language use in complex, situated, collaborative problem-solving scenarios, we publicly release the corpus, which comprises player videos, audio, transcripts, game state data, and both manual and automatic annotations of language data.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03381v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03381v1">üìÑ Download PDF</a></p><hr><h3 id=onethinker-all-in-one-reasoning-model-for-image-and-videohttpsarxivorgabs251203043v2><a href=https://arxiv.org/abs/2512.03043v2>OneThinker: All-in-one Reasoning Model for Image and Video</a><a hidden class=anchor aria-hidden=true href=#onethinker-all-in-one-reasoning-model-for-image-and-videohttpsarxivorgabs251203043v2>#</a></h3><p><strong>Authors:</strong> Kaituo Feng, Manyuan Zhang, Hongyu Li, Kaixuan Fan, Shuang Chen, Yilei Jiang, Dian Zheng, Peiwen Sun, Yiyuan Zhang, Haoze Sun, Yan Feng, Peng Pei, Xunliang Cai, Xiangyu Yue
<strong>Venue:</strong> arXiv (2025)</p><p>Reinforcement learning (RL) has recently achieved remarkable success in eliciting visual reasoning within Multimodal Large Language Models (MLLMs). However, existing approaches typically train separate models for different tasks and treat image and video reasoning as disjoint domains. This results in limited scalability toward a multimodal reasoning generalist, which restricts practical versatility and hinders potential knowledge sharing across tasks and modalities. To this end, we propose OneThinker, an all-in-one reasoning model that unifies image and video understanding across diverse fundamental visual tasks, including question answering, captioning, spatial and temporal grounding, tracking, and segmentation. To achieve this, we construct the OneThinker-600k training corpus covering all these tasks and employ commercial models for CoT annotation, resulting in OneThinker-SFT-340k for SFT cold start. Furthermore, we propose EMA-GRPO to handle reward heterogeneity in multi-task RL by tracking task-wise moving averages of reward standard deviations for balanced optimization. Extensive experiments on diverse visual benchmarks show that OneThinker delivers strong performance on 31 benchmarks, across 10 fundamental visual understanding tasks. Moreover, it exhibits effective knowledge transfer between certain tasks and preliminary zero-shot generalization ability, marking a step toward a unified multimodal reasoning generalist. All code, model, and data are released.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03043v2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03043v2">üìÑ Download PDF</a></p><hr><h3 id=ezyer-a-simulacrum-of-high-school-with-generative-agenthttpsarxivorgabs251202561v1><a href=https://arxiv.org/abs/2512.02561v1>EZYer: A simulacrum of high school with generative agent</a><a hidden class=anchor aria-hidden=true href=#ezyer-a-simulacrum-of-high-school-with-generative-agenthttpsarxivorgabs251202561v1>#</a></h3><p><strong>Authors:</strong> Jinming Yang, Zimu Ji, Weiqi Luo, Gaoxi Wang, Bin Ma, Yueling Deng
<strong>Venue:</strong> arXiv (2025)</p><p>With the rapid development of the online education and large language model, the existing educational tools still suffer from incomplete service, insufficient performance and weak interactivity in terms of courseware generation, interactive notes and quality assurance of content. In particular, the proposed generative agent EZYer : 1) Teacher Module: Integrating the Text Corpus retrieval and in-depth generation technologies, it automatically generates structured teaching materials and LaTeX Beamer courseware in line with the high school mathematics syllabus and supports user-defined image insertion. 2) Student Module: Throughout the collaborative interaction of the four roles of Teacher, Assistant, Top Student and Struggling Student, Note Taker summarizes and generates academic notes to enhance the depth and interest of learning. 3) Controller: set up keyword filtering system, content scoring system, role co-validation system, and dynamic content correction system. This ensure academic strictness and pedagogical propriety of EZYer inputs and outputs. In order to evaluate EZYer, this paper designs five-dimensional evaluation indexes of content accuracy, knowledge coverage, usability, formatting correctness and visual design and appeal, and scores 100 Beamer and Notes generated by EZYer by five large language models, separately, and the results show that the quality of EZYer-generated content is excellent and has a good application prospect.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02561v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02561v1">üìÑ Download PDF</a></p><hr><h3 id=statistical-properties-of-the-rooted-tree-encoding-of-mathbbnhttpsarxivorgabs251201436v1><a href=https://arxiv.org/abs/2512.01436v1>Statistical Properties of the Rooted-Tree Encoding of $\mathbb{N}$</a><a hidden class=anchor aria-hidden=true href=#statistical-properties-of-the-rooted-tree-encoding-of-mathbbnhttpsarxivorgabs251201436v1>#</a></h3><p><strong>Authors:</strong> Pierluigi Contucci, Claudio Giberti, Godwin Osabutey, Cecilia Vernia
<strong>Venue:</strong> arXiv (2025)</p><p>We prime-encode the natural numbers via recursive factorisation, iterated to the exponents, generating a corpus of planar rooted trees equivalently represented as Dyck words. This forms a deterministic text endowed with internal rules. Statistical analysis of the corpus reveals that the dictionary and the entropy grow sublinearly, compression shows non-monotonic trend, and the rank-frequency curves assume a stable parabolic form deviating from Zipf&rsquo;s law. Correlation analysis using mean-squared displacement reveals a transition from normal diffusion to superdiffusion in the associated walk. These findings characterise the tree-encoded sequence as a statistically structured text with long-range correlations grounded in its generative arithmetic law, providing an empirical basis for subsequent theoretical and learnability</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01436v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01436v1">üìÑ Download PDF</a></p><hr><h3 id=knowledge-graph-augmented-large-language-models-for-disease-predictionhttpsarxivorgabs251201210v2><a href=https://arxiv.org/abs/2512.01210v2>Knowledge Graph Augmented Large Language Models for Disease Prediction</a><a hidden class=anchor aria-hidden=true href=#knowledge-graph-augmented-large-language-models-for-disease-predictionhttpsarxivorgabs251201210v2>#</a></h3><p><strong>Authors:</strong> Ruiyu Wang, Tuan Vinh, Ran Xu, Yuyin Zhou, Jiaying Lu, Carl Yang, Francisco Pasquel
<strong>Venue:</strong> arXiv (2025)</p><p>Electronic health records (EHRs) support powerful clinical prediction models, but existing methods typically provide coarse, post hoc explanations that offer limited value for patient-level decision making. We introduce a knowledge graph (KG)-guided chain-of-thought (CoT) framework that generates clinically grounded and temporally consistent reasoning for visit-level disease prediction in MIMIC-III. ICD-9 codes are mapped to PrimeKG, from which disease-relevant nodes and multi-hop reasoning paths are extracted and used as scaffolds for CoT generation; only explanations whose conclusions match observed outcomes are retained. Lightweight LLaMA-3.1-Instruct-8B and Gemma-7B models are then fine-tuned on this supervision corpus. Across ten PrimeKG-mapped diseases and limited training cohorts (400 and 1000 cases), KG-guided models outperform strong classical baselines, achieving AUROC values of 0.66 to 0.70 and macro-AUPR values of 0.40 to 0.47. The models also transfer zero-shot to the CRADLE cohort, improving accuracy from approximately 0.40 to 0.51 up to 0.72 to 0.77. A blinded clinician evaluation shows consistent preference for KG-guided CoT explanations in clarity, relevance, and clinical correctness.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01210v2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01210v2">üìÑ Download PDF</a></p><hr><h3 id=a-practical-algorithm-for-3-admissibilityhttpsarxivorgabs251201121v1><a href=https://arxiv.org/abs/2512.01121v1>A practical algorithm for 3-admissibility</a><a hidden class=anchor aria-hidden=true href=#a-practical-algorithm-for-3-admissibilityhttpsarxivorgabs251201121v1>#</a></h3><p><strong>Authors:</strong> Christine Awofeso, Patrick Greaves, Oded Lachish, Felix Reidl
<strong>Venue:</strong> arXiv (2025)</p><p>The $3$-admissibility of a graph is a promising measure to identify real-world networks that have an algorithmically favourable structure.
We design an algorithm that decides whether the $3$-admissibility of an input graph~$G$ is at most~$p$ in time~\runtime and space~\memory, where $m$ is the number of edges in $G$ and $n$ the number of vertices. To the best of our knowledge, this is the first explicit algorithm to compute the $3$-admissibility.
The linear dependence on the input size in both time and space complexity, coupled with an `optimistic&rsquo; design philosophy for the algorithm itself, makes this algorithm practicable, as we demonstrate with an experimental evaluation on a corpus of \corpussize real-world networks.
Our experimental results show, surprisingly, that the $3$-admissibility of most real-world networks is not much larger than the $2$-admissibility, despite the fact that the former has better algorithmic properties than the latter.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01121v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01121v1">üìÑ Download PDF</a></p><hr><h3 id=when-safety-blocks-sense-measuring-semantic-confusion-in-llm-refusalshttpsarxivorgabs251201037v1><a href=https://arxiv.org/abs/2512.01037v1>When Safety Blocks Sense: Measuring Semantic Confusion in LLM Refusals</a><a hidden class=anchor aria-hidden=true href=#when-safety-blocks-sense-measuring-semantic-confusion-in-llm-refusalshttpsarxivorgabs251201037v1>#</a></h3><p><strong>Authors:</strong> Riad Ahmed Anonto, Md Labid Al Nahiyan, Md Tanvir Hassan, Ch. Md. Rakin Haider
<strong>Venue:</strong> arXiv (2025)</p><p>Safety-aligned language models often refuse prompts that are actually harmless. Current evaluations mostly report global rates such as false rejection or compliance. These scores treat each prompt alone and miss local inconsistency, where a model accepts one phrasing of an intent but rejects a close paraphrase. This gap limits diagnosis and tuning. We introduce &ldquo;semantic confusion,&rdquo; a failure mode that captures such local inconsistency, and a framework to measure it. We build ParaGuard, a 10k-prompt corpus of controlled paraphrase clusters that hold intent fixed while varying surface form. We then propose three model-agnostic metrics at the token level: Confusion Index, Confusion Rate, and Confusion Depth. These metrics compare each refusal to its nearest accepted neighbors and use token embeddings, next-token probabilities, and perplexity signals. Experiments across diverse model families and deployment guards show that global false-rejection rate hides critical structure. Our metrics reveal globally unstable boundaries in some settings, localized pockets of inconsistency in others, and cases where stricter refusal does not increase inconsistency. We also show how confusion-aware auditing separates how often a system refuses from how sensibly it refuses. This gives developers a practical signal to reduce false refusals while preserving safety.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.01037v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.01037v1">üìÑ Download PDF</a></p><hr><h3 id=measuring-the-unspoken-a-disentanglement-model-and-benchmark-for-psychological-analysis-in-the-wildhttpsarxivorgabs251204728v1><a href=https://arxiv.org/abs/2512.04728v1>Measuring the Unspoken: A Disentanglement Model and Benchmark for Psychological Analysis in the Wild</a><a hidden class=anchor aria-hidden=true href=#measuring-the-unspoken-a-disentanglement-model-and-benchmark-for-psychological-analysis-in-the-wildhttpsarxivorgabs251204728v1>#</a></h3><p><strong>Authors:</strong> Yigui Feng, Qinglin Wang, Haotian Mo, Yang Liu, Ke Liu, Gencheng Liu, Xinhai Chen, Siqi Shen, Songzhu Mei, Jie Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Generative psychological analysis of in-the-wild conversations faces two fundamental challenges: (1) existing Vision-Language Models (VLMs) fail to resolve Articulatory-Affective Ambiguity, where visual patterns of speech mimic emotional expressions; and (2) progress is stifled by a lack of verifiable evaluation metrics capable of assessing visual grounding and reasoning depth. We propose a complete ecosystem to address these twin challenges. First, we introduce Multilevel Insight Network for Disentanglement(MIND), a novel hierarchical visual encoder that introduces a Status Judgment module to algorithmically suppress ambiguous lip features based on their temporal feature variance, achieving explicit visual disentanglement. Second, we construct ConvoInsight-DB, a new large-scale dataset with expert annotations for micro-expressions and deep psychological inference. Third, Third, we designed the Mental Reasoning Insight Rating Metric (PRISM), an automated dimensional framework that uses expert-guided LLM to measure the multidimensional performance of large mental vision models. On our PRISM benchmark, MIND significantly outperforms all baselines, achieving a +86.95% gain in micro-expression detection over prior SOTA. Ablation studies confirm that our Status Judgment disentanglement module is the most critical component for this performance leap. Our code has been opened.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04728v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04728v1">üìÑ Download PDF</a></p><hr><h3 id=malicious-image-analysis-via-vision-language-segmentation-fusion-detection-element-and-location-in-one-shothttpsarxivorgabs251204599v1><a href=https://arxiv.org/abs/2512.04599v1>Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot</a><a hidden class=anchor aria-hidden=true href=#malicious-image-analysis-via-vision-language-segmentation-fusion-detection-element-and-location-in-one-shothttpsarxivorgabs251204599v1>#</a></h3><p><strong>Authors:</strong> Sheng Hang, Chaoxiang He, Hongsheng Hu, Hanqing Hu, Bin Benjamin Zhu, Shi-Feng Sun, Dawu Gu, Shuo Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Detecting illicit visual content demands more than image-level NSFW flags; moderators must also know what objects make an image illegal and where those objects occur. We introduce a zero-shot pipeline that simultaneously (i) detects if an image contains harmful content, (ii) identifies each critical element involved, and (iii) localizes those elements with pixel-accurate masks - all in one pass. The system first applies foundation segmentation model (SAM) to generate candidate object masks and refines them into larger independent regions. Each region is scored for malicious relevance by a vision-language model using open-vocabulary prompts; these scores weight a fusion step that produces a consolidated malicious object map. An ensemble across multiple segmenters hardens the pipeline against adaptive attacks that target any single segmentation method. Evaluated on a newly-annotated 790-image dataset spanning drug, sexual, violent and extremist content, our method attains 85.8% element-level recall, 78.1% precision and a 92.1% segment-success rate - exceeding direct zero-shot VLM localization by 27.4% recall at comparable precision. Against PGD adversarial perturbations crafted to break SAM and VLM, our method&rsquo;s precision and recall decreased by no more than 10%, demonstrating high robustness against attacks. The full pipeline processes an image in seconds, plugs seamlessly into existing VLM workflows, and constitutes the first practical tool for fine-grained, explainable malicious-image moderation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04599v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04599v1">üìÑ Download PDF</a></p><hr><h3 id=dataset-creation-for-supervised-deep-learning-based-analysis-of-microscopic-images----review-of-important-considerations-and-recommendationshttpsarxivorgabs251204564v1><a href=https://arxiv.org/abs/2512.04564v1>Dataset creation for supervised deep learning-based analysis of microscopic images &ndash; review of important considerations and recommendations</a><a hidden class=anchor aria-hidden=true href=#dataset-creation-for-supervised-deep-learning-based-analysis-of-microscopic-images----review-of-important-considerations-and-recommendationshttpsarxivorgabs251204564v1>#</a></h3><p><strong>Authors:</strong> Christof A. Bertram, Viktoria Weiss, Jonas Ammeling, F. Maria Schabel, Taryn A. Donovan, Frauke Wilm, Christian Marzahl, Katharina Breininger, Marc Aubreville
<strong>Venue:</strong> arXiv (2025)</p><p>Supervised deep learning (DL) receives great interest for automated analysis of microscopic images with an increasing body of literature supporting its potential. The development and validation of those DL models relies heavily on the availability of high-quality, large-scale datasets. However, creating such datasets is a complex and resource-intensive process, often hindered by challenges such as time constraints, domain variability, and risks of bias in image collection and label creation. This review provides a comprehensive guide to the critical steps in dataset creation, including: 1) image acquisition, 2) selection of annotation software, and 3) annotation creation. In addition to ensuring a sufficiently large number of images, it is crucial to address sources of image variability (domain shifts) - such as those related to slide preparation and digitization - that could lead to algorithmic errors if not adequately represented in the training data. Key quality criteria for annotations are the three &ldquo;C"s: correctness, completeness, and consistency. This review explores methods to enhance annotation quality through the use of advanced techniques that mitigate the limitations of single annotators. To support dataset creators, a standard operating procedure (SOP) is provided as supplemental material, outlining best practices for dataset development. Furthermore, the article underscores the importance of open datasets in driving innovation and enhancing reproducibility of DL research. By addressing the challenges and offering practical recommendations, this review aims to advance the creation of and availability to high-quality, large-scale datasets, ultimately contributing to the development of generalizable and robust DL models for pathology applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04564v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04564v1">üìÑ Download PDF</a></p><hr><h3 id=multi-loss-learning-for-speech-emotion-recognition-with-energy-adaptive-mixup-and-frame-level-attentionhttpsarxivorgabs251204551v1><a href=https://arxiv.org/abs/2512.04551v1>Multi-Loss Learning for Speech Emotion Recognition with Energy-Adaptive Mixup and Frame-Level Attention</a><a hidden class=anchor aria-hidden=true href=#multi-loss-learning-for-speech-emotion-recognition-with-energy-adaptive-mixup-and-frame-level-attentionhttpsarxivorgabs251204551v1>#</a></h3><p><strong>Authors:</strong> Cong Wang, Yizhong Geng, Yuhua Wen, Qifei Li, Yingming Gao, Ruimin Wang, Chunfeng Wang, Hao Li, Ya Li, Wei Chen
<strong>Venue:</strong> arXiv (2025)</p><p>Speech emotion recognition (SER) is an important technology in human-computer interaction. However, achieving high performance is challenging due to emotional complexity and scarce annotated data. To tackle these challenges, we propose a multi-loss learning (MLL) framework integrating an energy-adaptive mixup (EAM) method and a frame-level attention module (FLAM). The EAM method leverages SNR-based augmentation to generate diverse speech samples capturing subtle emotional variations. FLAM enhances frame-level feature extraction for multi-frame emotional cues. Our MLL strategy combines Kullback-Leibler divergence, focal, center, and supervised contrastive loss to optimize learning, address class imbalance, and improve feature separability. We evaluate our method on four widely used SER datasets: IEMOCAP, MSP-IMPROV, RAVDESS, and SAVEE. The results demonstrate our method achieves state-of-the-art performance, suggesting its effectiveness and robustness.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04551v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04551v1">üìÑ Download PDF</a></p><hr><h3 id=phyvllm-physics-guided-video-language-model-with-motion-appearance-disentanglementhttpsarxivorgabs251204532v1><a href=https://arxiv.org/abs/2512.04532v1>PhyVLLM: Physics-Guided Video Language Model with Motion-Appearance Disentanglement</a><a hidden class=anchor aria-hidden=true href=#phyvllm-physics-guided-video-language-model-with-motion-appearance-disentanglementhttpsarxivorgabs251204532v1>#</a></h3><p><strong>Authors:</strong> Yu-Wei Zhan, Xin Wang, Hong Chen, Tongtong Feng, Wei Feng, Ren Wang, Guangyao Li, Qing Li, Wenwu Zhu
<strong>Venue:</strong> arXiv (2025)</p><p>Video Large Language Models (Video LLMs) have shown impressive performance across a wide range of video-language tasks. However, they often fail in scenarios requiring a deeper understanding of physical dynamics. This limitation primarily arises from their reliance on appearance-based matching. Incorporating physical motion modeling is crucial for deeper video understanding, but presents three key challenges: (1) motion signals are often entangled with appearance variations, making it difficult to extract clean physical cues; (2) effective motion modeling requires not only continuous-time motion representations but also capturing physical dynamics; and (3) collecting accurate annotations for physical attributes is costly and often impractical. To address these issues, we propose PhyVLLM, a physical-guided video-language framework that explicitly incorporates physical motion into Video LLMs. Specifically, PhyVLLM disentangles visual appearance and object motion through a dual-branch encoder. To model physical dynamics over time, we incorporate a Neural Ordinary Differential Equation (Neural ODE) module, which generates differentiable physical dynamic representations. The resulting motion-aware representations are projected into the token space of a pretrained LLM, enabling physics reasoning without compromising the model&rsquo;s original multimodal capabilities. To circumvent the need for explicit physical labels, PhyVLLM employs a self-supervised manner to model the continuous evolution of object motion. Experimental results demonstrate that PhyVLLM significantly outperforms state-of-the-art Video LLMs on both physical reasoning and general video understanding tasks, highlighting the advantages of incorporating explicit physical modeling.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04532v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04532v1">üìÑ Download PDF</a></p><hr><h3 id=boundary-aware-test-time-adaptation-for-zero-shot-medical-image-segmentationhttpsarxivorgabs251204520v1><a href=https://arxiv.org/abs/2512.04520v1>Boundary-Aware Test-Time Adaptation for Zero-Shot Medical Image Segmentation</a><a hidden class=anchor aria-hidden=true href=#boundary-aware-test-time-adaptation-for-zero-shot-medical-image-segmentationhttpsarxivorgabs251204520v1>#</a></h3><p><strong>Authors:</strong> Chenlin Xu, Lei Zhang, Lituan Wang, Xinyu Pu, Pengfei Ma, Guangwu Qian, Zizhou Wang, Yan Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Due to the scarcity of annotated data and the substantial computational costs of model, conventional tuning methods in medical image segmentation face critical challenges. Current approaches to adapting pretrained models, including full-parameter and parameter-efficient fine-tuning, still rely heavily on task-specific training on downstream tasks. Therefore, zero-shot segmentation has gained increasing attention, especially with foundation models such as SAM demonstrating promising generalization capabilities. However, SAM still faces notable limitations on medical datasets due to domain shifts, making efficient zero-shot enhancement an urgent research goal. To address these challenges, we propose BA-TTA-SAM, a task-agnostic test-time adaptation framework that significantly enhances the zero-shot segmentation performance of SAM via test-time adaptation. This framework integrates two key mechanisms: (1) The encoder-level Gaussian prompt injection embeds Gaussian-based prompts directly into the image encoder, providing explicit guidance for initial representation learning. (2) The cross-layer boundary-aware attention alignment exploits the hierarchical feature interactions within the ViT backbone, aligning deep semantic responses with shallow boundary cues. Experiments on four datasets, including ISIC, Kvasir, BUSI, and REFUGE, show an average improvement of 12.4% in the DICE score compared with SAM&rsquo;s zero-shot segmentation performance. The results demonstrate that our method consistently outperforms state-of-the-art models in medical image segmentation. Our framework significantly enhances the generalization ability of SAM, without requiring any source-domain training data. Extensive experiments on publicly available medical datasets strongly demonstrate the superiority of our framework. Our code is available at <a href=https://github.com/Emilychenlin/BA-TTA-SAM>https://github.com/Emilychenlin/BA-TTA-SAM</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04520v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04520v1">üìÑ Download PDF</a></p><hr><h3 id=automating-complex-document-workflows-via-stepwise-and-rollback-enabled-operation-orchestrationhttpsarxivorgabs251204445v1><a href=https://arxiv.org/abs/2512.04445v1>Automating Complex Document Workflows via Stepwise and Rollback-Enabled Operation Orchestration</a><a hidden class=anchor aria-hidden=true href=#automating-complex-document-workflows-via-stepwise-and-rollback-enabled-operation-orchestrationhttpsarxivorgabs251204445v1>#</a></h3><p><strong>Authors:</strong> Yanbin Zhang, Hanhui Ye, Yue Bai, Qiming Zhang, Liao Xiang, Wu Mianzhi, Renjun Hu
<strong>Venue:</strong> arXiv (2025)</p><p>Workflow automation promises substantial productivity gains in everyday document-related tasks. While prior agentic systems can execute isolated instructions, they struggle with automating multi-step, session-level workflows due to limited control over the operational process. To this end, we introduce AutoDW, a novel execution framework that enables stepwise, rollback-enabled operation orchestration. AutoDW incrementally plans API actions conditioned on user instructions, intent-filtered API candidates, and the evolving states of the document. It further employs robust rollback mechanisms at both the argument and API levels, enabling dynamic correction and fault tolerance. These designs together ensure that the execution trajectory of AutoDW remains aligned with user intent and document context across long-horizon workflows. To assess its effectiveness, we construct a comprehensive benchmark of 250 sessions and 1,708 human-annotated instructions, reflecting realistic document processing scenarios with interdependent instructions. AutoDW achieves 90% and 62% completion rates on instruction- and session-level tasks, respectively, outperforming strong baselines by 40% and 76%. Moreover, AutoDW also remains robust for the decision of backbone LLMs and on tasks with varying difficulty. Code and data will be open-sourced. Code: <a href=https://github.com/YJett/AutoDW>https://github.com/YJett/AutoDW</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04445v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04445v1">üìÑ Download PDF</a></p><hr><h3 id=counting-without-running-evaluating-llms-reasoning-about-code-complexityhttpsarxivorgabs251204355v1><a href=https://arxiv.org/abs/2512.04355v1>Counting Without Running: Evaluating LLMs&rsquo; Reasoning About Code Complexity</a><a hidden class=anchor aria-hidden=true href=#counting-without-running-evaluating-llms-reasoning-about-code-complexityhttpsarxivorgabs251204355v1>#</a></h3><p><strong>Authors:</strong> Gregory Bolet, Giorgis Georgakoudis, Konstantinos Parasyris, Harshitha Menon, Niranjan Hasabnis, Kirk W. Cameron, Gal Oren
<strong>Venue:</strong> arXiv (2025)</p><p>Modern GPU software stacks demand developers who can anticipate performance bottlenecks before ever launching a kernel; misjudging floating-point workloads upstream can derail tuning, scheduling, and even hardware procurement. Yet despite rapid progress in code generation, today&rsquo;s Large Language Models (LLMs) are rarely tested on this kind of forward-looking reasoning. We close that gap with gpuFLOPBench, a benchmark that asks models to &ldquo;count without running&rdquo; by predicting single and double-precision FLOP counts for 577 CUDA kernels drawn from HeCBench, annotated with ground-truth profiles and eight execution attributes that distinguish trivially analyzable code from kernels whose FLOPs depend on hidden compiler or runtime behavior. Evaluating current closed-source reasoning models shows clear but uneven progress: the newest LLMs achieve perfect classification on straightforward kernels but still incur multiple order-of-magnitude errors whenever implicit FLOPs arise from division, intrinsic math functions, or common subexpressions. These results surface a core limitation of existing code assistants &ndash; the inability to internalize hardware-specific microcode effects &ndash; and position gpuFLOPBench as a focused testbed for developing LLM tooling that can reason about performance with the same rigor as experienced GPU developers. Sources are available at our repository: <a href=https://github.com/Scientific-Computing-Lab/gpuFLOPBench>https://github.com/Scientific-Computing-Lab/gpuFLOPBench</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04355v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04355v1">üìÑ Download PDF</a></p><hr><h3 id=gamma-from-mono-road-relative-metric-self-supervised-monocular-geometry-for-vehicular-applicationshttpsarxivorgabs251204303v1><a href=https://arxiv.org/abs/2512.04303v1>Gamma-from-Mono: Road-Relative, Metric, Self-Supervised Monocular Geometry for Vehicular Applications</a><a hidden class=anchor aria-hidden=true href=#gamma-from-mono-road-relative-metric-self-supervised-monocular-geometry-for-vehicular-applicationshttpsarxivorgabs251204303v1>#</a></h3><p><strong>Authors:</strong> Gasser Elazab, Maximilian Jansen, Michael Unterreiner, Olaf Hellwich
<strong>Venue:</strong> arXiv (2025)</p><p>Accurate perception of the vehicle&rsquo;s 3D surroundings, including fine-scale road geometry, such as bumps, slopes, and surface irregularities, is essential for safe and comfortable vehicle control. However, conventional monocular depth estimation often oversmooths these features, losing critical information for motion planning and stability. To address this, we introduce Gamma-from-Mono (GfM), a lightweight monocular geometry estimation method that resolves the projective ambiguity in single-camera reconstruction by decoupling global and local structure. GfM predicts a dominant road surface plane together with residual variations expressed by gamma, a dimensionless measure of vertical deviation from the plane, defined as the ratio of a point&rsquo;s height above it to its depth from the camera, and grounded in established planar parallax geometry. With only the camera&rsquo;s height above ground, this representation deterministically recovers metric depth via a closed form, avoiding full extrinsic calibration and naturally prioritizing near-road detail. Its physically interpretable formulation makes it well suited for self-supervised learning, eliminating the need for large annotated datasets. Evaluated on KITTI and the Road Surface Reconstruction Dataset (RSRD), GfM achieves state-of-the-art near-field accuracy in both depth and gamma estimation while maintaining competitive global depth performance. Our lightweight 8.88M-parameter model adapts robustly across diverse camera setups and, to our knowledge, is the first self-supervised monocular approach evaluated on RSRD.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04303v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04303v1">üìÑ Download PDF</a></p><hr><h3 id=educational-cone-model-in-embedding-vector-spaceshttpsarxivorgabs251204227v1><a href=https://arxiv.org/abs/2512.04227v1>Educational Cone Model in Embedding Vector Spaces</a><a hidden class=anchor aria-hidden=true href=#educational-cone-model-in-embedding-vector-spaceshttpsarxivorgabs251204227v1>#</a></h3><p><strong>Authors:</strong> Yo Ehara
<strong>Venue:</strong> arXiv (2025)</p><p>Human-annotated datasets with explicit difficulty ratings are essential in intelligent educational systems. Although embedding vector spaces are widely used to represent semantic closeness and are promising for analyzing text difficulty, the abundance of embedding methods creates a challenge in selecting the most suitable method. This study proposes the Educational Cone Model, which is a geometric framework based on the assumption that easier texts are less diverse (focusing on fundamental concepts), whereas harder texts are more diverse. This assumption leads to a cone-shaped distribution in the embedding space regardless of the embedding method used. The model frames the evaluation of embeddings as an optimization problem with the aim of detecting structured difficulty-based patterns. By designing specific loss functions, efficient closed-form solutions are derived that avoid costly computation. Empirical tests on real-world datasets validated the model&rsquo;s effectiveness and speed in identifying the embedding spaces that are best aligned with difficulty-annotated educational texts.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04227v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04227v1">üìÑ Download PDF</a></p><hr><h3 id=moregen-multi-agent-motion-reasoning-engine-for-code-based-text-to-video-synthesishttpsarxivorgabs251204221v1><a href=https://arxiv.org/abs/2512.04221v1>MoReGen: Multi-Agent Motion-Reasoning Engine for Code-based Text-to-Video Synthesis</a><a hidden class=anchor aria-hidden=true href=#moregen-multi-agent-motion-reasoning-engine-for-code-based-text-to-video-synthesishttpsarxivorgabs251204221v1>#</a></h3><p><strong>Authors:</strong> Xiangyu Bai, He Liang, Bishoy Galoaa, Utsav Nandi, Shayda Moezzi, Yuhang He, Sarah Ostadabbas
<strong>Venue:</strong> arXiv (2025)</p><p>While text-to-video (T2V) generation has achieved remarkable progress in photorealism, generating intent-aligned videos that faithfully obey physics principles remains a core challenge. In this work, we systematically study Newtonian motion-controlled text-to-video generation and evaluation, emphasizing physical precision and motion coherence. We introduce MoReGen, a motion-aware, physics-grounded T2V framework that integrates multi-agent LLMs, physics simulators, and renderers to generate reproducible, physically accurate videos from text prompts in the code domain. To quantitatively assess physical validity, we propose object-trajectory correspondence as a direct evaluation metric and present MoReSet, a benchmark of 1,275 human-annotated videos spanning nine classes of Newtonian phenomena with scene descriptions, spatiotemporal relations, and ground-truth trajectories. Using MoReSet, we conduct experiments on existing T2V models, evaluating their physical validity through both our MoRe metrics and existing physics-based evaluators. Our results reveal that state-of-the-art models struggle to maintain physical validity, while MoReGen establishes a principled direction toward physically coherent video synthesis.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04221v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04221v1">üìÑ Download PDF</a></p><hr><h3 id=fast--efficient-normalizing-flows-and-applications-of-image-generative-modelshttpsarxivorgabs251204039v1><a href=https://arxiv.org/abs/2512.04039v1>Fast & Efficient Normalizing Flows and Applications of Image Generative Models</a><a hidden class=anchor aria-hidden=true href=#fast--efficient-normalizing-flows-and-applications-of-image-generative-modelshttpsarxivorgabs251204039v1>#</a></h3><p><strong>Authors:</strong> Sandeep Nagar
<strong>Venue:</strong> arXiv (2025)</p><p>This thesis presents novel contributions in two primary areas: advancing the efficiency of generative models, particularly normalizing flows, and applying generative models to solve real-world computer vision challenges. The first part introduce significant improvements to normalizing flow architectures through six key innovations: 1) Development of invertible 3x3 Convolution layers with mathematically proven necessary and sufficient conditions for invertibility, (2) introduction of a more efficient Quad-coupling layer, 3) Design of a fast and efficient parallel inversion algorithm for kxk convolutional layers, 4) Fast & efficient backpropagation algorithm for inverse of convolution, 5) Using inverse of convolution, in Inverse-Flow, for the forward pass and training it using proposed backpropagation algorithm, and 6) Affine-StableSR, a compact and efficient super-resolution model that leverages pre-trained weights and Normalizing Flow layers to reduce parameter count while maintaining performance.
The second part: 1) An automated quality assessment system for agricultural produce using Conditional GANs to address class imbalance, data scarcity and annotation challenges, achieving good accuracy in seed purity testing; 2) An unsupervised geological mapping framework utilizing stacked autoencoders for dimensionality reduction, showing improved feature extraction compared to conventional methods; 3) We proposed a privacy preserving method for autonomous driving datasets using on face detection and image inpainting; 4) Utilizing Stable Diffusion based image inpainting for replacing the detected face and license plate to advancing privacy-preserving techniques and ethical considerations in the field.; and 5) An adapted diffusion model for art restoration that effectively handles multiple types of degradation through unified fine-tuning.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04039v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04039v1">üìÑ Download PDF</a></p><hr><h3 id=diq-h-evaluating-hallucination-persistence-in-vlms-under-temporal-visual-degradationhttpsarxivorgabs251203992v1><a href=https://arxiv.org/abs/2512.03992v1>DIQ-H: Evaluating Hallucination Persistence in VLMs Under Temporal Visual Degradation</a><a hidden class=anchor aria-hidden=true href=#diq-h-evaluating-hallucination-persistence-in-vlms-under-temporal-visual-degradationhttpsarxivorgabs251203992v1>#</a></h3><p><strong>Authors:</strong> Zexin Lin, Hawen Wan, Yebin Zhong, Xiaoqiang
<strong>Venue:</strong> arXiv (2025)</p><p>Vision-Language Models (VLMs) deployed in safety-critical applications such as autonomous driving must handle continuous visual streams under imperfect conditions. However, existing benchmarks focus on static, high-quality images and ignore temporal degradation and error propagation, which are critical failure modes where transient visual corruption induces hallucinations that persist across subsequent frames. We introduce DIQ-H, the first benchmark for evaluating VLM robustness under dynamic visual degradation in temporal sequences. DIQ-H applies physics-based corruptions including motion blur, sensor noise, and compression artifacts, and measures hallucination persistence, error recovery, and temporal consistency through multi-turn question-answering tasks. To enable scalable annotation, we propose Uncertainty-Guided Iterative Refinement (UIR), which generates reliable pseudo-ground-truth using lightweight VLMs with uncertainty filtering, achieving a 15.3 percent accuracy improvement. Experiments on 16 state-of-the-art VLMs reveal substantial robustness gaps: even advanced models such as GPT-4o achieve only a 78.5 percent recovery rate, while open-source models struggle with temporal consistency at less than 60 percent. DIQ-H provides a comprehensive platform for evaluating VLM reliability in real-world deployments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03992v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03992v1">üìÑ Download PDF</a></p><hr><h3 id=classification-of-user-satisfaction-in-hri-with-social-signals-in-the-wildhttpsarxivorgabs251203945v1><a href=https://arxiv.org/abs/2512.03945v1>Classification of User Satisfaction in HRI with Social Signals in the Wild</a><a hidden class=anchor aria-hidden=true href=#classification-of-user-satisfaction-in-hri-with-social-signals-in-the-wildhttpsarxivorgabs251203945v1>#</a></h3><p><strong>Authors:</strong> Michael Schiffmann, Sabina Jeschke, Anja Richert
<strong>Venue:</strong> arXiv (2025)</p><p>Socially interactive agents (SIAs) are being used in various scenarios and are nearing productive deployment. Evaluating user satisfaction with SIAs&rsquo; performance is a key factor in designing the interaction between the user and SIA. Currently, subjective user satisfaction is primarily assessed manually through questionnaires or indirectly via system metrics. This study examines the automatic classification of user satisfaction through analysis of social signals, aiming to enhance both manual and autonomous evaluation methods for SIAs. During a field trial at the Deutsches Museum Bonn, a Furhat Robotics head was employed as a service and information hub, collecting an &ldquo;in-the-wild&rdquo; dataset. This dataset comprises 46 single-user interactions, including questionnaire responses and video data. Our method focuses on automatically classifying user satisfaction based on time series classification. We use time series of social signal metrics derived from the body pose, time series of facial expressions, and physical distance. This study compares three feature engineering approaches on different machine learning models. The results confirm the method&rsquo;s effectiveness in reliably identifying interactions with low user satisfaction without the need for manually annotated datasets. This approach offers significant potential for enhancing SIA performance and user experience through automated feedback mechanisms.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03945v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03945v1">üìÑ Download PDF</a></p><hr><h3 id=fully-unsupervised-self-debiasing-of-text-to-image-diffusion-modelshttpsarxivorgabs251203749v1><a href=https://arxiv.org/abs/2512.03749v1>Fully Unsupervised Self-debiasing of Text-to-Image Diffusion Models</a><a hidden class=anchor aria-hidden=true href=#fully-unsupervised-self-debiasing-of-text-to-image-diffusion-modelshttpsarxivorgabs251203749v1>#</a></h3><p><strong>Authors:</strong> Korada Sri Vardhana, Shrikrishna Lolla, Soma Biswas
<strong>Venue:</strong> arXiv (2025)</p><p>Text-to-image (T2I) diffusion models have achieved widespread success due to their ability to generate high-resolution, photorealistic images. These models are trained on large-scale datasets, like LAION-5B, often scraped from the internet. However, since this data contains numerous biases, the models inherently learn and reproduce them, resulting in stereotypical outputs. We introduce SelfDebias, a fully unsupervised test-time debiasing method applicable to any diffusion model that uses a UNet as its noise predictor. SelfDebias identifies semantic clusters in an image encoder&rsquo;s embedding space and uses these clusters to guide the diffusion process during inference, minimizing the KL divergence between the output distribution and the uniform distribution. Unlike supervised approaches, SelfDebias does not require human-annotated datasets or external classifiers trained for each generated concept. Instead, it is designed to automatically identify semantic modes. Extensive experiments show that SelfDebias generalizes across prompts and diffusion model architectures, including both conditional and unconditional models. It not only effectively debiases images along key demographic dimensions while maintaining the visual fidelity of the generated images, but also more abstract concepts for which identifying biases is also challenging.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03749v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03749v1">üìÑ Download PDF</a></p><hr><h3 id=aitutor-evalkit-exploring-the-capabilities-of-ai-tutorshttpsarxivorgabs251203688v1><a href=https://arxiv.org/abs/2512.03688v1>AITutor-EvalKit: Exploring the Capabilities of AI Tutors</a><a hidden class=anchor aria-hidden=true href=#aitutor-evalkit-exploring-the-capabilities-of-ai-tutorshttpsarxivorgabs251203688v1>#</a></h3><p><strong>Authors:</strong> Numaan Naeem, Kaushal Kumar Maurya, Kseniia Petukhova, Ekaterina Kochmar
<strong>Venue:</strong> arXiv (2025)</p><p>We present AITutor-EvalKit, an application that uses language technology to evaluate the pedagogical quality of AI tutors, provides software for demonstration and evaluation, as well as model inspection and data visualization. This tool is aimed at education stakeholders as well as *ACL community at large, as it supports learning and can also be used to collect user feedback and annotations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03688v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03688v1">üìÑ Download PDF</a></p><hr><h3 id=colon-x-advancing-intelligent-colonoscopy-from-multimodal-understanding-to-clinical-reasoninghttpsarxivorgabs251203667v1><a href=https://arxiv.org/abs/2512.03667v1>Colon-X: Advancing Intelligent Colonoscopy from Multimodal Understanding to Clinical Reasoning</a><a hidden class=anchor aria-hidden=true href=#colon-x-advancing-intelligent-colonoscopy-from-multimodal-understanding-to-clinical-reasoninghttpsarxivorgabs251203667v1>#</a></h3><p><strong>Authors:</strong> Ge-Peng Ji, Jingyi Liu, Deng-Ping Fan, Nick Barnes
<strong>Venue:</strong> arXiv (2025)</p><p>In this study, we present Colon-X, an open initiative aimed at advancing multimodal intelligence in colonoscopy. We begin by constructing ColonVQA, the most comprehensive multimodal dataset ever built for colonoscopy, featuring over 1.1M+ visual question answering entries across 76 clinical findings and 18 multimodal tasks. Beyond serving as a community-wide data foundation, we further investigate a critical yet underexplored transition in colonoscopy - evolving from multimodal understanding to clinical reasoning: (a) To capture the current landscape of multimodal understanding behaviors, we systematically assess the generalizability of 22 multimodal large language models and examine their reliability under human-induced perturbations. The results reveal that clinical outputs from leading MLLMs remain far from robust and trustworthy. (b) To narrow this gap, we further explore reasoning-centric intelligence tailored for colonoscopy. Specifically, we curate ColonReason, a clinically grounded reasoning dataset annotated through a multi-expert debating pipeline, and develop ColonR1, the first R1-styled model incorporating task-adaptive rewarding and gradient-stable optimization techniques. Under data-scarce conditions, our ColonR1 achieves 56.61% overall accuracy, outperforming supervised fine-tuning by 25.22%, and sets a new reasoning-enabled baseline for multimodal colonoscopy analysis. All data and model resources are publicly available at <a href=https://github.com/ai4colonoscopy/Colon-X>https://github.com/ai4colonoscopy/Colon-X</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03667v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03667v1">üìÑ Download PDF</a></p><hr><h3 id=tog-bench-task-oriented-spatio-temporal-grounding-in-egocentric-videoshttpsarxivorgabs251203666v1><a href=https://arxiv.org/abs/2512.03666v1>ToG-Bench: Task-Oriented Spatio-Temporal Grounding in Egocentric Videos</a><a hidden class=anchor aria-hidden=true href=#tog-bench-task-oriented-spatio-temporal-grounding-in-egocentric-videoshttpsarxivorgabs251203666v1>#</a></h3><p><strong>Authors:</strong> Qi&rsquo;ao Xu, Tianwen Qian, Yuqian Fu, Kailing Li, Yang Jiao, Jiacheng Zhang, Xiaoling Wang, Liang He
<strong>Venue:</strong> arXiv (2025)</p><p>A core capability towards general embodied intelligence lies in localizing task-relevant objects from an egocentric perspective, formulated as Spatio-Temporal Video Grounding (STVG). Despite recent progress, existing STVG studies remain largely confined to object-centric and descriptive instructions, neglecting the task-oriented reasoning that is crucial for embodied agents to accomplish goal-directed interactions. To bridge this gap, we introduce \textbf{ToG-Bench}, the first task-oriented spatio-temporal video grounding benchmark for egocentric videos. ToG-Bench is characterized by three key features: (1) \textbf{Task-oriented Grounding}, which requires identifying and localizing objects based on intended tasks rather than straightforward descriptions; (2) \textbf{Explicit-Implicit Dual Grounding}, where target objects can be either explicitly mentioned or implicitly inferred by contextual reasoning; (3) \textbf{One-to-Many Grounding}, where a single instruction may correspond to multiple objects involved in task execution. Built upon videos sourced from ScanNet, ToG-Bench comprises 100 annotated clips with 2,704 task-oriented grounding instructions, constructed via a semi-automated pipeline that combines foundation model annotation and human refinement. In addition, we introduce a set of task-level evaluation metrics tailored for multi-object and explicit-implicit object grounding, and systematically benchmark seven state-of-the-art MLLMs. Extensive experiments reveal the intrinsic challenges of task-oriented STVG and substantial performance gaps across explicit-implicit and multi-object grounding, highlighting the difficulty of bridging perception and interaction in embodied scenarios. Data and code will be released at: \href{https://github.com/qaxuDev/ToG-Bench}{https://github.com/qaxuDev/ToG-Bench}..</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03666v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03666v1">üìÑ Download PDF</a></p><hr><h3 id=when-how-long-and-how-much-interpretable-neural-networks-for-time-series-regression-by-learning-to-mask-and-aggregatehttpsarxivorgabs251203578v1><a href=https://arxiv.org/abs/2512.03578v1>When, How Long and How Much? Interpretable Neural Networks for Time Series Regression by Learning to Mask and Aggregate</a><a hidden class=anchor aria-hidden=true href=#when-how-long-and-how-much-interpretable-neural-networks-for-time-series-regression-by-learning-to-mask-and-aggregatehttpsarxivorgabs251203578v1>#</a></h3><p><strong>Authors:</strong> Florent Forest, Amaury Wei, Olga Fink
<strong>Venue:</strong> arXiv (2025)</p><p>Time series extrinsic regression (TSER) refers to the task of predicting a continuous target variable from an input time series. It appears in many domains, including healthcare, finance, environmental monitoring, and engineering. In these settings, accurate predictions and trustworthy reasoning are both essential. Although state-of-the-art TSER models achieve strong predictive performance, they typically operate as black boxes, making it difficult to understand which temporal patterns drive their decisions. Post-hoc interpretability techniques, such as feature attribution, aim to to explain how the model arrives at its predictions, but often produce coarse, noisy, or unstable explanations. Recently, inherently interpretable approaches based on concepts, additive decompositions, or symbolic regression, have emerged as promising alternatives. However, these approaches remain limited: they require explicit supervision on the concepts themselves, often cannot capture interactions between time-series features, lack expressiveness for complex temporal patterns, and struggle to scale to high-dimensional multivariate data.
To address these limitations, we propose MAGNETS (Mask-and-AGgregate NEtwork for Time Series), an inherently interpretable neural architecture for TSER. MAGNETS learns a compact set of human-understandable concepts without requiring any annotations. Each concept corresponds to a learned, mask-based aggregation over selected input features, explicitly revealing both which features drive predictions and when they matter in the sequence. Predictions are formed as combinations of these learned concepts through a transparent, additive structure, enabling clear insight into the model&rsquo;s decision process.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03578v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03578v1">üìÑ Download PDF</a></p><hr><h3 id=afrobeats-dance-movement-analysis-using-computer-vision-a-proof-of-concept-framework-combining-yolo-and-segment-anything-modelhttpsarxivorgabs251203509v1><a href=https://arxiv.org/abs/2512.03509v1>AfroBeats Dance Movement Analysis Using Computer Vision: A Proof-of-Concept Framework Combining YOLO and Segment Anything Model</a><a hidden class=anchor aria-hidden=true href=#afrobeats-dance-movement-analysis-using-computer-vision-a-proof-of-concept-framework-combining-yolo-and-segment-anything-modelhttpsarxivorgabs251203509v1>#</a></h3><p><strong>Authors:</strong> Kwaku Opoku-Ware, Gideon Opoku
<strong>Venue:</strong> arXiv (2025)</p><p>This paper presents a preliminary investigation into automated dance movement analysis using contemporary computer vision techniques. We propose a proof-of-concept framework that integrates YOLOv8 and v11 for dancer detection with the Segment Anything Model (SAM) for precise segmentation, enabling the tracking and quantification of dancer movements in video recordings without specialized equipment or markers. Our approach identifies dancers within video frames, counts discrete dance steps, calculates spatial coverage patterns, and measures rhythm consistency across performance sequences. Testing this framework on a single 49-second recording of Ghanaian AfroBeats dance demonstrates technical feasibility, with the system achieving approximately 94% detection precision and 89% recall on manually inspected samples. The pixel-level segmentation provided by SAM, achieving approximately 83% intersection-over-union with visual inspection, enables motion quantification that captures body configuration changes beyond what bounding-box approaches can represent. Analysis of this preliminary case study indicates that the dancer classified as primary by our system executed 23% more steps with 37% higher motion intensity and utilized 42% more performance space compared to dancers classified as secondary. However, this work represents an early-stage investigation with substantial limitations including single-video validation, absence of systematic ground truth annotations, and lack of comparison with existing pose estimation methods. We present this framework to demonstrate technical feasibility, identify promising directions for quantitative dance metrics, and establish a foundation for future systematic validation studies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03509v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03509v1">üìÑ Download PDF</a></p><hr><h3 id=think-before-you-drive-world-model-inspired-multimodal-grounding-for-autonomous-vehicleshttpsarxivorgabs251203454v1><a href=https://arxiv.org/abs/2512.03454v1>Think Before You Drive: World Model-Inspired Multimodal Grounding for Autonomous Vehicles</a><a hidden class=anchor aria-hidden=true href=#think-before-you-drive-world-model-inspired-multimodal-grounding-for-autonomous-vehicleshttpsarxivorgabs251203454v1>#</a></h3><p><strong>Authors:</strong> Haicheng Liao, Huanming Shen, Bonan Wang, Yongkang Li, Yihong Tang, Chengyue Wang, Dingyi Zhuang, Kehua Chen, Hai Yang, Chengzhong Xu, Zhenning Li
<strong>Venue:</strong> arXiv (2025)</p><p>Interpreting natural-language commands to localize target objects is critical for autonomous driving (AD). Existing visual grounding (VG) methods for autonomous vehicles (AVs) typically struggle with ambiguous, context-dependent instructions, as they lack reasoning over 3D spatial relations and anticipated scene evolution. Grounded in the principles of world models, we propose ThinkDeeper, a framework that reasons about future spatial states before making grounding decisions. At its core is a Spatial-Aware World Model (SA-WM) that learns to reason ahead by distilling the current scene into a command-aware latent state and rolling out a sequence of future latent states, providing forward-looking cues for disambiguation. Complementing this, a hypergraph-guided decoder then hierarchically fuses these states with the multimodal input, capturing higher-order spatial dependencies for robust localization. In addition, we present DrivePilot, a multi-source VG dataset in AD, featuring semantic annotations generated by a Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT)-prompted LLM pipeline. Extensive evaluations on six benchmarks, ThinkDeeper ranks #1 on the Talk2Car leaderboard and surpasses state-of-the-art baselines on DrivePilot, MoCAD, and RefCOCO/+/g benchmarks. Notably, it shows strong robustness and efficiency in challenging scenes (long-text, multi-agent, ambiguity) and retains superior performance even when trained on 50% of the data.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03454v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03454v1">üìÑ Download PDF</a></p><hr><h3 id=multi-aspect-knowledge-enhanced-medical-vision-language-pretraining-with-multi-agent-data-generationhttpsarxivorgabs251203445v1><a href=https://arxiv.org/abs/2512.03445v1>Multi-Aspect Knowledge-Enhanced Medical Vision-Language Pretraining with Multi-Agent Data Generation</a><a hidden class=anchor aria-hidden=true href=#multi-aspect-knowledge-enhanced-medical-vision-language-pretraining-with-multi-agent-data-generationhttpsarxivorgabs251203445v1>#</a></h3><p><strong>Authors:</strong> Xieji Li, Siyuan Yan, Yingsheng Liu, H. Peter Soyer, Monika Janda, Victoria Mar, Zongyuan Ge
<strong>Venue:</strong> arXiv (2025)</p><p>Vision-language pretraining (VLP) has emerged as a powerful paradigm in medical image analysis, enabling representation learning from large-scale image-text pairs without relying on expensive manual annotations. However, existing methods often struggle with the noise inherent in web-collected data and the complexity of unstructured long medical texts. To address these challenges, we propose a novel VLP framework integrating a Multi-Agent data GENeration (MAGEN) system and Ontology-based Multi-Aspect Knowledge-Enhanced (O-MAKE) pretraining. First, MAGEN enhances data quality by synthesizing knowledge-enriched descriptions via a foundation model-assisted captioning and retrieval-based verification pipeline. Second, O-MAKE addresses the difficulty of learning from long, unstructured texts by decomposing them into distinct knowledge aspects. This facilitates fine-grained alignment at both global and patch levels, while explicitly modeling medical concept relationships through ontology-guided mechanisms. We validate our framework in the field of dermatology, where comprehensive experiments demonstrate the effectiveness of each component. Our approach achieves state-of-the-art zero-shot performance on disease classification and cross-modal retrieval tasks across eight datasets. Our code and the augmented dataset Derm1M-AgentAug, comprising over 400k skin-image-text pairs, will be released at <a href=https://github.com/SiyuanYan1/Derm1M>https://github.com/SiyuanYan1/Derm1M</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03445v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03445v1">üìÑ Download PDF</a></p><hr><h3 id=2bnirs-a-portable-multi-distance-broadband-oximeter-and-cytochrome-c-oxidase-monitoring-system-for-in-vivo-applicationshttpsarxivorgabs251204787v1><a href=https://arxiv.org/abs/2512.04787v1>2bNIRS: a portable, multi-distance, broadband oximeter and cytochrome-c-oxidase monitoring system for in vivo applications</a><a hidden class=anchor aria-hidden=true href=#2bnirs-a-portable-multi-distance-broadband-oximeter-and-cytochrome-c-oxidase-monitoring-system-for-in-vivo-applicationshttpsarxivorgabs251204787v1>#</a></h3><p><strong>Authors:</strong> Luca Giannoni, Archie Barraclough, Chiara Carnati, Frederic Lange, Ilias Tachtsidis
<strong>Venue:</strong> arXiv (2025)</p><p>Conventional near-infrared spectroscopy (NIRS) instruments typically employ 2-3 wavelengths for monitoring tissue haemodynamics. However, the use of broadband illumination (hundreds of wavelengths) unlocks also the targeting of tissue metabolism by exploiting the wide differential-redox peak of absorption of cytochrome-c-oxidase (CCO). For this purpose, we present here a novel, broadband (780-900nm), multi-distance NIRS system, called 2bNIRS. Compact and portable (20 x 30 x 40 cm3), 2bNIRS was validated using a dynamic, optical phantom con-taining blood and yeast, and benchmarked against a multi-wavelength time-domain NIRS (TD-NIRS) system. Validation confirmed its accuracy in tracking haemody-namic and metabolic changes, with superior oximetry performance achieved via our BRUNO algorithm, which integrates broadband spectral fitting with spatially-re-solved analysis. Preliminary in vivo, human applications demonstrated 2bNIRS ap-plicability to monitoring both muscle tissue, during arm cuff occlusions, and the brain, during frontal cortex activation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04787v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04787v1">üìÑ Download PDF</a></p><hr><h3 id=lafite-a-generative-latent-field-for-3d-native-texturinghttpsarxivorgabs251204786v1><a href=https://arxiv.org/abs/2512.04786v1>LaFiTe: A Generative Latent Field for 3D Native Texturing</a><a hidden class=anchor aria-hidden=true href=#lafite-a-generative-latent-field-for-3d-native-texturinghttpsarxivorgabs251204786v1>#</a></h3><p><strong>Authors:</strong> Chia-Hao Chen, Zi-Xin Zou, Yan-Pei Cao, Ze Yuan, Guan Luo, Xiaojuan Qi, Ding Liang, Song-Hai Zhang, Yuan-Chen Guo
<strong>Venue:</strong> arXiv (2025)</p><p>Generating high-fidelity, seamless textures directly on 3D surfaces, what we term 3D-native texturing, remains a fundamental open challenge, with the potential to overcome long-standing limitations of UV-based and multi-view projection methods. However, existing native approaches are constrained by the absence of a powerful and versatile latent representation, which severely limits the fidelity and generality of their generated textures. We identify this representation gap as the principal barrier to further progress. We introduce LaFiTe, a framework that addresses this challenge by learning to generate textures as a 3D generative sparse latent color field. At its core, LaFiTe employs a variational autoencoder (VAE) to encode complex surface appearance into a sparse, structured latent space, which is subsequently decoded into a continuous color field. This representation achieves unprecedented fidelity, exceeding state-of-the-art methods by >10 dB PSNR in reconstruction, by effectively disentangling texture appearance from mesh topology and UV parameterization. Building upon this strong representation, a conditional rectified-flow model synthesizes high-quality, coherent textures across diverse styles and geometries. Extensive experiments demonstrate that LaFiTe not only sets a new benchmark for 3D-native texturing but also enables flexible downstream applications such as material synthesis and texture super-resolution, paving the way for the next generation of 3D content creation workflows.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04786v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04786v1">üìÑ Download PDF</a></p><hr><h3 id=tempo-vine-a-multi-temporal-sensor-fusion-dataset-for-localization-and-mapping-in-vineyardshttpsarxivorgabs251204772v1><a href=https://arxiv.org/abs/2512.04772v1>TEMPO-VINE: A Multi-Temporal Sensor Fusion Dataset for Localization and Mapping in Vineyards</a><a hidden class=anchor aria-hidden=true href=#tempo-vine-a-multi-temporal-sensor-fusion-dataset-for-localization-and-mapping-in-vineyardshttpsarxivorgabs251204772v1>#</a></h3><p><strong>Authors:</strong> Mauro Martini, Marco Ambrosio, Judith Vilella-Cantos, Alessandro Navone, Marcello Chiaberge
<strong>Venue:</strong> arXiv (2025)</p><p>In recent years, precision agriculture has been introducing groundbreaking innovations in the field, with a strong focus on automation. However, research studies in robotics and autonomous navigation often rely on controlled simulations or isolated field trials. The absence of a realistic common benchmark represents a significant limitation for the diffusion of robust autonomous systems under real complex agricultural conditions. Vineyards pose significant challenges due to their dynamic nature, and they are increasingly drawing attention from both academic and industrial stakeholders interested in automation. In this context, we introduce the TEMPO-VINE dataset, a large-scale multi-temporal dataset specifically designed for evaluating sensor fusion, simultaneous localization and mapping (SLAM), and place recognition techniques within operational vineyard environments. TEMPO-VINE is the first multi-modal public dataset that brings together data from heterogeneous LiDARs of different price levels, AHRS, RTK-GPS, and cameras in real trellis and pergola vineyards, with multiple rows exceeding 100 m in length. In this work, we address a critical gap in the landscape of agricultural datasets by providing researchers with a comprehensive data collection and ground truth trajectories in different seasons, vegetation growth stages, terrain and weather conditions. The sequence paths with multiple runs and revisits will foster the development of sensor fusion, localization, mapping and place recognition solutions for agricultural fields. The dataset, the processing tools and the benchmarking results will be available at the dedicated webpage upon acceptance.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04772v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04772v1">üìÑ Download PDF</a></p><hr><h3 id=customer-identification-for-electricity-retailers-based-on-monthly-demand-profiles-by-activity-sectors-and-locationshttpsarxivorgabs251204776v1><a href=https://arxiv.org/abs/2512.04776v1>Customer Identification for Electricity Retailers Based on Monthly Demand Profiles by Activity Sectors and Locations</a><a hidden class=anchor aria-hidden=true href=#customer-identification-for-electricity-retailers-based-on-monthly-demand-profiles-by-activity-sectors-and-locationshttpsarxivorgabs251204776v1>#</a></h3><p><strong>Authors:</strong> Joaquin Luque, Alejandro Carrasco, Enrique Personal, Francisco Perez, Carlos Leon
<strong>Venue:</strong> arXiv (2025)</p><p>The increasing competition in the electric sector is challenging retail companies as they must assign its commercial efforts to attract the most profitable customers. Those are whose energy demand best fit certain target profiles, which usually depend on generation or cost policies. But, even when the demand profile is available, it is in an anonymous way, preventing its association to a particular client. In this paper, we explore a large dataset containing several millions of monthly demand profiles in Spain and use the available information about the associated economic sector and location for an indirect identification of the customers. The distance of the demand profile from the target is used to define a key performance indicator (KPI) which is used as the main driver of the proposed marketing strategy. The combined use of activity and location has been revealed as a powerful tool for indirect identification of customers, as 100,000 customers are uniquely identified, while about 300,000 clients are identifiable in small sets containing 10 or less consumers. To assess the proposed marketing strategy, it has been compared to the random attraction of new clients, showing a reduction of distance from the target of 40% for 10,000 new customers.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04776v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04776v1">üìÑ Download PDF</a></p><hr><h3 id=complementary-characterization-of-agent-based-models-via-computational-mechanics-and-diffusion-modelshttpsarxivorgabs251204771v1><a href=https://arxiv.org/abs/2512.04771v1>Complementary Characterization of Agent-Based Models via Computational Mechanics and Diffusion Models</a><a hidden class=anchor aria-hidden=true href=#complementary-characterization-of-agent-based-models-via-computational-mechanics-and-diffusion-modelshttpsarxivorgabs251204771v1>#</a></h3><p><strong>Authors:</strong> Roberto Garrone
<strong>Venue:</strong> arXiv (2025)</p><p>This article extends the preprint &ldquo;Characterizing Agent-Based Model Dynamics via $Œµ$-Machines and Kolmogorov-Style Complexity&rdquo; by introducing diffusion models as orthogonal and complementary tools for characterizing the output of agent-based models (ABMs). Where $Œµ$-machines capture the predictive temporal structure and intrinsic computation of ABM-generated time series, diffusion models characterize high-dimensional cross-sectional distributions, learn underlying data manifolds, and enable synthetic generation of plausible population-level outcomes. We provide a formal analysis demonstrating that the two approaches operate on distinct mathematical domains &ndash; processes vs. distributions &ndash; and show that their combination yields a two-axis representation of ABM behavior based on temporal organization and distributional geometry. To our knowledge, this is the first framework to integrate computational mechanics with score-based generative modeling for the structural analysis of ABM outputs, thereby situating ABM characterization within the broader landscape of modern machine-learning methods for density estimation and intrinsic computation. The framework is validated using the same elder-caregiver ABM dataset introduced in the companion paper, and we provide precise definitions and propositions formalizing the mathematical complementarity between $Œµ$-machines and diffusion models. This establishes a principled methodology for jointly analyzing temporal predictability and high-dimensional distributional structure in complex simulation models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04771v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04771v1">üìÑ Download PDF</a></p><hr><h2 id=-emotion_language>üîç emotion_language<a hidden class=anchor aria-hidden=true href=#-emotion_language>#</a></h2><h3 id=a-sanity-check-for-multi-in-domain-face-forgery-detection-in-the-real-worldhttpsarxivorgabs251204837v1><a href=https://arxiv.org/abs/2512.04837v1>A Sanity Check for Multi-In-Domain Face Forgery Detection in the Real World</a><a hidden class=anchor aria-hidden=true href=#a-sanity-check-for-multi-in-domain-face-forgery-detection-in-the-real-worldhttpsarxivorgabs251204837v1>#</a></h3><p><strong>Authors:</strong> Jikang Cheng, Renye Yan, Zhiyuan Yan, Yaozhong Gan, Xueyi Zhang, Zhongyuan Wang, Wei Peng, Ling Liang
<strong>Venue:</strong> arXiv (2025)</p><p>Existing methods for deepfake detection aim to develop generalizable detectors. Although &ldquo;generalizable&rdquo; is the ultimate target once and for all, with limited training forgeries and domains, it appears idealistic to expect generalization that covers entirely unseen variations, especially given the diversity of real-world deepfakes. Therefore, introducing large-scale multi-domain data for training can be feasible and important for real-world applications. However, within such a multi-domain scenario, the differences between multiple domains, rather than the subtle real/fake distinctions, dominate the feature space. As a result, despite detectors being able to relatively separate real and fake within each domain (i.e., high AUC), they struggle with single-image real/fake judgments in domain-unspecified conditions (i.e., low ACC). In this paper, we first define a new research paradigm named Multi-In-Domain Face Forgery Detection (MID-FFD), which includes sufficient volumes of real-fake domains for training. Then, the detector should provide definitive real-fake judgments to the domain-unspecified inputs, which simulate the frame-by-frame independent detection scenario in the real world. Meanwhile, to address the domain-dominant issue, we propose a model-agnostic framework termed DevDet (Developer for Detector) to amplify real/fake differences and make them dominant in the feature space. DevDet consists of a Face Forgery Developer (FFDev) and a Dose-Adaptive detector Fine-Tuning strategy (DAFT). Experiments demonstrate our superiority in predicting real-fake under the MID-FFD scenario while maintaining original generalization ability to unseen data.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04837v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04837v1">üìÑ Download PDF</a></p><hr><h3 id=unveiling-gravitational-waves-from-core-collapse-supernovae-with-musehttpsarxivorgabs251204804v1><a href=https://arxiv.org/abs/2512.04804v1>Unveiling gravitational waves from core-collapse supernovae with MUSE</a><a hidden class=anchor aria-hidden=true href=#unveiling-gravitational-waves-from-core-collapse-supernovae-with-musehttpsarxivorgabs251204804v1>#</a></h3><p><strong>Authors:</strong> Alessandro Veutro, Irene Di Palma, Marco Drago, Pablo Cerd√°-Dur√°n, Robin van der Laag, Melissa L√≥pez, Fulvio Ricci
<strong>Venue:</strong> arXiv (2025)</p><p>The core collapse of a massive star at the end of its life can give rise to one of the most powerful phenomena in the Universe. Because of violent mass motions that take place during the explosion, core-collapse supernovae have been considered a potential source of detectable gravitational waveforms for decades. However, their intrinsic stochasticity makes ineffective the use of modelled techniques such as matched filtering, forcing us to develop model independent technique to unveil their nature. In this work we present MUSE pipeline, which is based on a classification procedure of the time-frequency images using a Convolutional Neural Network. The network is trained on phenomenological waveforms that are built to mimic the main common features observed in numerical simulation. The method is finally tested on a representative 3D simulation catalog in the context of Einstein Telescope, a third generation GW telescope. Among the three detector geometries considered here, the 2L with a relative inclination of $45^\circ$ is the one achieving the best results, thus being able to detect a Kuroda2016-like waveform with an efficiency above $90%$ at 50 kpc.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04804v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04804v1">üìÑ Download PDF</a></p><hr><h3 id=graded-algebras-with-homogeneous-involution-and-varieties-of-almost-polynomial-growthhttpsarxivorgabs251204769v1><a href=https://arxiv.org/abs/2512.04769v1>Graded algebras with homogeneous involution and varieties of almost polynomial growth</a><a hidden class=anchor aria-hidden=true href=#graded-algebras-with-homogeneous-involution-and-varieties-of-almost-polynomial-growthhttpsarxivorgabs251204769v1>#</a></h3><p><strong>Authors:</strong> Wesley Quaresma Cota, Felipe Yasumura
<strong>Venue:</strong> arXiv (2025)</p><p>An important aspect in the theory of algebras with polynomial identities is the study of the asymptotic behavior of the codimension sequence $c_n(A),, n\geq 1,$ which measures the growth of polynomial identities of a given algebra $A$. In this context, graded identities naturally arise as prominent tools, since ordinary polynomial identities can be viewed as a particular case of graded identities. Moreover, as an involution does not necessarily preserve the homogeneous components of a grading, it is natural to consider the notion of a homogeneous involution. In this work, we investigate the behavior of the codimension sequence in the setting of $G$-graded algebras endowed with a homogeneous involution. More specifically, we characterize the varieties of polynomial growth in terms of the exclusion of a list of algebras from the variety. As a consequence, we provide the classification of the varieties with almost polynomial growth in this setting.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04769v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04769v1">üìÑ Download PDF</a></p><hr><h3 id=score-matching-for-estimating-finite-point-processeshttpsarxivorgabs251204617v1><a href=https://arxiv.org/abs/2512.04617v1>Score Matching for Estimating Finite Point Processes</a><a hidden class=anchor aria-hidden=true href=#score-matching-for-estimating-finite-point-processeshttpsarxivorgabs251204617v1>#</a></h3><p><strong>Authors:</strong> Haoqun Cao, Yixuan Zhang, Feng Zhou
<strong>Venue:</strong> arXiv (2025)</p><p>Score matching estimators have garnered significant attention in recent years because they eliminate the need to compute normalizing constants, thereby mitigating the computational challenges associated with maximum likelihood estimation (MLE).While several studies have proposed score matching estimators for point processes, this work highlights the limitations of these existing methods, which stem primarily from the lack of a mathematically rigorous analysis of how score matching behaves on finite point processes &ndash; special random configurations on bounded spaces where many of the usual assumptions and properties of score matching no longer hold. To this end, we develop a formal framework for score matching on finite point processes via Janossy measures and, within this framework, introduce an (autoregressive) weighted score-matching estimator, whose statistical properties we analyze in classical parametric settings. For general nonparametric (e.g., deep) point process models, we show that score matching alone does not uniquely identify the ground-truth distribution due to subtle normalization issues, and we propose a simple survival-classification augmentation that yields a complete, integration-free training objective for any intensity-based point process model for spatio-temporal case. Experiments on synthetic and real-world temporal and spatio-temporal datasets, demonstrate that our method accurately recovers intensities and achieves performance comparable to MLE with better efficiency.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04617v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04617v1">üìÑ Download PDF</a></p><hr><h3 id=standard-audiogram-classification-from-loudness-scaling-data-using-unsupervised-supervised-and-explainable-machine-learning-techniqueshttpsarxivorgabs251204616v1><a href=https://arxiv.org/abs/2512.04616v1>Standard audiogram classification from loudness scaling data using unsupervised, supervised, and explainable machine learning techniques</a><a hidden class=anchor aria-hidden=true href=#standard-audiogram-classification-from-loudness-scaling-data-using-unsupervised-supervised-and-explainable-machine-learning-techniqueshttpsarxivorgabs251204616v1>#</a></h3><p><strong>Authors:</strong> Chen Xu, Lena Schell-Majoor, Birger Kollmeier
<strong>Venue:</strong> arXiv (2025)</p><p>To address the calibration and procedural challenges inherent in remote audiogram assessment for rehabilitative audiology, this study investigated whether calibration-independent adaptive categorical loudness scaling (ACALOS) data can be used to approximate individual audiograms by classifying listeners into standard Bisgaard audiogram types using machine learning. Three classes of machine learning approaches - unsupervised, supervised, and explainable - were evaluated. Principal component analysis (PCA) was performed to extract the first two principal components, which together explained more than 50 percent of the variance. Seven supervised multi-class classifiers were trained and compared, alongside unsupervised and explainable methods. Model development and evaluation used a large auditory reference database containing ACALOS data (N = 847). The PCA factor map showed substantial overlap between listeners, indicating that cleanly separating participants into six Bisgaard classes based solely on their loudness patterns is challenging. Nevertheless, the models demonstrated reasonable classification performance, with logistic regression achieving the highest accuracy among supervised approaches. These findings demonstrate that machine learning models can predict standard Bisgaard audiogram types, within certain limits, from calibration-independent loudness perception data, supporting potential applications in remote or resource-limited settings without requiring a traditional audiogram.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04616v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04616v1">üìÑ Download PDF</a></p><hr><h3 id=mode-interactions-in-scalar-field-cosmologyhttpsarxivorgabs251204607v1><a href=https://arxiv.org/abs/2512.04607v1>Mode interactions in scalar field cosmology</a><a hidden class=anchor aria-hidden=true href=#mode-interactions-in-scalar-field-cosmologyhttpsarxivorgabs251204607v1>#</a></h3><p><strong>Authors:</strong> Spiros Cotsakis, Ignatios Antoniadis
<strong>Venue:</strong> arXiv (2025)</p><p>We study the dynamics of spatially homogeneous Friedmann&ndash;Robertson&ndash;Walker universes filled with a massive scalar field in a neighbourhood of the massless transition $s=1$. At this point the Einstein&ndash;scalar system exhibits a codimension&ndash;two Hopf&ndash;steady&ndash;state organising centre whose versal unfolding describes all small deformations of the quadratic model. After reduction to the centre manifold, the dynamics is governed by two slow geometric modes $(r,z)$: the Hopf amplitude $r$, measuring the kinetic departure from de Sitter, and the slowly drifting Hubble mode $z$. We show that the standard slow&ndash;roll parameters follow directly from these unfolding variables, $Œµ\sim\tfrac32 r^{2}$ and $Œ∑\sim z$, so that the spectral tilt, tensor&ndash;to&ndash;scalar ratio, and scalar amplitude arise as universal functions of $(r,z)$, independently of the choice of potential. The two unfolding parameters $(Œº_{1},Œº_{2})$ classify all perturbations of the quadratic model and can be interpreted physically as controlling the tilt and curvature deformations of generic polynomial inflationary potentials. Thus the near scale&ndash;invariance of primordial perturbations emerges as a structural property of the unfolding of the organising centre, providing a potential&ndash;independent mechanism for an early phase of accelerated expansion. We discuss the implications of this geometric framework for the interpretation and classification of inflationary models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04607v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04607v1">üìÑ Download PDF</a></p><hr><h3 id=exploiting-textttftraces-textttfunction_graph-tracer-features-for-machine-learning-a-case-study-on-encryption-detectionhttpsarxivorgabs251204590v1><a href=https://arxiv.org/abs/2512.04590v1>Exploiting \texttt{ftrace}&rsquo;s \texttt{function_graph} Tracer Features for Machine Learning: A Case Study on Encryption Detection</a><a hidden class=anchor aria-hidden=true href=#exploiting-textttftraces-textttfunction_graph-tracer-features-for-machine-learning-a-case-study-on-encryption-detectionhttpsarxivorgabs251204590v1>#</a></h3><p><strong>Authors:</strong> Kenan Begovic, Abdulaziz Al-Ali, Qutaibah Malluhi
<strong>Venue:</strong> arXiv (2025)</p><p>This paper proposes using the Linux kernel ftrace framework, particularly the function graph tracer, to generate informative system level data for machine learning (ML) applications. Experiments on a real world encryption detection task demonstrate the efficacy of the proposed features across several learning algorithms. The learner faces the problem of detecting encryption activities across a large dataset of files, using function call traces and graph based features. Empirical results highlight an outstanding accuracy of 99.28 on the task at hand, underscoring the efficacy of features derived from the function graph tracer. The results were further validated in an additional experiment targeting a multilabel classification problem, in which running programs were identified from trace data. This work provides comprehensive methodologies for preprocessing raw trace data and extracting graph based features, offering significant advancements in applying ML to system behavior analysis, program identification, and anomaly detection. By bridging the gap between system tracing and ML, this paper paves the way for innovative solutions in performance monitoring and security analytics.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04590v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04590v1">üìÑ Download PDF</a></p><hr><h3 id=an-all-optical-convolutional-neural-network-for-image-identificationhttpsarxivorgabs251204569v1><a href=https://arxiv.org/abs/2512.04569v1>An all-optical convolutional neural network for image identification</a><a hidden class=anchor aria-hidden=true href=#an-all-optical-convolutional-neural-network-for-image-identificationhttpsarxivorgabs251204569v1>#</a></h3><p><strong>Authors:</strong> Wei-Wei Fu, Dong Zhao, Qing-Hong Rao, Heng-Yi Wang, Ben-Li Yu, Zhi-Jia Hu, Fang-Wen Sun, Kun Huang
<strong>Venue:</strong> arXiv (2025)</p><p>In modern artificial intelligence, convolutional neural networks (CNNs) have become a cornerstone for visual and perceptual tasks. However, their implementation on conventional electronic hardware faces fundamental bottlenecks in speed and energy efficiency due to resistive and capacitive losses. Photonic alternatives offer a promising route, yet the difficulty of realizing optical nonlinearities has prevented the realization of all-optical CNNs capable of end-to-end image classification. Here, we demonstrate an all-optical CNN that bypasses the need for explicit optical nonlinear activations. Our architecture comprises a single spatial-differentiation convolutional stage&ndash;using 24 directional kernels spanning 360¬∞, along with a mean-filtering kernel&ndash;followed by a diffractive fully-connected layer. The directional convolution enhances feature selectivity, suppresses noise and crosstalk, and simplifies the classification task, allowing the weak nonlinearity inherent in optical diffraction to achieve high accuracy. We report experimentally classification accuracies of 86.8% on handwritten digits (MNIST) and 94.8% on a ten-class gesture dataset. The system delivers a computational throughput of 1.13X10^5 tera-operations per second (TOPS) and an energy efficiency of 1.51X10^3 TOPS/W&ndash;the highest reported among CNN hardware&ndash;with the potential to improve by a further 5-6 orders of magnitude using nanosecond-scale detectors. This work establishes a scalable pathway toward ultralow-latency, ultralow-energy vision processing for real-time intelligent systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04569v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04569v1">üìÑ Download PDF</a></p><hr><h3 id=reflection-of-nichols-algebras-over-coquasi-hopf-algebrashttpsarxivorgabs251204560v1><a href=https://arxiv.org/abs/2512.04560v1>Reflection of Nichols Algebras over Coquasi-Hopf Algebras</a><a hidden class=anchor aria-hidden=true href=#reflection-of-nichols-algebras-over-coquasi-hopf-algebrashttpsarxivorgabs251204560v1>#</a></h3><p><strong>Authors:</strong> Bowen Li, Gongxiang Liu
<strong>Venue:</strong> arXiv (2025)</p><p>This paper extends the foundational reflection theory of Nichols algebras to the setting of some certain coquasi-Hopf algebras. Our primary motivation arises from the classification of pointed finite-dimensional coquasi-Hopf algebras. We develop a reflection theory for tuples of simple Yetter-Drinfeld modules in the category $\GG$, where $G$ is a finite group and $Œ¶$ is a 3-cocycle on $G$. We prove that such a tuple gives rise to a semi-Cartan graph if admitting all reflections. Consequently, its Weyl groupoid is well-defined. We further establish several criteria for the finite-dimensionality of Nichols algebras in terms of the associated semi-Cartan graph. As an application, we provide a new proof for the infinite-dimensionality of a specific class of Nichols algebras previously studied in \cite{huang2024classification}, bypassing extensive computational arguments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04560v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04560v1">üìÑ Download PDF</a></p><hr><h3 id=efficient-identification-the-inequivalence-of-mutually-unbiased-bases-via-finite-operatorshttpsarxivorgabs251204543v1><a href=https://arxiv.org/abs/2512.04543v1>Efficient Identification the Inequivalence of Mutually Unbiased Bases via Finite Operators</a><a hidden class=anchor aria-hidden=true href=#efficient-identification-the-inequivalence-of-mutually-unbiased-bases-via-finite-operatorshttpsarxivorgabs251204543v1>#</a></h3><p><strong>Authors:</strong> Jianxin Song, Zhen-Peng Xu, Changliang Ren
<strong>Venue:</strong> arXiv (2025)</p><p>The structural characterization of high-dimensional mutually unbiased bases (MUBs) by classifying MUBs subsets remains a major open problem. The existing methods not only fail to conclude on the exact classification, but also are severely limited by computational resources and suffer from the numerical precision problem. Here we introduce an operational approach to identify the inequivalence of MUBs subsets, which has less time complexity and entirely avoids the computational precision issues. For arbitrary MUBs subsets of $k$ elements in any prime dimension, this method yields a universal analytical upper bound for the amount of MUBs equivalence classes. By applying this method through simple iterations, we further obtain tighter classification upper bounds for any prime dimension $d\leq 37$. Crucially, the comparison of these upper bounds with existing lower bounds successfully determines the exact classification for all MUBs subsets in any dimension $d \leq 17$. We further extend this method to the case that the dimension is a power of prime number. This general and scalable framework for the classification of MUBs subsets sheds new light on related applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04543v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04543v1">üìÑ Download PDF</a></p><hr><h3 id=detection-of-intoxicated-individuals-from-facial-video-sequences-via-a-recurrent-fusion-modelhttpsarxivorgabs251204536v1><a href=https://arxiv.org/abs/2512.04536v1>Detection of Intoxicated Individuals from Facial Video Sequences via a Recurrent Fusion Model</a><a hidden class=anchor aria-hidden=true href=#detection-of-intoxicated-individuals-from-facial-video-sequences-via-a-recurrent-fusion-modelhttpsarxivorgabs251204536v1>#</a></h3><p><strong>Authors:</strong> Bita Baroutian, Atefe Aghaei, Mohsen Ebrahimi Moghaddam
<strong>Venue:</strong> arXiv (2025)</p><p>Alcohol consumption is a significant public health concern and a major cause of accidents and fatalities worldwide. This study introduces a novel video-based facial sequence analysis approach dedicated to the detection of alcohol intoxication. The method integrates facial landmark analysis via a Graph Attention Network (GAT) with spatiotemporal visual features extracted using a 3D ResNet. These features are dynamically fused with adaptive prioritization to enhance classification performance. Additionally, we introduce a curated dataset comprising 3,542 video segments derived from 202 individuals to support training and evaluation. Our model is compared against two baselines: a custom 3D-CNN and a VGGFace+LSTM architecture. Experimental results show that our approach achieves 95.82% accuracy, 0.977 precision, and 0.97 recall, outperforming prior methods. The findings demonstrate the model&rsquo;s potential for practical deployment in public safety systems for non-invasive, reliable alcohol intoxication detection.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04536v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04536v1">üìÑ Download PDF</a></p><hr><h3 id=rge-gcn-recursive-gene-elimination-with-graph-convolutional-networks-for-rna-seq-based-early-cancer-detectionhttpsarxivorgabs251204333v1><a href=https://arxiv.org/abs/2512.04333v1>RGE-GCN: Recursive Gene Elimination with Graph Convolutional Networks for RNA-seq based Early Cancer Detection</a><a hidden class=anchor aria-hidden=true href=#rge-gcn-recursive-gene-elimination-with-graph-convolutional-networks-for-rna-seq-based-early-cancer-detectionhttpsarxivorgabs251204333v1>#</a></h3><p><strong>Authors:</strong> Shreyas Shende, Varsha Narayanan, Vishal Fenn, Yiran Huang, Dincer Goksuluk, Gaurav Choudhary, Melih Agraz, Mengjia Xu
<strong>Venue:</strong> arXiv (2025)</p><p>Early detection of cancer plays a key role in improving survival rates, but identifying reliable biomarkers from RNA-seq data is still a major challenge. The data are high-dimensional, and conventional statistical methods often fail to capture the complex relationships between genes. In this study, we introduce RGE-GCN (Recursive Gene Elimination with Graph Convolutional Networks), a framework that combines feature selection and classification in a single pipeline. Our approach builds a graph from gene expression profiles, uses a Graph Convolutional Network to classify cancer versus normal samples, and applies Integrated Gradients to highlight the most informative genes. By recursively removing less relevant genes, the model converges to a compact set of biomarkers that are both interpretable and predictive. We evaluated RGE-GCN on synthetic data as well as real-world RNA-seq cohorts of lung, kidney, and cervical cancers. Across all datasets, the method consistently achieved higher accuracy and F1-scores than standard tools such as DESeq2, edgeR, and limma-voom. Importantly, the selected genes aligned with well-known cancer pathways including PI3K-AKT, MAPK, SUMOylation, and immune regulation. These results suggest that RGE-GCN shows promise as a generalizable approach for RNA-seq based early cancer detection and biomarker discovery (<a href=https://rce-gcn.streamlit.app/>https://rce-gcn.streamlit.app/</a> ).</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04333v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04333v1">üìÑ Download PDF</a></p><hr><h3 id=open-set-face-forgery-detection-via-dual-level-evidence-collectionhttpsarxivorgabs251204331v1><a href=https://arxiv.org/abs/2512.04331v1>Open Set Face Forgery Detection via Dual-Level Evidence Collection</a><a hidden class=anchor aria-hidden=true href=#open-set-face-forgery-detection-via-dual-level-evidence-collectionhttpsarxivorgabs251204331v1>#</a></h3><p><strong>Authors:</strong> Zhongyi Cai, Bryce Gernon, Wentao Bao, Yifan Li, Matthew Wright, Yu Kong
<strong>Venue:</strong> arXiv (2025)</p><p>The proliferation of face forgeries has increasingly undermined confidence in the authenticity of online content. Given the rapid development of face forgery generation algorithms, new fake categories are likely to keep appearing, posing a major challenge to existing face forgery detection methods. Despite recent advances in face forgery detection, existing methods are typically limited to binary Real-vs-Fake classification or the identification of known fake categories, and are incapable of detecting the emergence of novel types of forgeries. In this work, we study the Open Set Face Forgery Detection (OSFFD) problem, which demands that the detection model recognize novel fake categories. We reformulate the OSFFD problem and address it through uncertainty estimation, enhancing its applicability to real-world scenarios. Specifically, we propose the Dual-Level Evidential face forgery Detection (DLED) approach, which collects and fuses category-specific evidence on the spatial and frequency levels to estimate prediction uncertainty. Extensive evaluations conducted across diverse experimental settings demonstrate that the proposed DLED method achieves state-of-the-art performance, outperforming various baseline models by an average of 20% in detecting forgeries from novel fake categories. Moreover, on the traditional Real-versus-Fake face forgery detection task, our DLED method concurrently exhibits competitive performance.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04331v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04331v1">üìÑ Download PDF</a></p><hr><h3 id=detection-and-imaging-of-chemicals-and-hidden-explosives-using-terahertz-time-domain-spectroscopy-and-deep-learninghttpsarxivorgabs251204330v1><a href=https://arxiv.org/abs/2512.04330v1>Detection and imaging of chemicals and hidden explosives using terahertz time-domain spectroscopy and deep learning</a><a hidden class=anchor aria-hidden=true href=#detection-and-imaging-of-chemicals-and-hidden-explosives-using-terahertz-time-domain-spectroscopy-and-deep-learninghttpsarxivorgabs251204330v1>#</a></h3><p><strong>Authors:</strong> Xinghe Jiang, Yuhang Li, Yuzhu Li, Che-Yung Shen, Aydogan Ozcan, Mona Jarrahi
<strong>Venue:</strong> arXiv (2025)</p><p>Detecting concealed chemicals and explosives remains a critical challenge in global security. Terahertz time-domain spectroscopy (THz-TDS) offers a promising non-invasive and stand-off detection technique owing to its ability to penetrate optically opaque materials without causing ionization damage. While many chemicals exhibit distinct spectral features in the terahertz range, conventional terahertz-based detection methods often struggle in real-world environments, where variations in sample geometry, thickness, and packaging can lead to inconsistent spectral responses. In this study, we present a chemical imaging system that integrates THz-TDS with deep learning to enable accurate pixel-level identification and classification of different explosives. Operating in reflection mode and enhanced with plasmonic nanoantenna arrays, our THz-TDS system achieves a peak dynamic range of 96 dB and a detection bandwidth of 4.5 THz, supporting practical, stand-off operation. By analyzing individual time-domain pulses with deep neural networks, the system exhibits strong resilience to environmental variations and sample inconsistencies. Blind testing across eight chemicals, including pharmaceutical excipients and explosive compounds, resulted in an average classification accuracy of 99.42% at the pixel level. Notably, the system maintained an average accuracy of 88.83% when detecting explosives concealed under opaque paper coverings, demonstrating its robust generalization capability. These results highlight the potential of combining advanced terahertz spectroscopy with neural networks for highly sensitive and specific chemical and explosive detection in diverse and operationally relevant scenarios.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04330v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04330v1">üìÑ Download PDF</a></p><hr><h3 id=mantra-a-framework-for-multi-stage-adaptive-noise-treatment-during-traininghttpsarxivorgabs251204319v1><a href=https://arxiv.org/abs/2512.04319v1>MANTRA: a Framework for Multi-stage Adaptive Noise TReAtment During Training</a><a hidden class=anchor aria-hidden=true href=#mantra-a-framework-for-multi-stage-adaptive-noise-treatment-during-traininghttpsarxivorgabs251204319v1>#</a></h3><p><strong>Authors:</strong> Zixiao Zhao, Fatemeh H. Fard, Jie JW Wu
<strong>Venue:</strong> arXiv (2025)</p><p>The reliable application of deep learning models to software engineering tasks hinges on high-quality training data. Yet, large-scale repositories inevitably introduce noisy or mislabeled examples that degrade both accuracy and robustness. While Noise Label Learning (NLL) has been extensively studied in other fields, there are a few works that investigate NLL in Software Engineering (SE) and Large Language Models (LLMs) for SE tasks. In this work, we propose MANTRA, a Multi-stage Adaptive Noise TReAtment framework that embeds noise diagnosis and mitigation directly into the fine-tuning process of code-Pretrained Language Models (PTM) and code-LLMs. We first investigate the effect of noise at varying levels on convergence and loss trajectories of the models. Then we apply an adaptive dropout strategy guided by per-sample loss dynamics and Gaussian Mixture Model clustering to exclude persistently noisy points while preserving clean data. Applying to code summarization and commit intent classification, our experiments reveal that some LLMs are more sensitive to noise than others. However, with MANTRA, the performance of all models in both tasks is improved. MANTRA enables researchers and practitioners to reduce the impact of errors introduced by the dataset in training, saves time in data cleaning and processing, while maximizing the effect of fine-tuning.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04319v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04319v1">üìÑ Download PDF</a></p><hr><h3 id=classification-of-homogeneous-odd-rota--baxter-operators-on-a-modified-witt-type-lie-superalgebrahttpsarxivorgabs251204294v1><a href=https://arxiv.org/abs/2512.04294v1>Classification of Homogeneous Odd Rota&ndash;Baxter Operators on a Modified Witt-Type Lie Superalgebra</a><a hidden class=anchor aria-hidden=true href=#classification-of-homogeneous-odd-rota--baxter-operators-on-a-modified-witt-type-lie-superalgebrahttpsarxivorgabs251204294v1>#</a></h3><p><strong>Authors:</strong> Mohsen Ben Abdallah, Marwa Ennaceur
<strong>Venue:</strong> arXiv (2025)</p><p>We classify all homogeneous odd (i.e., parity-reversing) Rota&ndash;Baxter operators of weight zero on the modified Witt-type Lie superalgebra $W = \langle L_m, G_n \rangle_{m,n\in\Z}$. Our classification shows that nontrivial such operators are highly constrained: either $g \equiv 0$ and $f$ is arbitrary, or $g \not\equiv 0$ forces $f \equiv 0$, and $g$ must take one of several rigid forms dictated by the integer shift $k$ (necessarily odd when $g(0) \neq 0$). We prove that every Rota&ndash;Baxter operator on $W$ decomposes uniquely into even and odd homogeneous components; we restrict our attention to the odd case, which yields the full nontrivial structure. Furthermore, we show that all derivations of $W$ are inner, that no Rota&ndash;Baxter operator on $W$ is invertible, and we describe the induced super pre-Lie algebra structure together with its cohomological interpretation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04294v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04294v1">üìÑ Download PDF</a></p><hr><h3 id=algebraic-identities-for-linear-operators-on-associative-triple-systems-long-versionhttpsarxivorgabs251204190v1><a href=https://arxiv.org/abs/2512.04190v1>Algebraic identities for linear operators on associative triple systems (long version)</a><a hidden class=anchor aria-hidden=true href=#algebraic-identities-for-linear-operators-on-associative-triple-systems-long-versionhttpsarxivorgabs251204190v1>#</a></h3><p><strong>Authors:</strong> Murray R. Bremner
<strong>Venue:</strong> arXiv (2025)</p><p>We present the first classification of algebraic identities in 3 variables for linear operators on associative structures. We work in the context of associative triple systems, but since any associative algebra with product $xy$ becomes an associative triple system with product $xyz$, our results apply to associative algebras as well. This is the first time that Rota&rsquo;s classification problem for linear operators has been extended to algebras with an $n$-ary operation for $n \ge 3$. Our work is an application of computational linear algebra to the classification problem for linear operators. We begin with a generic operator identity with indeterminate coefficients. From this we use operadic partial compositions to derive a large sparse matrix whose nonzero entries are the indeterminates. We follow the rank principle which states that significant operator identities correspond to coefficients which produce submaximal rank of the matrix. For operator identities of multiplicity 1 (each term contains the operator once) we obtain 6 families with 1 parameter, and 1 isolated solution. For multiplicity 2, we obtain 6 families with 2 parameters, 27 families with 1 parameter, and 9 isolated solutions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04190v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04190v1">üìÑ Download PDF</a></p><hr><h3 id=learning-group-actions-in-disentangled-latent-image-representationshttpsarxivorgabs251204015v1><a href=https://arxiv.org/abs/2512.04015v1>Learning Group Actions In Disentangled Latent Image Representations</a><a hidden class=anchor aria-hidden=true href=#learning-group-actions-in-disentangled-latent-image-representationshttpsarxivorgabs251204015v1>#</a></h3><p><strong>Authors:</strong> Farhana Hossain Swarnali, Miaomiao Zhang, Tonmoy Hossain
<strong>Venue:</strong> arXiv (2025)</p><p>Modeling group actions on latent representations enables controllable transformations of high-dimensional image data. Prior works applying group-theoretic priors or modeling transformations typically operate in the high-dimensional data space, where group actions apply uniformly across the entire input, making it difficult to disentangle the subspace that varies under transformations. While latent-space methods offer greater flexibility, they still require manual partitioning of latent variables into equivariant and invariant subspaces, limiting the ability to robustly learn and operate group actions within the representation space. To address this, we introduce a novel end-to-end framework that for the first time learns group actions on latent image manifolds, automatically discovering transformation-relevant structures without manual intervention. Our method uses learnable binary masks with straight-through estimation to dynamically partition latent representations into transformation-sensitive and invariant components. We formulate this within a unified optimization framework that jointly learns latent disentanglement and group transformation mappings. The framework can be seamlessly integrated with any standard encoder-decoder architecture. We validate our approach on five 2D/3D image datasets, demonstrating its ability to automatically learn disentangled latent factors for group actions in diverse data, while downstream classification tasks confirm the effectiveness of the learned representations. Our code is publicly available at <a href=https://github.com/farhanaswarnali/Learning-Group-Actions-In-Disentangled-Latent-Image-Representations>https://github.com/farhanaswarnali/Learning-Group-Actions-In-Disentangled-Latent-Image-Representations</a> .</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04015v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04015v1">üìÑ Download PDF</a></p><hr><h3 id=separating-halo-and-disk-stars-in-galaxies-with-fuzzy-set-theoryhttpsarxivorgabs251203965v1><a href=https://arxiv.org/abs/2512.03965v1>Separating halo and disk stars in galaxies with Fuzzy Set Theory</a><a hidden class=anchor aria-hidden=true href=#separating-halo-and-disk-stars-in-galaxies-with-fuzzy-set-theoryhttpsarxivorgabs251203965v1>#</a></h3><p><strong>Authors:</strong> Amit Mondal, Biswajit Pandey
<strong>Venue:</strong> arXiv (2025)</p><p>Disk and halo stars are generally classified using several conventional methods, such as the Toomre diagram, sharp cuts in metallicity ([Fe/H]), vertical distance ($\left|Z\right|$) from the Galactic plane, or thresholds on the orbital circularity parameter ($Œµ$). However, all these methods rely on hard selection cuts, which either contaminate samples when relaxed or exclude genuine members when applied too strictly, leading to uncertain and biased classifications. We develop a flexible and reliable approach to classify disk and halo stars in galaxies by applying fuzzy set theory, which can overcome the limitations of traditional hard-cut selection methods. As a case study, we analyze one of the Milky Way/M31-like galaxies in the TNG50 catalogue. We consider multiple stellar properties as fuzzy variables and characterize their variations between disk and halo stars to construct the respective membership functions. These functions are then combined to assign each star a membership degree corresponding to its galactic component. Our fuzzy set approach provides a more realistic distinction between the disk and the halo stars. This method effectively reduces contamination and recovers genuine members that are often excluded by rigid selection criteria. The fuzzy set theory framework offers a robust alternative to conventional hard-cut methods, enabling more accurate and physically meaningful separation of stellar populations in galaxies.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03965v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03965v1">üìÑ Download PDF</a></p><hr><h3 id=data-dependent-complexity-of-first-order-methods-for-binary-classificationhttpsarxivorgabs251203947v1><a href=https://arxiv.org/abs/2512.03947v1>Data-Dependent Complexity of First-Order Methods for Binary Classification</a><a hidden class=anchor aria-hidden=true href=#data-dependent-complexity-of-first-order-methods-for-binary-classificationhttpsarxivorgabs251203947v1>#</a></h3><p><strong>Authors:</strong> Matthew Hough, Stephen A. Vavasis
<strong>Venue:</strong> arXiv (2025)</p><p>Large-scale problems in data science are often modeled with optimization, and the optimization model is usually solved with first-order methods that may converge at a sublinear rate. Therefore, it is of interest to terminate the optimization algorithm as soon as the underlying data science task is accomplished. We consider FISTA for solving two binary classification problems: the ellipsoid separation problem (ESP), and the soft-margin support-vector machine (SVM). For the ESP, we cast the dual second-order cone program into a form amenable to FISTA and show that the FISTA residual converges to the infimal displacement vector of the primal-dual hybrid gradient (PDHG) algorithm, that directly encodes a separating hyperplane. We further derive a data-dependent iteration upper bound scaling as $\mathcal{O}(1/Œ¥_{\mathcal{A}}^2)$, where $Œ¥_{\mathcal{A}}$ is the minimal perturbation that destroys separability. For the SVM, we propose a strongly-concave perturbed dual that admits efficient FISTA updates under a linear time projection scheme, and with our parameter choices, the objective has small condition number, enabling rapid convergence. We prove that, under a reasonable data model, early-stopped iterates identify well-classified points and yield a hyperplane that exactly separates them, where the accuracy required of the dual iterate is governed by geometric properties of the data. In particular, the proposed early-stopping criteria diminish the need for hard-to-select tolerance-based stopping conditions. Our numerical experiments on ESP instances derived from MNIST data and on soft-margin SVM benchmarks indicate competitive runtimes and substantial speedups from stopping early.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03947v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03947v1">üìÑ Download PDF</a></p><hr><h3 id=well-rounded-ideal-lattices-from-totally-definite-quaternion-algebrashttpsarxivorgabs251203909v1><a href=https://arxiv.org/abs/2512.03909v1>Well-rounded ideal lattices from totally definite quaternion algebras</a><a hidden class=anchor aria-hidden=true href=#well-rounded-ideal-lattices-from-totally-definite-quaternion-algebrashttpsarxivorgabs251203909v1>#</a></h3><p><strong>Authors:</strong> Yuan Xiang Chew, Fr√©d√©rique Oggier
<strong>Venue:</strong> arXiv (2025)</p><p>We study well-rounded ideal lattices from totally definite quaternion algebras. We prove existence and classification results, and illustrate our methods with examples.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03909v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03909v1">üìÑ Download PDF</a></p><hr><h3 id=adhera-a-human-centered-health-informatics-solution-for-reducing-informal-caregiver-burden-through-improved-medication-adherencehttpsarxivorgabs251203878v1><a href=https://arxiv.org/abs/2512.03878v1>Adhera: A Human-Centered Health Informatics Solution for Reducing Informal Caregiver Burden through Improved Medication Adherence</a><a hidden class=anchor aria-hidden=true href=#adhera-a-human-centered-health-informatics-solution-for-reducing-informal-caregiver-burden-through-improved-medication-adherencehttpsarxivorgabs251203878v1>#</a></h3><p><strong>Authors:</strong> Zhiyin Zhou
<strong>Venue:</strong> arXiv (2025)</p><p>The growing global population of older adults, combined with ongoing healthcare workforce shortages, has increased reliance on informal caregivers, including family members and friends who provide unpaid support to individuals with chronic illnesses. Among their daily responsibilities, medication management remains one of the most demanding and error-prone tasks. Non-adherence to prescribed regimens not only undermines patient outcomes but also intensifies caregiver stress, anxiety, and fatigue. Although digital health technologies have proliferated to address adherence, most solutions focus exclusively on patients and neglect the informational and emotional needs of caregivers. This paper introduces Adhera, a caregiver-inclusive health informatics system designed to support medication adherence while reducing caregiver burden. Using a mixed-methods research design that included fifteen semi-structured caregiver interviews, sixty-five survey responses, and five pharmacist consultations, this study identified three primary challenges: caregiver stress related to uncertainty about medication intake, fragmented communication with healthcare professionals, and distrust in existing digital tools. Informed by the CeHRes Roadmap 2.0 and the Triple Bottom Line by Design and Culture (TBLD+C) framework, as well as recent co-design studies involving caregivers, Adhera integrates a sensor-equipped smart pill organizer with a mobile companion application that records intake events, sends real-time reminders, and provides caregivers with synchronized adherence data. Preliminary evaluation suggests that Adhera enhances visibility, improves caregiver confidence, and streamlines medication routines. This study contributes to the field of health informatics by demonstrating how human-centered design and collaborative frameworks can align technical innovation with empathy-driven care.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03878v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03878v1">üìÑ Download PDF</a></p><hr><h3 id=classification-of-diffusion-processes-in-dimension-d-via-the-carleman-approach-with-applications-to-models-involving-additive-multiplicative-or-square-root-noiseshttpsarxivorgabs251203857v1><a href=https://arxiv.org/abs/2512.03857v1>Classification of diffusion processes in dimension $d$ via the Carleman approach with applications to models involving additive, multiplicative or square-root noises</a><a hidden class=anchor aria-hidden=true href=#classification-of-diffusion-processes-in-dimension-d-via-the-carleman-approach-with-applications-to-models-involving-additive-multiplicative-or-square-root-noiseshttpsarxivorgabs251203857v1>#</a></h3><p><strong>Authors:</strong> Cecile Monthus
<strong>Venue:</strong> arXiv (2025)</p><p>The Carleman approach is well-known in the field of deterministic classical dynamics as a method to replace a finite number $d$ of non-linear differential equations by an infinite-dimensional linear system. Here this approach is applied to a system of $d$ stochastic differential equations for $[x_1(t),..,x_d(t)]$ when the forces and the diffusion-matrix elements are polynomials, in order to write the linear system governing the dynamics of the averaged values ${\mathbb E} ( x_1^{n_1}(t) x_2^{n_2}(t) &mldr; x_d^{n_d}(t) )$ labelled by the $d$ integers $(n_1,..,n_d)$. The natural decomposition of the Carleman matrix into blocks associated to the global degree $n=n_1+n_2+..+n_d$ is useful to identify the models that have the simplest spectral decompositions in the bi-orthogonal basis of right and left eigenvectors. This analysis is then applied to models with a single noise per coordinate, that can be either additive or multiplicative or square-root, or with two types of noises per coordinate, with many examples in dimensions $d=1,2$. In $d=1$, the Carleman matrix governing the dynamics of the moments ${\mathbb E} ( x^{n}(t) )$ is diagonal for the Geometric Brownian motion, while it is lower-triangular for the family of Pearson diffusions containing the Ornstein-Uhlenbeck and the Square-Root processes, as well as the Kesten, the Fisher-Snedecor and the Student processes that converge towards steady states with power-law-tails. In dimension $d=2$, the Carleman matrix governing the dynamics of the correlations ${\mathbb E} ( x_1^{n_1}(t) x_2^{n_2}(t) )$ has a natural decomposition into blocks associated to the global degree $n=n_1+n_2$, and we discuss the simplest models where the Carleman matrix is either block-diagonal or block-lower-triangular or block-upper-triangular.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03857v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03857v1">üìÑ Download PDF</a></p><hr><h3 id=pulse-a-unified-multi-task-architecture-for-cardiac-segmentation-diagnosis-and-few-shot-cross-modality-clinical-adaptationhttpsarxivorgabs251203848v1><a href=https://arxiv.org/abs/2512.03848v1>PULSE: A Unified Multi-Task Architecture for Cardiac Segmentation, Diagnosis, and Few-Shot Cross-Modality Clinical Adaptation</a><a hidden class=anchor aria-hidden=true href=#pulse-a-unified-multi-task-architecture-for-cardiac-segmentation-diagnosis-and-few-shot-cross-modality-clinical-adaptationhttpsarxivorgabs251203848v1>#</a></h3><p><strong>Authors:</strong> Hania Ghouse, Maryam Alsharqi, Farhad R. Nezami, Muzammil Behzad
<strong>Venue:</strong> arXiv (2025)</p><p>Cardiac image analysis remains fragmented across tasks: anatomical segmentation, disease classification, and grounded clinical report generation are typically handled by separate networks trained under different data regimes. No existing framework unifies these objectives within a single architecture while retaining generalization across imaging modalities and datasets. We introduce PULSE, a multi-task vision-language framework built on self-supervised representations and optimized through a composite supervision strategy that balances region overlap learning, pixel wise classification fidelity, and boundary aware IoU refinement. A multi-scale token reconstruction decoder enables anatomical segmentation, while shared global representations support disease classification and clinically grounded text output allowing the model to transition from pixels to structures and finally clinical reasoning within one architecture. Unlike prior task-specific pipelines, PULSE learns task-invariant cardiac priors, generalizes robustly across datasets, and can be adapted to new imaging modalities with minimal supervision. This moves the field closer to a scalable, foundation style cardiac analysis framework.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03848v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03848v1">üìÑ Download PDF</a></p><hr><h3 id=a-tangential-low-rank-adi-method-for-solving-indefinite-lyapunov-equationshttpsarxivorgabs251204983v1><a href=https://arxiv.org/abs/2512.04983v1>A tangential low-rank ADI method for solving indefinite Lyapunov equations</a><a hidden class=anchor aria-hidden=true href=#a-tangential-low-rank-adi-method-for-solving-indefinite-lyapunov-equationshttpsarxivorgabs251204983v1>#</a></h3><p><strong>Authors:</strong> Rudi Smith, Steffen W. R. Werner
<strong>Venue:</strong> arXiv (2025)</p><p>Continuous-time algebraic Lyapunov equations have become an essential tool in various applications. In the case of large-scale sparse coefficient matrices and indefinite constant terms, indefinite low-rank factorizations have successfully been used to allow methods like the alternating direction implicit (ADI) iteration to efficiently compute accurate approximations to the solution of the Lyapunov equation. However, classical block-type approaches quickly increase in computational costs when the rank of the constant term grows. In this paper, we propose a novel tangential reformulation of the ADI iteration that allows for the efficient construction of low-rank approximations to the solution of Lyapunov equations with indefinite right-hand sides even in the case of constant terms with higher ranks. We provide adaptive methods for the selection of the corresponding ADI parameters, namely shifts and tangential directions, which allow for the automatic application of the method to any relevant problem setting. The effectiveness of the developed algorithms is illustrated by several numerical examples.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04983v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04983v1">üìÑ Download PDF</a></p><hr><h3 id=multipole-decomposition-of-the-gravitational-field-of-a-point-mass-at-the-black-hole-horizonhttpsarxivorgabs251204976v1><a href=https://arxiv.org/abs/2512.04976v1>Multipole decomposition of the gravitational field of a point mass at the black hole horizon</a><a hidden class=anchor aria-hidden=true href=#multipole-decomposition-of-the-gravitational-field-of-a-point-mass-at-the-black-hole-horizonhttpsarxivorgabs251204976v1>#</a></h3><p><strong>Authors:</strong> Jo√£o P. B. Brito, Atsushi Higuchi, Lu√≠s C. B. Crispino
<strong>Venue:</strong> arXiv (2025)</p><p>The portion of the gravitational energy absorbed by the black hole due to the radial infall of a point mass is known to diverge at leading order in perturbation theory. This divergence is an artifact of the point-particle model, where the contribution of each multipole to the total absorbed energy is observed to be roughly constant. We show explicitly that this divergent energy arises from the infinite energy present in the singular static field arbitrarily close to the point mass, which also flows into the black hole when the particle trajectory crosses the horizon. We perform a multipole decomposition of the linearized gravitational field generated by the point mass near its world line at the black hole horizon. By applying the standard field-theoretical approach to the particle field, we compute the corresponding partial energy and find that it matches the constant multipole contribution.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04976v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04976v1">üìÑ Download PDF</a></p><hr><h3 id=on-world-volume-supersymmetry-of-supermembrane-action-in-static-gaugehttpsarxivorgabs251204948v1><a href=https://arxiv.org/abs/2512.04948v1>On world-volume supersymmetry of supermembrane action in static gauge</a><a hidden class=anchor aria-hidden=true href=#on-world-volume-supersymmetry-of-supermembrane-action-in-static-gaugehttpsarxivorgabs251204948v1>#</a></h3><p><strong>Authors:</strong> Arkady A. Tseytlin, Zihan Wang
<strong>Venue:</strong> arXiv (2025)</p><p>We review and elaborate on the issue of 3d world volume supersymmetry that appears as a residual part of global target space supersymmetry in the BST supermembrane action. While there is no direct ``spinning membrane&rsquo;&rsquo; analog of the world-volume supersymmetric spinning string action that could be obtained by coupling $D$ copies of 3d scalar multiplet to 3d supergravity, we discuss how one may construct an $N=1$ 3d supersymmetric analog of the derivative expansion of the bosonic membrane action in static gauge. We compare the resulting $N=1$ supersymmetric action for eight 3d scalar multiplets to the $N=8$ 3d supersymmetric action describing the $D=11$ supermembrane in the static gauge. The two actions are not equivalent which is related to the fact that the full $N=8$ supersymmetry of the static-gauge $D=11$ supermembrane action can be realised only if the fermions are described by an $SO(8)$ spinor rather than vector. The two actions are still directly related in special dimensions $D=4$ and 5. We also compute the one-loop world-volume scattering amplitudes for the two theories, finding that they indeed agree for $D=4,5$ but disagree for $D=11$.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04948v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04948v1">üìÑ Download PDF</a></p><hr><h3 id=in-search-of-the-electron-phonon-contribution-to-total-energyhttpsarxivorgabs251204897v1><a href=https://arxiv.org/abs/2512.04897v1>In search of the electron-phonon contribution to total energy</a><a hidden class=anchor aria-hidden=true href=#in-search-of-the-electron-phonon-contribution-to-total-energyhttpsarxivorgabs251204897v1>#</a></h3><p><strong>Authors:</strong> Samuel Ponc√©, Xavier Gonze
<strong>Venue:</strong> arXiv (2025)</p><p>The total energy is a fundamental characteristic of solids, molecules, and nanostructures. In most first-principles calculations of the total energy, the nuclear kinetic operator is decoupled from the many-body electronic Hamiltonian and the dynamics of the nuclei is reintroduced afterwards. This two-step procedure introduced by Born and Oppenheimer (BO) is approximate. Energies beyond the electronic and vibrational (or phononic) main contributions might be relevant when small energy differences are important, such as when predicting stable polymorphs or describing magnetic energy landscape. We clarify the different flavors of BO decoupling and give an exact formulation for the total energy in the basis of BO electronic wavefunctions. Then, we list contributions, beyond the main ones, that appear in a perturbative expansion in powers of $M_0^{-1/4}$, where $M_0$ is a typical nuclear mass, up to sixth order. Some of these might be grouped and denoted the electron-phonon contribution to total energy, $E^{\textrm{elph}}$, that first appears at fourth order. The electronic inertial mass contributes at sixth order. We clarify that the sum of the Allen-Heine-Cardona zero-point renormalization of eigenvalues over occupied states is not the electron-phonon contribution to the total energy but a part of the phononic contribution. The computation of the lowest-order $E^{\textrm{elph}}$ is implemented and shown to be small but non-negligible (3.8 meV per atom) in the case of diamond and its hexagonal polymorph. We also estimate the electronic inertial mass contribution and confirm the size-consistency of all computed terms.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04897v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04897v1">üìÑ Download PDF</a></p><hr><h3 id=decoy-state-quantum-key-distribution-over-227-km-with-a-frequency-converted-telecom-single-photon-sourcehttpsarxivorgabs251205101v1><a href=https://arxiv.org/abs/2512.05101v1>Decoy-state quantum key distribution over 227 km with a frequency-converted telecom single-photon source</a><a hidden class=anchor aria-hidden=true href=#decoy-state-quantum-key-distribution-over-227-km-with-a-frequency-converted-telecom-single-photon-sourcehttpsarxivorgabs251205101v1>#</a></h3><p><strong>Authors:</strong> Frederik Brooke Barnes, Roberto G. Pousa, Christopher L. Morrison, Zhe Xian Koong, Joseph Ho, Francesco Graffitti, John Jeffers, Daniel K. L. Oi, Brian D. Gerardot, Alessandro Fedrizzi
<strong>Venue:</strong> arXiv (2025)</p><p>We implement a decoy-state quantum key distribution scheme using a telecom C-band single-emitter source. The decoy states are created by varying the optical excitation of the quantum emitter to modulate the photon number distribution. We provide an analysis of our scheme based on existing security proofs, allowing the calculation of secret key rates including finite key effects. This enables us to demonstrate, with a realistic single-photon source, positive secret key rates using our scheme over 227 km of optical fiber, equivalent to a loss tolerance one order of magnitude greater than non-decoy schemes. This work broadens the scope of single-photon sources in future quantum networks by enabling long-distance QKD with realistic levels of single-photon purity.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05101v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05101v1">üìÑ Download PDF</a></p><hr><h3 id=performance-analysis-of-fluid-reconfigurable-intelligent-surface-over-covert-communicationshttpsarxivorgabs251205085v1><a href=https://arxiv.org/abs/2512.05085v1>Performance Analysis of Fluid Reconfigurable Intelligent Surface over Covert Communications</a><a hidden class=anchor aria-hidden=true href=#performance-analysis-of-fluid-reconfigurable-intelligent-surface-over-covert-communicationshttpsarxivorgabs251205085v1>#</a></h3><p><strong>Authors:</strong> Farshad Rostami Ghadi, Masoud Kaveh, Hanjiang Hong, Kai-Kit Wong, Riku Jantti, F. Javier Lopez-Martinez
<strong>Venue:</strong> arXiv (2025)</p><p>This paper investigates the impact of the recently proposed concept of fluid reconfigurable intelligent surfaces (FRIS) on covert communications. Specifically, we consider a communication scenario where a legitimate transmitter aims to covertly deliver information to its intended receiver through a planar FRIS, while an adversary attempts to detect whether any transmission is occurring. In this context, we analyze the false alarm (FA) and missed detection (MD) probabilities, and derive a closed-form expression for the covertness outage probability (COP). Furthermore, the success probability is characterized under the optimal detection threshold, providing new insights into the trade-off between covertness and reliable transmission. Numerical results reveal that FRIS provides a clear advantage over fixed-position RIS at low-to-moderate transmit powers by improving reliability and enhancing covertness, while at very high power levels, fixed-position RIS may sustain slightly higher success probability due to reduced leakage toward the adversary.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05085v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05085v1">üìÑ Download PDF</a></p><hr><h3 id=hybrid-nehari-schauder-type-fixed-point-results-and-applicationshttpsarxivorgabs251205054v1><a href=https://arxiv.org/abs/2512.05054v1>Hybrid Nehari-Schauder type fixed point results and applications</a><a hidden class=anchor aria-hidden=true href=#hybrid-nehari-schauder-type-fixed-point-results-and-applicationshttpsarxivorgabs251205054v1>#</a></h3><p><strong>Authors:</strong> Radu Precup, Andrei Stan
<strong>Venue:</strong> arXiv (2025)</p><p>This paper develops a fixed point version of the well-known Nehari manifold method from critical point theory. The main result is formulated for systems of operator equations, relying on the fixed point theorems of Schauder and Schaefer. The framework also allows for potential extensions combining our Nehari type approach with other fixed point principles. To demonstrate the applicability of the method, an example involving a system of nonlinear integral equations is provided.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05054v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05054v1">üìÑ Download PDF</a></p><hr><h3 id=impact-of-power-outages-on-the-adoption-of-residential-solar-photovoltaic-in-a-changing-climatehttpsarxivorgabs251205027v1><a href=https://arxiv.org/abs/2512.05027v1>Impact of power outages on the adoption of residential solar photovoltaic in a changing climate</a><a hidden class=anchor aria-hidden=true href=#impact-of-power-outages-on-the-adoption-of-residential-solar-photovoltaic-in-a-changing-climatehttpsarxivorgabs251205027v1>#</a></h3><p><strong>Authors:</strong> Jiashu Zhu, Wenbin Zhou, Laura Diaz Anadon, Shixiang Zhu
<strong>Venue:</strong> arXiv (2025)</p><p>Residential solar photovoltaic (PV) systems are a cornerstone of residential decarbonization and energy resilience. However, most existing systems are PV-only and cannot provide backup power during grid failures. Here, we present a high-resolution analysis of 377,726 households in Indianapolis, US, quantifying how power outages influence the installation of PV-only systems between 2014 and 2023. Using a two-part econometric panel model, we estimate the causal effect of power outage exposure and project future risks under a middle of the road climate scenario (RCP 4.5). We find that each additional hour of annual outage duration per household lowers the new-installation rate by 0.012 percentage points per year, equivalent to a 31% decline relative to the historical mean (2014-2023). With outage duration and frequency projected to double by 2040, these results reveal a potential vicious cycle between grid unreliability and slower decarbonization, calling for policies that integrate grid resilience and clean-energy goals.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05027v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05027v1">üìÑ Download PDF</a></p><hr><h3 id=geophysical-intensity-problems-the-axisymmetric-casehttpsarxivorgabs251205010v1><a href=https://arxiv.org/abs/2512.05010v1>Geophysical intensity problems: the axisymmetric case</a><a hidden class=anchor aria-hidden=true href=#geophysical-intensity-problems-the-axisymmetric-casehttpsarxivorgabs251205010v1>#</a></h3><p><strong>Authors:</strong> Ralf Kaiser
<strong>Venue:</strong> arXiv (2025)</p><p>Considering the earth or any other celestial body the main sources of the gravitational as well as of the magnetic field lie inside the body. Above the surface both fields are in good approximation harmonic vector fields determined by their values at the body&rsquo;s surface or any other surface enclosing the body. The intensity problem seeks to determine harmonic vector fields vanishing at infinity and with prescribed intensity of the field at the surface. This problem constitutes a nonlinear boundary value problem, whose general solvability is not yet established. In this paper {\em axisymmetric} harmonic fields ${\bf H}$ outside the unit sphere $S^2$ are studied and, given an axisymmetric H√∂lder continuous intensity function $I\neq 0$ on $S^2$, the existence of infinitely many solutions of the intensity problem is proved. These solutions can more precisely be characterized as follows: fix a number $\de \in \nat\setminus {1 }$ and a meridional plane $M$ through the symmetry axis $S!A$, and in $M$ a unit circle $S^1$ (symmetric with respect to $S!A$) and, furthermore, $2, N$, $N \in \nat_0$, points $z_n \in M$ (symmetric with respect to $S!A$, avoiding $S!A$, and outside $S^1$), then the existence of an (up to a sign) unique harmonic field ${\bf H}$ is established that vanishes at (the axisymmetric circles piercing $M$ at) $z_n$ and nowhere else, that has intensity $I$ at $S^2$ and (exact) decay order $\de$ at infinity. The proof is based on the solution of a nonlinear elliptic equation with discontinuous coefficients, which are, moreover, singular at the symmetry axis. Its combination with fixed boundary conditions was the basis of a recent treatment of the ``geomagnetic direction problem&rsquo;&rsquo; \cite{KR22}. Here we have instead natural boundary conditions, which provide less information, and which require, therefore, in part new solution techniques and sharper estimates.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05010v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05010v1">üìÑ Download PDF</a></p><hr><h3 id=fractured-poroelastic-media-in-the-limit-of-vanishing-aperturehttpsarxivorgabs251204978v1><a href=https://arxiv.org/abs/2512.04978v1>Fractured Poroelastic Media in the Limit of Vanishing Aperture</a><a hidden class=anchor aria-hidden=true href=#fractured-poroelastic-media-in-the-limit-of-vanishing-aperturehttpsarxivorgabs251204978v1>#</a></h3><p><strong>Authors:</strong> Maximilian H√∂rl, Kundan Kumar, Christian Rohde
<strong>Venue:</strong> arXiv (2025)</p><p>We consider a poroelastic medium with a thin heterogeneity, also referred to as a fracture. Fluid flow and mechanical deformation inside both bulk and fracture are governed by the quasi-static Biot equations. The fracture&rsquo;s material parameters, such as hydraulic conductivity and elasticity, are assumed to scale with powers of the width-to-length ratio $\varepsilon$ of the fracture. Based on a priori estimates, we rigorously derive limit models as $\varepsilon \rightarrow 0$ and identify different limit regimes. We obtain five regimes for the hydraulic conductivity and two for the elasticity. While many cases yield discrete fracture models, others result in two-scale limit problems dominated by normal flow or deformation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04978v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04978v1">üìÑ Download PDF</a></p><hr><h3 id=mittag-leffler-functions-and-convex-orderinghttpsarxivorgabs251204940v1><a href=https://arxiv.org/abs/2512.04940v1>Mittag-Leffler functions and convex ordering</a><a hidden class=anchor aria-hidden=true href=#mittag-leffler-functions-and-convex-orderinghttpsarxivorgabs251204940v1>#</a></h3><p><strong>Authors:</strong> Rui Ferreira, Thomas Simon
<strong>Venue:</strong> arXiv (2025)</p><p>The monotonicity of the Mittag-Leffler function $E_Œ±$ with respect to the parameter $Œ±$ is investigated, via some convex ordering properties for related random variables. In particular, it is shown that the mapping $Œ±\mapsto E_Œ±(x^Œ±)$ decreases on $(0,2)$ for all $x> 0$, that the mapping $Œ±\mapsto E_Œ±(-x^Œ±)$ decreases on $(0,1)$ for all $x\ge 1$ and that the mapping $Œ±\mapsto E_Œ±(Œì(1+Œ±)x)$ decreases on $(0,1)$ for all $x\in{\mathbb R}^\ast.$ Analogous results are presented for the two parameter Mittag-Leffler functions $E_{Œ±, Œ≤}$ with $Œ≤\ge Œ±,$ with an emphasis on the extremal case $Œ≤=Œ±.$ Several applications of these results are discussed for Abelian integral equations and subdiffusions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04940v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04940v1">üìÑ Download PDF</a></p><hr><h3 id=next-order-asymptotics-for-the-volume-of-schatten-ballshttpsarxivorgabs251204933v1><a href=https://arxiv.org/abs/2512.04933v1>Next-order asymptotics for the volume of Schatten balls</a><a hidden class=anchor aria-hidden=true href=#next-order-asymptotics-for-the-volume-of-schatten-ballshttpsarxivorgabs251204933v1>#</a></h3><p><strong>Authors:</strong> Mathias Sonnleitner
<strong>Venue:</strong> arXiv (2025)</p><p>The volume of the unit balls of self-adjoint finite-dimensional Schatten $p$-classes of $n\times n$-matrices, $1\le p\le \infty$, is only known exactly for $p=2$ and $p=\infty$. We give an asymptotic expansion of the logarithmic volume to order $o(n)$ for general $p\ge\frac{3}{2}$. The proof rests on asymptotics for the partition function of $Œ≤$-ensembles due to Lebl√© and Serfaty [Invent. Math. 210(3):645&ndash;757, 2017]. Independently, the case $p\ge 2$ was obtained by Dworaczek Guera, Memin and Pain [arXiv:2511.05386]. In the complex case the asymptotic expansion is continued to order $O(1)$ for all $p\ge 1$.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04933v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04933v1">üìÑ Download PDF</a></p><hr><h3 id=weak-convergence-rates-for-spectral-regularization-via-sampling-inequalitieshttpsarxivorgabs251204929v1><a href=https://arxiv.org/abs/2512.04929v1>Weak convergence rates for spectral regularization via sampling inequalities</a><a hidden class=anchor aria-hidden=true href=#weak-convergence-rates-for-spectral-regularization-via-sampling-inequalitieshttpsarxivorgabs251204929v1>#</a></h3><p><strong>Authors:</strong> Sabrina Guastavino, Gabriele Santin, Francesco Marchetti, Federico Benvenuto
<strong>Venue:</strong> arXiv (2025)</p><p>Convergence rates in spectral regularization methods quantify the approximation error in inverse problems as a function of the noise level or the number of sampling points. Classical strong convergence rate results typically rely on source conditions, which are essential for estimating the truncation error. However, in the framework of kernel approximation, the truncation error in the case of Tikhonov regularization can be characterized entirely through sampling inequalities, without invoking source conditions. In this paper, we first generalize sampling inequalities to spectral regularization, and then, by exploiting the connection between inverse problems and kernel approximation, we derive weak convergence rate bounds for inverse problems, independently of source conditions. These weak convergence rates are established and analyzed when the forward operator is compact and uniformly bounded, or the kernel operator is of trace class.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04929v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04929v1">üìÑ Download PDF</a></p><hr><h3 id=quantitative-rigidity-of-the-wasserstein-contraction-under-convolutionhttpsarxivorgabs251204928v1><a href=https://arxiv.org/abs/2512.04928v1>Quantitative rigidity of the Wasserstein contraction under convolution</a><a hidden class=anchor aria-hidden=true href=#quantitative-rigidity-of-the-wasserstein-contraction-under-convolutionhttpsarxivorgabs251204928v1>#</a></h3><p><strong>Authors:</strong> Max Fathi, Michael Goldman, Daniel Tsodyks
<strong>Venue:</strong> arXiv (2025)</p><p>The aim of this paper is to investigate the contraction properties of $p$-Wasserstein distances with respect to convolution in Euclidean spaces both qualitatively and quantitatively. We connect this question to the question of uniform convexity of the Kantorovich functional on which there was substantial recent progress (mostly for $p=2$ and partially for $p>1$). Motivated by this connection we extend these uniform convexity results to the case $p=1$, which is of independent interest.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04928v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04928v1">üìÑ Download PDF</a></p><hr><h3 id=side-by-side-first-price-auctions-with-imperfect-biddershttpsarxivorgabs251204850v1><a href=https://arxiv.org/abs/2512.04850v1>Side-by-side first-price auctions with imperfect bidders</a><a hidden class=anchor aria-hidden=true href=#side-by-side-first-price-auctions-with-imperfect-biddershttpsarxivorgabs251204850v1>#</a></h3><p><strong>Authors:</strong> Benjamin Heymann
<strong>Venue:</strong> arXiv (2025)</p><p>We model a procurement scenario in which two \textit{imperfect} bidders act simultaneously on behalf of a single buyer, a configuration common in display advertising and referred to as \textit{side-by-side bidding} but largely unexplored in theory. We prove that the iterated best response algorithm converges to an equilibrium under standard distributional assumptions and provide sufficient condition for uniqueness. Beyond establishing existence and convergence, our analysis provides a tractable numerical method for quantitative studies of side-by-side procurement.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04850v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04850v1">üìÑ Download PDF</a></p><hr><h3 id=aim-resolve-automatic-identification-and-modeling-for-bayesian-radio-interferometric-imaginghttpsarxivorgabs251204840v1><a href=https://arxiv.org/abs/2512.04840v1>aim-resolve: Automatic Identification and Modeling for Bayesian Radio Interferometric Imaging</a><a hidden class=anchor aria-hidden=true href=#aim-resolve-automatic-identification-and-modeling-for-bayesian-radio-interferometric-imaginghttpsarxivorgabs251204840v1>#</a></h3><p><strong>Authors:</strong> Richard Fuchs, Jakob Knollm√ºller, Jakob Roth, Vincent Eberle, Philipp Frank, Torsten A. En√ülin, Lukas Heinrich
<strong>Venue:</strong> arXiv (2025)</p><p>Modern radio interferometers deliver large volumes of data containing high-sensitivity sky maps over wide fields-of-view. These large area observations can contain various and superposed structures such as point sources, extended objects, and large-scale diffuse emission. To fully realize the potential of these observations, it is crucial to build appropriate sky emission models which separate and reconstruct the underlying astrophysical components. We introduce aim-resolve, an automatic and iterative method that combines the Bayesian imaging algorithm resolve with deep learning and clustering algorithms in order to jointly solve the reconstruction and source extraction problem. The method identifies and models different astrophysical components in radio observations while providing uncertainty quantification of the results. By using different model descriptions for point sources, extended objects, and diffuse background emission, the method efficiently separates the individual components and improves the overall reconstruction. We demonstrate the effectiveness of this method on synthetic image data containing multiple different sources. We further show the application of aim-resolve to an L-band (856 - 1712 MHz) MeerKAT observation of the radio galaxy ESO 137-006 and other radio galaxies in that environment. We observe a reasonable object identification for both applications, yielding a clean separation of the individual components and precise reconstructions of point sources and extended objects along with detailed uncertainty quantification. In particular, the method enables the creation of catalogs containing source positions and brightnesses and the corresponding uncertainties. The full decoupling of sky emission model and instrument response makes the method applicable to a wide variety of instruments or wavelength bands.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04840v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04840v1">üìÑ Download PDF</a></p><hr><h3 id=a-tutorial-on-regression-analysis-from-linear-models-to-deep-learning----lecture-notes-on-artificial-intelligencehttpsarxivorgabs251204747v1><a href=https://arxiv.org/abs/2512.04747v1>A Tutorial on Regression Analysis: From Linear Models to Deep Learning &ndash; Lecture Notes on Artificial Intelligence</a><a hidden class=anchor aria-hidden=true href=#a-tutorial-on-regression-analysis-from-linear-models-to-deep-learning----lecture-notes-on-artificial-intelligencehttpsarxivorgabs251204747v1>#</a></h3><p><strong>Authors:</strong> Jingyuan Wang, Jiahao Ji
<strong>Venue:</strong> arXiv (2025)</p><p>This article serves as the regression analysis lecture notes in the Intelligent Computing course cluster (including the courses of Artificial Intelligence, Data Mining, Machine Learning, and Pattern Recognition). It aims to provide students &ndash; who are assumed to possess only basic university-level mathematics (i.e., with prerequisite courses in calculus, linear algebra, and probability theory) &ndash; with a comprehensive and self-contained understanding of regression analysis without requiring any additional references. The lecture notes systematically introduce the fundamental concepts, modeling components, and theoretical foundations of regression analysis, covering linear regression, logistic regression, multinomial logistic regression, polynomial regression, basis-function models, kernel-based methods, and neural-network-based nonlinear regression. Core methodological topics include loss-function design, parameter-estimation principles, ordinary least squares, gradient-based optimization algorithms and their variants, as well as regularization techniques such as Ridge and LASSO regression. Through detailed mathematical derivations, illustrative examples, and intuitive visual explanations, the materials help students understand not only how regression models are constructed and optimized, but also how they reveal the underlying relationships between features and response variables. By bridging classical statistical modeling and modern machine-learning practice, these lecture notes aim to equip students with a solid conceptual and technical foundation for further study in advanced artificial intelligence models.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04747v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04747v1">üìÑ Download PDF</a></p><hr><h3 id=accelerating-discovery-of-infrared-nonlinear-optical-materials-with-large-shift-current-via-high-throughput-screeninghttpsarxivorgabs251204717v1><a href=https://arxiv.org/abs/2512.04717v1>Accelerating discovery of infrared nonlinear optical materials with large shift current via high-throughput screening</a><a hidden class=anchor aria-hidden=true href=#accelerating-discovery-of-infrared-nonlinear-optical-materials-with-large-shift-current-via-high-throughput-screeninghttpsarxivorgabs251204717v1>#</a></h3><p><strong>Authors:</strong> Aiqin Yang, Dian Jin, Mingkang Liu, Daye Zheng, Qi Wang, Qiangqiang Gu, Jian-Hua Jiang
<strong>Venue:</strong> arXiv (2025)</p><p>Discovering nonlinear optical (NLO) materials with strong shift current response, particularly in the infrared (IR) regime, is essential for next-generation optoelectronics yet remains highly challenging in both experiments and theory, which still largely relies on case by case studies. Here, we employ a high-throughput screening strategy, applying a multi-step filter to the Materials Project database (>154,000 materials), which yielded 2,519 candidate materials for detailed first-principle evaluation. From these calculations, we identify 32 NLO materials with strong shift current response ($œÉ$ > 100 $ŒºA/V^2$). Our work reveals that layered structures with $C_{3v}$ symmetry and heavy $p$-block elements (e.g. Te, Sb) exhibit apparent superiority in enhancing shift current. More importantly, 9 of these compounds show shift current response peaks in the IR region, with the strongest reaching 616 $ŒºA/V^2$, holding significant application potential in fields such as IR photodetection, sensing, and energy harvesting. Beyond identifying promising candidates, this work establishes a comprehensive and high-quality first-principles dataset for NLO response, providing a solid foundation for future AI-driven screening and accelerated discovery of high-performance NLO materials, as demonstrated by a prototype machine-learning application.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04717v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04717v1">üìÑ Download PDF</a></p><hr><h3 id=towards-an-ai-fluid-scientist-llm-powered-scientific-discovery-in-experimental-fluid-mechanicshttpsarxivorgabs251204716v1><a href=https://arxiv.org/abs/2512.04716v1>Towards an AI Fluid Scientist: LLM-Powered Scientific Discovery in Experimental Fluid Mechanics</a><a hidden class=anchor aria-hidden=true href=#towards-an-ai-fluid-scientist-llm-powered-scientific-discovery-in-experimental-fluid-mechanicshttpsarxivorgabs251204716v1>#</a></h3><p><strong>Authors:</strong> Haodong Feng, Lugang Ye, Dixia Fan
<strong>Venue:</strong> arXiv (2025)</p><p>The integration of artificial intelligence into experimental fluid mechanics promises to accelerate discovery, yet most AI applications remain narrowly focused on numerical studies. This work proposes an AI Fluid Scientist framework that autonomously executes the complete experimental workflow: hypothesis generation, experimental design, robotic execution, data analysis, and manuscript preparation. We validate this through investigation of vortex-induced vibration (VIV) and wake-induced vibration (WIV) in tandem cylinders. Our work has four key contributions: (1) A computer-controlled circulating water tunnel (CWT) with programmatic control of flow velocity, cylinder position, and forcing parameters (vibration frequency and amplitude) with data acquisition (displacement, force, and torque). (2) Automated experiments reproduce literature benchmarks (Khalak and Williamson [1999] and Assi et al. [2013, 2010]) with frequency lock-in within 4% and matching critical spacing trends. (3) The framework with Human-in-the-Loop (HIL) discovers more WIV amplitude response phenomena, and uses a neural network to fit physical laws from data, which is 31% higher than that of polynomial fitting. (4) The framework with multi-agent with virtual-real interaction system executes hundreds of experiments end-to-end, which automatically completes the entire process of scientific research from hypothesis generation, experimental design, experimental execution, data analysis, and manuscript preparation. It greatly liberates human researchers and improves study efficiency, providing new paradigm for the development and research of experimental fluid mechanics.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04716v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04716v1">üìÑ Download PDF</a></p><hr><h3 id=polaris-is-multi-agentic-reasoning-the-next-wave-in-engineering-self-adaptive-systemshttpsarxivorgabs251204702v1><a href=https://arxiv.org/abs/2512.04702v1>POLARIS: Is Multi-Agentic Reasoning the Next Wave in Engineering Self-Adaptive Systems?</a><a hidden class=anchor aria-hidden=true href=#polaris-is-multi-agentic-reasoning-the-next-wave-in-engineering-self-adaptive-systemshttpsarxivorgabs251204702v1>#</a></h3><p><strong>Authors:</strong> Divyansh Pandey, Vyakhya Gupta, Prakhar Singhal, Karthik Vaidhyanathan
<strong>Venue:</strong> arXiv (2025)</p><p>The growing scale, complexity, interconnectivity, and autonomy of modern software ecosystems introduce unprecedented uncertainty, challenging the foundations of traditional self-adaptation. Existing approaches, typically rule-driven controllers or isolated learning components, struggle to generalize to novel contexts or coordinate responses across distributed subsystems, leaving them ill-equipped for emergent unknown unknowns. Recent discussions on Self-Adaptation 2.0 emphasize an equal partnership between AI and adaptive systems, merging learning-driven intelligence with adaptive control for predictive and proactive behavior. Building on this foundation, we introduce POLARIS, a three-layer multi-agentic self-adaptation framework that advances beyond reactive adaptation. POLARIS integrates: (1) a low-latency Adapter layer for monitoring and safe execution, (2) a transparent Reasoning layer that generates and verifies plans using tool-aware, explainable agents, and (3) a Meta layer that records experiences and meta-learns improved adaptation policies over time. Through shared knowledge and predictive models, POLARIS handles uncertainty, learns from past actions, and evolves its strategies, enabling systems that anticipate change and maintain resilient, goal-directed behavior. Preliminary evaluation on two self-adaptive exemplars, SWIM and SWITCH, shows that POLARIS consistently outperforms state-of-the-art baselines. We argue this marks a shift toward Self-Adaptation 3.0, akin to Software 3.0: a paradigm where systems not only learn from their environment but also reason about and evolve their own adaptation processes, continuously improving to meet novel challenges.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04702v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04702v1">üìÑ Download PDF</a></p><hr><h3 id=collective-cluster-nucleation-dynamics-in-2d-ising-quantum-magnetshttpsarxivorgabs251204656v1><a href=https://arxiv.org/abs/2512.04656v1>Collective cluster nucleation dynamics in 2D Ising quantum magnets</a><a hidden class=anchor aria-hidden=true href=#collective-cluster-nucleation-dynamics-in-2d-ising-quantum-magnetshttpsarxivorgabs251204656v1>#</a></h3><p><strong>Authors:</strong> Philip Osterholz, Fabio Bensch, Shuanghong Tang, Silpa Baburaj Sheela, Igor Lesanovsky, Christian Gro√ü
<strong>Venue:</strong> arXiv (2025)</p><p>Strongly interacting many-body systems often show collective properties that are non-trivially related to the microscopic degrees of freedom. Collectivity is responsible for intriguing ground state properties, for example, in superconductors. However, collective effects may also govern the non-equilibrium response of quantum systems, not only in condensed matter physics but also in quantum field theories modeling the properties of our universe. Understanding emergent collective dynamics from first principles, in particular in non-perturbative regimes, is therefore one of the central challenges in quantum many-body physics. Here we report on the observation of collective cluster nucleation in 2D quantum Ising systems realized in an atomic Rydberg array. We observe a confined regime in which the steady-state cluster size is energy-dependent and a deconfined regime characterized by kinetically constrained dynamics of cluster nucleation. Our results mark a qualitative leap for quantum simulations with Rydberg arrays and shed light on highly collective non-equilibrium processes in one of the most important textbook models of condensed matter physics with relevance from quantum magnets and the kinetics of glass formers to cosmology.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04656v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04656v1">üìÑ Download PDF</a></p><hr><h3 id=rethinking-decoupled-knowledge-distillation-a-predictive-distribution-perspectivehttpsarxivorgabs251204625v1><a href=https://arxiv.org/abs/2512.04625v1>Rethinking Decoupled Knowledge Distillation: A Predictive Distribution Perspective</a><a hidden class=anchor aria-hidden=true href=#rethinking-decoupled-knowledge-distillation-a-predictive-distribution-perspectivehttpsarxivorgabs251204625v1>#</a></h3><p><strong>Authors:</strong> Bowen Zheng, Ran Cheng
<strong>Venue:</strong> arXiv (2025)</p><p>In the history of knowledge distillation, the focus has once shifted over time from logit-based to feature-based approaches. However, this transition has been revisited with the advent of Decoupled Knowledge Distillation (DKD), which re-emphasizes the importance of logit knowledge through advanced decoupling and weighting strategies. While DKD marks a significant advancement, its underlying mechanisms merit deeper exploration. As a response, we rethink DKD from a predictive distribution perspective. First, we introduce an enhanced version, the Generalized Decoupled Knowledge Distillation (GDKD) loss, which offers a more versatile method for decoupling logits. Then we pay particular attention to the teacher model&rsquo;s predictive distribution and its impact on the gradients of GDKD loss, uncovering two critical insights often overlooked: (1) the partitioning by the top logit considerably improves the interrelationship of non-top logits, and (2) amplifying the focus on the distillation loss of non-top logits enhances the knowledge extraction among them. Utilizing these insights, we further propose a streamlined GDKD algorithm with an efficient partition strategy to handle the multimodality of teacher models&rsquo; predictive distribution. Our comprehensive experiments conducted on a variety of benchmarks, including CIFAR-100, ImageNet, Tiny-ImageNet, CUB-200-2011, and Cityscapes, demonstrate GDKD&rsquo;s superior performance over both the original DKD and other leading knowledge distillation methods. The code is available at <a href=https://github.com/ZaberKo/GDKD>https://github.com/ZaberKo/GDKD</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04625v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04625v1">üìÑ Download PDF</a></p><hr><h3 id=the-ethics-of-generative-aihttpsarxivorgabs251204598v1><a href=https://arxiv.org/abs/2512.04598v1>The Ethics of Generative AI</a><a hidden class=anchor aria-hidden=true href=#the-ethics-of-generative-aihttpsarxivorgabs251204598v1>#</a></h3><p><strong>Authors:</strong> Michael Klenk
<strong>Venue:</strong> arXiv (2025)</p><p>This chapter discusses the ethics of generative AI. It provides a technical primer to show how generative AI affords experiencing technology as if it were human, and this affordance provides a fruitful focus for the philosophical ethics of generative AI. It then shows how generative AI can both aggravate and alleviate familiar ethical concerns in AI ethics, including responsibility, privacy, bias and fairness, and forms of alienation and exploitation. Finally, the chapter examines ethical questions that arise specifically from generative AI&rsquo;s mimetic generativity, such as debates about authorship and credit, the emergence of as-if social relationships with machines, and new forms of influence, persuasion, and manipulation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04598v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04598v1">üìÑ Download PDF</a></p><hr><h3 id=magnetocaloric-effect-measurements-in-ultrahigh-magnetic-fields-up-to-120-thttpsarxivorgabs251204509v1><a href=https://arxiv.org/abs/2512.04509v1>Magnetocaloric effect measurements in ultrahigh magnetic fields up to 120 T</a><a hidden class=anchor aria-hidden=true href=#magnetocaloric-effect-measurements-in-ultrahigh-magnetic-fields-up-to-120-thttpsarxivorgabs251204509v1>#</a></h3><p><strong>Authors:</strong> Reon Ogawa, Masaki Gen, Kazuyuki Matsuhira, Yoshimitsu Kohama
<strong>Venue:</strong> arXiv (2025)</p><p>We report proof-of-concept measurements of the magnetocaloric effect (MCE) in ultrahigh magnetic fields up to 120 T for the classical spin-ice compound Ho$<em>{2}$Ti$</em>{2}$O$<em>{7}$. Radio-frequency resistivity measurements using an Au$</em>{16}$Ge$_{84}$ thin-film thermometer enable us to detect a rapid change in the sample temperature associated with a crystal-field level crossing in the high-field region in addition to a giant MCE at low fields. We discuss a possible delay in the temperature response and outline prospects for more precise MCE measurements in destructive pulsed fields.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04509v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04509v1">üìÑ Download PDF</a></p><hr><h3 id=collective-vibrational-resonance-and-mode-selection-in-nonlinear-resonator-arrayshttpsarxivorgabs251204507v1><a href=https://arxiv.org/abs/2512.04507v1>Collective vibrational resonance and mode selection in nonlinear resonator arrays</a><a hidden class=anchor aria-hidden=true href=#collective-vibrational-resonance-and-mode-selection-in-nonlinear-resonator-arrayshttpsarxivorgabs251204507v1>#</a></h3><p><strong>Authors:</strong> Somnath Roy, Mattia Coccolo, Anirban Ray, Asesh Roy Chowdhury
<strong>Venue:</strong> arXiv (2025)</p><p>This article investigates how a uniform high frequency (HF) drive applied to each site of a weakly-coupled discrete nonlinear resonator array can modulate the onsite natural stiffness and damping and thereby facilitate the active tunability of the nonlinear response and the phonon dispersion relation externally. Starting from a canonical model of parametrically excited \textit{van der Pol-Duffing} chain of oscillators with nearest neighbor coupling, a systematic two-widely separated time scale expansion (\textit{Direct Partition of Motion}) has been employed, in the backdrop of Blekhman&rsquo;s perturbation scheme. This procedure eliminates the fast scale and yields the effective collective dynamics of the array with renormalized stiffness and damping, modified by the high-frequency drive. The resulting dispersion shift controls which normal modes enter the parametric resonance window, allowing highly selective activation of specific bulk modes through external HF tuning. The collective resonant response to the parametric excitation and mode-selection by the HF drive has been analyzed and validated by detailed numerical simulations. The results offer a straightforward, experimentally tractable route to active control of response and channelize energy through selective mode activation in MEMS/NEMS arrays and related resonator platforms.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04507v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04507v1">üìÑ Download PDF</a></p><hr><h3 id=on-angular-dependent-response-to-gravitational-wave-signals-for-time-delay-interferometry-combinationshttpsarxivorgabs251204473v1><a href=https://arxiv.org/abs/2512.04473v1>On angular dependent response to gravitational-wave signals for time-delay interferometry combinations</a><a hidden class=anchor aria-hidden=true href=#on-angular-dependent-response-to-gravitational-wave-signals-for-time-delay-interferometry-combinationshttpsarxivorgabs251204473v1>#</a></h3><p><strong>Authors:</strong> Pan-Pan Wang, Hao-Kang Chen, Wei-Liang Qian, Rui Luo, Jing Zhou, Wei-Sheng Huang, Yu-Jie Tan, Cheng-Gang Shao
<strong>Venue:</strong> arXiv (2025)</p><p>Space-based gravitational wave (GW) detectors are designed for wave sources in the millihertz band with different locations and orientations.
Time-delay interferometry (TDI) technique is an indispensable ingredient in space-borne GW detection that effectively suppresses the laser phase noise.
The abundant TDI solutions derived in the literature also feature distinct angular-dependent sensitivities.
Because a GW source&rsquo;s angular location is unknown prior to the signals&rsquo; detection, a solid-angle average is often performed when analyzing the sensitivity function of a given TDI combination.
The present study explores the angular dependence of the detector&rsquo;s sensitivity.
This detail is relevant, because once the initial detection is achieved, the source&rsquo;s location can be extracted and used to provide information on a refined TDI combination tailored for the specific GW source.
As the TDI technique is a post-processing algorithm, such a procedure can be implemented in practice.
We evaluate the angular dependence of the detector&rsquo;s response function to the GW signals for different TDI combinations as a function of the orientation angles.
Moreover, we classify the response functions into seven categories at the low-frequency limit, leveraging the characteristics of the underlying geometrical TDI combinations.
By further averaging out the azimuthal angle $œÜ_D$ in the detector&rsquo;s plane, the main features of the resulting response functions and their zenithal dependence with respect to the GW source are scrutinized.
The findings presented in this work provide pertinent insights for ongoing space-borne detector programs.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04473v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04473v1">üìÑ Download PDF</a></p><hr><h3 id=learning-heterogeneous-ordinal-graphical-models-via-bayesian-nonparametric-clusteringhttpsarxivorgabs251204407v1><a href=https://arxiv.org/abs/2512.04407v1>Learning Heterogeneous Ordinal Graphical Models via Bayesian Nonparametric Clustering</a><a hidden class=anchor aria-hidden=true href=#learning-heterogeneous-ordinal-graphical-models-via-bayesian-nonparametric-clusteringhttpsarxivorgabs251204407v1>#</a></h3><p><strong>Authors:</strong> Wang Wen, Ziqi Chen, Guanyu Hu
<strong>Venue:</strong> arXiv (2025)</p><p>Graphical models are powerful tools for capturing conditional dependence structures in complex systems but remain underexplored in analyzing ordinal data, especially in sports analytics. Ordinal variables, such as team rankings, player performance ratings, and survey responses, are pervasive in sports data but present unique challenges, particularly when accounting for heterogeneous subgroups, such as teams with varying styles or players with distinct roles. Existing methods, including probit graphical models, struggle with modeling heterogeneity and selecting the number of subgroups effectively. We propose a novel nonparametric Bayesian framework using the Mixture of Finite Mixtures (MFM) approach to address these challenges. Our method allows for flexible subgroup discovery and models each subgroup with a probit graphical model, simultaneously estimating the number of clusters and their configurations. We develop an efficient Gibbs sampling algorithm for inference, enabling robust estimation of cluster-specific structures and parameters. This framework is particularly suited to sports analytics, uncovering latent patterns in player performance metrics. Our work bridges critical gaps in modeling ordinal data and provides a foundation for advanced decision-making in sports performance and strategy.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04407v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04407v1">üìÑ Download PDF</a></p><hr><h3 id=autoguard-a-self-healing-proactive-security-layer-for-devsecops-pipelines-using-reinforcement-learninghttpsarxivorgabs251204368v1><a href=https://arxiv.org/abs/2512.04368v1>AutoGuard: A Self-Healing Proactive Security Layer for DevSecOps Pipelines Using Reinforcement Learning</a><a hidden class=anchor aria-hidden=true href=#autoguard-a-self-healing-proactive-security-layer-for-devsecops-pipelines-using-reinforcement-learninghttpsarxivorgabs251204368v1>#</a></h3><p><strong>Authors:</strong> Praveen Anugula, Avdhesh Kumar Bhardwaj, Navin Chhibber, Rohit Tewari, Sunil Khemka, Piyush Ranjan
<strong>Venue:</strong> arXiv (2025)</p><p>Contemporary DevSecOps pipelines have to deal with the evolution of security in an ever-continuously integrated and deployed environment. Existing methods,such as rule-based intrusion detection and static vulnerability scanning, are inadequate and unreceptive to changes in the system, causing longer response times and organization needs exposure to emerging attack vectors. In light of the previous constraints, we introduce AutoGuard to the DevSecOps ecosystem, a reinforcement learning (RL)-powered self-healing security framework built to pre-emptively protect DevSecOps environments. AutoGuard is a self-securing security environment that continuously observes pipeline activities for potential anomalies while preemptively remediating the environment. The model observes and reacts based on a policy that is continually learned dynamically over time. The RL agent improves each action over time through reward-based learning aimed at improving the agent&rsquo;s ability to prevent, detect and respond to a security incident in real-time. Testing using simulated ContinuousIntegration / Continuous Deployment (CI/CD) environments showed AutoGuard to successfully improve threat detection accuracy by 22%, reduce mean time torecovery (MTTR) for incidents by 38% and increase overall resilience to incidents as compared to traditional methods.
Keywords- DevSecOps, Reinforcement Learning, Self- Healing Security, Continuous Integration, Automated Threat Mitigation</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04368v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04368v1">üìÑ Download PDF</a></p><hr><h3 id=making-cellular-networks-crisis-proof-towards-island-ready-resilient-by-design-6g-communication-networkhttpsarxivorgabs251204346v1><a href=https://arxiv.org/abs/2512.04346v1>Making Cellular Networks Crisis-Proof: Towards Island-Ready, Resilient-By-Design 6G Communication Network</a><a hidden class=anchor aria-hidden=true href=#making-cellular-networks-crisis-proof-towards-island-ready-resilient-by-design-6g-communication-networkhttpsarxivorgabs251204346v1>#</a></h3><p><strong>Authors:</strong> Leon Janzen, Matthias Hollick
<strong>Venue:</strong> arXiv (2025)</p><p>5G and 5G-Advanced cellular networks are vulnerable to regional outages resulting from disasters or targeted attacks. This fragility stems from the reliance on the central core network involved for most 5G connectivity use cases. Crisis-struck regions isolated from the cellular core network form islands, where crisis response is hindered by the unavailability of recovery-relevant services, such as emergency calls, cell broadcasts, messengers, and news apps. Our concept of island-ready, resilient-by-design 6G communication networks envisions local cellular connectivity allowing users to connect to regional application servers, which is currently impossible. In our conceptualization, we follow an all-society approach, as realizing island connectivity requires the cooperation of multiple actors, including users, operators, developers, providers, and authorities. We evaluate how island-ready 5G and 5G-Advanced systems are and outline the open challenges stakeholders must address for full island readiness, such as decentralizing the 6G core network and designing local-first application architectures.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04346v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04346v1">üìÑ Download PDF</a></p><hr><h3 id=beampattern-synthesis-for-discrete-phase-ris-in-communication-and-sensing-systemshttpsarxivorgabs251204881v1><a href=https://arxiv.org/abs/2512.04881v1>Beampattern Synthesis for Discrete Phase RIS in Communication and Sensing Systems</a><a hidden class=anchor aria-hidden=true href=#beampattern-synthesis-for-discrete-phase-ris-in-communication-and-sensing-systemshttpsarxivorgabs251204881v1>#</a></h3><p><strong>Authors:</strong> Xiao Cai, Hei Victor Cheng, Daniel E. Lucani
<strong>Venue:</strong> arXiv (2025)</p><p>Extensive research on Reconfigurable Intelligent Surfaces (RIS) has primarily focused on optimizing reflective coefficients for passive beamforming in specific target directions. This optimization typically assumes prior knowledge of the target direction, which is unavailable before the target is detected. To enhance direction estimation, it is critical to develop array pattern synthesis techniques that yield a wider beam by maximizing the received power over the entire target area. Although this challenge has been addressed with active antennas, RIS systems pose a unique challenge due to their inherent phase constraints, which can be continuous or discrete.
This work addresses this challenge through a novel array pattern synthesis method tailored for discrete phase constraints in RIS. We introduce a penalty method that pushes these constraints to the boundary of the convex hull. Then, the Minorization-Maximization (MM) method is utilized to reformulate the problem into a convex one. Our numerical results show that our algorithm can generate a wide beam pattern comparable to that achievable with per-power constraints, with both the amplitudes and phases being adjustable. We compare our method with a traditional beam sweeping technique, showing a) several orders of magnitude reduction of the MSE of Angle of Arrival (AOA) at low to medium Signal-to-Noise Ratio (SNR)s; and b) $8$~dB SNR reduction to achieve a high probability of detection.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04881v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04881v1">üìÑ Download PDF</a></p><hr><h3 id=detecting-relativistic-black-hole-collisions-near-a-massive-black-holehttpsarxivorgabs251204851v1><a href=https://arxiv.org/abs/2512.04851v1>Detecting relativistic black hole collisions near a massive black hole</a><a hidden class=anchor aria-hidden=true href=#detecting-relativistic-black-hole-collisions-near-a-massive-black-holehttpsarxivorgabs251204851v1>#</a></h3><p><strong>Authors:</strong> Yirong Fang, Changfu Shi, Jianwei Mei
<strong>Venue:</strong> arXiv (2025)</p><p>Relativistic black hole collisions are one of the most dramatic astrophysical events that can be imagined. They could provide the ideal condition for searching for possible new physics beyond general relativity. However, such events are presumably rare and difficult to occur under normal conditions. Black holes in a triple system can be accelerated to the relativistic limit and may harbor the chance for a relativistic collision. In this paper, we study the relativistic black hole collisions in a massive black hole background and the capabilities of several current and future gravitational wave detectors in detecting such signals.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04851v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04851v1">üìÑ Download PDF</a></p><hr><h3 id=detect-duality-obstruction-of-calibrations-in-smooth-categoryhttpsarxivorgabs251204789v1><a href=https://arxiv.org/abs/2512.04789v1>Detect duality obstruction of calibrations in smooth category</a><a hidden class=anchor aria-hidden=true href=#detect-duality-obstruction-of-calibrations-in-smooth-categoryhttpsarxivorgabs251204789v1>#</a></h3><p><strong>Authors:</strong> Yongsheng Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>This paper consists of three parts: a. exhibit a new gluing result which can dramatically simplify extensions of calibration pairs; b. observe that every Lawlor cone can support coflat calibrations singular only at the origin; c. show that there exist many Lawlor cones which cannot support any smooth calibrations. As an application, we extend our previous work on detecting duality obstruction of calibrations in the smooth category.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04789v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04789v1">üìÑ Download PDF</a></p><hr><h3 id=evolutionary-dynamics-based-on-reputation-in-networked-populations-with-game-transitionshttpsarxivorgabs251204671v1><a href=https://arxiv.org/abs/2512.04671v1>Evolutionary Dynamics Based on Reputation in Networked Populations with Game Transitions</a><a hidden class=anchor aria-hidden=true href=#evolutionary-dynamics-based-on-reputation-in-networked-populations-with-game-transitionshttpsarxivorgabs251204671v1>#</a></h3><p><strong>Authors:</strong> Yuji Zhang, Minyu Feng, J√ºrgen Kurths, Attila Szolnoki
<strong>Venue:</strong> arXiv (2025)</p><p>The environment undergoes perpetual changes that are influenced by a combination of endogenous and exogenous factors. Consequently, it exerts a substantial influence on an individual&rsquo;s physical and psychological state, directly or indirectly affecting the evolutionary dynamics of a population described by a network, which in turn can also alter the environment. Furthermore, the evolution of strategies, shaped by reputation, can diverge due to variations in multiple factors. To explore the potential consequences of the mentioned situations, this paper studies how game and reputation dynamics alter the evolution of cooperation. Concretely, game transitions are determined by individuals&rsquo; behaviors and external uncontrollable factors. The cooperation level of its neighbors reflects individuals&rsquo; reputation, and further, a general fitness function regarding payoff and reputation is provided. Within the context of the donation game, we investigate the relevant outcomes associated with the aforementioned evolutionary process, considering various topologies for distinct interactions. Additionally, a biased mutation is introduced to gain a deeper insight into the strategy evolution. We detect a substantial increase in the cooperation level through intensive simulations, and some important phenomena are observed, e.g., the unilateral increase of the value of prosocial behavior limits promotion in cooperative behavior in square-lattice networks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04671v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04671v1">üìÑ Download PDF</a></p><hr><h3 id=progress-towards-a-microchannel-plate-detector-with-algan-photocathode-and-cross-strip-anode-for-ultraviolet-astronomyhttpsarxivorgabs251204669v1><a href=https://arxiv.org/abs/2512.04669v1>Progress towards a microchannel plate detector with AlGaN photocathode and cross-strip anode for ultraviolet astronomy</a><a hidden class=anchor aria-hidden=true href=#progress-towards-a-microchannel-plate-detector-with-algan-photocathode-and-cross-strip-anode-for-ultraviolet-astronomyhttpsarxivorgabs251204669v1>#</a></h3><p><strong>Authors:</strong> S. Diebold, J. Barnstedt, L. Conti, H. R. Elsener, L. Hanke, M. H√∂ltzli, C. Kalkuhl, D. Rau, D. Schaadt, T. Schanz, B. Stelzer, K. Werner
<strong>Venue:</strong> arXiv (2025)</p><p>Microchannel plates (MCPs) were the driving detector technology for ultraviolet (UV) astronomy over many years, and still today MCP-based detectors are the baseline for several planned UV instruments. The development of advanced MCP detectors is ongoing and pursues the major goals of maximizing sensitivity, resolution, and lifetime, while at the same time decreasing weight, volume, and power consumption.
Development efforts for an MCP-based detector system for the UV are running at IAAT at the University of T√ºbingen. In this publication, we present our latest results towards coating aluminum gallium nitride (AlGaN) photocathodes directly on MCPs, to improve quantum detection efficiency in the far- and extreme-UV. Furthermore, we report on the implementation of a non-iterative centroiding algorithm for our coplanar cross-strip anode directly in an FPGA.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04669v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04669v1">üìÑ Download PDF</a></p><hr><h3 id=federated-learning-for-anomaly-detection-in-maritime-movement-datahttpsarxivorgabs251204635v1><a href=https://arxiv.org/abs/2512.04635v1>Federated Learning for Anomaly Detection in Maritime Movement Data</a><a hidden class=anchor aria-hidden=true href=#federated-learning-for-anomaly-detection-in-maritime-movement-datahttpsarxivorgabs251204635v1>#</a></h3><p><strong>Authors:</strong> Anita Graser, Axel Wei√üenfeld, Clemens Heistracher, Melitta Dragaschnig, Peter Widhalm
<strong>Venue:</strong> arXiv (2025)</p><p>This paper introduces M3fed, a novel solution for federated learning of movement anomaly detection models. This innovation has the potential to improve data privacy and reduce communication costs in machine learning for movement anomaly detection. We present the novel federated learning (FL) strategies employed to train M3fed, perform an example experiment with maritime AIS data, and evaluate the results with respect to communication costs and FL model quality by comparing classic centralized M3 and the new federated M3fed.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04635v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04635v1">üìÑ Download PDF</a></p><hr><h3 id=live-avatar-streaming-real-time-audio-driven-avatar-generation-with-infinite-lengthhttpsarxivorgabs251204677v1><a href=https://arxiv.org/abs/2512.04677v1>Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length</a><a hidden class=anchor aria-hidden=true href=#live-avatar-streaming-real-time-audio-driven-avatar-generation-with-infinite-lengthhttpsarxivorgabs251204677v1>#</a></h3><p><strong>Authors:</strong> Yubo Huang, Hailong Guo, Fangtai Wu, Shifeng Zhang, Shijie Huang, Qijun Gan, Lin Liu, Sirui Zhao, Enhong Chen, Jiaming Liu, Steven Hoi
<strong>Venue:</strong> arXiv (2025)</p><p>Existing diffusion-based video generation methods are fundamentally constrained by sequential computation and long-horizon inconsistency, limiting their practical adoption in real-time, streaming audio-driven avatar synthesis. We present Live Avatar, an algorithm-system co-designed framework that enables efficient, high-fidelity, and infinite-length avatar generation using a 14-billion-parameter diffusion model. Our approach introduces Timestep-forcing Pipeline Parallelism (TPP), a distributed inference paradigm that pipelines denoising steps across multiple GPUs, effectively breaking the autoregressive bottleneck and ensuring stable, low-latency real-time streaming. To further enhance temporal consistency and mitigate identity drift and color artifacts, we propose the Rolling Sink Frame Mechanism (RSFM), which maintains sequence fidelity by dynamically recalibrating appearance using a cached reference image. Additionally, we leverage Self-Forcing Distribution Matching Distillation to facilitate causal, streamable adaptation of large-scale models without sacrificing visual quality. Live Avatar demonstrates state-of-the-art performance, reaching 20 FPS end-to-end generation on 5 H800 GPUs, and, to the best of our knowledge, is the first to achieve practical, real-time, high-fidelity avatar generation at this scale. Our work establishes a new paradigm for deploying advanced diffusion models in industrial long-form video synthesis applications.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04677v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04677v1">üìÑ Download PDF</a></p><hr><h3 id=pbfuzz-agentic-directed-fuzzing-for-pov-generationhttpsarxivorgabs251204611v1><a href=https://arxiv.org/abs/2512.04611v1>PBFuzz: Agentic Directed Fuzzing for PoV Generation</a><a hidden class=anchor aria-hidden=true href=#pbfuzz-agentic-directed-fuzzing-for-pov-generationhttpsarxivorgabs251204611v1>#</a></h3><p><strong>Authors:</strong> Haochen Zeng, Andrew Bao, Jiajun Cheng, Chengyu Song
<strong>Venue:</strong> arXiv (2025)</p><p>Proof-of-Vulnerability (PoV) input generation is a critical task in software security and supports downstream applications such as path generation and validation. Generating a PoV input requires solving two sets of constraints: (1) reachability constraints for reaching vulnerable code locations, and (2) triggering constraints for activating the target vulnerability. Existing approaches, including directed greybox fuzzing and LLM-assisted fuzzing, struggle to efficiently satisfy these constraints. This work presents an agentic method that mimics human experts. Human analysts iteratively study code to extract semantic reachability and triggering constraints, form hypotheses about PoV triggering strategies, encode them as test inputs, and refine their understanding using debugging feedback. We automate this process with an agentic directed fuzzing framework called PBFuzz. PBFuzz tackles four challenges in agentic PoV generation: autonomous code reasoning for semantic constraint extraction, custom program-analysis tools for targeted inference, persistent memory to avoid hypothesis drift, and property-based testing for efficient constraint solving while preserving input structure. Experiments on the Magma benchmark show strong results. PBFuzz triggered 57 vulnerabilities, surpassing all baselines, and uniquely triggered 17 vulnerabilities not exposed by existing fuzzers. PBFuzz achieved this within a 30-minute budget per target, while conventional approaches use 24 hours. Median time-to-exposure was 339 seconds for PBFuzz versus 8680 seconds for AFL++ with CmpLog, giving a 25.6x efficiency improvement with an API cost of 1.83 USD per vulnerability.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04611v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04611v1">üìÑ Download PDF</a></p><hr><h3 id=on-the-limits-of-test-time-compute-sequential-reward-filtering-for-better-inferencehttpsarxivorgabs251204558v1><a href=https://arxiv.org/abs/2512.04558v1>On the Limits of Test-Time Compute: Sequential Reward Filtering for Better Inference</a><a hidden class=anchor aria-hidden=true href=#on-the-limits-of-test-time-compute-sequential-reward-filtering-for-better-inferencehttpsarxivorgabs251204558v1>#</a></h3><p><strong>Authors:</strong> Yue Yu, Qiwei Di, Quanquan Gu, Dongruo Zhou
<strong>Venue:</strong> arXiv (2025)</p><p>Test-time compute (TTC) has become an increasingly prominent paradigm for enhancing large language models (LLMs). Despite the empirical success of methods such as best-of-$n$ (BoN) sampling and sequential revision, their fundamental limits remain unclear. We address this gap by analyzing a mixture-of-reference policy model and proving that standard BoN is inherently suboptimal. To move closer to the optimal frontier, we study reward-filtered sequential inference, a simple procedure that selectively incorporates only high-reward generations into the context. This mechanism concentrates computation on superior policy candidates and suppresses inferior ones. On the theoretical side, we show that reward-filtered sequential inference yields strictly stronger guarantees than standard TTC paradigms. On the empirical side, we evaluate such an inference strategy across diverse benchmarks and observe consistent improvements over widely used approaches, demonstrating the practical effectiveness of our framework.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04558v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04558v1">üìÑ Download PDF</a></p><hr><h3 id=constraining-regular-primordial-black-holes-with-isocurvature-gravitational-waveshttpsarxivorgabs251204548v1><a href=https://arxiv.org/abs/2512.04548v1>Constraining regular primordial black holes with isocurvature gravitational waves</a><a hidden class=anchor aria-hidden=true href=#constraining-regular-primordial-black-holes-with-isocurvature-gravitational-waveshttpsarxivorgabs251204548v1>#</a></h3><p><strong>Authors:</strong> Ngo Phuc Duc Loc
<strong>Venue:</strong> arXiv (2025)</p><p>We find the constraint on the population of ultra-light regular primordial black holes (RPBHs) by using isocurvature gravitational waves (GW). If ultra-light RPBHs dominated the early Universe, the initial isocurvature perturbation is converted into curvature perturbation that induce second-order GW background upon evaporation of RPBHs. The upper limit of extra relativistic degrees of freedom $ŒîN_{\rm eff}$, which could be inferred from Big Bang Nucleosynthesis or Cosmic Microwave Background observations, places a constraint on the maximum energy density of GW, which in turn can be used to constrain the RPBH population. As RPBHs have different lifetime from their singular counterparts, the constraint must be modified accordingly. While the formalism that we provide is generic, we work out explicitly the case of Simpson-Visser metric for demonstration. The RPBHs associated with this metric have lower Hawking temperature and smaller horizon size, leading to a longer lifetime than the singular Schwarzschild black holes. This implies a stronger constraint on RPBH population as they dominate the Universe for a longer period of time and generate stronger GW.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04548v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04548v1">üìÑ Download PDF</a></p><hr><h3 id=estimation-and-inference-in-models-with-multiple-behavioural-equilibriahttpsarxivorgabs251204541v1><a href=https://arxiv.org/abs/2512.04541v1>Estimation and inference in models with multiple behavioural equilibria</a><a hidden class=anchor aria-hidden=true href=#estimation-and-inference-in-models-with-multiple-behavioural-equilibriahttpsarxivorgabs251204541v1>#</a></h3><p><strong>Authors:</strong> Alexander Mayer, Davide Raggi
<strong>Venue:</strong> arXiv (2025)</p><p>We develop estimation and inference methods for a stylized macroeconomic model with potentially multiple behavioural equilibria, where agents form expectations using a constant-gain learning rule. We first show geometric ergodicity of the underlying process to study in a second step (strong) consistency and asymptotic normality of the nonlinear least squares estimator for the structural parameters. We propose inference procedures for the structural parameters and uniform confidence bands for the equilibria. When equilibrium solutions are repeated, mixed convergence rates and non-standard limit distributions emerge. Monte Carlo simulations and an empirical application illustrate the finite-sample performance of our methods.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04541v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04541v1">üìÑ Download PDF</a></p><hr><h3 id=a-quarkyonic-quark-meson-coupling-model-for-nuclear-and-neutron-matterhttpsarxivorgabs251204505v1><a href=https://arxiv.org/abs/2512.04505v1>A Quarkyonic Quark-Meson Coupling Model for Nuclear and Neutron Matter</a><a hidden class=anchor aria-hidden=true href=#a-quarkyonic-quark-meson-coupling-model-for-nuclear-and-neutron-matterhttpsarxivorgabs251204505v1>#</a></h3><p><strong>Authors:</strong> Koichi Saito, Tsuyoshi Miyatsu, Myung-Ki Cheoun
<strong>Venue:</strong> arXiv (2025)</p><p>We unite the dual quarkyonic model with the quark-meson coupling (QMC) model to construct a novel nuclear model based on the quark degrees of freedom, which can cover a wide range of nuclear density from low density to the crossover region. In the model, the relativistic, gaussian quark wavefunction is used to describe the nucleon structure. We first evaluate the energy density, chemical potential, pressure and sound velocity within the ideal Fermi gas picture. In this case, those physical quantities are discontinuous or divergent at the quark saturation density, where quarkyonic phase emerges. To remove such singular behavior, we next introduce an infrared regulator, and combine the dual quarkyonic model and the QMC model to include the nuclear interaction &ndash; we call it the quarkyonic quark-meson coupling (QQMC) model. We then find that the quark saturation density depends strongly on the nucleon size. For example, when $r_p = 0.6, (0.8)$ fm, where $r_p$ is the root-mean-square radius of proton, the quark saturation density is about $3.6,(1.5) \times œÅ_0$ in symmetric nuclear matter, where $œÅ_0$ is the nuclear saturation density. It is notable that the nuclear interaction is quite important to consider physical quantities quantitatively. In fact, the QQMC model can produce the sound velocity which is consistent with that inferred from the observed data of several neutron stars. Furthermore, pressure in symmetric or pure neutron matter deduced from the experiments of heavy-ion collisions at high energy can be explained by the QQMC model as well. We discuss in detail the formulation for the QQMC model and the physical quantities calculated by the model.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04505v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04505v1">üìÑ Download PDF</a></p><hr><h3 id=guidnoise-single-pair-guided-diffusion-for-generalized-noise-synthesishttpsarxivorgabs251204456v1><a href=https://arxiv.org/abs/2512.04456v1>GuidNoise: Single-Pair Guided Diffusion for Generalized Noise Synthesis</a><a hidden class=anchor aria-hidden=true href=#guidnoise-single-pair-guided-diffusion-for-generalized-noise-synthesishttpsarxivorgabs251204456v1>#</a></h3><p><strong>Authors:</strong> Changjin Kim, HyeokJun Lee, YoungJoon Yoo
<strong>Venue:</strong> arXiv (2025)</p><p>Recent image denoising methods have leveraged generative modeling for real noise synthesis to address the costly acquisition of real-world noisy data. However, these generative models typically require camera metadata and extensive target-specific noisy-clean image pairs, often showing limited generalization between settings. In this paper, to mitigate the prerequisites, we propose a Single-Pair Guided Diffusion for generalized noise synthesis GuidNoise, which uses a single noisy/clean pair as the guidance, often easily obtained by itself within a training set. To train GuidNoise, which generates synthetic noisy images from the guidance, we introduce a guidance-aware affine feature modification (GAFM) and a noise-aware refine loss to leverage the inherent potential of diffusion models. This loss function refines the diffusion model&rsquo;s backward process, making the model more adept at generating realistic noise distributions. The GuidNoise synthesizes high-quality noisy images under diverse noise environments without additional metadata during both training and inference. Additionally, GuidNoise enables the efficient generation of noisy-clean image pairs at inference time, making synthetic noise readily applicable for augmenting training data. This self-augmentation significantly improves denoising performance, especially in practical scenarios with lightweight models and limited training data. The code is available at <a href=https://github.com/chjinny/GuidNoise>https://github.com/chjinny/GuidNoise</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04456v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04456v1">üìÑ Download PDF</a></p><hr><h3 id=open-ended-goal-inference-through-actions-and-language-for-human-robot-collaborationhttpsarxivorgabs251204453v1><a href=https://arxiv.org/abs/2512.04453v1>Open-Ended Goal Inference through Actions and Language for Human-Robot Collaboration</a><a hidden class=anchor aria-hidden=true href=#open-ended-goal-inference-through-actions-and-language-for-human-robot-collaborationhttpsarxivorgabs251204453v1>#</a></h3><p><strong>Authors:</strong> Debasmita Ghose, Oz Gitelson, Marynel Vazquez, Brian Scassellati
<strong>Venue:</strong> arXiv (2025)</p><p>To collaborate with humans, robots must infer goals that are often ambiguous, difficult to articulate, or not drawn from a fixed set. Prior approaches restrict inference to a predefined goal set, rely only on observed actions, or depend exclusively on explicit instructions, making them brittle in real-world interactions. We present BALI (Bidirectional Action-Language Inference) for goal prediction, a method that integrates natural language preferences with observed human actions in a receding-horizon planning tree. BALI combines language and action cues from the human, asks clarifying questions only when the expected information gain from the answer outweighs the cost of interruption, and selects supportive actions that align with inferred goals. We evaluate the approach in collaborative cooking tasks, where goals may be novel to the robot and unbounded. Compared to baselines, BALI yields more stable goal predictions and significantly fewer mistakes.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04453v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04453v1">üìÑ Download PDF</a></p><hr><h3 id=nori-an-ml-augmented-ocean-boundary-layer-parameterizationhttpsarxivorgabs251204452v1><a href=https://arxiv.org/abs/2512.04452v1>NORi: An ML-Augmented Ocean Boundary Layer Parameterization</a><a hidden class=anchor aria-hidden=true href=#nori-an-ml-augmented-ocean-boundary-layer-parameterizationhttpsarxivorgabs251204452v1>#</a></h3><p><strong>Authors:</strong> Xin Kai Lee, Ali Ramadhan, Andre Souza, Gregory LeClaire Wagner, Simone Silvestri, John Marshall, Raffaele Ferrari
<strong>Venue:</strong> arXiv (2025)</p><p>NORi is a machine-learned (ML) parameterization of ocean boundary layer turbulence that is physics-based and augmented with neural networks. NORi stands for neural ordinary differential equations (NODEs) Richardson number (Ri) closure. The physical parameterization is controlled by a Richardson number-dependent diffusivity and viscosity. The NODEs are trained to capture the entrainment through the base of the boundary layer, which cannot be represented with a local diffusive closure. The parameterization is trained using large-eddy simulations in an &ldquo;a posteriori&rdquo; fashion, where parameters are calibrated with a loss function that explicitly depends on the actual time-integrated variables of interest rather than the instantaneous subgrid fluxes, which are inherently noisy. NORi is designed for the realistic nonlinear equation of state of seawater and demonstrates excellent prediction and generalization capabilities in capturing entrainment dynamics under different convective strengths, oceanic background stratifications, rotation strengths, and surface wind forcings. NORi is numerically stable for at least 100 years of integration time in large-scale simulations, despite only being trained on 2-day horizons, and can be run with time steps as long as one hour. The highly expressive neural networks, combined with a physically-rigorous base closure, prove to be a robust paradigm for designing parameterizations for climate models where data requirements are drastically reduced, inference performance can be directly targeted and optimized, and numerical stability is implicitly encouraged during training.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04452v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04452v1">üìÑ Download PDF</a></p><hr><h3 id=sedimentary-models-of-fossil-biomolecules-principles-and-methodological-improvementshttpsarxivorgabs251204427v1><a href=https://arxiv.org/abs/2512.04427v1>Sedimentary models of fossil biomolecules, principles and methodological improvements</a><a hidden class=anchor aria-hidden=true href=#sedimentary-models-of-fossil-biomolecules-principles-and-methodological-improvementshttpsarxivorgabs251204427v1>#</a></h3><p><strong>Authors:</strong> Wan-Qian Zhao, Li-Juan Zhao
<strong>Venue:</strong> arXiv (2025)</p><p>Deamination has historically been important for authenticating ancient biomolecules. However, expanding paleogenomic datasets indicate that damage patterns are more influenced by burial hydrology and microstructural context than by molecular age or ancestry. Fossils interact with their environments differently: some form closed, water-restricted compartments that preserve minimally damaged endogenous biomolecules, whereas others serve as open molecular reservoirs in which infiltrated environmental biomolecules undergo extensive deamination from repeated water exposure. Reliance on deamination alone can therefore suppress endogenous signals and complicate the interpretation of exogenous sequences. By introducing the molecular sedimentation model for fossil biomolecules, this Perspective outlines a source tracing framework that integrates fossil microstructure, ecological reference sets, and species-specific fragments to enable more reliable molecular inference across diverse depositional environments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04427v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04427v1">üìÑ Download PDF</a></p><hr><h3 id=bridging-probabilistic-inference-and-behavior-trees-an-interactive-framework-for-adaptive-multi-robot-cooperationhttpsarxivorgabs251204404v1><a href=https://arxiv.org/abs/2512.04404v1>Bridging Probabilistic Inference and Behavior Trees: An Interactive Framework for Adaptive Multi-Robot Cooperation</a><a hidden class=anchor aria-hidden=true href=#bridging-probabilistic-inference-and-behavior-trees-an-interactive-framework-for-adaptive-multi-robot-cooperationhttpsarxivorgabs251204404v1>#</a></h3><p><strong>Authors:</strong> Chaoran Wang, Jingyuan Sun, Yanhui Zhang, Changju Wu
<strong>Venue:</strong> arXiv (2025)</p><p>This paper proposes an Interactive Inference Behavior Tree (IIBT) framework that integrates behavior trees (BTs) with active inference under the free energy principle for distributed multi-robot decision-making. The proposed IIBT node extends conventional BTs with probabilistic reasoning, enabling online joint planning and execution across multiple robots. It remains fully compatible with standard BT architectures, allowing seamless integration into existing multi-robot control systems. Within this framework, multi-robot cooperation is formulated as a free-energy minimization process, where each robot dynamically updates its preference matrix based on perceptual inputs and peer intentions, thereby achieving adaptive coordination in partially observable and dynamic environments. The proposed approach is validated through both simulation and real-world experiments, including a multi-robot maze navigation and a collaborative manipulation task, compared against traditional BTs(<a href=https://youtu.be/KX_oT3IDTf4%29>https://youtu.be/KX_oT3IDTf4)</a>. Experimental results demonstrate that the IIBT framework reduces BT node complexity by over 70%, while maintaining robust, interpretable, and adaptive cooperative behavior under environmental uncertainty.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04404v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04404v1">üìÑ Download PDF</a></p><hr><h3 id=phapcompass-probabilistic-assembly-and-uncertainty-quantification-of-polyploid-haplotype-phasehttpsarxivorgabs251204393v1><a href=https://arxiv.org/abs/2512.04393v1>pHapCompass: Probabilistic Assembly and Uncertainty Quantification of Polyploid Haplotype Phase</a><a hidden class=anchor aria-hidden=true href=#phapcompass-probabilistic-assembly-and-uncertainty-quantification-of-polyploid-haplotype-phasehttpsarxivorgabs251204393v1>#</a></h3><p><strong>Authors:</strong> Marjan Hosseini, Ella Veiner, Thomas Bergendahl, Tala Yasenpoor, Zane Smith, Margaret Staton, Derek Aguiar
<strong>Venue:</strong> arXiv (2025)</p><p>Computing haplotypes from sequencing data, i.e. haplotype assembly, is an important component of foundational molecular and population genetics problems, including interpreting the effects of genetic variation on complex traits and reconstructing genealogical relationships. Assembling the haplotypes of polyploid genomes remains a significant challenge due to the exponential search space of haplotype phasings and read assignment ambiguity; the latter challenge is particularly difficult for polyploid haplotype assemblers since the information contained within the observed sequence reads is often insufficient for unambiguous haplotype assignment in polyploid genomes. We present pHapCompass, probabilistic haplotype assembly algorithms for diploid and polyploid genomes that explicitly model and propagate read assignment ambiguity to compute a distribution over polyploid haplotype phasings. We develop graph theoretic algorithms to enable statistical inference and uncertainty quantification despite an exponential space of possible phasings. Since prior work evaluates polyploid haplotype assembly on synthetic genomes that do not reflect the realistic genomic complexity of polyploidy organisms, we develop a computational workflow for simulating genomes and DNA-seq for auto- and allopolyploids. Additionally, we generalize the vector error rate and minimum error correction evaluation criteria for partially phased haplotypes. Benchmarking of pHapCompass and several existing polyploid haplotype assemblers shows that pHapCompass yields competitive performance across varying genomic complexities and polyploid structures while retaining an accurate quantification of phase uncertainty. The source code for pHapCompass, simulation scripts, and datasets are freely available at <a href=https://github.com/bayesomicslab/pHapCompass>https://github.com/bayesomicslab/pHapCompass</a>.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04393v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04393v1">üìÑ Download PDF</a></p><hr><h3 id=informative-missingness-and-its-implications-in-semi-supervised-learninghttpsarxivorgabs251204392v1><a href=https://arxiv.org/abs/2512.04392v1>Informative missingness and its implications in semi-supervised learning</a><a hidden class=anchor aria-hidden=true href=#informative-missingness-and-its-implications-in-semi-supervised-learninghttpsarxivorgabs251204392v1>#</a></h3><p><strong>Authors:</strong> Jinran Wu, You-Gan Wang, Geoffrey J. McLachlan
<strong>Venue:</strong> arXiv (2025)</p><p>Semi-supervised learning (SSL) constructs classifiers using both labelled and unlabelled data. It leverages information from labelled samples, whose acquisition is often costly or labour-intensive, together with unlabelled data to enhance prediction performance. This defines an incomplete-data problem, which statistically can be formulated within the likelihood framework for finite mixture models that can be fitted using the expectation-maximisation (EM) algorithm. Ideally, one would prefer a completely labelled sample, as one would anticipate that a labelled observation provides more information than an unlabelled one. However, when the mechanism governing label absence depends on the observed features or the class labels or both, the missingness indicators themselves contain useful information. In certain situations, the information gained from modelling the missing-label mechanism can even outweigh the loss due to missing labels, yielding a classifier with a smaller expected error than one based on a completely labelled sample analysed. This improvement arises particularly when class overlap is moderate, labelled data are sparse, and the missingness is informative. Modelling such informative missingness thus offers a coherent statistical framework that unifies likelihood-based inference with the behaviour of empirical SSL methods.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04392v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04392v1">üìÑ Download PDF</a></p><hr><h3 id=fma-net-motion--and-exposure-aware-real-world-joint-video-super-resolution-and-deblurringhttpsarxivorgabs251204390v1><a href=https://arxiv.org/abs/2512.04390v1>FMA-Net++: Motion- and Exposure-Aware Real-World Joint Video Super-Resolution and Deblurring</a><a hidden class=anchor aria-hidden=true href=#fma-net-motion--and-exposure-aware-real-world-joint-video-super-resolution-and-deblurringhttpsarxivorgabs251204390v1>#</a></h3><p><strong>Authors:</strong> Geunhyuk Youk, Jihyong Oh, Munchurl Kim
<strong>Venue:</strong> arXiv (2025)</p><p>Real-world video restoration is plagued by complex degradations from motion coupled with dynamically varying exposure - a key challenge largely overlooked by prior works and a common artifact of auto-exposure or low-light capture. We present FMA-Net++, a framework for joint video super-resolution and deblurring that explicitly models this coupled effect of motion and dynamically varying exposure. FMA-Net++ adopts a sequence-level architecture built from Hierarchical Refinement with Bidirectional Propagation blocks, enabling parallel, long-range temporal modeling. Within each block, an Exposure Time-aware Modulation layer conditions features on per-frame exposure, which in turn drives an exposure-aware Flow-Guided Dynamic Filtering module to infer motion- and exposure-aware degradation kernels. FMA-Net++ decouples degradation learning from restoration: the former predicts exposure- and motion-aware priors to guide the latter, improving both accuracy and efficiency. To evaluate under realistic capture conditions, we introduce REDS-ME (multi-exposure) and REDS-RE (random-exposure) benchmarks. Trained solely on synthetic data, FMA-Net++ achieves state-of-the-art accuracy and temporal consistency on our new benchmarks and GoPro, outperforming recent methods in both restoration quality and inference speed, and generalizes well to challenging real-world videos.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04390v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04390v1">üìÑ Download PDF</a></p><hr><h3 id=when-genai-meets-fake-news-understanding-image-cascade-dynamics-on-reddithttpsarxivorgabs251204639v1><a href=https://arxiv.org/abs/2512.04639v1>When GenAI Meets Fake News: Understanding Image Cascade Dynamics on Reddit</a><a hidden class=anchor aria-hidden=true href=#when-genai-meets-fake-news-understanding-image-cascade-dynamics-on-reddithttpsarxivorgabs251204639v1>#</a></h3><p><strong>Authors:</strong> Saumya Chauhan, Mila Hong, Maria Vazhaeparambil
<strong>Venue:</strong> arXiv (2025)</p><p>AI-generated content and misinformation are increasingly prevalent on social networks. While prior research primarily examined textual misinformation, fewer studies have focused on visual content&rsquo;s role in virality. In this work, we present the first large-scale analysis of how misinformation and AI-generated images propagate through repost cascades across five ideologically diverse Reddit communities. By integrating textual sentiment, visual attributes, and diffusion metrics (e.g., time-to-first repost, community reach), our framework accurately predicts both immediate post-level virality (AUC=0.83) and long-term cascade-level spread (AUC=0.998). These findings offer essential insights for moderating synthetic and misleading visual content online.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04639v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04639v1">üìÑ Download PDF</a></p><hr><h3 id=analysis-of-provincial-export-performance-in-turkiye-a-spectral-clustering-approachhttpsarxivorgabs251204466v1><a href=https://arxiv.org/abs/2512.04466v1>Analysis of Provincial Export Performance in Turkiye: A Spectral Clustering Approach</a><a hidden class=anchor aria-hidden=true href=#analysis-of-provincial-export-performance-in-turkiye-a-spectral-clustering-approachhttpsarxivorgabs251204466v1>#</a></h3><p><strong>Authors:</strong> Emre Akusta
<strong>Venue:</strong> arXiv (2025)</p><p>This study analyzes and clusters Turkiye&rsquo;s 81 provinces based on their export performance. The study uses import, export and net export data for 2023. In addition, exchange rate-adjusted versions of the data were also included to eliminate the effects of exchange rate fluctuations. Spectral clustering method is used to group the export performance of cities. The optimum number of clusters was determined by the Eigen-Gap method. The Silhouette coefficient method was used to evaluate the clustering performance. As a result of the analysis, it was determined that the data set was optimally separated into 3 clusters. Spectral-clustering analysis based on export performance showed that 42% of the provinces are in the &ldquo;Low&rdquo;, 33% in the &ldquo;Medium&rdquo; and 25% in the &ldquo;High&rdquo; export performance category. In terms of import performance, 44%, 33%, 33%, and 22% of the provinces are in the &ldquo;Medium&rdquo;, &ldquo;High&rdquo;, and &ldquo;Low&rdquo; categories, respectively. In terms of net exports, 38, 35% and 27% of the provinces are in the &ldquo;Low&rdquo;, &ldquo;Medium&rdquo; and &ldquo;High&rdquo; net export performance categories, respectively. Izmir has the highest net export performance, while Istanbul has the lowest.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04466v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04466v1">üìÑ Download PDF</a></p><hr><h3 id=distributed-articulation-point-identification-in-time-varying-undirected-networkshttpsarxivorgabs251204409v1><a href=https://arxiv.org/abs/2512.04409v1>Distributed Articulation Point Identification in Time-Varying Undirected Networks</a><a hidden class=anchor aria-hidden=true href=#distributed-articulation-point-identification-in-time-varying-undirected-networkshttpsarxivorgabs251204409v1>#</a></h3><p><strong>Authors:</strong> Xinye Xie, Ronghao Zheng, Senlin Zhang, Meiqin Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Identifying articulation points (APs) is fundamental to assessing the robustness of time-varying networks. In such dynamic environments, topological changes including edge additions and deletions can instantly alter the set of APs, demanding rapid and efficient re-assessment. This paper proposes a fully distributed algorithm for identifying APs and monitoring biconnectivity. Our core contribution is an incremental update protocol. Unlike static methods that require global re-initialization which incurs high communication overhead, our algorithm propagates information from the site of the change, updating only the affected nodes&rsquo; state values. This approach, which builds upon a maximum consensus protocol, not only ensures convergence to the correct AP set following topological changes but also preserves network privacy by preventing nodes from reconstructing the global topology. We provide rigorous proofs of correctness for this eventual convergence and demonstrate its applicability and efficiency through experiments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04409v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04409v1">üìÑ Download PDF</a></p><hr><h3 id=a-turtle-model-of-food-system-transformations-embracing-citizens-diverse-values-and-knowledge-in-change-processeshttpsarxivorgabs251204384v1><a href=https://arxiv.org/abs/2512.04384v1>A &lsquo;Turtle Model&rsquo; of Food System Transformations: Embracing Citizens&rsquo; Diverse Values and Knowledge in Change Processes</a><a hidden class=anchor aria-hidden=true href=#a-turtle-model-of-food-system-transformations-embracing-citizens-diverse-values-and-knowledge-in-change-processeshttpsarxivorgabs251204384v1>#</a></h3><p><strong>Authors:</strong> Matthias Kaiser, Agnese Cretella, Cordula Scherer, Mimi E. Lam
<strong>Venue:</strong> arXiv (2025)</p><p>We explore the challenges and opportunities of transitioning towards sustainable food systems through the lens of democratic food governance fostering inclusive and systemic transformation. Drawing on concepts of wicked problems and systems thinking, we propose a theory of change represented as a &rsquo;turtle model&rsquo; that embraces the diversity of citizens&rsquo; values and knowledge to highlight multiple avenues of transformation. As quadruple helix innovation and governance hubs, cities can be hotspots for food system transformations. We illustrate this for Dublin, Ireland, where local citizens&rsquo; value-based food identities were galvanized to activate ecological awareness and promote sustainable seafood consumption. Within this democratic food governance framework, approaches such as open science, transdisciplinarity, and citizen engagement are fit-for-purpose to engage diverse food actors from government, industry, academia, and civil society in shared dialogue and action to transform food systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04384v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04384v1">üìÑ Download PDF</a></p><hr><h3 id=mapping-data-labour-supply-chain-in-africa-in-an-era-of-digital-apartheid-a-struggle-for-recognitionhttpsarxivorgabs251204269v1><a href=https://arxiv.org/abs/2512.04269v1>Mapping Data Labour Supply Chain in Africa in an Era of Digital Apartheid: a Struggle for Recognition</a><a hidden class=anchor aria-hidden=true href=#mapping-data-labour-supply-chain-in-africa-in-an-era-of-digital-apartheid-a-struggle-for-recognitionhttpsarxivorgabs251204269v1>#</a></h3><p><strong>Authors:</strong> Jessica Pidoux, Sofia Kypraiou, Sonia Kgomo, Kauna Ibrahim Malgwi, Richard Mwaura Mathenge, Mophat Okinyi, James Oyange, Mariame Tighanimine
<strong>Venue:</strong> arXiv (2025)</p><p>Content moderation and data labelling work has shifted to the Global South, particularly Africa, where workers operate under precarious conditions while remaining invisible to users. This study addresses the gap in understanding the scope of this industry and the working conditions of African content moderation workforce through a participatory approach. We collaborated with a union of content moderators to conduct desk research, deploy a questionnaire (n=81), and gather ethnographic observations across nine months that could answer their social needs. Our findings show that content moderation operations span 43 out of 55 African countries, involving 17 major firms serving predominantly North-American and European clients, with workers facing insecurity and inadequate psychological support. We contribute the first comprehensive map of Africa&rsquo;s content moderation industry, demonstrate a participatory methodology that centers workers&rsquo; collective actions in documenting their conditions, and apply Honneth&rsquo;s ``struggle for recognition&rsquo;&rsquo; framework to understand data workers&rsquo; demands for professional acknowledgement.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04269v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04269v1">üìÑ Download PDF</a></p><hr><h3 id=toward-virtuous-reinforcement-learninghttpsarxivorgabs251204246v1><a href=https://arxiv.org/abs/2512.04246v1>Toward Virtuous Reinforcement Learning</a><a hidden class=anchor aria-hidden=true href=#toward-virtuous-reinforcement-learninghttpsarxivorgabs251204246v1>#</a></h3><p><strong>Authors:</strong> Majid Ghasemi, Mark Crowley
<strong>Venue:</strong> arXiv (2025)</p><p>This paper critiques common patterns in machine ethics for Reinforcement Learning (RL) and argues for a virtue focused alternative. We highlight two recurring limitations in much of the current literature: (i) rule based (deontological) methods that encode duties as constraints or shields often struggle under ambiguity and nonstationarity and do not cultivate lasting habits, and (ii) many reward based approaches, especially single objective RL, implicitly compress diverse moral considerations into a single scalar signal, which can obscure trade offs and invite proxy gaming in practice. We instead treat ethics as policy level dispositions, that is, relatively stable habits that hold up when incentives, partners, or contexts change. This shifts evaluation beyond rule checks or scalar returns toward trait summaries, durability under interventions, and explicit reporting of moral trade offs. Our roadmap combines four components: (1) social learning in multi agent RL to acquire virtue like patterns from imperfect but normatively informed exemplars; (2) multi objective and constrained formulations that preserve value conflicts and incorporate risk aware criteria to guard against harm; (3) affinity based regularization toward updateable virtue priors that support trait like stability under distribution shift while allowing norms to evolve; and (4) operationalizing diverse ethical traditions as practical control signals, making explicit the value and cultural assumptions that shape ethical RL benchmarks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04246v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04246v1">üìÑ Download PDF</a></p><hr><h3 id=post-cold-war-diaspora-of-russian-particle-physicistshttpsarxivorgabs251204052v1><a href=https://arxiv.org/abs/2512.04052v1>Post-Cold War Diaspora of Russian Particle Physicists</a><a hidden class=anchor aria-hidden=true href=#post-cold-war-diaspora-of-russian-particle-physicistshttpsarxivorgabs251204052v1>#</a></h3><p><strong>Authors:</strong> Vladimir Shiltsev
<strong>Venue:</strong> arXiv (2025)</p><p>While the migration of scientists from the Soviet Union to the West occurred at a modest pace during the 1970s and 1980s, the dissolution of the USSR in 1991 and the ensuing economic and social hardships precipitated a massive exodus that amounted to a true brain drain. The international physics community, particularly in Europe and the United States, absorbed a substantial influx of specialists in nuclear, high-energy, and accelerator physics, including both seasoned scientists and engineers as well as promising graduate students and postdoctoral fellows. Many of these emigre researchers went on to assume leadership positions, drive major experimental and theoretical initiatives, and achieve scientific distinction that equaled or even surpassed their accomplishments at home. In this article we explore the defining features of this post Cold War scientific diaspora, assess its impact on Russia research infrastructure and capabilities, and evaluate its enduring contributions to global particle physics collaborations and discoveries.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04052v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04052v1">üìÑ Download PDF</a></p><hr><h3 id=polarization-by-design-how-elites-could-shape-mass-preferences-as-ai-reduces-persuasion-costshttpsarxivorgabs251204047v1><a href=https://arxiv.org/abs/2512.04047v1>Polarization by Design: How Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs</a><a hidden class=anchor aria-hidden=true href=#polarization-by-design-how-elites-could-shape-mass-preferences-as-ai-reduces-persuasion-costshttpsarxivorgabs251204047v1>#</a></h3><p><strong>Authors:</strong> Nadav Kunievsky
<strong>Venue:</strong> arXiv (2025)</p><p>In democracies, major policy decisions typically require some form of majority or consensus, so elites must secure mass support to govern. Historically, elites could shape support only through limited instruments like schooling and mass media; advances in AI-driven persuasion sharply reduce the cost and increase the precision of shaping public opinion, making the distribution of preferences itself an object of deliberate design. We develop a dynamic model in which elites choose how much to reshape the distribution of policy preferences, subject to persuasion costs and a majority rule constraint. With a single elite, any optimal intervention tends to push society toward more polarized opinion profiles - a <code>polarization pull'' - and improvements in persuasion technology accelerate this drift. When two opposed elites alternate in power, the same technology also creates incentives to park society in </code>semi-lock&rsquo;&rsquo; regions where opinions are more cohesive and harder for a rival to overturn, so advances in persuasion can either heighten or dampen polarization depending on the environment. Taken together, cheaper persuasion technologies recast polarization as a strategic instrument of governance rather than a purely emergent social byproduct, with important implications for democratic stability as AI capabilities advance.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04047v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04047v1">üìÑ Download PDF</a></p><hr><h3 id=when-to-say-hi---learn-to-open-a-conversation-with-an-in-the-wild-datasethttpsarxivorgabs251203991v1><a href=https://arxiv.org/abs/2512.03991v1>When to Say &ldquo;Hi&rdquo; - Learn to Open a Conversation with an in-the-wild Dataset</a><a hidden class=anchor aria-hidden=true href=#when-to-say-hi---learn-to-open-a-conversation-with-an-in-the-wild-datasethttpsarxivorgabs251203991v1>#</a></h3><p><strong>Authors:</strong> Michael Schiffmann, Felix Struth, Sabina Jeschke, Anja Richert
<strong>Venue:</strong> arXiv (2025)</p><p>The social capabilities of socially interactive agents (SIA) are a key to successful and smooth interactions between the user and the SIA. A successful start of the interaction is one of the essential factors for satisfying SIA interactions. For a service and information task in which the SIA helps with information, e.g. about the location, it is an important skill to master the opening of the conversation and to recognize which interlocutor opens the conversation and when. We are therefore investigating the extent to which the opening of the conversation can be trained using the user&rsquo;s body language as an input for machine learning to ensure smooth conversation starts for the interaction. In this paper we propose the Interaction Initiation System (IIS) which we developed, trained and validated using an in-the-wild data set. In a field test at the Deutsches Museum Bonn, a Furhat robot from Furhat Robotics was used as a service and information point. Over the period of use we collected the data of \textit{N} = 201 single user interactions for the training of the algorithms. We can show that the IIS, achieves a performance that allows the conclusion that this system is able to determine the greeting period and the opener of the interaction.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03991v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03991v1">üìÑ Download PDF</a></p><hr><h3 id=aggregating-maximal-cliques-in-real-world-graphshttpsarxivorgabs251203960v1><a href=https://arxiv.org/abs/2512.03960v1>Aggregating maximal cliques in real-world graphs</a><a hidden class=anchor aria-hidden=true href=#aggregating-maximal-cliques-in-real-world-graphshttpsarxivorgabs251203960v1>#</a></h3><p><strong>Authors:</strong> Noga Alon, Sabyasachi Basu, Shweta Jain, Haim Kaplan, Jakub ≈ÅƒÖcki, Blair D. Sullivan
<strong>Venue:</strong> arXiv (2025)</p><p>Maximal clique enumeration is a fundamental graph mining task, but its utility is often limited by computational intractability and highly redundant output. To address these challenges, we introduce \emph{$œÅ$-dense aggregators}, a novel approach that succinctly captures maximal clique structure. Instead of listing all cliques, we identify a small collection of clusters with edge density at least $œÅ$ that collectively contain every maximal clique.
In contrast to maximal clique enumeration, we prove that for all $œÅ&lt; 1$, every graph admits a $œÅ$-dense aggregator of \emph{sub-exponential} size, $n^{O(\log_{1/œÅ}n)}$, and provide an algorithm achieving this bound. For graphs with bounded degeneracy, a typical characteristic of real-world networks, our algorithm runs in near-linear time and produces near-linear size aggregators. We also establish a matching lower bound on aggregator size, proving our results are essentially tight. In an empirical evaluation on real-world networks, we demonstrate significant practical benefits for the use of aggregators: our algorithm is consistently faster than the state-of-the-art clique enumeration algorithm, with median speedups over $6\times$ for $œÅ=0.1$ (and over $300\times$ in an extreme case), while delivering a much more concise structural summary.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03960v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03960v1">üìÑ Download PDF</a></p><hr><h3 id=dsp-a-statistically-principled-structural-polarization-measurehttpsarxivorgabs251203937v1><a href=https://arxiv.org/abs/2512.03937v1>DSP: A Statistically-Principled Structural Polarization Measure</a><a hidden class=anchor aria-hidden=true href=#dsp-a-statistically-principled-structural-polarization-measurehttpsarxivorgabs251203937v1>#</a></h3><p><strong>Authors:</strong> Giulia Preti, Matteo Riondato, Aristides Gionis, Gianmarco De Francisci Morales
<strong>Venue:</strong> arXiv (2025)</p><p>Social and information networks may become polarized, leading to echo chambers and political gridlock. Accurately measuring this phenomenon is a critical challenge. Existing measures often conflate genuine structural division with random topological features, yielding misleadingly high polarization scores on random networks, and failing to distinguish real-world networks from randomized null models. We introduce DSP, a Diffusion-based Structural Polarization measure designed from first principles to correct for such biases. DSP removes the arbitrary concept of &lsquo;influencers&rsquo; used by the popular Random Walk Controversy (RWC) score, instead treating every node as a potential origin for a random walk. To validate our approach, we introduce a set of desirable properties for polarization measures, expressed through reference topologies with known structural properties. We show that DSP satisfies these desiderata, being near-zero for non-polarized structures such as cliques and random networks, while correctly capturing the expected polarization of reference topologies such as monochromatic-splittable networks. Our method applied to U.S. Congress datasets uncovers trends of increasing polarization in recent years. By integrating a null model into its core definition, DSP provides a reliable and interpretable diagnostic tool, highlighting the necessity of statistically-grounded metrics to analyze societal fragmentation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03937v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03937v1">üìÑ Download PDF</a></p><hr><h3 id=generating-a-contact-matrix-for-aged-care-settings-in-australia-an-agent-based-model-studyhttpsarxivorgabs251203866v1><a href=https://arxiv.org/abs/2512.03866v1>Generating a Contact Matrix for Aged Care Settings in Australia: an agent-based model study</a><a hidden class=anchor aria-hidden=true href=#generating-a-contact-matrix-for-aged-care-settings-in-australia-an-agent-based-model-studyhttpsarxivorgabs251203866v1>#</a></h3><p><strong>Authors:</strong> Haley Stone, C. Raina MacIntyre, Mohana Kunasekaran, Chris Poulos, David Heslop
<strong>Venue:</strong> arXiv (2025)</p><p>This study presents an agent-based model (ABM) developed to simulate staff and resident interactions within a synthetic aged care facility, capturing movement, task execution, and proximity-based contact events across three staff shifts and varying levels of resident care. Contacts were defined by spatial thresholds (1.5 m and 3 m) and cumulative duration, enabling the generation of detailed contact matrices. Simulation results showed that low and medium care residents experienced the highest frequency of interactions, particularly with staff on morning and afternoon shifts, while high care residents and night staff had substantially fewer contacts. Contact rates varied significantly by care level and shift, confirmed through Poisson-based regression modelling. Temporal analyses revealed clustering of high-risk contacts during structured daily routines, especially communal and care activities. An integrated airborne transmission module, seeded with a single infectious staff member, demonstrated that infection risk was highest during high-contact shifts and among medium care residents. Vaccination scenarios reduced predicted transmission by up to 68%, with the greatest impact observed when both staff and residents were vaccinated. These findings highlight the importance of accounting for contact heterogeneity in aged care and demonstrate the utility of ABMs for evaluating targeted infection control strategies in high-risk, enclosed environments.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03866v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03866v1">üìÑ Download PDF</a></p><hr><h3 id=does-globalization-promote-or-hinder-sustainable-development-evidence-from-turkiye-on-the-three-dimensions-of-globalizationhttpsarxivorgabs251203822v1><a href=https://arxiv.org/abs/2512.03822v1>Does Globalization Promote or Hinder Sustainable Development? Evidence from Turkiye on the Three Dimensions of Globalization</a><a hidden class=anchor aria-hidden=true href=#does-globalization-promote-or-hinder-sustainable-development-evidence-from-turkiye-on-the-three-dimensions-of-globalizationhttpsarxivorgabs251203822v1>#</a></h3><p><strong>Authors:</strong> Emre Akusta
<strong>Venue:</strong> arXiv (2025)</p><p>This study analyzes the impact of globalization on sustainable development in Turkiye. We used the ARDL method with annual data for the period 2000-2021. Results reveal that economic globalization promotes positively to sustainable development in the short run with a coefficient of 0.144 and in the long run with a 0.153 coefficient. Although social globalization has a negative impact with a coefficient of -0.150 in the short run, this effect turns positive with a coefficient of 0.080 in the long run. Political globalization strongly supports sustainable development with a coefficient of 0.254 in the short run and 2.634 in the long run. Finally, total globalization has a positive impact on sustainable development in the short and long run with coefficients of 0.339 and 0.196, respectively.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03822v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03822v1">üìÑ Download PDF</a></p><hr><h3 id=from-micro-distributions-to-macro-regularities-a-critique-and-reconstruction-of-the-production-function-based-on-the-maximum-entropy-principlehttpsarxivorgabs251203812v1><a href=https://arxiv.org/abs/2512.03812v1>From Micro-Distributions to Macro-Regularities: A Critique and Reconstruction of the Production Function Based on the Maximum Entropy Principle</a><a hidden class=anchor aria-hidden=true href=#from-micro-distributions-to-macro-regularities-a-critique-and-reconstruction-of-the-production-function-based-on-the-maximum-entropy-principlehttpsarxivorgabs251203812v1>#</a></h3><p><strong>Authors:</strong> Jihyuan Liuh
<strong>Venue:</strong> arXiv (2025)</p><p>This paper aims to provide a micro-foundation for the Cobb-Douglas production function based on statistical physics, and to launch a critique of its political-economic implications. By introducing the Maximum Entropy Principle and an axiom of scale invariance, we prove that in an economic system with incomplete information, the most unbiased distribution of micro-level technical coefficients must take the form of a truncated power law. Based on this, statistical aggregation naturally leads to the emergence of a constant-returns-to-scale Cobb-Douglas function at the macro level. This result not only provides a micro-foundation for neoclassical growth models that does not rely on a representative agent or value aggregation of capital but, more importantly, reveals that the aggregate production function is essentially a lossy compression of micro-level information. In this compression process, the social-historical relations embedded in distribution parameters are &rsquo;naturalized&rsquo; into seemingly eternal technical laws, which is the manifestation of Marx&rsquo;s critique of &lsquo;fetishism&rsquo; at the level of mathematical logic. This paper further deepens the understanding of the production function as a statistical phenomenon rather than a technical law through dialogues with Marx, the Cambridge School, and Shaikh.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03812v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03812v1">üìÑ Download PDF</a></p><hr><h3 id=mpcformer-a-physics-informed-data-driven-approach-for-explainable-socially-aware-autonomous-drivinghttpsarxivorgabs251203795v1><a href=https://arxiv.org/abs/2512.03795v1>MPCFormer: A physics-informed data-driven approach for explainable socially-aware autonomous driving</a><a hidden class=anchor aria-hidden=true href=#mpcformer-a-physics-informed-data-driven-approach-for-explainable-socially-aware-autonomous-drivinghttpsarxivorgabs251203795v1>#</a></h3><p><strong>Authors:</strong> Jia Hu, Zhexi Lian, Xuerun Yan, Ruiang Bi, Dou Shen, Yu Ruan, Haoran Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Autonomous Driving (AD) vehicles still struggle to exhibit human-like behavior in highly dynamic and interactive traffic scenarios. The key challenge lies in AD&rsquo;s limited ability to interact with surrounding vehicles, largely due to a lack of understanding the underlying mechanisms of social interaction. To address this issue, we introduce MPCFormer, an explainable socially-aware autonomous driving approach with physics-informed and data-driven coupled social interaction dynamics. In this model, the dynamics are formulated into a discrete space-state representation, which embeds physics priors to enhance modeling explainability. The dynamics coefficients are learned from naturalistic driving data via a Transformer-based encoder-decoder architecture. To the best of our knowledge, MPCFormer is the first approach to explicitly model the dynamics of multi-vehicle social interactions. The learned social interaction dynamics enable the planner to generate manifold, human-like behaviors when interacting with surrounding traffic. By leveraging the MPC framework, the approach mitigates the potential safety risks typically associated with purely learning-based methods. Open-looped evaluation on NGSIM dataset demonstrates that MPCFormer achieves superior social interaction awareness, yielding the lowest trajectory prediction errors compared with other state-of-the-art approach. The prediction achieves an ADE as low as 0.86 m over a long prediction horizon of 5 seconds. Close-looped experiments in highly intense interaction scenarios, where consecutive lane changes are required to exit an off-ramp, further validate the effectiveness of MPCFormer. Results show that MPCFormer achieves the highest planning success rate of 94.67%, improves driving efficiency by 15.75%, and reduces the collision rate from 21.25% to 0.5%, outperforming a frontier Reinforcement Learning (RL) based planner.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03795v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03795v1">üìÑ Download PDF</a></p><hr><h3 id=quantum-simulations-of-opinion-dynamicshttpsarxivorgabs251203770v1><a href=https://arxiv.org/abs/2512.03770v1>Quantum Simulations of Opinion Dynamics</a><a hidden class=anchor aria-hidden=true href=#quantum-simulations-of-opinion-dynamicshttpsarxivorgabs251203770v1>#</a></h3><p><strong>Authors:</strong> Xingyu Guo, Xiaoyang Wang, Lingxiao Wang
<strong>Venue:</strong> arXiv (2025)</p><p>Quantum computing offers powerful new approaches for modeling complex social phenomena. Here, we propose and demonstrate quantum simulations of opinion dynamics, leveraging quantum superposition, measurement-induced state collapse, and entanglement to model realistic psychological and social processes. Specifically, we develop quantum models of opinion dynamics, solving exactly and simulating on IBM Quantum hardware. Our results, based on quantum devices and validated with practical quantum circuits, illustrate how quantum effects can enhance understanding of consensus formation, polarization, and collective decision-making. These findings pave the way for further exploration into quantum-enhanced social modeling, highlighting the potential of near-term quantum computers for simulating collective behavior in complex systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03770v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03770v1">üìÑ Download PDF</a></p><hr><h3 id=eminds-understanding-user-behavior-progression-for-mental-health-exploration-on-social-mediahttpsarxivorgabs251203495v1><a href=https://arxiv.org/abs/2512.03495v1>EMINDS: Understanding User Behavior Progression for Mental Health Exploration on Social Media</a><a hidden class=anchor aria-hidden=true href=#eminds-understanding-user-behavior-progression-for-mental-health-exploration-on-social-mediahttpsarxivorgabs251203495v1>#</a></h3><p><strong>Authors:</strong> Rui Sheng, Yifang Wang, Xingbo Wang, Shun Dai, Qingyu Guo, Tai-Quan Peng, Huamin Qu, Dongyu Liu
<strong>Venue:</strong> arXiv (2025)</p><p>Mental health is an urgent societal issue, and social scientists are increasingly turning to online mental health communities (OMHCs) to analyze user behavior data for early intervention. However, existing sequence mining techniques fall short of the urgent need to explore the behavior progression of different groups (e.g., recovery or deterioration groups) and track the potential long-term impact of behaviors on mental health status. To address this issue, we introduce EMINDS, a visual analytics system built on a novel automatic mining pipeline that extracts distinct behavior stages and assesses the potential impact of frequent stage patterns on mental health status over time. The system includes a set of interactive visualizations that summarize the meaning of each behavior stage and the evolution of different stage patterns. We feature a pattern-centric Sankey diagram to reveal contextual information about the impact of stage patterns on mental health, helping experts understand the specific changes in sequences before and after a stage pattern. We evaluated the effectiveness and usability of EMINDS through two case studies and expert interviews, which examined the potential stage patterns impacting long-term mental health by analyzing user behaviors on Reddit.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03495v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03495v1">üìÑ Download PDF</a></p><hr><h3 id=full-stack-alignment-co-aligning-ai-and-institutions-with-thick-models-of-valuehttpsarxivorgabs251203399v1><a href=https://arxiv.org/abs/2512.03399v1>Full-Stack Alignment: Co-Aligning AI and Institutions with Thick Models of Value</a><a hidden class=anchor aria-hidden=true href=#full-stack-alignment-co-aligning-ai-and-institutions-with-thick-models-of-valuehttpsarxivorgabs251203399v1>#</a></h3><p><strong>Authors:</strong> Joe Edelman, Tan Zhi-Xuan, Ryan Lowe, Oliver Klingefjord, Vincent Wang-Mascianica, Matija Franklin, Ryan Othniel Kearns, Ellie Hain, Atrisha Sarkar, Michiel Bakker, Fazl Barez, David Duvenaud, Jakob Foerster, Iason Gabriel, Joseph Gubbels, Bryce Goodman, Andreas Haupt, Jobst Heitzig, Julian Jara-Ettinger, Atoosa Kasirzadeh, James Ravi Kirkpatrick, Andrew Koh, W. Bradley Knox, Philipp Koralus, Joel Lehman, Sydney Levine, Samuele Marro, Manon Revel, Toby Shorin, Morgan Sutherland, Michael Henry Tessler, Ivan Vendrov, James Wilken-Smith
<strong>Venue:</strong> arXiv (2025)</p><p>Beneficial societal outcomes cannot be guaranteed by aligning individual AI systems with the intentions of their operators or users. Even an AI system that is perfectly aligned to the intentions of its operating organization can lead to bad outcomes if the goals of that organization are misaligned with those of other institutions and individuals. For this reason, we need full-stack alignment, the concurrent alignment of AI systems and the institutions that shape them with what people value. This can be done without imposing a particular vision of individual or collective flourishing. We argue that current approaches for representing values, such as utility functions, preference orderings, or unstructured text, struggle to address these and other issues effectively. They struggle to distinguish values from other signals, to support principled normative reasoning, and to model collective goods. We propose thick models of value will be needed. These structure the way values and norms are represented, enabling systems to distinguish enduring values from fleeting preferences, to model the social embedding of individual choices, and to reason normatively, applying values in new domains. We demonstrate this approach in five areas: AI value stewardship, normatively competent agents, win-win negotiation systems, meaning-preserving economic mechanisms, and democratic regulatory institutions.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03399v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03399v1">üìÑ Download PDF</a></p><hr><h3 id=epistemic-substitution-how-grokipedias-ai-generated-encyclopedia-restructures-authorityhttpsarxivorgabs251203337v1><a href=https://arxiv.org/abs/2512.03337v1>Epistemic Substitution: How Grokipedia&rsquo;s AI-Generated Encyclopedia Restructures Authority</a><a hidden class=anchor aria-hidden=true href=#epistemic-substitution-how-grokipedias-ai-generated-encyclopedia-restructures-authorityhttpsarxivorgabs251203337v1>#</a></h3><p><strong>Authors:</strong> Aliakbar Mehdizadeh, Martin Hilbert
<strong>Venue:</strong> arXiv (2025)</p><p>A quarter century ago, Wikipedia&rsquo;s decentralized, crowdsourced, and consensus-driven model replaced the centralized, expert-driven, and authority-based standard for encyclopedic knowledge curation. The emergence of generative AI encyclopedias, such as Grokipedia, possibly presents another potential shift in epistemic evolution. This study investigates whether AI- and human-curated encyclopedias rely on the same foundations of authority. We conducted a multi-scale comparative analysis of the citation networks from 72 matched article pairs, which cite a total of almost 60,000 sources. Using an 8-category epistemic classification, we mapped the &ldquo;epistemic profiles&rdquo; of the articles on each platform. Our findings reveal several quantitative and qualitative differences in how knowledge is sourced and encyclopedia claims are epistemologically justified. Grokipedia replaces Wikipedia&rsquo;s heavy reliance on peer-reviewed &ldquo;Academic & Scholarly&rdquo; work with a notable increase in &ldquo;User-generated&rdquo; and &ldquo;Civic organization&rdquo; sources. Comparative network analyses further show that Grokipedia employs very different epistemological profiles when sourcing leisure topics (such as Sports and Entertainment) and more societal sensitive civic topics (such as Politics & Conflicts, Geographical Entities, and General Knowledge & Society). Finally, we find a &ldquo;scaling-law for AI-generated knowledge sourcing&rdquo; that shows a linear relationship between article length and citation density, which is distinct from collective human reference sourcing. We conclude that this first implementation of an LLM-based encyclopedia does not merely automate knowledge production but restructures it. Given the notable changes and the important role of encyclopedias, we suggest the continuation and deepening of algorithm audits, such as the one presented here, in order to understand the ongoing epistemological shifts.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03337v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03337v1">üìÑ Download PDF</a></p><hr><h3 id=evaluating-generalization-capabilities-of-llm-based-agents-in-mixed-motive-scenarios-using-concordiahttpsarxivorgabs251203318v1><a href=https://arxiv.org/abs/2512.03318v1>Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia</a><a hidden class=anchor aria-hidden=true href=#evaluating-generalization-capabilities-of-llm-based-agents-in-mixed-motive-scenarios-using-concordiahttpsarxivorgabs251203318v1>#</a></h3><p><strong>Authors:</strong> Chandler Smith, Marwa Abdulhai, Manfred Diaz, Marko Tesic, Rakshit S. Trivedi, Alexander Sasha Vezhnevets, Lewis Hammond, Jesse Clifton, Minsuk Chang, Edgar A. Du√©√±ez-Guzm√°n, John P. Agapiou, Jayd Matyas, Danny Karmon, Akash Kundu, Aliaksei Korshuk, Ananya Ananya, Arrasy Rahman, Avinaash Anand Kulandaivel, Bain McHale, Beining Zhang, Buyantuev Alexander, Carlos Saith Rodriguez Rojas, Caroline Wang, Chetan Talele, Chenao Liu, Chichen Lin, Diana Riazi, Di Yang Shi, Emanuel Tewolde, Elizaveta Tennant, Fangwei Zhong, Fuyang Cui, Gang Zhao, Gema Parre√±o Piqueras, Hyeonggeun Yun, Ilya Makarov, Jiaxun Cui, Jebish Purbey, Jim Dilkes, Jord Nguyen, Lingyun Xiao, Luis Felipe Giraldo, Manuela Chacon-Chamorro, Manuel Sebastian Rios Beltran, Marta Emili Garc√≠a Segura, Mengmeng Wang, Mogtaba Alim, Nicanor Quijano, Nico Schiavone, Olivia Macmillan-Scott, Oswaldo Pe√±a, Peter Stone, Ram Mohan Rao Kadiyala, Rolando Fernandez, Ruben Manrique, Sunjia Lu, Sheila A. McIlraith, Shamika Dhuri, Shuqing Shi, Siddhant Gupta, Sneheel Sarangi, Sriram Ganapathi Subramanian, Taehun Cha, Toryn Q. Klassen, Wenming Tu, Weijian Fan, Wu Ruiyang, Xue Feng, Yali Du, Yang Liu, Yiding Wang, Yipeng Kang, Yoonchang Sung, Yuxuan Chen, Zhaowei Zhang, Zhihan Wang, Zhiqiang Wu, Ziang Chen, Zilong Zheng, Zixia Jia, Ziyan Wang, Dylan Hadfield-Menell, Natasha Jaques, Tim Baarslag, Jose Hernandez-Orallo, Joel Z. Leibo
<strong>Venue:</strong> arXiv (2025)</p><p>Large Language Model (LLM) agents have demonstrated impressive capabilities for social interaction and are increasingly being deployed in situations where they might engage with both human and artificial agents. These interactions represent a critical frontier for LLM-based agents, yet existing evaluation methods fail to measure how well these capabilities generalize to novel social situations. In this paper, we introduce a method for evaluating the ability of LLM-based agents to cooperate in zero-shot, mixed-motive environments using Concordia, a natural language multi-agent simulation environment. Our method measures general cooperative intelligence by testing an agent&rsquo;s ability to identify and exploit opportunities for mutual gain across diverse partners and contexts. We present empirical results from the NeurIPS 2024 Concordia Contest, where agents were evaluated on their ability to achieve mutual gains across a suite of diverse scenarios ranging from negotiation to collective action problems. Our findings reveal significant gaps between current agent capabilities and the robust generalization required for reliable cooperation, particularly in scenarios demanding persuasion and norm enforcement.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03318v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03318v1">üìÑ Download PDF</a></p><hr><h3 id=associating-healthcare-teamwork-with-patient-outcomes-for-predictive-analysishttpsarxivorgabs251203296v1><a href=https://arxiv.org/abs/2512.03296v1>Associating Healthcare Teamwork with Patient Outcomes for Predictive Analysis</a><a hidden class=anchor aria-hidden=true href=#associating-healthcare-teamwork-with-patient-outcomes-for-predictive-analysishttpsarxivorgabs251203296v1>#</a></h3><p><strong>Authors:</strong> Hsiao-Ying Lu, Kwan-Liu Ma
<strong>Venue:</strong> arXiv (2025)</p><p>Cancer treatment outcomes are influenced not only by clinical and demographic factors but also by the collaboration of healthcare teams. However, prior work has largely overlooked the potential role of human collaboration in shaping patient survival. This paper presents an applied AI approach to uncovering the impact of healthcare professionals&rsquo; (HCPs) collaboration-captured through electronic health record (EHR) systems-on cancer patient outcomes. We model EHR-mediated HCP interactions as networks and apply machine learning techniques to detect predictive signals of patient survival embedded in these collaborations. Our models are cross validated to ensure generalizability, and we explain the predictions by identifying key network traits associated with improved outcomes. Importantly, clinical experts and literature validate the relevance of the identified crucial collaboration traits, reinforcing their potential for real-world applications. This work contributes to a practical workflow for leveraging digital traces of collaboration and AI to assess and improve team-based healthcare. The approach is potentially transferable to other domains involving complex collaboration and offers actionable insights to support data-informed interventions in healthcare delivery.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03296v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03296v1">üìÑ Download PDF</a></p><hr><h3 id=culture-affordance-atlas-reconciling-object-diversity-through-functional-mappinghttpsarxivorgabs251203173v1><a href=https://arxiv.org/abs/2512.03173v1>Culture Affordance Atlas: Reconciling Object Diversity Through Functional Mapping</a><a hidden class=anchor aria-hidden=true href=#culture-affordance-atlas-reconciling-object-diversity-through-functional-mappinghttpsarxivorgabs251203173v1>#</a></h3><p><strong>Authors:</strong> Joan Nwatu, Longju Bai, Oana Ignat, Rada Mihalcea
<strong>Venue:</strong> arXiv (2025)</p><p>Culture shapes the objects people use and for what purposes, yet mainstream Vision-Language (VL) datasets frequently exhibit cultural biases, disproportionately favoring higher-income, Western contexts. This imbalance reduces model generalizability and perpetuates performance disparities, especially impacting lower-income and non-Western communities. To address these disparities, we propose a novel function-centric framework that categorizes objects by the functions they fulfill, across diverse cultural and economic contexts. We implement this framework by creating the Culture Affordance Atlas, a re-annotated and culturally grounded restructuring of the Dollar Street dataset spanning 46 functions and 288 objects publicly available at <a href=https://lit.eecs.umich.edu/CultureAffordance-Atlas/index.html>https://lit.eecs.umich.edu/CultureAffordance-Atlas/index.html</a>. Through extensive empirical analyses using the CLIP model, we demonstrate that function-centric labels substantially reduce socioeconomic performance gaps between high- and low-income groups by a median of 6 pp (statistically significant), improving model effectiveness for lower-income contexts. Furthermore, our analyses reveals numerous culturally essential objects that are frequently overlooked in prominent VL datasets. Our contributions offer a scalable pathway toward building inclusive VL datasets and equitable AI systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03173v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03173v1">üìÑ Download PDF</a></p><hr><h3 id=the-moral-consistency-pipeline-continuous-ethical-evaluation-for-large-language-modelshttpsarxivorgabs251203026v1><a href=https://arxiv.org/abs/2512.03026v1>The Moral Consistency Pipeline: Continuous Ethical Evaluation for Large Language Models</a><a hidden class=anchor aria-hidden=true href=#the-moral-consistency-pipeline-continuous-ethical-evaluation-for-large-language-modelshttpsarxivorgabs251203026v1>#</a></h3><p><strong>Authors:</strong> Saeid Jamshidi, Kawser Wazed Nafi, Arghavan Moradi Dakhel, Negar Shahabi, Foutse Khomh
<strong>Venue:</strong> arXiv (2025)</p><p>The rapid advancement and adaptability of Large Language Models (LLMs) highlight the need for moral consistency, the capacity to maintain ethically coherent reasoning across varied contexts. Existing alignment frameworks, structured approaches designed to align model behavior with human ethical and social norms, often rely on static datasets and post-hoc evaluations, offering limited insight into how ethical reasoning may evolve across different contexts or temporal scales. This study presents the Moral Consistency Pipeline (MoCoP), a dataset-free, closed-loop framework for continuously evaluating and interpreting the moral stability of LLMs. MoCoP combines three supporting layers: (i) lexical integrity analysis, (ii) semantic risk estimation, and (iii) reasoning-based judgment modeling within a self-sustaining architecture that autonomously generates, evaluates, and refines ethical scenarios without external supervision. Our empirical results on GPT-4-Turbo and DeepSeek suggest that MoCoP effectively captures longitudinal ethical behavior, revealing a strong inverse relationship between ethical and toxicity dimensions (correlation rET = -0.81, p value less than 0.001) and a near-zero association with response latency (correlation rEL approximately equal to 0). These findings demonstrate that moral coherence and linguistic safety tend to emerge as stable and interpretable characteristics of model behavior rather than short-term fluctuations. Furthermore, by reframing ethical evaluation as a dynamic, model-agnostic form of moral introspection, MoCoP offers a reproducible foundation for scalable, continuous auditing and advances the study of computational morality in autonomous AI systems.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03026v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03026v1">üìÑ Download PDF</a></p><hr><h3 id=from-moderation-to-mediation-can-llms-serve-as-mediators-in-online-flame-warshttpsarxivorgabs251203005v1><a href=https://arxiv.org/abs/2512.03005v1>From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?</a><a hidden class=anchor aria-hidden=true href=#from-moderation-to-mediation-can-llms-serve-as-mediators-in-online-flame-warshttpsarxivorgabs251203005v1>#</a></h3><p><strong>Authors:</strong> Dawei Li, Abdullah Alnaibari, Arslan Bisharat, Manny Sandoval, Deborah Hall, Yasin Silva, Huan Liu
<strong>Venue:</strong> arXiv (2025)</p><p>The rapid advancement of large language models (LLMs) has opened new possibilities for AI for good applications. As LLMs increasingly mediate online communication, their potential to foster empathy and constructive dialogue becomes an important frontier for responsible AI research. This work explores whether LLMs can serve not only as moderators that detect harmful content, but as mediators capable of understanding and de-escalating online conflicts. Our framework decomposes mediation into two subtasks: judgment, where an LLM evaluates the fairness and emotional dynamics of a conversation, and steering, where it generates empathetic, de-escalatory messages to guide participants toward resolution. To assess mediation quality, we construct a large Reddit-based dataset and propose a multi-stage evaluation pipeline combining principle-based scoring, user simulation, and human comparison. Experiments show that API-based models outperform open-source counterparts in both reasoning and intervention alignment when doing mediation. Our findings highlight both the promise and limitations of current LLMs as emerging agents for online social mediation.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.03005v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.03005v1">üìÑ Download PDF</a></p><hr><h3 id=benchmarking-scientific-understanding-and-reasoning-for-video-generation-using-videoscience-benchhttpsarxivorgabs251202942v1><a href=https://arxiv.org/abs/2512.02942v1>Benchmarking Scientific Understanding and Reasoning for Video Generation using VideoScience-Bench</a><a hidden class=anchor aria-hidden=true href=#benchmarking-scientific-understanding-and-reasoning-for-video-generation-using-videoscience-benchhttpsarxivorgabs251202942v1>#</a></h3><p><strong>Authors:</strong> Lanxiang Hu, Abhilash Shankarampeta, Yixin Huang, Zilin Dai, Haoyang Yu, Yujie Zhao, Haoqiang Kang, Daniel Zhao, Tajana Rosing, Hao Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>The next frontier for video generation lies in developing models capable of zero-shot reasoning, where understanding real-world scientific laws is crucial for accurate physical outcome modeling under diverse conditions. However, existing video benchmarks are physical commonsense-based, offering limited insight into video models&rsquo; scientific reasoning capability. We introduce VideoScience-Bench, a benchmark designed to evaluate undergraduate-level scientific understanding in video models. Each prompt encodes a composite scientific scenario that requires understanding and reasoning across multiple scientific concepts to generate the correct phenomenon. The benchmark comprises 200 carefully curated prompts spanning 14 topics and 103 concepts in physics and chemistry. We conduct expert-annotated evaluations across seven state-of-the-art video models in T2V and I2V settings along five dimensions: Prompt Consistency, Phenomenon Congruency, Correct Dynamism, Immutability, and Spatio-Temporal Continuity. Using a VLM-as-a-Judge to assess video generations, we observe strong correlation with human assessments. To the best of our knowledge, VideoScience-Bench is the first benchmark to evaluate video models not only as generators but also as reasoners, requiring their generations to demonstrate scientific understanding consistent with expected physical and chemical phenomena. Our data and evaluation code are available at: \href{https://github.com/hao-ai-lab/VideoScience}{github.com/hao-ai-lab/VideoScience}.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02942v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02942v1">üìÑ Download PDF</a></p><hr><h3 id=learning-multimodal-embeddings-for-traffic-accident-prediction-and-causal-estimationhttpsarxivorgabs251202920v1><a href=https://arxiv.org/abs/2512.02920v1>Learning Multimodal Embeddings for Traffic Accident Prediction and Causal Estimation</a><a hidden class=anchor aria-hidden=true href=#learning-multimodal-embeddings-for-traffic-accident-prediction-and-causal-estimationhttpsarxivorgabs251202920v1>#</a></h3><p><strong>Authors:</strong> Ziniu Zhang, Minxuan Duan, Haris N. Koutsopoulos, Hongyang R. Zhang
<strong>Venue:</strong> arXiv (2025)</p><p>We consider analyzing traffic accident patterns using both road network data and satellite images aligned to road graph nodes. Previous work for predicting accident occurrences relies primarily on road network structural features while overlooking physical and environmental information from the road surface and its surroundings. In this work, we construct a large multimodal dataset across six U.S. states, containing nine million traffic accident records from official sources, and one million high-resolution satellite images for each node of the road network. Additionally, every node is annotated with features such as the region&rsquo;s weather statistics and road type (e.g., residential vs. motorway), and each edge is annotated with traffic volume information (i.e., Average Annual Daily Traffic). Utilizing this dataset, we conduct a comprehensive evaluation of multimodal learning methods that integrate both visual and network embeddings. Our findings show that integrating both data modalities improves prediction accuracy, achieving an average AUROC of $90.1%$, which is a $3.7%$ gain over graph neural network models that only utilize graph structures. With the improved embeddings, we conduct a causal analysis based on a matching estimator to estimate the key contributing factors influencing traffic accidents. We find that accident rates rise by $24%$ under higher precipitation, by $22%$ on higher-speed roads such as motorways, and by $29%$ due to seasonal patterns, after adjusting for other confounding factors. Ablation studies confirm that satellite imagery features are essential for achieving accurate prediction.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02920v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02920v1">üìÑ Download PDF</a></p><hr><h3 id=humans-incorrectly-reject-confident-accusatory-ai-judgmentshttpsarxivorgabs251202848v1><a href=https://arxiv.org/abs/2512.02848v1>Humans incorrectly reject confident accusatory AI judgments</a><a hidden class=anchor aria-hidden=true href=#humans-incorrectly-reject-confident-accusatory-ai-judgmentshttpsarxivorgabs251202848v1>#</a></h3><p><strong>Authors:</strong> Riccardo Loconte, Merylin Monaro, Pietro Pietrini, Bruno Verschuere, Bennett Kleinberg
<strong>Venue:</strong> arXiv (2025)</p><p>Automated verbal deception detection using methods from Artificial Intelligence (AI) has been shown to outperform humans in disentangling lies from truths. Research suggests that transparency and interpretability of computational methods tend to increase human acceptance of using AI to support decisions. However, the extent to which humans accept AI judgments for deception detection remains unclear. We experimentally examined how an AI model&rsquo;s accuracy (i.e., its overall performance in deception detection) and confidence (i.e., the model&rsquo;s uncertainty in single-statements predictions) influence human adoption of the model&rsquo;s judgments. Participants (n=373) were presented with veracity judgments of an AI model with high or low overall accuracy and various degrees of prediction confidence. The results showed that humans followed predictions from a highly accurate model more than from a less accurate one. Interestingly, the more confident the model, the more people deviated from it, especially if the model predicted deception. We also found that human interaction with algorithmic predictions either worsened the machine&rsquo;s performance or was ineffective. While this human aversion to accept highly confident algorithmic predictions was partly explained by participants&rsquo; tendency to overestimate humans&rsquo; deception detection abilities, we also discuss how truth-default theory and the social costs of accusing someone of lying help explain the findings.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02848v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02848v1">üìÑ Download PDF</a></p><hr><h3 id=bangla-hate-speech-classification-with-fine-tuned-transformer-modelshttpsarxivorgabs251202845v1><a href=https://arxiv.org/abs/2512.02845v1>Bangla Hate Speech Classification with Fine-tuned Transformer Models</a><a hidden class=anchor aria-hidden=true href=#bangla-hate-speech-classification-with-fine-tuned-transformer-modelshttpsarxivorgabs251202845v1>#</a></h3><p><strong>Authors:</strong> Yalda Keivan Jafari, Krishno Dey
<strong>Venue:</strong> arXiv (2025)</p><p>Hate speech recognition in low-resource languages remains a difficult problem due to insufficient datasets, orthographic heterogeneity, and linguistic variety. Bangla is spoken by more than 230 million people of Bangladesh and India (West Bengal). Despite the growing need for automated moderation on social media platforms, Bangla is significantly under-represented in computational resources. In this work, we study Subtask 1A and Subtask 1B of the BLP 2025 Shared Task on hate speech detection. We reproduce the official baselines (e.g., Majority, Random, Support Vector Machine) and also produce and consider Logistic Regression, Random Forest, and Decision Tree as baseline methods. We also utilized transformer-based models such as DistilBERT, BanglaBERT, m-BERT, and XLM-RoBERTa for hate speech classification. All the transformer-based models outperformed baseline methods for the subtasks, except for DistilBERT. Among the transformer-based models, BanglaBERT produces the best performance for both subtasks. Despite being smaller in size, BanglaBERT outperforms both m-BERT and XLM-RoBERTa, which suggests language-specific pre-training is very important. Our results highlight the potential and need for pre-trained language models for the low-resource Bangla language.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02845v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02845v1">üìÑ Download PDF</a></p><hr><h3 id=menta-a-small-language-model-for-on-device-mental-health-predictionhttpsarxivorgabs251202716v2><a href=https://arxiv.org/abs/2512.02716v2>Menta: A Small Language Model for On-Device Mental Health Prediction</a><a hidden class=anchor aria-hidden=true href=#menta-a-small-language-model-for-on-device-mental-health-predictionhttpsarxivorgabs251202716v2>#</a></h3><p><strong>Authors:</strong> Tianyi Zhang, Xiangyuan Xue, Lingyan Ruan, Shiya Fu, Feng Xia, Simon D&rsquo;Alfonso, Vassilis Kostakos, Ting Dang, Hong Jia
<strong>Venue:</strong> arXiv (2025)</p><p>Mental health conditions affect hundreds of millions globally, yet early detection remains limited. While large language models (LLMs) have shown promise in mental health applications, their size and computational demands hinder practical deployment. Small language models (SLMs) offer a lightweight alternative, but their use for social media&ndash;based mental health prediction remains largely underexplored. In this study, we introduce Menta, the first optimized SLM fine-tuned specifically for multi-task mental health prediction from social media data. Menta is jointly trained across six classification tasks using a LoRA-based framework, a cross-dataset strategy, and a balanced accuracy&ndash;oriented loss. Evaluated against nine state-of-the-art SLM baselines, Menta achieves an average improvement of 15.2% across tasks covering depression, stress, and suicidality compared with the best-performing non&ndash;fine-tuned SLMs. It also achieves higher accuracy on depression and stress classification tasks compared to 13B-parameter LLMs, while being approximately 3.25x smaller. Moreover, we demonstrate real-time, on-device deployment of Menta on an iPhone 15 Pro Max, requiring only approximately 3GB RAM. Supported by a comprehensive benchmark against existing SLMs and LLMs, Menta highlights the potential for scalable, privacy-preserving mental health monitoring. Code is available at: <a href=https://xxue752-nz.github.io/menta-project/>https://xxue752-nz.github.io/menta-project/</a></p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02716v2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02716v2">üìÑ Download PDF</a></p><hr><h3 id=embedding-networks-with-the-random-walk-first-return-time-distributionhttpsarxivorgabs251202694v2><a href=https://arxiv.org/abs/2512.02694v2>Embedding networks with the random walk first return time distribution</a><a hidden class=anchor aria-hidden=true href=#embedding-networks-with-the-random-walk-first-return-time-distributionhttpsarxivorgabs251202694v2>#</a></h3><p><strong>Authors:</strong> Vedanta Thapar, Renaud Lambiotte, George T. Cantwell
<strong>Venue:</strong> arXiv (2025)</p><p>We propose the first return time distribution (FRTD) of a random walk as an interpretable and mathematically grounded node embedding. The FRTD assigns a probability mass function to each node, allowing us to define a distance between any pair of nodes using standard metrics for discrete distributions. We present several arguments to motivate the FRTD embedding. First, we show that FRTDs are strictly more informative than eigenvalue spectra, yet insufficient for complete graph identification, thus placing FRTD equivalence between cospectrality and isomorphism. Second, we argue that FRTD equivalence between nodes captures structural similarity. Third, we empirically demonstrate that the FRTD embedding outperforms manually designed graph metrics in network alignment tasks. Finally, we show that random networks that approximately match the FRTD of a desired target also preserve other salient features. Together these results demonstrate the FRTD as a simple and mathematically principled embedding for complex networks.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02694v2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02694v2">üìÑ Download PDF</a></p><hr><h3 id=an-empirical-survey-of-model-merging-algorithms-for-social-bias-mitigationhttpsarxivorgabs251202689v1><a href=https://arxiv.org/abs/2512.02689v1>An Empirical Survey of Model Merging Algorithms for Social Bias Mitigation</a><a hidden class=anchor aria-hidden=true href=#an-empirical-survey-of-model-merging-algorithms-for-social-bias-mitigationhttpsarxivorgabs251202689v1>#</a></h3><p><strong>Authors:</strong> Daiki Shirafuji, Tatsuhiko Saito, Yasutomo Kimura
<strong>Venue:</strong> arXiv (2025)</p><p>Large language models (LLMs) are known to inherit and even amplify societal biases present in their pre-training corpora, threatening fairness and social trust. To address this issue, recent work has explored ``editing&rsquo;&rsquo; LLM parameters to mitigate social bias with model merging approaches; however, there is no empirical comparison. In this work, we empirically survey seven algorithms: Linear, Karcher Mean, SLERP, NuSLERP, TIES, DELLA, and Nearswap, applying 13 open weight models in the GPT, LLaMA, and Qwen families. We perform a comprehensive evaluation using three bias datasets (BBQ, BOLD, and HONEST) and measure the impact of these techniques on LLM performance in downstream tasks of the SuperGLUE benchmark. We find a trade-off between bias reduction and downstream performance: methods achieving greater bias mitigation degrade accuracy, particularly on tasks requiring reading comprehension and commonsense and causal reasoning. Among the merging algorithms, Linear, SLERP, and Nearswap consistently reduce bias while maintaining overall performance, with SLERP at moderate interpolation weights emerging as the most balanced choice. These results highlight the potential of model merging algorithms for bias mitigation, while indicating that excessive debiasing or inappropriate merging methods may lead to the degradation of important linguistic abilities.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02689v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02689v1">üìÑ Download PDF</a></p><hr><h3 id=measuring-and-rating-socioeconomic-disparities-among-provinces-a-case-of-turkiyehttpsarxivorgabs251202687v1><a href=https://arxiv.org/abs/2512.02687v1>Measuring and Rating Socioeconomic Disparities among Provinces: A Case of Turkiye</a><a hidden class=anchor aria-hidden=true href=#measuring-and-rating-socioeconomic-disparities-among-provinces-a-case-of-turkiyehttpsarxivorgabs251202687v1>#</a></h3><p><strong>Authors:</strong> Emre Akusta
<strong>Venue:</strong> arXiv (2025)</p><p>Regional disparities in the economic and social structures of countries have a great impact on their development levels. In geographically, culturally and economically diverse countries like Turkiye, determining the socioeconomic status of the provinces and regional differences is an important step for planning and implementing effective policies. Therefore, this study aims to determine the socioeconomic disparities of the provinces in Turkiye. For this purpose, a socioeconomic development index covering the economic and social dimensions of 81 provinces was constructed. For the index, 16 different indicators representing economic and social factors were used. These indicators were converted into indices using the Min-Max normalization method and Principal Component Analysis. Afterwards, using these indices, the provinces were divided into groups using the K-Means clustering algorithm and the Elbow method. In the last part of the study, the results are presented in a visual format using Scatter Plots, clustering maps and QGIS mapping tools. The results of the study show that 2 of the 81 provinces in Turkiye have very high, 30 high, 25 medium and 24 low socioeconomic indices. Istanbul and Ankara have very high socioeconomic status. In general, the provinces in western Turkiye have a high socioeconomic index, while the provinces in eastern and southeastern Anatolia face serious challenges in terms of socioeconomic indicators.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02687v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02687v1">üìÑ Download PDF</a></p><hr><h3 id=on-the-relationship-between-heider-links-and-ising-spinshttpsarxivorgabs251202644v1><a href=https://arxiv.org/abs/2512.02644v1>On the relationship between Heider links and Ising spins</a><a hidden class=anchor aria-hidden=true href=#on-the-relationship-between-heider-links-and-ising-spinshttpsarxivorgabs251202644v1>#</a></h3><p><strong>Authors:</strong> Zdzis≈Çaw Burda, Maciej Wo≈Çoszyn, Krzysztof Malarz, Krzysztof Ku≈Çakowski
<strong>Venue:</strong> arXiv (2025)</p><p>We show that the Heider model with an external field is equivalent, in the limit of structural balance, to the Ising model with nearest-neighbor interactions without an external field. More precisely, we claim that the signs of the Heider relations that maintain structural equilibrium in the system can be represented as nearest neighbor Ising spin products. We demonstrate this explicitly for a complete graph and provide a general argument for an arbitrary graph. A consequence of the equivalence is that the system of balanced Heider states undergoes a phase transition, inherited from the Ising model, at a critical value of the social field at which the fluctuations of edge magnetization are maximal.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02644v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02644v1">üìÑ Download PDF</a></p><hr><h3 id=investigating-the-integrated-digital-interventions-delivered-by-a-therapeutic-companion-agent-for-young-adults-with-symptoms-of-depression-a-proof-of-concept-studyhttpsarxivorgabs251202608v1><a href=https://arxiv.org/abs/2512.02608v1>Investigating the Integrated Digital Interventions Delivered by a Therapeutic Companion Agent for Young Adults with Symptoms of Depression: A Proof-of-Concept Study</a><a hidden class=anchor aria-hidden=true href=#investigating-the-integrated-digital-interventions-delivered-by-a-therapeutic-companion-agent-for-young-adults-with-symptoms-of-depression-a-proof-of-concept-studyhttpsarxivorgabs251202608v1>#</a></h3><p><strong>Authors:</strong> Youngjae Yoo, Minuk Kim, Soyoung Kim, Gayeon Lee, Jinwoo Kim
<strong>Venue:</strong> arXiv (2025)</p><p>Background: Despite the clinical effectiveness of digital interventions for young adults with depression, low engagement and adherence remain persistent challenges. Building a strong digital therapeutic alliance has been proposed to address these barriers. This study highlights the need for a conversational therapeutic companion agent (TCA)-based intervention design. Objective: This study aimed to develop a Wizard-of-Oz TCA-centered prototype integrating social-support-based ecological momentary assessment (EMA), ecological momentary intervention (EMI), behavioral activation, and gamification. We evaluated the six-week proof-of-concept efficacy of this intervention among young adults with depressive symptoms. Methods: Korean young adults aged 20&ndash;39 years with mild-to-moderate depressive symptoms (PHQ-9) were recruited online. The intervention group ($n = 29$) received a six-week TCA-based digital intervention, while the control group ($n = 29$), recruited four weeks later, continued their usual routines. The TCA guided four daily behavioral-activation tasks, three mood assessments, meditation, daily summaries, and weekly mission feedback. Both groups were assessed at baseline and at weeks 2, 4, and 6 using the BDI-II, GAD-7, and Q-LES-Q-SF. Results: Of 58 participants, 57 completed the study (one dropout in the intervention group). At week 6, the intervention group showed significantly greater reductions in depressive symptoms and improvements in quality of life than controls. Adherence was 78% for EMA, 51% for EMI, and 65% for daily routines. Conclusions: The TCA-based digital intervention improved depressive symptoms and quality of life with adherence levels comparable to previous digital health interventions. Future studies should refine the TCA design and conduct larger-scale evaluations.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02608v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02608v1">üìÑ Download PDF</a></p><hr><h3 id=reframing-human-robot-interaction-through-extended-reality-unlocking-safer-smarter-and-more-empathic-interactions-with-virtual-robots-and-foundation-modelshttpsarxivorgabs251202569v1><a href=https://arxiv.org/abs/2512.02569v1>Reframing Human-Robot Interaction Through Extended Reality: Unlocking Safer, Smarter, and More Empathic Interactions with Virtual Robots and Foundation Models</a><a hidden class=anchor aria-hidden=true href=#reframing-human-robot-interaction-through-extended-reality-unlocking-safer-smarter-and-more-empathic-interactions-with-virtual-robots-and-foundation-modelshttpsarxivorgabs251202569v1>#</a></h3><p><strong>Authors:</strong> Yuchong Zhang, Yong Ma, Danica Kragic
<strong>Venue:</strong> arXiv (2025)</p><p>This perspective reframes human-robot interaction (HRI) through extended reality (XR), arguing that virtual robots powered by large foundation models (FMs) can serve as cognitively grounded, empathic agents. Unlike physical robots, XR-native agents are unbound by hardware constraints and can be instantiated, adapted, and scaled on demand, while still affording embodiment and co-presence. We synthesize work across XR, HRI, and cognitive AI to show how such agents can support safety-critical scenarios, socially and cognitively empathic interaction across domains, and outreaching physical capabilities with XR and AI integration. We then discuss how multimodal large FMs (e.g., large language model, large vision model, and vision-language model) enable context-aware reasoning, affect-sensitive situations, and long-term adaptation, positioning virtual robots as cognitive and empathic mediators rather than mere simulation assets. At the same time, we highlight challenges and potential risks, including overtrust, cultural and representational bias, privacy concerns around biometric sensing, and data governance and transparency. The paper concludes by outlining a research agenda for human-centered, ethically grounded XR agents - emphasizing multi-layered evaluation frameworks, multi-user ecosystems, mixed virtual-physical embodiment, and societal and ethical design practices to envision XR-based virtual agents powered by FMs as reshaping future HRI into a more efficient and adaptive paradigm.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.02569v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.02569v1">üìÑ Download PDF</a></p><hr><h3 id=a-randomized-scheduling-framework-for-privacy-preserving-multi-robot-rendezvous-given-prior-informationhttpsarxivorgabs251205053v1><a href=https://arxiv.org/abs/2512.05053v1>A Randomized Scheduling Framework for Privacy-Preserving Multi-robot Rendezvous given Prior Information</a><a hidden class=anchor aria-hidden=true href=#a-randomized-scheduling-framework-for-privacy-preserving-multi-robot-rendezvous-given-prior-informationhttpsarxivorgabs251205053v1>#</a></h3><p><strong>Authors:</strong> Le Liu, Yu Kawano, Ming Cao
<strong>Venue:</strong> arXiv (2025)</p><p>Privacy has become a critical concern in modern multi-robot systems, driven by both ethical considerations and operational constraints. As a result, growing attention has been directed toward privacy-preserving coordination in dynamical multi-robot systems. This work introduces a randomized scheduling mechanism for privacy-preserving robot rendezvous. The proposed approach achieves improved privacy even at lower communication rates, where privacy is quantified via pointwise maximal leakage. We show that lower transmission rates provide stronger privacy guarantees and prove that rendezvous is still achieved under the randomized scheduling mechanism. Numerical simulations are provided to demonstrate the effectiveness of the method.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05053v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05053v1">üìÑ Download PDF</a></p><hr><h3 id=opacity-estimation-of-oo-collision-from-combolt-ita-hybridhttpsarxivorgabs251205009v1><a href=https://arxiv.org/abs/2512.05009v1>Opacity estimation of OO collision from CoMBolt-ITA hybrid</a><a hidden class=anchor aria-hidden=true href=#opacity-estimation-of-oo-collision-from-combolt-ita-hybridhttpsarxivorgabs251205009v1>#</a></h3><p><strong>Authors:</strong> Seyed Farid Taghavi, Seyed Mohammad Ali Tabatabaee Mehr
<strong>Venue:</strong> arXiv (2025)</p><p>Understanding the effect of system size on the applicability of the hydrodynamic description in heavy-ion physics remains unclear. Recent measurements of OO collisions at the LHC offer a new opportunity to refine our understanding of collectivity because of their intermediate size relative to heavy-ion and small-system collisions, as well as the relatively good control over their initial state. We use the CoMBolt-ITA hybrid model to describe recent OO measurements at the LHC. The model employs TrENTo for the initial state. A combination of the pre-equilibration and hydrodynamized medium stages is modeled consistently by CoMBolt-ITA, which evolves the Boltzmann distribution of massless collective excitations. The afterburner stage is included by employing UrQMD. Using this approach, we test whether the system lies in the regime where its spatial size approaches the mean free path, corresponding to low opacity, or in the opposite limit, where its size exceeds the mean free path sufficiently to enter the fluid-like evolution regime with high opacity. We find that, in light of the data-model comparison and considering the current status of the model, OO collisions with centralities larger than $60%$ gradually leave the domain of fluid-like evolution.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05009v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05009v1">üìÑ Download PDF</a></p><hr><h3 id=plumbing-bijectionshttpsarxivorgabs251205001v1><a href=https://arxiv.org/abs/2512.05001v1>Plumbing bijections</a><a hidden class=anchor aria-hidden=true href=#plumbing-bijectionshttpsarxivorgabs251205001v1>#</a></h3><p><strong>Authors:</strong> Vincent Pilaud
<strong>Venue:</strong> arXiv (2025)</p><p>The legendary Mario and Luigi show us that whether you slap in the crossings as early as a warp pipe can shoot you or as late as the very last bend, the water system in Yoshi Hill comes out exactly the same!</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.05001v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.05001v1">üìÑ Download PDF</a></p><hr><h3 id=circuit-quantum-acoustodynamics-in-a-scalable-phononic-integrated-circuit-architecturehttpsarxivorgabs251204953v1><a href=https://arxiv.org/abs/2512.04953v1>Circuit Quantum Acoustodynamics in a Scalable Phononic Integrated Circuit Architecture</a><a hidden class=anchor aria-hidden=true href=#circuit-quantum-acoustodynamics-in-a-scalable-phononic-integrated-circuit-architecturehttpsarxivorgabs251204953v1>#</a></h3><p><strong>Authors:</strong> Weiting Wang, Lintao Xiao, Bo Zhang, Yu Zeng, Ziyue Hua, Chuanlong Ma, Hongwei Huang, Yifang Xu, Jia-Qi Wang, Guangming Xue, Haifeng Yu, Xin-Biao Xu, Chang-Ling Zou, Luyan Sun
<strong>Venue:</strong> arXiv (2025)</p><p>Previous demonstrations of quantum acoustic systems have been limited to isolated devices, with limited capability to route phonons and interconnect multi-port acoustic elements for further extension. Here, we demonstrate a scalable architecture for circuit quantum acoustodynamics (cQAD) by integrating superconducting qubits with suspension-free phononic integrated circuits (PnICs). Coherent coupling between tunable transmon qubits and waveguide-integrated phononic cavities, including Fabry-Perot cavities via monolithic integration and microring cavities via flip-chip assembly, has been achieved, producing a pronounced enhancement of phonon emission with a Purcell factor of ~19. These devices represent elementary building blocks for scalable phononic circuits, establishing the foundation for phonon-based quantum information processors and the testbed for novel quantum acoustic phenomena.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04953v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04953v1">üìÑ Download PDF</a></p><hr><h3 id=a-non-linear-differential-equation-for-the-periods-of-elliptic-surfaceshttpsarxivorgabs251204930v1><a href=https://arxiv.org/abs/2512.04930v1>A non-linear differential equation for the periods of elliptic surfaces</a><a hidden class=anchor aria-hidden=true href=#a-non-linear-differential-equation-for-the-periods-of-elliptic-surfaceshttpsarxivorgabs251204930v1>#</a></h3><p><strong>Authors:</strong> N. I. Shepherd-Barron
<strong>Venue:</strong> arXiv (2025)</p><p>Suppose that $f:X\to C$ is a general Jacobian elliptic surface over the complex numbers. Then the primitive cohomology $H^{1,1}<em>{prim}(X)$ has, up to a sign, a natural orthonormal basis $(Œ∑_i)</em>{i\in [1, N]}$ given by certain meromorphic $2$-forms $Œ∑_i$ of the second kind, one for each ramification point of the classifying morphism $œÜ$ from $C$ to the stack of generalized elliptic curves. (Here $N$ is any one of $h^{1,1}<em>{prim}(X)$, the number of moduli of $X$ and the degree of the ramification of $œÜ$; these numbers are equal.) A choice of local co-ordinate on the stack of elliptic curves provides, via the branch locus of $œÜ$, an {√©}tale local co-ordinate system $(t_i)</em>{i\in [1, N]}$ on the stack of Jacobian elliptic surfaces.
The main result here is that truncation of the Gauss&ndash;Manin connexion yields the system $${\partial_i H=(\partial_i Œ∑_i\wedgeŒ∑_i)H}_{i\in [1, N]}$$ of non-linear pde satisfied by $H=[Œ∑_1,\ldots, Œ∑_N]$, where $\partial_i =\partial/\partial t_i$ and the skew tensor $\partial_i Œ∑_i\wedgeŒ∑_i$ of rank $2$ is the ecliptic of $Œ∑_i$ (the plane in which the particle $Œ∑_i$ is instantaneously moving with respect to $t_i$). Moreover, after rigidification of the integral cohomology, $H$ can be interpreted as providing a period map for these surfaces with values in the complex orthogonal group $O_N$, and we prove a generic infinitesimal Torelli theorem for this map. For rational elliptic surfaces this can be calculated explicitly.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04930v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04930v1">üìÑ Download PDF</a></p><hr><h3 id=doppler-shift-mitigation-in-a-chip-scale-atomic-beam-clockhttpsarxivorgabs251204905v1><a href=https://arxiv.org/abs/2512.04905v1>Doppler Shift Mitigation in a Chip-Scale Atomic Beam Clock</a><a hidden class=anchor aria-hidden=true href=#doppler-shift-mitigation-in-a-chip-scale-atomic-beam-clockhttpsarxivorgabs251204905v1>#</a></h3><p><strong>Authors:</strong> Alexander Staron, Gabriela Martinez, Nicholas Nardelli, Travis Autry, John Kitching, William McGehee
<strong>Venue:</strong> arXiv (2025)</p><p>Chip-scale microwave atomic systems based on thermal atomic beams offer a promising approach to realize low-power and low-drift clocks for timing holdover applications. Miniature beam clocks are expected to suppress many of the shifts that commonly limit existing chip-scale atomic clocks based on coherent population trapping, including collisional shifts and some light shifts. However, the beam geometry can amplify some challenges such as Doppler shifts, which generate a strong sensitivity to laser frequency variation. Using a cm-scale 87Rb atom beam clock, we identify a surprisingly strong competition between Doppler shifts and resonant light shifts arising from asymmetric decay in the clock spectroscopy Œõ-system. Leveraging this competition between Doppler and resonant light shifts, we demonstrate clock operation at specific, convenient experimental parameters consistent with zero sensitivity to laser frequency variation and white-noise-limited clock frequency averaging for 1000 s of integration.</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=2512.04905v1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=2512.04905v1">üìÑ Download PDF</a></p><hr><h2 id=-cross-lingual>üîç cross-lingual<a hidden class=anchor aria-hidden=true href=#-cross-lingual>#</a></h2><h3 id=kda-knowledge-distillation-adapter-for-cross-lingual-transferhttpsaclanthologyorg2025inlg-main8><a href=https://aclanthology.org/2025.inlg-main.8/>KDA: Knowledge Distillation Adapter for Cross-Lingual Transfer</a><a hidden class=anchor aria-hidden=true href=#kda-knowledge-distillation-adapter-for-cross-lingual-transferhttpsaclanthologyorg2025inlg-main8>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Tue,)</p><p>Ta-Bao Nguyen, Nguyen-Phuong Phan, Tung Le and Huy Tien Nguyen in Proceedings of the 18th International Natural Language Generation Conference</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.inlg-main.8">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.inlg-main.8">üìÑ Download PDF</a></p><hr><h3 id=are-knowledge-and-reference-in-multilingual-language-models-cross-lingually-consistenthttpsaclanthologyorg2025findings-emnlp267><a href=https://aclanthology.org/2025.findings-emnlp.267/>Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent?</a><a hidden class=anchor aria-hidden=true href=#are-knowledge-and-reference-in-multilingual-language-models-cross-lingually-consistenthttpsaclanthologyorg2025findings-emnlp267>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Xi Ai, Mahardika Krisna Ihsani and Min-Yen Kan in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.267">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.267">üìÑ Download PDF</a></p><hr><h3 id=ccl-xcot-an-efficient-cross-lingual-knowledge-transfer-method-for-mitigating-hallucination-generationhttpsaclanthologyorg2025findings-emnlp93><a href=https://aclanthology.org/2025.findings-emnlp.93/>CCL-XCoT: An Efficient Cross-Lingual Knowledge Transfer Method for Mitigating Hallucination Generation</a><a hidden class=anchor aria-hidden=true href=#ccl-xcot-an-efficient-cross-lingual-knowledge-transfer-method-for-mitigating-hallucination-generationhttpsaclanthologyorg2025findings-emnlp93>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Zheng Weihua, Roy Ka-Wei Lee, Zhengyuan Liu, Wu Kui, AiTi Aw and Bowei Zou in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.93">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.93">üìÑ Download PDF</a></p><hr><h3 id=deft-x-denoised-sparse-fine-tuning-for-zero-shot-cross-lingual-transferhttpsaclanthologyorg2025findings-emnlp100><a href=https://aclanthology.org/2025.findings-emnlp.100/>DeFT-X: Denoised Sparse Fine-Tuning for Zero-Shot Cross-Lingual Transfer</a><a hidden class=anchor aria-hidden=true href=#deft-x-denoised-sparse-fine-tuning-for-zero-shot-cross-lingual-transferhttpsaclanthologyorg2025findings-emnlp100>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Sona Elza Simon and Preethi Jyothi in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.100">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.100">üìÑ Download PDF</a></p><hr><h3 id=disentangling-language-understanding-and-reasoning-structures-in-cross-lingual-chain-of-thought-promptinghttpsaclanthologyorg2025findings-emnlp652><a href=https://aclanthology.org/2025.findings-emnlp.652/>Disentangling Language Understanding and Reasoning Structures in Cross-lingual Chain-of-Thought Prompting</a><a hidden class=anchor aria-hidden=true href=#disentangling-language-understanding-and-reasoning-structures-in-cross-lingual-chain-of-thought-promptinghttpsaclanthologyorg2025findings-emnlp652>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Khanh-Tung Tran, Nguyet-Hang Vu, Barry O‚ÄôSullivan and Hoang D. Nguyen in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.652">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.652">üìÑ Download PDF</a></p><hr><h3 id=dlir-spherical-adaptation-for-cross-lingual-knowledge-transfer-of-sociological-concepts-alignmenthttpsaclanthologyorg2025findings-emnlp109><a href=https://aclanthology.org/2025.findings-emnlp.109/>DLIR: Spherical Adaptation for Cross-Lingual Knowledge Transfer of Sociological Concepts Alignment</a><a hidden class=anchor aria-hidden=true href=#dlir-spherical-adaptation-for-cross-lingual-knowledge-transfer-of-sociological-concepts-alignmenthttpsaclanthologyorg2025findings-emnlp109>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Zeqiang Wang, Jon Johnson and Suparna De in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.109">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.109">üìÑ Download PDF</a></p><hr><h3 id=efficientxlang-towards-improving-token-efficiency-through-cross-lingual-reasoninghttpsaclanthologyorg2025findings-emnlp845><a href=https://aclanthology.org/2025.findings-emnlp.845/>EfficientXLang: Towards Improving Token Efficiency Through Cross-Lingual Reasoning</a><a hidden class=anchor aria-hidden=true href=#efficientxlang-towards-improving-token-efficiency-through-cross-lingual-reasoninghttpsaclanthologyorg2025findings-emnlp845>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Sanchit Ahuja, Praneetha Vaddamanu and Barun Patra in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.845">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.845">üìÑ Download PDF</a></p><hr><h3 id=evaluating-large-language-models-for-cross-lingual-retrievalhttpsaclanthologyorg2025findings-emnlp612><a href=https://aclanthology.org/2025.findings-emnlp.612/>Evaluating Large Language Models for Cross-Lingual Retrieval</a><a hidden class=anchor aria-hidden=true href=#evaluating-large-language-models-for-cross-lingual-retrievalhttpsaclanthologyorg2025findings-emnlp612>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Longfei Zuo, Pingjun Hong, Oliver Kraus, Barbara Plank and Robert Litschko in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.612">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.612">üìÑ Download PDF</a></p><hr><h3 id=evaluating-the-robustness-and-accuracy-of-text-watermarking-under-real-world-cross-lingual-manipulationshttpsaclanthologyorg2025findings-emnlp390><a href=https://aclanthology.org/2025.findings-emnlp.390/>Evaluating the Robustness and Accuracy of Text Watermarking Under Real-World Cross-Lingual Manipulations</a><a hidden class=anchor aria-hidden=true href=#evaluating-the-robustness-and-accuracy-of-text-watermarking-under-real-world-cross-lingual-manipulationshttpsaclanthologyorg2025findings-emnlp390>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Mansour Al Ghanim, Jiaqi Xue, Rochana Prih Hastuti, Mengxin Zheng, Yan Solihin and Qian Lou in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.390">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.390">üìÑ Download PDF</a></p><hr><h3 id=examining-multilingual-embedding-models-cross-lingually-through-llm-generated-adversarial-exampleshttpsaclanthologyorg2025findings-emnlp115><a href=https://aclanthology.org/2025.findings-emnlp.115/>Examining Multilingual Embedding Models Cross-Lingually Through LLM-Generated Adversarial Examples</a><a hidden class=anchor aria-hidden=true href=#examining-multilingual-embedding-models-cross-lingually-through-llm-generated-adversarial-exampleshttpsaclanthologyorg2025findings-emnlp115>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Andrianos Michail, Simon Clematide and Rico Sennrich in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.115">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.115">üìÑ Download PDF</a></p><hr><h3 id=facilitating-cross-lingual-transfer-of-empathy-through-language-independent-latent-diffusion-a-case-study-in-chinesehttpsaclanthologyorg2025findings-emnlp1313><a href=https://aclanthology.org/2025.findings-emnlp.1313/>Facilitating Cross-lingual Transfer of Empathy through Language-independent Latent Diffusion: A Case Study in Chinese</a><a hidden class=anchor aria-hidden=true href=#facilitating-cross-lingual-transfer-of-empathy-through-language-independent-latent-diffusion-a-case-study-in-chinesehttpsaclanthologyorg2025findings-emnlp1313>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Junlin Li, Peng Bo and Yu-Yin Hsu in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.1313">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.1313">üìÑ Download PDF</a></p><hr><h3 id=leveraging-high-resource-english-corpora-for-cross-lingual-domain-adaptation-in-low-resource-japanese-medicine-via-continued-pre-traininghttpsaclanthologyorg2025findings-emnlp615><a href=https://aclanthology.org/2025.findings-emnlp.615/>Leveraging High-Resource English Corpora for Cross-lingual Domain Adaptation in Low-Resource Japanese Medicine via Continued Pre-training</a><a hidden class=anchor aria-hidden=true href=#leveraging-high-resource-english-corpora-for-cross-lingual-domain-adaptation-in-low-resource-japanese-medicine-via-continued-pre-traininghttpsaclanthologyorg2025findings-emnlp615>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Kazuma Kobayashi, Zhen Wan, Fei Cheng, Yuma Tsuta, Xin Zhao, Junfeng Jiang, Jiahao Huang, Zhiyi Huang, Yusuke Oda, Rio Yokota, Yuki Arase, Daisuke Kawahara, Akiko Aizawa and Sadao Kurohashi in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.615">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.615">üìÑ Download PDF</a></p><hr><h3 id=magix-a-multi-granular-adaptive-graph-intelligence-framework-for-enhancing-cross-lingual-raghttpsaclanthologyorg2025findings-emnlp279><a href=https://aclanthology.org/2025.findings-emnlp.279/>MaGiX: A Multi-Granular Adaptive Graph Intelligence Framework for Enhancing Cross-Lingual RAG</a><a hidden class=anchor aria-hidden=true href=#magix-a-multi-granular-adaptive-graph-intelligence-framework-for-enhancing-cross-lingual-raghttpsaclanthologyorg2025findings-emnlp279>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Nguyen Manh Hieu, Vu Lam Anh, Hung Pham Van, Nam Le Hai, Linh Ngo Van, Nguyen Thi Ngoc Diep and Thien Huu Nguyen in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.279">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.279">üìÑ Download PDF</a></p><hr><h3 id=memory-enhanced-large-language-model-for-cross-lingual-dependency-parsing-via-deep-hierarchical-syntax-understandinghttpsaclanthologyorg2025findings-emnlp101><a href=https://aclanthology.org/2025.findings-emnlp.101/>Memory-enhanced Large Language Model for Cross-lingual Dependency Parsing via Deep Hierarchical Syntax Understanding</a><a hidden class=anchor aria-hidden=true href=#memory-enhanced-large-language-model-for-cross-lingual-dependency-parsing-via-deep-hierarchical-syntax-understandinghttpsaclanthologyorg2025findings-emnlp101>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Jianjian Liu, Ying Li, Zhengtao Yu, Shun Su, Shengxiang Gao and Yuxin Huang in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.101">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.101">üìÑ Download PDF</a></p><hr><h3 id=multilingual-generative-retrieval-via-cross-lingual-semantic-compressionhttpsaclanthologyorg2025findings-emnlp575><a href=https://aclanthology.org/2025.findings-emnlp.575/>Multilingual Generative Retrieval via Cross-lingual Semantic Compression</a><a hidden class=anchor aria-hidden=true href=#multilingual-generative-retrieval-via-cross-lingual-semantic-compressionhttpsaclanthologyorg2025findings-emnlp575>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Yuxin Huang, Simeng Wu, Ran Song, Yan Xiang, Yantuan Xian, Shengxiang Gao and Zhengtao Yu in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.575">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.575">üìÑ Download PDF</a></p><hr><h3 id=neighxlm-enhancing-cross-lingual-transfer-in-low-resource-languages-via-neighbor-augmented-contrastive-pretraininghttpsaclanthologyorg2025findings-emnlp163><a href=https://aclanthology.org/2025.findings-emnlp.163/>NeighXLM: Enhancing Cross-Lingual Transfer in Low-Resource Languages via Neighbor-Augmented Contrastive Pretraining</a><a hidden class=anchor aria-hidden=true href=#neighxlm-enhancing-cross-lingual-transfer-in-low-resource-languages-via-neighbor-augmented-contrastive-pretraininghttpsaclanthologyorg2025findings-emnlp163>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Sicheng Wang, Wenyi Wu and Zibo Zhang in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.163">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.163">üìÑ Download PDF</a></p><hr><h3 id=protoxtm-cross-lingual-topic-modeling-with-document-level-prototype-based-contrastive-learninghttpsaclanthologyorg2025findings-emnlp1107><a href=https://aclanthology.org/2025.findings-emnlp.1107/>ProtoXTM: Cross-Lingual Topic Modeling with Document-Level Prototype-based Contrastive Learning</a><a hidden class=anchor aria-hidden=true href=#protoxtm-cross-lingual-topic-modeling-with-document-level-prototype-based-contrastive-learninghttpsaclanthologyorg2025findings-emnlp1107>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Seung-Won Seo and Soon-Sun Kwon in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.1107">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.1107">üìÑ Download PDF</a></p><hr><h3 id=xl-suite-cross-lingual-synthetic-training-and-evaluation-data-for-open-ended-generationhttpsaclanthologyorg2025findings-emnlp550><a href=https://aclanthology.org/2025.findings-emnlp.550/>XL-Suite: Cross-Lingual Synthetic Training and Evaluation Data for Open-Ended Generation</a><a hidden class=anchor aria-hidden=true href=#xl-suite-cross-lingual-synthetic-training-and-evaluation-data-for-open-ended-generationhttpsaclanthologyorg2025findings-emnlp550>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Vivek Iyer, Pinzhen Chen, Ricardo Rei and Alexandra Birch in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.550">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.550">üìÑ Download PDF</a></p><hr><h3 id=xrag-cross-lingual-retrieval-augmented-generationhttpsaclanthologyorg2025findings-emnlp849><a href=https://aclanthology.org/2025.findings-emnlp.849/>XRAG: Cross-lingual Retrieval-Augmented Generation</a><a hidden class=anchor aria-hidden=true href=#xrag-cross-lingual-retrieval-augmented-generationhttpsaclanthologyorg2025findings-emnlp849>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Wei Liu, Sony Trenous, Leonardo F. R. Ribeiro, Bill Byrne and Felix Hieber in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.849">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.849">üìÑ Download PDF</a></p><hr><h3 id=xtra-cross-lingual-topic-modeling-with-topic-and-representation-alignmentshttpsaclanthologyorg2025findings-emnlp298><a href=https://aclanthology.org/2025.findings-emnlp.298/>XTRA: Cross-Lingual Topic Modeling with Topic and Representation Alignments</a><a hidden class=anchor aria-hidden=true href=#xtra-cross-lingual-topic-modeling-with-topic-and-representation-alignmentshttpsaclanthologyorg2025findings-emnlp298>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Tien Phat Nguyen, Ngo Vu Minh, Tung Nguyen, Linh Ngo Van, Duc Anh Nguyen, Dinh Viet Sang and Trung Le in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.298">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.298">üìÑ Download PDF</a></p><hr><h3 id=zero-shot-cross-lingual-ner-via-mitigating-language-difference-an-entity-aligned-translation-perspectivehttpsaclanthologyorg2025findings-emnlp244><a href=https://aclanthology.org/2025.findings-emnlp.244/>Zero-shot Cross-lingual NER via Mitigating Language Difference: An Entity-aligned Translation Perspective</a><a hidden class=anchor aria-hidden=true href=#zero-shot-cross-lingual-ner-via-mitigating-language-difference-an-entity-aligned-translation-perspectivehttpsaclanthologyorg2025findings-emnlp244>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Zhihao Zhang, Sophia Yat Mei Lee, Dong Zhang, Shoushan Li and Guodong Zhou in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.244">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.244">üìÑ Download PDF</a></p><hr><h2 id=-code-switching>üîç code-switching<a hidden class=anchor aria-hidden=true href=#-code-switching>#</a></h2><h3 id=can-code-switched-texts-activate-a-knowledge-switch-in-llms-a-case-study-on-english-korean-code-switchinghttpsaclanthologyorg2025findings-emnlp1215><a href=https://aclanthology.org/2025.findings-emnlp.1215/>Can Code-Switched Texts Activate a Knowledge Switch in LLMs? A Case Study on English-Korean Code-Switching</a><a hidden class=anchor aria-hidden=true href=#can-code-switched-texts-activate-a-knowledge-switch-in-llms-a-case-study-on-english-korean-code-switchinghttpsaclanthologyorg2025findings-emnlp1215>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Seoyeon Kim, Huiseo Kim, Chanjun Park, Jinyoung Yeo and Dongha Lee in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.1215">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.1215">üìÑ Download PDF</a></p><hr><h3 id=unicom-a-universal-code-switching-speech-generatorhttpsaclanthologyorg2025findings-emnlp715><a href=https://aclanthology.org/2025.findings-emnlp.715/>UniCoM: A Universal Code-Switching Speech Generator</a><a hidden class=anchor aria-hidden=true href=#unicom-a-universal-code-switching-speech-generatorhttpsaclanthologyorg2025findings-emnlp715>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Sangmin Lee, Woojin Chung, Seyun Um and Hong-Goo Kang in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.715">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.715">üìÑ Download PDF</a></p><hr><h2 id=-low-resource-language>üîç low-resource language<a hidden class=anchor aria-hidden=true href=#-low-resource-language>#</a></h2><h3 id=diploma-efficient-adaptation-of-instructed-llms-to-low-resource-languages-via-post-training-delta-merginghttpsaclanthologyorg2025findings-emnlp1355><a href=https://aclanthology.org/2025.findings-emnlp.1355/>DIPLomA: Efficient Adaptation of Instructed LLMs to Low-Resource Languages via Post-Training Delta Merging</a><a hidden class=anchor aria-hidden=true href=#diploma-efficient-adaptation-of-instructed-llms-to-low-resource-languages-via-post-training-delta-merginghttpsaclanthologyorg2025findings-emnlp1355>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Ixak Sarasua, Ander Corral and Xabier Saralegi in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.1355">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.1355">üìÑ Download PDF</a></p><hr><h3 id=low-resource-languages-llm-disinformation-is-within-reach-the-case-of-walliserdeutschhttpsaclanthologyorg2025findings-emnlp1396><a href=https://aclanthology.org/2025.findings-emnlp.1396/>Low-Resource Languages LLM Disinformation is Within Reach: The Case of Walliserdeutsch</a><a hidden class=anchor aria-hidden=true href=#low-resource-languages-llm-disinformation-is-within-reach-the-case-of-walliserdeutschhttpsaclanthologyorg2025findings-emnlp1396>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Andrei Kucharavy, Sherine Seppey, Cyril Vallez, Dimitri Percia David and Ljiljana Dolamic in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.1396">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.1396">üìÑ Download PDF</a></p><hr><h3 id=parsing-the-switch-llm-based-ud-annotation-for-complex-code-switched-and-low-resource-languageshttpsaclanthologyorg2025findings-emnlp863><a href=https://aclanthology.org/2025.findings-emnlp.863/>Parsing the Switch: LLM-Based UD Annotation for Complex Code-Switched and Low-Resource Languages</a><a hidden class=anchor aria-hidden=true href=#parsing-the-switch-llm-based-ud-annotation-for-complex-code-switched-and-low-resource-languageshttpsaclanthologyorg2025findings-emnlp863>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Olga Kellert, Nemika Tyagi, Muhammad Imran, Nelvin Licona-Guevara and Carlos G√≥mez-Rodr√≠guez in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.863">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.863">üìÑ Download PDF</a></p><hr><h2 id=-cross-lingual-transfer>üîç cross-lingual transfer<a hidden class=anchor aria-hidden=true href=#-cross-lingual-transfer>#</a></h2><p><em>No papers found for this category this week.</em></p><h2 id=-multilingual-alignment>üîç multilingual alignment<a hidden class=anchor aria-hidden=true href=#-multilingual-alignment>#</a></h2><h3 id=cm-align-consistency-based-multilingual-alignment-for-large-language-modelshttpsaclanthologyorg2025findings-emnlp1401><a href=https://aclanthology.org/2025.findings-emnlp.1401/>CM-Align: Consistency-based Multilingual Alignment for Large Language Models</a><a hidden class=anchor aria-hidden=true href=#cm-align-consistency-based-multilingual-alignment-for-large-language-modelshttpsaclanthologyorg2025findings-emnlp1401>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Xue Zhang, Yunlong Liang, Fandong Meng, Songming Zhang, Yufeng Chen, Jinan Xu and Jie Zhou in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.1401">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.1401">üìÑ Download PDF</a></p><hr><h2 id=-cross-lingual-retrieval>üîç cross-lingual retrieval<a hidden class=anchor aria-hidden=true href=#-cross-lingual-retrieval>#</a></h2><p><em>No papers found for this category this week.</em></p><h2 id=-surprisal>üîç surprisal<a hidden class=anchor aria-hidden=true href=#-surprisal>#</a></h2><h3 id=surprisal-reveals-diversity-gaps-in-image-captioning-and-different-scorers-change-the-storyhttpsaclanthologyorg2025inlg-main22><a href=https://aclanthology.org/2025.inlg-main.22/>Surprisal reveals diversity gaps in image captioning and different scorers change the story</a><a hidden class=anchor aria-hidden=true href=#surprisal-reveals-diversity-gaps-in-image-captioning-and-different-scorers-change-the-storyhttpsaclanthologyorg2025inlg-main22>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Tue,)</p><p>Nikolai Ilinykh and Simon Dobnik in Proceedings of the 18th International Natural Language Generation Conference</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.inlg-main.22">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.inlg-main.22">üìÑ Download PDF</a></p><hr><h3 id=evaluating-text-generation-quality-using-spectral-distances-of-surprisalhttpsaclanthologyorg2025findings-emnlp132><a href=https://aclanthology.org/2025.findings-emnlp.132/>Evaluating Text Generation Quality Using Spectral Distances of Surprisal</a><a hidden class=anchor aria-hidden=true href=#evaluating-text-generation-quality-using-spectral-distances-of-surprisalhttpsaclanthologyorg2025findings-emnlp132>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Zhichen Liu, Yongyuan Li, Yang Xu, Yu Wang, Yingfang Yuan and Zuhao Yang in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.132">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.132">üìÑ Download PDF</a></p><hr><h2 id=-contextual-embedding>üîç contextual embedding<a hidden class=anchor aria-hidden=true href=#-contextual-embedding>#</a></h2><h3 id=zero-shot-contextual-embeddings-via-offline-synthetic-corpus-generationhttpsaclanthologyorg2025findings-emnlp111><a href=https://aclanthology.org/2025.findings-emnlp.111/>Zero-Shot Contextual Embeddings via Offline Synthetic Corpus Generation</a><a hidden class=anchor aria-hidden=true href=#zero-shot-contextual-embeddings-via-offline-synthetic-corpus-generationhttpsaclanthologyorg2025findings-emnlp111>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Philip Lippmann and Jie Yang in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.111">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.111">üìÑ Download PDF</a></p><hr><h2 id=-llm-evaluation>üîç llm evaluation<a hidden class=anchor aria-hidden=true href=#-llm-evaluation>#</a></h2><h3 id=do-before-you-judge-self-reference-as-a-pathway-to-better-llm-evaluationhttpsaclanthologyorg2025findings-emnlp1342><a href=https://aclanthology.org/2025.findings-emnlp.1342/>Do Before You Judge: Self-Reference as a Pathway to Better LLM Evaluation</a><a hidden class=anchor aria-hidden=true href=#do-before-you-judge-self-reference-as-a-pathway-to-better-llm-evaluationhttpsaclanthologyorg2025findings-emnlp1342>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Wei-Hsiang Lin, Sheng-Lun Wei, Hen-Hsen Huang and Hsin-Hsi Chen in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.1342">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.1342">üìÑ Download PDF</a></p><hr><h3 id=from-kmmlu-redux-to-pro-a-professional-korean-benchmark-suite-for-llm-evaluationhttpsaclanthologyorg2025findings-emnlp1038><a href=https://aclanthology.org/2025.findings-emnlp.1038/>From KMMLU-Redux to Pro: A Professional Korean Benchmark Suite for LLM Evaluation</a><a hidden class=anchor aria-hidden=true href=#from-kmmlu-redux-to-pro-a-professional-korean-benchmark-suite-for-llm-evaluationhttpsaclanthologyorg2025findings-emnlp1038>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Seokhee Hong, Sunkyoung Kim, Guijin Son, Soyeon Kim, Yeonjung Hong and Jinsik Lee in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.1038">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.1038">üìÑ Download PDF</a></p><hr><h3 id=instance-level-randomization-toward-more-stable-llm-evaluationshttpsaclanthologyorg2025findings-emnlp182><a href=https://aclanthology.org/2025.findings-emnlp.182/>Instance-level Randomization: Toward More Stable LLM Evaluations</a><a hidden class=anchor aria-hidden=true href=#instance-level-randomization-toward-more-stable-llm-evaluationshttpsaclanthologyorg2025findings-emnlp182>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Yiyang Li, Yonghuang Wu, Ying Luo, Liangtai Sun, Zishu Qin, Lin Qiu, Xuezhi Cao and Xunliang Cai in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.182">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.182">üìÑ Download PDF</a></p><hr><h3 id=reliableeval-a-recipe-for-stochastic-llm-evaluation-via-method-of-momentshttpsaclanthologyorg2025findings-emnlp594><a href=https://aclanthology.org/2025.findings-emnlp.594/>ReliableEval: A Recipe for Stochastic LLM Evaluation via Method of Moments</a><a hidden class=anchor aria-hidden=true href=#reliableeval-a-recipe-for-stochastic-llm-evaluation-via-method-of-momentshttpsaclanthologyorg2025findings-emnlp594>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Gili Lior, Eliya Habba, Shahar Levy, Avi Caciularu and Gabriel Stanovsky in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.594">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.594">üìÑ Download PDF</a></p><hr><h2 id=-emotion-recognition>üîç emotion recognition<a hidden class=anchor aria-hidden=true href=#-emotion-recognition>#</a></h2><h3 id=a-comprehensive-pipeline-for-vietnamese-speech-recognition-and-emotion-recognitionhttpsaclanthologyorg2025vlsp-14><a href=https://aclanthology.org/2025.vlsp-1.4/>A Comprehensive Pipeline for Vietnamese Speech Recognition and Emotion Recognition</a><a hidden class=anchor aria-hidden=true href=#a-comprehensive-pipeline-for-vietnamese-speech-recognition-and-emotion-recognitionhttpsaclanthologyorg2025vlsp-14>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Thu,)</p><p>Hy Nguyen Thien in Proceedings of the 11th International Workshop on Vietnamese Language and Speech Processing</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.vlsp-1.4">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.vlsp-1.4">üìÑ Download PDF</a></p><hr><h3 id=dfat-dual-stage-fusion-of-acoustic-and-text-feature-for-speech-emotion-recognitionhttpsaclanthologyorg2025vlsp-16><a href=https://aclanthology.org/2025.vlsp-1.6/>DFAT: Dual-stage Fusion of Acoustic and Text feature for Speech Emotion Recognition</a><a hidden class=anchor aria-hidden=true href=#dfat-dual-stage-fusion-of-acoustic-and-text-feature-for-speech-emotion-recognitionhttpsaclanthologyorg2025vlsp-16>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Thu,)</p><p>Nhi Nguyen Yen Truong, Sang Le Quang, Huy Tran Quang, Tri Pham Xuan, Duong Tran Ham, Binh Tran Le Hai, Tin Huynh and Kiem Hoang in Proceedings of the 11th International Workshop on Vietnamese Language and Speech Processing</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.vlsp-1.6">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.vlsp-1.6">üìÑ Download PDF</a></p><hr><h3 id=speech-recognition-and-speech-emotion-recognition-approach-for-vlsp-2025httpsaclanthologyorg2025vlsp-12><a href=https://aclanthology.org/2025.vlsp-1.2/>Speech recognition and speech emotion recognition approach for VLSP 2025</a><a hidden class=anchor aria-hidden=true href=#speech-recognition-and-speech-emotion-recognition-approach-for-vlsp-2025httpsaclanthologyorg2025vlsp-12>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Thu,)</p><p>Bui Tien Dat and Nguyen Duy Khanh in Proceedings of the 11th International Workshop on Vietnamese Language and Speech Processing</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.vlsp-1.2">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.vlsp-1.2">üìÑ Download PDF</a></p><hr><h3 id=vlsp-2025-asrser-vietnamese-speech-recognition-and-speech-emotion-recognition-challenge-technical-analysis-and-insightshttpsaclanthologyorg2025vlsp-11><a href=https://aclanthology.org/2025.vlsp-1.1/>VLSP 2025 ASR/SER: Vietnamese Speech Recognition and Speech Emotion Recognition Challenge: Technical Analysis and Insights</a><a hidden class=anchor aria-hidden=true href=#vlsp-2025-asrser-vietnamese-speech-recognition-and-speech-emotion-recognition-challenge-technical-analysis-and-insightshttpsaclanthologyorg2025vlsp-11>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Thu,)</p><p>Manh Hai Cao, Chi Dung Hoang, Quang Trung Le and Van Hai Do in Proceedings of the 11th International Workshop on Vietnamese Language and Speech Processing</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.vlsp-1.1">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.vlsp-1.1">üìÑ Download PDF</a></p><hr><h3 id=emo-rl-emotion-rule-based-reinforcement-learning-enhanced-audio-language-model-for-generalized-speech-emotion-recognitionhttpsaclanthologyorg2025findings-emnlp1018><a href=https://aclanthology.org/2025.findings-emnlp.1018/>EMO-RL: Emotion-Rule-Based Reinforcement Learning Enhanced Audio-Language Model for Generalized Speech Emotion Recognition</a><a hidden class=anchor aria-hidden=true href=#emo-rl-emotion-rule-based-reinforcement-learning-enhanced-audio-language-model-for-generalized-speech-emotion-recognitionhttpsaclanthologyorg2025findings-emnlp1018>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Pengcheng Li, Botao Zhao, Zuheng Kang, Junqing Peng, Xiaoyang Qu, Yayun He and Jianzong Wang in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.1018">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.1018">üìÑ Download PDF</a></p><hr><h3 id=grpo-guided-modality-selection-enhanced-lora-tuned-llms-for-multimodal-emotion-recognitionhttpsaclanthologyorg2025findings-emnlp1059><a href=https://aclanthology.org/2025.findings-emnlp.1059/>GRPO-Guided Modality Selection Enhanced LoRA-Tuned LLMs for Multimodal Emotion Recognition</a><a hidden class=anchor aria-hidden=true href=#grpo-guided-modality-selection-enhanced-lora-tuned-llms-for-multimodal-emotion-recognitionhttpsaclanthologyorg2025findings-emnlp1059>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Yang Chen, Shuwan Yang, Yan Xiang, Ran Song, Yuxin Huang and Zhengtao Yu in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.1059">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.1059">üìÑ Download PDF</a></p><hr><h3 id=multimodal-emotion-recognition-in-conversations-a-survey-of-methods-trends-challenges-and-prospectshttpsaclanthologyorg2025findings-emnlp332><a href=https://aclanthology.org/2025.findings-emnlp.332/>Multimodal Emotion Recognition in Conversations: A Survey of Methods, Trends, Challenges and Prospects</a><a hidden class=anchor aria-hidden=true href=#multimodal-emotion-recognition-in-conversations-a-survey-of-methods-trends-challenges-and-prospectshttpsaclanthologyorg2025findings-emnlp332>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>ChengYan Wu, Yiqiang Cai, Yang Liu, Pengxu Zhu, Yun Xue, Ziwei Gong, Julia Hirschberg and Bolei Ma in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.332">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.332">üìÑ Download PDF</a></p><hr><h2 id=-sentiment-analysis>üîç sentiment analysis<a hidden class=anchor aria-hidden=true href=#-sentiment-analysis>#</a></h2><h3 id=exploring-the-power-of-large-language-models-for-vietnamese-implitcit-sentiment-analysishttpsaclanthologyorg2025inlg-main14><a href=https://aclanthology.org/2025.inlg-main.14/>Exploring the Power of Large Language Models for Vietnamese Implitcit Sentiment Analysis</a><a hidden class=anchor aria-hidden=true href=#exploring-the-power-of-large-language-models-for-vietnamese-implitcit-sentiment-analysishttpsaclanthologyorg2025inlg-main14>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Tue,)</p><p>Huy Gia Luu and Dang Van Thin in Proceedings of the 18th International Natural Language Generation Conference</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.inlg-main.14">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.inlg-main.14">üìÑ Download PDF</a></p><hr><h3 id=aspect-based-sentiment-analysis-via-synthetic-image-generationhttpsaclanthologyorg2025findings-emnlp1190><a href=https://aclanthology.org/2025.findings-emnlp.1190/>Aspect-based Sentiment Analysis via Synthetic Image Generation</a><a hidden class=anchor aria-hidden=true href=#aspect-based-sentiment-analysis-via-synthetic-image-generationhttpsaclanthologyorg2025findings-emnlp1190>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Ge Chen, Zhongqing Wang and Guodong Zhou in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.1190">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.1190">üìÑ Download PDF</a></p><hr><h3 id=tf-mamba-text-enhanced-fusion-mamba-with-missing-modalities-for-robust-multimodal-sentiment-analysishttpsaclanthologyorg2025findings-emnlp602><a href=https://aclanthology.org/2025.findings-emnlp.602/>TF-Mamba: Text-enhanced Fusion Mamba with Missing Modalities for Robust Multimodal Sentiment Analysis</a><a hidden class=anchor aria-hidden=true href=#tf-mamba-text-enhanced-fusion-mamba-with-missing-modalities-for-robust-multimodal-sentiment-analysishttpsaclanthologyorg2025findings-emnlp602>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Xiang Li, Xianfu Cheng, Dezhuang Miao, Xiaoming Zhang and Zhoujun Li in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.602">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.602">üìÑ Download PDF</a></p><hr><h3 id=zero-shot-cross-domain-aspect-based-sentiment-analysis-via-domain-contextualized-chain-of-thought-reasoninghttpsaclanthologyorg2025findings-emnlp245><a href=https://aclanthology.org/2025.findings-emnlp.245/>Zero-Shot Cross-Domain Aspect-Based Sentiment Analysis via Domain-Contextualized Chain-of-Thought Reasoning</a><a hidden class=anchor aria-hidden=true href=#zero-shot-cross-domain-aspect-based-sentiment-analysis-via-domain-contextualized-chain-of-thought-reasoninghttpsaclanthologyorg2025findings-emnlp245>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Chuming Shen, Wei Wei, Dong Wang and Zhong-Hao Wang in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.245">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.245">üìÑ Download PDF</a></p><hr><h2 id=-humor-detection>üîç humor detection<a hidden class=anchor aria-hidden=true href=#-humor-detection>#</a></h2><h3 id=standup4ai-a-new-multilingual-dataset-for-humor-detection-in-stand-up-comedy-videoshttpsaclanthologyorg2025findings-emnlp919><a href=https://aclanthology.org/2025.findings-emnlp.919/>StandUp4AI: A New Multilingual Dataset for Humor Detection in Stand-up Comedy Videos</a><a hidden class=anchor aria-hidden=true href=#standup4ai-a-new-multilingual-dataset-for-humor-detection-in-stand-up-comedy-videoshttpsaclanthologyorg2025findings-emnlp919>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Valentin Barriere, Nahuel Gomez, L√©o Hemamou, Sofia Callejas and Brian Ravenet in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.919">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.919">üìÑ Download PDF</a></p><hr><h2 id=-sarcasm-detection>üîç sarcasm detection<a hidden class=anchor aria-hidden=true href=#-sarcasm-detection>#</a></h2><h3 id=revealing-the-impact-of-synthetic-native-samples-and-multi-tasking-strategies-in-hindi-english-code-mixed-humour-and-sarcasm-detectionhttpsaclanthologyorg2025findings-emnlp1308><a href=https://aclanthology.org/2025.findings-emnlp.1308/>Revealing the impact of synthetic native samples and multi-tasking strategies in Hindi-English code-mixed humour and sarcasm detection</a><a hidden class=anchor aria-hidden=true href=#revealing-the-impact-of-synthetic-native-samples-and-multi-tasking-strategies-in-hindi-english-code-mixed-humour-and-sarcasm-detectionhttpsaclanthologyorg2025findings-emnlp1308>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Debajyoti Mazumder, Aakash Kumar and Jasabanta Patro in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.1308">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.1308">üìÑ Download PDF</a></p><hr><h3 id=sarcasm-r1-enhancing-sarcasm-detection-through-focused-reasoninghttpsaclanthologyorg2025findings-emnlp570><a href=https://aclanthology.org/2025.findings-emnlp.570/>Sarcasm-R1: Enhancing Sarcasm Detection through Focused Reasoning</a><a hidden class=anchor aria-hidden=true href=#sarcasm-r1-enhancing-sarcasm-detection-through-focused-reasoninghttpsaclanthologyorg2025findings-emnlp570>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Qi Yang, Jingjie Zeng, Liang Yang, Kai Ma and Hongfei Lin in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.570">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.570">üìÑ Download PDF</a></p><hr><h2 id=-figurative-language>üîç figurative language<a hidden class=anchor aria-hidden=true href=#-figurative-language>#</a></h2><h3 id=learning-trajectories-of-figurative-language-for-pre-trained-language-modelshttpsaclanthologyorg2025findings-emnlp779><a href=https://aclanthology.org/2025.findings-emnlp.779/>Learning Trajectories of Figurative Language for Pre-Trained Language Models</a><a hidden class=anchor aria-hidden=true href=#learning-trajectories-of-figurative-language-for-pre-trained-language-modelshttpsaclanthologyorg2025findings-emnlp779>#</a></h3><p><strong>Authors:</strong>
<strong>Venue:</strong> (Fri,)</p><p>Nicola Arici, Luca Putelli, Ejdis Gjinika, Ivan Serina and Alfonso Gerevini in Findings of the Association for Computational Linguistics: EMNLP 2025</p><p><a href="https://papersdb.wangyilin-0429.workers.dev/api/save?pid=https://aclanthology.org/papers/2025.findings-emnlp.779">üì• Save to Zotero</a> ¬†¬† <a href="https://papersdb.wangyilin-0429.workers.dev/api/pdf?pid=https://aclanthology.org/papers/2025.findings-emnlp.779">üìÑ Download PDF</a></p><hr></div><footer class=post-footer><ul class=post-tags></ul></footer><div><div class=pagination__title><span class=pagination__title-h style=font-size:20px>Comments</span><hr></div><div id=tcomment></div><script src=https://cdn.staticfile.org/twikoo/1.6.39/twikoo.all.min.js></script><script>twikoo.init({envId:"https://mangodb-theta.vercel.app/",el:"#tcomment",lang:"en-US",path:window.TWIKOO_MAGIC_PATH||window.location.pathname})</script></div></article></main><footer class=footer><span>&copy; 2026 <a href=https://garyforreal.me/zh/>Gary's House</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span><div class=busuanzi-footer><span id=busuanzi_container_site_pv>Views: <span id=busuanzi_value_site_pv></span>
</span><span id=busuanzi_container_site_uv>Visitors: <span id=busuanzi_value_site_uv></span></span></div></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="Â§çÂà∂";function s(){t.innerHTML="Â∑≤Â§çÂà∂ÔºÅ",setTimeout(()=>{t.innerHTML="Â§çÂà∂"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>